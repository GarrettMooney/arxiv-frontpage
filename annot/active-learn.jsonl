{"text":"Personalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1102641885,"dev-research":0.4281315079,"prompt-eng":0.5110887158,"data-quality":0.1390148647,"ml-security":0.1578728936}}
{"text":"However, the process of personalization presents inherent challenges in terms of time and memory requirements.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1095203201,"dev-research":0.4291537992,"prompt-eng":0.4754930095,"data-quality":0.1193310142,"ml-security":0.1721599794}}
{"text":"Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1410360466,"dev-research":0.3745104113,"prompt-eng":0.4628008494,"data-quality":0.0636506325,"ml-security":0.1141571511}}
{"text":"To overcome these challenges, we propose HyperDreamBooth-a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1835820264,"dev-research":0.3940892307,"prompt-eng":0.4499724373,"data-quality":0.1005353545,"ml-security":0.191418312}}
{"text":"By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1053912783,"dev-research":0.4018335269,"prompt-eng":0.4704705816,"data-quality":0.0868953603,"ml-security":0.1447642014}}
{"text":"Our method achieves personalization on faces in roughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual Inversion, using as few as one reference image, with the same quality and style diversity as DreamBooth.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.166558517,"dev-research":0.4107819475,"prompt-eng":0.4641341848,"data-quality":0.0992931599,"ml-security":0.1431637526}}
{"text":"Also our method yields a model that is 10000x smaller than a normal DreamBooth model.","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.1082313974,"dev-research":0.3918402052,"prompt-eng":0.4034732291,"data-quality":0.0815506094,"ml-security":0.0993831358}}
{"text":"Project page: https://hyperdreambooth.github.io","meta":{"url":"http://arxiv.org/abs/2307.06949v1"},"cats":{"new-dataset":0.3704907435,"dev-research":0.4656692565,"prompt-eng":0.4271637003,"data-quality":0.0978537376,"ml-security":0.0898415628}}
{"text":"Prompt learning has emerged as an efficient alternative for fine-tuning foundational models, such as CLIP, for various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.063448306,"dev-research":0.4311859652,"prompt-eng":0.6274809346,"data-quality":0.1248234177,"ml-security":0.2489073076}}
{"text":"Conventionally trained using the task-specific objective, i.e., cross-entropy loss, prompts tend to overfit downstream data distributions and find it challenging to capture task-agnostic general features from the frozen CLIP.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.1724550447,"dev-research":0.4023520602,"prompt-eng":0.5356278415,"data-quality":0.2090762395,"ml-security":0.2760334727}}
{"text":"This leads to the loss of the model's original generalization capability.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.0217584863,"dev-research":0.4250512537,"prompt-eng":0.4305654638,"data-quality":0.2282507319,"ml-security":0.2827889664}}
{"text":"To address this issue, our work introduces a self-regularization framework for prompting called PromptSRC (Prompting with Self-regulating Constraints).","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.0655959058,"dev-research":0.4724304374,"prompt-eng":0.6473896676,"data-quality":0.286401422,"ml-security":0.2417422612}}
{"text":"PromptSRC guides the prompts to optimize for both task-specific and task-agnostic general representations using a three-pronged approach by: (a) regulating {prompted} representations via mutual agreement maximization with the frozen model, (b) regulating with self-ensemble of prompts over the training trajectory to encode their complementary strengths, and (c) regulating with textual diversity to mitigate sample diversity imbalance with the visual branch.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.1036562989,"dev-research":0.4334266667,"prompt-eng":0.6169387343,"data-quality":0.2112517288,"ml-security":0.1745702117}}
{"text":"To the best of our knowledge, this is the first regularization framework for prompt learning that avoids overfitting by jointly attending to pre-trained model features, the training trajectory during prompting, and the textual diversity.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.0885777338,"dev-research":0.4257698668,"prompt-eng":0.6200204496,"data-quality":0.2702269205,"ml-security":0.3107256479}}
{"text":"PromptSRC explicitly steers the prompts to learn a representation space that maximizes performance on downstream tasks without compromising CLIP generalization.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.0729613392,"dev-research":0.4716917686,"prompt-eng":0.5844492039,"data-quality":0.1043478749,"ml-security":0.2031773493}}
{"text":"We perform extensive experiments on 4 benchmarks where PromptSRC overall performs favorably well compared to the existing methods.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.1236988417,"dev-research":0.4318279007,"prompt-eng":0.6268827694,"data-quality":0.1225273898,"ml-security":0.1508837665}}
{"text":"Our code and pre-trained models are publicly available at: https://github.com/muzairkhattak/PromptSRC.","meta":{"url":"http://arxiv.org/abs/2307.06948v1"},"cats":{"new-dataset":0.390631773,"dev-research":0.4561983645,"prompt-eng":0.610557801,"data-quality":0.0923094118,"ml-security":0.2097886847}}
{"text":"Recent video recognition models utilize Transformer models for long-range spatio-temporal context modeling.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.1489282455,"dev-research":0.339369966,"prompt-eng":0.4166894482,"data-quality":0.0898458831,"ml-security":0.0899305991}}
{"text":"Video transformer designs are based on self-attention that can model global context at a high computational cost.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.0879413929,"dev-research":0.4036865997,"prompt-eng":0.444749153,"data-quality":0.0935887301,"ml-security":0.0801621613}}
{"text":"In comparison, convolutional designs for videos offer an efficient alternative but lack long-range dependency modeling.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.122627617,"dev-research":0.3970215981,"prompt-eng":0.4369445127,"data-quality":0.085043489,"ml-security":0.0704537934}}
{"text":"Towards achieving the best of both designs, this work proposes Video-FocalNet, an effective and efficient architecture for video recognition that models both local and global contexts.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.1850045412,"dev-research":0.3621084309,"prompt-eng":0.4193154723,"data-quality":0.1417914241,"ml-security":0.0990348897}}
{"text":"Video-FocalNet is based on a spatio-temporal focal modulation architecture that reverses the interaction and aggregation steps of self-attention for better efficiency.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.1172180487,"dev-research":0.3848349445,"prompt-eng":0.4535694826,"data-quality":0.0798459599,"ml-security":0.0818338037}}
{"text":"Further, the aggregation step and the interaction step are both implemented using efficient convolution and element-wise multiplication operations that are computationally less expensive than their self-attention counterparts on video representations.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.0727580317,"dev-research":0.3895691785,"prompt-eng":0.4317652982,"data-quality":0.0755853108,"ml-security":0.0436566923}}
{"text":"We extensively explore the design space of focal modulation-based spatio-temporal context modeling and demonstrate our parallel spatial and temporal encoding design to be the optimal choice.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.1325337269,"dev-research":0.3798136912,"prompt-eng":0.4121392956,"data-quality":0.0421564795,"ml-security":0.0742095806}}
{"text":"Video-FocalNets perform favorably well against the state-of-the-art transformer-based models for video recognition on three large-scale datasets (Kinetics-400, Kinetics-600, and SS-v2) at a lower computational cost.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.2368231714,"dev-research":0.3150843909,"prompt-eng":0.4089141234,"data-quality":0.1120216884,"ml-security":0.1561882789}}
{"text":"Our code/models are released at https://github.com/TalalWasim/Video-FocalNets.","meta":{"url":"http://arxiv.org/abs/2307.06947v1"},"cats":{"new-dataset":0.35500464,"dev-research":0.4158438088,"prompt-eng":0.454707876,"data-quality":0.0874673378,"ml-security":0.0828369215}}
{"text":"We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM).","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.2469880295,"dev-research":0.4229129123,"prompt-eng":0.5219651277,"data-quality":0.2716855647,"ml-security":0.1198146375}}
{"text":"The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.1548454562,"dev-research":0.4268466089,"prompt-eng":0.4627797188,"data-quality":0.1172740051,"ml-security":0.1212357862}}
{"text":"We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.324903084,"dev-research":0.4359770224,"prompt-eng":0.5371948865,"data-quality":0.3127735957,"ml-security":0.1228553414}}
{"text":"Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.1141015553,"dev-research":0.4510489334,"prompt-eng":0.5348240117,"data-quality":0.1582682709,"ml-security":0.1682504472}}
{"text":"Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.0974918611,"dev-research":0.4325466343,"prompt-eng":0.5498024678,"data-quality":0.1602409806,"ml-security":0.1831196723}}
{"text":"The promising results demonstrate significant implications of the ICAE for its novel approach to the long context problem and its potential to reduce computation and memory overheads for LLM inference in practice, suggesting further research effort in context management for an LLM.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.0758098078,"dev-research":0.4216827119,"prompt-eng":0.470809943,"data-quality":0.0904082928,"ml-security":0.1437534006}}
{"text":"Our code and data will be released shortly.","meta":{"url":"http://arxiv.org/abs/2307.06945v1"},"cats":{"new-dataset":0.7879385764,"dev-research":0.5107394329,"prompt-eng":0.5010766323,"data-quality":0.101941066,"ml-security":0.2620133541}}
{"text":"This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.6794630971,"dev-research":0.4255285183,"prompt-eng":0.4997542668,"data-quality":0.144212878,"ml-security":0.0653502508}}
{"text":"The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.6865598338,"dev-research":0.3901299881,"prompt-eng":0.4162780861,"data-quality":0.1673425652,"ml-security":0.0895661481}}
{"text":"Our core contribution is to develop a scalable approach to autonomously build a high-quality video-text dataset with large language models (LLM), thereby showcasing its efficacy in learning video-language representation at scale.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.4740059962,"dev-research":0.405390141,"prompt-eng":0.5505862586,"data-quality":0.2444851574,"ml-security":0.128157285}}
{"text":"Specifically, we utilize a multi-scale approach to generate video-related descriptions.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.2680641875,"dev-research":0.4725106031,"prompt-eng":0.5470914512,"data-quality":0.1984926628,"ml-security":0.0343034599}}
{"text":"Furthermore, we introduce ViCLIP, a video-text representation learning model based on ViT-L. Learned on InternVid via contrastive learning, this model demonstrates leading zero-shot action recognition and competitive video retrieval performance.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.2934569322,"dev-research":0.3814904855,"prompt-eng":0.4498366715,"data-quality":0.140137688,"ml-security":0.0880179411}}
{"text":"Beyond basic video understanding tasks like recognition and retrieval, our dataset and model have broad applications.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.3377966442,"dev-research":0.3994396252,"prompt-eng":0.4322223897,"data-quality":0.1054050884,"ml-security":0.0894307194}}
{"text":"They are particularly beneficial for generating interleaved video-text data for learning a video-centric dialogue system, advancing video-to-text and text-to-video generation research.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.44072042,"dev-research":0.4671834347,"prompt-eng":0.5707763097,"data-quality":0.2030714307,"ml-security":0.0860275984}}
{"text":"These proposed resources provide a tool for researchers and practitioners interested in multimodal video understanding and generation.","meta":{"url":"http://arxiv.org/abs/2307.06942v1"},"cats":{"new-dataset":0.3937631025,"dev-research":0.4669875979,"prompt-eng":0.5149479395,"data-quality":0.1222795072,"ml-security":0.0312696119}}
{"text":"Explainable Artificial Intelligence (XAI) has received widespread interest in recent years, and two of the most popular types of explanations are feature attributions, and counterfactual explanations.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.1537707459,"dev-research":0.5097681186,"prompt-eng":0.4997752656,"data-quality":0.2081649082,"ml-security":0.2855906324}}
{"text":"These classes of approaches have been largely studied independently and the few attempts at reconciling them have been primarily empirical.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.0466090138,"dev-research":0.4503357603,"prompt-eng":0.3894537976,"data-quality":0.0942233037,"ml-security":0.0842841675}}
{"text":"This work establishes a clear theoretical connection between game-theoretic feature attributions, focusing on but not limited to SHAP, and counterfactuals explanations.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.1019187029,"dev-research":0.4762657666,"prompt-eng":0.4473598641,"data-quality":0.175395635,"ml-security":0.3460525291}}
{"text":"After motivating operative changes to Shapley values based feature attributions and counterfactual explanations, we prove that, under conditions, they are in fact equivalent.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.0769869974,"dev-research":0.4615073715,"prompt-eng":0.4760835844,"data-quality":0.2532613997,"ml-security":0.1977718142}}
{"text":"We then extend the equivalency result to game-theoretic solution concepts beyond Shapley values.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.0796558376,"dev-research":0.4463185824,"prompt-eng":0.3800201405,"data-quality":0.0879136672,"ml-security":0.1589417814}}
{"text":"Moreover, through the analysis of the conditions of such equivalence, we shed light on the limitations of naively using counterfactual explanations to provide feature importances.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.0575245533,"dev-research":0.4671886956,"prompt-eng":0.4564168525,"data-quality":0.2786159552,"ml-security":0.2202089741}}
{"text":"Experiments on three datasets quantitatively show the difference in explanations at every stage of the connection between the two approaches and corroborate the theoretical findings.","meta":{"url":"http://arxiv.org/abs/2307.06941v1"},"cats":{"new-dataset":0.0972125544,"dev-research":0.4960509877,"prompt-eng":0.4085483846,"data-quality":0.2021585636,"ml-security":0.1518564148}}
{"text":"Generating videos for visual storytelling can be a tedious and complex process that typically requires either live-action filming or graphics animation rendering.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.1713602727,"dev-research":0.4606439626,"prompt-eng":0.4347544784,"data-quality":0.0751715238,"ml-security":0.0442448514}}
{"text":"To bypass these challenges, our key idea is to utilize the abundance of existing video clips and synthesize a coherent storytelling video by customizing their appearances.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.1762467118,"dev-research":0.4581194703,"prompt-eng":0.4736402367,"data-quality":0.1335405305,"ml-security":0.080618268}}
{"text":"We achieve this by developing a framework comprised of two functional modules: (i) Motion Structure Retrieval, which provides video candidates with desired scene or motion context described by query texts, and (ii) Structure-Guided Text-to-Video Synthesis, which generates plot-aligned videos under the guidance of motion structure and text prompts.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.3164792573,"dev-research":0.4340571809,"prompt-eng":0.4893878603,"data-quality":0.0967903115,"ml-security":0.034882362}}
{"text":"For the first module, we leverage an off-the-shelf video retrieval system and extract video depths as motion structure.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.3652707204,"dev-research":0.3683099571,"prompt-eng":0.4318875553,"data-quality":0.0797882712,"ml-security":0.0334859901}}
{"text":"For the second module, we propose a controllable video generation model that offers flexible controls over structure and characters.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.1683156926,"dev-research":0.4383793777,"prompt-eng":0.4957828541,"data-quality":0.1020045393,"ml-security":0.0420265483}}
{"text":"The videos are synthesized by following the structural guidance and appearance instruction.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.2282504809,"dev-research":0.4281960553,"prompt-eng":0.4531668744,"data-quality":0.0740752626,"ml-security":0.0458582619}}
{"text":"To ensure visual consistency across clips, we propose an effective concept personalization approach, which allows the specification of the desired character identities through text prompts.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.1794869065,"dev-research":0.4671560595,"prompt-eng":0.5943407519,"data-quality":0.2893797193,"ml-security":0.1372039071}}
{"text":"Extensive experiments demonstrate that our approach exhibits significant advantages over various existing baselines.","meta":{"url":"http://arxiv.org/abs/2307.06940v1"},"cats":{"new-dataset":0.0402962843,"dev-research":0.4515732053,"prompt-eng":0.4190894245,"data-quality":0.0950934845,"ml-security":0.0909635324}}
{"text":"As digital technologies become more pervasive in society and the economy, cybersecurity incidents become more frequent and impactful.","meta":{"url":"http://arxiv.org/abs/2307.06932v1"},"cats":{"new-dataset":0.1300085286,"dev-research":0.4868228761,"prompt-eng":0.4359044244,"data-quality":0.0929073982,"ml-security":0.4840359971}}
{"text":"According to the NIS and NIS2 Directives, EU Member States and their Operators of Essential Services must establish a minimum baseline set of cybersecurity capabilities and engage in cross-border coordination and cooperation.","meta":{"url":"http://arxiv.org/abs/2307.06932v1"},"cats":{"new-dataset":0.077975295,"dev-research":0.4165225538,"prompt-eng":0.4046827179,"data-quality":0.0831690044,"ml-security":0.2672814141}}
{"text":"However, this is only a small step towards European cyber resilience.","meta":{"url":"http://arxiv.org/abs/2307.06932v1"},"cats":{"new-dataset":0.0663061459,"dev-research":0.4442062396,"prompt-eng":0.3810752307,"data-quality":0.126708186,"ml-security":0.3998680853}}
{"text":"In this landscape, preparedness, shared situational awareness, and coordinated incident response are essential for effective cyber crisis management and resilience.","meta":{"url":"http://arxiv.org/abs/2307.06932v1"},"cats":{"new-dataset":0.2126842401,"dev-research":0.4591290213,"prompt-eng":0.4839603193,"data-quality":0.1022438792,"ml-security":0.2857165982}}
{"text":"Motivated by the above, this paper presents PHOENI2X, an EU-funded project aiming to design, develop, and deliver a Cyber Resilience Framework providing Artificial-Intelligence-assisted orchestration, automation and response capabilities for business continuity and recovery, incident response, and information exchange, tailored to the needs of Operators of Essential Services and the EU Member State authorities entrusted with cybersecurity.","meta":{"url":"http://arxiv.org/abs/2307.06932v1"},"cats":{"new-dataset":0.2328621361,"dev-research":0.4452994486,"prompt-eng":0.4672364684,"data-quality":0.1157144632,"ml-security":0.3161519349}}
{"text":"Modular vision-language models (Vision-LLMs) align pretrained image encoders with (pretrained) large language models (LLMs), representing a computationally much more efficient alternative to end-to-end training of large vision-language models from scratch, which is prohibitively expensive for most.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.1806059627,"dev-research":0.4215488443,"prompt-eng":0.5495214563,"data-quality":0.1175278853,"ml-security":0.1117397668}}
{"text":"Vision-LLMs instead post-hoc condition LLMs to `understand' the output of an image encoder.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.0763243095,"dev-research":0.4255888274,"prompt-eng":0.484831618,"data-quality":0.1530620587,"ml-security":0.116536614}}
{"text":"With the abundance of readily available high-quality English image-text data as well as monolingual English LLMs, the research focus has been on English-only Vision-LLMs.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.3367601971,"dev-research":0.4002820459,"prompt-eng":0.5617011555,"data-quality":0.2200615053,"ml-security":0.0925378911}}
{"text":"Multilingual vision-language models are still predominantly obtained via expensive end-to-end pretraining, resulting in comparatively smaller models, trained on limited multilingual image data supplemented with text-only multilingual corpora.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.3626108467,"dev-research":0.3890306999,"prompt-eng":0.5267132245,"data-quality":0.21823452,"ml-security":0.0921119902}}
{"text":"In this work, we present mBLIP, the first multilingual Vision-LLM, which we obtain in a computationally efficient manner -- on consumer hardware using only a few million training examples -- by leveraging a pretrained multilingual LLM.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.3402902223,"dev-research":0.4160814013,"prompt-eng":0.5329746775,"data-quality":0.1789950384,"ml-security":0.0962513963}}
{"text":"To this end, we \\textit{re-align} an image encoder previously tuned to an English LLM to a new, multilingual LLM -- for this, we leverage multilingual data from a mix of vision-and-language tasks, which we obtain by machine-translating high-quality English data to 95 languages.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.4642041363,"dev-research":0.4373354633,"prompt-eng":0.5522826407,"data-quality":0.2372174404,"ml-security":0.0628755942}}
{"text":"On the IGLUE benchmark, mBLIP yields results competitive with state-of-the-art models.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.1365452449,"dev-research":0.371666522,"prompt-eng":0.4162515131,"data-quality":0.0778108862,"ml-security":0.0618012343}}
{"text":"Moreover, in image captioning on XM3600, mBLIP (zero-shot) even outperforms PaLI-X (a model with 55B parameters).","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.1939179655,"dev-research":0.3758302152,"prompt-eng":0.4872268238,"data-quality":0.2836606769,"ml-security":0.0990719475}}
{"text":"Compared to these very large multilingual vision-language models trained from scratch, we obtain mBLIP by training orders of magnitude fewer parameters on magnitudes less data.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.3302481693,"dev-research":0.4091029584,"prompt-eng":0.5183453666,"data-quality":0.2488211918,"ml-security":0.113161633}}
{"text":"We release our model and code at \\url{https://github.com/gregor-ge/mBLIP}.","meta":{"url":"http://arxiv.org/abs/2307.06930v1"},"cats":{"new-dataset":0.2657775778,"dev-research":0.4238667806,"prompt-eng":0.5077353347,"data-quality":0.149962603,"ml-security":0.1287645617}}
{"text":"We introduce two-sided type systems, which are a particular kind of sequent calculi for typing formulas.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.1088072315,"dev-research":0.4506465534,"prompt-eng":0.4332817795,"data-quality":0.0940173066,"ml-security":0.115226364}}
{"text":"Two-sided type systems allow for hypothetical reasoning over the typing of compound program expressions, and the refutation of typing formulas.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.0599773666,"dev-research":0.5199488834,"prompt-eng":0.4312451802,"data-quality":0.1040215816,"ml-security":0.1542012845}}
{"text":"By incorporating a type of all values, these type systems support symmetrical notions of well-typing and ill-typing, guaranteeing both that well-typed programs don't go wrong and that ill-typed programs do not evaluate - that is, reach a value.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.0513672351,"dev-research":0.4975511343,"prompt-eng":0.4509007666,"data-quality":0.1519060654,"ml-security":0.1940090572}}
{"text":"This makes two-sided type systems suitable for incorrectness reasoning in higher-order program verification, which we illustrate through an application to precise data-flow typing in a language with constructors and pattern matching.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.0912063774,"dev-research":0.5133402375,"prompt-eng":0.4784679381,"data-quality":0.267035643,"ml-security":0.1766159323}}
{"text":"Finally, we investigate the internalisation of the meta-level negation in the system as a complement operator on types.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.0559817307,"dev-research":0.4489922991,"prompt-eng":0.4197286618,"data-quality":0.2128020825,"ml-security":0.1153166243}}
{"text":"This motivates an alternative semantics for the typing judgement, which guarantees that ill-typed programs don't evaluate, but in which well-typed programs may yet go wrong.","meta":{"url":"http://arxiv.org/abs/2307.06928v1"},"cats":{"new-dataset":0.0260825998,"dev-research":0.5625784648,"prompt-eng":0.4506689102,"data-quality":0.2344060653,"ml-security":0.1708629212}}
{"text":"Text-to-image (T2I) personalization allows users to guide the creative image generation process by combining their own visual concepts in natural language prompts.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.2589851345,"dev-research":0.4957772278,"prompt-eng":0.5754303482,"data-quality":0.2017269742,"ml-security":0.0832795487}}
{"text":"Recently, encoder-based techniques have emerged as a new effective approach for T2I personalization, reducing the need for multiple images and long training times.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.1593350803,"dev-research":0.4124299277,"prompt-eng":0.4970302219,"data-quality":0.133259781,"ml-security":0.1412079145}}
{"text":"However, most existing encoders are limited to a single-class domain, which hinders their ability to handle diverse concepts.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.0745152978,"dev-research":0.4176462594,"prompt-eng":0.4084600557,"data-quality":0.1373634401,"ml-security":0.236417832}}
{"text":"In this work, we propose a domain-agnostic method that does not require any specialized dataset or prior information about the personalized concepts.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.2693625954,"dev-research":0.4319983098,"prompt-eng":0.4815062368,"data-quality":0.2267669636,"ml-security":0.1677605759}}
{"text":"We introduce a novel contrastive-based regularization technique to maintain high fidelity to the target concept characteristics while keeping the predicted embeddings close to editable regions of the latent space, by pushing the predicted tokens toward their nearest existing CLIP tokens.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.0893361644,"dev-research":0.4139282346,"prompt-eng":0.5341348257,"data-quality":0.3543489542,"ml-security":0.1514619766}}
{"text":"Our experimental results demonstrate the effectiveness of our approach and show how the learned tokens are more semantic than tokens predicted by unregularized models.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.0687854605,"dev-research":0.4511484709,"prompt-eng":0.5521609679,"data-quality":0.47262751,"ml-security":0.2799806601}}
{"text":"This leads to a better representation that achieves state-of-the-art performance while being more flexible than previous methods.","meta":{"url":"http://arxiv.org/abs/2307.06925v1"},"cats":{"new-dataset":0.0430654126,"dev-research":0.4554705762,"prompt-eng":0.4049444197,"data-quality":0.1043238294,"ml-security":0.0757448568}}
{"text":"Persons with visual impairments (PwVI) have difficulties understanding and navigating spaces around them.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.0587957737,"dev-research":0.417406728,"prompt-eng":0.3882723369,"data-quality":0.1263678606,"ml-security":0.0616891375}}
{"text":"Current wayfinding technologies either focus solely on navigation or provide limited communication about the environment.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.0450734004,"dev-research":0.4425205344,"prompt-eng":0.378676139,"data-quality":0.0447038991,"ml-security":0.1058939809}}
{"text":"Motivated by recent advances in visual-language grounding and semantic navigation, we propose DRAGON, a guiding robot powered by a dialogue system and the ability to associate the environment with natural language.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.2599498926,"dev-research":0.4695421161,"prompt-eng":0.5572841691,"data-quality":0.1654754788,"ml-security":0.106580059}}
{"text":"By understanding the commands from the user, DRAGON is able to guide the user to the desired landmarks on the map, describe the environment, and answer questions from visual observations.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.2179367155,"dev-research":0.5060063751,"prompt-eng":0.5028972292,"data-quality":0.086297541,"ml-security":0.0900957559}}
{"text":"Through effective utilization of dialogue, the robot can ground the user's free-form descriptions to landmarks in the environment, and give the user semantic information through spoken language.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.2060542218,"dev-research":0.4747503463,"prompt-eng":0.5734860629,"data-quality":0.1169012803,"ml-security":0.092948175}}
{"text":"We conduct a user study with blindfolded participants in an everyday indoor environment.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.2764433098,"dev-research":0.4212357832,"prompt-eng":0.4275912779,"data-quality":0.0776210738,"ml-security":0.1421604361}}
{"text":"Our results demonstrate that DRAGON is able to communicate with the user smoothly, provide a good guiding experience, and connect users with their surrounding environment in an intuitive manner.","meta":{"url":"http://arxiv.org/abs/2307.06924v1"},"cats":{"new-dataset":0.1849397114,"dev-research":0.500037428,"prompt-eng":0.4807333491,"data-quality":0.076243616,"ml-security":0.1190940357}}
{"text":"Alloy is a declarative modeling language that is well suited for verifying system designs.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.0475235813,"dev-research":0.4486772817,"prompt-eng":0.4792472773,"data-quality":0.1010251495,"ml-security":0.1407645224}}
{"text":"Alloy models are automatically analyzed using the Analyzer, a toolset that helps the user understand their system by displaying the consequences of their properties, helping identify any missing or incorrect properties, and exploring the impact of modifications to those properties.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.0722722869,"dev-research":0.4576696942,"prompt-eng":0.4926398369,"data-quality":0.1351810686,"ml-security":0.1179869959}}
{"text":"To achieve this, the Analyzer invokes off-the-shelf SAT solvers to search for scenarios, which are assignments to the sets and relations of the model such that all executed formulas hold.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.1628846477,"dev-research":0.4321971486,"prompt-eng":0.4682566731,"data-quality":0.0696056661,"ml-security":0.1492758857}}
{"text":"To help write more accurate software models, Alloy has a unit testing framework, AUnit, which allows users to outline specific scenarios and check if those scenarios are correctly generated or prevented by their model.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.0947678014,"dev-research":0.4611352824,"prompt-eng":0.5174430719,"data-quality":0.1220275904,"ml-security":0.1881280065}}
{"text":"Unfortunately, AUnit currently only supports textual specifications of scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.1996067916,"dev-research":0.4654374372,"prompt-eng":0.5363802206,"data-quality":0.1573068356,"ml-security":0.1361966362}}
{"text":"This paper introduces Crucible, which allows users to graphically create AUnit test cases.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.173546409,"dev-research":0.496829794,"prompt-eng":0.5110246266,"data-quality":0.1320753825,"ml-security":0.3136474449}}
{"text":"In addition, Crucible provides automated guidance to users to ensure they are creating well structured, valuable test cases.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.1346983879,"dev-research":0.4956349166,"prompt-eng":0.514417022,"data-quality":0.1141179195,"ml-security":0.1926638256}}
{"text":"As a result, Crucible eases the burden of adopting AUnit and brings AUnit test case creation more in line with how Alloy scenarios are commonly interacted with, which is graphically.","meta":{"url":"http://arxiv.org/abs/2307.06922v1"},"cats":{"new-dataset":0.0505769261,"dev-research":0.4622795977,"prompt-eng":0.4790158349,"data-quality":0.1034406008,"ml-security":0.2244801031}}
{"text":"We present a new procedure to infer size bounds for integer programs automatically.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.1090409264,"dev-research":0.4936688798,"prompt-eng":0.41388701,"data-quality":0.1086573306,"ml-security":0.1932301219}}
{"text":"Size bounds are important for the deduction of bounds on the runtime complexity or in general, for the resource analysis of programs.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.0573668627,"dev-research":0.4795396069,"prompt-eng":0.3269668874,"data-quality":0.066117506,"ml-security":0.2254688552}}
{"text":"We show that our technique is complete (i.e., it always computes finite size bounds) for a subclass of loops, possibly with non-linear arithmetic.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.1088828152,"dev-research":0.4146325117,"prompt-eng":0.351531993,"data-quality":0.1430388219,"ml-security":0.1864690345}}
{"text":"Moreover, we present a novel approach to combine and integrate this complete technique into an incomplete approach to infer size and runtime bounds of general integer programs.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.0814942454,"dev-research":0.4645969101,"prompt-eng":0.3711082322,"data-quality":0.0700357693,"ml-security":0.1721637796}}
{"text":"We prove completeness of our integration for an important subclass of integer programs.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.0747918756,"dev-research":0.461788082,"prompt-eng":0.4135604923,"data-quality":0.1285000091,"ml-security":0.1516275748}}
{"text":"We implemented our new algorithm in the automated complexity analysis tool KoAT to evaluate its power, in particular on programs with non-linear arithmetic.","meta":{"url":"http://arxiv.org/abs/2307.06921v1"},"cats":{"new-dataset":0.0957873836,"dev-research":0.4948305681,"prompt-eng":0.3614969567,"data-quality":0.0966339344,"ml-security":0.1399410724}}
{"text":"Federated and decentralized networks supporting frequently changing system participants are a requirement for future Internet of Things (IoT) use cases.","meta":{"url":"http://arxiv.org/abs/2307.06919v1"},"cats":{"new-dataset":0.1150876792,"dev-research":0.4143116297,"prompt-eng":0.402515377,"data-quality":0.0551124209,"ml-security":0.23802494}}
{"text":"IoT devices and networks often lack adequate authentication and authorization mechanisms, resulting in insufficient privacy for entities in such systems.","meta":{"url":"http://arxiv.org/abs/2307.06919v1"},"cats":{"new-dataset":0.0539699127,"dev-research":0.4271292639,"prompt-eng":0.3965588046,"data-quality":0.107886929,"ml-security":0.4314795244}}
{"text":"In this work we address both issues by designing a privacy preserving challenge-response style authentication and authorization scheme based on Decentralized Identifiers and Verifiable Credentials.","meta":{"url":"http://arxiv.org/abs/2307.06919v1"},"cats":{"new-dataset":0.0984183276,"dev-research":0.4062149149,"prompt-eng":0.4354324624,"data-quality":0.1369500816,"ml-security":0.4866076721}}
{"text":"Our solution allows a decentralized permission management of frequently changing network participants and supports authenticated encryption for data confidentiality.","meta":{"url":"http://arxiv.org/abs/2307.06919v1"},"cats":{"new-dataset":0.20384952,"dev-research":0.4354241057,"prompt-eng":0.4171292979,"data-quality":0.0599224276,"ml-security":0.4403290885}}
{"text":"We demonstrate our solution in an MQTT 5.0 scenario and evaluate its security, privacy guarantees, and performance.","meta":{"url":"http://arxiv.org/abs/2307.06919v1"},"cats":{"new-dataset":0.1595076609,"dev-research":0.427232531,"prompt-eng":0.4182549963,"data-quality":0.0981818258,"ml-security":0.3708836121}}
{"text":"Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.3833253962,"dev-research":0.4293191742,"prompt-eng":0.435493436,"data-quality":0.104094925,"ml-security":0.1132559013}}
{"text":"KGs surpass any other form of representation in terms of effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.0372601728,"dev-research":0.3732149988,"prompt-eng":0.3955121178,"data-quality":0.0959333215,"ml-security":0.1523168273}}
{"text":"However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.1581393956,"dev-research":0.4489883585,"prompt-eng":0.4195617245,"data-quality":0.0864224209,"ml-security":0.0973766101}}
{"text":"It also demands a significant amount of work.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.0575841456,"dev-research":0.4390548029,"prompt-eng":0.3366180278,"data-quality":0.0600531708,"ml-security":0.0717169442}}
{"text":"Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.120261028,"dev-research":0.4244787764,"prompt-eng":0.6019210526,"data-quality":0.1524692925,"ml-security":0.1076659843}}
{"text":"In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.","meta":{"url":"http://arxiv.org/abs/2307.06917v1"},"cats":{"new-dataset":0.1894621315,"dev-research":0.4194931456,"prompt-eng":0.4729175852,"data-quality":0.0820012659,"ml-security":0.0730976483}}
{"text":"Interpreting the inner workings of deep learning models is crucial for establishing trust and ensuring model safety.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.0895456232,"dev-research":0.4256600907,"prompt-eng":0.4609425911,"data-quality":0.2584943879,"ml-security":0.5647496493}}
{"text":"Concept-based explanations have emerged as a superior approach that is more interpretable than feature attribution estimates such as pixel saliency.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.1033917681,"dev-research":0.4902914828,"prompt-eng":0.4742356888,"data-quality":0.285521861,"ml-security":0.1640890853}}
{"text":"However, defining the concepts for the interpretability analysis biases the explanations by the user's expectations on the concepts.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.0843992973,"dev-research":0.4925904403,"prompt-eng":0.458447634,"data-quality":0.2941342328,"ml-security":0.1817487795}}
{"text":"To address this, we propose a novel post-hoc unsupervised method that automatically uncovers the concepts learned by deep models during training.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.1748559439,"dev-research":0.42312381,"prompt-eng":0.5368364817,"data-quality":0.2406201682,"ml-security":0.2668518868}}
{"text":"By decomposing the latent space of a layer in singular vectors and refining them by unsupervised clustering, we uncover concept vectors aligned with directions of high variance that are relevant to the model prediction, and that point to semantically distinct concepts.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.0953589484,"dev-research":0.4251660428,"prompt-eng":0.497340485,"data-quality":0.2659643247,"ml-security":0.1993595196}}
{"text":"Our extensive experiments reveal that the majority of our concepts are readily understandable to humans, exhibit coherency, and bear relevance to the task at hand.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.0783298249,"dev-research":0.4646971476,"prompt-eng":0.4543623642,"data-quality":0.1539698909,"ml-security":0.1048377784}}
{"text":"Moreover, we showcase the practical utility of our method in dataset exploration, where our concept vectors successfully identify outlier training samples affected by various confounding factors.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.2564239744,"dev-research":0.4421826622,"prompt-eng":0.4716239551,"data-quality":0.4467742383,"ml-security":0.4366415026}}
{"text":"This novel exploration technique has remarkable versatility to data types and model architectures and it will facilitate the identification of biases and the discovery of sources of error within training data.","meta":{"url":"http://arxiv.org/abs/2307.06913v1"},"cats":{"new-dataset":0.1180808422,"dev-research":0.3989645242,"prompt-eng":0.498763822,"data-quality":0.3262287028,"ml-security":0.2402143556}}
{"text":"Swarm robotics is an emerging field of research which is increasingly attracting attention thanks to the advances in robotics and its potential applications.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.0844291737,"dev-research":0.3826015368,"prompt-eng":0.4300215266,"data-quality":0.0674187064,"ml-security":0.0783617264}}
{"text":"However, despite the enthusiasm surrounding this area of research, software development for swarm robotics is still a tedious task.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.0999309534,"dev-research":0.4794822435,"prompt-eng":0.4329718542,"data-quality":0.0638081904,"ml-security":0.0790980319}}
{"text":"That fact is partly due to the lack of dedicated solutions, in particular for low-cost systems to be produced in large numbers and that can have important resource constraints.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.0636159608,"dev-research":0.4800573073,"prompt-eng":0.344223571,"data-quality":0.0650158452,"ml-security":0.1119234706}}
{"text":"To address this issue, we introduce BittyBuzz, a novel runtime platform: it allows Buzz, a domain-specific language, to run on microcontrollers while maintaining dynamic memory management.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.2447602875,"dev-research":0.5056926828,"prompt-eng":0.512778955,"data-quality":0.1662840797,"ml-security":0.1854433849}}
{"text":"BittyBuzz is designed to fit a flash memory as small as 32 kB (with usable space for scripts) and work with as little as 2 kB of RAM.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.1836297968,"dev-research":0.4821969931,"prompt-eng":0.4420664677,"data-quality":0.0780576304,"ml-security":0.1326578789}}
{"text":"In this work, we introduce the BittyBuzz implementation, its differences from the original Buzz virtual machine, and its advantages for swarm robotics systems.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.1603744785,"dev-research":0.4576168604,"prompt-eng":0.4610471853,"data-quality":0.1152837932,"ml-security":0.0940156724}}
{"text":"We show that BittyBuzz is successfully integrated with three robotic platforms with minimal memory footprint and conduct experiments to show computation performance of BittyBuzz.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.1543140689,"dev-research":0.4476259356,"prompt-eng":0.436630223,"data-quality":0.0536777411,"ml-security":0.0807984899}}
{"text":"Results show that BittyBuzz can be effectively used to implement common swarm behaviors on microcontroller-based systems.","meta":{"url":"http://arxiv.org/abs/2307.06912v1"},"cats":{"new-dataset":0.0908807147,"dev-research":0.4706568692,"prompt-eng":0.4525082407,"data-quality":0.0949805369,"ml-security":0.1698715444}}
{"text":"Before deploying a language model (LM) within a given domain, it is important to measure its tendency to generate factually incorrect information in that domain.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.0824108952,"dev-research":0.4611413181,"prompt-eng":0.5585568845,"data-quality":0.5846375789,"ml-security":0.1768120532}}
{"text":"Existing factual generation evaluation methods focus on facts sampled from the LM itself, and thus do not control the set of evaluated facts and might under-represent rare and unlikely facts.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.1053991124,"dev-research":0.4579963214,"prompt-eng":0.4964437447,"data-quality":0.304646671,"ml-security":0.1164058525}}
{"text":"We propose FACTOR:","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.1161791432,"dev-research":0.4588588671,"prompt-eng":0.4166412613,"data-quality":0.0907804231,"ml-security":0.0869344516}}
{"text":"Factual Assessment via Corpus TransfORmation, a scalable approach for evaluating LM factuality.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.1620343643,"dev-research":0.445236109,"prompt-eng":0.5197662162,"data-quality":0.2962414228,"ml-security":0.0936636722}}
{"text":"FACTOR automatically transforms a factual corpus of interest into a benchmark evaluating an LM's propensity to generate true facts from the corpus vs. similar but incorrect statements.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.1329167455,"dev-research":0.4462843278,"prompt-eng":0.5545741241,"data-quality":0.34200665,"ml-security":0.1033535667}}
{"text":"We use our framework to create two benchmarks: Wiki-FACTOR and News-FACTOR.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.2358306195,"dev-research":0.4490335034,"prompt-eng":0.4628412225,"data-quality":0.1033255929,"ml-security":0.0626765869}}
{"text":"We show that: (i) our benchmark scores increase with model size and improve when the LM is augmented with retrieval; (ii) benchmark score correlates with perplexity, but the two metrics do not always agree on model ranking; and (iii) when perplexity and benchmark score disagree, the latter better reflects factuality in open-ended generation, as measured by human annotators.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.1383556157,"dev-research":0.4751815872,"prompt-eng":0.5556189702,"data-quality":0.2418108301,"ml-security":0.0949207207}}
{"text":"We make our data and code publicly available in https://github.com/AI21Labs/factor.","meta":{"url":"http://arxiv.org/abs/2307.06908v1"},"cats":{"new-dataset":0.6819345972,"dev-research":0.4941863559,"prompt-eng":0.4952755773,"data-quality":0.1321301635,"ml-security":0.1978012974}}
{"text":"Despite the trend towards ubiquitous wireless connectivity, there are scenarios where the communications infrastructure is damaged and wireless coverage is insufficient or does not exist, such as in natural disasters and temporary crowded events.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.1102864007,"dev-research":0.4180930801,"prompt-eng":0.4399637576,"data-quality":0.1410399087,"ml-security":0.3069763357}}
{"text":"Flying networks, composed of Unmanned Aerial Vehicles (UAV), have emerged as a flexible and cost-effective solution to provide on-demand wireless connectivity in these scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.0779205078,"dev-research":0.4070314159,"prompt-eng":0.3840129347,"data-quality":0.0588553937,"ml-security":0.1246708184}}
{"text":"UAVs have the capability to operate virtually everywhere, and the growing payload capacity makes them suitable platforms to carry wireless communications hardware.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.0632970625,"dev-research":0.4243070143,"prompt-eng":0.395050851,"data-quality":0.0363500777,"ml-security":0.1621566074}}
{"text":"The state of the art in the field of flying networks is mainly focused on the optimal positioning of the flying nodes, while the wireless link parameters are configured with default values.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.0593343858,"dev-research":0.4159648951,"prompt-eng":0.3881659945,"data-quality":0.0796241301,"ml-security":0.0979070719}}
{"text":"On the other hand, current link adaptation algorithms are mainly targeting fixed or low mobility scenarios.   ","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.0422239159,"dev-research":0.4199713234,"prompt-eng":0.3940358979,"data-quality":0.1213670601,"ml-security":0.1489233491}}
{"text":"We propose a novel rate adaptation approach for flying networks, named Trajectory Aware Rate Adaptation (TARA), which leverages the knowledge of flying nodes' movement to predict future channel conditions and perform rate adaptation accordingly.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.1322542617,"dev-research":0.4102619552,"prompt-eng":0.439108044,"data-quality":0.1174786127,"ml-security":0.1232355036}}
{"text":"Simulation results of 100 different trajectories show that our solution increases throughput by up to 53% and achieves an average improvement of 14%, when compared with conventional rate adaptation algorithms such as Minstrel-HT.","meta":{"url":"http://arxiv.org/abs/2307.06905v1"},"cats":{"new-dataset":0.1028860119,"dev-research":0.3591628976,"prompt-eng":0.3986270422,"data-quality":0.0640533307,"ml-security":0.0793427929}}
{"text":"Joint commitment was argued to \"make our social world\" (Gilbert, 2014) and to separate us from other primates.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.1116002741,"dev-research":0.4298039056,"prompt-eng":0.392376658,"data-quality":0.0893714333,"ml-security":0.0894400843}}
{"text":"'Joint' entails that neither of us promises anything, unless the other promises as well.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0994362834,"dev-research":0.4114468958,"prompt-eng":0.3739341383,"data-quality":0.0924929295,"ml-security":0.0872007227}}
{"text":"When we need to coordinate for the best mutual outcome, any commitment is beneficial.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0457772271,"dev-research":0.4266172281,"prompt-eng":0.3592481991,"data-quality":0.0587832863,"ml-security":0.1057779969}}
{"text":"However, when we are tempted to free-ride (i.e. in social dilemmas), commitment serves no obvious purpose.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0737406613,"dev-research":0.4255509195,"prompt-eng":0.3414981516,"data-quality":0.0667075437,"ml-security":0.1887435395}}
{"text":"We show that a reputation system, which judges action in social dilemmas only after joint commitment, can prevent free-riding.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.1023843871,"dev-research":0.4111560808,"prompt-eng":0.3963872815,"data-quality":0.1213639791,"ml-security":0.3499071288}}
{"text":"Keeping commitments builds trust.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.1072526055,"dev-research":0.4469005754,"prompt-eng":0.4282356186,"data-quality":0.0990720275,"ml-security":0.1984079784}}
{"text":"We can selectively enter joint commitments with trustworthy individuals to ensure their cooperation (since they will now be judged).","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0564378531,"dev-research":0.4286119811,"prompt-eng":0.4427415495,"data-quality":0.093031085,"ml-security":0.2559004256}}
{"text":"We simply do not commit to cooperate with those we do not trust, and hence can freely defect without losing the trust of others.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0815659764,"dev-research":0.4481273234,"prompt-eng":0.4031808092,"data-quality":0.1562358613,"ml-security":0.2976270667}}
{"text":"This principle might be the reason for pointedly public joint commitments, such as marriage.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0387887634,"dev-research":0.415282865,"prompt-eng":0.349361578,"data-quality":0.0810207412,"ml-security":0.135869763}}
{"text":"It is especially relevant to our evolutionary past, in which no mechanisms existed to enforce commitments reliably and impartially (e.g. via a powerful and accountable government).","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0472892222,"dev-research":0.4473835538,"prompt-eng":0.3432256634,"data-quality":0.0887181104,"ml-security":0.2239747348}}
{"text":"Much research from anthropology, philosophy and psychology made the assumption that past collaborations were mutually beneficial and had little possibilities to free-ride, for which there is little support.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0516165672,"dev-research":0.4565256885,"prompt-eng":0.3468181839,"data-quality":0.1011618033,"ml-security":0.0800152228}}
{"text":"Our evolutionary game theory approach proves that this assumption is not necessary, because free-riding could have been dealt with joint commitments and reputation.","meta":{"url":"http://arxiv.org/abs/2307.06898v1"},"cats":{"new-dataset":0.0450347295,"dev-research":0.4354914438,"prompt-eng":0.3305745394,"data-quality":0.0732655906,"ml-security":0.3226718073}}
{"text":"Automata operating on infinite objects feature prominently in the theory of the modal $\\mu$-calculus.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.0422520353,"dev-research":0.3991928701,"prompt-eng":0.4163393513,"data-quality":0.094047665,"ml-security":0.134808682}}
{"text":"One such application concerns the tableau games introduced by Niwi\\'{n}ski & Walukiewicz, of which the winning condition for infinite plays can be naturally checked by a nondeterministic parity stream automaton.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.1143253124,"dev-research":0.4260051505,"prompt-eng":0.4136315386,"data-quality":0.0906299517,"ml-security":0.1782775599}}
{"text":"Inspired by work of Jungteerapanich and Stirling we show how determinization constructions of this automaton may be used to directly obtain proof systems for the $\\mu$-calculus.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.0755945045,"dev-research":0.425986768,"prompt-eng":0.4506882722,"data-quality":0.1069331786,"ml-security":0.1853469223}}
{"text":"More concretely, we introduce a binary tree construction for determinizing nondeterministic parity stream automata.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.1158804616,"dev-research":0.4214259833,"prompt-eng":0.4537764403,"data-quality":0.1825928872,"ml-security":0.211630533}}
{"text":"Using this construction we define the annotated cyclic proof system $\\mathsf{BT}$, where formulas are annotated by tuples of binary strings.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.1347597941,"dev-research":0.4797213683,"prompt-eng":0.4338240851,"data-quality":0.2472050824,"ml-security":0.1296639925}}
{"text":"Soundness and Completeness of this system follow almost immediately from the correctness of the determinization method.","meta":{"url":"http://arxiv.org/abs/2307.06897v1"},"cats":{"new-dataset":0.0828610529,"dev-research":0.3995765406,"prompt-eng":0.4513064297,"data-quality":0.2367046255,"ml-security":0.1776407198}}
{"text":"Automation of logistic processes is essential to improve productivity and reduce costs.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.0492101066,"dev-research":0.4816792997,"prompt-eng":0.4646033621,"data-quality":0.0673544021,"ml-security":0.0619396218}}
{"text":"In this context, intelligent warehouses are becoming a key to logistic systems thanks to their ability of optimizing transportation tasks and, consequently, reducing costs.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1182568385,"dev-research":0.4443611263,"prompt-eng":0.4308149343,"data-quality":0.0761856585,"ml-security":0.0811896996}}
{"text":"This paper initially presents briefly routing systems applied on intelligent warehouses.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1179567021,"dev-research":0.4312439589,"prompt-eng":0.4082639142,"data-quality":0.0798791272,"ml-security":0.0638278861}}
{"text":"Then, we present the approach used to develop our router system.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1298240167,"dev-research":0.4769268101,"prompt-eng":0.4059700813,"data-quality":0.0783625663,"ml-security":0.1422740564}}
{"text":"This router system is able to solve traffic jams and collisions, generate conflict-free and optimized paths before sending the final paths to the robotic forklifts.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1094942556,"dev-research":0.445274156,"prompt-eng":0.4363277489,"data-quality":0.0581519108,"ml-security":0.1282453285}}
{"text":"It also verifies the progress of all tasks.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.0611667028,"dev-research":0.4767054503,"prompt-eng":0.3864498896,"data-quality":0.0651743169,"ml-security":0.0631647901}}
{"text":"When a problem occurs, the router system can change the task priorities, routes, etc. in order to avoid new conflicts.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.0470895673,"dev-research":0.4750534077,"prompt-eng":0.4050313171,"data-quality":0.0919560036,"ml-security":0.1633335469}}
{"text":"In the routing simulations, each vehicle executes its tasks starting from a predefined initial pose, moving to the desired position.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1094189556,"dev-research":0.4068987416,"prompt-eng":0.40958777,"data-quality":0.052504225,"ml-security":0.0796560411}}
{"text":"Our algorithm is based on Dijkstra's shortest path and the time window approaches and it was implemented in C language.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1811152606,"dev-research":0.4292737256,"prompt-eng":0.3360951724,"data-quality":0.0667012758,"ml-security":0.0771111435}}
{"text":"Computer simulation tests were used to validate the algorithm efficiency under different working conditions.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.0302738774,"dev-research":0.4150454418,"prompt-eng":0.3402699858,"data-quality":0.0976546018,"ml-security":0.0877332517}}
{"text":"Several simulations were carried out using the Player/Stage Simulator to test the algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.1512131509,"dev-research":0.4041057645,"prompt-eng":0.4254209491,"data-quality":0.0617331488,"ml-security":0.1138003622}}
{"text":"Thanks to the simulations, we could solve many faults and refine the algorithms before embedding them in real robots.","meta":{"url":"http://arxiv.org/abs/2307.06893v1"},"cats":{"new-dataset":0.090748174,"dev-research":0.4141534717,"prompt-eng":0.4287874744,"data-quality":0.1680699368,"ml-security":0.21761845}}
{"text":"In this paper, we study the problem of minimizing the spread of a viral epidemic when immunization takes a non-negligible amount of time to take into effect.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.0717130897,"dev-research":0.4109767048,"prompt-eng":0.3969095893,"data-quality":0.0849750876,"ml-security":0.3575432618}}
{"text":"Specifically, our problem is to determine which set of nodes to be vaccinated when vaccines take a random amount of time in order to maximize the total reward, which is the expected number of saved nodes.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.1095303835,"dev-research":0.3850655764,"prompt-eng":0.4202237112,"data-quality":0.1019012823,"ml-security":0.2365629404}}
{"text":"We first provide a mathematical analysis for the reward function of vaccinating an arbitrary number of nodes when there is a single source of infection.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.0927730626,"dev-research":0.4138323532,"prompt-eng":0.4157070639,"data-quality":0.088732553,"ml-security":0.3203918345}}
{"text":"While it is infeasible to obtain the optimal solution analytically due to the combinatorial nature of the problem, we establish that the problem is a monotone submodular maximization problem and develop a greedy algorithm that achieves a $(1\\!-\\!1/e)$-approximation.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.1565848974,"dev-research":0.3929064677,"prompt-eng":0.3867636286,"data-quality":0.1110061531,"ml-security":0.1295511719}}
{"text":"We further extend the scenario to the ones with multiple infection sources and discuss how the greedy algorithm can be applied systematically for the multiple-source scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.226852851,"dev-research":0.4161485889,"prompt-eng":0.4290442586,"data-quality":0.1264517942,"ml-security":0.3536609816}}
{"text":"We finally present extensive simulation results to demonstrate the superiority of our greedy algorithm over other baseline vaccination strategies.","meta":{"url":"http://arxiv.org/abs/2307.06889v1"},"cats":{"new-dataset":0.0969620667,"dev-research":0.3649609402,"prompt-eng":0.4283258719,"data-quality":0.0792095839,"ml-security":0.3346954006}}
{"text":"Feature learning, i.e. extracting meaningful representations of data, is quintessential to the practical success of neural networks trained with gradient descent, yet it is notoriously difficult to explain how and why it occurs.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.0488876692,"dev-research":0.407623699,"prompt-eng":0.4079246849,"data-quality":0.2482997373,"ml-security":0.3699470566}}
{"text":"Recent theoretical studies have shown that shallow neural networks optimized on a single task with gradient-based methods can learn meaningful features, extending our understanding beyond the neural tangent kernel or random feature regime in which negligible feature learning occurs.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.0631338735,"dev-research":0.3693775093,"prompt-eng":0.4110575244,"data-quality":0.2030300395,"ml-security":0.2645189984}}
{"text":"But in practice, neural networks are increasingly often trained on {\\em many} tasks simultaneously with differing loss functions, and these prior analyses do not generalize to such settings.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.0306849393,"dev-research":0.3848237693,"prompt-eng":0.4284966559,"data-quality":0.1675717157,"ml-security":0.2367190478}}
{"text":"In the multi-task learning setting, a variety of studies have shown effective feature learning by simple linear models.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.0697109519,"dev-research":0.3987570451,"prompt-eng":0.4561047653,"data-quality":0.1829112732,"ml-security":0.187017912}}
{"text":"However, multi-task learning via {\\em nonlinear} models, arguably the most common learning paradigm in practice, remains largely mysterious.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.058830539,"dev-research":0.3914903561,"prompt-eng":0.4540826272,"data-quality":0.1192076061,"ml-security":0.1987642174}}
{"text":"In this work, we present the first results proving feature learning occurs in a multi-task setting with a nonlinear model.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.1599221065,"dev-research":0.4188141975,"prompt-eng":0.4717337986,"data-quality":0.1916932935,"ml-security":0.2126866195}}
{"text":"We show that when the tasks are binary classification problems with labels depending on only $r$ directions within the ambient $d\\gg r$-dimensional input space, executing a simple gradient-based multitask learning algorithm on a two-layer ReLU neural network learns the ground-truth $r$ directions.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.1126179721,"dev-research":0.3889013519,"prompt-eng":0.4518887452,"data-quality":0.2550204043,"ml-security":0.2247739564}}
{"text":"In particular, any downstream task on the $r$ ground-truth coordinates can be solved by learning a linear classifier with sample and neuron complexity independent of the ambient dimension $d$, while a random feature model requires exponential complexity in $d$ for such a guarantee.","meta":{"url":"http://arxiv.org/abs/2307.06887v1"},"cats":{"new-dataset":0.0941303817,"dev-research":0.3812187469,"prompt-eng":0.3934982208,"data-quality":0.0761316929,"ml-security":0.1778753395}}
{"text":"Delays and asynchrony are inevitable in large-scale machine-learning problems where communication plays a key role.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.1130803207,"dev-research":0.3845038829,"prompt-eng":0.438649243,"data-quality":0.1424783224,"ml-security":0.3901943571}}
{"text":"As such, several works have extensively analyzed stochastic optimization with delayed gradients.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0616702524,"dev-research":0.3846270881,"prompt-eng":0.417052405,"data-quality":0.096584182,"ml-security":0.1129805906}}
{"text":"However, as far as we are aware, no analogous theory is available for min-max optimization, a topic that has gained recent popularity due to applications in adversarial robustness, game theory, and reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0651762575,"dev-research":0.3802290311,"prompt-eng":0.4004572371,"data-quality":0.1134341225,"ml-security":0.4211648634}}
{"text":"Motivated by this gap, we examine the performance of standard min-max optimization algorithms with delayed gradient updates.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0648860136,"dev-research":0.3710478299,"prompt-eng":0.3654717259,"data-quality":0.0908240271,"ml-security":0.1465070902}}
{"text":"First, we show (empirically) that even small delays can cause prominent algorithms like Extra-gradient (\\texttt{EG}) to diverge on simple instances for which \\texttt{EG} guarantees convergence in the absence of delays.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0257977993,"dev-research":0.4012776817,"prompt-eng":0.3544380257,"data-quality":0.1185823343,"ml-security":0.216993905}}
{"text":"Our empirical study thus suggests the need for a careful analysis of delayed versions of min-max optimization algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0421901979,"dev-research":0.4036113613,"prompt-eng":0.3602369792,"data-quality":0.104350818,"ml-security":0.1572099096}}
{"text":"Accordingly, under suitable technical assumptions, we prove that Gradient Descent-Ascent (\\texttt{GDA}) and \\texttt{EG} with delayed updates continue to guarantee convergence to saddle points for convex-concave and strongly convex-strongly concave settings.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0552382988,"dev-research":0.3960688654,"prompt-eng":0.4168625337,"data-quality":0.119081953,"ml-security":0.3164015632}}
{"text":"Our complexity bounds reveal, in a transparent manner, the slow-down in convergence caused by delays.","meta":{"url":"http://arxiv.org/abs/2307.06886v1"},"cats":{"new-dataset":0.0468641152,"dev-research":0.4461849758,"prompt-eng":0.3362722615,"data-quality":0.0563089698,"ml-security":0.19008309}}
{"text":"The problem of continual learning in the domain of reinforcement learning, often called non-stationary reinforcement learning, has been identified as an important challenge to the application of reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.06877v1"},"cats":{"new-dataset":0.0531481171,"dev-research":0.3969816109,"prompt-eng":0.3831577613,"data-quality":0.1095385828,"ml-security":0.1859415835}}
{"text":"We prove a worst-case complexity result, which we believe captures this challenge: Modifying the probabilities or the reward of a single state-action pair in a reinforcement learning problem requires an amount of time almost as large as the number of states in order to keep the value function up to date, unless the strong exponential time hypothesis (SETH) is false; SETH is a widely accepted strengthening of the P $\\neq$ NP conjecture.","meta":{"url":"http://arxiv.org/abs/2307.06877v1"},"cats":{"new-dataset":0.066758604,"dev-research":0.4060961039,"prompt-eng":0.3772750573,"data-quality":0.1055952791,"ml-security":0.3270896232}}
{"text":"Recall that the number of states in current applications of reinforcement learning is typically astronomical.","meta":{"url":"http://arxiv.org/abs/2307.06877v1"},"cats":{"new-dataset":0.0612476366,"dev-research":0.3999948385,"prompt-eng":0.4304367558,"data-quality":0.0887635595,"ml-security":0.1532036001}}
{"text":"In contrast, we show that just $\\textit{adding}$ a new state-action pair is considerably easier to implement.","meta":{"url":"http://arxiv.org/abs/2307.06877v1"},"cats":{"new-dataset":0.0215855905,"dev-research":0.4307335582,"prompt-eng":0.410924279,"data-quality":0.0597961172,"ml-security":0.1102936151}}
{"text":"Internet measurements are a crucial foundation of IPv6-related research.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.1662168669,"dev-research":0.4144742353,"prompt-eng":0.3987310608,"data-quality":0.0894744226,"ml-security":0.216752811}}
{"text":"Due to the infeasibility of full address space scans for IPv6 however, those measurements rely on collections of reliably responsive, unbiased addresses, as provided e.g., by the IPv6 Hitlist service.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.1453602502,"dev-research":0.3900487961,"prompt-eng":0.404596431,"data-quality":0.130369397,"ml-security":0.2057911027}}
{"text":"Although used for various use cases, the hitlist provides an unfiltered list of responsive addresses, the hosts behind which can come from a range of different networks and devices, such as web servers, customer-premises equipment (CPE) devices, and Internet infrastructure.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.1439719659,"dev-research":0.4534312742,"prompt-eng":0.445858055,"data-quality":0.1064961155,"ml-security":0.2991392435}}
{"text":"In this paper, we demonstrate the importance of tailoring hitlists in accordance with the research goal in question.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.19435166,"dev-research":0.4518517092,"prompt-eng":0.4702050538,"data-quality":0.2052801838,"ml-security":0.2074100553}}
{"text":"By using PeeringDB we classify hitlist addresses into six different network categories, uncovering that 42% of hitlist addresses are in ISP networks.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.2471956061,"dev-research":0.4332968372,"prompt-eng":0.4430819781,"data-quality":0.1614446658,"ml-security":0.3143721144}}
{"text":"Moreover, we show the different behavior of those addresses depending on their respective category, e.g., ISP addresses exhibiting a relatively low lifetime.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.1178837734,"dev-research":0.404997254,"prompt-eng":0.3924344066,"data-quality":0.13768699,"ml-security":0.2630324073}}
{"text":"Furthermore, we analyze different Target Generation Algorithms (TGAs), which are used to increase the coverage of IPv6 measurements by generating new responsive targets for scans.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.1013896535,"dev-research":0.4042209846,"prompt-eng":0.4214567403,"data-quality":0.0989911884,"ml-security":0.1982408769}}
{"text":"We evaluate their performance under various conditions and find generated addresses to show vastly differing responsiveness levels for different TGAs.","meta":{"url":"http://arxiv.org/abs/2307.06872v1"},"cats":{"new-dataset":0.0660027428,"dev-research":0.3886784559,"prompt-eng":0.4380396408,"data-quality":0.1010739611,"ml-security":0.0928652108}}
{"text":"Local authorities in England, such as Leicestershire County Council (LCC), provide Early Help services that can be offered at any point in a young person's life when they experience difficulties that cannot be supported by universal services alone, such as schools.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.1602474421,"dev-research":0.4156368898,"prompt-eng":0.4519595486,"data-quality":0.114367204,"ml-security":0.1701118125}}
{"text":"This paper investigates the utilisation of machine learning (ML) to assist experts in identifying families that may need to be referred for Early Help assessment and support.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.1448352501,"dev-research":0.394859179,"prompt-eng":0.4707135239,"data-quality":0.1959035672,"ml-security":0.156018919}}
{"text":"LCC provided an anonymised dataset comprising 14360 records of young people under the age of 18.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.7832169333,"dev-research":0.3881822016,"prompt-eng":0.4117164736,"data-quality":0.1723380081,"ml-security":0.257110745}}
{"text":"The dataset was pre-processed, machine learning models were build, and experiments were conducted to validate and test the performance of the models.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.2984640698,"dev-research":0.4097578556,"prompt-eng":0.5021063511,"data-quality":0.1281596424,"ml-security":0.1730375162}}
{"text":"Bias mitigation techniques were applied to improve the fairness of these models.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.0501222262,"dev-research":0.3906927239,"prompt-eng":0.4236966803,"data-quality":0.2174942628,"ml-security":0.424946959}}
{"text":"During testing, while the models demonstrated the capability to identify young people requiring intervention or early help, they also produced a significant number of false positives, especially when constructed with imbalanced data, incorrectly identifying individuals who most likely did not need an Early Help referral.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.0541088969,"dev-research":0.4233058343,"prompt-eng":0.491132349,"data-quality":0.3445469784,"ml-security":0.3354919422}}
{"text":"This paper empirically explores the suitability of data-driven ML models for identifying young people who may require Early Help services and discusses their appropriateness and limitations for this task.","meta":{"url":"http://arxiv.org/abs/2307.06871v1"},"cats":{"new-dataset":0.2032456734,"dev-research":0.4106165999,"prompt-eng":0.4641937551,"data-quality":0.1655010503,"ml-security":0.2243201084}}
{"text":"A robot deployed in a home over long stretches of time faces a true lifelong learning problem.","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.1357890133,"dev-research":0.4004494816,"prompt-eng":0.4094096247,"data-quality":0.0942184205,"ml-security":0.1893039356}}
{"text":"As it seeks to provide assistance to its users, the robot should leverage any accumulated experience to improve its own knowledge to become a more proficient assistant.","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.0770929019,"dev-research":0.4746119683,"prompt-eng":0.5176103227,"data-quality":0.0888158375,"ml-security":0.1165535452}}
{"text":"We formalize this setting with a novel lifelong learning problem formulation in the context of learning for task and motion planning (TAMP).","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.1490167295,"dev-research":0.4144888109,"prompt-eng":0.4192943464,"data-quality":0.0726119747,"ml-security":0.1601267566}}
{"text":"Exploiting the modularity of TAMP systems, we develop a generative mixture model that produces candidate continuous parameters for a planner.","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.0871302069,"dev-research":0.4125817277,"prompt-eng":0.5180571507,"data-quality":0.0487153354,"ml-security":0.089145167}}
{"text":"Whereas most existing lifelong learning approaches determine a priori how data is shared across task models, our approach learns shared and non-shared models and determines which to use online during planning based on auxiliary tasks that serve as a proxy for each model's understanding of a state.","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.1519068914,"dev-research":0.4285325401,"prompt-eng":0.4759914967,"data-quality":0.0805550796,"ml-security":0.1449023027}}
{"text":"Our method exhibits substantial improvements in planning success on simulated 2D domains and on several problems from the BEHAVIOR benchmark.","meta":{"url":"http://arxiv.org/abs/2307.06870v1"},"cats":{"new-dataset":0.1094862855,"dev-research":0.379240232,"prompt-eng":0.3954575921,"data-quality":0.0498650335,"ml-security":0.0640434401}}
{"text":"Existing evaluation metrics for natural language generation (NLG) tasks face the challenges on generalization ability and interpretability.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.14435938,"dev-research":0.4798927835,"prompt-eng":0.5408270607,"data-quality":0.2895797372,"ml-security":0.066789881}}
{"text":"Specifically, most of the well-performed metrics are required to train on evaluation datasets of specific NLG tasks and evaluation dimensions, which may cause over-fitting to task-specific datasets.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.1048105589,"dev-research":0.4413323342,"prompt-eng":0.5035505285,"data-quality":0.2296682638,"ml-security":0.103444964}}
{"text":"Furthermore, existing metrics only provide an evaluation score for each dimension without revealing the evidence to interpret how this score is obtained.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.0794011294,"dev-research":0.4190479559,"prompt-eng":0.3797819234,"data-quality":0.137779456,"ml-security":0.0913092487}}
{"text":"To deal with these challenges, we propose a simple yet effective metric called DecompEval.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.1417544977,"dev-research":0.4459632302,"prompt-eng":0.4416749571,"data-quality":0.210044246,"ml-security":0.2103945819}}
{"text":"This metric formulates NLG evaluation as an instruction-style question answering task and utilizes instruction-tuned pre-trained language models (PLMs) without training on evaluation datasets, aiming to enhance the generalization ability.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.118970605,"dev-research":0.4818656224,"prompt-eng":0.5787826409,"data-quality":0.175460474,"ml-security":0.0837734596}}
{"text":"To make the evaluation process more interpretable, we decompose our devised instruction-style question about the quality of generated texts into the subquestions that measure the quality of each sentence.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.1037847824,"dev-research":0.5340549808,"prompt-eng":0.5423927777,"data-quality":0.2360495193,"ml-security":0.0600584992}}
{"text":"The subquestions with their answers generated by PLMs are then recomposed as evidence to obtain the evaluation result.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.1081776292,"dev-research":0.4895322126,"prompt-eng":0.5236633397,"data-quality":0.1790647916,"ml-security":0.0859501321}}
{"text":"Experimental results show that DecompEval achieves state-of-the-art performance in untrained metrics for evaluating text summarization and dialogue generation, which also exhibits strong dimension-level / task-level generalization ability and interpretability.","meta":{"url":"http://arxiv.org/abs/2307.06869v1"},"cats":{"new-dataset":0.1162329578,"dev-research":0.4662908409,"prompt-eng":0.5499687767,"data-quality":0.1546323799,"ml-security":0.0826123332}}
{"text":"The generations of large language models are commonly controlled through prompting techniques, where a user's query to the model is prefixed with a prompt that aims to guide the model's behaviour on the query.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.1189413584,"dev-research":0.4964060661,"prompt-eng":0.6478711782,"data-quality":0.1261416223,"ml-security":0.1538330285}}
{"text":"The prompts used by companies to guide their models are often treated as secrets, to be hidden from the user making the query.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.1359042566,"dev-research":0.4964395933,"prompt-eng":0.5304742779,"data-quality":0.1182250605,"ml-security":0.4747078534}}
{"text":"They have even been treated as commodities to be bought and sold.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.1907785533,"dev-research":0.4165326465,"prompt-eng":0.3855931521,"data-quality":0.1717597596,"ml-security":0.1138780786}}
{"text":"However, there has been anecdotal evidence showing that the prompts can be extracted by a user even when they are kept secret.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.1284031383,"dev-research":0.4790677043,"prompt-eng":0.6029192622,"data-quality":0.1458958792,"ml-security":0.4715561897}}
{"text":"In this paper, we present a framework for systematically measuring the success of prompt extraction attacks.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.0918308426,"dev-research":0.4770930363,"prompt-eng":0.5732442146,"data-quality":0.4117376516,"ml-security":0.7568497923}}
{"text":"In experiments with multiple sources of prompts and multiple underlying language models, we find that simple text-based attacks can in fact reveal prompts with high probability.","meta":{"url":"http://arxiv.org/abs/2307.06865v1"},"cats":{"new-dataset":0.0755901875,"dev-research":0.4907033954,"prompt-eng":0.6317136778,"data-quality":0.3566008938,"ml-security":0.7584090619}}
{"text":"Lane detection plays a pivotal role in the field of autonomous vehicles and advanced driving assistant systems (ADAS).","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.1106395032,"dev-research":0.3714949889,"prompt-eng":0.4291610691,"data-quality":0.1866420929,"ml-security":0.1563821984}}
{"text":"Over the years, numerous algorithms have emerged, spanning from rudimentary image processing techniques to sophisticated deep neural networks.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.1116565188,"dev-research":0.3551708265,"prompt-eng":0.3920769972,"data-quality":0.110950052,"ml-security":0.1490084606}}
{"text":"The performance of deep learning-based models is highly dependent on the quality of their training data.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.1097555243,"dev-research":0.3509618431,"prompt-eng":0.4510301736,"data-quality":0.1943329568,"ml-security":0.2365618783}}
{"text":"Consequently, these models often experience a decline in performance when confronted with challenging scenarios such as extreme lighting conditions, partially visible lane markings, and sparse lane markings like Botts' dots.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.0714896271,"dev-research":0.398012979,"prompt-eng":0.4253541987,"data-quality":0.1675400275,"ml-security":0.1286647696}}
{"text":"To address this, we present an end-to-end lane detection and classification system based on deep learning methodologies.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.3538747582,"dev-research":0.3548540958,"prompt-eng":0.4205307634,"data-quality":0.1621115539,"ml-security":0.2155276798}}
{"text":"In our study, we introduce a unique dataset meticulously curated to encompass scenarios that pose significant challenges for state-of-the-art (SOTA) models.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.5582611489,"dev-research":0.38436077,"prompt-eng":0.4881020932,"data-quality":0.0955198703,"ml-security":0.22493939}}
{"text":"Through fine-tuning selected models, we aim to achieve enhanced localization accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.1414956602,"dev-research":0.3642793015,"prompt-eng":0.4892088752,"data-quality":0.237212287,"ml-security":0.0774437048}}
{"text":"Moreover, we propose a CNN-based classification branch, seamlessly integrated with the detector, facilitating the identification of distinct lane types.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.2633148808,"dev-research":0.3459369323,"prompt-eng":0.4238856459,"data-quality":0.2304512044,"ml-security":0.1366163393}}
{"text":"This architecture enables informed lane-changing decisions and empowers more resilient ADAS capabilities.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.1016840727,"dev-research":0.415787518,"prompt-eng":0.4261908821,"data-quality":0.1059465729,"ml-security":0.2150872601}}
{"text":"We also investigate the effect of using mixed precision training and testing on different models and batch sizes.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.066175671,"dev-research":0.3833873477,"prompt-eng":0.4720405803,"data-quality":0.2419287549,"ml-security":0.1570628604}}
{"text":"Experimental evaluations conducted on the widely-used TuSimple dataset, Caltech lane dataset, and our LVLane dataset demonstrate the effectiveness of our model in accurately detecting and classifying lanes amidst challenging scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.3188758226,"dev-research":0.3574145716,"prompt-eng":0.4283925647,"data-quality":0.205508488,"ml-security":0.1902106506}}
{"text":"Our method achieves state-of-the-art classification results on the TuSimple dataset.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.5049994736,"dev-research":0.38957722,"prompt-eng":0.4448605613,"data-quality":0.2679495373,"ml-security":0.2271158623}}
{"text":"The code of the work will be published upon the acceptance of the paper.","meta":{"url":"http://arxiv.org/abs/2307.06853v1"},"cats":{"new-dataset":0.2062107613,"dev-research":0.4994786721,"prompt-eng":0.464010125,"data-quality":0.1579098365,"ml-security":0.0833804014}}
{"text":"Accurate 3D sensing of suturing thread is a challenging problem in automated surgical suturing because of the high state-space complexity, thinness and deformability of the thread, and possibility of occlusion by the grippers and tissue.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.0623355077,"dev-research":0.345557798,"prompt-eng":0.3693012871,"data-quality":0.0639844989,"ml-security":0.0671262876}}
{"text":"In this work we present a method for tracking surgical thread in 3D which is robust to occlusions and complex thread configurations, and apply it to autonomously perform the surgical suture \"tail-shortening\" task: pulling thread through tissue until a desired \"tail\" length remains exposed.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.0808003193,"dev-research":0.3827231357,"prompt-eng":0.3689085456,"data-quality":0.044690592,"ml-security":0.048594983}}
{"text":"The method utilizes a learned 2D surgical thread detection network to segment suturing thread in RGB images.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.1070594887,"dev-research":0.3740744035,"prompt-eng":0.4094195052,"data-quality":0.108785886,"ml-security":0.0817367541}}
{"text":"It then identifies the thread path in 2D and reconstructs the thread in 3D as a NURBS spline by triangulating the detections from two stereo cameras.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.1122481009,"dev-research":0.4319308879,"prompt-eng":0.3927074125,"data-quality":0.0898260526,"ml-security":0.0683948868}}
{"text":"Once a 3D thread model is initialized, the method tracks the thread across subsequent frames.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.0414308388,"dev-research":0.4471639442,"prompt-eng":0.3977271064,"data-quality":0.094695991,"ml-security":0.0750507106}}
{"text":"Experiments suggest the method achieves a 1.33 pixel average reprojection error on challenging single-frame 3D thread reconstructions, and an 0.84 pixel average reprojection error on two tracking sequences.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.1251231964,"dev-research":0.3603294405,"prompt-eng":0.3947052191,"data-quality":0.2139370719,"ml-security":0.0769480409}}
{"text":"On the tail-shortening task, it accomplishes a 90% success rate across 20 trials.","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.0537124547,"dev-research":0.4126274452,"prompt-eng":0.4533955355,"data-quality":0.1070893452,"ml-security":0.0724378165}}
{"text":"Supplemental materials are available at https://sites.google.com/berkeley.edu/autolab-surgical-thread/ .","meta":{"url":"http://arxiv.org/abs/2307.06845v1"},"cats":{"new-dataset":0.2246522194,"dev-research":0.4127049497,"prompt-eng":0.4924340917,"data-quality":0.1398141304,"ml-security":0.049145518}}
{"text":"Earthquakes are one of the most destructive natural disasters harming life and the infrastructure of cities.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.1757997314,"dev-research":0.4216270472,"prompt-eng":0.3853096535,"data-quality":0.1605343061,"ml-security":0.3613547068}}
{"text":"After an earthquake, functioning communication and computational capacity are crucial for rescue teams and healthcare of victims.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.1656365175,"dev-research":0.4440814837,"prompt-eng":0.408036439,"data-quality":0.0468441777,"ml-security":0.1699198709}}
{"text":"Therefore, an earthquake can be investigated for dynamic capacity enhancement in which additional resources are deployed since the surviving portion of the infrastructure may not meet the demand of the users.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.0995592977,"dev-research":0.4202228174,"prompt-eng":0.369132434,"data-quality":0.0610677263,"ml-security":0.1673323099}}
{"text":"In this study, we propose a new computation paradigm, air computing, which is the air vehicle assisted next generation edge computing through different air platforms, in order to enhance the capacity of the areas affected by an earthquake.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.1699032887,"dev-research":0.4373744218,"prompt-eng":0.3487967753,"data-quality":0.0478030042,"ml-security":0.1768051318}}
{"text":"To this end, we put forward a novel paradigm that presents a dynamic, responsive, and high-resolution computation environment by explaining its corresponding components, air layers, and essential advantages.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.1099123061,"dev-research":0.438833453,"prompt-eng":0.3860846342,"data-quality":0.0371717355,"ml-security":0.114852131}}
{"text":"Moreover, we focus on the unmanned aerial vehicle (UAV) deployment problem and apply three different methods including the emergency method, the load balancing method, and the location selection index (LSI) method in which we take the delay requirements of applications into account.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.0579938403,"dev-research":0.4184104759,"prompt-eng":0.3678930472,"data-quality":0.0571173767,"ml-security":0.0982203475}}
{"text":"To test and compare their performance in terms of the task success rate, we developed an earthquake scenario in which three towns are affected with different severity.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.1341231864,"dev-research":0.436124045,"prompt-eng":0.4434180205,"data-quality":0.1073457326,"ml-security":0.0858298756}}
{"text":"The experimental results showed that each method can be beneficial considering the circumstances, and goal of the rescue.","meta":{"url":"http://arxiv.org/abs/2307.06838v1"},"cats":{"new-dataset":0.0534041557,"dev-research":0.4606554252,"prompt-eng":0.3781845272,"data-quality":0.0563453383,"ml-security":0.1331645783}}
{"text":"Domain generalization (DG) is about learning models that generalize well to new domains that are related to, but different from, the training domain(s).","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.090258003,"dev-research":0.4334356941,"prompt-eng":0.4930198788,"data-quality":0.1398383693,"ml-security":0.1480185744}}
{"text":"It is a fundamental problem in machine learning and has attracted much attention in recent years.","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0933342586,"dev-research":0.3909224499,"prompt-eng":0.3980283837,"data-quality":0.2418678105,"ml-security":0.3413943369}}
{"text":"A large number of approaches have been proposed.","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0533850158,"dev-research":0.4574075485,"prompt-eng":0.385921255,"data-quality":0.0513360616,"ml-security":0.1053631274}}
{"text":"Different approaches are motivated from different perspectives, making it difficult to gain an overall understanding of the area.","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0322107499,"dev-research":0.4993543818,"prompt-eng":0.3614183016,"data-quality":0.0843274154,"ml-security":0.0674915848}}
{"text":"In this paper, we propose a causal framework for domain generalization and present an understanding of common DG approaches in the framework.","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.050411752,"dev-research":0.4801520492,"prompt-eng":0.465137711,"data-quality":0.126218632,"ml-security":0.1251920741}}
{"text":"Our work sheds new lights on the following questions: (1) What are the key ideas behind each DG method?","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0746159504,"dev-research":0.4888697514,"prompt-eng":0.4233525562,"data-quality":0.1036326156,"ml-security":0.0755779037}}
{"text":"(2) Why is it expected to improve generalization to new domains theoretically?","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0289589583,"dev-research":0.4457685743,"prompt-eng":0.4049214797,"data-quality":0.1373046934,"ml-security":0.1920357209}}
{"text":"(3) How are different DG methods related to each other and what are relative advantages and limitations?","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0609121109,"dev-research":0.4506681101,"prompt-eng":0.3835878008,"data-quality":0.0618628944,"ml-security":0.055450495}}
{"text":"By providing a unified perspective on DG, we hope to help researchers better understand the underlying principles and develop more effective approaches for this critical problem in machine learning.","meta":{"url":"http://arxiv.org/abs/2307.06825v1"},"cats":{"new-dataset":0.0877224789,"dev-research":0.4172460503,"prompt-eng":0.4793781364,"data-quality":0.2470160415,"ml-security":0.2926703512}}
{"text":"The field of Tiny Machine Learning (TinyML) has made substantial advancements in democratizing machine learning on low-footprint devices, such as microcontrollers.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.0884847194,"dev-research":0.4371053887,"prompt-eng":0.461414101,"data-quality":0.1267648075,"ml-security":0.3264867881}}
{"text":"The prevalence of these miniature devices raises the question of whether aggregating their knowledge can benefit TinyML applications.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.0633267932,"dev-research":0.4665431219,"prompt-eng":0.4510589715,"data-quality":0.1092963168,"ml-security":0.1175467186}}
{"text":"Federated meta-learning is a promising answer to this question, as it addresses the scarcity of labeled data and heterogeneous data distribution across devices in the real world.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.2902040572,"dev-research":0.3826828977,"prompt-eng":0.4827717092,"data-quality":0.246643696,"ml-security":0.2835143598}}
{"text":"However, deploying TinyML hardware faces unique resource constraints, making existing methods impractical due to energy, privacy, and communication limitations.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.0538634912,"dev-research":0.4730536102,"prompt-eng":0.4196833079,"data-quality":0.0881596109,"ml-security":0.1891789886}}
{"text":"We introduce TinyMetaFed, a model-agnostic meta-learning framework suitable for TinyML.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.1177293313,"dev-research":0.4043862123,"prompt-eng":0.4976842457,"data-quality":0.179070892,"ml-security":0.1294429876}}
{"text":"TinyMetaFed facilitates collaborative training of a neural network initialization that can be quickly fine-tuned on new devices.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.07501895,"dev-research":0.4582558428,"prompt-eng":0.4755836268,"data-quality":0.1328727664,"ml-security":0.1674195422}}
{"text":"It offers communication savings and privacy protection through partial local reconstruction and Top-P% selective communication, computational efficiency via online learning, and robustness to client heterogeneity through few-shot learning.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.1688986383,"dev-research":0.3969485308,"prompt-eng":0.4510238592,"data-quality":0.1199400572,"ml-security":0.4655706825}}
{"text":"The evaluations on three TinyML use cases demonstrate that TinyMetaFed can significantly reduce energy consumption and communication overhead, accelerate convergence, and stabilize the training process.","meta":{"url":"http://arxiv.org/abs/2307.06822v1"},"cats":{"new-dataset":0.0381465562,"dev-research":0.4139107951,"prompt-eng":0.4106444892,"data-quality":0.1284605173,"ml-security":0.13848376}}
{"text":"We present a solution to the problem of spatio-temporal calibration for event cameras mounted on an onmi-directional vehicle.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.2831362541,"dev-research":0.3628751145,"prompt-eng":0.4063921681,"data-quality":0.1130400144,"ml-security":0.0501975988}}
{"text":"Different from traditional methods that typically determine the camera's pose with respect to the vehicle's body frame using alignment of trajectories, our approach leverages the kinematic correlation of two sets of linear velocity estimates from event data and wheel odometers, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.3651581986,"dev-research":0.3810678687,"prompt-eng":0.4014208042,"data-quality":0.1008718694,"ml-security":0.0769738107}}
{"text":"The overall calibration task consists of estimating the underlying temporal offset between the two heterogeneous sensors, and furthermore, recovering the extrinsic rotation that defines the linear relationship between the two sets of velocity estimates.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.1703470526,"dev-research":0.3784409774,"prompt-eng":0.4186069981,"data-quality":0.1157013474,"ml-security":0.0554953405}}
{"text":"The first sub-problem is formulated as an optimization one, which looks for the optimal temporal offset that maximizes a correlation measurement invariant to arbitrary linear transformation.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.0941299569,"dev-research":0.3642704282,"prompt-eng":0.3647213098,"data-quality":0.1189412584,"ml-security":0.0819999805}}
{"text":"Once the temporal offset is compensated, the extrinsic rotation can be worked out with an iterative closed-form solver that incrementally registers associated linear velocity estimates.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.1076816285,"dev-research":0.4008387559,"prompt-eng":0.3911782862,"data-quality":0.0631097869,"ml-security":0.0750737594}}
{"text":"The proposed algorithm is proved effective on both synthetic data and real data, outperforming traditional methods based on alignment of trajectories.","meta":{"url":"http://arxiv.org/abs/2307.06810v1"},"cats":{"new-dataset":0.3229707774,"dev-research":0.3553582884,"prompt-eng":0.3444554862,"data-quality":0.1254123833,"ml-security":0.0797799392}}
{"text":"The paper completely characterizes the primality of acyclic DFAs, where a DFA $\\mathcal{A}$ is prime if there do not exist DFAs $\\mathcal{A}_1,\\dots,\\mathcal{A}_t$ with $\\mathcal{L}(\\mathcal{A}) = \\bigcap_{i=1}^{t} \\mathcal{L}({\\mathcal{A}_i})$ such that each $\\mathcal{A}_i$ has strictly less states than the minimal DFA recognizing the same language as $\\mathcal{A}$. A regular language is prime if its minimal DFA is prime.","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0796008887,"dev-research":0.4159453819,"prompt-eng":0.4371942264,"data-quality":0.1751029722,"ml-security":0.125395848}}
{"text":"Thus, this result also characterizes the primality of finite languages.   ","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0748335056,"dev-research":0.4643055956,"prompt-eng":0.4319442161,"data-quality":0.1572042512,"ml-security":0.150033432}}
{"text":"Further, the $\\mathsf{NL}$-completeness of the corresponding decision problem $\\mathsf{PrimeDFA}_{\\text{fin}}$ is proven.","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0846746026,"dev-research":0.4307834417,"prompt-eng":0.4192205421,"data-quality":0.1793985922,"ml-security":0.1486601751}}
{"text":"The paper also characterizes the primality of acyclic DFAs under two different notions of compositionality, union and union-intersection compositionality.   ","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0558228288,"dev-research":0.423405753,"prompt-eng":0.4050031501,"data-quality":0.1420665783,"ml-security":0.1002376734}}
{"text":"Additionally, the paper introduces the notion of S-primality, where a DFA $\\mathcal{A}$ is S-prime if there do not exist DFAs $\\mathcal{A}_1,\\dots,\\mathcal{A}_t$ with $\\mathcal{L}(\\mathcal{A}) = \\bigcap_{i=1}^{t} \\mathcal{L}(\\mathcal{A}_i)$ such that each $\\mathcal{A}_i$ has strictly less states than $\\mathcal{A}$ itself.","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0655785013,"dev-research":0.3987099507,"prompt-eng":0.4046769661,"data-quality":0.1218544092,"ml-security":0.138459414}}
{"text":"It is proven that the problem of deciding S-primality for a given DFA is $\\mathsf{NL}$-hard.","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0636671555,"dev-research":0.4028265155,"prompt-eng":0.423622773,"data-quality":0.2063641452,"ml-security":0.1388643277}}
{"text":"To do so, the $\\mathsf{NL}$-completeness of $\\mathsf{2MinimalDFA}$","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0884478856,"dev-research":0.4175406361,"prompt-eng":0.4590885844,"data-quality":0.21908404,"ml-security":0.0819176392}}
{"text":", the basic problem of deciding minimality for a DFA with at most two letters, is proven.","meta":{"url":"http://arxiv.org/abs/2307.06802v1"},"cats":{"new-dataset":0.0455507589,"dev-research":0.4074499753,"prompt-eng":0.4203893431,"data-quality":0.2153097157,"ml-security":0.1408186132}}
{"text":"In this study, we address the challenge of using energy-based models to produce high-quality, label-specific data in complex structured datasets, such as population genetics, RNA or protein sequences data.","meta":{"url":"http://arxiv.org/abs/2307.06797v1"},"cats":{"new-dataset":0.5215187157,"dev-research":0.3857645993,"prompt-eng":0.4863437912,"data-quality":0.2414995687,"ml-security":0.1357690794}}
{"text":"Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times.","meta":{"url":"http://arxiv.org/abs/2307.06797v1"},"cats":{"new-dataset":0.1344612155,"dev-research":0.3673314668,"prompt-eng":0.4371840453,"data-quality":0.1295052576,"ml-security":0.1670363702}}
{"text":"To address these issues, we use a novel training algorithm that exploits non-equilibrium effects.","meta":{"url":"http://arxiv.org/abs/2307.06797v1"},"cats":{"new-dataset":0.0753190171,"dev-research":0.379412151,"prompt-eng":0.4155702953,"data-quality":0.1568016835,"ml-security":0.3783153047}}
{"text":"This approach, applied on the Restricted Boltzmann Machine, improves the model's ability to correctly classify samples and generate high-quality synthetic data in only a few sampling steps.","meta":{"url":"http://arxiv.org/abs/2307.06797v1"},"cats":{"new-dataset":0.2416643127,"dev-research":0.3647917261,"prompt-eng":0.459305456,"data-quality":0.1750232197,"ml-security":0.1946609821}}
{"text":"The effectiveness of this method is demonstrated by its successful application to four different types of data: handwritten digits, mutations of human genomes classified by continental origin, functionally characterized sequences of an enzyme protein family, and homologous RNA sequences from specific taxonomies.","meta":{"url":"http://arxiv.org/abs/2307.06797v1"},"cats":{"new-dataset":0.3574554808,"dev-research":0.4117388536,"prompt-eng":0.4091635103,"data-quality":0.2058583796,"ml-security":0.1246976865}}
{"text":"Vision-language foundation models such as CLIP have shown impressive zero-shot performance on many tasks and datasets, especially thanks to their free-text inputs.","meta":{"url":"http://arxiv.org/abs/2307.06795v1"},"cats":{"new-dataset":0.2660689029,"dev-research":0.3888495023,"prompt-eng":0.4773671532,"data-quality":0.2037889091,"ml-security":0.1281697295}}
{"text":"However, they struggle to handle some downstream tasks, such as fine-grained attribute detection and localization.","meta":{"url":"http://arxiv.org/abs/2307.06795v1"},"cats":{"new-dataset":0.0860172904,"dev-research":0.4379778307,"prompt-eng":0.4901200074,"data-quality":0.3538089946,"ml-security":0.1364575879}}
{"text":"In this paper, we propose a multitask fine-tuning strategy based on a positive/negative prompt formulation to further leverage the capacities of the vision-language foundation models.","meta":{"url":"http://arxiv.org/abs/2307.06795v1"},"cats":{"new-dataset":0.0747205418,"dev-research":0.4654770327,"prompt-eng":0.5647171253,"data-quality":0.1814697493,"ml-security":0.0882173676}}
{"text":"Using the CLIP architecture as baseline, we show strong improvements on bird fine-grained attribute detection and localization tasks, while also increasing the classification performance on the CUB200-2011 dataset.","meta":{"url":"http://arxiv.org/abs/2307.06795v1"},"cats":{"new-dataset":0.2603042199,"dev-research":0.3663990801,"prompt-eng":0.4722778802,"data-quality":0.3063503056,"ml-security":0.1568286648}}
{"text":"We provide source code for reproducibility purposes: it is available at https://github.com/FactoDeepLearning/MultitaskVLFM.","meta":{"url":"http://arxiv.org/abs/2307.06795v1"},"cats":{"new-dataset":0.330558316,"dev-research":0.4516189692,"prompt-eng":0.5247453906,"data-quality":0.1223995979,"ml-security":0.0904693864}}
{"text":"Larger language models, such as GPT-3, have shown to be excellent in many tasks.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.1749363144,"dev-research":0.4515478593,"prompt-eng":0.5048419242,"data-quality":0.118404005,"ml-security":0.0661347723}}
{"text":"However, we demonstrate that out-of-ordinary questions can throw the model off guard.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.0665749192,"dev-research":0.4561895823,"prompt-eng":0.503656583,"data-quality":0.1929132091,"ml-security":0.25991034}}
{"text":"This work focuses on finding answers to negated complementary questions in commonsense scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.2208246577,"dev-research":0.4644568903,"prompt-eng":0.4363566282,"data-quality":0.2055293618,"ml-security":0.1396629316}}
{"text":"We illustrate how such questions adversely affect the model responses.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.0663001665,"dev-research":0.4459186968,"prompt-eng":0.5165611463,"data-quality":0.195231715,"ml-security":0.2778086463}}
{"text":"We propose a model-agnostic methodology to improve the performance in negated complementary scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.0407305862,"dev-research":0.4165413956,"prompt-eng":0.4383466051,"data-quality":0.1785204357,"ml-security":0.1565495312}}
{"text":"Our method outperforms few-shot generation from GPT-3 (by more than 11 points) and, more importantly, highlights the significance of studying the response of large language models in negated complementary questions.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.1339083435,"dev-research":0.4431052905,"prompt-eng":0.5269041232,"data-quality":0.2441558206,"ml-security":0.0816311419}}
{"text":"The code, data, and experiments are available under: https://github.com/navidre/negated_complementary_commonsense.","meta":{"url":"http://arxiv.org/abs/2307.06794v1"},"cats":{"new-dataset":0.2939012466,"dev-research":0.4337682492,"prompt-eng":0.4623615269,"data-quality":0.2827588331,"ml-security":0.1357700099}}
{"text":"In the Planar Disjoint Paths problem, one is given an undirected planar graph with a set of $k$ vertex pairs $(s_i,t_i)$ and the task is to find $k$ pairwise vertex-disjoint paths such that the $i$-th path connects $s_i$ to $t_i$. We study the problem through the lens of kernelization, aiming at efficiently reducing the input size in terms of a parameter.","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.1096706791,"dev-research":0.3887772734,"prompt-eng":0.3647817047,"data-quality":0.1121483337,"ml-security":0.1398858353}}
{"text":"We show that Planar Disjoint Paths does not admit a polynomial kernel when parameterized by $k$ unless coNP $\\subseteq$ NP/poly, resolving an open problem by [Bodlaender, Thomass{\\'e}, Yeo, ESA'09].","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.1105329081,"dev-research":0.4202930522,"prompt-eng":0.3754945181,"data-quality":0.1220522406,"ml-security":0.1805215733}}
{"text":"Moreover, we rule out the existence of a polynomial Turing kernel unless the WK-hierarchy collapses.","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.0826843704,"dev-research":0.4321156569,"prompt-eng":0.4264801531,"data-quality":0.1231990163,"ml-security":0.2167830394}}
{"text":"Our reduction carries over to the setting of edge-disjoint paths, where the kernelization status remained open even in general graphs.   ","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.0729662646,"dev-research":0.3923843054,"prompt-eng":0.3632204003,"data-quality":0.1776570807,"ml-security":0.1475455868}}
{"text":"On the positive side, we present a polynomial kernel for Planar Disjoint Paths parameterized by $k + tw$, where $tw$ denotes the treewidth of the input graph.","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.1349690593,"dev-research":0.4189935895,"prompt-eng":0.3810239903,"data-quality":0.1073732265,"ml-security":0.1205555953}}
{"text":"As a consequence of both our results, we rule out the possibility of a polynomial-time (Turing) treewidth reduction to $tw= k^{O(1)}$ under the same assumptions.","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.0704801588,"dev-research":0.4231406284,"prompt-eng":0.3540937439,"data-quality":0.1012662891,"ml-security":0.133578819}}
{"text":"To the best of our knowledge, this is the first hardness result of this kind.","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.1664368777,"dev-research":0.4103829865,"prompt-eng":0.3764051139,"data-quality":0.1909154099,"ml-security":0.1163824654}}
{"text":"Finally, combining our kernel with the known techniques [Adler, Kolliopoulos, Krause, Lokshtanov, Saurabh, Thilikos, JCTB'17; Schrijver, SICOMP'94] yields an alternative (and arguably simpler) proof that Planar Disjoint Paths can be solved in time $2^{O(k^2)}\\cdot n^{O(1)}$, matching the result of [Lokshtanov, Misra, Pilipczuk, Saurabh, Zehavi, STOC'20].","meta":{"url":"http://arxiv.org/abs/2307.06792v1"},"cats":{"new-dataset":0.0821695402,"dev-research":0.4052290236,"prompt-eng":0.3266325409,"data-quality":0.0655376651,"ml-security":0.1258329466}}
{"text":"We specify a file-oriented data format suitable for parallel, partition-independent disk I/O. Here, a partition refers to a disjoint and ordered distribution of the data elements between one or more processes.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.3094031274,"dev-research":0.417445756,"prompt-eng":0.3914555715,"data-quality":0.0776572209,"ml-security":0.0920124818}}
{"text":"The format is designed such that the file contents are invariant under linear (i. e., unpermuted), parallel repartition of the data prior to writing.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.2323457172,"dev-research":0.4328800416,"prompt-eng":0.3920142845,"data-quality":0.147137895,"ml-security":0.1201600119}}
{"text":"The file contents are indistinguishable from writing in serial.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.3362353986,"dev-research":0.4704908984,"prompt-eng":0.4265279478,"data-quality":0.1792986593,"ml-security":0.0923733249}}
{"text":"In the same vein, the file can be read on any number of processes that agree on any partition of the number of elements stored.   ","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.2180247212,"dev-research":0.423533393,"prompt-eng":0.4015615025,"data-quality":0.0823108991,"ml-security":0.0956055152}}
{"text":"In addition to the format specification we propose an optional convention to implement transparent per-element data compression.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.1097571422,"dev-research":0.4395792456,"prompt-eng":0.4193953066,"data-quality":0.2006131574,"ml-security":0.1329949492}}
{"text":"The compressed data and metadata is layered inside ordinary format elements.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.2365528366,"dev-research":0.4571974511,"prompt-eng":0.4279453076,"data-quality":0.2075563282,"ml-security":0.152105978}}
{"text":"Overall, we pay special attention to both human and machine readability.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.154577388,"dev-research":0.4395408239,"prompt-eng":0.5002374689,"data-quality":0.2365563695,"ml-security":0.0818623439}}
{"text":"If pure ASCII data is written, or compressed data is reencoded to ASCII, the entire file including its header and sectioning metadata remains entirely in ASCII.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.1468643816,"dev-research":0.4498172416,"prompt-eng":0.4177199034,"data-quality":0.2826213603,"ml-security":0.1159625277}}
{"text":"If binary data is written, the metadata stays easy on the human eye.   ","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.2608912162,"dev-research":0.4740299212,"prompt-eng":0.4225027224,"data-quality":0.2100523621,"ml-security":0.1516514202}}
{"text":"We refer to this format as scda.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.481959308,"dev-research":0.4392716295,"prompt-eng":0.4660066909,"data-quality":0.1630085748,"ml-security":0.1483212358}}
{"text":"Conceptually, it lies one layer below and is oblivious to the definition of variables, the binary representation of numbers, considerations of endianness, and self-describing headers, which may all be specified on top of scda.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.1589644742,"dev-research":0.4738812095,"prompt-eng":0.4255051066,"data-quality":0.0858162446,"ml-security":0.1446059059}}
{"text":"The main purpose of the format is to abstract any parallelism and provide sufficient structure as a foundation for a generic and flexible archival and checkpoint/restart.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.1780383147,"dev-research":0.4443820437,"prompt-eng":0.4124320932,"data-quality":0.1100873413,"ml-security":0.091993215}}
{"text":"A documented reference implementation is available as part of the general-purpose libsc free software library.","meta":{"url":"http://arxiv.org/abs/2307.06789v1"},"cats":{"new-dataset":0.2464267679,"dev-research":0.4815665885,"prompt-eng":0.4473290275,"data-quality":0.1518322034,"ml-security":0.1126047684}}
{"text":"This paper presents a novel algorithm for crack localisation and detection based on visual and tactile analysis via fibre-optics.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1665384422,"dev-research":0.4016917563,"prompt-eng":0.3796664809,"data-quality":0.1833822236,"ml-security":0.1483560821}}
{"text":"A finger-shaped sensor based on fibre-optics is employed for the data acquisition to collect data for the analysis and the experiments.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.3637488236,"dev-research":0.3704833986,"prompt-eng":0.4048701156,"data-quality":0.0863568627,"ml-security":0.0948836853}}
{"text":"To detect the possible locations of cracks a camera is used to scan an environment while running an object detection algorithm.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1356274139,"dev-research":0.4242643182,"prompt-eng":0.3819685462,"data-quality":0.2032710021,"ml-security":0.148675691}}
{"text":"Once the crack is detected, a fully-connected graph is created from a skeletonised version of the crack.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.2176167651,"dev-research":0.436866269,"prompt-eng":0.3879440664,"data-quality":0.2179817486,"ml-security":0.1159725681}}
{"text":"A minimum spanning tree is then employed for calculating the shortest path to explore the crack which is then used to develop the motion planner for the robotic manipulator.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.0728037287,"dev-research":0.4551907654,"prompt-eng":0.3559529148,"data-quality":0.0630247106,"ml-security":0.0806449073}}
{"text":"The motion planner divides the crack into multiple nodes which are then explored individually.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.149860088,"dev-research":0.437945572,"prompt-eng":0.3838883652,"data-quality":0.0757976333,"ml-security":0.0791749915}}
{"text":"Then, the manipulator starts the exploration and performs the tactile data classification to confirm if there is indeed a crack in that location or just a false positive from the vision algorithm.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1291100058,"dev-research":0.3986726723,"prompt-eng":0.4214245965,"data-quality":0.1831347011,"ml-security":0.1593651812}}
{"text":"If a crack is detected, also the length, width, orientation and number of branches are calculated.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1523534558,"dev-research":0.4288344822,"prompt-eng":0.3861904763,"data-quality":0.2191405759,"ml-security":0.1012894339}}
{"text":"This is repeated until all the nodes of the crack are explored.   ","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1289260502,"dev-research":0.4294536794,"prompt-eng":0.3816280377,"data-quality":0.2245610898,"ml-security":0.1651205308}}
{"text":"In order to validate the complete algorithm, various experiments are performed: comparison of exploration of cracks through full scan and motion planning algorithm, implementation of frequency-based features for crack classification and geometry analysis using a combination of vision and tactile data.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1596702597,"dev-research":0.3859893952,"prompt-eng":0.3587736486,"data-quality":0.120180273,"ml-security":0.1065757594}}
{"text":"From the results of the experiments, it is shown that the proposed algorithm is able to detect cracks and improve the results obtained from vision to correctly classify cracks and their geometry with minimal cost thanks to the motion planning algorithm.","meta":{"url":"http://arxiv.org/abs/2307.06784v1"},"cats":{"new-dataset":0.1419942818,"dev-research":0.3821859476,"prompt-eng":0.329858947,"data-quality":0.1478255051,"ml-security":0.0808338847}}
{"text":"In today's highly connected society, we are constantly asked to provide personal information to retailers, voter surveys, medical professionals, and other data collection efforts.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.6236164451,"dev-research":0.4132298714,"prompt-eng":0.491023849,"data-quality":0.122048357,"ml-security":0.2967773722}}
{"text":"The collected data is stored in large data warehouses.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.7741454014,"dev-research":0.4131135707,"prompt-eng":0.4378626244,"data-quality":0.093571414,"ml-security":0.1396854167}}
{"text":"Organisations and statistical agencies share and use this data to facilitate research in public health, economics, sociology, etc.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.6332453385,"dev-research":0.4031321453,"prompt-eng":0.4191707831,"data-quality":0.0790980326,"ml-security":0.1714774025}}
{"text":"However, this data contains sensitive information about individuals, which can result in identity theft, financial loss, stress and depression, embarrassment, abuse, etc.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.4899869312,"dev-research":0.4003998263,"prompt-eng":0.4275890162,"data-quality":0.223484183,"ml-security":0.5428586208}}
{"text":"Therefore, one must ensure rigorous management of individuals' privacy.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.1181245322,"dev-research":0.4315108108,"prompt-eng":0.4037202962,"data-quality":0.0936435263,"ml-security":0.424659138}}
{"text":"We propose, an advanced data privacy management architecture composed of three layers.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.3512065337,"dev-research":0.3983333985,"prompt-eng":0.4227689552,"data-quality":0.0944408552,"ml-security":0.491279743}}
{"text":"The data management layer consists of de-identification and anonymisation, the access management layer for re-enforcing data access based on the concepts of Role-Based Access Control and the Chinese Wall Security Policy, and the roles layer for regulating different users.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.3084831624,"dev-research":0.4114152408,"prompt-eng":0.4196032261,"data-quality":0.087635941,"ml-security":0.5050598123}}
{"text":"The proposed system architecture is validated on healthcare datasets.","meta":{"url":"http://arxiv.org/abs/2307.06779v1"},"cats":{"new-dataset":0.4534420267,"dev-research":0.3607499723,"prompt-eng":0.398155889,"data-quality":0.0994904334,"ml-security":0.2069766641}}
{"text":"A rational relation is conjugate if every pair of related words are conjugates.","meta":{"url":"http://arxiv.org/abs/2307.06777v1"},"cats":{"new-dataset":0.1446266287,"dev-research":0.4089846117,"prompt-eng":0.4286599267,"data-quality":0.2044575108,"ml-security":0.1231364462}}
{"text":"It is shown that checking whether a rational relation is conjugate is decidable.","meta":{"url":"http://arxiv.org/abs/2307.06777v1"},"cats":{"new-dataset":0.099334673,"dev-research":0.4048470567,"prompt-eng":0.4138164889,"data-quality":0.1757406105,"ml-security":0.1488015879}}
{"text":"For this, we generalise the Lyndon-Sch\\\"utzenberger's theorem from word combinatorics.","meta":{"url":"http://arxiv.org/abs/2307.06777v1"},"cats":{"new-dataset":0.1528831029,"dev-research":0.4075212717,"prompt-eng":0.4179304893,"data-quality":0.1406233954,"ml-security":0.1122660707}}
{"text":"A consequence of the generalisation is that a set of pairs generated by a sumfree rational expression is conjugate if and only if there is a word witnessing the conjugacy of all the pairs.","meta":{"url":"http://arxiv.org/abs/2307.06777v1"},"cats":{"new-dataset":0.088310955,"dev-research":0.4221663763,"prompt-eng":0.3907707773,"data-quality":0.1419999786,"ml-security":0.2002563447}}
{"text":"In this work, we study the square min-sum bin packing problem (SMSBPP), where a list of square items has to be packed into indexed square bins of dimensions $1 \\times 1$ with no overlap between the areas of the items.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.1730460323,"dev-research":0.4196762961,"prompt-eng":0.3613791312,"data-quality":0.0974945016,"ml-security":0.106862271}}
{"text":"The bins are indexed and the cost of packing each item is equal to the index of the bin in which it is placed in.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.1245280312,"dev-research":0.4638456231,"prompt-eng":0.3740108292,"data-quality":0.0934502684,"ml-security":0.0619089276}}
{"text":"The objective is to minimize the total cost of packing all items, which is equivalent to minimizing the average cost of items.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.0408008284,"dev-research":0.448044649,"prompt-eng":0.3706104931,"data-quality":0.0853659386,"ml-security":0.1046081882}}
{"text":"The problem has applications in minimizing the average time of logistic operations such as cutting stock and delivery of products.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.1003519738,"dev-research":0.410979688,"prompt-eng":0.3673084627,"data-quality":0.0807072976,"ml-security":0.0972689112}}
{"text":"We prove that classic algorithms for two-dimensional bin packing that order items in non-increasing order of size, such as Next Fit Decreasing Height or Any Fit Decreasing Height heuristics, can have an arbitrarily bad performance for SMSBPP.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.1199648459,"dev-research":0.4220449945,"prompt-eng":0.3702823645,"data-quality":0.0786187576,"ml-security":0.0818667667}}
{"text":"We, then, present a $\\frac{53}{22}$-approximation and a PTAS for the problem.","meta":{"url":"http://arxiv.org/abs/2307.06776v1"},"cats":{"new-dataset":0.1364668665,"dev-research":0.3957340761,"prompt-eng":0.3906580482,"data-quality":0.1326177821,"ml-security":0.0710910734}}
{"text":"A Stackelberg Vertex Cover game is played on an undirected graph $\\mathcal{G}$ where some of the vertices are under the control of a \\emph{leader}.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.1263740178,"dev-research":0.404601362,"prompt-eng":0.3974445009,"data-quality":0.0894260124,"ml-security":0.2124154525}}
{"text":"The remaining vertices are assigned a fixed weight.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.0452591138,"dev-research":0.4085772641,"prompt-eng":0.3637833475,"data-quality":0.1282214712,"ml-security":0.0803046648}}
{"text":"The game is played in two stages.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.2224102291,"dev-research":0.416595215,"prompt-eng":0.4221668324,"data-quality":0.0560985141,"ml-security":0.1049581241}}
{"text":"First, the leader chooses prices for the vertices under her control.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.0859633401,"dev-research":0.4271514384,"prompt-eng":0.4009482921,"data-quality":0.0595425652,"ml-security":0.1141687291}}
{"text":"Afterward, the second player, called \\emph{follower}, selects a min weight vertex cover in the resulting weighted graph.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.0615547121,"dev-research":0.3965091046,"prompt-eng":0.4357038757,"data-quality":0.0942140631,"ml-security":0.1092492734}}
{"text":"That is, the follower selects a subset of vertices $C^*$ such that every edge has at least one endpoint in $C^*$ of minimum weight w.r.t.\\ to the fixed weights, and the prices set by the leader.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.0567918298,"dev-research":0.4021724963,"prompt-eng":0.3933656077,"data-quality":0.1023037413,"ml-security":0.1296088421}}
{"text":"Stackelberg Vertex Cover (StackVC) describes the leader's optimization problem to select prices in the first stage of the game so as to maximize her revenue, which is the cumulative price of all her (priceable) vertices that are contained in the follower's solution.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.1255281492,"dev-research":0.4208271534,"prompt-eng":0.4162713578,"data-quality":0.0673943568,"ml-security":0.1592190525}}
{"text":"Previous research showed that StackVC is \\textsf{NP}-hard on bipartite graphs, but solvable in polynomial time in the special case of bipartite graphs, where all priceable vertices belong to the same side of the bipartition.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.1129455836,"dev-research":0.3828249393,"prompt-eng":0.3520812333,"data-quality":0.0950680365,"ml-security":0.1088189308}}
{"text":"In this paper, we investigate StackVC on paths and present a dynamic program with linear time and space complexity.","meta":{"url":"http://arxiv.org/abs/2307.06772v1"},"cats":{"new-dataset":0.1748534079,"dev-research":0.4413401236,"prompt-eng":0.3881114058,"data-quality":0.0554202337,"ml-security":0.0955578559}}
{"text":"This paper extends the work started in 2002 by Demaine, Demaine and Verill (DDV) on coin-moving puzzles.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.1752513519,"dev-research":0.4419529715,"prompt-eng":0.373345541,"data-quality":0.1187910728,"ml-security":0.1077019372}}
{"text":"These puzzles have a long history in the recreational literature, but were first systematically analyzed by DDV, who gave a full characterization of the solvable puzzles on the triangular grid and a partial characterization of the solvable puzzles on the square grid.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.2461404906,"dev-research":0.4271817432,"prompt-eng":0.3348302341,"data-quality":0.0640475809,"ml-security":0.0833654308}}
{"text":"This article specifically extends the study of the game on the square grid.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.2347567117,"dev-research":0.442742042,"prompt-eng":0.3521927864,"data-quality":0.0413477933,"ml-security":0.1309465077}}
{"text":"Notably, DDV's result on puzzles with two \"extra coins\" is shown to be overly broad: this paper provides counterexamples as well as a revised version of this theorem.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.0570977507,"dev-research":0.4576874485,"prompt-eng":0.3482177975,"data-quality":0.1463266936,"ml-security":0.1476893649}}
{"text":"A new method for solving puzzles with two extra coins is then presented, which covers some cases where the aforementioned theorem does not apply.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.0596185691,"dev-research":0.4650187757,"prompt-eng":0.3284960357,"data-quality":0.1491912749,"ml-security":0.1432551933}}
{"text":"Puzzles with just one extra coin seem even more complicated, and are only touched upon by DDV.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.0625238325,"dev-research":0.4582820451,"prompt-eng":0.3753860234,"data-quality":0.091268676,"ml-security":0.1134058786}}
{"text":"This paper delves deeper, studying a class of such puzzles that may be considered equivalent to a game of \"poking\" coins.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.183118649,"dev-research":0.4484174252,"prompt-eng":0.3937189576,"data-quality":0.1065500343,"ml-security":0.1879063197}}
{"text":"Within this class, some cases are considered that are amenable to analysis.","meta":{"url":"http://arxiv.org/abs/2307.06767v1"},"cats":{"new-dataset":0.1228476578,"dev-research":0.4151964943,"prompt-eng":0.3707872362,"data-quality":0.1457900419,"ml-security":0.2069250679}}
{"text":"In online monitoring, we first synthesize a monitor from a formal specification, which later runs in tandem with the system under study, incrementally receiving its progress and evolving with the system.","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.1435693398,"dev-research":0.5043250514,"prompt-eng":0.4985214207,"data-quality":0.1047829027,"ml-security":0.1034841858}}
{"text":"In offline monitoring the trace is logged as the system progresses to later do post-mortem analysis after the system has finished executing.   ","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.1714003384,"dev-research":0.4746531644,"prompt-eng":0.4422504577,"data-quality":0.0999534756,"ml-security":0.1142645401}}
{"text":"In this paper we propose retroactive dynamic parametrization, a technique that allows a monitor to revisit the past log as it progresses, while still executing in an online manner.","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.0804625273,"dev-research":0.4849280192,"prompt-eng":0.4984678065,"data-quality":0.0952093086,"ml-security":0.1307484648}}
{"text":"This feature allows new monitors to be incorporated into a running system and to revisit the past for particular behaviors based on new information discovered.","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.1181612058,"dev-research":0.5001248993,"prompt-eng":0.4706086092,"data-quality":0.1155278384,"ml-security":0.1478620747}}
{"text":"Retroactive parametrization also allows a monitor to lazily ignore events and revisit and process them later, when it discovers that it should have followed those events.","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.026866439,"dev-research":0.4822722056,"prompt-eng":0.4609187069,"data-quality":0.1102370372,"ml-security":0.133514119}}
{"text":"We showcase the use of retroactive dynamic parametrization to monitor denial of service attacks on a network using network logs.","meta":{"url":"http://arxiv.org/abs/2307.06763v1"},"cats":{"new-dataset":0.0706221759,"dev-research":0.4668566409,"prompt-eng":0.4348999864,"data-quality":0.1217804128,"ml-security":0.5322565058}}
{"text":"We initiate an empirical investigation into differentially private graph neural networks on population graphs from the medical domain by examining privacy-utility trade-offs at different privacy levels on both real-world and synthetic datasets and performing auditing through membership inference attacks.","meta":{"url":"http://arxiv.org/abs/2307.06760v1"},"cats":{"new-dataset":0.344113233,"dev-research":0.3771123059,"prompt-eng":0.3889088551,"data-quality":0.1452891315,"ml-security":0.622206986}}
{"text":"Our findings highlight the potential and the challenges of this specific DP application area.","meta":{"url":"http://arxiv.org/abs/2307.06760v1"},"cats":{"new-dataset":0.1274788781,"dev-research":0.4529990961,"prompt-eng":0.4312625651,"data-quality":0.103818487,"ml-security":0.1848325905}}
{"text":"Moreover, we find evidence that the underlying graph structure constitutes a potential factor for larger performance gaps by showing a correlation between the degree of graph homophily and the accuracy of the trained model.","meta":{"url":"http://arxiv.org/abs/2307.06760v1"},"cats":{"new-dataset":0.0550648442,"dev-research":0.3906112113,"prompt-eng":0.3869795503,"data-quality":0.1875213695,"ml-security":0.1039719145}}
{"text":"In this paper we present a layered approach for multi-agent control problem, decomposed into three stages, each building upon the results of the previous one.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.0843119486,"dev-research":0.4087063794,"prompt-eng":0.4082886478,"data-quality":0.0611385413,"ml-security":0.1231501379}}
{"text":"First, a high-level plan for a coarse abstraction of the system is computed, relying on parametric timed automata augmented with stopwatches as they allow to efficiently model simplified dynamics of such systems.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.0646698135,"dev-research":0.4388205416,"prompt-eng":0.44391172,"data-quality":0.0415527958,"ml-security":0.1156252825}}
{"text":"In the second stage, the high-level plan, based on SMT-formulation, mainly handles the combinatorial aspects of the problem, provides a more dynamically accurate solution.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.1121911875,"dev-research":0.4308874734,"prompt-eng":0.4248109661,"data-quality":0.0351192777,"ml-security":0.0634869331}}
{"text":"These stages are collectively referred to as the SWA-SMT solver.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.1016819229,"dev-research":0.4545307849,"prompt-eng":0.4544394404,"data-quality":0.0605670759,"ml-security":0.064988665}}
{"text":"They are correct by construction but lack a crucial feature: they cannot be executed in real time.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.0518408819,"dev-research":0.45975182,"prompt-eng":0.3899421297,"data-quality":0.1667918498,"ml-security":0.1281425746}}
{"text":"To overcome this, we use SWA-SMT solutions as the initial training dataset for our last stage, which aims at obtaining a neural network control policy.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.3198926232,"dev-research":0.3985821998,"prompt-eng":0.5128694676,"data-quality":0.0941539661,"ml-security":0.2220261642}}
{"text":"We use reinforcement learning to train the policy, and show that the initial dataset is crucial for the overall success of the method.","meta":{"url":"http://arxiv.org/abs/2307.06758v1"},"cats":{"new-dataset":0.2307952219,"dev-research":0.4189862902,"prompt-eng":0.4935257557,"data-quality":0.1651152027,"ml-security":0.1868547724}}
{"text":"Cache side channel attacks are increasingly alarming in modern processors due to the recent emergence of Spectre and Meltdown attacks.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0678935475,"dev-research":0.4478626786,"prompt-eng":0.4365291736,"data-quality":0.1842005585,"ml-security":0.4776659643}}
{"text":"A typical attack performs intentional cache access and manipulates cache states to leak secrets by observing the victim's cache access patterns.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0715024283,"dev-research":0.4695144681,"prompt-eng":0.4249125617,"data-quality":0.1468137374,"ml-security":0.6537396004}}
{"text":"Different countermeasures have been proposed to defend against both general and transient execution based attacks.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0333781766,"dev-research":0.4484481401,"prompt-eng":0.4216496234,"data-quality":0.117317986,"ml-security":0.7321275089}}
{"text":"Despite their effectiveness, they mostly trade some level of performance for security, or have restricted security scope.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0651511658,"dev-research":0.4454443248,"prompt-eng":0.385521892,"data-quality":0.0671195317,"ml-security":0.3412148188}}
{"text":"In this paper, we seek an approach to enforcing security while maintaining performance.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0516038719,"dev-research":0.467543085,"prompt-eng":0.4001722721,"data-quality":0.1158283314,"ml-security":0.580431163}}
{"text":"We leverage the insight that attackers need to access cache in order to manipulate and observe cache state changes for information leakage.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.1088665426,"dev-research":0.503450761,"prompt-eng":0.4575886878,"data-quality":0.1745369025,"ml-security":0.6740585259}}
{"text":"Specifically, we propose Prefender, a secure prefetcher that learns and predicts attack-related accesses for prefetching the cachelines to simultaneously help security and performance.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.1054123512,"dev-research":0.4684511847,"prompt-eng":0.4821576934,"data-quality":0.108568739,"ml-security":0.5944785502}}
{"text":"Our results show that Prefender is effective against several cache side channel attacks while maintaining or even improving performance for SPEC CPU 2006 and 2017 benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.06756v1"},"cats":{"new-dataset":0.0532698284,"dev-research":0.4469216321,"prompt-eng":0.460637999,"data-quality":0.1224484063,"ml-security":0.4605624387}}
{"text":"The learning of Gaussian Mixture Models (also referred to simply as GMMs) plays an important role in machine learning.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.0646664968,"dev-research":0.3791282386,"prompt-eng":0.4842602331,"data-quality":0.102381869,"ml-security":0.1515769367}}
{"text":"Known for their expressiveness and interpretability, Gaussian mixture models have a wide range of applications, from statistics, computer vision to distributional reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1664800481,"dev-research":0.3434177,"prompt-eng":0.4746898322,"data-quality":0.0952535793,"ml-security":0.1236825946}}
{"text":"However, as of today, few known algorithms can fit or learn these models, some of which include Expectation-Maximization algorithms and Sliced Wasserstein Distance.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1443714453,"dev-research":0.3349727356,"prompt-eng":0.4107087779,"data-quality":0.1044053537,"ml-security":0.1866987325}}
{"text":"Even fewer algorithms are compatible with gradient descent, the common learning process for neural networks.   ","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.039058793,"dev-research":0.3886852691,"prompt-eng":0.3867321635,"data-quality":0.126570348,"ml-security":0.2274406302}}
{"text":"In this paper, we derive a closed formula of two GMMs in the univariate, one-dimensional case, then propose a distance function called Sliced Cram\\'er 2-distance for learning general multivariate GMMs.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1656914473,"dev-research":0.3760872425,"prompt-eng":0.4426197791,"data-quality":0.1044728181,"ml-security":0.1324987049}}
{"text":"Our approach has several advantages over many previous methods.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.0461781596,"dev-research":0.4813986312,"prompt-eng":0.3842695551,"data-quality":0.0831801002,"ml-security":0.1152078751}}
{"text":"First, it has a closed-form expression for the univariate case and is easy to compute and implement using common machine learning libraries (e.g., PyTorch and TensorFlow).","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1701567112,"dev-research":0.4018961845,"prompt-eng":0.438775476,"data-quality":0.0863935315,"ml-security":0.1982588251}}
{"text":"Second, it is compatible with gradient descent, which enables us to integrate GMMs with neural networks seamlessly.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.0398343114,"dev-research":0.3979774408,"prompt-eng":0.4527793782,"data-quality":0.0706031068,"ml-security":0.1303828346}}
{"text":"Third, it can fit a GMM not only to a set of data points, but also to another GMM directly, without sampling from the target model.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1003329017,"dev-research":0.3644349758,"prompt-eng":0.4369944391,"data-quality":0.0870968678,"ml-security":0.0954802527}}
{"text":"And fourth, it has some theoretical guarantees like global gradient boundedness and unbiased sampling gradient.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.0536534726,"dev-research":0.3445837973,"prompt-eng":0.3733044159,"data-quality":0.1068359067,"ml-security":0.2068797133}}
{"text":"These features are especially useful for distributional reinforcement learning and Deep Q Networks, where the goal is to learn a distribution over future rewards.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1974760661,"dev-research":0.3900007899,"prompt-eng":0.4654357445,"data-quality":0.0849283862,"ml-security":0.2137441687}}
{"text":"We will also construct a Gaussian Mixture Distributional Deep Q Network as a toy example to demonstrate its effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.1914964129,"dev-research":0.365023455,"prompt-eng":0.4969264113,"data-quality":0.1446515017,"ml-security":0.1714266034}}
{"text":"Compared with previous models, this model is parameter efficient in terms of representing a distribution and possesses better interpretability.","meta":{"url":"http://arxiv.org/abs/2307.06753v1"},"cats":{"new-dataset":0.0716359137,"dev-research":0.4169588411,"prompt-eng":0.4609496559,"data-quality":0.1107156028,"ml-security":0.1158703267}}
{"text":"We define a $q$-linear path in a hypergraph $H$ as a sequence $(e_1,\\ldots,e_L)$ of edges of $H$ such that $|e_i \\cap e_{i+1}| \\in","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.0953311507,"dev-research":0.4191009822,"prompt-eng":0.3547614258,"data-quality":0.1248769866,"ml-security":0.0771717957}}
{"text":"[\\![1,q]\\!]$ and $e_i \\cap e_j=\\varnothing$ if $|i-j|>1$.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.1684234641,"dev-research":0.4026737708,"prompt-eng":0.3985016861,"data-quality":0.1129730641,"ml-security":0.0832689152}}
{"text":"In this paper, we study the connected components associated to these paths when $q=k-2$ where $k$ is the rank of $H$. If $k=3$ then $q=1$ which coincides with the well-known notion of linear path or loose path.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.1187568394,"dev-research":0.4251377023,"prompt-eng":0.38194566,"data-quality":0.1141977012,"ml-security":0.0897665091}}
{"text":"We describe the structure of the connected components, using an algorithmic proof which shows that the connected components can be computed in polynomial time.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.0813796549,"dev-research":0.4042532467,"prompt-eng":0.3441731994,"data-quality":0.0984203728,"ml-security":0.1189325197}}
{"text":"We then mention two consequences of our algorithmic result.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.037155947,"dev-research":0.4786129866,"prompt-eng":0.356357306,"data-quality":0.2571892431,"ml-security":0.2509750664}}
{"text":"The first one is that deciding the winner of the Maker-Breaker game on a hypergraph of rank 3 can be done in polynomial time.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.1346813818,"dev-research":0.4675998396,"prompt-eng":0.3515328124,"data-quality":0.140294018,"ml-security":0.1080364518}}
{"text":"The second one is that tractable cases for the NP-complete problem of \"Paths Avoiding Forbidden Pairs\" in a graph can be deduced from the recognition of a special type of line graph of a hypergraph.","meta":{"url":"http://arxiv.org/abs/2307.06752v1"},"cats":{"new-dataset":0.0815844048,"dev-research":0.4245039912,"prompt-eng":0.3385328911,"data-quality":0.1559537417,"ml-security":0.1205758011}}
{"text":"Gait Recognition is a computer vision task aiming to identify people by their walking patterns.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.2276200598,"dev-research":0.3859311491,"prompt-eng":0.4017001374,"data-quality":0.1321461638,"ml-security":0.0924398111}}
{"text":"Existing methods show impressive results on individual datasets but lack the ability to generalize to unseen scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.32462905,"dev-research":0.4125510799,"prompt-eng":0.4142553227,"data-quality":0.2387644246,"ml-security":0.2834810581}}
{"text":"Unsupervised Domain Adaptation (UDA) tries to adapt a model, pre-trained in a supervised manner on a source domain, to an unlabelled target domain.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.1423299812,"dev-research":0.4355028313,"prompt-eng":0.5059907572,"data-quality":0.2318270116,"ml-security":0.2097070436}}
{"text":"UDA for Gait Recognition is still in its infancy and existing works proposed solutions to limited scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.1698846874,"dev-research":0.3666341766,"prompt-eng":0.391009871,"data-quality":0.1092860413,"ml-security":0.1186471816}}
{"text":"In this paper, we reveal a fundamental phenomenon in adaptation of gait recognition models, in which the target domain is biased to pose-based features rather than identity features, causing a significant performance drop in the identification task.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.0872458237,"dev-research":0.3600084136,"prompt-eng":0.433905096,"data-quality":0.1794596405,"ml-security":0.2031667488}}
{"text":"We suggest Gait Orientation-based method for Unsupervised Domain Adaptation (GOUDA) to reduce this bias.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.1146378743,"dev-research":0.3783024474,"prompt-eng":0.4591302408,"data-quality":0.1085089521,"ml-security":0.0970630212}}
{"text":"To this end, we present a novel Triplet Selection algorithm with a curriculum learning framework, aiming to adapt the embedding space by pushing away samples of similar poses and bringing closer samples of different poses.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.339915849,"dev-research":0.3686386008,"prompt-eng":0.4709994753,"data-quality":0.0744149485,"ml-security":0.1390065475}}
{"text":"We provide extensive experiments on four widely-used gait datasets, CASIA-B, OU-MVLP, GREW, and Gait3D, and on three backbones, GaitSet, GaitPart, and GaitGL, showing the superiority of our proposed method over prior works.","meta":{"url":"http://arxiv.org/abs/2307.06751v1"},"cats":{"new-dataset":0.2891484638,"dev-research":0.3806565666,"prompt-eng":0.4403266382,"data-quality":0.0875782179,"ml-security":0.0946935005}}
{"text":"Smart city solutions require innovative governance approaches together with the smart use of technology, such as digital twins, by city managers and policymakers to manage the big societal challenges.","meta":{"url":"http://arxiv.org/abs/2307.06743v1"},"cats":{"new-dataset":0.1422276121,"dev-research":0.4719134314,"prompt-eng":0.3794805714,"data-quality":0.086660147,"ml-security":0.2038166388}}
{"text":"The project Smart Cities aNd Digital Twins in Lower Austria (SCiNDTiLA) extends the state of the art of research in several contributing disciplines and uses the foundations of complexity theory and computational social science methods to develop a digital-twin-based smart city model.","meta":{"url":"http://arxiv.org/abs/2307.06743v1"},"cats":{"new-dataset":0.186050312,"dev-research":0.4318616292,"prompt-eng":0.3745769557,"data-quality":0.0687349628,"ml-security":0.1494814484}}
{"text":"The project will also apply a novel transdisciplinary process to conceptualise sustainable smart cities and validate the smart city generic model.","meta":{"url":"http://arxiv.org/abs/2307.06743v1"},"cats":{"new-dataset":0.1552723861,"dev-research":0.4487054621,"prompt-eng":0.3756989041,"data-quality":0.0647784843,"ml-security":0.090846338}}
{"text":"The outcomes will be translated into a roadmap highlighting methodologies, guidelines and policy recommendations for tackling societal challenges in smart cities with a focus on rescaling the entire framework to be transferred to regions, smaller towns and non-urban environments, such as rural areas and smart villages, in ways that fit the respective local governance, ethical and operational capacity context.","meta":{"url":"http://arxiv.org/abs/2307.06743v1"},"cats":{"new-dataset":0.161077421,"dev-research":0.4542025025,"prompt-eng":0.3991358108,"data-quality":0.099501114,"ml-security":0.1392608899}}
{"text":"Closeness is one of the most studied characteristics of networks.","meta":{"url":"http://arxiv.org/abs/2307.06738v1"},"cats":{"new-dataset":0.1070148388,"dev-research":0.4387396456,"prompt-eng":0.3837124689,"data-quality":0.1125247778,"ml-security":0.1652802477}}
{"text":"Residual closeness is a very sensitive measure of graphs robustness.","meta":{"url":"http://arxiv.org/abs/2307.06738v1"},"cats":{"new-dataset":0.1038553447,"dev-research":0.4191040795,"prompt-eng":0.3694792936,"data-quality":0.3141735209,"ml-security":0.2185905901}}
{"text":"Additional closeness is a measure of growth potentials of networks.","meta":{"url":"http://arxiv.org/abs/2307.06738v1"},"cats":{"new-dataset":0.0709195539,"dev-research":0.4463410941,"prompt-eng":0.3555713363,"data-quality":0.0830756024,"ml-security":0.1304370953}}
{"text":"In this article we calculate the closeness, vertex residual closeness, link residual closeness, and additional closeness of lollipop graphs.","meta":{"url":"http://arxiv.org/abs/2307.06738v1"},"cats":{"new-dataset":0.2312618308,"dev-research":0.4123307004,"prompt-eng":0.3873276579,"data-quality":0.1551346433,"ml-security":0.1062206983}}
{"text":"Human Pose Estimation is a thoroughly researched problem; however, most datasets focus on the side and front-view scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.3683704283,"dev-research":0.3655651542,"prompt-eng":0.4048221933,"data-quality":0.1092016179,"ml-security":0.2262033019}}
{"text":"We address the limitation by proposing a novel approach that tackles the challenges posed by extreme viewpoints and poses.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.1142318356,"dev-research":0.4345537346,"prompt-eng":0.3417847872,"data-quality":0.0580628963,"ml-security":0.2118811063}}
{"text":"We introduce a new method for synthetic data generation - RePoGen, RarE POses GENerator - with comprehensive control over pose and view to augment the COCO dataset.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.551404812,"dev-research":0.3732879144,"prompt-eng":0.4592444461,"data-quality":0.1360332901,"ml-security":0.1497011852}}
{"text":"Experiments on a new dataset of real images show that adding RePoGen data to the COCO surpasses previous attempts to top-view pose estimation and significantly improves performance on the bottom-view dataset.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.3468678184,"dev-research":0.3730690908,"prompt-eng":0.4249880871,"data-quality":0.1518902352,"ml-security":0.1145362409}}
{"text":"Through an extensive ablation study on both the top and bottom view data, we elucidate the contributions of methodological choices and demonstrate improved performance.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.1202060598,"dev-research":0.3753549688,"prompt-eng":0.394465311,"data-quality":0.110345169,"ml-security":0.0399557512}}
{"text":"The code and the datasets are available on the project website.","meta":{"url":"http://arxiv.org/abs/2307.06737v1"},"cats":{"new-dataset":0.8884586989,"dev-research":0.4692574005,"prompt-eng":0.4749106821,"data-quality":0.0827363785,"ml-security":0.1387144788}}
{"text":"Time series forecasting has received wide interest from existing research due to its broad applications and inherent challenging.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.1277003848,"dev-research":0.3896310067,"prompt-eng":0.3832697797,"data-quality":0.0605009649,"ml-security":0.1430338934}}
{"text":"The research challenge lies in identifying effective patterns in historical series and applying them to future forecasting.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.1393551143,"dev-research":0.391589735,"prompt-eng":0.4046812661,"data-quality":0.0931041943,"ml-security":0.1024421624}}
{"text":"Advanced models based on point-wise connected MLP and Transformer architectures have strong fitting power, but their secondary computational complexity limits practicality.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.0437524761,"dev-research":0.3260909482,"prompt-eng":0.35471581,"data-quality":0.0634276753,"ml-security":0.1100663906}}
{"text":"Additionally, those structures inherently disrupt the temporal order, reducing the information utilization and making the forecasting process uninterpretable.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.0562045679,"dev-research":0.438574929,"prompt-eng":0.3955418335,"data-quality":0.08437329,"ml-security":0.1760417237}}
{"text":"To solve these problems, this paper proposes a forecasting model, MPR-Net.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.1547074472,"dev-research":0.3974740821,"prompt-eng":0.4254560866,"data-quality":0.0939201951,"ml-security":0.0981711977}}
{"text":"It first adaptively decomposes multi-scale historical series patterns using convolution operation, then constructs a pattern extension forecasting method based on the prior knowledge of pattern reproduction, and finally reconstructs future patterns into future series using deconvolution operation.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.1487709871,"dev-research":0.3964592705,"prompt-eng":0.4141601041,"data-quality":0.0725119336,"ml-security":0.0937625004}}
{"text":"By leveraging the temporal dependencies present in the time series, MPR-Net not only achieves linear time complexity, but also makes the forecasting process interpretable.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.0496562565,"dev-research":0.4244608464,"prompt-eng":0.3618891559,"data-quality":0.0571338577,"ml-security":0.0873517994}}
{"text":"By carrying out sufficient experiments on more than ten real data sets of both short and long term forecasting tasks, MPR-Net achieves the state of the art forecasting performance, as well as good generalization and robustness performance.","meta":{"url":"http://arxiv.org/abs/2307.06736v1"},"cats":{"new-dataset":0.1442840946,"dev-research":0.3795555867,"prompt-eng":0.4104892474,"data-quality":0.0710039915,"ml-security":0.1138761707}}
{"text":"In fair division problems, the notion of price of fairness measures the loss in welfare due to a fairness constraint.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.0808507789,"dev-research":0.4268944037,"prompt-eng":0.3649620243,"data-quality":0.1761409821,"ml-security":0.2421810601}}
{"text":"Prior work on the price of fairness has focused primarily on envy-freeness up to one good (EF1) as the fairness constraint, and on the utilitarian and egalitarian welfare measures.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.0989259763,"dev-research":0.4127070833,"prompt-eng":0.395090019,"data-quality":0.0875529396,"ml-security":0.2069069688}}
{"text":"Our work instead focuses on the price of equitability up to one good (EQ1) (which we term price of equity) and considers the broad class of generalized $p$-mean welfare measures (which includes utilitarian, egalitarian, and Nash welfare as special cases).","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.0720957733,"dev-research":0.3993514542,"prompt-eng":0.4110605791,"data-quality":0.1003841492,"ml-security":0.1159489007}}
{"text":"We derive fine-grained bounds on the price of equity in terms of the number of agent types (i.e., the maximum number of agents with distinct valuations), which allows us to identify scenarios where the existing bounds in terms of the number of agents are overly pessimistic.   ","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.1200729823,"dev-research":0.4304714048,"prompt-eng":0.4284901091,"data-quality":0.1100627814,"ml-security":0.2031782502}}
{"text":"Our work focuses on the setting with binary additive valuations, and obtains upper and lower bounds on the price of equity for $p$-mean welfare for all $p \\leqslant 1$. For any fixed $p$, our bounds are tight up to constant factors.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.1002004599,"dev-research":0.4213696989,"prompt-eng":0.4136707248,"data-quality":0.1036433387,"ml-security":0.1263298258}}
{"text":"A useful insight of our work is to identify the structure of allocations that underlie the upper (respectively, the lower) bounds simultaneously for all $p$-mean welfare measures, thus providing a unified structural understanding of price of fairness in this setting.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.085962593,"dev-research":0.4238068148,"prompt-eng":0.4021184864,"data-quality":0.0984996786,"ml-security":0.2393221826}}
{"text":"This structural understanding, in fact, extends to the more general class of binary submodular (or matroid rank) valuations.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.0626702447,"dev-research":0.435753122,"prompt-eng":0.4101304286,"data-quality":0.1162544124,"ml-security":0.1251707345}}
{"text":"We also show that, unlike binary additive valuations, for binary submodular valuations the number of agent types does not provide bounds on the price of equity.","meta":{"url":"http://arxiv.org/abs/2307.06726v1"},"cats":{"new-dataset":0.0773461527,"dev-research":0.4224894891,"prompt-eng":0.4073313055,"data-quality":0.0922221305,"ml-security":0.1232878673}}
{"text":"Object detection in remote sensing is a crucial computer vision task that has seen significant advancements with deep learning techniques.","meta":{"url":"http://arxiv.org/abs/2307.06724v1"},"cats":{"new-dataset":0.1711082993,"dev-research":0.3741640931,"prompt-eng":0.4381062637,"data-quality":0.1632621049,"ml-security":0.1942874511}}
{"text":"However, most existing works in this area focus on the use of generic object detection and do not leverage the potential of multimodal data fusion.","meta":{"url":"http://arxiv.org/abs/2307.06724v1"},"cats":{"new-dataset":0.2241978573,"dev-research":0.3899338927,"prompt-eng":0.4324043493,"data-quality":0.1529449071,"ml-security":0.1042755209}}
{"text":"In this paper, we present a comparison of methods for multimodal object detection in remote sensing, survey available multimodal datasets suitable for evaluation, and discuss future directions.","meta":{"url":"http://arxiv.org/abs/2307.06724v1"},"cats":{"new-dataset":0.3742153516,"dev-research":0.3696467706,"prompt-eng":0.4383009418,"data-quality":0.1400584627,"ml-security":0.0970741741}}
{"text":"In this paper, we study parallel algorithms for the correlation clustering problem, where every pair of two different entities is labeled with similar or dissimilar.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.185761831,"dev-research":0.3761939267,"prompt-eng":0.4006694258,"data-quality":0.270066788,"ml-security":0.1217987863}}
{"text":"The goal is to partition the entities into clusters to minimize the number of disagreements with the labels.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.132067473,"dev-research":0.4323636479,"prompt-eng":0.4477730078,"data-quality":0.3967323477,"ml-security":0.0960610073}}
{"text":"Currently, all efficient parallel algorithms have an approximation ratio of at least 3.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.0727069819,"dev-research":0.3542895378,"prompt-eng":0.3041423604,"data-quality":0.0913578777,"ml-security":0.107725489}}
{"text":"In comparison with the $1.994+\\epsilon$ ratio achieved by polynomial-time sequential algorithms [CLN22], a significant gap exists.   ","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.0507177529,"dev-research":0.3760685064,"prompt-eng":0.3427142079,"data-quality":0.1085102369,"ml-security":0.1495425358}}
{"text":"We propose the first poly-logarithmic depth parallel algorithm that achieves a better approximation ratio than 3.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.1140976174,"dev-research":0.3607270771,"prompt-eng":0.311279918,"data-quality":0.0627411379,"ml-security":0.0787579934}}
{"text":"Specifically, our algorithm computes a $(2.4+\\epsilon)$-approximate solution and uses $\\tilde{O}(m^{1.5})$ work.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.0488952051,"dev-research":0.3821580912,"prompt-eng":0.3519735598,"data-quality":0.1501361411,"ml-security":0.1188141847}}
{"text":"Additionally, it can be translated into a $\\tilde{O}(m^{1.5})$-time sequential algorithm and a poly-logarithmic rounds sublinear-memory MPC algorithm with $\\tilde{O}(m^{1.5})$ total memory.   ","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.0896567862,"dev-research":0.3782557402,"prompt-eng":0.3768055059,"data-quality":0.0670561443,"ml-security":0.0878605096}}
{"text":"Our approach is inspired by Awerbuch, Khandekar, and Rao's [AKR12] length-constrained multi-commodity flow algorithm, where we develop an efficient parallel algorithm to solve a truncated correlation clustering linear program of Charikar, Guruswami, and","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.1449129796,"dev-research":0.3617504742,"prompt-eng":0.3456871916,"data-quality":0.0860224215,"ml-security":0.0858345089}}
{"text":"Wirth [CGW05].","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.1694599705,"dev-research":0.4463857881,"prompt-eng":0.4221024673,"data-quality":0.1252060516,"ml-security":0.1272797252}}
{"text":"Then we show the solution of the truncated linear program can be rounded with a factor of at most 2.4 loss by using the framework of [CMSY15].","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.0777736974,"dev-research":0.4407297423,"prompt-eng":0.3918021651,"data-quality":0.1732076383,"ml-security":0.1970310655}}
{"text":"Such a rounding framework can then be implemented using parallel pivot-based approaches.","meta":{"url":"http://arxiv.org/abs/2307.06723v1"},"cats":{"new-dataset":0.1233664735,"dev-research":0.4097444085,"prompt-eng":0.3884839938,"data-quality":0.0908255725,"ml-security":0.1147439059}}
{"text":"Dialog policies, which determine a system's action based on the current state at each dialog turn, are crucial to the success of the dialog.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.0616038038,"dev-research":0.4841835109,"prompt-eng":0.5533477426,"data-quality":0.1288806404,"ml-security":0.1292757352}}
{"text":"In recent years, reinforcement learning (RL) has emerged as a promising option for dialog policy learning (DPL).","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.1521886794,"dev-research":0.4299401572,"prompt-eng":0.5577386735,"data-quality":0.0909726892,"ml-security":0.1529832846}}
{"text":"In RL-based DPL, dialog policies are updated according to rewards.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.1435256382,"dev-research":0.4684456402,"prompt-eng":0.5441610262,"data-quality":0.1211101405,"ml-security":0.1254719695}}
{"text":"The manual construction of fine-grained rewards, such as state-action-based ones, to effectively guide the dialog policy is challenging in multi-domain task-oriented dialog scenarios with numerous state-action pair combinations.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.0846669827,"dev-research":0.4541321933,"prompt-eng":0.5774694478,"data-quality":0.1120009098,"ml-security":0.1167624747}}
{"text":"One way to estimate rewards from collected data is to train the reward estimator and dialog policy simultaneously using adversarial learning (AL).","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.2533632445,"dev-research":0.4070656028,"prompt-eng":0.5463457894,"data-quality":0.168518273,"ml-security":0.3648121982}}
{"text":"Although this method has demonstrated superior performance experimentally, it is fraught with the inherent problems of AL, such as mode collapse.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.0246966911,"dev-research":0.4040571929,"prompt-eng":0.3647439431,"data-quality":0.127492666,"ml-security":0.1105181777}}
{"text":"This paper first identifies the role of AL in DPL through detailed analyses of the objective functions of dialog policy and reward estimator.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.0945636184,"dev-research":0.4696365286,"prompt-eng":0.5308076853,"data-quality":0.1160890505,"ml-security":0.1257338153}}
{"text":"Next, based on these analyses, we propose a method that eliminates AL from reward estimation and DPL while retaining its advantages.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.0584411977,"dev-research":0.438222539,"prompt-eng":0.4252095354,"data-quality":0.1042666484,"ml-security":0.1488027531}}
{"text":"We evaluate our method using MultiWOZ, a multi-domain task-oriented dialog corpus.","meta":{"url":"http://arxiv.org/abs/2307.06721v1"},"cats":{"new-dataset":0.1953572307,"dev-research":0.4674123256,"prompt-eng":0.5776202499,"data-quality":0.1728884855,"ml-security":0.0537581667}}
{"text":"This paper studies a reconstruction-based approach for weakly-supervised animal detection from aerial images in marine environments.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.0790968453,"dev-research":0.35208325,"prompt-eng":0.4388452162,"data-quality":0.2768575093,"ml-security":0.1283895415}}
{"text":"Such an approach leverages an anomaly detection framework that computes metrics directly on the input space, enhancing interpretability and anomaly localization compared to feature embedding methods.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.0871820589,"dev-research":0.446915362,"prompt-eng":0.4567492282,"data-quality":0.3975438065,"ml-security":0.4107160072}}
{"text":"Building upon the success of Vector-Quantized Variational Autoencoders in anomaly detection on computer vision datasets, we adapt them to the marine animal detection domain and address the challenge of handling noisy data.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.1132331429,"dev-research":0.3853883387,"prompt-eng":0.4573420836,"data-quality":0.336467853,"ml-security":0.2517053801}}
{"text":"To evaluate our approach, we compare it with existing methods in the context of marine animal detection from aerial image data.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.125979592,"dev-research":0.3828936165,"prompt-eng":0.3897313861,"data-quality":0.2417381135,"ml-security":0.1027440326}}
{"text":"Experiments conducted on two dedicated datasets demonstrate the superior performance of the proposed method over recent studies in the literature.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.319479893,"dev-research":0.3600212716,"prompt-eng":0.4157415404,"data-quality":0.1424536314,"ml-security":0.1161117889}}
{"text":"Our framework offers improved interpretability and localization of anomalies, providing valuable insights for monitoring marine ecosystems and mitigating the impact of human activities on marine animals.","meta":{"url":"http://arxiv.org/abs/2307.06720v1"},"cats":{"new-dataset":0.1159016339,"dev-research":0.4444695146,"prompt-eng":0.4376860851,"data-quality":0.2997962831,"ml-security":0.1570961015}}
{"text":"Reconfigurable intelligent surface (RIS) is a promising solution to boost coverage sustainably by reflecting waves from a transmitter to a receiver and acting as a low-power and passive relay.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.0623367241,"dev-research":0.4060608472,"prompt-eng":0.4471642114,"data-quality":0.0588738071,"ml-security":0.1678216892}}
{"text":"In this paper, for the first time, we demonstrate experimentally that a reconfigurable intelligent surface designed for sub6GHz, and using varactor technology, can perform three-dimensional reflective beamforming.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.0883283745,"dev-research":0.366802679,"prompt-eng":0.4190956866,"data-quality":0.0444223572,"ml-security":0.0577647575}}
{"text":"This result is achieved with a RIS prototype of 984 unit-cells, thanks to a compact control circuit individually addressing and configuring the voltage of each unit-cell, with a distinct voltage.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.0753956424,"dev-research":0.3791113305,"prompt-eng":0.4393968645,"data-quality":0.0903100431,"ml-security":0.0926586638}}
{"text":"To our knowledge, this prototype configures 17 to 70 times more distinct voltages than in the state-of-the-art.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.1120467804,"dev-research":0.3926218817,"prompt-eng":0.4368528123,"data-quality":0.0858638891,"ml-security":0.113784277}}
{"text":"The experimental results in an indoor environment show a 10 dB gain.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.0921649537,"dev-research":0.382788772,"prompt-eng":0.4376569393,"data-quality":0.1460124857,"ml-security":0.1348572561}}
{"text":"They also show, for the first time, that producing such a new prototype is feasible with minimal energy footprint and environmental impact, thanks to refurbishing.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.1077131589,"dev-research":0.4594399012,"prompt-eng":0.4233265995,"data-quality":0.0731447729,"ml-security":0.0629211563}}
{"text":"Indeed, a reflectarray antenna originally designed for three-dimensional beamforming has been turned into a RIS.","meta":{"url":"http://arxiv.org/abs/2307.06716v1"},"cats":{"new-dataset":0.069870551,"dev-research":0.3769540419,"prompt-eng":0.390332204,"data-quality":0.0846775453,"ml-security":0.1165952556}}
{"text":"A promising approach to deal with the high hardware cost and energy consumption of massive MIMO transmitters is to use low-resolution digital-to-analog converters (DACs) at each antenna element.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0509308392,"dev-research":0.386780457,"prompt-eng":0.4318660408,"data-quality":0.1051117456,"ml-security":0.1173674282}}
{"text":"This leads to a transmission scheme where the transmitted signals are restricted to a finite set of voltage levels.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0653901242,"dev-research":0.3890112421,"prompt-eng":0.3893049402,"data-quality":0.0660989789,"ml-security":0.3202763806}}
{"text":"This paper is concerned with the analysis and optimization of a low-cost quantized precoding strategy, referred to as linear-quantized precoding, for a downlink massive MIMO system under Rayleigh fading.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0608161447,"dev-research":0.3731006256,"prompt-eng":0.4215283886,"data-quality":0.0769623277,"ml-security":0.1667220063}}
{"text":"In linear-quantized precoding, the signals are first processed by a linear precoding matrix and subsequently quantized component-wise by the DAC.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0676695448,"dev-research":0.3786768008,"prompt-eng":0.445921273,"data-quality":0.1069133225,"ml-security":0.1662716907}}
{"text":"In this paper, we analyze both the signal-to-interference-plus-noise ratio (SINR) and the symbol error probability (SEP) performances of such linear-quantized precoding schemes in an asymptotic framework where the number of transmit antennas and the number of users grow large with a fixed ratio.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0533485343,"dev-research":0.3870381772,"prompt-eng":0.4035507478,"data-quality":0.1735075679,"ml-security":0.2352426282}}
{"text":"Our results provide a rigorous justification for the heuristic arguments based on the Bussgang decomposition that are commonly used in prior works.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0438606892,"dev-research":0.4503770496,"prompt-eng":0.3660523232,"data-quality":0.0819124229,"ml-security":0.1052809652}}
{"text":"Based on the asymptotic analysis, we further derive the optimal precoder within a class of linear-quantized precoders that includes several popular precoders as special cases.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0805955133,"dev-research":0.372415305,"prompt-eng":0.4166077624,"data-quality":0.1090263476,"ml-security":0.2122392415}}
{"text":"Our numerical results demonstrate the excellent accuracy of the asymptotic analysis for finite systems and the optimality of the derived precoder.","meta":{"url":"http://arxiv.org/abs/2307.06714v1"},"cats":{"new-dataset":0.0603557136,"dev-research":0.3867737208,"prompt-eng":0.3816019656,"data-quality":0.0835887922,"ml-security":0.1930840834}}
{"text":"A wide variety of natural language tasks are currently being addressed with large-scale language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.06713v1"},"cats":{"new-dataset":0.1648484323,"dev-research":0.4381673136,"prompt-eng":0.6053367768,"data-quality":0.1921891458,"ml-security":0.1100907355}}
{"text":"These models are usually trained with a very large amount of unsupervised text data and adapted to perform a downstream natural language task using methods like fine-tuning, calibration or in-context learning.","meta":{"url":"http://arxiv.org/abs/2307.06713v1"},"cats":{"new-dataset":0.2230415223,"dev-research":0.4318771741,"prompt-eng":0.5779989503,"data-quality":0.237629987,"ml-security":0.1150699266}}
{"text":"In this work, we propose an approach to adapt the prior class distribution to perform text classification tasks without the need for labelled samples and only few in-domain sample queries.","meta":{"url":"http://arxiv.org/abs/2307.06713v1"},"cats":{"new-dataset":0.2404024779,"dev-research":0.3973874122,"prompt-eng":0.5393692382,"data-quality":0.4327706488,"ml-security":0.2114520168}}
{"text":"The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task.","meta":{"url":"http://arxiv.org/abs/2307.06713v1"},"cats":{"new-dataset":0.0686179919,"dev-research":0.3800675899,"prompt-eng":0.5449395475,"data-quality":0.1090560412,"ml-security":0.1533311192}}
{"text":"Results show that these methods outperform the un-adapted model for different number of training shots in the prompt and a previous approach were calibration is performed without using any adaptation data.","meta":{"url":"http://arxiv.org/abs/2307.06713v1"},"cats":{"new-dataset":0.1328727535,"dev-research":0.3671419636,"prompt-eng":0.5170016441,"data-quality":0.2307510437,"ml-security":0.1597598331}}
{"text":"A wide variety of generative models for graphs have been proposed.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1844284078,"dev-research":0.423954258,"prompt-eng":0.4741347333,"data-quality":0.1439551258,"ml-security":0.0813864356}}
{"text":"They are used in drug discovery, road networks, neural architecture search, and program synthesis.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1546476997,"dev-research":0.4371632513,"prompt-eng":0.4065772573,"data-quality":0.09201123,"ml-security":0.1852661166}}
{"text":"Generating graphs has theoretical challenges, such as isomorphic representations -- evaluating how well a generative model performs is difficult.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.0623323833,"dev-research":0.4234457298,"prompt-eng":0.4565589769,"data-quality":0.16343295,"ml-security":0.1125886725}}
{"text":"Which model to choose depending on the application domain?   ","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1012647856,"dev-research":0.4134927769,"prompt-eng":0.4244908019,"data-quality":0.0629481164,"ml-security":0.1118144153}}
{"text":"We extensively study kernel-based metrics on distributions of graph invariants and manifold-based and kernel-based metrics in graph embedding space.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1522072222,"dev-research":0.4125865633,"prompt-eng":0.4185573988,"data-quality":0.2492838816,"ml-security":0.119353338}}
{"text":"Manifold-based metrics outperform kernel-based metrics in embedding space.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1416424423,"dev-research":0.3856866474,"prompt-eng":0.4286257829,"data-quality":0.2403619644,"ml-security":0.1113998497}}
{"text":"We use these metrics to compare GraphRNN and GRAN, two well-known generative models for graphs, and unveil the influence of node orderings.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1341895169,"dev-research":0.4359568833,"prompt-eng":0.4509497845,"data-quality":0.1547892691,"ml-security":0.0577511831}}
{"text":"It shows the superiority of GRAN over GraphRNN - further, our proposed adaptation of GraphRNN with a depth-first search ordering is effective for small-sized graphs.   ","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.1665852055,"dev-research":0.4041329903,"prompt-eng":0.3886537893,"data-quality":0.1271559511,"ml-security":0.0837176106}}
{"text":"A guideline on good practices regarding dataset selection and node feature initialization is provided.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.2557215579,"dev-research":0.4131938551,"prompt-eng":0.4622963309,"data-quality":0.166375442,"ml-security":0.1527049652}}
{"text":"Our work is accompanied by open-source code and reproducible experiments.","meta":{"url":"http://arxiv.org/abs/2307.06709v1"},"cats":{"new-dataset":0.3504565904,"dev-research":0.5031795517,"prompt-eng":0.4515344343,"data-quality":0.1681927515,"ml-security":0.1571253485}}
{"text":"Although the NLP community has adopted central differential privacy as a go-to framework for privacy-preserving model training or data sharing, the choice and interpretation of the key parameter, privacy budget $\\varepsilon$ that governs the strength of privacy protection, remains largely arbitrary.","meta":{"url":"http://arxiv.org/abs/2307.06708v1"},"cats":{"new-dataset":0.2387401669,"dev-research":0.4293746228,"prompt-eng":0.4160135398,"data-quality":0.153720727,"ml-security":0.6047163386}}
{"text":"We argue that determining the $\\varepsilon$ value should not be solely in the hands of researchers or system developers, but must also take into account the actual people who share their potentially sensitive data.","meta":{"url":"http://arxiv.org/abs/2307.06708v1"},"cats":{"new-dataset":0.2063381351,"dev-research":0.4621579661,"prompt-eng":0.4105113344,"data-quality":0.2478421947,"ml-security":0.5535634516}}
{"text":"In other words: Would you share your instant messages for $\\varepsilon$ of 10?","meta":{"url":"http://arxiv.org/abs/2307.06708v1"},"cats":{"new-dataset":0.1551963178,"dev-research":0.4300835509,"prompt-eng":0.4578237268,"data-quality":0.1682857892,"ml-security":0.2965411489}}
{"text":"We address this research gap by designing, implementing, and conducting a behavioral experiment (311 lay participants) to study the behavior of people in uncertain decision-making situations with respect to privacy-threatening situations.","meta":{"url":"http://arxiv.org/abs/2307.06708v1"},"cats":{"new-dataset":0.1703186851,"dev-research":0.4581216914,"prompt-eng":0.4587132855,"data-quality":0.1444050445,"ml-security":0.3566259621}}
{"text":"Framing the risk perception in terms of two realistic NLP scenarios and using a vignette behavioral study help us determine what $\\varepsilon$ thresholds would lead lay people to be willing to share sensitive textual data - to our knowledge, the first study of its kind.","meta":{"url":"http://arxiv.org/abs/2307.06708v1"},"cats":{"new-dataset":0.1383056625,"dev-research":0.4479014653,"prompt-eng":0.4988781743,"data-quality":0.2929019141,"ml-security":0.3732612632}}
{"text":"Answer selection in open-domain dialogues aims to select an accurate answer from candidates.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.1233684809,"dev-research":0.4662158484,"prompt-eng":0.5375385192,"data-quality":0.0853410978,"ml-security":0.1004468435}}
{"text":"Recent success of answer selection models hinges on training with large amounts of labeled data.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.1879538615,"dev-research":0.4276700095,"prompt-eng":0.5619949738,"data-quality":0.2282693459,"ml-security":0.1473895998}}
{"text":"However, collecting large-scale labeled data is labor-intensive and time-consuming.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.3887033883,"dev-research":0.403122097,"prompt-eng":0.4077469466,"data-quality":0.2085337133,"ml-security":0.1276976364}}
{"text":"In this paper, we introduce the predicted intent labels to calibrate answer labels in a self-training paradigm.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.1646527374,"dev-research":0.4578649698,"prompt-eng":0.5691235996,"data-quality":0.3094437508,"ml-security":0.1553189143}}
{"text":"Specifically, we propose the intent-calibrated self-training (ICAST) to improve the quality of pseudo answer labels through the intent-calibrated answer selection paradigm, in which we employ pseudo intent labels to help improve pseudo answer labels.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.1091033859,"dev-research":0.4661517319,"prompt-eng":0.5563964405,"data-quality":0.2678802466,"ml-security":0.1161345136}}
{"text":"We carry out extensive experiments on two benchmark datasets with open-domain dialogues.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.5607921481,"dev-research":0.413838864,"prompt-eng":0.5543083944,"data-quality":0.1508499018,"ml-security":0.1370103395}}
{"text":"The experimental results show that ICAST outperforms baselines consistently with 1%, 5% and 10% labeled data.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.2144252354,"dev-research":0.4114554344,"prompt-eng":0.4856605251,"data-quality":0.3979823633,"ml-security":0.0809664241}}
{"text":"Specifically, it improves 2.06% and 1.00% of F1 score on the two datasets, compared with the strongest baseline with only 5% labeled data.","meta":{"url":"http://arxiv.org/abs/2307.06703v1"},"cats":{"new-dataset":0.2324606118,"dev-research":0.4146039372,"prompt-eng":0.4488089705,"data-quality":0.2671602779,"ml-security":0.0997036841}}
{"text":"We address the video prediction task by putting forth a novel model that combines (i) our recently proposed hierarchical residual vector quantized variational autoencoder (HR-VQVAE), and (ii) a novel spatiotemporal PixelCNN (ST-PixelCNN).","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1581963601,"dev-research":0.3862866138,"prompt-eng":0.4568133585,"data-quality":0.1113376225,"ml-security":0.104179523}}
{"text":"We refer to this approach as a sequential hierarchical residual learning vector quantized variational autoencoder (S-HR-VQVAE).","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1235781091,"dev-research":0.3670319895,"prompt-eng":0.4788912455,"data-quality":0.1006100585,"ml-security":0.0964926976}}
{"text":"By leveraging the intrinsic capabilities of HR-VQVAE at modeling still images with a parsimonious representation, combined with the ST-PixelCNN's ability at handling spatiotemporal information, S-HR-VQVAE can better deal with chief challenges in video prediction.","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1282659261,"dev-research":0.3828790479,"prompt-eng":0.430221971,"data-quality":0.1239407595,"ml-security":0.1084029065}}
{"text":"These include learning spatiotemporal information, handling high dimensional data, combating blurry prediction, and implicit modeling of physical characteristics.","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1813963274,"dev-research":0.4022280396,"prompt-eng":0.449266814,"data-quality":0.0812158111,"ml-security":0.2151412818}}
{"text":"Extensive experimental results on the KTH Human Action and Moving-MNIST tasks demonstrate that our model compares favorably against top video prediction techniques both in quantitative and qualitative evaluations despite a much smaller model size.","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1410728469,"dev-research":0.3851947024,"prompt-eng":0.4498050103,"data-quality":0.0789401071,"ml-security":0.0773744441}}
{"text":"Finally, we boost S-HR-VQVAE by proposing a novel training method to jointly estimate the HR-VQVAE and ST-PixelCNN parameters.","meta":{"url":"http://arxiv.org/abs/2307.06701v1"},"cats":{"new-dataset":0.1105703077,"dev-research":0.3586810049,"prompt-eng":0.4471141933,"data-quality":0.1362786727,"ml-security":0.129898243}}
{"text":"Mathematics is a highly specialized domain with its own unique set of challenges that has seen limited study in natural language processing.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.1394865567,"dev-research":0.4446641899,"prompt-eng":0.42587862,"data-quality":0.1686466991,"ml-security":0.1508503129}}
{"text":"However, mathematics is used in a wide variety of fields and multidisciplinary research in many different domains often relies on an understanding of mathematical concepts.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.0752420141,"dev-research":0.4320635862,"prompt-eng":0.3438330574,"data-quality":0.0798046092,"ml-security":0.128386537}}
{"text":"To aid researchers coming from other fields, we develop a prototype system for searching for and defining mathematical concepts in context, focusing on the field of category theory.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.1181927276,"dev-research":0.446896618,"prompt-eng":0.3996377456,"data-quality":0.1239990197,"ml-security":0.1225450095}}
{"text":"This system, Parmesan, depends on natural language processing components including concept extraction, relation extraction, definition extraction, and entity linking.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.2504217675,"dev-research":0.4773542492,"prompt-eng":0.5092212662,"data-quality":0.2347687923,"ml-security":0.0793294167}}
{"text":"In developing this system, we show that existing techniques cannot be applied directly to the category theory domain, and suggest hybrid techniques that do perform well, though we expect the system to evolve over time.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.0700134282,"dev-research":0.4204027743,"prompt-eng":0.4311196307,"data-quality":0.1414522114,"ml-security":0.1168448362}}
{"text":"We also provide two cleaned mathematical corpora that power the prototype system, which are based on journal articles and wiki pages, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.1218801359,"dev-research":0.4780678773,"prompt-eng":0.4501714374,"data-quality":0.1611048256,"ml-security":0.1181120439}}
{"text":"The corpora have been annotated with dependency trees, lemmas, and part-of-speech tags.","meta":{"url":"http://arxiv.org/abs/2307.06699v1"},"cats":{"new-dataset":0.2522928103,"dev-research":0.4565800646,"prompt-eng":0.5348303026,"data-quality":0.4118906117,"ml-security":0.095282566}}
{"text":"Knowledge Graph Embedding (KGE) models are used to learn continuous representations of entities and relations.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.2073803158,"dev-research":0.410001697,"prompt-eng":0.4613804714,"data-quality":0.1411633381,"ml-security":0.088728243}}
{"text":"A key task in the literature is predicting missing links between entities.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.166077702,"dev-research":0.4461043402,"prompt-eng":0.4846765044,"data-quality":0.2970369909,"ml-security":0.0743031275}}
{"text":"However, Knowledge Graphs are not just sets of links but also have semantics underlying their structure.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.1672281844,"dev-research":0.4553949969,"prompt-eng":0.418739447,"data-quality":0.1563666711,"ml-security":0.0911316859}}
{"text":"Semantics is crucial in several downstream tasks, such as query answering or reasoning.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.0681463998,"dev-research":0.5112821333,"prompt-eng":0.4724500953,"data-quality":0.151732362,"ml-security":0.0764533421}}
{"text":"We introduce the subgraph inference task, where a model has to generate likely and semantically valid subgraphs.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.1830840432,"dev-research":0.433926759,"prompt-eng":0.4926619277,"data-quality":0.3092168249,"ml-security":0.1136568566}}
{"text":"We propose IntelliGraphs, a set of five new Knowledge Graph datasets.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.6758824343,"dev-research":0.4623646649,"prompt-eng":0.4428864721,"data-quality":0.2181642697,"ml-security":0.1057892502}}
{"text":"The IntelliGraphs datasets contain subgraphs with semantics expressed in logical rules for evaluating subgraph inference.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.2762468228,"dev-research":0.4638617383,"prompt-eng":0.4534915034,"data-quality":0.2484433791,"ml-security":0.0764618672}}
{"text":"We also present the dataset generator that produced the synthetic datasets.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.8470290348,"dev-research":0.42488755,"prompt-eng":0.4765685265,"data-quality":0.1732349455,"ml-security":0.1631602713}}
{"text":"We designed four novel baseline models, which include three models based on traditional KGEs.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.0719621211,"dev-research":0.3401030334,"prompt-eng":0.4551065751,"data-quality":0.0503132125,"ml-security":0.0555357688}}
{"text":"We evaluate their expressiveness and show that these models cannot capture the semantics.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.0683281297,"dev-research":0.4614392304,"prompt-eng":0.4732211283,"data-quality":0.3266753613,"ml-security":0.181164682}}
{"text":"We believe this benchmark will encourage the development of machine learning models that emphasize semantic understanding.","meta":{"url":"http://arxiv.org/abs/2307.06698v1"},"cats":{"new-dataset":0.1569463485,"dev-research":0.4632668434,"prompt-eng":0.5231207862,"data-quality":0.2699725446,"ml-security":0.1860727097}}
{"text":"The growing popularity of Deep Neural Networks, which often require computationally expensive training and access to a vast amount of data, calls for accurate authorship verification methods to deter unlawful dissemination of the models and identify the source of the leak.","meta":{"url":"http://arxiv.org/abs/2307.06695v1"},"cats":{"new-dataset":0.1733674489,"dev-research":0.4168646374,"prompt-eng":0.4377948097,"data-quality":0.356910655,"ml-security":0.5871605542}}
{"text":"In DNN watermarking the owner may have access to the full network (white-box) or only be able to extract information from its output to queries (black-box), but a watermarked model may include both approaches in order to gather sufficient evidence to then gain access to the network.","meta":{"url":"http://arxiv.org/abs/2307.06695v1"},"cats":{"new-dataset":0.1030391255,"dev-research":0.4230345332,"prompt-eng":0.416871402,"data-quality":0.1856731865,"ml-security":0.4708856116}}
{"text":"Although there has been limited research in white-box watermarking that considers traitor tracing, this problem is yet to be explored in the black-box scenario.","meta":{"url":"http://arxiv.org/abs/2307.06695v1"},"cats":{"new-dataset":0.089648348,"dev-research":0.4279048558,"prompt-eng":0.4319908147,"data-quality":0.2465497919,"ml-security":0.5781748816}}
{"text":"In this paper, we propose a black-and-white-box watermarking method that opens the door to collusion-resistant traitor tracing in black-box, exploiting the properties of Tardos codes, and making it possible to identify the source of the leak before access to the model is granted.","meta":{"url":"http://arxiv.org/abs/2307.06695v1"},"cats":{"new-dataset":0.143689492,"dev-research":0.476426794,"prompt-eng":0.4373580846,"data-quality":0.248144229,"ml-security":0.6361426595}}
{"text":"While experimental results show that the method can successfully identify traitors, even when further attacks have been performed, we also discuss its limitations and open problems for traitor tracing in black-box.","meta":{"url":"http://arxiv.org/abs/2307.06695v1"},"cats":{"new-dataset":0.0892943214,"dev-research":0.4452654879,"prompt-eng":0.4364665224,"data-quality":0.1657575822,"ml-security":0.696701261}}
{"text":"Ageing detection and failure prediction are essential in many Internet of Things (IoT) deployments, which operate huge quantities of embedded devices unattended in the field for years.","meta":{"url":"http://arxiv.org/abs/2307.06693v1"},"cats":{"new-dataset":0.1159767525,"dev-research":0.4217968601,"prompt-eng":0.4697760022,"data-quality":0.2048878866,"ml-security":0.2307902182}}
{"text":"In this paper, we present a large-scale empirical analysis of natural SRAM wear-out using 154 boards from a general-purpose testbed.","meta":{"url":"http://arxiv.org/abs/2307.06693v1"},"cats":{"new-dataset":0.1395859837,"dev-research":0.395373993,"prompt-eng":0.4361044106,"data-quality":0.223662235,"ml-security":0.1796155908}}
{"text":"Starting from SRAM initialization bias, which each node can easily collect at startup, we apply various metrics for feature extraction and experiment with common machine learning methods to predict the age of operation for this node.","meta":{"url":"http://arxiv.org/abs/2307.06693v1"},"cats":{"new-dataset":0.1107657499,"dev-research":0.4115135357,"prompt-eng":0.4472016803,"data-quality":0.1405136012,"ml-security":0.1742432719}}
{"text":"Our findings indicate that even though ageing impacts are subtle, our indicators can well estimate usage times with an $R^2$ score of 0.77 and a mean error of 24% using regressors, and with an F1 score above 0.6 for classifiers applying a six-months resolution.","meta":{"url":"http://arxiv.org/abs/2307.06693v1"},"cats":{"new-dataset":0.1433421554,"dev-research":0.4007269598,"prompt-eng":0.4187094054,"data-quality":0.1933908242,"ml-security":0.1775403227}}
{"text":"Negotiations, introduced by Esparza et al., are a model for concurrent systems where computations involving a set of agents are described in terms of their interactions.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.1150381459,"dev-research":0.4556388718,"prompt-eng":0.4340993894,"data-quality":0.0480259082,"ml-security":0.1639894412}}
{"text":"In many situations, it is natural to impose timing constraints between interactions -- for instance, to limit the time available to enter the PIN after inserting a card into an ATM.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.0221454658,"dev-research":0.4467581212,"prompt-eng":0.3825225426,"data-quality":0.0620051926,"ml-security":0.167977535}}
{"text":"To model this, we introduce a real-time aspect to negotiations.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.1154041647,"dev-research":0.4590582642,"prompt-eng":0.4731321319,"data-quality":0.0675806113,"ml-security":0.116465279}}
{"text":"In our model of local-timed negotiations, agents have local reference times that evolve independently.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.099930076,"dev-research":0.4471914446,"prompt-eng":0.4478942421,"data-quality":0.0719437041,"ml-security":0.1173907862}}
{"text":"Inspired by the model of networks of timed automata, each agent is equipped with a set of local clocks.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.1150187101,"dev-research":0.4408230529,"prompt-eng":0.4573496138,"data-quality":0.0890806988,"ml-security":0.1617339496}}
{"text":"Similar to timed automata, the outcomes of a negotiation contain guards and resets over the local clocks.   ","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.0590420164,"dev-research":0.4654210227,"prompt-eng":0.4728593794,"data-quality":0.1157366151,"ml-security":0.2235258618}}
{"text":"As a new feature, we allow some interactions to force the reference clocks of the participating agents to synchronize.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.1157165694,"dev-research":0.4418534336,"prompt-eng":0.486949239,"data-quality":0.0872276155,"ml-security":0.1374646677}}
{"text":"This synchronization constraint allows us to model interesting scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.0999756324,"dev-research":0.437848983,"prompt-eng":0.4418358704,"data-quality":0.0737265316,"ml-security":0.1756214777}}
{"text":"Surprisingly, it also gives unlimited computing power.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.1067332377,"dev-research":0.455128981,"prompt-eng":0.3366217311,"data-quality":0.0376548342,"ml-security":0.199423784}}
{"text":"We show that reachability is undecidable for local-timed negotiations with a mixture of synchronized and unsynchronized interactions.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.0800041312,"dev-research":0.4137391893,"prompt-eng":0.4092164115,"data-quality":0.0751525076,"ml-security":0.1609856529}}
{"text":"We study restrictions on the use of synchronized interactions that make the problem decidable.","meta":{"url":"http://arxiv.org/abs/2307.06691v1"},"cats":{"new-dataset":0.0702160906,"dev-research":0.4356970327,"prompt-eng":0.4040631814,"data-quality":0.1035318047,"ml-security":0.2497037095}}
{"text":"In the realm of Tiny AI, we introduce \"You Only Look at Interested Cells\" (YOLIC), an efficient method for object localization and classification on edge devices.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.1064219787,"dev-research":0.3978798623,"prompt-eng":0.4142652877,"data-quality":0.127948526,"ml-security":0.1192984803}}
{"text":"Seamlessly blending the strengths of semantic segmentation and object detection, YOLIC offers superior computational efficiency and precision.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.1688190689,"dev-research":0.3898440719,"prompt-eng":0.4395936925,"data-quality":0.1960199301,"ml-security":0.092890819}}
{"text":"By adopting Cells of Interest for classification instead of individual pixels, YOLIC encapsulates relevant information, reduces computational load, and enables rough object shape inference.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.1299163439,"dev-research":0.4059385456,"prompt-eng":0.4166438616,"data-quality":0.1160065528,"ml-security":0.1225325506}}
{"text":"Importantly, the need for bounding box regression is obviated, as YOLIC capitalizes on the predetermined cell configuration that provides information about potential object location, size, and shape.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.1218313118,"dev-research":0.4317325605,"prompt-eng":0.4188256446,"data-quality":0.1041100918,"ml-security":0.1742416474}}
{"text":"To tackle the issue of single-label classification limitations, a multi-label classification approach is applied to each cell, effectively recognizing overlapping or closely situated objects.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.160667079,"dev-research":0.3768487004,"prompt-eng":0.4094237559,"data-quality":0.4123429874,"ml-security":0.129395805}}
{"text":"This paper presents extensive experiments on multiple datasets, demonstrating that YOLIC achieves detection performance comparable to the state-of-the-art YOLO algorithms while surpassing in speed, exceeding 30fps on a Raspberry Pi 4B CPU.","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.3454406359,"dev-research":0.3731033182,"prompt-eng":0.4396828875,"data-quality":0.2076338363,"ml-security":0.1991575643}}
{"text":"All resources related to this study, including datasets, cell designer, image annotation tool, and source code, have been made publicly available on our project website at https://kai3316.github.io/yolic.github.io","meta":{"url":"http://arxiv.org/abs/2307.06689v1"},"cats":{"new-dataset":0.6463215525,"dev-research":0.4388354401,"prompt-eng":0.4627436089,"data-quality":0.1535006875,"ml-security":0.0898226898}}
{"text":"Heading towards navigational autonomy in unmanned surface vehicles (USVs) in the maritime sector can fundamentally lead towards safer waters as well as reduced operating costs, while also providing a range of exciting new capabilities for oceanic research, exploration and monitoring.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.102256381,"dev-research":0.4125346354,"prompt-eng":0.4066228133,"data-quality":0.0766526782,"ml-security":0.114798301}}
{"text":"However, achieving such a goal is challenging.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.0670649597,"dev-research":0.4020048836,"prompt-eng":0.3541055668,"data-quality":0.0889872506,"ml-security":0.0956572869}}
{"text":"USV control systems must, safely and reliably, be able to adhere to the international regulations for preventing collisions at sea (COLREGs) in encounters with other vessels as they navigate to a given waypoint while being affected by realistic weather conditions, either during the day or at night.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.0974624042,"dev-research":0.4014986062,"prompt-eng":0.4515313283,"data-quality":0.0839212888,"ml-security":0.1896334017}}
{"text":"To deal with the multitude of possible scenarios, it is critical to have a virtual environment that is able to replicate the realistic operating conditions USVs will encounter, before they can be implemented in the real world.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.0978385117,"dev-research":0.4298986233,"prompt-eng":0.423640008,"data-quality":0.0793436245,"ml-security":0.1941353177}}
{"text":"Such \"digital twins\" form the foundations upon which Deep Reinforcement Learning (DRL) and Computer Vision (CV) algorithms can be used to develop and guide USV control systems.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.0992862917,"dev-research":0.3888427892,"prompt-eng":0.4381446146,"data-quality":0.0799504054,"ml-security":0.2361599286}}
{"text":"In this paper we describe the novel development of a COLREG-compliant DRL-based collision avoidant navigational system with CV-based awareness in a realistic ocean simulation environment.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.1258196406,"dev-research":0.3770090716,"prompt-eng":0.4453685075,"data-quality":0.0758941058,"ml-security":0.1556080584}}
{"text":"The performance of the trained autonomous Agents resulting from this approach is evaluated in several successful navigations to set waypoints in both open sea and coastal encounters with other vessels.","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.0917616195,"dev-research":0.4044452136,"prompt-eng":0.447477233,"data-quality":0.087640987,"ml-security":0.1371045032}}
{"text":"A binary executable version of the simulator with trained agents is available at https://github.com/aavek/Aeolus-Ocean","meta":{"url":"http://arxiv.org/abs/2307.06688v1"},"cats":{"new-dataset":0.3822802531,"dev-research":0.4226281565,"prompt-eng":0.4649763147,"data-quality":0.066070174,"ml-security":0.1717441176}}
{"text":"In recent years, ubiquitous semantic Metaverse has been studied to revolutionize immersive cyber-virtual experiences for augmented reality (AR) and virtual reality (VR) users, which leverages advanced semantic understanding and representation to enable seamless, context-aware interactions within mixed-reality environments.","meta":{"url":"http://arxiv.org/abs/2307.06687v1"},"cats":{"new-dataset":0.1374553417,"dev-research":0.4463295701,"prompt-eng":0.4748793144,"data-quality":0.1117007333,"ml-security":0.0903699753}}
{"text":"This survey focuses on the intelligence and spatio-temporal characteristics of four fundamental system components in ubiquitous semantic Metaverse, i.e., artificial intelligence (AI), spatio-temporal data representation (STDR), semantic Internet of Things (SIoT), and semantic-enhanced digital twin (SDT).","meta":{"url":"http://arxiv.org/abs/2307.06687v1"},"cats":{"new-dataset":0.2737593165,"dev-research":0.4235859389,"prompt-eng":0.4644812797,"data-quality":0.1071341044,"ml-security":0.0958589333}}
{"text":"We thoroughly survey the representative techniques of the four fundamental system components that enable intelligent, personalized, and context-aware interactions with typical use cases of the ubiquitous semantic Metaverse, such as remote education, work and collaboration, entertainment and socialization, healthcare, and e-commerce marketing.","meta":{"url":"http://arxiv.org/abs/2307.06687v1"},"cats":{"new-dataset":0.1799439868,"dev-research":0.4806004609,"prompt-eng":0.5246349953,"data-quality":0.1279006193,"ml-security":0.0885786755}}
{"text":"Furthermore, we outline the opportunities for constructing the future ubiquitous semantic Metaverse, including scalability and interoperability, privacy and security, performance measurement and standardization, as well as ethical considerations and responsible AI.","meta":{"url":"http://arxiv.org/abs/2307.06687v1"},"cats":{"new-dataset":0.2038850878,"dev-research":0.4714715388,"prompt-eng":0.4818730104,"data-quality":0.1502973929,"ml-security":0.2247619566}}
{"text":"Addressing those challenges is important for creating a robust, secure, and ethically sound system environment that offers engaging immersive experiences for the users and AR/VR applications.","meta":{"url":"http://arxiv.org/abs/2307.06687v1"},"cats":{"new-dataset":0.1540418191,"dev-research":0.4320001448,"prompt-eng":0.4453790247,"data-quality":0.1026088467,"ml-security":0.2363374713}}
{"text":"This paper adopts a cognitive psychology perspective to investigate the recurring mistakes in code resulting from the mental set (Einstellung) effect.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.1068367574,"dev-research":0.5582972202,"prompt-eng":0.4630256326,"data-quality":0.4064434059,"ml-security":0.1739356079}}
{"text":"The Einstellung effect is the tendency to approach problem-solving with a preconceived mindset, often overlooking better solutions that may be available.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0371304978,"dev-research":0.5055500428,"prompt-eng":0.4021160747,"data-quality":0.1142334205,"ml-security":0.1241633176}}
{"text":"This effect can significantly impact creative thinking, as the development of patterns of thought can hinder the emergence of novel and creative ideas.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0505727575,"dev-research":0.5222975886,"prompt-eng":0.3743661928,"data-quality":0.1139870816,"ml-security":0.1319120756}}
{"text":"Our study aims to test the Einstellung effect and the two mechanisms of its overcoming in the field of programming.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0494126932,"dev-research":0.551404117,"prompt-eng":0.4026019787,"data-quality":0.1163003523,"ml-security":0.1730336116}}
{"text":"The first intervention was the change of the color scheme of the code editor to the less habitual one.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0757949008,"dev-research":0.5401931279,"prompt-eng":0.4424935376,"data-quality":0.2028406759,"ml-security":0.0908067029}}
{"text":"The second intervention was a combination of instruction to \"forget the previous solutions and tasks\" and the change in the color scheme.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0740250835,"dev-research":0.498127427,"prompt-eng":0.4343331948,"data-quality":0.1047126889,"ml-security":0.0735768419}}
{"text":"During the experiment, participants were given two sets of four programming tasks.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.1608515841,"dev-research":0.5141251681,"prompt-eng":0.4467402782,"data-quality":0.0879065649,"ml-security":0.0747452941}}
{"text":"Each task had two possible solutions: one using suboptimal code dictated by the mental set, and the other using a less familiar but more efficient and recommended methodology.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.1169772109,"dev-research":0.5130085229,"prompt-eng":0.4128894095,"data-quality":0.079069617,"ml-security":0.0533818782}}
{"text":"Between the sets, participants either received no treatment or one of two interventions aimed at helping them overcome the mental set.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.112901055,"dev-research":0.4206052579,"prompt-eng":0.3871653983,"data-quality":0.1294627243,"ml-security":0.0932893497}}
{"text":"The results of our experiment suggest that the tested techniques were insufficient to support overcoming the mental set, which we attribute to the specificity of the programming domain.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.0696099297,"dev-research":0.5458618971,"prompt-eng":0.4269823164,"data-quality":0.118321408,"ml-security":0.1433601969}}
{"text":"The study contributes to the existing literature by providing insights into creativity support during problem-solving in software development and offering a framework for experimental research in this field.","meta":{"url":"http://arxiv.org/abs/2307.06673v1"},"cats":{"new-dataset":0.1304076289,"dev-research":0.6009470826,"prompt-eng":0.4287092265,"data-quality":0.1498948622,"ml-security":0.1151449044}}
{"text":"Audio has become an increasingly crucial biometric modality due to its ability to provide an intuitive way for humans to interact with machines.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.0982450706,"dev-research":0.3952093117,"prompt-eng":0.4896152258,"data-quality":0.1238850785,"ml-security":0.185950721}}
{"text":"It is currently being used for a range of applications, including person authentication to banking to virtual assistants.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.1509465397,"dev-research":0.4419168495,"prompt-eng":0.4485040972,"data-quality":0.0737576686,"ml-security":0.261353477}}
{"text":"Research has shown that these systems are also susceptible to spoofing and attacks.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.0800163888,"dev-research":0.4252907218,"prompt-eng":0.4426117471,"data-quality":0.1381893688,"ml-security":0.6816452421}}
{"text":"Therefore, protecting audio processing systems against fraudulent activities, such as identity theft, financial fraud, and spreading misinformation, is of paramount importance.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.0971548243,"dev-research":0.4065877096,"prompt-eng":0.3986265397,"data-quality":0.2871836295,"ml-security":0.613887261}}
{"text":"This paper reviews the current state-of-the-art techniques for detecting audio spoofing and discusses the current challenges along with open research problems.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.1470770656,"dev-research":0.3843849822,"prompt-eng":0.4353017946,"data-quality":0.4004582265,"ml-security":0.4181155059}}
{"text":"The paper further highlights the importance of considering the ethical and privacy implications of audio spoofing detection systems.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.1711351801,"dev-research":0.4003993138,"prompt-eng":0.4044523977,"data-quality":0.3351688934,"ml-security":0.6307147484}}
{"text":"Lastly, the work aims to accentuate the need for building more robust and generalizable methods, the integration of automatic speaker verification and countermeasure systems, and better evaluation protocols.","meta":{"url":"http://arxiv.org/abs/2307.06669v1"},"cats":{"new-dataset":0.0904191416,"dev-research":0.4094646747,"prompt-eng":0.5566868578,"data-quality":0.2841774644,"ml-security":0.1165183832}}
{"text":"Deep neural networks face many problems in the field of hyperspectral image classification, lack of effective utilization of spatial spectral information, gradient disappearance and overfitting as the model depth increases.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.13451575,"dev-research":0.3531335776,"prompt-eng":0.4029548669,"data-quality":0.2245580678,"ml-security":0.245592435}}
{"text":"In order to accelerate the deployment of the model on edge devices with strict latency requirements and limited computing power, we introduce a lightweight model based on the improved 3D-Densenet model and designs DGCNet.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.07652083,"dev-research":0.3887965648,"prompt-eng":0.3681718433,"data-quality":0.063568432,"ml-security":0.1532482135}}
{"text":"It improves the disadvantage of group convolution.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.0362181191,"dev-research":0.3985209377,"prompt-eng":0.3865515681,"data-quality":0.1108460334,"ml-security":0.1413313696}}
{"text":"Referring to the idea of dynamic network, dynamic group convolution(DGC) is designed on 3d convolution kernel.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.1455605895,"dev-research":0.3723384244,"prompt-eng":0.3943852592,"data-quality":0.0802140952,"ml-security":0.1043852985}}
{"text":"DGC introduces small feature selectors for each grouping to dynamically decide which part of the input channel to connect based on the activations of all input channels.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.0387095429,"dev-research":0.4439039427,"prompt-eng":0.4831016863,"data-quality":0.122891185,"ml-security":0.0872118499}}
{"text":"Multiple groups can capture different and complementary visual and semantic features of input images, allowing convolution neural network(CNN) to learn rich features.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.2495861434,"dev-research":0.3907690134,"prompt-eng":0.4607257116,"data-quality":0.1654920914,"ml-security":0.1295498455}}
{"text":"3D convolution extracts high-dimensional and redundant hyperspectral data, and there is also a lot of redundant information between convolution kernels.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.1686328307,"dev-research":0.3701347501,"prompt-eng":0.3965458519,"data-quality":0.1214229365,"ml-security":0.1173836378}}
{"text":"DGC module allows 3D-Densenet to select channel information with richer semantic features and discard inactive regions.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.1453040175,"dev-research":0.4301925081,"prompt-eng":0.4229761017,"data-quality":0.1540983412,"ml-security":0.0801169399}}
{"text":"The 3D-CNN passing through the DGC module can be regarded as a pruned network.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.1213079347,"dev-research":0.4058765015,"prompt-eng":0.3953394447,"data-quality":0.1121765249,"ml-security":0.1195597659}}
{"text":"DGC not only allows 3D-CNN to complete sufficient feature extraction, but also takes into account the requirements of speed and calculation amount.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.0797589208,"dev-research":0.3925952386,"prompt-eng":0.3699067132,"data-quality":0.0912658831,"ml-security":0.0695571358}}
{"text":"The inference speed and accuracy have been improved, with outstanding performance on the IN, Pavia and KSC datasets, ahead of the mainstream hyperspectral image classification methods.","meta":{"url":"http://arxiv.org/abs/2307.06667v1"},"cats":{"new-dataset":0.2213295985,"dev-research":0.3460502439,"prompt-eng":0.4115962058,"data-quality":0.1546356088,"ml-security":0.1060881455}}
{"text":"The automatic classification of 3D medical data is memory-intensive.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.3197741271,"dev-research":0.3718634242,"prompt-eng":0.388765692,"data-quality":0.097103888,"ml-security":0.1039194796}}
{"text":"Also, variations in the number of slices between samples is common.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.2202844939,"dev-research":0.3666060563,"prompt-eng":0.3809435137,"data-quality":0.1418610313,"ml-security":0.0542425215}}
{"text":"Naive solutions such as subsampling can solve these problems, but at the cost of potentially eliminating relevant diagnosis information.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.1109728926,"dev-research":0.407520198,"prompt-eng":0.3962433146,"data-quality":0.276308701,"ml-security":0.2599300098}}
{"text":"Transformers have shown promising performance for sequential data analysis.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.2305771627,"dev-research":0.3648602268,"prompt-eng":0.4094154352,"data-quality":0.0738390308,"ml-security":0.1215137619}}
{"text":"However, their application for long-sequences is data, computationally, and memory demanding.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.2122355949,"dev-research":0.4006548376,"prompt-eng":0.3423062147,"data-quality":0.0791786721,"ml-security":0.1141325165}}
{"text":"In this paper, we propose an end-to-end Transformer-based framework that allows to classify volumetric data of variable length in an efficient fashion.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.2405559224,"dev-research":0.3270217383,"prompt-eng":0.3851090687,"data-quality":0.118791846,"ml-security":0.1018921336}}
{"text":"Particularly, by randomizing the input slice-wise resolution during training, we enhance the capacity of the learnable positional embedding assigned to each volume slice.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.1087236643,"dev-research":0.3493120551,"prompt-eng":0.4717193759,"data-quality":0.1386277531,"ml-security":0.1566425103}}
{"text":"Consequently, the accumulated positional information in each positional embedding can be generalized to the neighbouring slices, even for high resolution volumes at the test time.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.1053214533,"dev-research":0.3593770023,"prompt-eng":0.4269878646,"data-quality":0.1142248636,"ml-security":0.083153173}}
{"text":"By doing so, the model will be more robust to variable volume length and amenable to different computational budgets.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.0313588375,"dev-research":0.377415042,"prompt-eng":0.3926342632,"data-quality":0.0607158708,"ml-security":0.1169815603}}
{"text":"We evaluated the proposed approach in retinal OCT volume classification and achieved 21.96% average improvement in balanced accuracy on a 9-class diagnostic task, compared to state-of-the-art video transformers.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.1036898017,"dev-research":0.3562891112,"prompt-eng":0.402798021,"data-quality":0.2528879099,"ml-security":0.081393875}}
{"text":"Our findings show that varying the slice-wise resolution of the input during training results in more informative volume representation as compared to training with fixed number of slices per volume.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.1102691803,"dev-research":0.3637939941,"prompt-eng":0.4575849315,"data-quality":0.1751008793,"ml-security":0.1113248701}}
{"text":"Our code is available at: https://github.com/marziehoghbaie/VLFAT.","meta":{"url":"http://arxiv.org/abs/2307.06666v1"},"cats":{"new-dataset":0.3664119033,"dev-research":0.4585869693,"prompt-eng":0.4607527043,"data-quality":0.1190075911,"ml-security":0.0815772889}}
{"text":"Blockchain (BC) and Computer Vision (CV) are the two emerging fields with the potential to transform various sectors.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.1666284193,"dev-research":0.4182522373,"prompt-eng":0.3676765436,"data-quality":0.1076549128,"ml-security":0.1933298271}}
{"text":"The ability of BC can help in offering decentralized and secure data storage, while CV allows machines to learn and understand visual data.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.1857364041,"dev-research":0.422155438,"prompt-eng":0.4017020665,"data-quality":0.0840102381,"ml-security":0.2194307006}}
{"text":"This integration of the two technologies holds massive promise for developing innovative applications that can provide solutions to the challenges in various sectors such as supply chain management, healthcare, smart cities, and defense.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.1485977638,"dev-research":0.4631765039,"prompt-eng":0.4325352041,"data-quality":0.0513628561,"ml-security":0.1187890267}}
{"text":"This review explores a comprehensive analysis of the integration of BC and CV by examining their combination and potential applications.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.0666890762,"dev-research":0.40815074,"prompt-eng":0.4395764517,"data-quality":0.1172697658,"ml-security":0.0846009187}}
{"text":"It also provides a detailed analysis of the fundamental concepts of both technologies, highlighting their strengths and limitations.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.1421151016,"dev-research":0.4652382084,"prompt-eng":0.4085617827,"data-quality":0.0412802707,"ml-security":0.0501536953}}
{"text":"This paper also explores current research efforts that make use of the benefits offered by this combination.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.0323377927,"dev-research":0.4588061848,"prompt-eng":0.3520401754,"data-quality":0.0431811705,"ml-security":0.0883503685}}
{"text":"The effort includes how BC can be used as an added layer of security in CV systems and also ensure data integrity, enabling decentralized image and video analytics using BC.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.1304056091,"dev-research":0.4542402741,"prompt-eng":0.4212686543,"data-quality":0.1243742315,"ml-security":0.2600524213}}
{"text":"The challenges and open issues associated with this integration are also identified, and appropriate potential future directions are also proposed.","meta":{"url":"http://arxiv.org/abs/2307.06659v1"},"cats":{"new-dataset":0.0961779501,"dev-research":0.4388779922,"prompt-eng":0.4209061428,"data-quality":0.0945103878,"ml-security":0.1010305062}}
{"text":"Pair programming (PP) has been a widespread practice for decades and is known for facilitating knowledge exchange and improving the quality of software.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.1596793338,"dev-research":0.5237368112,"prompt-eng":0.4466831848,"data-quality":0.0999127583,"ml-security":0.1073421274}}
{"text":"Many agilists advocated the importance of collocation, face-to-face interaction, and physical artifacts incorporated in the shared workspace when pairing.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.0526714845,"dev-research":0.4498847374,"prompt-eng":0.4225494403,"data-quality":0.0652910627,"ml-security":0.0759817771}}
{"text":"After a long period of forced work-from-home, many knowledge workers prefer to work remotely two or three days per week, which is affecting practices such as PP.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.1190850823,"dev-research":0.4359812783,"prompt-eng":0.375410579,"data-quality":0.0537719794,"ml-security":0.1240122777}}
{"text":"In this revelatory single-case study, we aimed to understand how PP is practiced during hybrid work when team members alternate between on-site days and working from home.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.0922683364,"dev-research":0.4504845753,"prompt-eng":0.4169009939,"data-quality":0.0653587966,"ml-security":0.1019211352}}
{"text":"We collected qualitative and quantitative data through 11 semi-structured interviews, observations, feedback sessions, and self-reported surveys.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.472148097,"dev-research":0.420274134,"prompt-eng":0.4833127488,"data-quality":0.1155767853,"ml-security":0.0833484685}}
{"text":"The interviewees were members of an agile software development team in a Norwegian fintech company.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.2804657514,"dev-research":0.5160020893,"prompt-eng":0.4702209227,"data-quality":0.1025082346,"ml-security":0.1519310577}}
{"text":"The results presented in this paper indicate that PP can be practiced through on-site, remote, and mixed sessions, where the mixed mode seems to be the least advantageous.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.054234289,"dev-research":0.4045729328,"prompt-eng":0.4379488521,"data-quality":0.0632332406,"ml-security":0.0958895146}}
{"text":"The findings highlight the importance of adapting the work environment to suit individual work mode preferences when it comes to PP.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.0811692254,"dev-research":0.4880097055,"prompt-eng":0.4180326952,"data-quality":0.0578311831,"ml-security":0.0951576358}}
{"text":"In the future, we will build on these findings to explore PP in other teams and organizations practicing hybrid work.","meta":{"url":"http://arxiv.org/abs/2307.06658v1"},"cats":{"new-dataset":0.1575938474,"dev-research":0.4704966159,"prompt-eng":0.4383009448,"data-quality":0.0655400517,"ml-security":0.10240168}}
{"text":"In this work, an efficient precoding design scheme is proposed for downlink cell-free distributed massive multiple-input multiple-output (DM-MIMO) filter bank multi-carrier (FBMC) systems with asynchronous reception and highly frequency selectivity.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.0579010412,"dev-research":0.3541801933,"prompt-eng":0.3858596356,"data-quality":0.0670740767,"ml-security":0.1109233603}}
{"text":"The proposed scheme includes a multiple interpolation structure to eliminate the impact of response difference we recently discovered, which has better performance in highly frequency-selective channels.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.040732068,"dev-research":0.3598130376,"prompt-eng":0.4119351838,"data-quality":0.0873024746,"ml-security":0.0868746062}}
{"text":"Besides, we also consider the phase shift in asynchronous reception and introduce a phase compensation in the design process.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.0429773234,"dev-research":0.4100024115,"prompt-eng":0.4018839074,"data-quality":0.0828679665,"ml-security":0.1192596014}}
{"text":"The phase compensation also benefits from the multiple interpolation structure and better adapts to asynchronous reception.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.0482303226,"dev-research":0.3705900189,"prompt-eng":0.3761172768,"data-quality":0.0817361948,"ml-security":0.094667194}}
{"text":"Based on the proposed scheme, we theoretically analyze its ergodic achievable rate performance and derive a closed-form expression.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.0752467484,"dev-research":0.3512116218,"prompt-eng":0.3699536468,"data-quality":0.0918640889,"ml-security":0.2318813989}}
{"text":"Simulation results show that the derived expression can accurately characterize the rate performance, and FBMC with the proposed scheme outperforms orthogonal frequency-division multiplexing (OFDM) in the asynchronous scenario.","meta":{"url":"http://arxiv.org/abs/2307.06657v1"},"cats":{"new-dataset":0.064677686,"dev-research":0.3979085085,"prompt-eng":0.3842957055,"data-quality":0.1224339921,"ml-security":0.1051871741}}
{"text":"Given a set of squares and a strip of bounded width and infinite height, we consider a square strip packaging problem, which we call the square independent packing problem (SIPP), to minimize the strip height so that all the squares are packed into independent cells separated by horizontal and vertical partitions.","meta":{"url":"http://arxiv.org/abs/2307.06654v1"},"cats":{"new-dataset":0.2003023243,"dev-research":0.4146480661,"prompt-eng":0.3593329528,"data-quality":0.1072267283,"ml-security":0.1299067201}}
{"text":"For the SIPP, we first investigate efficient solution representations and propose a compact representation that reduces the search space from $\\Omega(n!)$ to $O(2^n)$, with $n$ the number of given squares, while guaranteeing that there exists a solution representation that corresponds to an optimal solution.","meta":{"url":"http://arxiv.org/abs/2307.06654v1"},"cats":{"new-dataset":0.0959956585,"dev-research":0.4134027881,"prompt-eng":0.3686314255,"data-quality":0.0693941236,"ml-security":0.169020144}}
{"text":"Based on the solution representation, we show that the problem is NP-hard, and then we propose a fully polynomial-time approximation scheme (FPTAS) to solve it.","meta":{"url":"http://arxiv.org/abs/2307.06654v1"},"cats":{"new-dataset":0.1130576896,"dev-research":0.3919735627,"prompt-eng":0.3366648906,"data-quality":0.1331967024,"ml-security":0.1290503527}}
{"text":"We also propose three mathematical programming formulations based on different solution representations and confirm the performance of these algorithms through computational experiments.","meta":{"url":"http://arxiv.org/abs/2307.06654v1"},"cats":{"new-dataset":0.0612399735,"dev-research":0.4163566779,"prompt-eng":0.3413516657,"data-quality":0.0932618568,"ml-security":0.0918564748}}
{"text":"Finally, we discuss several extensions that are relevant to practical applications.","meta":{"url":"http://arxiv.org/abs/2307.06654v1"},"cats":{"new-dataset":0.0629559995,"dev-research":0.4757903667,"prompt-eng":0.4172293057,"data-quality":0.0987245757,"ml-security":0.1308411012}}
{"text":"We present DeepIPCv2, an autonomous driving model that perceives the environment using a LiDAR sensor for more robust drivability, especially when driving under poor illumination conditions.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.2063926985,"dev-research":0.3602755095,"prompt-eng":0.4276969834,"data-quality":0.1332448938,"ml-security":0.2106637832}}
{"text":"DeepIPCv2 takes a set of LiDAR point clouds for its main perception input.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.1897378633,"dev-research":0.3554720284,"prompt-eng":0.4272099538,"data-quality":0.0937324851,"ml-security":0.1446524115}}
{"text":"As point clouds are not affected by illumination changes, they can provide a clear observation of the surroundings no matter what the condition is.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.0682886984,"dev-research":0.385176277,"prompt-eng":0.3585373105,"data-quality":0.1285628241,"ml-security":0.115438853}}
{"text":"This results in a better scene understanding and stable features provided by the perception module to support the controller module in estimating navigational control properly.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.1717593786,"dev-research":0.4080849937,"prompt-eng":0.4819857413,"data-quality":0.1795572676,"ml-security":0.0601179256}}
{"text":"To evaluate its performance, we conduct several tests by deploying the model to predict a set of driving records and perform real automated driving under three different conditions.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.1967290394,"dev-research":0.3990331824,"prompt-eng":0.5017133939,"data-quality":0.1153246931,"ml-security":0.1187175303}}
{"text":"We also conduct ablation and comparative studies with some recent models to justify its performance.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.0882121017,"dev-research":0.3654021374,"prompt-eng":0.3870233726,"data-quality":0.0931108965,"ml-security":0.0428359282}}
{"text":"Based on the experimental results, DeepIPCv2 shows a robust performance by achieving the best drivability in all conditions.","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.1598091611,"dev-research":0.3679215337,"prompt-eng":0.4074160206,"data-quality":0.1362084273,"ml-security":0.2049553453}}
{"text":"Codes are available at https://github.com/oskarnatan/DeepIPCv2","meta":{"url":"http://arxiv.org/abs/2307.06647v1"},"cats":{"new-dataset":0.4112385741,"dev-research":0.4313561288,"prompt-eng":0.4442597415,"data-quality":0.121078863,"ml-security":0.1392206339}}
{"text":"Predicting the behavior of real-time traffic (e.g., VoIP) in mobility scenarios could help the operators to better plan their network infrastructures and to optimize the allocation of resources.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.1451897345,"dev-research":0.393510016,"prompt-eng":0.4459454687,"data-quality":0.0727408978,"ml-security":0.2215104036}}
{"text":"Accordingly, in this work the authors propose a forecasting analysis of crucial QoS/QoE descriptors (some of which neglected in the technical literature) of VoIP traffic in a real mobile environment.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.1647033083,"dev-research":0.3747986331,"prompt-eng":0.4520059189,"data-quality":0.0995541431,"ml-security":0.1927893776}}
{"text":"The problem is formulated in terms of a multivariate time series analysis.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.2112808242,"dev-research":0.3745571624,"prompt-eng":0.3790354431,"data-quality":0.0945961753,"ml-security":0.124389185}}
{"text":"Such a formalization allows to discover and model the temporal relationships among various descriptors and to forecast their behaviors for future periods.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.1670749851,"dev-research":0.4443080958,"prompt-eng":0.48192995,"data-quality":0.0990967209,"ml-security":0.1184980924}}
{"text":"Techniques such as Vector Autoregressive models and machine learning (deep-based and tree-based) approaches are employed and compared in terms of performance and time complexity, by reframing the multivariate time series problem into a supervised learning one.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.1554084722,"dev-research":0.3630464798,"prompt-eng":0.411486672,"data-quality":0.1047899101,"ml-security":0.1521162039}}
{"text":"Moreover, a series of auxiliary analyses (stationarity, orthogonal impulse responses, etc.) are performed to discover the analytical structure of the time series and to provide deep insights about their relationships.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.0931386359,"dev-research":0.4014286495,"prompt-eng":0.4005339027,"data-quality":0.0833597641,"ml-security":0.11497645}}
{"text":"The whole theoretical analysis has an experimental counterpart since a set of trials across a real-world LTE-Advanced environment has been performed to collect, post-process and analyze about 600,000 voice packets, organized per flow and differentiated per codec.","meta":{"url":"http://arxiv.org/abs/2307.06645v1"},"cats":{"new-dataset":0.1359285741,"dev-research":0.4064844712,"prompt-eng":0.4610645904,"data-quality":0.0985520408,"ml-security":0.1083672881}}
{"text":"Indirect surveys, in which respondents provide information about other people they know, have been proposed for scenarios where privacy is important or where the population to be surveyed is hard to reach.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.2607087499,"dev-research":0.4252460379,"prompt-eng":0.4640251685,"data-quality":0.1133708355,"ml-security":0.3792892569}}
{"text":"As an example, during various stages of the COVID-19 pandemic surveys, including indirect surveys, have been used to estimate the number of cases or the level of vaccination.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.3309504183,"dev-research":0.4078003393,"prompt-eng":0.4829111287,"data-quality":0.10530508,"ml-security":0.203172262}}
{"text":"The Network Scale-up Method (NSUM) is the classical approach to developing such estimates but was designed with discrete, time-limited indirect surveys in mind.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.1729773992,"dev-research":0.3624364853,"prompt-eng":0.3845507817,"data-quality":0.0798933276,"ml-security":0.0786765632}}
{"text":"Further, it requires asking for or estimating the number of individuals in each respondent's network.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.1588581573,"dev-research":0.4085254753,"prompt-eng":0.4807271924,"data-quality":0.0904477449,"ml-security":0.1340553186}}
{"text":"In recent years, surveys are being increasingly deployed online and collecting data continuously (e.g., COVID-19 surveys on Facebook during much of the pandemic).","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.4834518657,"dev-research":0.4026884225,"prompt-eng":0.44906518,"data-quality":0.0794012675,"ml-security":0.2156468274}}
{"text":"Conventional NSUM can be applied to these scenarios by analyzing the data independently during each time interval, but this misses the opportunity of leveraging the temporal dimension.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.1904592581,"dev-research":0.3911289102,"prompt-eng":0.4076557527,"data-quality":0.0807397827,"ml-security":0.0785097451}}
{"text":"Understanding the advantage of simply smoothing NSUM results to various degrees is not trivial.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.0395158463,"dev-research":0.4161091212,"prompt-eng":0.3498558355,"data-quality":0.0779845716,"ml-security":0.0645958293}}
{"text":"We propose to use the responses from indirect surveys collected over time and develop analytical tools (i) to prove that indirect surveys can be used to provide better estimates for the size of the hidden population compared to direct surveys, and (ii) to identify appropriate aggregations over time to further improve the estimates.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.3312760524,"dev-research":0.4010424909,"prompt-eng":0.4455543974,"data-quality":0.1231877496,"ml-security":0.162092746}}
{"text":"We demonstrate through simulations that our approach outperforms traditional NSUM and direct surveying methods to estimate the size of a time-varying hidden population.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.2277624431,"dev-research":0.3371017432,"prompt-eng":0.4163593377,"data-quality":0.0781150174,"ml-security":0.137688723}}
{"text":"We also demonstrate the superiority of our approach on an existing indirect survey dataset on COVID-19 confirmed cases.","meta":{"url":"http://arxiv.org/abs/2307.06643v1"},"cats":{"new-dataset":0.5431953276,"dev-research":0.4362855173,"prompt-eng":0.5022817374,"data-quality":0.13663084,"ml-security":0.2192961758}}
{"text":"Decentralized learning algorithms are an essential tool for designing multi-agent systems, as they enable agents to autonomously learn from their experience and past interactions.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.1168368913,"dev-research":0.4168833646,"prompt-eng":0.4565553845,"data-quality":0.080917078,"ml-security":0.2843391543}}
{"text":"In this work, we propose a theoretical and algorithmic framework for real-time identification of the learning dynamics that govern agent behavior using a short burst of a single system trajectory.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.1104120237,"dev-research":0.3835049742,"prompt-eng":0.4532257882,"data-quality":0.1006968489,"ml-security":0.3688334006}}
{"text":"Our method identifies agent dynamics through polynomial regression, where we compensate for limited data by incorporating side-information constraints that capture fundamental assumptions or expectations about agent behavior.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.160255127,"dev-research":0.4512540449,"prompt-eng":0.4408541809,"data-quality":0.0880449745,"ml-security":0.3537359663}}
{"text":"These constraints are enforced computationally using sum-of-squares optimization, leading to a hierarchy of increasingly better approximations of the true agent dynamics.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.0411931931,"dev-research":0.3899508765,"prompt-eng":0.3621391287,"data-quality":0.0395415401,"ml-security":0.1996881863}}
{"text":"Extensive experiments demonstrated that our approach, using only 5 samples from a short run of a single trajectory, accurately recovers the true dynamics across various benchmarks, including equilibrium selection and prediction of chaotic systems up to 10 Lyapunov times.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.111357987,"dev-research":0.3416928564,"prompt-eng":0.41344223,"data-quality":0.1073265935,"ml-security":0.1766914137}}
{"text":"These findings suggest that our approach has significant potential to support effective policy and decision-making in strategic multi-agent systems.","meta":{"url":"http://arxiv.org/abs/2307.06640v1"},"cats":{"new-dataset":0.0733676134,"dev-research":0.4485296085,"prompt-eng":0.4284691015,"data-quality":0.0582982154,"ml-security":0.0953894667}}
{"text":"From its conception, 6G is being designed with a particular focus on sustainability.","meta":{"url":"http://arxiv.org/abs/2307.06636v1"},"cats":{"new-dataset":0.1113232683,"dev-research":0.4227539065,"prompt-eng":0.3720163069,"data-quality":0.0729683282,"ml-security":0.0620444696}}
{"text":"The general philosophy of the H2020 Hexa-X project work on sustainability in 6G is based on two principles: to reduce direct negative life cycle impacts of 6G systems as much as possible (Sustainable 6G) and to analyze use cases that maximize positive environmental, social, and economic effects in other sectors of society (6G for Sustainability or its enablement effect).","meta":{"url":"http://arxiv.org/abs/2307.06636v1"},"cats":{"new-dataset":0.1421448532,"dev-research":0.446985358,"prompt-eng":0.3770397684,"data-quality":0.0647662398,"ml-security":0.0535872417}}
{"text":"To apply this philosophy, Hexa-X is designing 6G with three sustainability objectives in mind: to enable the reduction of emissions in 6G-powered sectors of society, to reduce the total cost of ownership and to improve energy efficiency.","meta":{"url":"http://arxiv.org/abs/2307.06636v1"},"cats":{"new-dataset":0.0891159715,"dev-research":0.4433033686,"prompt-eng":0.3637938376,"data-quality":0.0526657818,"ml-security":0.0435619509}}
{"text":"This paper describes these objectives, their associated KPIs and quantitative targets, and the levers to reach them.","meta":{"url":"http://arxiv.org/abs/2307.06636v1"},"cats":{"new-dataset":0.0619313019,"dev-research":0.4108527114,"prompt-eng":0.4076277542,"data-quality":0.0853111787,"ml-security":0.1250261948}}
{"text":"Furthermore, to maximize the positive effects of 6G through the enablement effect, a link between 6G and the United Nations' Sustainable Development Goals (UN SDGs) framework is proposed and illustrated by Hexa-X use case families.","meta":{"url":"http://arxiv.org/abs/2307.06636v1"},"cats":{"new-dataset":0.1214461279,"dev-research":0.4399033695,"prompt-eng":0.3955236284,"data-quality":0.0549967711,"ml-security":0.0576858821}}
{"text":"This paper deals with the trade-off between time, workload, and versatility in self-stabilization, a general and lightweight fault-tolerant concept in distributed computing.","meta":{"url":"http://arxiv.org/abs/2307.06635v1"},"cats":{"new-dataset":0.0993517431,"dev-research":0.4380486765,"prompt-eng":0.390019718,"data-quality":0.1498403161,"ml-security":0.2247857578}}
{"text":"In this context, we propose a transformer that provides an asynchronous silent self-stabilizing version Trans(AlgI) of any terminating synchronous algorithm AlgI.","meta":{"url":"http://arxiv.org/abs/2307.06635v1"},"cats":{"new-dataset":0.0826485419,"dev-research":0.4174369682,"prompt-eng":0.3970511524,"data-quality":0.1791682413,"ml-security":0.1695605843}}
{"text":"The transformed algorithm Trans(AlgI) works under the distributed unfair daemon and is efficient both in moves and rounds.","meta":{"url":"http://arxiv.org/abs/2307.06635v1"},"cats":{"new-dataset":0.0953859597,"dev-research":0.3873103863,"prompt-eng":0.3626090202,"data-quality":0.0628726647,"ml-security":0.1383234845}}
{"text":"Our transformer allows to easily obtain fully-polynomial silent self-stabilizing solutions that are also asymptotically optimal in rounds.","meta":{"url":"http://arxiv.org/abs/2307.06635v1"},"cats":{"new-dataset":0.047292256,"dev-research":0.3781836288,"prompt-eng":0.3722532346,"data-quality":0.1407209164,"ml-security":0.2597659614}}
{"text":"We illustrate the efficiency and versatility of our transformer with several efficient (i.e., fully-polynomial) silent self-stabilizing instances solving major distributed computing problems, namely vertex coloring, Breadth-First Search (BFS) spanning tree construction, k-clustering, and leader election.","meta":{"url":"http://arxiv.org/abs/2307.06635v1"},"cats":{"new-dataset":0.0657268945,"dev-research":0.3806689307,"prompt-eng":0.3719393884,"data-quality":0.1176720825,"ml-security":0.2241052155}}
{"text":"Most of the existing LiDAR-inertial navigation systems are based on frame-to-map registrations, leading to inconsistency in state estimation.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.1343188667,"dev-research":0.369119049,"prompt-eng":0.4076715162,"data-quality":0.1386991945,"ml-security":0.0854904367}}
{"text":"The newest solid-state LiDAR with a non-repetitive scanning pattern makes it possible to achieve a consistent LiDAR-inertial estimator by employing a frame-to-frame data association.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.1451229447,"dev-research":0.3566849542,"prompt-eng":0.4197385229,"data-quality":0.1224274588,"ml-security":0.0836475435}}
{"text":"In this letter, we propose a robust and consistent frame-to-frame LiDAR-inertial navigation system (FF-LINS) for solid-state LiDARs.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.149186676,"dev-research":0.3588377415,"prompt-eng":0.4100834785,"data-quality":0.0913006322,"ml-security":0.0737759437}}
{"text":"With the INS-centric LiDAR frame processing, the keyframe point-cloud map is built using the accumulated point clouds to construct the frame-to-frame data association.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.2457253762,"dev-research":0.3855552764,"prompt-eng":0.3975669714,"data-quality":0.0943978353,"ml-security":0.1079810273}}
{"text":"The LiDAR frame-to-frame and the inertial measurement unit (IMU) preintegration measurements are tightly integrated using the factor graph optimization, with online calibration of the LiDAR-IMU extrinsic and time-delay parameters.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.0982349474,"dev-research":0.3722616499,"prompt-eng":0.4176537819,"data-quality":0.0892709106,"ml-security":0.0473004861}}
{"text":"The experiments on the public and private datasets demonstrate that the proposed FF-LINS achieves superior accuracy and robustness than the state-of-the-art systems.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.4171551911,"dev-research":0.3634492679,"prompt-eng":0.4193545366,"data-quality":0.2542833074,"ml-security":0.2927344824}}
{"text":"Besides, the LiDAR-IMU extrinsic and time-delay parameters are estimated effectively, and the online calibration notably improves the pose accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.1150647244,"dev-research":0.3543889611,"prompt-eng":0.4155568414,"data-quality":0.1038864712,"ml-security":0.0746816092}}
{"text":"The proposed FF-LINS and the employed datasets are open-sourced on GitHub (https://github.com/i2Nav-WHU/FF-LINS).","meta":{"url":"http://arxiv.org/abs/2307.06632v1"},"cats":{"new-dataset":0.6963150315,"dev-research":0.3638152138,"prompt-eng":0.4414927206,"data-quality":0.1064890313,"ml-security":0.1010069407}}
{"text":"Knowledge distillation (KD) has shown great potential for transferring knowledge from a complex teacher model to a simple student model in which the heavy learning task can be accomplished efficiently and without losing too much prediction accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.1045024846,"dev-research":0.4176040164,"prompt-eng":0.4790585118,"data-quality":0.0904550312,"ml-security":0.2166910746}}
{"text":"Recently, many attempts have been made by applying the KD mechanism to the graph representation learning models such as graph neural networks (GNNs) to accelerate the model's inference speed via student models.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.1213595103,"dev-research":0.376664118,"prompt-eng":0.4273707741,"data-quality":0.0982115528,"ml-security":0.1853914715}}
{"text":"However, many existing KD-based GNNs utilize MLP as a universal approximator in the student model to imitate the teacher model's process without considering the graph knowledge from the teacher model.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.0740397592,"dev-research":0.3684023411,"prompt-eng":0.4279707526,"data-quality":0.1099895867,"ml-security":0.2155853936}}
{"text":"In this work, we provide a KD-based framework on multi-scaled GNNs, known as graph framelet, and prove that by adequately utilizing the graph knowledge in a multi-scaled manner provided by graph framelet decomposition, the student model is capable of adapting both homophilic and heterophilic graphs and has the potential of alleviating the over-squashing issue with a simple yet effectively graph surgery.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.153993019,"dev-research":0.3936774581,"prompt-eng":0.4054031402,"data-quality":0.1716857273,"ml-security":0.1433796689}}
{"text":"Furthermore, we show how the graph knowledge supplied by the teacher is learned and digested by the student model via both algebra and geometry.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.1720481922,"dev-research":0.4725657621,"prompt-eng":0.3882586022,"data-quality":0.0947161386,"ml-security":0.1443105928}}
{"text":"Comprehensive experiments show that our proposed model can generate learning accuracy identical to or even surpass the teacher model while maintaining the high speed of inference.","meta":{"url":"http://arxiv.org/abs/2307.06631v1"},"cats":{"new-dataset":0.0913805542,"dev-research":0.3890472739,"prompt-eng":0.5271307813,"data-quality":0.1307987293,"ml-security":0.1964892595}}
{"text":"In this work, the novel Image Transformation Sequence Retrieval (ITSR) task is presented, in which a model must retrieve the sequence of transformations between two given images that act as source and target, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06630v1"},"cats":{"new-dataset":0.2907433672,"dev-research":0.3776213526,"prompt-eng":0.4588204122,"data-quality":0.1051497124,"ml-security":0.0728436739}}
{"text":"Given certain characteristics of the challenge such as the multiplicity of a correct sequence or the correlation between consecutive steps of the process, we propose a solution to ITSR using a general model-based Reinforcement Learning such as Monte Carlo Tree Search (MCTS), which is combined with a deep neural network.","meta":{"url":"http://arxiv.org/abs/2307.06630v1"},"cats":{"new-dataset":0.1296776955,"dev-research":0.3721697139,"prompt-eng":0.4834297172,"data-quality":0.0880164566,"ml-security":0.1299256003}}
{"text":"Our experiments provide a benchmark in both synthetic and real domains, where the proposed approach is compared with supervised training.","meta":{"url":"http://arxiv.org/abs/2307.06630v1"},"cats":{"new-dataset":0.1991988208,"dev-research":0.381161092,"prompt-eng":0.4808196973,"data-quality":0.2646535698,"ml-security":0.2129273043}}
{"text":"The results report that a model trained with MCTS is able to outperform its supervised counterpart in both the simplest and the most complex cases.","meta":{"url":"http://arxiv.org/abs/2307.06630v1"},"cats":{"new-dataset":0.0653618348,"dev-research":0.4092238553,"prompt-eng":0.5171645755,"data-quality":0.2726363224,"ml-security":0.1433564313}}
{"text":"Our work draws interesting conclusions about the nature of ITSR and its associated challenges.","meta":{"url":"http://arxiv.org/abs/2307.06630v1"},"cats":{"new-dataset":0.1752521903,"dev-research":0.4782790395,"prompt-eng":0.4295486741,"data-quality":0.1285187665,"ml-security":0.1200106373}}
{"text":"We propose fast and practical quantum-inspired classical algorithms for solving linear systems.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.0503769943,"dev-research":0.3689414609,"prompt-eng":0.343779768,"data-quality":0.062038531,"ml-security":0.1319248591}}
{"text":"Specifically, given sampling and query access to a matrix $A\\in\\mathbb{R}^{m\\times n}$ and a vector $b\\in\\mathbb{R}^m$, we propose classical algorithms that produce a data structure for the solution $x\\in\\mathbb{R}^{n}$ of the linear system $Ax=b$ with the ability to sample and query its entries.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.1928307425,"dev-research":0.3649052633,"prompt-eng":0.3791797906,"data-quality":0.0848716272,"ml-security":0.2146941697}}
{"text":"The resulting $x$ satisfies $\\|x-A^{+}b\\|\\leq\\epsilon\\|A^{+}b\\|$, where $\\|\\cdot\\|$ is the spectral norm and $A^+$ is the Moore-Penrose inverse of $A$.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.1103254418,"dev-research":0.4191866468,"prompt-eng":0.3734390564,"data-quality":0.1456424237,"ml-security":0.232484664}}
{"text":"Our algorithm has time complexity $\\widetilde{O}(\\kappa_F^4/\\kappa\\epsilon^2)$ in the general case, where $\\kappa_{F} =\\|A\\|_F\\|A^+\\|$ and $\\kappa=\\|A\\|\\|A^+\\|$ are condition numbers.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.0784157359,"dev-research":0.3917933864,"prompt-eng":0.3354553956,"data-quality":0.1348254113,"ml-security":0.1715303353}}
{"text":"Compared to the prior state-of-the-art result [Shao and Montanaro, arXiv:2103.10309v2], our algorithm achieves a polynomial speedup in condition numbers.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.1238151875,"dev-research":0.3885164937,"prompt-eng":0.3689995363,"data-quality":0.0764184015,"ml-security":0.1563901227}}
{"text":"When $A$ is $s$-sparse, our algorithm has complexity $\\widetilde{O}(s \\kappa\\log(1/\\epsilon))$, matching the quantum lower bound for solving linear systems in $\\kappa$ and $1/\\epsilon$ up to poly-logarithmic factors [Harrow and Kothari].","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.050265359,"dev-research":0.3748457512,"prompt-eng":0.357356588,"data-quality":0.0855077804,"ml-security":0.1639858708}}
{"text":"When $A$ is $s$-sparse and symmetric positive-definite, our algorithm has complexity $\\widetilde{O}(s\\sqrt{\\kappa}\\log(1/\\epsilon))$.   Technically, our main contribution is the application of the heavy ball momentum method to quantum-inspired classical algorithms for solving linear systems, where we propose two new methods with speedups: quantum-inspired Kaczmarz method with momentum and quantum-inspired coordinate descent method with momentum.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.0407551127,"dev-research":0.3721774758,"prompt-eng":0.3356067542,"data-quality":0.0699378825,"ml-security":0.1415823296}}
{"text":"Their analysis exploits careful decomposition of the momentum transition matrix and the application of novel spectral norm concentration bounds for independent random matrices.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.065291615,"dev-research":0.3578071701,"prompt-eng":0.4031427048,"data-quality":0.0719989089,"ml-security":0.1732126166}}
{"text":"Finally, we also conduct numerical experiments for our algorithms on both synthetic and real-world datasets, and the experimental results support our theoretical claims.","meta":{"url":"http://arxiv.org/abs/2307.06627v1"},"cats":{"new-dataset":0.223470562,"dev-research":0.3413864047,"prompt-eng":0.3626867259,"data-quality":0.1641930034,"ml-security":0.2168080329}}
{"text":"Deception detection is an interdisciplinary field attracting researchers from psychology, criminology, computer science, and economics.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.1339074795,"dev-research":0.4142333666,"prompt-eng":0.4236624286,"data-quality":0.2335436328,"ml-security":0.4316468481}}
{"text":"We propose a multimodal approach combining deep learning and discriminative models for automated deception detection.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.2592245922,"dev-research":0.3715955734,"prompt-eng":0.5098194951,"data-quality":0.2857387711,"ml-security":0.2913355078}}
{"text":"Using video modalities, we employ convolutional end-to-end learning to analyze gaze, head pose, and facial expressions, achieving promising results compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.1783597337,"dev-research":0.409863984,"prompt-eng":0.4559459438,"data-quality":0.1534049637,"ml-security":0.0913750362}}
{"text":"Due to limited training data, we also utilize discriminative models for deception detection.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.1826195093,"dev-research":0.3661513146,"prompt-eng":0.4924088591,"data-quality":0.2731971115,"ml-security":0.4692681331}}
{"text":"Although sequence-to-class approaches are explored, discriminative models outperform them due to data scarcity.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.3421689928,"dev-research":0.3761380624,"prompt-eng":0.4744415483,"data-quality":0.2449756498,"ml-security":0.3201316292}}
{"text":"Our approach is evaluated on five datasets, including a new Rolling-Dice Experiment motivated by economic factors.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.4563478874,"dev-research":0.4285887409,"prompt-eng":0.4293239173,"data-quality":0.0901410911,"ml-security":0.1246250654}}
{"text":"Results indicate that facial expressions outperform gaze and head pose, and combining modalities with feature selection enhances detection performance.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.0588417781,"dev-research":0.4216025518,"prompt-eng":0.4369536813,"data-quality":0.1574123166,"ml-security":0.1002554778}}
{"text":"Differences in expressed features across datasets emphasize the importance of scenario-specific training data and the influence of context on deceptive behavior.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.2020318532,"dev-research":0.4333442992,"prompt-eng":0.4807767508,"data-quality":0.3213527129,"ml-security":0.5327917927}}
{"text":"Cross-dataset experiments reinforce these findings.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.3781948475,"dev-research":0.4370104182,"prompt-eng":0.4846846459,"data-quality":0.2322891906,"ml-security":0.2024935734}}
{"text":"Despite the challenges posed by low-stake datasets, including the Rolling-Dice Experiment, deception detection performance exceeds chance levels.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.2547689162,"dev-research":0.3597693991,"prompt-eng":0.4236637,"data-quality":0.2142360974,"ml-security":0.4478606386}}
{"text":"Our proposed multimodal approach and comprehensive evaluation shed light on the potential of automating deception detection from video modalities, opening avenues for future research.","meta":{"url":"http://arxiv.org/abs/2307.06625v1"},"cats":{"new-dataset":0.138373913,"dev-research":0.3958676627,"prompt-eng":0.48617609,"data-quality":0.3041149973,"ml-security":0.2224623121}}
{"text":"When it comes to storing 3D city models in a database, the implementation of the CityGML data model can be quite demanding and often results in complicated schemas.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.4159578971,"dev-research":0.4009188031,"prompt-eng":0.3970435176,"data-quality":0.0646162014,"ml-security":0.1046205765}}
{"text":"As an example, 3DCityDB, a widely used solution, depends on a schema having 66 tables, mapping closely the CityGML architecture.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.3905194646,"dev-research":0.4313650436,"prompt-eng":0.4066267402,"data-quality":0.0656628871,"ml-security":0.0726255786}}
{"text":"In this paper, we propose an alternative (called cjdb) for storing CityGML models efficiently in PostgreSQL with a much simpler table structure and data model design (only 3 tables are necessary).","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.3110712258,"dev-research":0.3995169866,"prompt-eng":0.3972314402,"data-quality":0.069126333,"ml-security":0.1112788639}}
{"text":"This is achieved by storing the attributes and geometries of the objects directly in JSON.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.1694350477,"dev-research":0.4157641814,"prompt-eng":0.4546975326,"data-quality":0.073621001,"ml-security":0.1096817729}}
{"text":"In the case of the geometries we thus adopt the Simple Feature paradigm and we use the structure of CityJSON.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.120298969,"dev-research":0.4438675708,"prompt-eng":0.3897557467,"data-quality":0.0715624068,"ml-security":0.1092267379}}
{"text":"We compare our solution against 3DCityDB with large real-world 3D city models, and we find that cjdb has significantly lower demands in storage space (around a factor of 10), allows for faster import/export of data, and has a comparable data retrieval speed with some queries being faster and some slower.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.4127102347,"dev-research":0.3940016056,"prompt-eng":0.3693946427,"data-quality":0.0655809164,"ml-security":0.1183473397}}
{"text":"The accompanying software (importer and exporter) is available at https://github.com/cityjson/cjdb/ under a permissive open-source license.","meta":{"url":"http://arxiv.org/abs/2307.06621v1"},"cats":{"new-dataset":0.516977759,"dev-research":0.4379166235,"prompt-eng":0.4359680664,"data-quality":0.1159160697,"ml-security":0.1124628055}}
{"text":"In this paper we consider online distributed learning problems.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.1398266377,"dev-research":0.4255047085,"prompt-eng":0.423836404,"data-quality":0.1750743401,"ml-security":0.2981244859}}
{"text":"Online distributed learning refers to the process of training learning models on distributed data sources.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.1543831724,"dev-research":0.4238986718,"prompt-eng":0.4395591494,"data-quality":0.1362836195,"ml-security":0.2902854796}}
{"text":"In our setting a set of agents need to cooperatively train a learning model from streaming data.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.2579609886,"dev-research":0.3881913991,"prompt-eng":0.4859120145,"data-quality":0.1081440504,"ml-security":0.2754463867}}
{"text":"Differently from federated learning, the proposed approach does not rely on a central server but only on peer-to-peer communications among the agents.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.094567918,"dev-research":0.4020807556,"prompt-eng":0.4238559094,"data-quality":0.0967604762,"ml-security":0.287840437}}
{"text":"This approach is often used in scenarios where data cannot be moved to a centralized location due to privacy, security, or cost reasons.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.1203224025,"dev-research":0.4374979009,"prompt-eng":0.3655069328,"data-quality":0.1299795819,"ml-security":0.3809126339}}
{"text":"In order to overcome the absence of a central server, we propose a distributed algorithm that relies on a quantized, finite-time coordination protocol to aggregate the locally trained models.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.1231141196,"dev-research":0.3548881407,"prompt-eng":0.4461032693,"data-quality":0.0776013618,"ml-security":0.2520397649}}
{"text":"Furthermore, our algorithm allows for the use of stochastic gradients during local training.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.0933837799,"dev-research":0.3625070938,"prompt-eng":0.4547823915,"data-quality":0.1953819731,"ml-security":0.2131437409}}
{"text":"Stochastic gradients are computed using a randomly sampled subset of the local training data, which makes the proposed algorithm more efficient and scalable than traditional gradient descent.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.096357079,"dev-research":0.3381804201,"prompt-eng":0.4238948305,"data-quality":0.1981255198,"ml-security":0.2531496368}}
{"text":"In our paper, we analyze the performance of the proposed algorithm in terms of the mean distance from the online solution.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.1142086765,"dev-research":0.4109768619,"prompt-eng":0.3474264816,"data-quality":0.0943868363,"ml-security":0.0746967394}}
{"text":"Finally, we present numerical results for a logistic regression task.","meta":{"url":"http://arxiv.org/abs/2307.06620v1"},"cats":{"new-dataset":0.2764270315,"dev-research":0.4204967312,"prompt-eng":0.4953119109,"data-quality":0.1311552313,"ml-security":0.0942661124}}
{"text":"The performance of data fusion and tracking algorithms often depends on parameters that not only describe the sensor system, but can also be task-specific.","meta":{"url":"http://arxiv.org/abs/2307.06618v1"},"cats":{"new-dataset":0.1204590488,"dev-research":0.3808665421,"prompt-eng":0.3810735156,"data-quality":0.0816325846,"ml-security":0.1062566187}}
{"text":"While for the sensor system tuning these variables is time-consuming and mostly requires expert knowledge, intrinsic parameters of targets under track can even be completely unobservable until the system is deployed.","meta":{"url":"http://arxiv.org/abs/2307.06618v1"},"cats":{"new-dataset":0.0679347328,"dev-research":0.4062732524,"prompt-eng":0.456609396,"data-quality":0.1334770022,"ml-security":0.1905261111}}
{"text":"With state-of-the-art sensor systems growing more and more complex, the number of parameters naturally increases, necessitating the automatic optimization of the model variables.","meta":{"url":"http://arxiv.org/abs/2307.06618v1"},"cats":{"new-dataset":0.0749572638,"dev-research":0.4021096953,"prompt-eng":0.5019010985,"data-quality":0.0807680029,"ml-security":0.1604200338}}
{"text":"In this paper, the parameters of an interacting multiple model (IMM) filter are optimized solely using measurements, thus without necessity for any ground-truth data.","meta":{"url":"http://arxiv.org/abs/2307.06618v1"},"cats":{"new-dataset":0.0645280991,"dev-research":0.3336455957,"prompt-eng":0.4637194535,"data-quality":0.0940487173,"ml-security":0.1223837908}}
{"text":"The resulting method is evaluated through an ablation study on simulated data, where the trained model manages to match the performance of a filter parametrized with ground-truth values.","meta":{"url":"http://arxiv.org/abs/2307.06618v1"},"cats":{"new-dataset":0.1030527155,"dev-research":0.3419031611,"prompt-eng":0.4422205224,"data-quality":0.184145295,"ml-security":0.1034593319}}
{"text":"Software vulnerabilities leading to various detriments such as crashes, data loss, and security breaches, significantly hinder the quality, affecting the market adoption of software applications and systems.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.1436145538,"dev-research":0.5433122199,"prompt-eng":0.4198005376,"data-quality":0.2441705376,"ml-security":0.5847194352}}
{"text":"Although traditional methods such as automated software testing, fault localization, and repair have been intensively studied, static analysis tools are most commonly used and have an inherent false positives rate, posing a solid challenge to developer productivity.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.121089653,"dev-research":0.5443434527,"prompt-eng":0.4648039095,"data-quality":0.3945467438,"ml-security":0.2159144353}}
{"text":"Large Language Models (LLMs) offer a promising solution to these persistent issues.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.164155296,"dev-research":0.4284360017,"prompt-eng":0.5862205669,"data-quality":0.2970309919,"ml-security":0.209400808}}
{"text":"Among these, FalconLLM has shown substantial potential in identifying intricate patterns and complex vulnerabilities, hence crucial in software vulnerability detection.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.2078701854,"dev-research":0.5281039159,"prompt-eng":0.4845712663,"data-quality":0.1930561684,"ml-security":0.5863285064}}
{"text":"In this paper, for the first time, FalconLLM is being fine-tuned for cybersecurity applications, thus introducing SecureFalcon, an innovative model architecture built upon FalconLLM.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.1398822928,"dev-research":0.4450388269,"prompt-eng":0.461457635,"data-quality":0.0672736154,"ml-security":0.5611603058}}
{"text":"SecureFalcon is trained to differentiate between vulnerable and non-vulnerable C code samples.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.2169970572,"dev-research":0.4926005039,"prompt-eng":0.5014354445,"data-quality":0.2194708662,"ml-security":0.5247067838}}
{"text":"We build a new training dataset, FormAI, constructed thanks to Generative Artificial Intelligence (AI) and formal verification to evaluate its performance.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.4578511664,"dev-research":0.4064990699,"prompt-eng":0.5153612338,"data-quality":0.2195062773,"ml-security":0.1614551063}}
{"text":"SecureFalcon achieved an impressive 94% accuracy rate in detecting software vulnerabilities, emphasizing its significant potential to redefine software vulnerability detection methods in cybersecurity.","meta":{"url":"http://arxiv.org/abs/2307.06616v1"},"cats":{"new-dataset":0.1496519879,"dev-research":0.4845846287,"prompt-eng":0.483061651,"data-quality":0.2622114446,"ml-security":0.5185806017}}
{"text":"Entropic risk (ERisk) is an established risk measure in finance, quantifying risk by an exponential re-weighting of rewards.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.1157496801,"dev-research":0.4175596134,"prompt-eng":0.4461297862,"data-quality":0.1396006269,"ml-security":0.2054465913}}
{"text":"We study ERisk for the first time in the context of turn-based stochastic games with the total reward objective.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.1069848507,"dev-research":0.409953842,"prompt-eng":0.4281541741,"data-quality":0.0921681118,"ml-security":0.1667851515}}
{"text":"This gives rise to an objective function that demands the control of systems in a risk-averse manner.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0523976912,"dev-research":0.4619869496,"prompt-eng":0.4092753689,"data-quality":0.0537944619,"ml-security":0.3700628774}}
{"text":"We show that the resulting games are determined and, in particular, admit optimal memoryless deterministic strategies.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0981448363,"dev-research":0.4206092191,"prompt-eng":0.3873267667,"data-quality":0.0755614391,"ml-security":0.3417460547}}
{"text":"This contrasts risk measures that previously have been considered in the special case of Markov decision processes and that require randomization and/or memory.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0673341729,"dev-research":0.3790932606,"prompt-eng":0.4369157234,"data-quality":0.0922202759,"ml-security":0.280560056}}
{"text":"We provide several results on the decidability and the computational complexity of the threshold problem, i.e. whether the optimal value of ERisk exceeds a given threshold.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0613660362,"dev-research":0.3916564134,"prompt-eng":0.3774795164,"data-quality":0.1729904974,"ml-security":0.2047060858}}
{"text":"In the most general case, the problem is decidable subject to Shanuel's conjecture.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.1015249522,"dev-research":0.4174071819,"prompt-eng":0.3805728756,"data-quality":0.1543087735,"ml-security":0.18652343}}
{"text":"If all inputs are rational, the resulting threshold problem can be solved using algebraic numbers, leading to decidability via a polynomial-time reduction to the existential theory of the reals.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0624145903,"dev-research":0.4049618584,"prompt-eng":0.3783026739,"data-quality":0.1591803721,"ml-security":0.3218102398}}
{"text":"Further restrictions on the encoding of the input allow the solution of the threshold problem in NP$\\cap$coNP.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.0668800207,"dev-research":0.3941548785,"prompt-eng":0.3803808099,"data-quality":0.1603727113,"ml-security":0.2401149174}}
{"text":"Finally, an approximation algorithm for the optimal value of ERisk is provided.","meta":{"url":"http://arxiv.org/abs/2307.06611v1"},"cats":{"new-dataset":0.1118876733,"dev-research":0.3525105165,"prompt-eng":0.364337978,"data-quality":0.1438713129,"ml-security":0.0664883228}}
{"text":"Recently, the no-box adversarial attack, in which the attacker lacks access to the model's architecture, weights, and training data, become the most practical and challenging attack setup.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0972771303,"dev-research":0.3915221996,"prompt-eng":0.425294865,"data-quality":0.1313252297,"ml-security":0.8415685045}}
{"text":"However, there is an unawareness of the potential and flexibility inherent in the surrogate model selection process on no-box setting.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0332050766,"dev-research":0.402616341,"prompt-eng":0.4302553811,"data-quality":0.065226588,"ml-security":0.1654414418}}
{"text":"Inspired by the burgeoning interest in utilizing foundational models to address downstream tasks, this paper adopts an innovative idea that 1) recasting adversarial attack as a downstream task.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.064728647,"dev-research":0.4454617635,"prompt-eng":0.4976572323,"data-quality":0.1744715404,"ml-security":0.7455493879}}
{"text":"Specifically, image noise generation to meet the emerging trend and 2) introducing foundational models as surrogate models.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.1217729966,"dev-research":0.3657115577,"prompt-eng":0.4869198837,"data-quality":0.1656359692,"ml-security":0.1365321041}}
{"text":"Harnessing the concept of non-robust features, we elaborate on two guiding principles for surrogate model selection to explain why the foundational model is an optimal choice for this role.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0608933511,"dev-research":0.3651160961,"prompt-eng":0.4403706758,"data-quality":0.1111110994,"ml-security":0.2538557442}}
{"text":"However, paradoxically, we observe that these foundational models underperform.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0632507631,"dev-research":0.3889109137,"prompt-eng":0.4543542655,"data-quality":0.1497927154,"ml-security":0.1664954805}}
{"text":"Analyzing this unexpected behavior within the feature space, we attribute the lackluster performance of foundational models (e.g., CLIP) to their significant representational capacity and, conversely, their lack of discriminative prowess.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0607971514,"dev-research":0.3964006579,"prompt-eng":0.4845923081,"data-quality":0.1809454582,"ml-security":0.207321141}}
{"text":"To mitigate this issue, we propose the use of a margin-based loss strategy for the fine-tuning of foundational models on target images.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0953851736,"dev-research":0.3718081126,"prompt-eng":0.4830003369,"data-quality":0.1412950609,"ml-security":0.1432327388}}
{"text":"The experimental results verify that our approach, which employs the basic Fast Gradient Sign Method (FGSM) attack algorithm, outstrips the performance of other, more convoluted algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0459961273,"dev-research":0.3914983399,"prompt-eng":0.4159062224,"data-quality":0.1194364492,"ml-security":0.6296011583}}
{"text":"We conclude by advocating for the research community to consider surrogate models as crucial determinants in the effectiveness of adversarial attacks in no-box settings.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0731456887,"dev-research":0.4063247305,"prompt-eng":0.4536467044,"data-quality":0.1786406595,"ml-security":0.7605669404}}
{"text":"The implications of our work bear relevance for improving the efficacy of such adversarial attacks and the overall robustness of AI systems.","meta":{"url":"http://arxiv.org/abs/2307.06608v1"},"cats":{"new-dataset":0.0524762832,"dev-research":0.4477019373,"prompt-eng":0.4440488525,"data-quality":0.2945211203,"ml-security":0.7199631158}}
{"text":"Pre-transformation with an upper-triangular matrix (including cyclic redundancy check (CRC), parity-check (PC) and polarization-adjusted convolutional (PAC) codes) improves the weight spectrum of Reed-Muller (RM) codes and polar codes significantly.","meta":{"url":"http://arxiv.org/abs/2307.06599v1"},"cats":{"new-dataset":0.0749737345,"dev-research":0.4109079906,"prompt-eng":0.4426622215,"data-quality":0.1231075448,"ml-security":0.0877451056}}
{"text":"However, a theoretical analysis to quantify the improvement is missing.","meta":{"url":"http://arxiv.org/abs/2307.06599v1"},"cats":{"new-dataset":0.0366468141,"dev-research":0.4482058501,"prompt-eng":0.3469835846,"data-quality":0.1917225618,"ml-security":0.0542920709}}
{"text":"In this paper, we provide asymptotic analysis on the number of low-weight codewords of the original and pre-transformed RM codes respectively, and prove that pre-transformation significantly reduces low-weight codewords, even in the order sense.","meta":{"url":"http://arxiv.org/abs/2307.06599v1"},"cats":{"new-dataset":0.0854540966,"dev-research":0.4761177877,"prompt-eng":0.4007590404,"data-quality":0.2443207197,"ml-security":0.1570470099}}
{"text":"For polar codes, we prove that the average number of minimum-weight codewords does not increase after pre-transformation.","meta":{"url":"http://arxiv.org/abs/2307.06599v1"},"cats":{"new-dataset":0.0721315084,"dev-research":0.4597363233,"prompt-eng":0.411131629,"data-quality":0.2034214281,"ml-security":0.1358277491}}
{"text":"Both results confirm the advantages of pre-transformation.","meta":{"url":"http://arxiv.org/abs/2307.06599v1"},"cats":{"new-dataset":0.05732451,"dev-research":0.4531661629,"prompt-eng":0.4134799742,"data-quality":0.0805143288,"ml-security":0.0709744492}}
{"text":"Which integer sequences are sequences of generalized weights of a linear code?","meta":{"url":"http://arxiv.org/abs/2307.06595v1"},"cats":{"new-dataset":0.1463011614,"dev-research":0.4121742553,"prompt-eng":0.3824560356,"data-quality":0.120307337,"ml-security":0.1741254078}}
{"text":"In this paper, we answer this question for linear block codes, rank-metric codes, and more generally for sum-rank metric codes.","meta":{"url":"http://arxiv.org/abs/2307.06595v1"},"cats":{"new-dataset":0.148420823,"dev-research":0.462774902,"prompt-eng":0.3886036267,"data-quality":0.1780140084,"ml-security":0.1088836944}}
{"text":"We do so under an existence assumption for MDS and MSRD codes.","meta":{"url":"http://arxiv.org/abs/2307.06595v1"},"cats":{"new-dataset":0.0608038182,"dev-research":0.4503303763,"prompt-eng":0.4346656542,"data-quality":0.1449171088,"ml-security":0.2338299094}}
{"text":"We also prove that the same integer sequences appear as sequences of greedy weights of linear block codes, rank-metric codes, and sum-rank metric codes.","meta":{"url":"http://arxiv.org/abs/2307.06595v1"},"cats":{"new-dataset":0.1735931201,"dev-research":0.4535033283,"prompt-eng":0.3817523741,"data-quality":0.1531101537,"ml-security":0.1636895811}}
{"text":"Finally, we characterize the integer sequences which appear as sequences of relative generalized weights (respectively, relative greedy weights) of linear block codes.","meta":{"url":"http://arxiv.org/abs/2307.06595v1"},"cats":{"new-dataset":0.1378792191,"dev-research":0.4263898998,"prompt-eng":0.3871220053,"data-quality":0.1358052296,"ml-security":0.1856082139}}
{"text":"In this paper, we consider algorithms for edge-coloring multigraphs $G$ of bounded maximum degree, i.e., $\\Delta(G) = O(1)$. Shannon's theorem states that any multigraph of maximum degree $\\Delta$ can be properly edge-colored with $\\lfloor 3\\Delta/2\\rfloor$ colors.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1734677287,"dev-research":0.3996004979,"prompt-eng":0.3144138692,"data-quality":0.1208165613,"ml-security":0.1020128971}}
{"text":"Our main results include algorithms for computing such colorings.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1828459921,"dev-research":0.4279347974,"prompt-eng":0.3633871499,"data-quality":0.1251920764,"ml-security":0.0887050849}}
{"text":"We design deterministic and randomized sequential algorithms with running time $O(n\\log n)$ and $O(n)$, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1110744261,"dev-research":0.3816029804,"prompt-eng":0.3801879017,"data-quality":0.0815205387,"ml-security":0.2190710115}}
{"text":"This is the first improvement since the $O(n^2)$ algorithm in Shannon's original paper, and our randomized algorithm is optimal up to constant factors.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.0768274177,"dev-research":0.377592349,"prompt-eng":0.3616504435,"data-quality":0.16442478,"ml-security":0.1299718103}}
{"text":"We also develop distributed algorithms in the $\\mathsf{LOCAL}$ model of computation.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.0666067358,"dev-research":0.4407461693,"prompt-eng":0.3945677722,"data-quality":0.1196470909,"ml-security":0.2330314506}}
{"text":"Namely, we design deterministic and randomized $\\mathsf{LOCAL}$ algorithms with running time $\\tilde O(\\log^5 n)$ and $O(\\log^2n)$, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.0654774371,"dev-research":0.4122275374,"prompt-eng":0.356102534,"data-quality":0.0952004989,"ml-security":0.2823533798}}
{"text":"The deterministic sequential algorithm is a simplified extension of earlier work of Gabow et al. in edge-coloring simple graphs.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1289933123,"dev-research":0.4256989758,"prompt-eng":0.3616660546,"data-quality":0.1267226957,"ml-security":0.1608599015}}
{"text":"The other algorithms apply the entropy compression method in a similar way to recent work by the author and Bernshteyn, where the authors design algorithms for Vizing's theorem for simple graphs.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1068225822,"dev-research":0.4208240188,"prompt-eng":0.3455578122,"data-quality":0.1491810844,"ml-security":0.1099832781}}
{"text":"We also extend their results to Vizing's theorem for multigraphs.","meta":{"url":"http://arxiv.org/abs/2307.06579v1"},"cats":{"new-dataset":0.1446656532,"dev-research":0.4300618382,"prompt-eng":0.3831063411,"data-quality":0.1581584372,"ml-security":0.076268904}}
{"text":"Retinal vessel segmentation is generally grounded in image-based datasets collected with bench-top devices.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.2119841598,"dev-research":0.35061401,"prompt-eng":0.3898385613,"data-quality":0.1391518555,"ml-security":0.0915138859}}
{"text":"The static images naturally lose the dynamic characteristics of retina fluctuation, resulting in diminished dataset richness, and the usage of bench-top devices further restricts dataset scalability due to its limited accessibility.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.2515830923,"dev-research":0.3719369352,"prompt-eng":0.3751902765,"data-quality":0.1243672059,"ml-security":0.1668150981}}
{"text":"Considering these limitations, we introduce the first video-based retinal dataset by employing handheld devices for data acquisition.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.5310009363,"dev-research":0.3605257231,"prompt-eng":0.3959215865,"data-quality":0.090687106,"ml-security":0.0728476603}}
{"text":"The dataset comprises 635 smartphone-based fundus videos collected from four different clinics, involving 415 patients from 50 to 75 years old.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.6738187115,"dev-research":0.3620632017,"prompt-eng":0.4414524915,"data-quality":0.1063405044,"ml-security":0.1306933321}}
{"text":"It delivers comprehensive and precise annotations of retinal structures in both spatial and temporal dimensions, aiming to advance the landscape of vasculature segmentation.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.1587004641,"dev-research":0.3712681,"prompt-eng":0.3996789205,"data-quality":0.1432550529,"ml-security":0.0619711231}}
{"text":"Specifically, the dataset provides three levels of spatial annotations: binary vessel masks for overall retinal structure delineation, general vein-artery masks for distinguishing the vein and artery, and fine-grained vein-artery masks for further characterizing the granularities of each artery and vein.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.4438208206,"dev-research":0.3937621049,"prompt-eng":0.4081954216,"data-quality":0.207602553,"ml-security":0.1229491163}}
{"text":"In addition, the dataset offers temporal annotations that capture the vessel pulsation characteristics, assisting in detecting ocular diseases that require fine-grained recognition of hemodynamic fluctuation.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.3789323655,"dev-research":0.3829733752,"prompt-eng":0.4311356985,"data-quality":0.2222007086,"ml-security":0.0968185285}}
{"text":"In application, our dataset exhibits a significant domain shift with respect to data captured by bench-top devices, thus posing great challenges to existing methods.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.3805132354,"dev-research":0.3792525488,"prompt-eng":0.4360706512,"data-quality":0.1286098022,"ml-security":0.1718179544}}
{"text":"In the experiments, we provide evaluation metrics and benchmark results on our dataset, reflecting both the potential and challenges it offers for vessel segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.2417612089,"dev-research":0.3284781358,"prompt-eng":0.3910810029,"data-quality":0.1409883324,"ml-security":0.0707219055}}
{"text":"We hope this challenging dataset would significantly contribute to the development of eye disease diagnosis and early prevention.","meta":{"url":"http://arxiv.org/abs/2307.06577v1"},"cats":{"new-dataset":0.6125730096,"dev-research":0.4147880074,"prompt-eng":0.4494825681,"data-quality":0.1221951544,"ml-security":0.1699200398}}
{"text":"Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.0959579716,"dev-research":0.4072498458,"prompt-eng":0.4727198949,"data-quality":0.1428177833,"ml-security":0.198278166}}
{"text":"Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.2387123925,"dev-research":0.4363469921,"prompt-eng":0.4624765213,"data-quality":0.2342387912,"ml-security":0.0774661936}}
{"text":"However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.0497829398,"dev-research":0.485050032,"prompt-eng":0.3845570541,"data-quality":0.2270234536,"ml-security":0.2106471608}}
{"text":"To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.1855876609,"dev-research":0.4169140856,"prompt-eng":0.4842767065,"data-quality":0.1555454892,"ml-security":0.1307778039}}
{"text":"We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.3081275826,"dev-research":0.3991395996,"prompt-eng":0.4577866032,"data-quality":0.217445712,"ml-security":0.1249571711}}
{"text":"Similarly, we extend this approach to a Global Candidate News Encoder, utilizing a global entity graph and a candidate news aggregator to enhance candidate news representation.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.2377465767,"dev-research":0.4125362749,"prompt-eng":0.4854243698,"data-quality":0.1990783605,"ml-security":0.1104152096}}
{"text":"Evaluation results on two public news datasets demonstrate that our method outperforms existing approaches.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.3572976205,"dev-research":0.4112459398,"prompt-eng":0.4828965442,"data-quality":0.2830028535,"ml-security":0.1516557245}}
{"text":"Furthermore, our model offers more diverse recommendations.","meta":{"url":"http://arxiv.org/abs/2307.06576v1"},"cats":{"new-dataset":0.1609615268,"dev-research":0.4303895515,"prompt-eng":0.4551698029,"data-quality":0.0776192334,"ml-security":0.1135511191}}
{"text":"Aiming at designing plausible decoders with channel information free, low complexity, high throughput, and approaching maximum likelihood performance, we put forward a streamlined architecture which concatenates sequentially three components.","meta":{"url":"http://arxiv.org/abs/2307.06575v1"},"cats":{"new-dataset":0.1129673698,"dev-research":0.3952238863,"prompt-eng":0.491419044,"data-quality":0.1037849094,"ml-security":0.1816334118}}
{"text":"Specifically, to tackle the decoding failures of normalized min-sum, the whole decoding trajectory, not limited to the last iteration information conventionally, is fed into a trained convolutional neural network to yield new reliability metric for each sequence bit, termed decoding information aggregation.","meta":{"url":"http://arxiv.org/abs/2307.06575v1"},"cats":{"new-dataset":0.0986375663,"dev-research":0.3703300944,"prompt-eng":0.4406561338,"data-quality":0.3110823201,"ml-security":0.1904008236}}
{"text":"Then an adapted order statistics decoding, following the suggested decoding path, is adopted to process the sequence ordered with new metric more efficiently in that many invalid searches contained in conventional methods otherwise are evaded.","meta":{"url":"http://arxiv.org/abs/2307.06575v1"},"cats":{"new-dataset":0.1024448798,"dev-research":0.4109206276,"prompt-eng":0.4426204233,"data-quality":0.1851228423,"ml-security":0.1166942189}}
{"text":"The role of decoding information aggregation is elaborated via statistics data to reveal that it can arrange more error-prone bits into the fore part of most reliable basis of order statistics decoding, which is vital for the effective decoding enhancement.","meta":{"url":"http://arxiv.org/abs/2307.06575v1"},"cats":{"new-dataset":0.132366903,"dev-research":0.4324171383,"prompt-eng":0.4767322937,"data-quality":0.3027269265,"ml-security":0.1827322433}}
{"text":"We argue the superposition of improved bitwise reliability of the most reliable basis and the imposed rigorous code structure by OSD enables the proposed architecture being a competitive rival of the state of the art decoders, which was verified in extensive simulation in terms of performance, complexity and latency for short and moderate LDPC codes.","meta":{"url":"http://arxiv.org/abs/2307.06575v1"},"cats":{"new-dataset":0.0716996271,"dev-research":0.4215308688,"prompt-eng":0.3986830881,"data-quality":0.1549464422,"ml-security":0.1544477023}}
{"text":"Online polarization research currently focuses on studying single-issue opinion distributions or computing distance metrics of interaction network structures.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.105010117,"dev-research":0.4327290759,"prompt-eng":0.4307919941,"data-quality":0.132405556,"ml-security":0.0795029405}}
{"text":"Limited data availability often restricts studies to positive interaction data, which can misrepresent the reality of a discussion.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.1982683605,"dev-research":0.4164801911,"prompt-eng":0.4263433441,"data-quality":0.1989566703,"ml-security":0.1893628619}}
{"text":"We introduce a novel framework that aims at combining these three aspects, content and interactions, as well as their nature (positive or negative), while challenging the prevailing notion of polarization as an umbrella term for all forms of online conflict or opposing opinions.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.0998702479,"dev-research":0.4421198306,"prompt-eng":0.4040479893,"data-quality":0.1693902659,"ml-security":0.15246642}}
{"text":"In our approach, built on the concepts of cleavage structures and structural balance of signed social networks, we factorize polarization into two distinct metrics: Antagonism and Alignment.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.0792200285,"dev-research":0.417191616,"prompt-eng":0.3957370233,"data-quality":0.1505945201,"ml-security":0.1641246902}}
{"text":"Antagonism quantifies hostility in online discussions, based on the reactions of users to content.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.0953430968,"dev-research":0.4554410019,"prompt-eng":0.4477862854,"data-quality":0.2048097695,"ml-security":0.2179687532}}
{"text":"Alignment uses signed structural information encoded in long-term user-user relations on the platform to describe how well user interactions fit the global and/or traditional sides of discussion.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.1571581461,"dev-research":0.4739167052,"prompt-eng":0.4830461942,"data-quality":0.1598026734,"ml-security":0.069953607}}
{"text":"We can analyse the change of these metrics through time, localizing both relevant trends but also sudden changes that can be mapped to specific contexts or events.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.228212223,"dev-research":0.4247679704,"prompt-eng":0.4445410873,"data-quality":0.1430421111,"ml-security":0.0682434833}}
{"text":"We apply our methods to two distinct platforms: Birdwatch, a US crowd-based fact-checking extension of Twitter, and DerStandard, an Austrian online newspaper with discussion forums.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.3357849333,"dev-research":0.4392194881,"prompt-eng":0.4865709938,"data-quality":0.2113757764,"ml-security":0.145576719}}
{"text":"In these two use cases, we find that our framework is capable of describing the global status of the groups of users (identification of cleavages) while also providing relevant findings on specific issues or in specific time frames.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.1982962641,"dev-research":0.4765546817,"prompt-eng":0.4659564499,"data-quality":0.24552383,"ml-security":0.2916684514}}
{"text":"Furthermore, we show that our four metrics describe distinct phenomena, emphasizing their independent consideration for unpacking polarization complexities.","meta":{"url":"http://arxiv.org/abs/2307.06571v1"},"cats":{"new-dataset":0.0585956586,"dev-research":0.4027496001,"prompt-eng":0.4013039831,"data-quality":0.1483767047,"ml-security":0.0753844932}}
{"text":"In this technical report, we present our findings from a study conducted on the EPIC-KITCHENS-100 Unsupervised Domain Adaptation task for Action Recognition.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.155306475,"dev-research":0.3963456648,"prompt-eng":0.5057085829,"data-quality":0.1575200883,"ml-security":0.0798624557}}
{"text":"Our research focuses on the innovative application of a differentiable logic loss in the training to leverage the co-occurrence relations between verb and noun, as well as the pre-trained Large Language Models (LLMs) to generate the logic rules for the adaptation to unseen action labels.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.1319696477,"dev-research":0.4500714641,"prompt-eng":0.559782268,"data-quality":0.363484206,"ml-security":0.1530752032}}
{"text":"Specifically, the model's predictions are treated as the truth assignment of a co-occurrence logic formula to compute the logic loss, which measures the consistency between the predictions and the logic constraints.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.0975425763,"dev-research":0.448252164,"prompt-eng":0.4870358215,"data-quality":0.2268743515,"ml-security":0.1104131596}}
{"text":"By using the verb-noun co-occurrence matrix generated from the dataset, we observe a moderate improvement in model performance compared to our baseline framework.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.2568171308,"dev-research":0.4425792397,"prompt-eng":0.483252533,"data-quality":0.2065683799,"ml-security":0.0693459395}}
{"text":"To further enhance the model's adaptability to novel action labels, we experiment with rules generated using GPT-3.5, which leads to a slight decrease in performance.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.1282568437,"dev-research":0.4084593417,"prompt-eng":0.4833116857,"data-quality":0.2416206017,"ml-security":0.0855563993}}
{"text":"These findings shed light on the potential and challenges of incorporating differentiable logic and LLMs for knowledge extraction in unsupervised domain adaptation for action recognition.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.1845769017,"dev-research":0.3994032453,"prompt-eng":0.5168936374,"data-quality":0.1495924617,"ml-security":0.0970261356}}
{"text":"Our final submission (entitled `NS-LLM') achieved the first place in terms of top-1 action recognition accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06569v1"},"cats":{"new-dataset":0.1711208455,"dev-research":0.402883939,"prompt-eng":0.5100565432,"data-quality":0.2006435926,"ml-security":0.0707902086}}
{"text":"Ship orientation angle prediction (SOAP) with optical remote sensing images is an important image processing task, which often relies on deep convolutional neural networks (CNNs) to make accurate predictions.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.2318503638,"dev-research":0.3894339552,"prompt-eng":0.4360330424,"data-quality":0.1529660615,"ml-security":0.1121275514}}
{"text":"This paper proposes a novel framework to reduce the model sizes and computational costs of SOAP models without harming prediction accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.0940203564,"dev-research":0.4377745703,"prompt-eng":0.4206058128,"data-quality":0.1359721999,"ml-security":0.3487677559}}
{"text":"First, a new SOAP model called Mobile-SOAP is designed based on MobileNetV2, achieving state-of-the-art prediction accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.1576278269,"dev-research":0.4511671833,"prompt-eng":0.450847585,"data-quality":0.1230745459,"ml-security":0.2368169063}}
{"text":"Four tiny SOAP models are also created by replacing the convolutional blocks in Mobile-SOAP with four small-scale networks, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.0657195989,"dev-research":0.4325181802,"prompt-eng":0.4060145442,"data-quality":0.1025916476,"ml-security":0.1717181822}}
{"text":"Then, to transfer knowledge from Mobile-SOAP to four lightweight models, we propose a novel knowledge distillation (KD) framework termed SOAP-KD consisting of a novel feature-based guidance loss and an optimized synthetic samples-based knowledge transfer mechanism.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.1153110704,"dev-research":0.4514488034,"prompt-eng":0.5041725594,"data-quality":0.1289201137,"ml-security":0.2232885406}}
{"text":"Lastly, extensive experiments on the FGSC-23 dataset confirm the superiority of Mobile-SOAP over existing models and also demonstrate the effectiveness of SOAP-KD in improving the prediction performance of four specially designed tiny models.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.1269291919,"dev-research":0.4150447433,"prompt-eng":0.4672674729,"data-quality":0.1128695069,"ml-security":0.2508911726}}
{"text":"Notably, by using SOAP-KD, the test mean absolute error of the ShuffleNetV2x1.0-based model is only 8% higher than that of Mobile-SOAP, but its number of parameters and multiply-accumulate operations (MACs) are respectively 61.6% and 60.8% less.","meta":{"url":"http://arxiv.org/abs/2307.06566v1"},"cats":{"new-dataset":0.10703242,"dev-research":0.4300488986,"prompt-eng":0.4143571584,"data-quality":0.184267716,"ml-security":0.1656230459}}
{"text":"Deep learning has been widely used in many fields, but the model training process usually consumes massive computational resources and time.","meta":{"url":"http://arxiv.org/abs/2307.06565v1"},"cats":{"new-dataset":0.0958773702,"dev-research":0.366160624,"prompt-eng":0.405707565,"data-quality":0.0579305856,"ml-security":0.2091246278}}
{"text":"Therefore, designing an efficient neural network training method with a provable convergence guarantee is a fundamental and important research question.","meta":{"url":"http://arxiv.org/abs/2307.06565v1"},"cats":{"new-dataset":0.0402904497,"dev-research":0.3662282997,"prompt-eng":0.3697814116,"data-quality":0.149736294,"ml-security":0.2486653483}}
{"text":"In this paper, we present a static half-space report data structure that consists of a fully connected two-layer neural network for shifted ReLU activation to enable activated neuron identification in sublinear time via geometric search.","meta":{"url":"http://arxiv.org/abs/2307.06565v1"},"cats":{"new-dataset":0.0772604657,"dev-research":0.3561314843,"prompt-eng":0.4038737169,"data-quality":0.147033247,"ml-security":0.1637642686}}
{"text":"We also prove that our algorithm can converge in $O(M^2/\\epsilon^2)$ time with network size quadratic in the coefficient norm upper bound $M$ and error term $\\epsilon$.","meta":{"url":"http://arxiv.org/abs/2307.06565v1"},"cats":{"new-dataset":0.0677976925,"dev-research":0.3776225072,"prompt-eng":0.3393842898,"data-quality":0.160849709,"ml-security":0.2323264644}}
{"text":"Prescriptive process monitoring methods seek to optimize the performance of business processes by triggering interventions at runtime, thereby increasing the probability of positive case outcomes.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0465562482,"dev-research":0.4688109125,"prompt-eng":0.4776726433,"data-quality":0.074896231,"ml-security":0.0918340114}}
{"text":"These interventions are triggered according to an intervention policy.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0589257591,"dev-research":0.46344149,"prompt-eng":0.4602817875,"data-quality":0.1458372415,"ml-security":0.1780993311}}
{"text":"Reinforcement learning has been put forward as an approach to learning intervention policies through trial and error.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0706191844,"dev-research":0.4194839718,"prompt-eng":0.4690714131,"data-quality":0.1500850299,"ml-security":0.1562257795}}
{"text":"Existing approaches in this space assume that the number of resources available to perform interventions in a process is unlimited, an unrealistic assumption in practice.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0895619187,"dev-research":0.43504103,"prompt-eng":0.3509933109,"data-quality":0.0476583985,"ml-security":0.1666764176}}
{"text":"This paper argues that, in the presence of resource constraints, a key dilemma in the field of prescriptive process monitoring is to trigger interventions based not only on predictions of their necessity, timeliness, or effect but also on the uncertainty of these predictions and the level of resource utilization.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0677996382,"dev-research":0.4540133876,"prompt-eng":0.4635723848,"data-quality":0.0786680058,"ml-security":0.1118068018}}
{"text":"Indeed, committing scarce resources to an intervention when the necessity or effects of this intervention are highly uncertain may intuitively lead to suboptimal intervention effects.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0205654933,"dev-research":0.4592279145,"prompt-eng":0.3822215384,"data-quality":0.1102206156,"ml-security":0.1478971363}}
{"text":"Accordingly, the paper proposes a reinforcement learning approach for prescriptive process monitoring that leverages conformal prediction techniques to consider the uncertainty of the predictions upon which an intervention decision is based.","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.0633198378,"dev-research":0.4221717007,"prompt-eng":0.5240012316,"data-quality":0.1093356529,"ml-security":0.1574222806}}
{"text":"An evaluation using real-life datasets demonstrates that explicitly modeling uncertainty using conformal predictions helps reinforcement learning agents converge towards policies with higher net intervention gain","meta":{"url":"http://arxiv.org/abs/2307.06564v1"},"cats":{"new-dataset":0.1055776968,"dev-research":0.3957802907,"prompt-eng":0.4663732669,"data-quality":0.1182527857,"ml-security":0.1955458873}}
{"text":"Money is more than just a numeric value.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.1509216414,"dev-research":0.4381475199,"prompt-eng":0.3709307881,"data-quality":0.1402926951,"ml-security":0.1610670648}}
{"text":"It embodies trust and moral gravity, and it offers flexible ways to transact.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.0719859139,"dev-research":0.4718208656,"prompt-eng":0.387334076,"data-quality":0.0706160027,"ml-security":0.1564554247}}
{"text":"However, the emergence of Central Bank Digital Currency (CBDC) is set to bring about a drastic change in the future of money.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.1334224613,"dev-research":0.4547192569,"prompt-eng":0.4083956609,"data-quality":0.1113701012,"ml-security":0.2056981805}}
{"text":"This paper invites designers to reflect on their role in shaping material and immaterial monetary change.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.0683130822,"dev-research":0.4779418187,"prompt-eng":0.4082208203,"data-quality":0.0882011753,"ml-security":0.0842179898}}
{"text":"In this rapidly changing landscape, design could be instrumental in uncovering and showcasing the diverse values that money holds for different stakeholders.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.1487866665,"dev-research":0.4755844103,"prompt-eng":0.3968133611,"data-quality":0.0752257356,"ml-security":0.1303613078}}
{"text":"Understanding these diversities could promote a more equitable and inclusive financial, social, and global landscape within emergent forms of cash-like digital currency.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.1556409158,"dev-research":0.421039936,"prompt-eng":0.3738115738,"data-quality":0.0971766803,"ml-security":0.1263193985}}
{"text":"Without such consideration, certain forms of money we have come to know could disappear, along with the values people hold upon them.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.106603401,"dev-research":0.4064339732,"prompt-eng":0.3711791407,"data-quality":0.1702962903,"ml-security":0.2562493782}}
{"text":"We report on semi-structured interviews with stakeholders who have current knowledge or involvement in the emerging field of Central Bank Digital Currency (CBDC).","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.2637275063,"dev-research":0.460126383,"prompt-eng":0.4541011266,"data-quality":0.1416717405,"ml-security":0.1356203509}}
{"text":"Our research indicates that this new form of money presents both challenges and opportunities for designers.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.0818677081,"dev-research":0.4787933091,"prompt-eng":0.3797208553,"data-quality":0.07663919,"ml-security":0.1285172254}}
{"text":"Specifically, we emphasise the potential for Central Bank Digital Currency (CBDC) to either positively or negatively reform values through its design.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.0565067205,"dev-research":0.4569844223,"prompt-eng":0.4072868041,"data-quality":0.1503486092,"ml-security":0.1570099919}}
{"text":"By considering time, reflecting present values, and promoting inclusion in its deployment, we can strive to ensure that Central Bank Digital Currency (CBDC) represents the diverse needs and perspectives of its users.","meta":{"url":"http://arxiv.org/abs/2307.06563v1"},"cats":{"new-dataset":0.1428699528,"dev-research":0.4460820978,"prompt-eng":0.4355332613,"data-quality":0.1304554341,"ml-security":0.1340987422}}
{"text":"Normalization of objectives plays a crucial role in evolutionary multi-objective optimization (EMO) to handle objective functions with different scales, which can be found in real-world problems.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0412457857,"dev-research":0.3820858487,"prompt-eng":0.3859988859,"data-quality":0.0610255988,"ml-security":0.1565084491}}
{"text":"Although the effect of normalization methods on the performance of EMO algorithms has been investigated in the literature, that of preference-based EMO (PBEMO) algorithms is poorly understood.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0362817455,"dev-research":0.3761679551,"prompt-eng":0.4510243451,"data-quality":0.1168143184,"ml-security":0.1446142069}}
{"text":"Since PBEMO aims to approximate a region of interest, its population generally does not cover the Pareto front in the objective space.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0580974749,"dev-research":0.4081546249,"prompt-eng":0.4026653818,"data-quality":0.1054507998,"ml-security":0.1406425057}}
{"text":"This property may make normalization of objectives in PBEMO difficult.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0254075545,"dev-research":0.4326435362,"prompt-eng":0.4510837325,"data-quality":0.1453209585,"ml-security":0.1414062086}}
{"text":"This paper investigates the effectiveness of three normalization methods in three representative PBEMO algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0353870083,"dev-research":0.3588210184,"prompt-eng":0.3807140517,"data-quality":0.1338443507,"ml-security":0.1010155222}}
{"text":"We present a bounded archive-based method for approximating the nadir point.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.136804911,"dev-research":0.3789648888,"prompt-eng":0.3413075343,"data-quality":0.0929404644,"ml-security":0.0618465305}}
{"text":"First, we demonstrate that the normalization methods in PBEMO perform significantly worse than that in conventional EMO in terms of approximating the ideal point, nadir point, and range of the PF.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0357522349,"dev-research":0.3563347404,"prompt-eng":0.4304695329,"data-quality":0.1103922076,"ml-security":0.0913031868}}
{"text":"Then, we show that PBEMO requires normalization of objectives on problems with differently scaled objectives.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.0244447302,"dev-research":0.4295976807,"prompt-eng":0.4263575803,"data-quality":0.1382188294,"ml-security":0.1425452109}}
{"text":"Our results show that there is no clear \"best normalization method\" in PBEMO, but an external archive-based method performs relatively well.","meta":{"url":"http://arxiv.org/abs/2307.06562v1"},"cats":{"new-dataset":0.140133538,"dev-research":0.3898413633,"prompt-eng":0.4338600552,"data-quality":0.2021497291,"ml-security":0.090250255}}
{"text":"Federated learning is a distributed machine learning approach where local weight parameters trained by clients locally are aggregated as global parameters by a server.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.1291879369,"dev-research":0.3841640866,"prompt-eng":0.4604831654,"data-quality":0.1416098134,"ml-security":0.3246613833}}
{"text":"The global parameters can be trained without uploading privacy-sensitive raw data owned by clients to the server.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.1761899769,"dev-research":0.4207865037,"prompt-eng":0.4722889983,"data-quality":0.0995063812,"ml-security":0.4275776852}}
{"text":"The aggregation on the server is simply done by averaging the local weight parameters, so it is an I/O intensive task where a network processing accounts for a large portion compared to the computation.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.0508391491,"dev-research":0.4003645291,"prompt-eng":0.3870656466,"data-quality":0.0633220368,"ml-security":0.0913909378}}
{"text":"The network processing workload further increases as the number of clients increases.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.0674444368,"dev-research":0.4745698209,"prompt-eng":0.3714274576,"data-quality":0.0613110467,"ml-security":0.1525497277}}
{"text":"To mitigate the network processing workload, in this paper, the federated learning server is offloaded to NVIDIA BlueField-2 DPU which is a smart NIC (Network Interface Card) that has eight processing cores.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.1572692298,"dev-research":0.3859632203,"prompt-eng":0.3805072475,"data-quality":0.091873581,"ml-security":0.2320911401}}
{"text":"Dedicated processing cores are assigned by DPDK (Data Plane Development Kit) for receiving the local weight parameters and sending the global parameters.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.1104084116,"dev-research":0.4168353723,"prompt-eng":0.4249493509,"data-quality":0.069038997,"ml-security":0.0943385131}}
{"text":"The aggregation task is parallelized by exploiting multiple cores available on the DPU.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.0624420095,"dev-research":0.4070114465,"prompt-eng":0.408801628,"data-quality":0.0593748546,"ml-security":0.0933568144}}
{"text":"To further improve the performance, an approximated design that eliminates an exclusive access control between the computation threads is also implemented.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.0402782322,"dev-research":0.438499552,"prompt-eng":0.355201096,"data-quality":0.0579267755,"ml-security":0.1777698563}}
{"text":"Evaluation results show that the federated learning server on the DPU accelerates the execution time by 1.32 times compared with that on the host CPU with a negligible accuracy loss.","meta":{"url":"http://arxiv.org/abs/2307.06561v1"},"cats":{"new-dataset":0.0859348011,"dev-research":0.4170761135,"prompt-eng":0.4463913469,"data-quality":0.1070753184,"ml-security":0.2558376857}}
{"text":"This paper explores the expressive power of deep neural networks for a diverse range of activation functions.","meta":{"url":"http://arxiv.org/abs/2307.06555v1"},"cats":{"new-dataset":0.0881489475,"dev-research":0.389362119,"prompt-eng":0.4198294383,"data-quality":0.1216736484,"ml-security":0.2969354107}}
{"text":"An activation function set $\\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\\mathtt{ReLU}$, $\\mathtt{LeakyReLU}$, $\\mathtt{ReLU}^2$, $\\mathtt{ELU}$, $\\mathtt{SELU}$, $\\mathtt{Softplus}$, $\\mathtt{GELU}$, $\\mathtt{SiLU}$, $\\mathtt{Swish}$, $\\mathtt{Mish}$, $\\mathtt{Sigmoid}$, $\\mathtt{Tanh}$, $\\mathtt{Arctan}$, $\\mathtt{Softsign}$, $\\mathtt{dSiLU}$, and $\\mathtt{SRS}$. We demonstrate that for any activation function $\\varrho\\in \\mathscr{A}$, a $\\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set.","meta":{"url":"http://arxiv.org/abs/2307.06555v1"},"cats":{"new-dataset":0.0267174734,"dev-research":0.410562533,"prompt-eng":0.3941352317,"data-quality":0.1601807114,"ml-security":0.2240961097}}
{"text":"This finding enables the extension of most approximation results achieved with $\\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.","meta":{"url":"http://arxiv.org/abs/2307.06555v1"},"cats":{"new-dataset":0.0408803001,"dev-research":0.3858818315,"prompt-eng":0.3685518954,"data-quality":0.1240513176,"ml-security":0.2462316235}}
{"text":"Polynomials defined on specific rings are heavily involved in various cryptographic schemes, and the corresponding operations are usually the computation bottleneck of the whole scheme.   ","meta":{"url":"http://arxiv.org/abs/2307.06554v1"},"cats":{"new-dataset":0.0387260165,"dev-research":0.4320122147,"prompt-eng":0.3461161905,"data-quality":0.0551745259,"ml-security":0.1793315088}}
{"text":"We propose to utilize TPU, an emerging hardware designed for AI applications, to speed up polynomial operations and convert TPU to a cryptographic accelerator.   ","meta":{"url":"http://arxiv.org/abs/2307.06554v1"},"cats":{"new-dataset":0.0972077833,"dev-research":0.3826725219,"prompt-eng":0.414617199,"data-quality":0.061149681,"ml-security":0.2530404075}}
{"text":"We also conduct preliminary evaluation and discuss the limitations of current work and future plan.","meta":{"url":"http://arxiv.org/abs/2307.06554v1"},"cats":{"new-dataset":0.1455204688,"dev-research":0.4597173527,"prompt-eng":0.4380417652,"data-quality":0.0517865654,"ml-security":0.0604796903}}
{"text":"Insights are often considered the ideal outcome of visual analysis sessions.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1386248135,"dev-research":0.4474530161,"prompt-eng":0.4124696705,"data-quality":0.1151893539,"ml-security":0.0687239887}}
{"text":"However, there is no single definition of what an insight is.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.0936169598,"dev-research":0.4288999556,"prompt-eng":0.3454718501,"data-quality":0.0957429932,"ml-security":0.0745608584}}
{"text":"Some scholars define insights as correlations, while others define them as hypotheses or aha moments.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1293678949,"dev-research":0.4347717276,"prompt-eng":0.3839615155,"data-quality":0.1135981228,"ml-security":0.0518042055}}
{"text":"This lack of a clear definition can make it difficult to build visualization tools that effectively support insight discovery.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1835365304,"dev-research":0.5047977684,"prompt-eng":0.4285098661,"data-quality":0.1629331429,"ml-security":0.0850103863}}
{"text":"In this paper, we contribute a comprehensive literature review that maps the landscape of existing insight definitions.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1069318463,"dev-research":0.4936972441,"prompt-eng":0.4120315473,"data-quality":0.1055042635,"ml-security":0.0643296126}}
{"text":"We summarize key themes regarding how insight is defined, with the goal of helping readers identify which definitions of insight align closely with their research and tool development goals.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1156195769,"dev-research":0.5272053157,"prompt-eng":0.4290847411,"data-quality":0.0881883565,"ml-security":0.0706761037}}
{"text":"Based on our review, we also suggest interesting research directions, such as synthesizing a unified formalism for insight and connecting theories of insight to other critical concepts in visualization research.","meta":{"url":"http://arxiv.org/abs/2307.06551v1"},"cats":{"new-dataset":0.1602781523,"dev-research":0.4960995303,"prompt-eng":0.4374786465,"data-quality":0.0899756362,"ml-security":0.0620541364}}
{"text":"Deep neural networks have proven to be vulnerable to adversarial attacks in the form of adding specific perturbations on images to make wrong outputs.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0884108646,"dev-research":0.3897193568,"prompt-eng":0.4461550718,"data-quality":0.5002670241,"ml-security":0.7975549514}}
{"text":"Designing stronger adversarial attack methods can help more reliably evaluate the robustness of DNN models.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0849090738,"dev-research":0.3844683055,"prompt-eng":0.4506217509,"data-quality":0.2893280875,"ml-security":0.7648704934}}
{"text":"To release the harbor burden and improve the attack performance, auto machine learning (AutoML) has recently emerged as one successful technique to help automatically find the near-optimal adversarial attack strategy.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0751052932,"dev-research":0.4246947293,"prompt-eng":0.4714205329,"data-quality":0.1911689505,"ml-security":0.7696392589}}
{"text":"However, existing works about AutoML for adversarial attacks only focus on $L_{\\infty}$-norm-based perturbations.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0467044202,"dev-research":0.425985457,"prompt-eng":0.4372946559,"data-quality":0.2730114459,"ml-security":0.7228218322}}
{"text":"In fact, semantic perturbations attract increasing attention due to their naturalnesses and physical realizability.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0457298412,"dev-research":0.4615735702,"prompt-eng":0.464044361,"data-quality":0.282699617,"ml-security":0.1858281723}}
{"text":"To bridge the gap between AutoML and semantic adversarial attacks, we propose a novel method called multi-objective evolutionary search of variable-length composite semantic perturbations (MES-VCSP).","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0751888649,"dev-research":0.4306829462,"prompt-eng":0.4815393651,"data-quality":0.2737624015,"ml-security":0.5032346148}}
{"text":"Specifically, we construct the mathematical model of variable-length composite semantic perturbations, which provides five gradient-based semantic attack methods.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0616234723,"dev-research":0.4446388758,"prompt-eng":0.4802842814,"data-quality":0.4253484696,"ml-security":0.6807680775}}
{"text":"The same type of perturbation in an attack sequence is allowed to be performed multiple times.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.0266431092,"dev-research":0.4143651152,"prompt-eng":0.389945793,"data-quality":0.1243710536,"ml-security":0.4234309212}}
{"text":"Besides, we introduce the multi-objective evolutionary search consisting of NSGA-II and neighborhood search to find near-optimal variable-length attack sequences.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.1050248938,"dev-research":0.4016623867,"prompt-eng":0.3836772121,"data-quality":0.0516224939,"ml-security":0.4553445746}}
{"text":"Experimental results on CIFAR10","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.2044014192,"dev-research":0.3739413934,"prompt-eng":0.4108869509,"data-quality":0.1829071021,"ml-security":0.1112016072}}
{"text":"and ImageNet datasets show that compared with existing methods, MES-VCSP can obtain adversarial examples with a higher attack success rate, more naturalness, and less time cost.","meta":{"url":"http://arxiv.org/abs/2307.06548v1"},"cats":{"new-dataset":0.1837824398,"dev-research":0.4086835759,"prompt-eng":0.463133961,"data-quality":0.2171778716,"ml-security":0.5894169059}}
{"text":"Inverse reinforcement learning (IRL) algorithms often rely on (forward) reinforcement learning or planning over a given time horizon to compute an approximately optimal policy for a hypothesized reward function and then match this policy with expert demonstrations.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0858099096,"dev-research":0.4177358485,"prompt-eng":0.4865794619,"data-quality":0.0620046793,"ml-security":0.2300276491}}
{"text":"The time horizon plays a critical role in determining both the accuracy of reward estimate and the computational efficiency of IRL algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0511572417,"dev-research":0.406898967,"prompt-eng":0.3905945885,"data-quality":0.0747603615,"ml-security":0.1761078706}}
{"text":"Interestingly, an effective time horizon shorter than the ground-truth value often produces better results faster.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0904690084,"dev-research":0.3792348232,"prompt-eng":0.3748632318,"data-quality":0.1110277784,"ml-security":0.1374596581}}
{"text":"This work formally analyzes this phenomenon and provides an explanation: the time horizon controls the complexity of an induced policy class and mitigates overfitting with limited data.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0676668875,"dev-research":0.4256088119,"prompt-eng":0.3821396884,"data-quality":0.1061687903,"ml-security":0.4004826284}}
{"text":"This analysis leads to a principled choice of the effective horizon for IRL.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0420597308,"dev-research":0.4186245432,"prompt-eng":0.3945267906,"data-quality":0.0693800647,"ml-security":0.1473324358}}
{"text":"It also prompts us to reexamine the classic IRL formulation: it is more natural to learn jointly the reward and the effective horizon together rather than the reward alone with a given horizon.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0303948671,"dev-research":0.4391259701,"prompt-eng":0.4039162331,"data-quality":0.0794869244,"ml-security":0.154057122}}
{"text":"Our experimental results confirm the theoretical analysis.","meta":{"url":"http://arxiv.org/abs/2307.06541v1"},"cats":{"new-dataset":0.0484390354,"dev-research":0.409849763,"prompt-eng":0.3801902212,"data-quality":0.1261243357,"ml-security":0.1078183576}}
{"text":"This study addressed the complex task of sentiment analysis on a dataset of 119,988 original tweets from Weibo using a Convolutional Neural Network (CNN), offering a new approach to Natural Language Processing (NLP).","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.2780704032,"dev-research":0.409760442,"prompt-eng":0.4601908092,"data-quality":0.2652874918,"ml-security":0.1677230923}}
{"text":"The data, sourced from Baidu's PaddlePaddle AI platform, were meticulously preprocessed, tokenized, and categorized based on sentiment labels.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.4245467284,"dev-research":0.4740400324,"prompt-eng":0.5179633207,"data-quality":0.3100286767,"ml-security":0.1387107975}}
{"text":"A CNN-based model was utilized, leveraging word embeddings for feature extraction, and trained to perform sentiment classification.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.1648991681,"dev-research":0.3975445315,"prompt-eng":0.4863749982,"data-quality":0.2426149747,"ml-security":0.1086929768}}
{"text":"The model achieved a macro-average F1-score of approximately 0.73 on the test set, showing balanced performance across positive, neutral, and negative sentiments.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.1381972488,"dev-research":0.4035144609,"prompt-eng":0.4724362397,"data-quality":0.1596980926,"ml-security":0.0629234172}}
{"text":"The findings underscore the effectiveness of CNNs for sentiment analysis tasks, with implications for practical applications in social media analysis, market research, and policy studies.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.1304250028,"dev-research":0.408761594,"prompt-eng":0.4672400104,"data-quality":0.3258674299,"ml-security":0.1403720886}}
{"text":"The complete experimental content and code have been made publicly available on the Kaggle data platform for further research and development.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.6403518589,"dev-research":0.4463461423,"prompt-eng":0.44241053,"data-quality":0.0863614842,"ml-security":0.1515313748}}
{"text":"Future work may involve exploring different architectures, such as Recurrent Neural Networks (RNN) or transformers, or using more complex pre-trained models like BERT, to further improve the model's ability to understand linguistic nuances and context.","meta":{"url":"http://arxiv.org/abs/2307.06540v1"},"cats":{"new-dataset":0.1258418184,"dev-research":0.4664327359,"prompt-eng":0.5124745864,"data-quality":0.0924107454,"ml-security":0.1343580488}}
{"text":"Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.0714342818,"dev-research":0.3935639916,"prompt-eng":0.449823274,"data-quality":0.0971130131,"ml-security":0.1928532602}}
{"text":"While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.0916769162,"dev-research":0.3679997344,"prompt-eng":0.4365374852,"data-quality":0.0720049506,"ml-security":0.1368881964}}
{"text":"In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.1419869539,"dev-research":0.3639572337,"prompt-eng":0.4492315738,"data-quality":0.1307852728,"ml-security":0.2062805021}}
{"text":"As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.1296818444,"dev-research":0.3478787102,"prompt-eng":0.3854625531,"data-quality":0.1133615153,"ml-security":0.0916131653}}
{"text":"Moreover our algorithm works in the challenging partially-observed setting.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.1731736277,"dev-research":0.3611251361,"prompt-eng":0.3770190945,"data-quality":0.1939445464,"ml-security":0.1059802009}}
{"text":"Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a close relative of modern tensor decomposition methods for learning latent variable models.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.0876126904,"dev-research":0.3716319249,"prompt-eng":0.4752426364,"data-quality":0.1256898882,"ml-security":0.1352047021}}
{"text":"This gives us a playbook for how to extend it to work with more complicated generative models.","meta":{"url":"http://arxiv.org/abs/2307.06538v1"},"cats":{"new-dataset":0.1274798798,"dev-research":0.4537689485,"prompt-eng":0.5317598611,"data-quality":0.1246404437,"ml-security":0.0841869551}}
{"text":"Duan, Wu and Zhou (FOCS 2023) recently obtained the improved upper bound on the exponent of square matrix multiplication $\\omega<2.3719$ by introducing a new approach to quantify and compensate the ``combination loss\" in prior analyses of powers of the Coppersmith-Winograd tensor.","meta":{"url":"http://arxiv.org/abs/2307.06535v1"},"cats":{"new-dataset":0.0621754543,"dev-research":0.3888015084,"prompt-eng":0.3697103367,"data-quality":0.0942771016,"ml-security":0.207366906}}
{"text":"In this paper we show how to use this new approach to improve the exponent of rectangular matrix multiplication as well.","meta":{"url":"http://arxiv.org/abs/2307.06535v1"},"cats":{"new-dataset":0.0563458849,"dev-research":0.417431313,"prompt-eng":0.347130818,"data-quality":0.0707960865,"ml-security":0.1318684109}}
{"text":"Our main technical contribution is showing how to combine this analysis of the combination loss and the analysis of the fourth power of the Coppersmith-Winograd tensor in the context of rectangular matrix multiplication developed by Le Gall and Urrutia (SODA 2018).","meta":{"url":"http://arxiv.org/abs/2307.06535v1"},"cats":{"new-dataset":0.0746479179,"dev-research":0.4059760619,"prompt-eng":0.3836848185,"data-quality":0.1096064227,"ml-security":0.1473039367}}
{"text":"Self-supervised learning (SSL) has proven effective in solving various problems by generating internal supervisory signals.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.1085621512,"dev-research":0.4448956934,"prompt-eng":0.4965059274,"data-quality":0.1856425734,"ml-security":0.2769532485}}
{"text":"Unsupervised anomaly detection, which faces the high cost of obtaining true labels, is an area that can greatly benefit from SSL.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.0905023046,"dev-research":0.406765348,"prompt-eng":0.4456668012,"data-quality":0.4355640883,"ml-security":0.5395287324}}
{"text":"However, recent literature suggests that tuning the hyperparameters (HP) of data augmentation functions is crucial to the success of SSL-based anomaly detection (SSAD), yet a systematic method for doing so remains unknown.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.0744761635,"dev-research":0.422617609,"prompt-eng":0.4761837287,"data-quality":0.3012090014,"ml-security":0.4223800779}}
{"text":"In this work, we propose DSV (Discordance and Separability Validation), an unsupervised validation loss to select high-performing detection models with effective augmentation HPs.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.0742449262,"dev-research":0.3456927603,"prompt-eng":0.4819640899,"data-quality":0.3649958939,"ml-security":0.2934067753}}
{"text":"DSV captures the alignment between an augmentation function and the anomaly-generating mechanism with surrogate losses, which approximate the discordance and separability of test data, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.0861119879,"dev-research":0.4278326254,"prompt-eng":0.4590494405,"data-quality":0.2444338943,"ml-security":0.2118668687}}
{"text":"As a result, the evaluation via DSV leads to selecting an effective SSAD model exhibiting better alignment, which results in high detection accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.0861063265,"dev-research":0.3905926299,"prompt-eng":0.474230863,"data-quality":0.1767525421,"ml-security":0.0991618452}}
{"text":"We theoretically derive the degree of approximation conducted by the surrogate losses and empirically show that DSV outperforms a wide range of baselines on 21 real-world tasks.","meta":{"url":"http://arxiv.org/abs/2307.06534v1"},"cats":{"new-dataset":0.142149325,"dev-research":0.3940329608,"prompt-eng":0.4466128155,"data-quality":0.0862655694,"ml-security":0.12980589}}
{"text":"Existing person re-identification (re-ID) research mainly focuses on pedestrian identity matching across cameras in adjacent areas.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.1888772593,"dev-research":0.3696649965,"prompt-eng":0.4131856986,"data-quality":0.1542462017,"ml-security":0.1515333323}}
{"text":"However, in reality, it is inevitable to face the problem of pedestrian identity matching across long-distance scenes.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.0905571148,"dev-research":0.3704236031,"prompt-eng":0.3949400288,"data-quality":0.1797589841,"ml-security":0.1978986303}}
{"text":"The cross-camera pedestrian samples collected from long-distance scenes often have no positive samples.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.2430427269,"dev-research":0.3367231218,"prompt-eng":0.3725218392,"data-quality":0.2489080045,"ml-security":0.1402840238}}
{"text":"It is extremely challenging to use cross-camera negative samples to achieve cross-region pedestrian identity matching.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.1801571297,"dev-research":0.3408910945,"prompt-eng":0.4107782094,"data-quality":0.1707514904,"ml-security":0.1843179493}}
{"text":"Therefore, a novel domain-adaptive person re-ID method that focuses on cross-camera consistent discriminative feature learning under the supervision of unpaired samples is proposed.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.219289157,"dev-research":0.3774395978,"prompt-eng":0.4643155562,"data-quality":0.1763285125,"ml-security":0.1481955169}}
{"text":"This method mainly includes category synergy co-promotion module (CSCM) and cross-camera consistent feature learning module (CCFLM).","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.2593715151,"dev-research":0.4389607194,"prompt-eng":0.4837700793,"data-quality":0.1776845822,"ml-security":0.0648015888}}
{"text":"In CSCM, a task-specific feature recombination (FRT) mechanism is proposed.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.067155187,"dev-research":0.4890754568,"prompt-eng":0.5122152881,"data-quality":0.1195540627,"ml-security":0.1400904068}}
{"text":"This mechanism first groups features according to their contributions to specific tasks.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.0823310996,"dev-research":0.4706388282,"prompt-eng":0.434629321,"data-quality":0.0612666828,"ml-security":0.1102496544}}
{"text":"Then an interactive promotion learning (IPL) scheme between feature groups is developed and embedded in this mechanism to enhance feature discriminability.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.1192092225,"dev-research":0.4490499831,"prompt-eng":0.5045324046,"data-quality":0.1667755082,"ml-security":0.2003885893}}
{"text":"Since the control parameters of the specific task model are reduced after division by task, the generalization ability of the model is improved.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.0364576737,"dev-research":0.4255365362,"prompt-eng":0.4654330102,"data-quality":0.0749819445,"ml-security":0.1200276536}}
{"text":"In CCFLM, instance-level feature distribution alignment and cross-camera identity consistent learning methods are constructed.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.2432573275,"dev-research":0.3718688346,"prompt-eng":0.4848874981,"data-quality":0.2944788539,"ml-security":0.1085549525}}
{"text":"Therefore, the supervised model training is achieved under the style supervision of the target domain by exchanging styles between source-domain samples and target-domain samples, and the challenges caused by the lack of cross-camera paired samples are solved by utilizing cross-camera similar samples.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.2075765592,"dev-research":0.3969320084,"prompt-eng":0.5426676512,"data-quality":0.2707525715,"ml-security":0.1566472334}}
{"text":"In experiments, three challenging datasets are used as target domains, and the effectiveness of the proposed method is demonstrated through four experimental settings.","meta":{"url":"http://arxiv.org/abs/2307.06533v1"},"cats":{"new-dataset":0.2763854931,"dev-research":0.3685128751,"prompt-eng":0.4635329846,"data-quality":0.2061739333,"ml-security":0.2944587912}}
{"text":"This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.1437463344,"dev-research":0.3820310822,"prompt-eng":0.5789979568,"data-quality":0.2736400108,"ml-security":0.1186711338}}
{"text":"The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP).","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.1027038312,"dev-research":0.4791739456,"prompt-eng":0.5891752466,"data-quality":0.1716818931,"ml-security":0.0931206773}}
{"text":"Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.0929961978,"dev-research":0.413024905,"prompt-eng":0.5495241705,"data-quality":0.1688236955,"ml-security":0.1489661145}}
{"text":"We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.5656331186,"dev-research":0.3948311056,"prompt-eng":0.5233783907,"data-quality":0.0813848984,"ml-security":0.0941661336}}
{"text":"Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.0986699141,"dev-research":0.4049138019,"prompt-eng":0.5208728038,"data-quality":0.2026952014,"ml-security":0.1436461215}}
{"text":"Despite further exploration with varied settings and models, the corrected sentences from the LLMs frequently resulted in higher Word Error Rates (WER), demonstrating the limitations of LLMs in speech applications.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.0828880896,"dev-research":0.4168415595,"prompt-eng":0.5839515659,"data-quality":0.4294945768,"ml-security":0.1095259747}}
{"text":"This paper provides a detailed overview of these experiments, their results, and implications, establishing that using LLMs' in-context learning capabilities to correct potential errors in speech recognition transcriptions is still a challenging task at the current stage.","meta":{"url":"http://arxiv.org/abs/2307.06530v1"},"cats":{"new-dataset":0.101275686,"dev-research":0.4002098927,"prompt-eng":0.5744810917,"data-quality":0.3991564744,"ml-security":0.170745099}}
{"text":"This study introduces a novel and efficient least squares based method for rectangle fitting, using a continuous fitness function that approximates a unit square accurately.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.0832762628,"dev-research":0.3560878715,"prompt-eng":0.3537937174,"data-quality":0.085051984,"ml-security":0.1043647951}}
{"text":"The proposed method is compared with the existing method in the literature using both simulated data and real data.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.2135022172,"dev-research":0.3610043824,"prompt-eng":0.3924626563,"data-quality":0.1450080662,"ml-security":0.0731434305}}
{"text":"The real data is derived from aerial photogrammetry point clouds of a rectangular building.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.3170321121,"dev-research":0.3933338316,"prompt-eng":0.3838483539,"data-quality":0.0845408371,"ml-security":0.107903346}}
{"text":"The simulated tests show that the proposed method performs better than the reference method, reducing the root-mean-square error by about 93% and 14% for clean datasets and noisy point clouds, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.1781955824,"dev-research":0.3685178605,"prompt-eng":0.3886915027,"data-quality":0.2448709168,"ml-security":0.0901959517}}
{"text":"The proposed method also improves the fitting of the real dataset by about 81%, achieving centimetre level accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.2982230993,"dev-research":0.3671672847,"prompt-eng":0.3985409269,"data-quality":0.2125946726,"ml-security":0.0994308364}}
{"text":"Furthermore, the test results show that the proposed method converges in fewer than 10 iterations.","meta":{"url":"http://arxiv.org/abs/2307.06528v1"},"cats":{"new-dataset":0.0549795323,"dev-research":0.4159427739,"prompt-eng":0.3365396384,"data-quality":0.1222424027,"ml-security":0.0840117998}}
{"text":"Egocentric action recognition is gaining significant attention in the field of human action recognition.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.105844386,"dev-research":0.3946715926,"prompt-eng":0.4405187537,"data-quality":0.1619804707,"ml-security":0.10677329}}
{"text":"In this paper, we address data scarcity issue in egocentric action recognition from a compositional generalization perspective.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.1608650824,"dev-research":0.3862556266,"prompt-eng":0.4318066998,"data-quality":0.143521237,"ml-security":0.1861785576}}
{"text":"To tackle this problem, we propose a free-form composition network (FFCN) that can simultaneously learn disentangled verb, preposition, and noun representations, and then use them to compose new samples in the feature space for rare classes of action videos.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.188751659,"dev-research":0.4145312951,"prompt-eng":0.4748047028,"data-quality":0.1542715754,"ml-security":0.0985756713}}
{"text":"First, we use a graph to capture the spatial-temporal relations among different hand/object instances in each action video.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.3230410582,"dev-research":0.4096201171,"prompt-eng":0.4455497745,"data-quality":0.0733010434,"ml-security":0.0399524355}}
{"text":"We thus decompose each action into a set of verb and preposition spatial-temporal representations using the edge features in the graph.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.1662539716,"dev-research":0.4604956179,"prompt-eng":0.4171103708,"data-quality":0.1140252671,"ml-security":0.0711688499}}
{"text":"The temporal decomposition extracts verb and preposition representations from different video frames, while the spatial decomposition adaptively learns verb and preposition representations from action-related instances in each frame.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.1337831277,"dev-research":0.4601298147,"prompt-eng":0.4446033944,"data-quality":0.1610764773,"ml-security":0.0696266881}}
{"text":"With these spatial-temporal representations of verbs and prepositions, we can compose new samples for those rare classes in a free-form manner, which is not restricted to a rigid form of a verb and a noun.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.1585905833,"dev-research":0.4283942362,"prompt-eng":0.4351051841,"data-quality":0.1446165595,"ml-security":0.1355306441}}
{"text":"The proposed FFCN can directly generate new training data samples for rare classes, hence significantly improve action recognition performance.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.2305814622,"dev-research":0.3440984998,"prompt-eng":0.4466628535,"data-quality":0.154892191,"ml-security":0.1801361671}}
{"text":"We evaluated our method on three popular egocentric action recognition datasets, Something-Something V2, H2O, and EPIC-KITCHENS-100, and the experimental results demonstrate the effectiveness of the proposed method for handling data scarcity problems, including long-tailed and few-shot egocentric action recognition.","meta":{"url":"http://arxiv.org/abs/2307.06527v1"},"cats":{"new-dataset":0.3082959641,"dev-research":0.3710720437,"prompt-eng":0.4407721388,"data-quality":0.160153772,"ml-security":0.1689327795}}
{"text":"Large-scale pre-trained vision-language models allow for the zero-shot text-based generation of 3D avatars.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.2484659747,"dev-research":0.4224244208,"prompt-eng":0.5108877069,"data-quality":0.157563122,"ml-security":0.111452656}}
{"text":"The previous state-of-the-art method utilized CLIP to supervise neural implicit models that reconstructed a human body mesh.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.0978819029,"dev-research":0.3743876738,"prompt-eng":0.4520702725,"data-quality":0.0959035409,"ml-security":0.1450585149}}
{"text":"However, this approach has two limitations.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.03475793,"dev-research":0.4209510357,"prompt-eng":0.304219977,"data-quality":0.0797429941,"ml-security":0.1600606345}}
{"text":"Firstly, the lack of avatar-specific models can cause facial distortion and unrealistic clothing in the generated avatars.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.058216532,"dev-research":0.4113880684,"prompt-eng":0.4187248734,"data-quality":0.1674482592,"ml-security":0.1690676843}}
{"text":"Secondly, CLIP only provides optimization direction for the overall appearance, resulting in less impressive results.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.0260482344,"dev-research":0.4077404798,"prompt-eng":0.3744034193,"data-quality":0.1005957742,"ml-security":0.0680635421}}
{"text":"To address these limitations, we propose AvatarFusion, the first framework to use a latent diffusion model to provide pixel-level guidance for generating human-realistic avatars while simultaneously segmenting clothing from the avatar's body.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.1058759281,"dev-research":0.3730043903,"prompt-eng":0.4624516044,"data-quality":0.0622302581,"ml-security":0.0889067717}}
{"text":"AvatarFusion includes the first clothing-decoupled neural implicit avatar model that employs a novel Dual Volume Rendering strategy to render the decoupled skin and clothing sub-models in one space.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.1340705066,"dev-research":0.3979263622,"prompt-eng":0.4373209567,"data-quality":0.0727310195,"ml-security":0.1546407514}}
{"text":"We also introduce a novel optimization method, called Pixel-Semantics Difference-Sampling (PS-DS), which semantically separates the generation of body and clothes, and generates a variety of clothing styles.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.1557691678,"dev-research":0.4194991466,"prompt-eng":0.4591287981,"data-quality":0.1658207523,"ml-security":0.071088755}}
{"text":"Moreover, we establish the first benchmark for zero-shot text-to-avatar generation.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.2222880261,"dev-research":0.4197400877,"prompt-eng":0.4677367063,"data-quality":0.1735706124,"ml-security":0.1015861201}}
{"text":"Our experimental results demonstrate that our framework outperforms previous approaches, with significant improvements observed in all metrics.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.1129102168,"dev-research":0.4161145619,"prompt-eng":0.4454898642,"data-quality":0.1777188978,"ml-security":0.1146097351}}
{"text":"Additionally, since our model is clothing-decoupled, we can exchange the clothes of avatars.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.1647939351,"dev-research":0.4169802858,"prompt-eng":0.466861925,"data-quality":0.108846054,"ml-security":0.1816474206}}
{"text":"Code will be available on Github.","meta":{"url":"http://arxiv.org/abs/2307.06526v1"},"cats":{"new-dataset":0.3206420648,"dev-research":0.5129377626,"prompt-eng":0.491650752,"data-quality":0.1380407225,"ml-security":0.0992137475}}
{"text":"Automated negotiation support systems aim to help human negotiators reach more favorable outcomes in multi-issue negotiations (e.g., an employer and a candidate negotiating over issues such as salary, hours, and promotions before a job offer).","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.1187292579,"dev-research":0.4731350353,"prompt-eng":0.4969571606,"data-quality":0.1231469501,"ml-security":0.0991505888}}
{"text":"To be successful, these systems must accurately track agreements reached by participants in real-time.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.129254266,"dev-research":0.4522036553,"prompt-eng":0.4399636024,"data-quality":0.1263258705,"ml-security":0.1013004193}}
{"text":"Existing approaches either focus on task-oriented dialogues or produce unstructured outputs, rendering them unsuitable for this objective.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.1208114758,"dev-research":0.5016997431,"prompt-eng":0.4810876668,"data-quality":0.1415245608,"ml-security":0.1225114921}}
{"text":"Our work introduces the novel task of agreement tracking for two-party multi-issue negotiations, which requires continuous monitoring of agreements within a structured state space.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.1494004996,"dev-research":0.4462050643,"prompt-eng":0.469299099,"data-quality":0.1283613802,"ml-security":0.0619766372}}
{"text":"To address the scarcity of annotated corpora with realistic multi-issue negotiation dialogues, we use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly available.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.6595207285,"dev-research":0.4721300315,"prompt-eng":0.5512910379,"data-quality":0.2253860373,"ml-security":0.1346502815}}
{"text":"We present a strong initial baseline for our task by transfer-learning a T5 model trained on the MultiWOZ 2.4 corpus.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.3173741056,"dev-research":0.3823964658,"prompt-eng":0.5248899365,"data-quality":0.182188498,"ml-security":0.0970863628}}
{"text":"Pre-training T5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9% respectively over training solely on GPT-Negochat.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.1140314469,"dev-research":0.4106127763,"prompt-eng":0.4523692633,"data-quality":0.0832707467,"ml-security":0.1300237778}}
{"text":"We validate our method's sample-efficiency via smaller training subset experiments.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.06147569,"dev-research":0.3981079247,"prompt-eng":0.4395518193,"data-quality":0.2143218659,"ml-security":0.1521083599}}
{"text":"By releasing GPT-Negochat and our baseline models, we aim to encourage further research in multi-issue negotiation dialogue agreement tracking.","meta":{"url":"http://arxiv.org/abs/2307.06524v1"},"cats":{"new-dataset":0.2675445829,"dev-research":0.4628844866,"prompt-eng":0.5364012768,"data-quality":0.1441179771,"ml-security":0.0892956578}}
{"text":"Drug discovery is adapting to novel technologies such as data science, informatics, and artificial intelligence (AI) to accelerate effective treatment development while reducing costs and animal experiments.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.2493685232,"dev-research":0.4497306457,"prompt-eng":0.4132192113,"data-quality":0.1005717631,"ml-security":0.2225985038}}
{"text":"AI is transforming drug discovery, as indicated by increasing interest from investors, industrial and academic scientists, and legislators.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.1323481295,"dev-research":0.4616015783,"prompt-eng":0.3933011123,"data-quality":0.0922249217,"ml-security":0.1883084629}}
{"text":"Successful drug discovery requires optimizing properties related to pharmacodynamics, pharmacokinetics, and clinical outcomes.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.1023967677,"dev-research":0.3949107995,"prompt-eng":0.3961018368,"data-quality":0.0952293034,"ml-security":0.1956801757}}
{"text":"This review discusses the use of AI in the three pillars of drug discovery: diseases, targets, and therapeutic modalities, with a focus on small molecule drugs.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.1818086784,"dev-research":0.4208739816,"prompt-eng":0.418356883,"data-quality":0.1057242913,"ml-security":0.1535915921}}
{"text":"AI technologies, such as generative chemistry, machine learning, and multi-property optimization, have enabled several compounds to enter clinical trials.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.0793652114,"dev-research":0.4154586463,"prompt-eng":0.435016808,"data-quality":0.0902437269,"ml-security":0.135753948}}
{"text":"The scientific community must carefully vet known information to address the reproducibility crisis.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.2279104991,"dev-research":0.4649179456,"prompt-eng":0.467970409,"data-quality":0.2709134258,"ml-security":0.238916714}}
{"text":"The full potential of AI in drug discovery can only be realized with sufficient ground truth and appropriate human intervention at later pipeline stages.","meta":{"url":"http://arxiv.org/abs/2307.06521v1"},"cats":{"new-dataset":0.0882152418,"dev-research":0.4051142862,"prompt-eng":0.4055087504,"data-quality":0.1140796123,"ml-security":0.2454005005}}
{"text":"Quantum computing is emerging as an unprecedented threat to the current state of widely used cryptographic systems.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.0878277037,"dev-research":0.3815235849,"prompt-eng":0.3919701423,"data-quality":0.0681075602,"ml-security":0.4640172506}}
{"text":"Cryptographic methods that have been considered secure for decades will likely be broken, with enormous impact on the security of sensitive data and communications in enterprises worldwide.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.16088248,"dev-research":0.410485295,"prompt-eng":0.3956608467,"data-quality":0.1664988719,"ml-security":0.5891392509}}
{"text":"A plan to migrate to quantum-resistant cryptographic systems is required.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.1078858595,"dev-research":0.380864832,"prompt-eng":0.39445415,"data-quality":0.0505004455,"ml-security":0.3306295986}}
{"text":"However, migrating an enterprise system to ensure a quantum-safe state is a complex process.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.0702545164,"dev-research":0.436340848,"prompt-eng":0.411259619,"data-quality":0.0642765641,"ml-security":0.1644183612}}
{"text":"Enterprises will require systematic guidance to perform this migration to remain resilient in a post-quantum era, as many organisations do not have staff with the expertise to manage this process unaided.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.0823031369,"dev-research":0.4587935739,"prompt-eng":0.4252289276,"data-quality":0.0615192014,"ml-security":0.087443775}}
{"text":"This paper presents a comprehensive framework designed to aid enterprises in their migration.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.1696544641,"dev-research":0.4626495926,"prompt-eng":0.4183330838,"data-quality":0.1021766061,"ml-security":0.0786557863}}
{"text":"The framework articulates key steps and technical considerations in the cryptographic migration process.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.1113213202,"dev-research":0.4337322586,"prompt-eng":0.4122479874,"data-quality":0.099194292,"ml-security":0.3016254}}
{"text":"It makes use of existing organisational inventories and provides a roadmap for prioritising the replacement of cryptosystems in a post-quantum context.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.0768754774,"dev-research":0.4663351729,"prompt-eng":0.4023659618,"data-quality":0.050161675,"ml-security":0.2220137396}}
{"text":"The framework enables the efficient identification of cryptographic objects, and can be integrated with other frameworks in enterprise settings to minimise operational disruption during migration.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.1615307809,"dev-research":0.4274262459,"prompt-eng":0.4386987548,"data-quality":0.1320535919,"ml-security":0.4215812571}}
{"text":"Practical case studies are included to demonstrate the utility and efficacy of the proposed framework using graph theoretic techniques to determine and evaluate cryptographic dependencies.","meta":{"url":"http://arxiv.org/abs/2307.06520v1"},"cats":{"new-dataset":0.0775034024,"dev-research":0.4279087622,"prompt-eng":0.3787661054,"data-quality":0.1158461646,"ml-security":0.3796915192}}
{"text":"Machine Learning (ML) systems, particularly when deployed in high-stakes domains, are deeply consequential.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.1061339931,"dev-research":0.4105921017,"prompt-eng":0.4504760956,"data-quality":0.1604008128,"ml-security":0.5613575299}}
{"text":"They can exacerbate existing inequities, create new modes of discrimination, and reify outdated social constructs.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.0555778781,"dev-research":0.474421792,"prompt-eng":0.3906129456,"data-quality":0.2659674568,"ml-security":0.405330621}}
{"text":"Accordingly, the social context (i.e. organisations, teams, cultures) in which ML systems are developed is a site of active research for the field of AI ethics, and intervention for policymakers.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.1951268667,"dev-research":0.4728181624,"prompt-eng":0.4240313004,"data-quality":0.1043175078,"ml-security":0.2897671729}}
{"text":"This paper focuses on one aspect of social context that is often overlooked: interactions between practitioners and the tools they rely on, and the role these interactions play in shaping ML practices and the development of ML systems.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.1381750462,"dev-research":0.4638745117,"prompt-eng":0.4464112574,"data-quality":0.1360475511,"ml-security":0.2908595895}}
{"text":"In particular, through an empirical study of questions asked on the Stack Exchange forums, the use of interactive computing platforms (e.g. Jupyter Notebook and Google Colab) in ML practices is explored.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.2002618943,"dev-research":0.51354689,"prompt-eng":0.4952540117,"data-quality":0.1006936424,"ml-security":0.1816963033}}
{"text":"I find that interactive computing platforms are used in a host of learning and coordination practices, which constitutes an infrastructural relationship between interactive computing platforms and ML practitioners.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.20720724,"dev-research":0.4917273995,"prompt-eng":0.4293624815,"data-quality":0.0665245507,"ml-security":0.1932590134}}
{"text":"I describe how ML practices are co-evolving alongside the development of interactive computing platforms, and highlight how this risks making invisible aspects of the ML life cycle that AI ethics researchers' have demonstrated to be particularly salient for the societal impact of deployed ML systems.","meta":{"url":"http://arxiv.org/abs/2307.06518v1"},"cats":{"new-dataset":0.2325062876,"dev-research":0.4966749626,"prompt-eng":0.4349628491,"data-quality":0.1177818494,"ml-security":0.4462061263}}
{"text":"Beliefs and values are increasingly being incorporated into our AI systems through alignment processes, such as carefully curating data collection principles or regularizing the loss function used for training.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.1437434485,"dev-research":0.4176749024,"prompt-eng":0.4696068513,"data-quality":0.2073264598,"ml-security":0.23812117}}
{"text":"However, the meta-alignment problem is that these human beliefs are diverse and not aligned across populations; furthermore, the implicit strength of each belief may not be well calibrated even among humans, especially when trying to generalize across contexts.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.0932879911,"dev-research":0.3944836955,"prompt-eng":0.4432893689,"data-quality":0.2080622819,"ml-security":0.081431341}}
{"text":"Specifically, in high regret situations, we observe that contextual counterfactuals and recourse costs are particularly important in updating a decision maker's beliefs and the strengths to which such beliefs are held.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.0768218239,"dev-research":0.4570117916,"prompt-eng":0.4486390295,"data-quality":0.1643686294,"ml-security":0.1874769938}}
{"text":"Therefore, we argue that including counterfactuals is key to an accurate calibration of beliefs during alignment.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.1223277364,"dev-research":0.4279871121,"prompt-eng":0.4953182032,"data-quality":0.302206443,"ml-security":0.134611739}}
{"text":"To do this, we first segment belief diversity into two categories: subjectivity (across individuals within a population) and epistemic uncertainty (within an individual across different contexts).","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.161374338,"dev-research":0.3925313819,"prompt-eng":0.4497003415,"data-quality":0.1677442984,"ml-security":0.0788815602}}
{"text":"By leveraging our notion of epistemic uncertainty, we introduce `the belief calibration cycle' framework to more holistically calibrate this diversity of beliefs with context-driven counterfactual reasoning by using a multi-objective optimization.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.16794515,"dev-research":0.4253892446,"prompt-eng":0.516511864,"data-quality":0.2679701616,"ml-security":0.1604370635}}
{"text":"We empirically apply our framework for finding a Pareto frontier of clustered optimal belief strengths that generalize across different contexts, demonstrating its efficacy on a toy dataset for credit decisions.","meta":{"url":"http://arxiv.org/abs/2307.06513v1"},"cats":{"new-dataset":0.1425522813,"dev-research":0.4022985861,"prompt-eng":0.4785508567,"data-quality":0.1998020883,"ml-security":0.1379054494}}
{"text":"Integrating deep learning with clinical expertise holds great potential for addressing healthcare challenges and empowering medical professionals with improved diagnostic tools.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1732624181,"dev-research":0.405347155,"prompt-eng":0.4703413552,"data-quality":0.1071906935,"ml-security":0.2135140602}}
{"text":"However, the need for annotated medical images is often an obstacle to leveraging the full power of machine learning models.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1731842367,"dev-research":0.3839401395,"prompt-eng":0.4484032876,"data-quality":0.2671888676,"ml-security":0.2634491011}}
{"text":"Our research demonstrates that by combining synthetic images, generated using diffusion models, with real images, we can enhance nonalcoholic fatty liver disease (NAFLD) classification performance.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1904135784,"dev-research":0.3647287201,"prompt-eng":0.423341435,"data-quality":0.1642857228,"ml-security":0.144898307}}
{"text":"We evaluate the quality of the synthetic images by comparing two metrics: Inception Score (IS) and Fr\\'{e}chet Inception Distance (FID), computed on diffusion-generated images and generative adversarial networks (GANs)-generated images.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1948910193,"dev-research":0.4206728331,"prompt-eng":0.4507421718,"data-quality":0.2422422927,"ml-security":0.1447410242}}
{"text":"Our results show superior performance for the diffusion-generated images, with a maximum IS score of $1.90$ compared to $1.67$ for GANs, and a minimum FID score of $69.45$ compared to $99.53$ for GANs.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1092066931,"dev-research":0.382330951,"prompt-eng":0.4374588009,"data-quality":0.1090569487,"ml-security":0.0706111847}}
{"text":"Utilizing a partially frozen CNN backbone (EfficientNet v1), our synthetic augmentation method achieves a maximum image-level ROC AUC of $0.904$ on a NAFLD prediction task.","meta":{"url":"http://arxiv.org/abs/2307.06507v1"},"cats":{"new-dataset":0.1221555939,"dev-research":0.3759171942,"prompt-eng":0.463865493,"data-quality":0.1928998357,"ml-security":0.2424072838}}
{"text":"Fast-growing scientific publications present challenges to the scientific community.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.2102417455,"dev-research":0.4006817841,"prompt-eng":0.4045968703,"data-quality":0.1434987709,"ml-security":0.1045594651}}
{"text":"In this paper, we describe their implications to researchers.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.0696745579,"dev-research":0.4833019547,"prompt-eng":0.3980822303,"data-quality":0.1652591951,"ml-security":0.2115579254}}
{"text":"As references form explicit foundations for researchers to conduct a study, we investigate the evolution in reference patterns based on 60.8 million papers published from 1960 to 2015.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.2071738749,"dev-research":0.4349105081,"prompt-eng":0.4324166913,"data-quality":0.1184449282,"ml-security":0.1041635081}}
{"text":"The results demonstrate that recent papers contain more references than older ones, especially the well-cited papers compared with other papers.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.1550467153,"dev-research":0.4221562292,"prompt-eng":0.4186353093,"data-quality":0.1624668741,"ml-security":0.0696762958}}
{"text":"Well-cited papers receive 10 or more citations within 5 years of publication.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.1134370393,"dev-research":0.3867843276,"prompt-eng":0.3789568586,"data-quality":0.1216756882,"ml-security":0.0787789787}}
{"text":"Their references cover a longer period from classic research to very recent studies.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.2286917976,"dev-research":0.3998497397,"prompt-eng":0.3820069446,"data-quality":0.0808536886,"ml-security":0.0832636574}}
{"text":"Authors of well-cited papers are also farsighted to discover the reference papers with good potential to receive high citation numbers in near future.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.1325653875,"dev-research":0.4178832423,"prompt-eng":0.4219928631,"data-quality":0.113693474,"ml-security":0.1481051311}}
{"text":"We also discover that the number of accumulative publications has a negative impact on next-5-year citation count for most fields except Chemistry, Materials science, Environmental science, Biology, and Engineering.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.1024530551,"dev-research":0.4132388548,"prompt-eng":0.4199180743,"data-quality":0.1773857821,"ml-security":0.1047498521}}
{"text":"Our findings suggest that researchers are expected to devote more effort to producing impactful research.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.0712644397,"dev-research":0.480668448,"prompt-eng":0.4211769386,"data-quality":0.081222487,"ml-security":0.1032224563}}
{"text":"Based on all these findings, we strongly advise against judging researchers simply based on the number of their publications.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.143394539,"dev-research":0.4201297857,"prompt-eng":0.4313114616,"data-quality":0.2332311782,"ml-security":0.1777766408}}
{"text":"On the other hand, authors and reviewers should ensure that published papers contain adequate contributions.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.0407379007,"dev-research":0.4903400338,"prompt-eng":0.3880235323,"data-quality":0.2219686344,"ml-security":0.1025471007}}
{"text":"The code for our analysis is on GitHub: https://github.com/ECNU-Text-Computing/Research-Explosion.","meta":{"url":"http://arxiv.org/abs/2307.06506v1"},"cats":{"new-dataset":0.3273971286,"dev-research":0.4754141772,"prompt-eng":0.4430724912,"data-quality":0.2038255093,"ml-security":0.0845985922}}
{"text":"Autonomous driving on water surfaces plays an essential role in executing hazardous and time-consuming missions, such as maritime surveillance, survivors rescue, environmental monitoring, hydrography mapping and waste cleaning.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.1213928786,"dev-research":0.3817920789,"prompt-eng":0.4132959457,"data-quality":0.0878563709,"ml-security":0.1258484872}}
{"text":"This work presents WaterScenes, the first multi-task 4D radar-camera fusion dataset for autonomous driving on water surfaces.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.4571682496,"dev-research":0.3718965564,"prompt-eng":0.4173450771,"data-quality":0.0955821636,"ml-security":0.1024184118}}
{"text":"Equipped with a 4D radar and a monocular camera, our Unmanned Surface Vehicle (USV) proffers all-weather solutions for discerning object-related information, including color, shape, texture, range, velocity, azimuth, and elevation.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.2830382265,"dev-research":0.4168087969,"prompt-eng":0.4499123417,"data-quality":0.0883344151,"ml-security":0.0933680588}}
{"text":"Focusing on typical static and dynamic objects on water surfaces, we label the camera images and radar point clouds at pixel-level and point-level, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.219779078,"dev-research":0.3737234813,"prompt-eng":0.4175500127,"data-quality":0.144434909,"ml-security":0.1055883506}}
{"text":"In addition to basic perception tasks, such as object detection, instance segmentation and semantic segmentation, we also provide annotations for free-space segmentation and waterline segmentation.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.2061318471,"dev-research":0.3944928477,"prompt-eng":0.4600246934,"data-quality":0.286339043,"ml-security":0.0986690663}}
{"text":"Leveraging the multi-task and multi-modal data, we conduct numerous experiments on the single modality of radar and camera, as well as the fused modalities.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.1208532609,"dev-research":0.3812592648,"prompt-eng":0.455253232,"data-quality":0.094822811,"ml-security":0.0853573141}}
{"text":"Results demonstrate that 4D radar-camera fusion can considerably enhance the robustness of perception on water surfaces, especially in adverse lighting and weather conditions.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.1006931647,"dev-research":0.3787968783,"prompt-eng":0.4011698313,"data-quality":0.0929681898,"ml-security":0.1025346149}}
{"text":"WaterScenes dataset is public on https://waterscenes.github.io.","meta":{"url":"http://arxiv.org/abs/2307.06505v1"},"cats":{"new-dataset":0.8197350868,"dev-research":0.3944430294,"prompt-eng":0.4454906265,"data-quality":0.1100905158,"ml-security":0.1452788663}}
{"text":"Objective: The artificial pancreas (AP) has shown promising potential in achieving closed-loop glucose control for individuals with type 1 diabetes mellitus (T1DM).","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1088898753,"dev-research":0.4011810819,"prompt-eng":0.4159791602,"data-quality":0.0745095649,"ml-security":0.0682384524}}
{"text":"However, designing an effective control policy for the AP remains challenging due to the complex physiological processes, delayed insulin response, and inaccurate glucose measurements.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1071527098,"dev-research":0.4021765348,"prompt-eng":0.420710852,"data-quality":0.080976696,"ml-security":0.0947955751}}
{"text":"While model predictive control (MPC) offers safety and stability through the dynamic model and safety constraints, it lacks individualization and is adversely affected by unannounced meals.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.0879867953,"dev-research":0.3703934171,"prompt-eng":0.4334235578,"data-quality":0.0846114935,"ml-security":0.2543284032}}
{"text":"Conversely, deep reinforcement learning (DRL) provides personalized and adaptive strategies but faces challenges with distribution shifts and substantial data requirements.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1448579621,"dev-research":0.371047982,"prompt-eng":0.431754719,"data-quality":0.0656543605,"ml-security":0.2367548867}}
{"text":"Methods: We propose a hybrid control policy for the artificial pancreas (HyCPAP) to address the above challenges.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.0504452777,"dev-research":0.3887547712,"prompt-eng":0.4079745718,"data-quality":0.0691417881,"ml-security":0.1008656292}}
{"text":"HyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the strengths of both policies while compensating for their respective limitations.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.0530993191,"dev-research":0.4137917538,"prompt-eng":0.4471470218,"data-quality":0.0880802325,"ml-security":0.1465090959}}
{"text":"To facilitate faster deployment of AP systems in real-world settings, we further incorporate meta-learning techniques into HyCPAP, leveraging previous experience and patient-shared knowledge to enable fast adaptation to new patients with limited available data.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1473412466,"dev-research":0.4006813585,"prompt-eng":0.4879130347,"data-quality":0.0856470323,"ml-security":0.172405937}}
{"text":"Results: We conduct extensive experiments using the FDA-accepted UVA/Padova T1DM simulator across three scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1541823009,"dev-research":0.3868566352,"prompt-eng":0.4414574687,"data-quality":0.1113212109,"ml-security":0.1619984856}}
{"text":"Our approaches achieve the highest percentage of time spent in the desired euglycemic range and the lowest occurrences of hypoglycemia.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.1174730266,"dev-research":0.4206651854,"prompt-eng":0.3759033233,"data-quality":0.0686499553,"ml-security":0.078590573}}
{"text":"Conclusion: The results clearly demonstrate the superiority of our methods for closed-loop glucose management in individuals with T1DM.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.0997279711,"dev-research":0.3976273712,"prompt-eng":0.4289185965,"data-quality":0.1087904636,"ml-security":0.0577991473}}
{"text":"Significance: The study presents novel control policies for AP systems, affirming the great potential of proposed methods for efficient closed-loop glucose control.","meta":{"url":"http://arxiv.org/abs/2307.06501v1"},"cats":{"new-dataset":0.0737499617,"dev-research":0.4116560133,"prompt-eng":0.3979535151,"data-quality":0.0640166356,"ml-security":0.0885717741}}
{"text":"Convolutional neural networks (CNNs) have demonstrated remarkable success in vision-related tasks.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.1394649062,"dev-research":0.3773309235,"prompt-eng":0.4257884441,"data-quality":0.1249068707,"ml-security":0.0959966299}}
{"text":"However, their susceptibility to failing when inputs deviate from the training distribution is well-documented.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.0589551465,"dev-research":0.4018633349,"prompt-eng":0.480992128,"data-quality":0.4967925011,"ml-security":0.4438611467}}
{"text":"Recent studies suggest that CNNs exhibit a bias toward texture instead of object shape in image classification tasks, and that background information may affect predictions.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.0902436661,"dev-research":0.3958250572,"prompt-eng":0.4236332969,"data-quality":0.2317570513,"ml-security":0.2598590662}}
{"text":"This paper investigates the ability of CNNs to adapt to different color distributions in an image while maintaining context and background.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.1301172537,"dev-research":0.3876821946,"prompt-eng":0.4084692319,"data-quality":0.1514281991,"ml-security":0.1496371576}}
{"text":"The results of our experiments on modified MNIST and FashionMNIST data demonstrate that changes in color can substantially affect classification accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.0888075601,"dev-research":0.4133033045,"prompt-eng":0.4551649369,"data-quality":0.3287275705,"ml-security":0.1832659428}}
{"text":"The paper explores the effects of various regularization techniques on generalization error across datasets and proposes a minor architectural modification utilizing the dropout regularization in a novel way that enhances model reliance on color-invariant intensity-based features for improved classification accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.128461644,"dev-research":0.3740618607,"prompt-eng":0.4319835435,"data-quality":0.4976204495,"ml-security":0.234191978}}
{"text":"Overall, this work contributes to ongoing efforts to understand the limitations and challenges of CNNs in image classification tasks and offers potential solutions to enhance their performance.","meta":{"url":"http://arxiv.org/abs/2307.06500v1"},"cats":{"new-dataset":0.1328667134,"dev-research":0.3767166818,"prompt-eng":0.4138035222,"data-quality":0.22596917,"ml-security":0.2031159155}}
{"text":"Deep learning models are susceptible to adversarial samples in white and black-box environments.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.1245540202,"dev-research":0.3626695424,"prompt-eng":0.4624120607,"data-quality":0.2812839113,"ml-security":0.7586404038}}
{"text":"Although previous studies have shown high attack success rates, coupling DNN models with interpretation models could offer a sense of security when a human expert is involved, who can identify whether a given sample is benign or malicious.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.0768160546,"dev-research":0.4235923356,"prompt-eng":0.5232466027,"data-quality":0.1966445946,"ml-security":0.6535891839}}
{"text":"However, in white-box environments, interpretable deep learning systems (IDLSes) have been shown to be vulnerable to malicious manipulations.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.1243859113,"dev-research":0.421477528,"prompt-eng":0.4729602629,"data-quality":0.1966924516,"ml-security":0.6838485542}}
{"text":"In black-box settings, as access to the components of IDLSes is limited, it becomes more challenging for the adversary to fool the system.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.0976891808,"dev-research":0.4692425938,"prompt-eng":0.4301776521,"data-quality":0.1505533024,"ml-security":0.6220889511}}
{"text":"In this work, we propose a Query-efficient Score-based black-box attack against IDLSes, QuScore, which requires no knowledge of the target model and its coupled interpretation model.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.1164464867,"dev-research":0.4382620664,"prompt-eng":0.4723776197,"data-quality":0.1847125518,"ml-security":0.7703271766}}
{"text":"QuScore is based on transfer-based and score-based methods by employing an effective microbial genetic algorithm.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.2185811384,"dev-research":0.4289411552,"prompt-eng":0.4391599284,"data-quality":0.1401475044,"ml-security":0.1084097943}}
{"text":"Our method is designed to reduce the number of queries necessary to carry out successful attacks, resulting in a more efficient process.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.0652873313,"dev-research":0.4538699946,"prompt-eng":0.3959610705,"data-quality":0.0808719575,"ml-security":0.606255245}}
{"text":"By continuously refining the adversarial samples created based on feedback scores from the IDLS, our approach effectively navigates the search space to identify perturbations that can fool the system.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.0966612756,"dev-research":0.4356480309,"prompt-eng":0.4945021152,"data-quality":0.3848807413,"ml-security":0.7362763731}}
{"text":"We evaluate the attack's effectiveness on four CNN models (Inception, ResNet, VGG, DenseNet) and two interpretation models (CAM, Grad), using both ImageNet and CIFAR datasets.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.1934598595,"dev-research":0.3978824525,"prompt-eng":0.4814340021,"data-quality":0.2197593348,"ml-security":0.5825697396}}
{"text":"Our results show that the proposed approach is query-efficient with a high attack success rate that can reach between 95% and 100% and transferability with an average success rate of 69% in the ImageNet and CIFAR datasets.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.273031194,"dev-research":0.3674880842,"prompt-eng":0.4372251074,"data-quality":0.1607252599,"ml-security":0.4760518695}}
{"text":"Our attack method generates adversarial examples with attribution maps that resemble benign samples.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.110123756,"dev-research":0.4168213994,"prompt-eng":0.4772444266,"data-quality":0.413919219,"ml-security":0.8317326173}}
{"text":"We have also demonstrated that our attack is resilient against various preprocessing defense techniques and can easily be transferred to different DNN models.","meta":{"url":"http://arxiv.org/abs/2307.06496v1"},"cats":{"new-dataset":0.0815600407,"dev-research":0.4235692137,"prompt-eng":0.4821705137,"data-quality":0.1313234897,"ml-security":0.7731529206}}
{"text":"Precomputed Radiance Transfer (PRT) remains an attractive solution for real-time rendering of complex light transport effects such as glossy global illumination.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.104006972,"dev-research":0.3935200527,"prompt-eng":0.4143602603,"data-quality":0.0572695046,"ml-security":0.0843936345}}
{"text":"After precomputation, we can relight the scene with new environment maps while changing viewpoint in real-time.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.091092562,"dev-research":0.4626368374,"prompt-eng":0.4360907691,"data-quality":0.065249371,"ml-security":0.0725461554}}
{"text":"However, practical PRT methods are usually limited to low-frequency spherical harmonic lighting.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.042296953,"dev-research":0.3653734992,"prompt-eng":0.3800923843,"data-quality":0.0839305907,"ml-security":0.1069175814}}
{"text":"All-frequency techniques using wavelets are promising but have so far had little practical impact.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.081873915,"dev-research":0.368819376,"prompt-eng":0.378043192,"data-quality":0.2159779638,"ml-security":0.1508636718}}
{"text":"The curse of dimensionality and much higher data requirements have typically limited them to relighting with fixed view or only direct lighting with triple product integrals.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.0554415782,"dev-research":0.3905865655,"prompt-eng":0.3522097261,"data-quality":0.0652790934,"ml-security":0.106086572}}
{"text":"In this paper, we demonstrate a hybrid neural-wavelet PRT solution to high-frequency indirect illumination, including glossy reflection, for relighting with changing view.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.0932978766,"dev-research":0.4163180813,"prompt-eng":0.4326323365,"data-quality":0.114190563,"ml-security":0.1282238312}}
{"text":"Specifically, we seek to represent the light transport function in the Haar wavelet basis.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.0983474227,"dev-research":0.3735494451,"prompt-eng":0.3737432898,"data-quality":0.0715653022,"ml-security":0.106939878}}
{"text":"For global illumination, we learn the wavelet transport using a small multi-layer perceptron (MLP) applied to a feature field as a function of spatial location and wavelet index, with reflected direction and material parameters being other MLP inputs.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.1163417775,"dev-research":0.363766409,"prompt-eng":0.4256819394,"data-quality":0.1111088748,"ml-security":0.1363648937}}
{"text":"We optimize/learn the feature field (compactly represented by a tensor decomposition) and MLP parameters from multiple images of the scene under different lighting and viewing conditions.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.1723726637,"dev-research":0.3476935496,"prompt-eng":0.4293360592,"data-quality":0.0986405207,"ml-security":0.091421785}}
{"text":"We demonstrate real-time (512 x 512 at 24 FPS, 800 x 600 at 13 FPS) precomputed rendering of challenging scenes involving view-dependent reflections and even caustics.","meta":{"url":"http://arxiv.org/abs/2307.06335v1"},"cats":{"new-dataset":0.1983365157,"dev-research":0.3624138598,"prompt-eng":0.3907439896,"data-quality":0.0549633559,"ml-security":0.0795387553}}
{"text":"Policies often fail due to distribution shift -- changes in the state and reward that occur when a policy is deployed in new environments.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.089902097,"dev-research":0.4207381739,"prompt-eng":0.4523902052,"data-quality":0.2365660228,"ml-security":0.1707075671}}
{"text":"Data augmentation can increase robustness by making the model invariant to task-irrelevant changes in the agent's observation.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.0861521557,"dev-research":0.4435845118,"prompt-eng":0.4976720208,"data-quality":0.2443757511,"ml-security":0.2262889593}}
{"text":"However, designers don't know which concepts are irrelevant a priori, especially when different end users have different preferences about how the task is performed.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.0286180732,"dev-research":0.5251273109,"prompt-eng":0.4191622371,"data-quality":0.1111069897,"ml-security":0.1113858059}}
{"text":"We propose an interactive framework to leverage feedback directly from the user to identify personalized task-irrelevant concepts.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.103124204,"dev-research":0.5257199616,"prompt-eng":0.5515601139,"data-quality":0.246197777,"ml-security":0.0979936946}}
{"text":"Our key idea is to generate counterfactual demonstrations that allow users to quickly identify possible task-relevant and irrelevant concepts.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.1723328071,"dev-research":0.5053347235,"prompt-eng":0.573392983,"data-quality":0.2119657197,"ml-security":0.1921621896}}
{"text":"The knowledge of task-irrelevant concepts is then used to perform data augmentation and thus obtain a policy adapted to personalized user objectives.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.11240975,"dev-research":0.4927630624,"prompt-eng":0.5080450656,"data-quality":0.1658559985,"ml-security":0.1594060867}}
{"text":"We present experiments validating our framework on discrete and continuous control tasks with real human users.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.1108315612,"dev-research":0.4192024124,"prompt-eng":0.4432179301,"data-quality":0.0578240712,"ml-security":0.0966603006}}
{"text":"Our method (1) enables users to better understand agent failure, (2) reduces the number of demonstrations required for fine-tuning, and (3) aligns the agent to individual user task preferences.","meta":{"url":"http://arxiv.org/abs/2307.06333v1"},"cats":{"new-dataset":0.068338093,"dev-research":0.5043345508,"prompt-eng":0.5310903234,"data-quality":0.1756524505,"ml-security":0.1338953723}}
{"text":"The main challenge of offline reinforcement learning, where data is limited, arises from a sequence of counterfactual reasoning dilemmas within the realm of potential actions: What if we were to choose a different course of action?","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.2010927071,"dev-research":0.4024366641,"prompt-eng":0.4628811619,"data-quality":0.0888142964,"ml-security":0.3016386555}}
{"text":"These circumstances frequently give rise to extrapolation errors, which tend to accumulate exponentially with the problem horizon.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0845669279,"dev-research":0.4095071005,"prompt-eng":0.357091055,"data-quality":0.2216055218,"ml-security":0.2379438313}}
{"text":"Hence, it becomes crucial to acknowledge that not all decision steps are equally important to the final outcome, and to budget the number of counterfactual decisions a policy make in order to control the extrapolation.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0710546755,"dev-research":0.4556703799,"prompt-eng":0.4258510444,"data-quality":0.1519461972,"ml-security":0.1834544309}}
{"text":"Contrary to existing approaches that use regularization on either the policy or value function, we propose an approach to explicitly bound the amount of out-of-distribution actions during training.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0774407446,"dev-research":0.3626061317,"prompt-eng":0.4633957025,"data-quality":0.1995072477,"ml-security":0.3440139207}}
{"text":"Specifically, our method utilizes dynamic programming to decide where to extrapolate and where not to, with an upper bound on the decisions different from behavior policy.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.09726746,"dev-research":0.4805109683,"prompt-eng":0.4393726346,"data-quality":0.0946870034,"ml-security":0.1683387533}}
{"text":"It balances between the potential for improvement from taking out-of-distribution actions and the risk of making errors due to extrapolation.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0497942332,"dev-research":0.4451179752,"prompt-eng":0.399141957,"data-quality":0.1817231142,"ml-security":0.2138041284}}
{"text":"Theoretically, we justify our method by the constrained optimality of the fixed point solution to our $Q$ updating rules.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0767207029,"dev-research":0.4286238561,"prompt-eng":0.3607056061,"data-quality":0.1301518301,"ml-security":0.1424306907}}
{"text":"Empirically, we show that the overall performance of our method is better than the state-of-the-art offline RL methods on tasks in the widely-used D4RL benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.06328v1"},"cats":{"new-dataset":0.0984431519,"dev-research":0.4164469424,"prompt-eng":0.4552019125,"data-quality":0.0894158027,"ml-security":0.0532573349}}
{"text":"In federated submodel learning (FSL), a machine learning model is divided into multiple submodels based on different types of data used for training.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.1405269918,"dev-research":0.3660070703,"prompt-eng":0.4535124344,"data-quality":0.0832395507,"ml-security":0.1891385404}}
{"text":"Each user involved in the training process only downloads and updates the submodel relevant to the user's local data, which significantly reduces the communication cost compared to classical federated learning (FL).","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.1400292826,"dev-research":0.4099309787,"prompt-eng":0.453226186,"data-quality":0.0923701867,"ml-security":0.3218063031}}
{"text":"However, the index of the submodel updated by the user and the values of the updates reveal information about the user's private data.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.3212303777,"dev-research":0.4511468775,"prompt-eng":0.4189264165,"data-quality":0.105033311,"ml-security":0.3041700983}}
{"text":"In order to guarantee information-theoretic privacy in FSL, the model is stored at multiple non-colluding databases, and the user sends queries and updates to each database in such a way that no information is revealed on the updating submodel index or the values of the updates.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.1879020281,"dev-research":0.4064189568,"prompt-eng":0.42491239,"data-quality":0.0910390956,"ml-security":0.3179915245}}
{"text":"In this work, we consider the practical scenario where the multiple non-colluding databases are allowed to have arbitrary storage constraints.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.1994889188,"dev-research":0.3700834265,"prompt-eng":0.3767267247,"data-quality":0.1612448272,"ml-security":0.1896698089}}
{"text":"The goal of this work is to develop read-write schemes and storage mechanisms for FSL that efficiently utilize the available storage in each database to store the submodel parameters in such a way that the total communication cost is minimized while guaranteeing information-theoretic privacy of the updating submodel index and the values of the updates.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.2613215494,"dev-research":0.3989344537,"prompt-eng":0.4228730544,"data-quality":0.0801519832,"ml-security":0.2019850938}}
{"text":"As the main result, we consider both heterogeneous and homogeneous storage constrained databases, and propose private read-write and storage schemes for the two cases.","meta":{"url":"http://arxiv.org/abs/2307.06323v1"},"cats":{"new-dataset":0.2655701372,"dev-research":0.3729856497,"prompt-eng":0.3600586745,"data-quality":0.0993859973,"ml-security":0.1897535322}}
{"text":"Crystalline defects, such as line-like dislocations, play an important role for the performance and reliability of many metallic devices.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.0447322107,"dev-research":0.4102360025,"prompt-eng":0.405337936,"data-quality":0.2343278438,"ml-security":0.1036966221}}
{"text":"Their interaction and evolution still poses a multitude of open questions to materials science and materials physics.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.0707112403,"dev-research":0.3984554619,"prompt-eng":0.4146852683,"data-quality":0.0607976983,"ml-security":0.0782099532}}
{"text":"In-situ TEM experiments can provide important insights into how dislocations behave and move.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.1488263016,"dev-research":0.4044702942,"prompt-eng":0.4349237343,"data-quality":0.1165680289,"ml-security":0.1245727161}}
{"text":"During such experiments, the dislocation microstructure is captured in form of videos.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.1485965264,"dev-research":0.3779693544,"prompt-eng":0.405307419,"data-quality":0.1354105581,"ml-security":0.0828712018}}
{"text":"The analysis of individual video frames can provide useful insights but is limited by the capabilities of automated identification, digitization, and quantitative extraction of the dislocations as curved objects.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.2013863662,"dev-research":0.3725570005,"prompt-eng":0.3911594732,"data-quality":0.2089932165,"ml-security":0.094226566}}
{"text":"The vast amount of data also makes manual annotation very time consuming, thereby limiting the use of Deep Learning-based, automated image analysis and segmentation of the dislocation microstructure.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.2624570391,"dev-research":0.3908836272,"prompt-eng":0.446188093,"data-quality":0.232551565,"ml-security":0.1475984386}}
{"text":"In this work, a parametric model for generating synthetic training data for segmentation of dislocations is developed.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.2340205195,"dev-research":0.3564172632,"prompt-eng":0.4287163014,"data-quality":0.1422465912,"ml-security":0.1426370391}}
{"text":"Even though domain scientists might dismiss synthetic training images sometimes as too artificial, our findings show that they can result in superior performance, particularly regarding the generalizing of the Deep Learning models with respect to different microstructures and imaging conditions.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.1123786009,"dev-research":0.3776689472,"prompt-eng":0.4407253811,"data-quality":0.1744214235,"ml-security":0.2481307962}}
{"text":"Additionally, we propose an enhanced deep learning method optimized for segmenting overlapping or intersecting dislocation lines.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.1601231678,"dev-research":0.3561502435,"prompt-eng":0.3802146851,"data-quality":0.1574279221,"ml-security":0.1255931845}}
{"text":"Upon testing this framework on four distinct real datasets, we find that our synthetic training data are able to yield high-quality results also on real images-even more so if fine-tune on a few real images was done.","meta":{"url":"http://arxiv.org/abs/2307.06322v1"},"cats":{"new-dataset":0.3729516356,"dev-research":0.3754103082,"prompt-eng":0.4325096404,"data-quality":0.2581401169,"ml-security":0.1870691308}}
{"text":"Cloud computing has brought a fundamental transformation in how organizations operate their applications, enabling them to achieve affordable high availability of services.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.1248752957,"dev-research":0.4298200975,"prompt-eng":0.3840477446,"data-quality":0.0555047518,"ml-security":0.1527016753}}
{"text":"Kubernetes has emerged as the preferred choice for container orchestration and service management across many Cloud computing platforms.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.0890398215,"dev-research":0.3755287531,"prompt-eng":0.3894695603,"data-quality":0.0709139648,"ml-security":0.1201555277}}
{"text":"The scheduler in Kubernetes plays a crucial role in determining the placement of newly deployed service containers.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.0774898094,"dev-research":0.4029721751,"prompt-eng":0.405996482,"data-quality":0.0987621263,"ml-security":0.1151540996}}
{"text":"However, the default scheduler, while fast, often lacks optimization, leading to inefficient service placement or even deployment failures.   ","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.0552151333,"dev-research":0.4019595772,"prompt-eng":0.3889074964,"data-quality":0.0997462209,"ml-security":0.093412358}}
{"text":"This paper introduces SAGE, a tool for optimal solutions in Kubernetes clusters that can also assist the Kubernetes default scheduler and any other custom scheduler in application deployment.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.1229125097,"dev-research":0.4066397599,"prompt-eng":0.4137160994,"data-quality":0.0972752681,"ml-security":0.0946572617}}
{"text":"SAGE computes an optimal deployment plan based on the constraints of the application to be deployed and the available Cloud resources.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.1465282233,"dev-research":0.429395044,"prompt-eng":0.4012726871,"data-quality":0.0532282528,"ml-security":0.111610788}}
{"text":"We show the potential benefits of using SAGE by considering test cases with various characteristics.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.1497058474,"dev-research":0.4859678138,"prompt-eng":0.4481219616,"data-quality":0.1226652599,"ml-security":0.1778448732}}
{"text":"It turns out that SAGE surpasses other schedulers by comprehensively analyzing the application demand and cluster image.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.1926059957,"dev-research":0.4268236449,"prompt-eng":0.4158924222,"data-quality":0.0690843554,"ml-security":0.0832816604}}
{"text":"This ability allows it to better understand the needs of the pods, resulting in consistently optimal solutions across all scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.0623181191,"dev-research":0.460732101,"prompt-eng":0.4299966442,"data-quality":0.0842780384,"ml-security":0.1243744035}}
{"text":"The accompanying material of this paper is publicly available at https://github.com/SAGE-Project/SAGE-Predeployer.","meta":{"url":"http://arxiv.org/abs/2307.06318v1"},"cats":{"new-dataset":0.2062025095,"dev-research":0.4568236754,"prompt-eng":0.4561324616,"data-quality":0.1011937718,"ml-security":0.0794449929}}
{"text":"Semi-supervised learning has become increasingly popular in medical image segmentation due to its ability to leverage large amounts of unlabeled data to extract additional information.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.1871095751,"dev-research":0.3619638617,"prompt-eng":0.4433511915,"data-quality":0.2148025458,"ml-security":0.155567546}}
{"text":"However, most existing semi-supervised segmentation methods only focus on extracting information from unlabeled data, disregarding the potential of labeled data to further improve the performance of the model.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.1387776116,"dev-research":0.3648748577,"prompt-eng":0.4358441085,"data-quality":0.4505171611,"ml-security":0.136386587}}
{"text":"In this paper, we propose a novel Correlation Aware Mutual Learning (CAML) framework that leverages labeled data to guide the extraction of information from unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.2598436207,"dev-research":0.389633221,"prompt-eng":0.4753677794,"data-quality":0.4382124273,"ml-security":0.1769491307}}
{"text":"Our approach is based on a mutual learning strategy that incorporates two modules: the Cross-sample Mutual Attention Module (CMA) and the Omni-Correlation Consistency Module (OCC).","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.1818356843,"dev-research":0.3633878305,"prompt-eng":0.513065488,"data-quality":0.24538212,"ml-security":0.0692870146}}
{"text":"The CMA module establishes dense cross-sample correlations among a group of samples, enabling the transfer of label prior knowledge to unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.2571375469,"dev-research":0.3871804005,"prompt-eng":0.5331229009,"data-quality":0.4080108597,"ml-security":0.0893174842}}
{"text":"The OCC module constructs omni-correlations between the unlabeled and labeled datasets and regularizes dual models by constraining the omni-correlation matrix of each sub-model to be consistent.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.1452645858,"dev-research":0.3861070058,"prompt-eng":0.4863602512,"data-quality":0.3272144743,"ml-security":0.0997153078}}
{"text":"Experiments on the Atrial Segmentation Challenge dataset demonstrate that our proposed approach outperforms state-of-the-art methods, highlighting the effectiveness of our framework in medical image segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.2214519061,"dev-research":0.3342506549,"prompt-eng":0.4179655805,"data-quality":0.1796537753,"ml-security":0.1344741863}}
{"text":"The codes, pre-trained weights, and data are publicly available.","meta":{"url":"http://arxiv.org/abs/2307.06312v1"},"cats":{"new-dataset":0.5425736973,"dev-research":0.412469855,"prompt-eng":0.4896818454,"data-quality":0.1004305692,"ml-security":0.2572416023}}
{"text":"In recent years, the role of image generative models in facial reenactment has been steadily increasing.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.0910380228,"dev-research":0.3721647424,"prompt-eng":0.449075067,"data-quality":0.071338936,"ml-security":0.0633480652}}
{"text":"Such models are usually subject-agnostic and trained on domain-wide datasets.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.2151759846,"dev-research":0.3885813423,"prompt-eng":0.5158077253,"data-quality":0.157224344,"ml-security":0.2166024409}}
{"text":"The appearance of the reenacted individual is learned from a single image, and hence, the entire breadth of the individual's appearance is not entirely captured, leading these methods to resort to unfaithful hallucination.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.0359324577,"dev-research":0.3927783998,"prompt-eng":0.4101472169,"data-quality":0.1440189332,"ml-security":0.2144482136}}
{"text":"Thanks to recent advancements, it is now possible to train a personalized generative model tailored specifically to a given individual.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.181512587,"dev-research":0.4001811934,"prompt-eng":0.5651582637,"data-quality":0.1098807375,"ml-security":0.1213064579}}
{"text":"In this paper, we propose a novel method for facial reenactment using a personalized generator.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.1031103145,"dev-research":0.3798406297,"prompt-eng":0.4420192526,"data-quality":0.090029212,"ml-security":0.0966623843}}
{"text":"We train the generator using frames from a short, yet varied, self-scan video captured using a simple commodity camera.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.2545242102,"dev-research":0.3892835132,"prompt-eng":0.4720372112,"data-quality":0.1484904348,"ml-security":0.0738810253}}
{"text":"Images synthesized by the personalized generator are guaranteed to preserve identity.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.1074732434,"dev-research":0.4115843594,"prompt-eng":0.4625062357,"data-quality":0.2218470226,"ml-security":0.2129225384}}
{"text":"The premise of our work is that the task of reenactment is thus reduced to accurately mimicking head poses and expressions.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.0542083557,"dev-research":0.4158766441,"prompt-eng":0.4113410687,"data-quality":0.0957147788,"ml-security":0.093170791}}
{"text":"To this end, we locate the desired frames in the latent space of the personalized generator using carefully designed latent optimization.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.1269843353,"dev-research":0.4299636443,"prompt-eng":0.499482325,"data-quality":0.1437395697,"ml-security":0.0773299777}}
{"text":"Through extensive evaluation, we demonstrate state-of-the-art performance for facial reenactment.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.0614688549,"dev-research":0.3526282769,"prompt-eng":0.4053245612,"data-quality":0.0730205509,"ml-security":0.0609542784}}
{"text":"Furthermore, we show that since our reenactment takes place in a semantic latent space, it can be semantically edited and stylized in post-processing.","meta":{"url":"http://arxiv.org/abs/2307.06307v1"},"cats":{"new-dataset":0.0570686928,"dev-research":0.4600233871,"prompt-eng":0.4923880194,"data-quality":0.2159237391,"ml-security":0.0679101204}}
{"text":"State-of-the-art federated learning algorithms such as FedAvg require carefully tuned stepsizes to achieve their best performance.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.1101693876,"dev-research":0.3845284781,"prompt-eng":0.4488152645,"data-quality":0.1162359358,"ml-security":0.2344261003}}
{"text":"The improvements proposed by existing adaptive federated methods involve tuning of additional hyperparameters such as momentum parameters, and consider adaptivity only in the server aggregation round, but not locally.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.0310933719,"dev-research":0.3646959563,"prompt-eng":0.4317069189,"data-quality":0.1019380477,"ml-security":0.1319914382}}
{"text":"These methods can be inefficient in many practical scenarios because they require excessive tuning of hyperparameters and do not capture local geometric information.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.0264346654,"dev-research":0.3988818026,"prompt-eng":0.3555899705,"data-quality":0.1055282276,"ml-security":0.1156329223}}
{"text":"In this work, we extend the recently proposed stochastic Polyak stepsize (SPS) to the federated learning setting, and propose new locally adaptive and nearly parameter-free distributed SPS variants (FedSPS and FedDecSPS).","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.1085754511,"dev-research":0.3761713035,"prompt-eng":0.4669174852,"data-quality":0.1148033424,"ml-security":0.2694305019}}
{"text":"We prove that FedSPS converges linearly in strongly convex and sublinearly in convex settings when the interpolation condition (overparametrization) is satisfied, and converges to a neighborhood of the solution in the general case.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.1154055596,"dev-research":0.4006484182,"prompt-eng":0.4129013995,"data-quality":0.1416848717,"ml-security":0.1980974265}}
{"text":"We extend our proposed method to a decreasing stepsize version FedDecSPS, that converges also when the interpolation condition does not hold.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.0930569526,"dev-research":0.3893033111,"prompt-eng":0.3926399782,"data-quality":0.1287640567,"ml-security":0.1208726873}}
{"text":"We validate our theoretical claims by performing illustrative convex experiments.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.0349833326,"dev-research":0.3966953669,"prompt-eng":0.3949357427,"data-quality":0.2092063518,"ml-security":0.2175618642}}
{"text":"Our proposed algorithms match the optimization performance of FedAvg with the best tuned hyperparameters in the i.i.d. case, and outperform FedAvg in the non-i.i.d. case.","meta":{"url":"http://arxiv.org/abs/2307.06306v1"},"cats":{"new-dataset":0.0865762068,"dev-research":0.3810496159,"prompt-eng":0.4521393334,"data-quality":0.1221520461,"ml-security":0.1365897313}}
{"text":"The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.0570292202,"dev-research":0.377521221,"prompt-eng":0.3965845747,"data-quality":0.1090893446,"ml-security":0.0754111584}}
{"text":"However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.1079987491,"dev-research":0.3772351505,"prompt-eng":0.4209839828,"data-quality":0.0784335153,"ml-security":0.0736312026}}
{"text":"We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.1650363953,"dev-research":0.4415145789,"prompt-eng":0.463952589,"data-quality":0.1150935082,"ml-security":0.0704921583}}
{"text":"Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.1886922217,"dev-research":0.3742526758,"prompt-eng":0.5350165086,"data-quality":0.1644002377,"ml-security":0.1051657515}}
{"text":"NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.192958205,"dev-research":0.3941555346,"prompt-eng":0.4427006557,"data-quality":0.1868183603,"ml-security":0.1491622107}}
{"text":"At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.0530883358,"dev-research":0.4388790184,"prompt-eng":0.490198167,"data-quality":0.0733866745,"ml-security":0.092834384}}
{"text":"We believe that NaViT marks a departure from the standard, CNN-designed, input and modelling pipeline used by most computer vision models, and represents a promising direction for ViTs.","meta":{"url":"http://arxiv.org/abs/2307.06304v1"},"cats":{"new-dataset":0.1827666194,"dev-research":0.4014064952,"prompt-eng":0.4540041467,"data-quality":0.114733636,"ml-security":0.0861910912}}
{"text":"The general consensus is that the Multiplicative Extended Kalman Filter (MEKF) is superior to the Additive Extended Kalman Filter (AEKF) based on a wealth of theoretical evidence.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0726511005,"dev-research":0.3409952143,"prompt-eng":0.3503066757,"data-quality":0.0642626644,"ml-security":0.0919613816}}
{"text":"This paper deals with a practical comparison between the two filters in simulation with the goal of verifying if the previous theoretical foundations are true.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0344668085,"dev-research":0.3478974184,"prompt-eng":0.375447408,"data-quality":0.1231896685,"ml-security":0.1209274372}}
{"text":"The AEKF and MEKF are two variants of the Extended Kalman Filter that differ in their approach to linearizing the system dynamics.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0936286024,"dev-research":0.3732788235,"prompt-eng":0.3653691241,"data-quality":0.0660807161,"ml-security":0.1083549022}}
{"text":"The AEKF uses an additive correction term to update the state estimate, while the MEKF uses a multiplicative correction term.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0824091957,"dev-research":0.4036133064,"prompt-eng":0.3855073546,"data-quality":0.1333447566,"ml-security":0.0745848545}}
{"text":"The two also differ in the state of which they use.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0940725234,"dev-research":0.4037471173,"prompt-eng":0.3816394385,"data-quality":0.1188807634,"ml-security":0.0748195769}}
{"text":"The AEKF uses the quaternion as its state while the MEKF uses the Gibbs vector as its state.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0975413828,"dev-research":0.374909683,"prompt-eng":0.3683118808,"data-quality":0.0637522745,"ml-security":0.0720075291}}
{"text":"The results show that the MEKF consistently outperforms the AEKF in terms of estimation accuracy with lower uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.2065155391,"dev-research":0.3439060892,"prompt-eng":0.4130897632,"data-quality":0.2368835937,"ml-security":0.1011244567}}
{"text":"The AEKF is more computationally efficient, but the difference is so low that it is almost negligible and it has no effect on a real-time application.","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.0528040641,"dev-research":0.4012170781,"prompt-eng":0.3173890076,"data-quality":0.0476908219,"ml-security":0.1123887133}}
{"text":"Overall, the results suggest that the MEKF is a better choise for satellite attitude estimation due to its superior estimation accuracy and lower uncertainty, which agrees with the statements from previous work","meta":{"url":"http://arxiv.org/abs/2307.06300v1"},"cats":{"new-dataset":0.1792934343,"dev-research":0.3907941335,"prompt-eng":0.3843402444,"data-quality":0.1196847272,"ml-security":0.0611310603}}
{"text":"Recent developments in deep neural networks (DNNs) have led to their adoption in safety-critical systems, which in turn has heightened the need for guaranteeing their safety.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.1839802145,"dev-research":0.4087590557,"prompt-eng":0.420780155,"data-quality":0.1895992813,"ml-security":0.5548018363}}
{"text":"These safety properties of DNNs can be proven using tools developed by the verification community.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.120069888,"dev-research":0.431455529,"prompt-eng":0.4415932895,"data-quality":0.271268994,"ml-security":0.396591778}}
{"text":"However, these tools are themselves prone to implementation bugs and numerical stability problems, which make their reliability questionable.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.0619265469,"dev-research":0.4617734371,"prompt-eng":0.3997328234,"data-quality":0.2772876955,"ml-security":0.1903095564}}
{"text":"To overcome this, some verifiers produce proofs of their results which can be checked by a trusted checker.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.1165971761,"dev-research":0.4471889096,"prompt-eng":0.4623871072,"data-quality":0.334782766,"ml-security":0.3594003113}}
{"text":"In this work, we present a novel implementation of a proof checker for DNN verification.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.1500498133,"dev-research":0.4303404395,"prompt-eng":0.4677300832,"data-quality":0.2634532213,"ml-security":0.2475592024}}
{"text":"It improves on existing implementations by offering numerical stability and greater verifiability.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.0329351442,"dev-research":0.4376961803,"prompt-eng":0.3566110015,"data-quality":0.0820063465,"ml-security":0.1485841062}}
{"text":"To achieve this, we leverage two key capabilities of Imandra, an industrial theorem prover: its support of infinite precision real arithmetic and its formal verification infrastructure.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.08483172,"dev-research":0.4457165322,"prompt-eng":0.3704112798,"data-quality":0.1301743921,"ml-security":0.1271215503}}
{"text":"So far, we have implemented a proof checker in Imandra, specified its correctness properties and started to verify the checker's compliance with them.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.1254012268,"dev-research":0.4453173615,"prompt-eng":0.4581507638,"data-quality":0.2609318755,"ml-security":0.1512657518}}
{"text":"Our ongoing work focuses on completing the formal verification of the checker and further optimizing its performance.","meta":{"url":"http://arxiv.org/abs/2307.06299v1"},"cats":{"new-dataset":0.0693676271,"dev-research":0.4445074421,"prompt-eng":0.465693972,"data-quality":0.1664199969,"ml-security":0.0683376297}}
{"text":"Image smoothing is by reducing pixel-wise gradients to smooth out details.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.073628795,"dev-research":0.4214477998,"prompt-eng":0.4005274141,"data-quality":0.127816892,"ml-security":0.0455429486}}
{"text":"As existing methods always rely on gradients to determine smoothing manners, it is difficult to distinguish structures and details to handle distinctively due to the overlapped ranges of gradients for structures and details.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0722300941,"dev-research":0.3819372413,"prompt-eng":0.4196464298,"data-quality":0.1510523007,"ml-security":0.0479384547}}
{"text":"Thus, it is still challenging to achieve high-quality results, especially on preserving weak structures and removing high-contrast details.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0816623138,"dev-research":0.3634305504,"prompt-eng":0.3974796229,"data-quality":0.1771856225,"ml-security":0.0751900408}}
{"text":"In this paper, we address this challenge by improving the real-time optimization-based method via iterative least squares (called ILS).","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0862069134,"dev-research":0.3793991423,"prompt-eng":0.390982274,"data-quality":0.1081783711,"ml-security":0.1594202623}}
{"text":"We observe that 1) ILS uses gradients as the independent variable in its penalty function for determining smoothing manners, and 2) the framework of ILS can still work for image smoothing when we use some values instead of gradients in the penalty function.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0405566436,"dev-research":0.3826777892,"prompt-eng":0.3858237407,"data-quality":0.1435398067,"ml-security":0.1384812762}}
{"text":"Thus, corresponding to the properties of pixels on structures or not, we compute some values to use in the penalty function to determine smoothing manners, and so we can handle structures and details distinctively, no matter whether their gradients are high or low.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0471786052,"dev-research":0.3706969752,"prompt-eng":0.3743328038,"data-quality":0.1297967889,"ml-security":0.0858488335}}
{"text":"As a result, we can conveniently remove high-contrast details while preserving weak structures.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0588741119,"dev-research":0.3785026963,"prompt-eng":0.4110142699,"data-quality":0.1585926601,"ml-security":0.1120816196}}
{"text":"Moreover, such values can be adjusted to accelerate optimization computation, so that we can use fewer iterations than the original ILS method for efficiency.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0213654493,"dev-research":0.3914700866,"prompt-eng":0.3381802953,"data-quality":0.0647068619,"ml-security":0.1548061399}}
{"text":"This also reduces the changes onto structures to help structure preservation.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0383288913,"dev-research":0.4470427007,"prompt-eng":0.3738386615,"data-quality":0.0752071359,"ml-security":0.0904558621}}
{"text":"Experimental results show our advantages over existing methods on efficiency and quality.","meta":{"url":"http://arxiv.org/abs/2307.06298v1"},"cats":{"new-dataset":0.0415122894,"dev-research":0.4608643418,"prompt-eng":0.3811527311,"data-quality":0.1416039037,"ml-security":0.0534846631}}
{"text":"We expect that many-core microprocessors will push performance per chip from the 10 gigaflop to the 10 teraflop range in the coming decade.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.0735714696,"dev-research":0.4064545404,"prompt-eng":0.4307878716,"data-quality":0.0574608513,"ml-security":0.1147628343}}
{"text":"To support this increased performance, memory and inter-core bandwidths will also have to scale by orders of magnitude.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.0435927376,"dev-research":0.4048621866,"prompt-eng":0.3810673593,"data-quality":0.062853729,"ml-security":0.0961830508}}
{"text":"Pin limitations, the energy cost of electrical signaling, and the non-scalability of chip-length global wires are significant bandwidth impediments.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.0379063824,"dev-research":0.3970495037,"prompt-eng":0.3648041711,"data-quality":0.1001091304,"ml-security":0.1015774634}}
{"text":"Recent developments in silicon nanophotonic technology have the potential to meet these off- and on- stack bandwidth requirements at acceptable power levels.   ","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.0827133524,"dev-research":0.3970916126,"prompt-eng":0.426024507,"data-quality":0.0841851241,"ml-security":0.1048896342}}
{"text":"Corona is a 3D many-core architecture that uses nanophotonic communication for both inter-core communication and off-stack communication to memory or I/O devices.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.1401397013,"dev-research":0.3932099875,"prompt-eng":0.3998952655,"data-quality":0.0660141521,"ml-security":0.0904865503}}
{"text":"Its peak floating-point performance is 10 teraflops.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.1097346575,"dev-research":0.3810864858,"prompt-eng":0.4055610082,"data-quality":0.0902971297,"ml-security":0.1094224125}}
{"text":"Dense wavelength division multiplexed optically connected memory modules provide 10 terabyte per second memory bandwidth.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.1643976236,"dev-research":0.388522899,"prompt-eng":0.4062666461,"data-quality":0.0874569233,"ml-security":0.0640698393}}
{"text":"A photonic crossbar fully interconnects its 256 low-power multithreaded cores at 20 terabyte per second bandwidth.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.1586868055,"dev-research":0.3984202398,"prompt-eng":0.4027678316,"data-quality":0.0391291171,"ml-security":0.0620958751}}
{"text":"We have simulated a 1024 thread Corona system running synthetic benchmarks and scaled versions of the SPLASH-2 benchmark suite.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.2091290456,"dev-research":0.3891854583,"prompt-eng":0.4317085797,"data-quality":0.0887614969,"ml-security":0.1203975827}}
{"text":"We believe that in comparison with an electrically-connected many-core alternative that uses the same on-stack interconnect power, Corona can provide 2 to 6 times more performance on many memory-intensive workloads, while simultaneously reducing power.","meta":{"url":"http://arxiv.org/abs/2307.06294v1"},"cats":{"new-dataset":0.0793392197,"dev-research":0.3966901829,"prompt-eng":0.3720156309,"data-quality":0.0703984238,"ml-security":0.0757598984}}
{"text":"Large language models typically undergo two training stages, pretraining and finetuning.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.0953630455,"dev-research":0.4021406405,"prompt-eng":0.5539531731,"data-quality":0.1569382672,"ml-security":0.1147403838}}
{"text":"Despite that large-scale pretraining endows the model with strong capabilities to generate natural language responses, these pretrained models can still fail to understand human instructions at times.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.0965098138,"dev-research":0.4708639959,"prompt-eng":0.6150881588,"data-quality":0.2110357349,"ml-security":0.1876307119}}
{"text":"To enhance language models' ability of interpreting and responding to instructions, instruction finetuning has emerged as a critical method in this area.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.0722853325,"dev-research":0.5045055491,"prompt-eng":0.5620504247,"data-quality":0.2113298903,"ml-security":0.0955823506}}
{"text":"Recent studies found that large language models can be finetuned to perform well even with a small amount of high-quality instruction-following data.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.1473830721,"dev-research":0.4386191404,"prompt-eng":0.5671341874,"data-quality":0.1779800177,"ml-security":0.1251355473}}
{"text":"However, the selection of high-quality datasets for finetuning language models still lacks clear guidelines to follow.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.3198965189,"dev-research":0.4168113874,"prompt-eng":0.501701256,"data-quality":0.4166363821,"ml-security":0.1271549997}}
{"text":"In this paper, we propose InstructMining, a linear rule for evaluating instruction-following data quality.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.1742062867,"dev-research":0.5063043321,"prompt-eng":0.5040026909,"data-quality":0.2561769154,"ml-security":0.154953544}}
{"text":"We formulate InstructMining using specific natural language indicators.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.1609855136,"dev-research":0.5297321262,"prompt-eng":0.6023998445,"data-quality":0.2754600313,"ml-security":0.0970092069}}
{"text":"To investigate the relationship between data quality and these indicators, we further conduct extensive finetuning experiments.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.2930238792,"dev-research":0.4561997803,"prompt-eng":0.4551807382,"data-quality":0.3554349922,"ml-security":0.1435611882}}
{"text":"The experiment results are then applied to estimating parameters in InstructMining.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.0981854881,"dev-research":0.4720591056,"prompt-eng":0.5104391638,"data-quality":0.1252728429,"ml-security":0.1081966754}}
{"text":"To further investigate its performance, we use InstructMining to select high-quality data from unseen datasets.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.4893994451,"dev-research":0.4362809383,"prompt-eng":0.4821925659,"data-quality":0.2516462274,"ml-security":0.2083263297}}
{"text":"Results demonstrate that InstructMining can help select relatively high-quality samples from various instruction-following datasets.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.3378112382,"dev-research":0.4709575672,"prompt-eng":0.5646583748,"data-quality":0.228287354,"ml-security":0.1247095715}}
{"text":"Compared to models finetuned on unfiltered datasets, models finetuned on InstructMining selected datasets perform better on 42.5% cases.","meta":{"url":"http://arxiv.org/abs/2307.06290v1"},"cats":{"new-dataset":0.2553646115,"dev-research":0.3955783391,"prompt-eng":0.4724996858,"data-quality":0.1716877369,"ml-security":0.2511120835}}
{"text":"The future of machine learning lies in moving data collection along with training to the edge.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.2700345244,"dev-research":0.389263471,"prompt-eng":0.4048652995,"data-quality":0.1149651126,"ml-security":0.3235676942}}
{"text":"Federated Learning, for short FL, has been recently proposed to achieve this goal.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.1608339878,"dev-research":0.3810849317,"prompt-eng":0.4679718703,"data-quality":0.0876742388,"ml-security":0.2285507086}}
{"text":"The principle of this approach is to aggregate models learned over a large number of distributed clients, i.e., resource-constrained mobile devices that collect data from their environment, to obtain a new more general model.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.1494993052,"dev-research":0.4266794442,"prompt-eng":0.4653253709,"data-quality":0.0808360457,"ml-security":0.2302292113}}
{"text":"The latter is subsequently redistributed to clients for further training.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.0976898937,"dev-research":0.4898109566,"prompt-eng":0.4151589357,"data-quality":0.1340468897,"ml-security":0.2295974548}}
{"text":"A key feature that distinguishes federated learning from data-center-based distributed training is the inherent heterogeneity.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.1154784167,"dev-research":0.3897130468,"prompt-eng":0.4197059281,"data-quality":0.1349108295,"ml-security":0.248390377}}
{"text":"In this work, we introduce and analyse a novel aggregation framework that allows for formalizing and tackling computational heterogeneity in federated optimization, in terms of both heterogeneous data and local updates.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.1070047696,"dev-research":0.3881792773,"prompt-eng":0.4008004425,"data-quality":0.0999035085,"ml-security":0.1390660209}}
{"text":"Proposed aggregation algorithms are extensively analyzed from a theoretical, and an experimental prospective.","meta":{"url":"http://arxiv.org/abs/2307.06283v1"},"cats":{"new-dataset":0.0884709336,"dev-research":0.369079785,"prompt-eng":0.375010727,"data-quality":0.1358727096,"ml-security":0.0785216203}}
{"text":"Large vision-language models have recently achieved remarkable progress, exhibiting great perception and reasoning abilities concerning visual information.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.1835040288,"dev-research":0.430901381,"prompt-eng":0.490981648,"data-quality":0.1546124871,"ml-security":0.0745399429}}
{"text":"However, how to effectively evaluate these large vision-language models remains a major obstacle, hindering future model development.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.1259541274,"dev-research":0.4350889536,"prompt-eng":0.5200451983,"data-quality":0.1919940084,"ml-security":0.0880864833}}
{"text":"Traditional benchmarks like VQAv2 or COCO Caption provide quantitative performance measurements but suffer from a lack of fine-grained ability assessment and non-robust evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.1604228061,"dev-research":0.4116180611,"prompt-eng":0.4810543312,"data-quality":0.1906712477,"ml-security":0.0804808715}}
{"text":"Recent subjective benchmarks, such as OwlEval, offer comprehensive evaluations of a model's abilities by incorporating human labor, but they are not scalable and display significant bias.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.0995402675,"dev-research":0.4409060678,"prompt-eng":0.4404640903,"data-quality":0.0922747088,"ml-security":0.0939037944}}
{"text":"In response to these challenges, we propose MMBench, a novel multi-modality benchmark.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.133057144,"dev-research":0.4056605322,"prompt-eng":0.4679708049,"data-quality":0.1310154161,"ml-security":0.0782468173}}
{"text":"MMBench methodically develops a comprehensive evaluation pipeline, primarily comprised of two elements.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.0452770114,"dev-research":0.4629865317,"prompt-eng":0.4812479116,"data-quality":0.1070416102,"ml-security":0.0431554485}}
{"text":"The first element is a meticulously curated dataset that surpasses existing similar benchmarks in terms of the number and variety of evaluation questions and abilities.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.462338223,"dev-research":0.4160549895,"prompt-eng":0.4675974763,"data-quality":0.1145910341,"ml-security":0.0997523171}}
{"text":"The second element introduces a novel CircularEval strategy and incorporates the use of ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.0864706344,"dev-research":0.4778610951,"prompt-eng":0.438255352,"data-quality":0.0570481876,"ml-security":0.0887096705}}
{"text":"This implementation is designed to convert free-form predictions into pre-defined choices, thereby facilitating a more robust evaluation of the model's predictions.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.104054225,"dev-research":0.4490506934,"prompt-eng":0.4946179018,"data-quality":0.0816287063,"ml-security":0.1657870289}}
{"text":"MMBench is a systematically-designed objective benchmark for robustly evaluating the various abilities of vision-language models.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.1364849835,"dev-research":0.4196846151,"prompt-eng":0.5047420724,"data-quality":0.2413621703,"ml-security":0.0821229738}}
{"text":"We hope MMBench will assist the research community in better evaluating their models and encourage future advancements in this domain.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.1055988448,"dev-research":0.4574206809,"prompt-eng":0.4766309759,"data-quality":0.0838403403,"ml-security":0.07648389}}
{"text":"Project page: https://opencompass.org.cn/mmbench.","meta":{"url":"http://arxiv.org/abs/2307.06281v1"},"cats":{"new-dataset":0.3341886979,"dev-research":0.4705113936,"prompt-eng":0.4612914025,"data-quality":0.0721116084,"ml-security":0.1447252797}}
{"text":"The Visual Turing Test is the ultimate goal to evaluate the realism of holographic displays.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.1011006704,"dev-research":0.4205840056,"prompt-eng":0.4221305413,"data-quality":0.1005688008,"ml-security":0.0574186893}}
{"text":"Previous studies have focused on addressing challenges such as limited \\'etendue and image quality over a large focal volume, but they have not investigated the effect of pupil sampling on the viewing experience in full 3D holograms.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.0791554097,"dev-research":0.3529350568,"prompt-eng":0.4156002662,"data-quality":0.0726534062,"ml-security":0.0561367339}}
{"text":"In this work, we tackle this problem with a novel hologram generation algorithm motivated by matching the projection operators of incoherent Light Field and coherent Wigner Function light transport.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.1018956481,"dev-research":0.364454757,"prompt-eng":0.3946119715,"data-quality":0.0710861288,"ml-security":0.0629631172}}
{"text":"To this end, we supervise hologram computation using synthesized photographs, which are rendered on-the-fly using Light Field refocusing from stochastically sampled pupil states during optimization.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.072565489,"dev-research":0.3522231588,"prompt-eng":0.4168418199,"data-quality":0.0619218072,"ml-security":0.0513968717}}
{"text":"The proposed method produces holograms with correct parallax and focus cues, which are important for passing the Visual Turing Test.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.0623119742,"dev-research":0.4005243675,"prompt-eng":0.4624245532,"data-quality":0.1023189794,"ml-security":0.0430781322}}
{"text":"We validate that our approach compares favorably to state-of-the-art CGH algorithms that use Light Field and Focal Stack supervision.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.103949908,"dev-research":0.3646897223,"prompt-eng":0.4052403821,"data-quality":0.0884374088,"ml-security":0.0525977678}}
{"text":"Our experiments demonstrate that our algorithm significantly improves the realism of the viewing experience for a variety of different pupil states.","meta":{"url":"http://arxiv.org/abs/2307.06277v1"},"cats":{"new-dataset":0.101186488,"dev-research":0.416596955,"prompt-eng":0.4280239061,"data-quality":0.104178886,"ml-security":0.0539738775}}
{"text":"We present an efficient labeling scheme for answering connectivity queries in graphs subject to a specified number of vertex failures.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.1633430207,"dev-research":0.4243034699,"prompt-eng":0.4599426593,"data-quality":0.4784619071,"ml-security":0.1461740604}}
{"text":"Our first result is a randomized construction of a labeling function that assigns vertices $O(f^3\\log^5 n)$-bit labels, such that given the labels of $F\\cup \\{s,t\\}$ where $|F|\\leq f$, we can correctly report, with probability $1-1/\\mathrm{poly}(n)$, whether $s$ and $t$ are connected in $G-F$. However, it is possible that over all $n^{O(f)}$ distinct queries, some are answered incorrectly.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.1712922343,"dev-research":0.4031726641,"prompt-eng":0.3856696265,"data-quality":0.3435831527,"ml-security":0.1160757357}}
{"text":"Our second result is a deterministic labeling function that produces $O(f^7 \\log^{13} n)$-bit labels such that all connectivity queries are answered correctly.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.3398306383,"dev-research":0.4108945051,"prompt-eng":0.4171204433,"data-quality":0.3327559919,"ml-security":0.1538481758}}
{"text":"Both upper bounds are polynomially off from an $\\Omega(f)$-bit lower bound.   ","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.0784699841,"dev-research":0.4296909131,"prompt-eng":0.3635882026,"data-quality":0.114756377,"ml-security":0.1607641308}}
{"text":"Our labeling schemes are based on a new low degree decomposition that improves the Duan-Pettie decomposition, and facilitates its distributed representation.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.2232927214,"dev-research":0.3980993498,"prompt-eng":0.4533695146,"data-quality":0.4190946955,"ml-security":0.1184946125}}
{"text":"We make heavy use of randomization to construct hitting sets, fault-tolerant graph sparsifiers, and in constructing linear sketches.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.1226675628,"dev-research":0.4402161826,"prompt-eng":0.4294397473,"data-quality":0.3377724578,"ml-security":0.3841527236}}
{"text":"Our derandomized labeling scheme combines a variety of techniques: the method of conditional expectations, hit-miss hash families, and $\\epsilon$-nets for axis-aligned rectangles.   ","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.2438510295,"dev-research":0.4048692779,"prompt-eng":0.4519230693,"data-quality":0.3964707526,"ml-security":0.1982458257}}
{"text":"The prior labeling scheme of Parter and Petruschka shows that $f=1$ and $f=2$ vertex faults can be handled with $O(\\log n)$- and $O(\\log^3 n)$-bit labels, respectively, and for $f>2$ vertex faults, $\\tilde{O}(n^{1-1/2^{f-2}})$-bit labels suffice.","meta":{"url":"http://arxiv.org/abs/2307.06276v1"},"cats":{"new-dataset":0.0916547276,"dev-research":0.4209156338,"prompt-eng":0.4181083928,"data-quality":0.5977632125,"ml-security":0.2041542905}}
{"text":"Image synthesis has seen significant advancements with the advent of diffusion-based generative models like Denoising Diffusion Probabilistic Models (DDPM) and text-to-image diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.1523963786,"dev-research":0.4031111828,"prompt-eng":0.4998186744,"data-quality":0.1183779088,"ml-security":0.0913312843}}
{"text":"Despite their efficacy, there is a dearth of research dedicated to detecting diffusion-generated images, which could pose potential security and privacy risks.","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.1937269386,"dev-research":0.380417538,"prompt-eng":0.4331102329,"data-quality":0.1613699228,"ml-security":0.3769142601}}
{"text":"This paper addresses this gap by proposing a novel detection method called Stepwise Error for Diffusion-generated Image Detection (SeDID).","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.1035805102,"dev-research":0.3722312682,"prompt-eng":0.3901302144,"data-quality":0.322919487,"ml-security":0.0844113376}}
{"text":"Comprising statistical-based $\\text{SeDID}_{\\text{Stat}}$ and neural network-based $\\text{SeDID}_{\\text{NNs}}$, SeDID exploits the unique attributes of diffusion models, namely deterministic reverse and deterministic denoising computation errors.","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.102280325,"dev-research":0.3718818437,"prompt-eng":0.4184678246,"data-quality":0.1553271417,"ml-security":0.2329225756}}
{"text":"Our evaluations demonstrate SeDID's superior performance over existing methods when applied to diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.078357693,"dev-research":0.3714450707,"prompt-eng":0.4215416588,"data-quality":0.0813090781,"ml-security":0.1047269591}}
{"text":"Thus, our work makes a pivotal contribution to distinguishing diffusion model-generated images, marking a significant step in the domain of artificial intelligence security.","meta":{"url":"http://arxiv.org/abs/2307.06272v1"},"cats":{"new-dataset":0.1525898234,"dev-research":0.4166373156,"prompt-eng":0.4617718481,"data-quality":0.1293321916,"ml-security":0.4889711402}}
{"text":"This paper presents a digital simulation method for the hobbing process of cylindrical gears.","meta":{"url":"http://arxiv.org/abs/2307.06270v1"},"cats":{"new-dataset":0.0789313276,"dev-research":0.3909860542,"prompt-eng":0.4297957645,"data-quality":0.0924775514,"ml-security":0.0547759967}}
{"text":"Based on the gear generation principle, taking the professional software as the tool, the problem of virtual hobbing simulation on involute helical gears was studied, and the virtual hobbing simulation of hobbing on the whole gear was completed by using macros of CATIA V5.","meta":{"url":"http://arxiv.org/abs/2307.06270v1"},"cats":{"new-dataset":0.06946491,"dev-research":0.4235335852,"prompt-eng":0.4523391146,"data-quality":0.0834299925,"ml-security":0.0475106341}}
{"text":"The validity of this method was validated by analyzing the tooth surface accuracy error of the model which was below 0.001 mm between the virtual tooth surface and the theoretical tooth surface and the possible factors that affected the tooth surface accuracy during manufacturing were also carried on the discussion.","meta":{"url":"http://arxiv.org/abs/2307.06270v1"},"cats":{"new-dataset":0.0459735879,"dev-research":0.400766955,"prompt-eng":0.3756429084,"data-quality":0.1535154376,"ml-security":0.055098137}}
{"text":"It offers a fictitious three-D platform for studying the principle of manufacture errors of a gear-cutting machine as well as the finite element analysis between the ideal tooth surface and the erroneous tooth surface.","meta":{"url":"http://arxiv.org/abs/2307.06270v1"},"cats":{"new-dataset":0.1201258628,"dev-research":0.4138685242,"prompt-eng":0.3731626623,"data-quality":0.1113709138,"ml-security":0.0546842565}}
{"text":"Well-calibrated traffic flow models are fundamental to understanding traffic phenomena and designing control strategies.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.0956303846,"dev-research":0.3801049196,"prompt-eng":0.4265539389,"data-quality":0.0906584403,"ml-security":0.1516093624}}
{"text":"Traditional calibration has been developed base on optimization methods.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.0891539381,"dev-research":0.3871649435,"prompt-eng":0.402803805,"data-quality":0.1463793118,"ml-security":0.0761403995}}
{"text":"In this paper, we propose a novel physics-informed, learning-based calibration approach that achieves performances comparable to and even better than those of optimization-based methods.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.1629104523,"dev-research":0.3562877216,"prompt-eng":0.4371379462,"data-quality":0.1879348594,"ml-security":0.115919785}}
{"text":"To this end, we combine the classical deep autoencoder, an unsupervised machine learning model consisting of one encoder and one decoder, with traffic flow models.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.2040084783,"dev-research":0.3802775962,"prompt-eng":0.4754301752,"data-quality":0.1227111932,"ml-security":0.2298767183}}
{"text":"Our approach informs the decoder of the physical traffic flow models and thus induces the encoder to yield reasonable traffic parameters given flow and speed measurements.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.1278052611,"dev-research":0.3981435162,"prompt-eng":0.4241708454,"data-quality":0.086295808,"ml-security":0.1523513845}}
{"text":"We also introduce the denoising autoencoder into our method so that it can handles not only with normal data but also with corrupted data with missing values.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.1485428822,"dev-research":0.3827858234,"prompt-eng":0.425202282,"data-quality":0.5357214166,"ml-security":0.2109507895}}
{"text":"We verified our approach with a case study of I-210 E in California.","meta":{"url":"http://arxiv.org/abs/2307.06267v1"},"cats":{"new-dataset":0.2360868238,"dev-research":0.4250066031,"prompt-eng":0.4661596119,"data-quality":0.1290266162,"ml-security":0.1070424705}}
{"text":"Digitized histopathology glass slides, known as Whole Slide Images (WSIs), are often several gigapixels large and contain sensitive metadata information, which makes distributed processing unfeasible.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.2298935848,"dev-research":0.3855663449,"prompt-eng":0.4379519356,"data-quality":0.1134534996,"ml-security":0.128200724}}
{"text":"Moreover, artifacts in WSIs may result in unreliable predictions when directly applied by Deep Learning (DL) algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.0632863639,"dev-research":0.3818906244,"prompt-eng":0.4386458203,"data-quality":0.4071085496,"ml-security":0.2745108013}}
{"text":"Therefore, preprocessing WSIs is beneficial, e.g., eliminating privacy-sensitive information, splitting a gigapixel medical image into tiles, and removing the diagnostically irrelevant areas.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.0713836907,"dev-research":0.4371504563,"prompt-eng":0.4000005835,"data-quality":0.066544546,"ml-security":0.1484608636}}
{"text":"This work proposes a cloud service to parallelize the preprocessing pipeline for large medical images.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.2398711303,"dev-research":0.3709696067,"prompt-eng":0.4141860565,"data-quality":0.0625830731,"ml-security":0.0917589133}}
{"text":"The data and model parallelization will not only boost the end-to-end processing efficiency for histological tasks but also secure the reconstruction of WSI by randomly distributing tiles across processing nodes.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.1663284648,"dev-research":0.3939869284,"prompt-eng":0.4064925881,"data-quality":0.0527505254,"ml-security":0.1341142146}}
{"text":"Furthermore, the initial steps of the pipeline will be integrated into the Jupyter-based Virtual Research Environment (VRE) to enable image owners to configure and automate the execution process based on resource allocation.","meta":{"url":"http://arxiv.org/abs/2307.06266v1"},"cats":{"new-dataset":0.1644415014,"dev-research":0.4083649839,"prompt-eng":0.4661945766,"data-quality":0.0855658699,"ml-security":0.0601384998}}
{"text":"Population-based structural health monitoring (PBSHM) aims to share valuable information among members of a population, such as normal- and damage-condition data, to improve inferences regarding the health states of the members.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.23705077,"dev-research":0.384826224,"prompt-eng":0.4408863653,"data-quality":0.0860434493,"ml-security":0.1659150789}}
{"text":"Even when the population is comprised of nominally-identical structures, benign variations among the members will exist as a result of slight differences in material properties, geometry, boundary conditions, or environmental effects (e.g., temperature changes).","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.0751275894,"dev-research":0.3905922866,"prompt-eng":0.4000094873,"data-quality":0.1193138314,"ml-security":0.1067075004}}
{"text":"These discrepancies can affect modal properties and present as changes in the characteristics of the resonance peaks of the frequency response function (FRF).","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.083448098,"dev-research":0.3823659111,"prompt-eng":0.4541595691,"data-quality":0.1868327941,"ml-security":0.0644653356}}
{"text":"Many SHM strategies depend on monitoring the dynamic properties of structures, so benign variations can be challenging for the practical implementation of these systems.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.0348256288,"dev-research":0.3725895678,"prompt-eng":0.4383886309,"data-quality":0.0774359184,"ml-security":0.1316816563}}
{"text":"Another common challenge with vibration-based SHM is data loss, which may result from transmission issues, sensor failure, a sample-rate mismatch between sensors, and other causes.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.1256610895,"dev-research":0.3638664548,"prompt-eng":0.468446427,"data-quality":0.2355126609,"ml-security":0.2271054637}}
{"text":"Missing data in the time domain will result in decreased resolution in the frequency domain, which can impair dynamic characterisation.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.0857352489,"dev-research":0.3808511859,"prompt-eng":0.4055192333,"data-quality":0.2445689115,"ml-security":0.1325061252}}
{"text":"The hierarchical Bayesian approach provides a useful modelling structure for PBSHM, because statistical distributions at the population and individual (or domain) level are learnt simultaneously to bolster statistical strength among the parameters.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.11192628,"dev-research":0.3865494023,"prompt-eng":0.4950901866,"data-quality":0.0702263938,"ml-security":0.0828734553}}
{"text":"As a result, variance is reduced among the parameter estimates, particularly when data are limited.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.1051856715,"dev-research":0.3875344085,"prompt-eng":0.4003884231,"data-quality":0.1071213912,"ml-security":0.1449620241}}
{"text":"In this paper, combined probabilistic FRF models are developed for a small population of nominally-identical helicopter blades under varying temperature conditions, using a hierarchical Bayesian structure.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.1632553859,"dev-research":0.3566586202,"prompt-eng":0.4739259213,"data-quality":0.0658527385,"ml-security":0.104602286}}
{"text":"These models address critical challenges in SHM, by accommodating benign variations that present as differences in the underlying dynamics, while also considering (and utilising), the similarities among the blades.","meta":{"url":"http://arxiv.org/abs/2307.06263v1"},"cats":{"new-dataset":0.0393257262,"dev-research":0.3982837944,"prompt-eng":0.4310849854,"data-quality":0.0573091413,"ml-security":0.1120952478}}
{"text":"To accommodate various use cases with differing characteristics, the Fifth Generation (5G) mobile communications system intends to utilize network slicing.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.079478899,"dev-research":0.4421413254,"prompt-eng":0.388349455,"data-quality":0.0790041284,"ml-security":0.1342319869}}
{"text":"Network slicing enables the creation of multiple logical networks over a shared physical network infrastructure.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0650409979,"dev-research":0.4560675737,"prompt-eng":0.3901715456,"data-quality":0.0712193004,"ml-security":0.1685626331}}
{"text":"While the problems such as resource allocation for multiple slices in mobile networks have been explored in considerable detail in the existing literature, the suitability of the existing mobile network architecture to support network slicing has not been analysed adequately.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0793402697,"dev-research":0.3916589778,"prompt-eng":0.358008615,"data-quality":0.0824677649,"ml-security":0.1431933642}}
{"text":"We think the existing 5G System (5GS) architecture suffers from certain limitations, such as a lack of slice isolation in its control plane.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0427467181,"dev-research":0.3830696933,"prompt-eng":0.3514990229,"data-quality":0.0625922929,"ml-security":0.1692694676}}
{"text":"This work focuses on the future evolution of the existing 5GS architecture from a slicing perspective, especially that of its control plane, addressing some of the limitations of the existing 5GS architecture.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.088691522,"dev-research":0.4072099227,"prompt-eng":0.3941762496,"data-quality":0.0441389544,"ml-security":0.112030182}}
{"text":"We propose a new network architecture which enables efficient slicing in beyond 5G networks.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.1024626464,"dev-research":0.4021365571,"prompt-eng":0.3592869434,"data-quality":0.0704680162,"ml-security":0.1541870388}}
{"text":"The proposed architecture results in enhanced modularity and scalability of the control plane in sliced mobile networks.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0593022549,"dev-research":0.4043919133,"prompt-eng":0.3626903716,"data-quality":0.0519976817,"ml-security":0.1499702864}}
{"text":"In addition, it also brings slice isolation to the control plane, which is not feasible in the existing 5G system.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0381476367,"dev-research":0.3965145724,"prompt-eng":0.3546206467,"data-quality":0.0722067054,"ml-security":0.1381608953}}
{"text":"We also present a performance evaluation that confirms the improved performance and scalability of the proposed system viz a viz the existing 5G system.","meta":{"url":"http://arxiv.org/abs/2307.06262v1"},"cats":{"new-dataset":0.0931569169,"dev-research":0.3880124139,"prompt-eng":0.3853699614,"data-quality":0.0857834918,"ml-security":0.0906542297}}
{"text":"Soft slender robots have attracted more and more research attentions in these years due to their continuity and compliance natures.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.0656698331,"dev-research":0.3859697232,"prompt-eng":0.4059959301,"data-quality":0.0746418755,"ml-security":0.0924319042}}
{"text":"However, mechanics modeling for soft robots interacting with environment is still an academic challenge because of the non-linearity of deformation and the non-smooth property of the contacts.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.1045655647,"dev-research":0.3957280287,"prompt-eng":0.4011537807,"data-quality":0.0868269232,"ml-security":0.1123111176}}
{"text":"In this work, starting from a piece-wise local strain field assumption, we propose a nonlinear dynamic model for soft robot via Cosserat rod theory using Newtonian mechanics which handles the frictional contact with environment and transfer them into the nonlinear complementary constraint (NCP) formulation.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.113384885,"dev-research":0.3905715872,"prompt-eng":0.3871904213,"data-quality":0.0783885938,"ml-security":0.0791381234}}
{"text":"Moreover, we smooth both the contact and friction constraints in order to convert the inequality equations of NCP to the smooth equality equations.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.1308952666,"dev-research":0.4313979237,"prompt-eng":0.3667909976,"data-quality":0.0621201861,"ml-security":0.0742558191}}
{"text":"The proposed model allows us to compute the dynamic deformation and frictional contact force under common optimization framework in real time when the soft slender robot interacts with other rigid or soft bodies.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.1412030862,"dev-research":0.3719468582,"prompt-eng":0.3822039748,"data-quality":0.0523587505,"ml-security":0.0915392112}}
{"text":"In the end, the corresponding experiments are carried out which valid our proposed dynamic model.","meta":{"url":"http://arxiv.org/abs/2307.06261v1"},"cats":{"new-dataset":0.0695572958,"dev-research":0.3773374849,"prompt-eng":0.4555120208,"data-quality":0.0824278879,"ml-security":0.1315436178}}
{"text":"Gastrointestinal endoscopy is a medical procedure that utilizes a flexible tube equipped with a camera and other instruments to examine the digestive tract.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.1985783272,"dev-research":0.3955731424,"prompt-eng":0.4319570131,"data-quality":0.1050479258,"ml-security":0.0737307391}}
{"text":"This minimally invasive technique allows for diagnosing and managing various gastrointestinal conditions, including inflammatory bowel disease, gastrointestinal bleeding, and colon cancer.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.0776607893,"dev-research":0.4202038596,"prompt-eng":0.389600579,"data-quality":0.0905436381,"ml-security":0.0878258603}}
{"text":"The early detection and identification of lesions in the upper gastrointestinal tract and the identification of malignant polyps that may pose a risk of cancer development are critical components of gastrointestinal endoscopy's diagnostic and therapeutic applications.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.1729578547,"dev-research":0.3983583729,"prompt-eng":0.445475125,"data-quality":0.1629371349,"ml-security":0.1339923922}}
{"text":"Therefore, enhancing the detection rates of gastrointestinal disorders can significantly improve a patient's prognosis by increasing the likelihood of timely medical intervention, which may prolong the patient's lifespan and improve overall health outcomes.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.0951715442,"dev-research":0.438469206,"prompt-eng":0.4358345928,"data-quality":0.1196782641,"ml-security":0.1410970738}}
{"text":"This paper presents a novel Transformer-based deep neural network designed to perform multiple tasks simultaneously, thereby enabling accurate identification of both upper gastrointestinal tract lesions and colon polyps.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.2016201437,"dev-research":0.3402986884,"prompt-eng":0.4307540766,"data-quality":0.117205558,"ml-security":0.1457011824}}
{"text":"Our approach proposes a unique global context-aware module and leverages the powerful MiT backbone, along with a feature alignment block, to enhance the network's representation capability.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.1045922688,"dev-research":0.4478324396,"prompt-eng":0.4940069264,"data-quality":0.1416291048,"ml-security":0.1389787303}}
{"text":"This novel design leads to a significant improvement in performance across various endoscopic diagnosis tasks.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.0655635737,"dev-research":0.3970751009,"prompt-eng":0.4057489551,"data-quality":0.08789272,"ml-security":0.0664612537}}
{"text":"Extensive experiments demonstrate the superior performance of our method compared to other state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2307.06260v1"},"cats":{"new-dataset":0.0335877952,"dev-research":0.3897531526,"prompt-eng":0.3946476327,"data-quality":0.1169101568,"ml-security":0.0679386586}}
{"text":"Automated driving systems can be helpful in a wide range of societal challenges, e.g., mobility-on-demand and transportation logistics for last-mile delivery, by aiding the vehicle driver or taking over the responsibility for the dynamic driving task partially or completely.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.1193224646,"dev-research":0.4335741012,"prompt-eng":0.4562421664,"data-quality":0.1085799944,"ml-security":0.1446731285}}
{"text":"Ensuring the safety of automated driving systems is no trivial task, even more so for those systems of SAE Level 3 or above.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.0652133839,"dev-research":0.4314423354,"prompt-eng":0.4067980026,"data-quality":0.1359637451,"ml-security":0.2342409235}}
{"text":"To achieve this, mechanisms are needed that can continuously monitor the system's operating conditions, also denoted as the system's operational design domain.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.0813882859,"dev-research":0.4939064046,"prompt-eng":0.4589535565,"data-quality":0.0536332773,"ml-security":0.1259765181}}
{"text":"This paper presents a safety concept for automated driving systems which uses a combination of onboard runtime monitoring via connected dependability cage and off-board runtime monitoring via a remote command control center, to continuously monitor the system's ODD.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.1894367415,"dev-research":0.436091864,"prompt-eng":0.4704886172,"data-quality":0.1572894818,"ml-security":0.226860558}}
{"text":"On one side, the connected dependability cage fulfills a double functionality: (1) to monitor continuously the operational design domain of the automated driving system, and (2) to transfer the responsibility in a smooth and safe manner between the automated driving system and the off-board remote safety driver, who is present in the remote command control center.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.0746529193,"dev-research":0.4540115568,"prompt-eng":0.4539997305,"data-quality":0.1112676561,"ml-security":0.1575793573}}
{"text":"On the other side, the remote command control center enables the remote safety driver the monitoring and takeover of the vehicle's control.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.1526887955,"dev-research":0.4688458637,"prompt-eng":0.4759997381,"data-quality":0.0881046539,"ml-security":0.1847612674}}
{"text":"We evaluate our safety concept for automated driving systems in a lab environment and on a test field track and report on results and lessons learned.","meta":{"url":"http://arxiv.org/abs/2307.06258v1"},"cats":{"new-dataset":0.2723385893,"dev-research":0.4408886475,"prompt-eng":0.4773627639,"data-quality":0.223620432,"ml-security":0.2300146785}}
{"text":"The tongue surface houses a range of papillae that are integral to the mechanics and chemistry of taste and textural sensation.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1127087026,"dev-research":0.3996539805,"prompt-eng":0.4264855816,"data-quality":0.0719556616,"ml-security":0.0802787448}}
{"text":"Although gustatory function of papillae is well investigated, the uniqueness of papillae within and across individuals remains elusive.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.0844234029,"dev-research":0.3811013037,"prompt-eng":0.4224601293,"data-quality":0.0870480461,"ml-security":0.0942545305}}
{"text":"Here, we present the first machine learning framework on 3D microscopic scans of human papillae (n = 2092), uncovering the uniqueness of geometric and topological features of papillae.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.2097677171,"dev-research":0.3567108699,"prompt-eng":0.3969375853,"data-quality":0.0743946353,"ml-security":0.1135784419}}
{"text":"The finer differences in shapes of papillae are investigated computationally based on a number of features derived from discrete differential geometry and computational topology.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.0733574715,"dev-research":0.373169275,"prompt-eng":0.3382761855,"data-quality":0.0625828199,"ml-security":0.0625340291}}
{"text":"Interpretable machine learning techniques show that persistent homology features of the papillae shape are the most effective in predicting the biological variables.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1432030825,"dev-research":0.3698159263,"prompt-eng":0.4223370839,"data-quality":0.1633037702,"ml-security":0.125710672}}
{"text":"Models trained on these features with small volumes of data samples predict the type of papillae with an accuracy of 85%.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1443830612,"dev-research":0.3453889818,"prompt-eng":0.4742274439,"data-quality":0.2171264113,"ml-security":0.1230837373}}
{"text":"The papillae type classification models can map the spatial arrangement of filiform and fungiform papillae on a surface.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1927599264,"dev-research":0.3716590317,"prompt-eng":0.4235244286,"data-quality":0.1204989304,"ml-security":0.088790789}}
{"text":"Remarkably, the papillae are found to be distinctive across individuals and an individual can be identified with an accuracy of 48% among the 15 participants from a single papillae.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1496026988,"dev-research":0.3548349992,"prompt-eng":0.4597328323,"data-quality":0.1742120172,"ml-security":0.0766420147}}
{"text":"Collectively, this is the first unprecedented evidence demonstrating that tongue papillae can serve as a unique identifier inspiring new research direction for food preferences and oral diagnostics.","meta":{"url":"http://arxiv.org/abs/2307.06255v1"},"cats":{"new-dataset":0.1379750419,"dev-research":0.4016116053,"prompt-eng":0.4463334555,"data-quality":0.1770454381,"ml-security":0.1318780589}}
{"text":"Target tracking plays a crucial role in real-world scenarios, particularly in drug-trafficking interdiction, where the knowledge of an adversarial target's location is often limited.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.1260684163,"dev-research":0.4018840498,"prompt-eng":0.4342141528,"data-quality":0.1765939645,"ml-security":0.5702592011}}
{"text":"Improving autonomous tracking systems will enable unmanned aerial, surface, and underwater vehicles to better assist in interdicting smugglers that use manned surface, semi-submersible, and aerial vessels.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.1302042431,"dev-research":0.4066548827,"prompt-eng":0.4212902001,"data-quality":0.0906558968,"ml-security":0.150144969}}
{"text":"As unmanned drones proliferate, accurate autonomous target estimation is even more crucial for security and safety.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.0650329635,"dev-research":0.4009232031,"prompt-eng":0.4195130622,"data-quality":0.1702858171,"ml-security":0.4503507773}}
{"text":"This paper presents Constrained Agent-based Diffusion for Enhanced Multi-Agent Tracking (CADENCE), an approach aimed at generating comprehensive predictions of adversary locations by leveraging past sparse state information.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.0914004841,"dev-research":0.3785352573,"prompt-eng":0.438663656,"data-quality":0.1027524608,"ml-security":0.3797142735}}
{"text":"To assess the effectiveness of this approach, we evaluate predictions on single-target and multi-target pursuit environments, employing Monte-Carlo sampling of the diffusion model to estimate the probability associated with each generated trajectory.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.0667449742,"dev-research":0.3373597985,"prompt-eng":0.4654541486,"data-quality":0.0812599677,"ml-security":0.1684842503}}
{"text":"We propose a novel cross-attention based diffusion model that utilizes constraint-based sampling to generate multimodal track hypotheses.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.1964176582,"dev-research":0.3576584864,"prompt-eng":0.5173759399,"data-quality":0.148850379,"ml-security":0.0670163229}}
{"text":"Our single-target model surpasses the performance of all baseline methods on Average Displacement Error (ADE) for predictions across all time horizons.","meta":{"url":"http://arxiv.org/abs/2307.06244v1"},"cats":{"new-dataset":0.0562096307,"dev-research":0.3594842103,"prompt-eng":0.4456735788,"data-quality":0.1432276547,"ml-security":0.1050204996}}
{"text":"The continuous representation of spatiotemporal data commonly relies on using abstract data types, such as \\textit{moving regions}, to represent entities whose shape and position continuously change over time.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.3225062855,"dev-research":0.3991944898,"prompt-eng":0.3903372366,"data-quality":0.0884594727,"ml-security":0.0786364136}}
{"text":"Creating this representation from discrete snapshots of real-world entities requires using interpolation methods to compute in-between data representations and estimate the position and shape of the object of interest at arbitrary temporal points.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.3454798952,"dev-research":0.3783805141,"prompt-eng":0.3799567626,"data-quality":0.0713285388,"ml-security":0.0630278174}}
{"text":"Existing region interpolation methods often fail to generate smooth and realistic representations of a region's evolution.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.1259550797,"dev-research":0.3748285438,"prompt-eng":0.3796474781,"data-quality":0.1821832935,"ml-security":0.0865547209}}
{"text":"However, recent advancements in deep learning techniques have revealed the potential of deep models trained on discrete observations to capture spatiotemporal dependencies through implicit feature learning.   ","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.1727043042,"dev-research":0.3791189073,"prompt-eng":0.4615949429,"data-quality":0.1636711044,"ml-security":0.2205510221}}
{"text":"In this work, we explore the capabilities of Conditional Variational Autoencoder (C-VAE) models to generate smooth and realistic representations of the spatiotemporal evolution of moving regions.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.152088674,"dev-research":0.3945185707,"prompt-eng":0.4539966551,"data-quality":0.0867021256,"ml-security":0.0594089862}}
{"text":"We evaluate our proposed approach on a sparsely annotated dataset on the burnt area of a forest fire.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.3738431043,"dev-research":0.4208408859,"prompt-eng":0.4388235762,"data-quality":0.3705699116,"ml-security":0.1142145458}}
{"text":"We apply compression operations to sample from the dataset and use the C-VAE model and other commonly used interpolation algorithms to generate in-between region representations.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.3028143331,"dev-research":0.3552446553,"prompt-eng":0.4292783044,"data-quality":0.1864443429,"ml-security":0.0746554295}}
{"text":"To evaluate the performance of the methods, we compare their interpolation results with manually annotated data and regions generated by a U-Net model.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.1601193004,"dev-research":0.4197510092,"prompt-eng":0.4513837494,"data-quality":0.1814117414,"ml-security":0.0773360301}}
{"text":"We also assess the quality of generated data considering temporal consistency metrics.   ","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.2746443068,"dev-research":0.4381726167,"prompt-eng":0.4698154175,"data-quality":0.301306075,"ml-security":0.0674893727}}
{"text":"The proposed C-VAE-based approach demonstrates competitive results in geometric similarity metrics.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.0569115833,"dev-research":0.3850091594,"prompt-eng":0.3741726746,"data-quality":0.111971378,"ml-security":0.0387582461}}
{"text":"It also exhibits superior temporal consistency, suggesting that C-VAE models may be a viable alternative to modelling the spatiotemporal evolution of 2D moving regions.","meta":{"url":"http://arxiv.org/abs/2307.06243v1"},"cats":{"new-dataset":0.0527954994,"dev-research":0.3713032868,"prompt-eng":0.3876413576,"data-quality":0.0655398493,"ml-security":0.0491090728}}
{"text":"Ongoing research and experiments have enabled quantum memory to realize the storage of qubits.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.133785912,"dev-research":0.3902340164,"prompt-eng":0.4187647523,"data-quality":0.0594465744,"ml-security":0.1248904809}}
{"text":"On the other hand, interleaving techniques are used to deal with burst of errors.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.0319867479,"dev-research":0.45521898,"prompt-eng":0.4492619528,"data-quality":0.3864961511,"ml-security":0.1305516655}}
{"text":"Effective interleaving techniques for combating burst of errors by using classical error-correcting codes have been proposed in several articles found in the literature, however, to the best of our knowledge, little is known regarding interleaving techniques for combating clusters of errors in topological quantum error-correcting codes.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.0517524872,"dev-research":0.4111969615,"prompt-eng":0.4212566819,"data-quality":0.4308814943,"ml-security":0.1638214598}}
{"text":"Motivated by that, in this work, we present new three and four-dimensional toric quantum codes which are featured by lattice codes and apply a quantum interleaving method to such new three and four-dimensional toric quantum codes.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.0962971288,"dev-research":0.4020425939,"prompt-eng":0.3965843414,"data-quality":0.0860997187,"ml-security":0.1108604498}}
{"text":"By applying such a method to these new codes we provide new three and four-dimensional quantum burst-error-correcting codes.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.1170775999,"dev-research":0.4236036974,"prompt-eng":0.4045494514,"data-quality":0.2254944642,"ml-security":0.1285206018}}
{"text":"As a consequence, new three and four-dimensional toric and burst-error-correcting quantum codes are obtained which have better information rates than those three and four-dimensional toric quantum codes from the literature.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.0893429192,"dev-research":0.3917624603,"prompt-eng":0.3976197917,"data-quality":0.1365103703,"ml-security":0.1315675151}}
{"text":"In addition to these proposed three and four-dimensional quantum burst-error-correcting codes improve such information rates, they can be used for burst-error-correction in errors which are located, quantum data stored and quantum channels with memory.","meta":{"url":"http://arxiv.org/abs/2307.06241v1"},"cats":{"new-dataset":0.1367975189,"dev-research":0.4088503217,"prompt-eng":0.4209144033,"data-quality":0.2404272339,"ml-security":0.1480529637}}
{"text":"The Drone Swarm Search project is an environment, based on PettingZoo, that is to be used in conjunction with multi-agent (or single-agent) reinforcement learning algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06240v1"},"cats":{"new-dataset":0.1066376898,"dev-research":0.4322986316,"prompt-eng":0.4455900727,"data-quality":0.054547542,"ml-security":0.1327354042}}
{"text":"It is an environment in which the agents (drones), have to find the targets (shipwrecked people).","meta":{"url":"http://arxiv.org/abs/2307.06240v1"},"cats":{"new-dataset":0.1655635784,"dev-research":0.4444089088,"prompt-eng":0.4087422667,"data-quality":0.1059785749,"ml-security":0.202623964}}
{"text":"The agents do not know the position of the target and do not receive rewards related to their own distance to the target(s).","meta":{"url":"http://arxiv.org/abs/2307.06240v1"},"cats":{"new-dataset":0.0716758723,"dev-research":0.4209708017,"prompt-eng":0.4038080624,"data-quality":0.133519007,"ml-security":0.2053150365}}
{"text":"However, the agents receive the probabilities of the target(s) being in a certain cell of the map.","meta":{"url":"http://arxiv.org/abs/2307.06240v1"},"cats":{"new-dataset":0.088310154,"dev-research":0.4111006257,"prompt-eng":0.4395345214,"data-quality":0.1166668797,"ml-security":0.2084358108}}
{"text":"The aim of this project is to aid in the study of reinforcement learning algorithms that require dynamic probabilities as inputs.","meta":{"url":"http://arxiv.org/abs/2307.06240v1"},"cats":{"new-dataset":0.0975124939,"dev-research":0.3989015148,"prompt-eng":0.4667484362,"data-quality":0.0838201764,"ml-security":0.2773552368}}
{"text":"Self-supervised molecular representation learning is critical for molecule-based tasks such as AI-assisted drug discovery.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.1603279607,"dev-research":0.4151503395,"prompt-eng":0.4603602811,"data-quality":0.1937911292,"ml-security":0.1837308707}}
{"text":"Recent studies consider leveraging both 2D and 3D information for representation learning, with straightforward alignment strategies that treat each modality separately.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.1665396488,"dev-research":0.3849697106,"prompt-eng":0.4408306436,"data-quality":0.114104737,"ml-security":0.1080520311}}
{"text":"In this work, we introduce a novel \"blend-then-predict\" self-supervised learning method (MoleBLEND), which blends atom relations from different modalities into one unified relation matrix for encoding, then recovers modality-specific information for both 2D and 3D structures.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.1749588814,"dev-research":0.387840476,"prompt-eng":0.4755909,"data-quality":0.1621828334,"ml-security":0.108224387}}
{"text":"By treating atom relationships as anchors, seemingly dissimilar 2D and 3D manifolds are aligned and integrated at fine-grained relation-level organically.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.0617188936,"dev-research":0.4141283767,"prompt-eng":0.389054634,"data-quality":0.0731461009,"ml-security":0.0600305982}}
{"text":"Extensive experiments show that MoleBLEND achieves state-of-the-art performance across major 2D/3D benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.0764589488,"dev-research":0.3828777927,"prompt-eng":0.3651648036,"data-quality":0.0701426559,"ml-security":0.0815909729}}
{"text":"We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (inter-modal prediction) and mask-then-predict (intra-modal prediction) objectives into a single cohesive blend-then-predict framework.","meta":{"url":"http://arxiv.org/abs/2307.06235v1"},"cats":{"new-dataset":0.070734476,"dev-research":0.3903526349,"prompt-eng":0.4708926247,"data-quality":0.1024302417,"ml-security":0.1085894688}}
{"text":"Poetry holds immense significance within the cultural and traditional fabric of any nation.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.3172773064,"dev-research":0.4389548565,"prompt-eng":0.4017337163,"data-quality":0.1382872996,"ml-security":0.0577689517}}
{"text":"It serves as a vehicle for poets to articulate their emotions, preserve customs, and convey the essence of their culture.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.2035283538,"dev-research":0.4582923348,"prompt-eng":0.4390395279,"data-quality":0.190053848,"ml-security":0.0833978982}}
{"text":"Arabic poetry is no exception, having played a cherished role in the heritage of the Arabic community throughout history and maintaining its relevance in the present era.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.2187226106,"dev-research":0.4200378956,"prompt-eng":0.3840767449,"data-quality":0.1794385292,"ml-security":0.1113843042}}
{"text":"Typically, comprehending Arabic poetry necessitates the expertise of a linguist who can analyze its content and assess its quality.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.170660826,"dev-research":0.456832173,"prompt-eng":0.4738633191,"data-quality":0.2976091263,"ml-security":0.0675382828}}
{"text":"This paper presents the introduction of a framework called \\textit{Ashaar} https://github.com/ARBML/Ashaar, which encompasses a collection of datasets and pre-trained models designed specifically for the analysis and generation of Arabic poetry.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.5476883347,"dev-research":0.4438238056,"prompt-eng":0.5233367732,"data-quality":0.266187794,"ml-security":0.1278970262}}
{"text":"The pipeline established within our proposed approach encompasses various aspects of poetry, such as meter, theme, and era classification.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.2048472721,"dev-research":0.4292988253,"prompt-eng":0.463349567,"data-quality":0.2136615805,"ml-security":0.0559434435}}
{"text":"It also incorporates automatic poetry diacritization, enabling more intricate analyses like automated extraction of the \\textit{Arudi} style.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.1999734453,"dev-research":0.4723737469,"prompt-eng":0.5268563862,"data-quality":0.3181399226,"ml-security":0.0636105732}}
{"text":"Additionally, we explore the feasibility of generating conditional poetry through the pre-training of a character-based GPT model.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.2193667966,"dev-research":0.4322861524,"prompt-eng":0.5542348946,"data-quality":0.1668829246,"ml-security":0.0934549475}}
{"text":"Furthermore, as part of this endeavor, we provide four datasets: one for poetry generation, another for diacritization, and two for Arudi-style prediction.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.6237799196,"dev-research":0.3891740105,"prompt-eng":0.5288137068,"data-quality":0.3068205891,"ml-security":0.1000708885}}
{"text":"These datasets aim to facilitate research and development in the field of Arabic poetry by enabling researchers and enthusiasts to delve into the nuances of this rich literary tradition.","meta":{"url":"http://arxiv.org/abs/2307.06218v1"},"cats":{"new-dataset":0.6671729632,"dev-research":0.4265663004,"prompt-eng":0.4420411521,"data-quality":0.2117266525,"ml-security":0.1481204137}}
{"text":"The COVID-19 pandemic has prompted countries around the world to introduce smartphone apps to support disease control efforts.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.2460722428,"dev-research":0.4588406519,"prompt-eng":0.4652743777,"data-quality":0.0562962768,"ml-security":0.1691237902}}
{"text":"Their purposes range from digital contact tracing to quarantine enforcement to vaccination passports, and their effectiveness often depends on widespread adoption.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.1667505912,"dev-research":0.4518705431,"prompt-eng":0.4481279435,"data-quality":0.0710883494,"ml-security":0.3019644965}}
{"text":"While previous work has identified factors that promote or hinder adoption, it has typically examined data collected at a single point in time or focused exclusively on digital contact tracing apps.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.1988177992,"dev-research":0.4702500886,"prompt-eng":0.4503547822,"data-quality":0.0896270598,"ml-security":0.1715335546}}
{"text":"In this work, we conduct the first representative study that examines changes in people's attitudes towards COVID-19-related smartphone apps for five different purposes over the first 1.5 years of the pandemic.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.3357717486,"dev-research":0.4842543407,"prompt-eng":0.4638797355,"data-quality":0.0889227177,"ml-security":0.1594060878}}
{"text":"In three survey rounds conducted between Summer 2020 and Summer 2021 in the United States and Germany, with approximately 1,000 participants per round and country, we investigate people's willingness to use such apps, their perceived utility, and people's attitudes towards them in different stages of the pandemic.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.3337188942,"dev-research":0.4655264596,"prompt-eng":0.4876778178,"data-quality":0.0737082387,"ml-security":0.2074578859}}
{"text":"Our results indicate that privacy is a consistent concern for participants, even in a public health crisis, and the collection of identity-related data significantly decreases acceptance of COVID-19 apps.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.3503707453,"dev-research":0.435365943,"prompt-eng":0.4175189622,"data-quality":0.1467341073,"ml-security":0.4562147051}}
{"text":"Trust in authorities is essential to increase confidence in government-backed apps and foster citizens' willingness to contribute to crisis management.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.2059819527,"dev-research":0.4579896884,"prompt-eng":0.4835869286,"data-quality":0.1228287373,"ml-security":0.2960564777}}
{"text":"There is a need for continuous communication with app users to emphasize the benefits of health crisis apps both for individuals and society, thus counteracting decreasing willingness to use them and perceived usefulness as the pandemic evolves.","meta":{"url":"http://arxiv.org/abs/2307.06214v1"},"cats":{"new-dataset":0.2408914993,"dev-research":0.4661873653,"prompt-eng":0.4384176637,"data-quality":0.0767770769,"ml-security":0.2341625173}}
{"text":"Information retrieval systems retrieves relevant documents based on a query submitted by the user.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1906697847,"dev-research":0.4691121784,"prompt-eng":0.5270585423,"data-quality":0.1331979395,"ml-security":0.129462475}}
{"text":"The documents are initially indexed and the words in the documents are assigned weights using a weighting technique called TFIDF which is the product of Term Frequency (TF) and Inverse Document Frequency (IDF).","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1347675013,"dev-research":0.4168729497,"prompt-eng":0.4738232387,"data-quality":0.2265988313,"ml-security":0.0894639703}}
{"text":"TF represents the number of occurrences of a term in a document.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.2445065776,"dev-research":0.4547769063,"prompt-eng":0.4595978504,"data-quality":0.1947928338,"ml-security":0.0702992853}}
{"text":"IDF measures whether the term is common or rare across all documents.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1714543504,"dev-research":0.4080078838,"prompt-eng":0.4654111615,"data-quality":0.2856328018,"ml-security":0.1033103906}}
{"text":"It is computed by dividing the total number of documents in the system by the number of documents containing the term and then computing the logarithm of the quotient.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1367362734,"dev-research":0.4350095567,"prompt-eng":0.4039232729,"data-quality":0.1253525259,"ml-security":0.0954268397}}
{"text":"By default, we use base 10 to calculate the logarithm.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1005166937,"dev-research":0.421498001,"prompt-eng":0.3972902761,"data-quality":0.1002136136,"ml-security":0.1074767883}}
{"text":"In this paper, we are going to test this weighting technique by using a range of log bases from 0.1 to 100.0 to calculate the IDF.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.1084386842,"dev-research":0.3830041289,"prompt-eng":0.4407140071,"data-quality":0.1576651901,"ml-security":0.0976334874}}
{"text":"Testing different log bases for vector model weighting technique is to highlight the importance of understanding the performance of the system at different weighting values.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.0384127925,"dev-research":0.4037311918,"prompt-eng":0.4432149638,"data-quality":0.0994166731,"ml-security":0.127907039}}
{"text":"We use the documents of MED, CRAN, NPL, LISA, and CISI test collections that scientists assembled explicitly for experiments in data information retrieval systems.","meta":{"url":"http://arxiv.org/abs/2307.06213v1"},"cats":{"new-dataset":0.3595929065,"dev-research":0.4424368737,"prompt-eng":0.5019085545,"data-quality":0.1861630327,"ml-security":0.0915474455}}
{"text":"We present a novel method to compute $\\textit{assume-guarantee contracts}$ in non-zerosum two-player games over finite graphs where each player has a different $ \\omega $-regular winning condition.","meta":{"url":"http://arxiv.org/abs/2307.06212v1"},"cats":{"new-dataset":0.1690235036,"dev-research":0.4245275643,"prompt-eng":0.3610899393,"data-quality":0.1378638365,"ml-security":0.201034945}}
{"text":"Given a game graph $G$ and two parity winning conditions $\\Phi_0$ and $\\Phi_1$ over $G$, we compute $\\textit{contracted strategy-masks}$ ($\\texttt{csm}$) $(\\Psi_{i},\\Phi_{i})$ for each Player $i$. Within a $\\texttt{csm}$, $\\Phi_{i}$ is a $\\textit{permissive strategy template}$ which collects an infinite number of winning strategies for Player $i$ under the assumption that Player $1-i$ chooses any strategy from the $\\textit{permissive assumption template}$ $\\Psi_{i}$. The main feature of $\\texttt{csm}$'s is their power to $\\textit{fully decentralize all remaining strategy choices}$ -- if the two player's $\\texttt{csm}$'s are compatible, they provide a pair of new local specifications $\\Phi_0^\\bullet$ and $\\Phi_1^\\bullet$ such that Player $i$ can locally and fully independently choose any strategy satisfying $\\Phi_i^\\bullet$ and the resulting strategy profile is ensured to be winning in the original two-objective game $(G,\\Phi_0,\\Phi_1)$.   In addition, the new specifications $\\Phi_i^\\bullet$ are $\\textit{maximally cooperative}$, i.e., allow for the distributed synthesis of any cooperative solution.","meta":{"url":"http://arxiv.org/abs/2307.06212v1"},"cats":{"new-dataset":0.057772204,"dev-research":0.4298168646,"prompt-eng":0.3925096095,"data-quality":0.0980200113,"ml-security":0.2865868737}}
{"text":"Further, our algorithmic computation of $\\texttt{csm}$'s is complete and ensured to terminate.   ","meta":{"url":"http://arxiv.org/abs/2307.06212v1"},"cats":{"new-dataset":0.0722989743,"dev-research":0.4309122424,"prompt-eng":0.4185839171,"data-quality":0.1354144699,"ml-security":0.185396431}}
{"text":"We illustrate how the unique features of our synthesis framework effectively address multiple challenges in the context of \\enquote{correct-by-design} logical control software synthesis for cyber-physical systems and provide empirical evidence that our approach possess desirable structural and computational properties compared to state-of-the-art techniques.","meta":{"url":"http://arxiv.org/abs/2307.06212v1"},"cats":{"new-dataset":0.0963282338,"dev-research":0.502995393,"prompt-eng":0.4536101871,"data-quality":0.1135889691,"ml-security":0.1701180185}}
{"text":"We investigate the mechanism design problem faced by a principal who hires \\emph{multiple} agents to gather and report costly information.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.098584328,"dev-research":0.4627638696,"prompt-eng":0.4572274599,"data-quality":0.0865662424,"ml-security":0.251603205}}
{"text":"Then, the principal exploits the information to make an informed decision.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.1207838235,"dev-research":0.4748302855,"prompt-eng":0.428069932,"data-quality":0.1587588358,"ml-security":0.4173469585}}
{"text":"We model this problem as a game, where the principal announces a mechanism consisting in action recommendations and a payment function, a.k.a. scoring rule.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.1668786859,"dev-research":0.425705348,"prompt-eng":0.443038314,"data-quality":0.0892152322,"ml-security":0.1823287445}}
{"text":"Then, each agent chooses an effort level and receives partial information about an underlying state of nature based on the effort.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.0552740641,"dev-research":0.4820701177,"prompt-eng":0.4535601484,"data-quality":0.0650180683,"ml-security":0.1113474541}}
{"text":"Finally, the agents report the information (possibly non-truthfully), the principal takes a decision based on this information, and the agents are paid according to the scoring rule.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.1632815898,"dev-research":0.4547536711,"prompt-eng":0.4643712404,"data-quality":0.1462304925,"ml-security":0.2018023304}}
{"text":"While previous work focuses on single-agent problems, we consider multi-agents settings.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.1123218913,"dev-research":0.4402837048,"prompt-eng":0.4425279336,"data-quality":0.0972703156,"ml-security":0.1515055101}}
{"text":"This poses the challenge of coordinating the agents' efforts and aggregating correlated information.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.0813982763,"dev-research":0.4488399789,"prompt-eng":0.4545991038,"data-quality":0.1020310774,"ml-security":0.159544669}}
{"text":"Indeed, we show that optimal mechanisms must correlate agents' efforts, which introduces externalities among the agents, and hence complex incentive compatibility constraints and equilibrium selection problems.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.040579041,"dev-research":0.4381170698,"prompt-eng":0.3886845571,"data-quality":0.0653785516,"ml-security":0.183039688}}
{"text":"First, we design a polynomial-time algorithm to find an optimal incentive compatible mechanism.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.0484091789,"dev-research":0.4203754943,"prompt-eng":0.3692853658,"data-quality":0.0825162362,"ml-security":0.2330891159}}
{"text":"Then, we study an online problem, where the principal repeatedly interacts with a group of unknown agents.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.1474869356,"dev-research":0.4210755709,"prompt-eng":0.4362156515,"data-quality":0.0873985121,"ml-security":0.3404770098}}
{"text":"We design a no-regret algorithm that provides $\\widetilde{\\mathcal{O}}(T^{2/3})$ regret with respect to an optimal mechanism, matching the state-of-the-art bound for single-agent settings.","meta":{"url":"http://arxiv.org/abs/2307.06210v1"},"cats":{"new-dataset":0.0652910868,"dev-research":0.3913560599,"prompt-eng":0.3808534128,"data-quality":0.0499801567,"ml-security":0.1848676018}}
{"text":"Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset.","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.0961766283,"dev-research":0.3919337261,"prompt-eng":0.4340268589,"data-quality":0.1089073835,"ml-security":0.0686168784}}
{"text":"To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets).","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.1427885724,"dev-research":0.4044136488,"prompt-eng":0.4600044046,"data-quality":0.2010268563,"ml-security":0.1043202485}}
{"text":"Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation.","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.0676311452,"dev-research":0.3963027269,"prompt-eng":0.4990399562,"data-quality":0.2210379208,"ml-security":0.158124291}}
{"text":"To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space.","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.1072316503,"dev-research":0.3888705459,"prompt-eng":0.4638274945,"data-quality":0.2901213403,"ml-security":0.153497631}}
{"text":"We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA).","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.1807749787,"dev-research":0.3429772539,"prompt-eng":0.4072797348,"data-quality":0.1440770651,"ml-security":0.0749320946}}
{"text":"Code and datasets are available on GitHub https://github.com/neurospin-projects/2023_rlouiset_sepvae.","meta":{"url":"http://arxiv.org/abs/2307.06206v1"},"cats":{"new-dataset":0.7779890379,"dev-research":0.4226766832,"prompt-eng":0.4675783486,"data-quality":0.1121606446,"ml-security":0.1320924122}}
{"text":"In autonomic computing, self-adaptation has been proposed as a fundamental paradigm to manage the complexity of multiagent systems (MASs).","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0731785275,"dev-research":0.4123661981,"prompt-eng":0.4369965433,"data-quality":0.0801381661,"ml-security":0.1143360152}}
{"text":"This achieved by extending a system with support to monitor and adapt itself to achieve specific concerns of interest.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0769743339,"dev-research":0.4800621935,"prompt-eng":0.435130703,"data-quality":0.0797668436,"ml-security":0.1262744026}}
{"text":"Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0968941864,"dev-research":0.467299943,"prompt-eng":0.4897890882,"data-quality":0.0699417818,"ml-security":0.1795174351}}
{"text":"However, improving the expressiveness of the interaction communication with MASs is not without challenges.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0578434596,"dev-research":0.4112183294,"prompt-eng":0.4971190392,"data-quality":0.1029431926,"ml-security":0.1052344909}}
{"text":"In this sense, the interplay between self-adaptive systems and effective communication is crucial for future MAS advancements.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0625505129,"dev-research":0.443035504,"prompt-eng":0.4646055965,"data-quality":0.0794968962,"ml-security":0.1492356134}}
{"text":"In this paper, we propose the integration of large language models (LLMs) such as GPT-based technologies into multiagent systems.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.1548817428,"dev-research":0.4345389759,"prompt-eng":0.5485888747,"data-quality":0.1057569423,"ml-security":0.1004929798}}
{"text":"We anchor our methodology on the MAPE-K model, which is renowned for its robust support in monitoring, analyzing, planning, and executing system adaptations in response to dynamic environments.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.1572360913,"dev-research":0.4292686778,"prompt-eng":0.4694702653,"data-quality":0.0773558402,"ml-security":0.1393153315}}
{"text":"We also present a practical illustration of the proposed approach, in which we implement and assess a basic MAS-based application.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0762498249,"dev-research":0.4462257719,"prompt-eng":0.464350058,"data-quality":0.0766544332,"ml-security":0.0695902321}}
{"text":"The approach significantly advances the state-of-the-art of self-adaptive systems by proposing a new paradigm for MAS self-adaptation of autonomous systems based on LLM capabilities.","meta":{"url":"http://arxiv.org/abs/2307.06187v1"},"cats":{"new-dataset":0.0715134092,"dev-research":0.4084699879,"prompt-eng":0.4826548369,"data-quality":0.0878299652,"ml-security":0.1601772}}
{"text":"Automatic examination of thin-prep cytologic test (TCT) slides can assist pathologists in finding cervical abnormality for accurate and efficient cancer screening.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.1136725536,"dev-research":0.4036677292,"prompt-eng":0.480808664,"data-quality":0.1283762878,"ml-security":0.0931452144}}
{"text":"Current solutions mostly need to localize suspicious cells and classify abnormality based on local patches, concerning the fact that whole slide images of TCT are extremely large.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.2300802788,"dev-research":0.4185036674,"prompt-eng":0.4523125508,"data-quality":0.1880719376,"ml-security":0.1958743279}}
{"text":"It thus requires many annotations of normal and abnormal cervical cells, to supervise the training of the patch-level classifier for promising performance.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.1535297212,"dev-research":0.3987424539,"prompt-eng":0.4513692875,"data-quality":0.3001477436,"ml-security":0.1810571099}}
{"text":"In this paper, we propose CellGAN to synthesize cytopathological images of various cervical cell types for augmenting patch-level cell classification.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.2622676165,"dev-research":0.4014488481,"prompt-eng":0.4260998226,"data-quality":0.21822773,"ml-security":0.1284712333}}
{"text":"Built upon a lightweight backbone, CellGAN is equipped with a non-linear class mapping network to effectively incorporate cell type information into image generation.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.2253266246,"dev-research":0.4141655168,"prompt-eng":0.4323389397,"data-quality":0.1844281753,"ml-security":0.1342542515}}
{"text":"We also propose the Skip-layer Global Context module to model the complex spatial relationship of the cells, and attain high fidelity of the synthesized images through adversarial learning.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.1817459112,"dev-research":0.3800736622,"prompt-eng":0.4264537527,"data-quality":0.1318207321,"ml-security":0.1840082085}}
{"text":"Our experiments demonstrate that CellGAN can produce visually plausible TCT cytopathological images for different cell types.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.2783602342,"dev-research":0.4213337484,"prompt-eng":0.4339967407,"data-quality":0.1727576842,"ml-security":0.0992822286}}
{"text":"We also validate the effectiveness of using CellGAN to greatly augment patch-level cell classification performance.","meta":{"url":"http://arxiv.org/abs/2307.06182v1"},"cats":{"new-dataset":0.1868403467,"dev-research":0.4229236587,"prompt-eng":0.4322505611,"data-quality":0.2589529351,"ml-security":0.1483207419}}
{"text":"This paper presents B-CLEAN-SC, a variation of CLEAN-SC for broadband sources.","meta":{"url":"http://arxiv.org/abs/2307.06181v1"},"cats":{"new-dataset":0.0833274396,"dev-research":0.4101405745,"prompt-eng":0.3969617552,"data-quality":0.1624600179,"ml-security":0.1465289684}}
{"text":"Opposed to CLEAN-SC, which ``deconvolves'' the beamforming map for each frequency individually, B-CLEAN-SC processes frequency intervals.","meta":{"url":"http://arxiv.org/abs/2307.06181v1"},"cats":{"new-dataset":0.092015901,"dev-research":0.3811227002,"prompt-eng":0.4093664458,"data-quality":0.1437252099,"ml-security":0.0785089516}}
{"text":"Instead of performing a deconvolution iteration at the location of the maximum level, B-CLEAN-SC performs it at the location of the over-frequency-averaged maximum to improve the location estimation.","meta":{"url":"http://arxiv.org/abs/2307.06181v1"},"cats":{"new-dataset":0.0866070857,"dev-research":0.3687370057,"prompt-eng":0.4002636975,"data-quality":0.1343667038,"ml-security":0.1107392736}}
{"text":"The method is validated and compared to standard CLEAN-SC on synthetic cases, and real-world experiments, for broad- and narrowband sources.","meta":{"url":"http://arxiv.org/abs/2307.06181v1"},"cats":{"new-dataset":0.0656783552,"dev-research":0.3609568767,"prompt-eng":0.4080419204,"data-quality":0.2193828114,"ml-security":0.1647615229}}
{"text":"It improves the source reconstruction at low and high frequencies and suppresses noise, while it only increases the need for memory but not computational effort.","meta":{"url":"http://arxiv.org/abs/2307.06181v1"},"cats":{"new-dataset":0.05101107,"dev-research":0.4251721263,"prompt-eng":0.3722602688,"data-quality":0.0924303455,"ml-security":0.0911758928}}
{"text":"Standard recognition approaches are unable to deal with novel categories at test time.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.0649176095,"dev-research":0.3727473424,"prompt-eng":0.401607285,"data-quality":0.5074542064,"ml-security":0.1944461036}}
{"text":"Their overconfidence on the known classes makes the predictions unreliable for safety-critical applications such as healthcare or autonomous driving.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.1524005274,"dev-research":0.4159101953,"prompt-eng":0.4317855354,"data-quality":0.3391536547,"ml-security":0.4747297506}}
{"text":"Out-Of-Distribution (OOD) detection methods provide a solution by identifying semantic novelty.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.1376974361,"dev-research":0.4420405467,"prompt-eng":0.4597935924,"data-quality":0.52228382,"ml-security":0.1947736739}}
{"text":"Most of these methods leverage a learning stage on the known data, which means training (or fine-tuning) a model to capture the concept of normality.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.1091513874,"dev-research":0.402788691,"prompt-eng":0.4360616592,"data-quality":0.2202334263,"ml-security":0.2000149276}}
{"text":"This process is clearly sensitive to the amount of available samples and might be computationally expensive for on-board systems.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.0872377567,"dev-research":0.3952158871,"prompt-eng":0.4189901381,"data-quality":0.1081564374,"ml-security":0.2001560288}}
{"text":"A viable alternative is that of evaluating similarities in the embedding space produced by large pre-trained models without any further learning effort.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.0853914635,"dev-research":0.4065970946,"prompt-eng":0.497916426,"data-quality":0.1432281247,"ml-security":0.1818320696}}
{"text":"We focus exactly on such a fine-tuning-free OOD detection setting.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.0794083211,"dev-research":0.3993434685,"prompt-eng":0.4407391946,"data-quality":0.1854501326,"ml-security":0.2147458384}}
{"text":"This works presents an in-depth analysis of the recently introduced relational reasoning pre-training and investigates the properties of the learned embedding, highlighting the existence of a correlation between the inter-class feature distance and the OOD detection accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.2295883619,"dev-research":0.4369586877,"prompt-eng":0.534276063,"data-quality":0.2127268705,"ml-security":0.1564250416}}
{"text":"As the class separation depends on the chosen pre-training objective, we propose an alternative loss function to control the inter-class margin, and we show its advantage with thorough experiments.","meta":{"url":"http://arxiv.org/abs/2307.06179v1"},"cats":{"new-dataset":0.0871933954,"dev-research":0.3679920485,"prompt-eng":0.4494873541,"data-quality":0.2175982113,"ml-security":0.2792824659}}
{"text":"Complex inner-city junctions are among the most critical traffic areas for injury and fatal accidents.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.1513739594,"dev-research":0.4258466512,"prompt-eng":0.375988971,"data-quality":0.1101822244,"ml-security":0.1767966194}}
{"text":"The development of highly automated driving (HAD) systems struggles with the complex and hectic everyday life within those areas.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.1092267618,"dev-research":0.465596521,"prompt-eng":0.4406864507,"data-quality":0.0982904008,"ml-security":0.1165694175}}
{"text":"Sensor-equipped smart infrastructures, which can communicate and cooperate with vehicles, are essential to enable a holistic scene understanding to resolve occlusions drivers and vehicle perception systems for themselves can not cover.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.1915504168,"dev-research":0.4010744509,"prompt-eng":0.4297741924,"data-quality":0.1776182474,"ml-security":0.1487426828}}
{"text":"We introduce an intelligent research infrastructure equipped with visual sensor technology, located at a public inner-city junction in Aschaffenburg, Germany.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.3984906861,"dev-research":0.4225259788,"prompt-eng":0.4208295894,"data-quality":0.1079199033,"ml-security":0.1017029044}}
{"text":"A multiple-view camera system monitors the traffic situation to perceive road users' behavior.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.221261372,"dev-research":0.3978495533,"prompt-eng":0.4135530173,"data-quality":0.1044517727,"ml-security":0.1121673056}}
{"text":"Both motorized and non-motorized traffic is considered.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.0576733059,"dev-research":0.3746362413,"prompt-eng":0.3699105334,"data-quality":0.0859025992,"ml-security":0.0892379273}}
{"text":"The system is used for research in data generation, evaluating new HAD sensors systems, algorithms, and Artificial Intelligence (AI) training strategies using real-, synthetic- and augmented data.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.4301299899,"dev-research":0.4248693863,"prompt-eng":0.4572909928,"data-quality":0.0915282954,"ml-security":0.1648904303}}
{"text":"In addition, the junction features a highly accurate digital twin.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.1078141413,"dev-research":0.3892762097,"prompt-eng":0.3863678248,"data-quality":0.154828078,"ml-security":0.0874505458}}
{"text":"Real-world data can be taken into the digital twin for simulation purposes and synthetic data generation.","meta":{"url":"http://arxiv.org/abs/2307.06177v1"},"cats":{"new-dataset":0.4102936864,"dev-research":0.380592731,"prompt-eng":0.3994593478,"data-quality":0.0856467146,"ml-security":0.1887931078}}
{"text":"Recent reinforcement learning (RL) methods have achieved success in various domains.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0447227548,"dev-research":0.3807326703,"prompt-eng":0.4389402899,"data-quality":0.0982817606,"ml-security":0.1325180646}}
{"text":"However, multi-agent RL (MARL) remains a challenge in terms of decentralization, partial observability and scalability to many agents.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0814828322,"dev-research":0.3919816637,"prompt-eng":0.3992398274,"data-quality":0.0614200833,"ml-security":0.1791550123}}
{"text":"Meanwhile, collective behavior requires resolution of the aforementioned challenges, and remains of importance to many state-of-the-art applications such as active matter physics, self-organizing systems, opinion dynamics, and biological or robotic swarms.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0770974642,"dev-research":0.3861791199,"prompt-eng":0.4483849244,"data-quality":0.1003100389,"ml-security":0.1217566259}}
{"text":"Here, MARL via mean field control (MFC) offers a potential solution to scalability, but fails to consider decentralized and partially observable systems.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0730319346,"dev-research":0.3514661572,"prompt-eng":0.4186834176,"data-quality":0.0632181158,"ml-security":0.1720061386}}
{"text":"In this paper, we enable decentralized behavior of agents under partial information by proposing novel models for decentralized partially observable MFC (Dec-POMFC), a broad class of problems with permutation-invariant agents allowing for reduction to tractable single-agent Markov decision processes (MDP) with single-agent RL solution.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0778007575,"dev-research":0.3771737373,"prompt-eng":0.4248002818,"data-quality":0.1036506958,"ml-security":0.2058934674}}
{"text":"We provide rigorous theoretical results, including a dynamic programming principle, together with optimality guarantees for Dec-POMFC solutions applied to finite swarms of interest.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.065702213,"dev-research":0.3838182195,"prompt-eng":0.4201784638,"data-quality":0.093559321,"ml-security":0.1642568584}}
{"text":"Algorithmically, we propose Dec-POMFC-based policy gradient methods for MARL via centralized training and decentralized execution, together with policy gradient approximation guarantees.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0803406184,"dev-research":0.3791539975,"prompt-eng":0.4485962063,"data-quality":0.0880875168,"ml-security":0.214173552}}
{"text":"In addition, we improve upon state-of-the-art histogram-based MFC by kernel methods, which is of separate interest also for fully observable MFC.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.2546571415,"dev-research":0.3698163861,"prompt-eng":0.4657005668,"data-quality":0.1736711008,"ml-security":0.067591659}}
{"text":"We evaluate numerically on representative collective behavior tasks such as adapted Kuramoto and Vicsek swarming models, being on par with state-of-the-art MARL.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.0686288497,"dev-research":0.3735653283,"prompt-eng":0.4664060814,"data-quality":0.0856179558,"ml-security":0.1146892022}}
{"text":"Overall, our framework takes a step towards RL-based engineering of artificial collective behavior via MFC.","meta":{"url":"http://arxiv.org/abs/2307.06175v1"},"cats":{"new-dataset":0.1021107002,"dev-research":0.4155249027,"prompt-eng":0.4856142288,"data-quality":0.0884103982,"ml-security":0.1344959658}}
{"text":"Nowadays, cars offer many possibilities to explore the world around you by providing location-based information displayed on a 2D-Map.","meta":{"url":"http://arxiv.org/abs/2307.06173v1"},"cats":{"new-dataset":0.2669483831,"dev-research":0.4200963749,"prompt-eng":0.3963889397,"data-quality":0.0932437112,"ml-security":0.1057518399}}
{"text":"However, this information is often only available to front-seat passengers while being restricted to in-car displays.","meta":{"url":"http://arxiv.org/abs/2307.06173v1"},"cats":{"new-dataset":0.1547583878,"dev-research":0.3810868508,"prompt-eng":0.4031898421,"data-quality":0.1004670221,"ml-security":0.234524426}}
{"text":"To propose a more natural way of interacting with the environment, we implemented an augmented reality head-mounted display to overlay points of interest onto the real world.","meta":{"url":"http://arxiv.org/abs/2307.06173v1"},"cats":{"new-dataset":0.1203677518,"dev-research":0.4410387375,"prompt-eng":0.4304332002,"data-quality":0.0588015515,"ml-security":0.0866413368}}
{"text":"We aim to compare multiple selection techniques for digital objects located outside a moving car by investigating head gaze with dwell time, head gaze with hardware button, eye gaze with hardware button, and hand pointing with gesture confirmation.","meta":{"url":"http://arxiv.org/abs/2307.06173v1"},"cats":{"new-dataset":0.1235523757,"dev-research":0.4217072806,"prompt-eng":0.4349003772,"data-quality":0.0621951538,"ml-security":0.0478374858}}
{"text":"Our study was conducted in a moving car under real-world conditions (N=22), with significant results indicating that hand pointing usage led to slower and less precise content selection while eye gaze was preferred by participants and performed on par with the other techniques.","meta":{"url":"http://arxiv.org/abs/2307.06173v1"},"cats":{"new-dataset":0.088235494,"dev-research":0.4089325009,"prompt-eng":0.391831808,"data-quality":0.0679093272,"ml-security":0.0466303085}}
{"text":"Physics-informed neural networks (PINNs) have emerged as promising surrogate modes for solving partial differential equations (PDEs).","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.0865583175,"dev-research":0.3897255688,"prompt-eng":0.4251522675,"data-quality":0.0556544341,"ml-security":0.1935945389}}
{"text":"Their effectiveness lies in the ability to capture solution-related features through neural networks.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.118480797,"dev-research":0.4941981734,"prompt-eng":0.4657765603,"data-quality":0.1510684274,"ml-security":0.1843471098}}
{"text":"However, original PINNs often suffer from bottlenecks, such as low accuracy and non-convergence, limiting their applicability in complex physical contexts.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.064478328,"dev-research":0.3968189728,"prompt-eng":0.3491631489,"data-quality":0.1156327559,"ml-security":0.1318413778}}
{"text":"To alleviate these issues, we proposed auxiliary-task learning-based physics-informed neural networks (ATL-PINNs), which provide four different auxiliary-task learning modes and investigate their performance compared with original PINNs.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.1500098597,"dev-research":0.385064996,"prompt-eng":0.4615418472,"data-quality":0.0910900936,"ml-security":0.1248949178}}
{"text":"We also employ the gradient cosine similarity algorithm to integrate auxiliary problem loss with the primary problem loss in ATL-PINNs, which aims to enhance the effectiveness of the auxiliary-task learning modes.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.0841878155,"dev-research":0.4326857362,"prompt-eng":0.455816564,"data-quality":0.1748206924,"ml-security":0.1370265696}}
{"text":"To the best of our knowledge, this is the first study to introduce auxiliary-task learning modes in the context of physics-informed learning.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.0871899221,"dev-research":0.4164285668,"prompt-eng":0.4620386978,"data-quality":0.084908531,"ml-security":0.1079738456}}
{"text":"We conduct experiments on three PDE problems across different fields and scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.0808907149,"dev-research":0.4071206804,"prompt-eng":0.4308166962,"data-quality":0.1034574396,"ml-security":0.1575905144}}
{"text":"Our findings demonstrate that the proposed auxiliary-task learning modes can significantly improve solution accuracy, achieving a maximum performance boost of 96.62% (averaging 28.23%) compared to the original single-task PINNs.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.0992901475,"dev-research":0.4875967762,"prompt-eng":0.4819153261,"data-quality":0.1510247529,"ml-security":0.0997601884}}
{"text":"The code and dataset are open source at https://github.com/junjun-yan/ATL-PINN.","meta":{"url":"http://arxiv.org/abs/2307.06167v1"},"cats":{"new-dataset":0.8359488718,"dev-research":0.4306458397,"prompt-eng":0.4783327879,"data-quality":0.0808526556,"ml-security":0.121710704}}
{"text":"Vision-Language Models (VLMs) are expected to be capable of reasoning with commonsense knowledge as human beings.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.23689651,"dev-research":0.4513056448,"prompt-eng":0.5051564328,"data-quality":0.1843505652,"ml-security":0.1121275126}}
{"text":"One example is that humans can reason where and when an image is taken based on their knowledge.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.1338304134,"dev-research":0.4723899271,"prompt-eng":0.430514047,"data-quality":0.2187802971,"ml-security":0.167657424}}
{"text":"This makes us wonder if, based on visual cues, Vision-Language Models that are pre-trained with large-scale image-text resources can achieve and even outperform human's capability in reasoning times and location.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.1833461704,"dev-research":0.4288181238,"prompt-eng":0.5218697081,"data-quality":0.1632157442,"ml-security":0.1003513057}}
{"text":"To address this question, we propose a two-stage \\recognition\\space and \\reasoning\\space probing task, applied to discriminative and generative VLMs to uncover whether VLMs can recognize times and location-relevant features and further reason about it.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.1373314661,"dev-research":0.4384870981,"prompt-eng":0.5015871932,"data-quality":0.1808638937,"ml-security":0.1736540565}}
{"text":"To facilitate the investigation, we introduce WikiTiLo, a well-curated image dataset compromising images with rich socio-cultural cues.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.7049462119,"dev-research":0.4057033688,"prompt-eng":0.4611471965,"data-quality":0.1703994835,"ml-security":0.2490617465}}
{"text":"In the extensive experimental studies, we find that although VLMs can effectively retain relevant features in visual encoders, they still fail to make perfect reasoning.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.0540823211,"dev-research":0.4624643937,"prompt-eng":0.4258596804,"data-quality":0.2108077815,"ml-security":0.1610743868}}
{"text":"We will release our dataset and codes to facilitate future studies.","meta":{"url":"http://arxiv.org/abs/2307.06166v1"},"cats":{"new-dataset":0.7935587683,"dev-research":0.4940527719,"prompt-eng":0.5039743197,"data-quality":0.1453786647,"ml-security":0.1958583769}}
{"text":"Inner-city intersections are among the most critical traffic areas for injury and fatal accidents.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.1430391064,"dev-research":0.423174163,"prompt-eng":0.3961748533,"data-quality":0.1176781201,"ml-security":0.209171525}}
{"text":"Automated vehicles struggle with the complex and hectic everyday life within those areas.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.1572614241,"dev-research":0.4319392045,"prompt-eng":0.4294589481,"data-quality":0.1248397574,"ml-security":0.1019895788}}
{"text":"Sensor-equipped smart infrastructures, which can cooperate with vehicles, can benefit automated traffic by extending the perception capabilities of drivers and vehicle perception systems.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.13208463,"dev-research":0.4026696637,"prompt-eng":0.4464978211,"data-quality":0.1181377347,"ml-security":0.1796373364}}
{"text":"Additionally, they offer the opportunity to gather reproducible and precise data of a holistic scene understanding, including context information as a basis for training algorithms for various applications in automated traffic.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.2653294079,"dev-research":0.4356988777,"prompt-eng":0.5054410194,"data-quality":0.1762830418,"ml-security":0.1242203996}}
{"text":"Therefore, we introduce the Infrastructural Multi-Person Trajectory and Context Dataset (IMPTC).","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.6675654611,"dev-research":0.3712260892,"prompt-eng":0.4251006385,"data-quality":0.0574472558,"ml-security":0.0897348054}}
{"text":"We use an intelligent public inner-city intersection in Germany with visual sensor technology.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.2042266587,"dev-research":0.4199052826,"prompt-eng":0.4289520786,"data-quality":0.1048094019,"ml-security":0.1218145338}}
{"text":"A multi-view camera and LiDAR system perceives traffic situations and road users' behavior.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.1609583365,"dev-research":0.3903448375,"prompt-eng":0.3984005793,"data-quality":0.0981824978,"ml-security":0.1478421625}}
{"text":"Additional sensors monitor contextual information like weather, lighting, and traffic light signal status.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.1874163745,"dev-research":0.4296776739,"prompt-eng":0.4378491196,"data-quality":0.1053072409,"ml-security":0.0965218668}}
{"text":"The data acquisition system focuses on Vulnerable Road Users (VRUs) and multi-agent interaction.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.361901992,"dev-research":0.3942544388,"prompt-eng":0.4788770491,"data-quality":0.097175632,"ml-security":0.356537133}}
{"text":"The resulting dataset consists of eight hours of measurement data.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.6554049848,"dev-research":0.3718329051,"prompt-eng":0.3832234084,"data-quality":0.0934388559,"ml-security":0.0951903378}}
{"text":"It contains over 2,500 VRU trajectories, including pedestrians, cyclists, e-scooter riders, strollers, and wheelchair users, and over 20,000 vehicle trajectories at different day times, weather conditions, and seasons.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.4174514155,"dev-research":0.3524002894,"prompt-eng":0.4090839158,"data-quality":0.0514204438,"ml-security":0.0669717241}}
{"text":"In addition, to enable the entire stack of research capabilities, the dataset includes all data, starting from the sensor-, calibration- and detection data until trajectory and context data.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.8029820859,"dev-research":0.377333735,"prompt-eng":0.4400850167,"data-quality":0.0709132427,"ml-security":0.136713848}}
{"text":"The dataset is continuously expanded and is available online for non-commercial research at https://github.com/kav-institute/imptc-dataset.","meta":{"url":"http://arxiv.org/abs/2307.06165v1"},"cats":{"new-dataset":0.8817214253,"dev-research":0.3745199555,"prompt-eng":0.4363926982,"data-quality":0.0679305953,"ml-security":0.1144202122}}
{"text":"In this paper, we present a systematic literature review on deep generative models for physiological signals, particularly electrocardiogram, electroencephalogram, photoplethysmogram and electromyogram.","meta":{"url":"http://arxiv.org/abs/2307.06162v1"},"cats":{"new-dataset":0.1678938814,"dev-research":0.3711116218,"prompt-eng":0.5064323834,"data-quality":0.1488745351,"ml-security":0.1282912757}}
{"text":"Compared to the existing review papers, we present the first review that summarizes the recent state-of-the-art deep generative models.","meta":{"url":"http://arxiv.org/abs/2307.06162v1"},"cats":{"new-dataset":0.1862058252,"dev-research":0.3883915462,"prompt-eng":0.5345084095,"data-quality":0.1456390125,"ml-security":0.0850962365}}
{"text":"By analysing the state-of-the-art research related to deep generative models along with their main applications and challenges, this review contributes to the overall understanding of these models applied to physiological signals.","meta":{"url":"http://arxiv.org/abs/2307.06162v1"},"cats":{"new-dataset":0.1490683312,"dev-research":0.3655726105,"prompt-eng":0.5065077966,"data-quality":0.1199546485,"ml-security":0.1154231349}}
{"text":"Additionally, by highlighting the employed evaluation protocol and the most used physiological databases, this review facilitates the assessment and benchmarking of deep generative models.","meta":{"url":"http://arxiv.org/abs/2307.06162v1"},"cats":{"new-dataset":0.2592970529,"dev-research":0.3600915758,"prompt-eng":0.5191535758,"data-quality":0.1261054468,"ml-security":0.0839842372}}
{"text":"With the growing capabilities and pervasiveness of AI systems, societies must collectively choose between reduced human autonomy, endangered democracies and limited human rights, and AI that is aligned to human and social values, nurturing collaboration, resilience, knowledge and ethical behaviour.","meta":{"url":"http://arxiv.org/abs/2307.06159v1"},"cats":{"new-dataset":0.1661326173,"dev-research":0.4435154475,"prompt-eng":0.4042746105,"data-quality":0.0630327671,"ml-security":0.2006307811}}
{"text":"In this chapter, we introduce the notion of self-reflective AI systems for meaningful human control over AI systems.","meta":{"url":"http://arxiv.org/abs/2307.06159v1"},"cats":{"new-dataset":0.1116547392,"dev-research":0.447163721,"prompt-eng":0.4930893891,"data-quality":0.1126799647,"ml-security":0.1753120081}}
{"text":"Focusing on decision support systems, we propose a framework that integrates knowledge from psychology and philosophy with formal reasoning methods and machine learning approaches to create AI systems responsive to human values and social norms.","meta":{"url":"http://arxiv.org/abs/2307.06159v1"},"cats":{"new-dataset":0.191027727,"dev-research":0.4534256257,"prompt-eng":0.4873309768,"data-quality":0.1687493255,"ml-security":0.1778264181}}
{"text":"We also propose a possible research approach to design and develop self-reflective capability in AI systems.","meta":{"url":"http://arxiv.org/abs/2307.06159v1"},"cats":{"new-dataset":0.0962820063,"dev-research":0.4550836252,"prompt-eng":0.4515308865,"data-quality":0.0718070446,"ml-security":0.1540225124}}
{"text":"Finally, we argue that self-reflective AI systems can lead to self-reflective hybrid systems (human + AI), thus increasing meaningful human control and empowering human moral reasoning by providing comprehensible information and insights on possible human moral blind spots.","meta":{"url":"http://arxiv.org/abs/2307.06159v1"},"cats":{"new-dataset":0.1390405009,"dev-research":0.4896735562,"prompt-eng":0.4639612346,"data-quality":0.1269209766,"ml-security":0.1712537012}}
{"text":"Maneuver decision-making is the core of unmanned combat aerial vehicle for autonomous air combat.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.0607662205,"dev-research":0.4202829325,"prompt-eng":0.4184356225,"data-quality":0.0617242713,"ml-security":0.1823998756}}
{"text":"To solve this problem, we propose an automatic curriculum reinforcement learning method, which enables agents to learn effective decisions in air combat from scratch.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.1788630332,"dev-research":0.425098359,"prompt-eng":0.502755135,"data-quality":0.0632552011,"ml-security":0.2490515911}}
{"text":"The range of initial states are used for distinguishing curricula of different difficulty levels, thereby maneuver decision is divided into a series of sub-tasks from easy to difficult, and test results are used to change sub-tasks.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.0530775533,"dev-research":0.4364195757,"prompt-eng":0.4405467229,"data-quality":0.0652282737,"ml-security":0.0544035432}}
{"text":"As sub-tasks change, agents gradually learn to complete a series of sub-tasks from easy to difficult, enabling them to make effective maneuvering decisions to cope with various states without the need to spend effort designing reward functions.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.0621918014,"dev-research":0.4501109583,"prompt-eng":0.4367080338,"data-quality":0.055746014,"ml-security":0.1139079825}}
{"text":"The ablation studied show that the automatic curriculum learning proposed in this article is an essential component for training through reinforcement learning, namely, agents cannot complete effective decisions without curriculum learning.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.1085535374,"dev-research":0.4020246303,"prompt-eng":0.4776299006,"data-quality":0.0998952013,"ml-security":0.1542106847}}
{"text":"Simulation experiments show that, after training, agents are able to make effective decisions given different states, including tracking, attacking and escaping, which are both rational and interpretable.","meta":{"url":"http://arxiv.org/abs/2307.06152v1"},"cats":{"new-dataset":0.0752795648,"dev-research":0.4306548232,"prompt-eng":0.453023611,"data-quality":0.1007080528,"ml-security":0.3255216345}}
{"text":"Large language models (LLMs) have triggered tremendous success to empower daily life by generative information, and the personalization of LLMs could further contribute to their applications due to better alignment with human intents.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.160070517,"dev-research":0.4402165806,"prompt-eng":0.6131351386,"data-quality":0.1485565938,"ml-security":0.1572014969}}
{"text":"Towards personalized generative services, a collaborative cloud-edge methodology sounds promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1638961067,"dev-research":0.4355615044,"prompt-eng":0.4247841545,"data-quality":0.0815619742,"ml-security":0.1104873448}}
{"text":"In this article, after discussing the pros and cons of several candidate cloud-edge collaboration techniques, we put forward NetGPT to capably deploy appropriate LLMs at the edge and the cloud in accordance with their computing capacity.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1165273816,"dev-research":0.4186665705,"prompt-eng":0.4522054602,"data-quality":0.0641853811,"ml-security":0.1528251166}}
{"text":"In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with cloud LLMs.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1227414949,"dev-research":0.4415478456,"prompt-eng":0.591575406,"data-quality":0.09645123,"ml-security":0.1839998251}}
{"text":"After deploying representative open-source LLMs (e.g., GPT-2-base and LLaMA model) at the edge and the cloud, we present the feasibility of NetGPT on the basis of low-rank adaptation-based light-weight fine-tuning.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.064784416,"dev-research":0.3871461552,"prompt-eng":0.4738392663,"data-quality":0.0804092451,"ml-security":0.1527877283}}
{"text":"Subsequently, we highlight substantial essential changes required for a native artificial intelligence (AI) network architecture towards NetGPT, with special emphasis on deeper integration of communications and computing resources and careful calibration of logical AI workflow.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1737402367,"dev-research":0.4554193539,"prompt-eng":0.4388100408,"data-quality":0.1076401388,"ml-security":0.1200514447}}
{"text":"Furthermore, we demonstrate several by-product benefits of NetGPT, given edge LLM's astonishing capability to predict trends and infer intents, which possibly leads to a unified solution for intelligent network management \\& orchestration.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1249665748,"dev-research":0.4809305995,"prompt-eng":0.4881051768,"data-quality":0.0945461951,"ml-security":0.1722966163}}
{"text":"In a nutshell, we argue that NetGPT is a promising native-AI network architecture beyond provisioning personalized generative services.","meta":{"url":"http://arxiv.org/abs/2307.06148v1"},"cats":{"new-dataset":0.1742063657,"dev-research":0.4552076253,"prompt-eng":0.4559228515,"data-quality":0.1033439442,"ml-security":0.1681030046}}
{"text":"Light field is a type of image data that captures the 3D scene information by recording light rays emitted from a scene at various orientations.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.3288685039,"dev-research":0.3967855897,"prompt-eng":0.3843122503,"data-quality":0.1067774011,"ml-security":0.0601643464}}
{"text":"It offers a more immersive perception than classic 2D images but at the cost of huge data volume.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.2008286226,"dev-research":0.3755285372,"prompt-eng":0.3499519181,"data-quality":0.0424397232,"ml-security":0.0720481028}}
{"text":"In this paper, we draw inspiration from the visual characteristics of Sub-Aperture Images (SAIs) of light field and design a compact neural network representation for the light field compression task.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.2406752519,"dev-research":0.3711268688,"prompt-eng":0.3715559588,"data-quality":0.1121423821,"ml-security":0.0634805293}}
{"text":"The network backbone takes randomly initialized noise as input and is supervised on the SAIs of the target light field.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.0918338413,"dev-research":0.3708394093,"prompt-eng":0.4873850233,"data-quality":0.2250633241,"ml-security":0.1617528841}}
{"text":"It is composed of two types of complementary kernels: descriptive kernels (descriptors) that store scene description information learned during training, and modulatory kernels (modulators) that control the rendering of different SAIs from the queried perspectives.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.1757118671,"dev-research":0.442690298,"prompt-eng":0.4895274184,"data-quality":0.1590377507,"ml-security":0.0800094222}}
{"text":"To further enhance compactness of the network meanwhile retain high quality of the decoded light field, we accordingly introduce modulator allocation and kernel tensor decomposition mechanisms, followed by non-uniform quantization and lossless entropy coding techniques, to finally form an efficient compression pipeline.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.0676888805,"dev-research":0.3672922062,"prompt-eng":0.3663877166,"data-quality":0.1130048239,"ml-security":0.1293881559}}
{"text":"Extensive experiments demonstrate that our method outperforms other state-of-the-art (SOTA) methods by a significant margin in the light field compression task.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.1117782069,"dev-research":0.3706545354,"prompt-eng":0.3696022084,"data-quality":0.1054809738,"ml-security":0.0453164755}}
{"text":"Moreover, after aligning descriptors, the modulators learned from one light field can be transferred to new light fields for rendering dense views, indicating a potential solution for view synthesis task.","meta":{"url":"http://arxiv.org/abs/2307.06143v1"},"cats":{"new-dataset":0.0570627605,"dev-research":0.4125349846,"prompt-eng":0.4134891806,"data-quality":0.0706771463,"ml-security":0.0557233809}}
{"text":"Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks.","meta":{"url":"http://arxiv.org/abs/2307.06135v1"},"cats":{"new-dataset":0.1525947018,"dev-research":0.4447670539,"prompt-eng":0.5616021819,"data-quality":0.0835612937,"ml-security":0.0892677129}}
{"text":"However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics.","meta":{"url":"http://arxiv.org/abs/2307.06135v1"},"cats":{"new-dataset":0.1092728653,"dev-research":0.3995265813,"prompt-eng":0.4202344458,"data-quality":0.0523801204,"ml-security":0.0715263082}}
{"text":"We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations.","meta":{"url":"http://arxiv.org/abs/2307.06135v1"},"cats":{"new-dataset":0.271599474,"dev-research":0.4149290279,"prompt-eng":0.4364749657,"data-quality":0.0491941189,"ml-security":0.0523757101}}
{"text":"To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a semantic search for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an iterative replanning pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures.","meta":{"url":"http://arxiv.org/abs/2307.06135v1"},"cats":{"new-dataset":0.1622470712,"dev-research":0.4234307433,"prompt-eng":0.436558107,"data-quality":0.0749119009,"ml-security":0.0490640224}}
{"text":"We evaluate our approach on two large-scale environments spanning up to 3 floors, 36 rooms and 140 objects, and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute.","meta":{"url":"http://arxiv.org/abs/2307.06135v1"},"cats":{"new-dataset":0.2331814704,"dev-research":0.4582437551,"prompt-eng":0.5018124589,"data-quality":0.0709868404,"ml-security":0.0961573829}}
{"text":"Since its introduction in 1987, the DNS has become one of the core components of the Internet.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1324109101,"dev-research":0.4551846858,"prompt-eng":0.3995363323,"data-quality":0.1099966676,"ml-security":0.1516315525}}
{"text":"While it was designed to work with both TCP and UDP, DNS-over-UDP (DoUDP) has become the default option due to its low overhead.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1544438318,"dev-research":0.4094126463,"prompt-eng":0.3598703968,"data-quality":0.0652221229,"ml-security":0.1849648848}}
{"text":"As new Resource Records were introduced, the sizes of DNS responses increased considerably.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1845130739,"dev-research":0.4285130635,"prompt-eng":0.4215699285,"data-quality":0.1070021196,"ml-security":0.1516155046}}
{"text":"This expansion of message body has led to truncation and IP fragmentation more often in recent years where large UDP responses make DNS an easy vector for amplifying denial-of-service attacks which can reduce the resiliency of DNS services.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.0969177024,"dev-research":0.4220828456,"prompt-eng":0.3912792323,"data-quality":0.1601565841,"ml-security":0.4638479081}}
{"text":"This paper investigates the resiliency, responsiveness, and usage of DoTCP and DoUDP over IPv4 and IPv6 for 10 widely used public DNS resolvers.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1318373416,"dev-research":0.4065537499,"prompt-eng":0.3916081186,"data-quality":0.0971304614,"ml-security":0.2686507514}}
{"text":"In these experiments, these aspects are investigated from the edge and from the core of the Internet to represent the communication of the resolvers with DNS clients and authoritative name servers.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1755732813,"dev-research":0.4501089926,"prompt-eng":0.4358690889,"data-quality":0.1508923952,"ml-security":0.1709059693}}
{"text":"Overall, more than 14M individual measurements from 2527 RIPE Atlas Probes have been analyzed, highlighting that most resolvers show similar resiliency for both DoTCP and DoUDP.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.2214023123,"dev-research":0.3741098446,"prompt-eng":0.4524995181,"data-quality":0.0867315388,"ml-security":0.1274380862}}
{"text":"While DNS Flag Day 2020 recommended 1232 bytes of buffer sizes yet we find out that 3 out of 10 resolvers mainly announce very large EDNS(0) buffer sizes both from the edge as well as from the core, which potentially causes fragmentation.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1717160383,"dev-research":0.4135158861,"prompt-eng":0.3639802427,"data-quality":0.1073075643,"ml-security":0.1747164918}}
{"text":"In reaction to large response sizes from authoritative name servers, we find that resolvers do not fall back to the usage of DoTCP in many cases, bearing the risk of fragmented responses.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1127584636,"dev-research":0.4107232308,"prompt-eng":0.4394924027,"data-quality":0.143027649,"ml-security":0.2995605569}}
{"text":"As the message sizes in the DNS are expected to grow further, this problem will become more urgent in the future.","meta":{"url":"http://arxiv.org/abs/2307.06131v1"},"cats":{"new-dataset":0.1541017859,"dev-research":0.4026730299,"prompt-eng":0.4037362836,"data-quality":0.1839474246,"ml-security":0.1874231824}}
{"text":"Constraint Acquisition (CA) systems can be used to assist in the modeling of constraint satisfaction problems.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0995109145,"dev-research":0.445001682,"prompt-eng":0.4696788847,"data-quality":0.1499763127,"ml-security":0.0733475722}}
{"text":"In (inter)active CA, the system is given a set of candidate constraints and posts queries to the user with the goal of finding the right constraints among the candidates.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.1047595793,"dev-research":0.4281094749,"prompt-eng":0.4569382112,"data-quality":0.0991886686,"ml-security":0.1110807327}}
{"text":"Current interactive CA algorithms suffer from at least two major bottlenecks.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.1143547963,"dev-research":0.3901818291,"prompt-eng":0.4089120484,"data-quality":0.0740694217,"ml-security":0.0986445798}}
{"text":"First, in order to converge, they require a large number of queries to be asked to the user.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0989296284,"dev-research":0.4218456412,"prompt-eng":0.4340537078,"data-quality":0.0620015725,"ml-security":0.13770168}}
{"text":"Second, they cannot handle large sets of candidate constraints, since these lead to large waiting times for the user.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0503805247,"dev-research":0.4282578453,"prompt-eng":0.4009002885,"data-quality":0.072786883,"ml-security":0.1856880762}}
{"text":"For this reason, the user must have fairly precise knowledge about what constraints the system should consider.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0677625814,"dev-research":0.4783844704,"prompt-eng":0.4173539129,"data-quality":0.143965119,"ml-security":0.1953290829}}
{"text":"In this paper, we alleviate these bottlenecks by presenting two novel methods that improve the efficiency of CA.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0528715621,"dev-research":0.3886272777,"prompt-eng":0.3772199877,"data-quality":0.1031508161,"ml-security":0.071711537}}
{"text":"First, we introduce a bottom-up approach named GrowAcq that reduces the maximum waiting time for the user and allows the system to handle much larger sets of candidate constraints.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.1508917859,"dev-research":0.4191445226,"prompt-eng":0.4158561018,"data-quality":0.0469532269,"ml-security":0.1332472028}}
{"text":"It also reduces the total number of queries for problems in which the target constraint network is not sparse.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0262142779,"dev-research":0.431765406,"prompt-eng":0.3701987302,"data-quality":0.0816342625,"ml-security":0.2081893822}}
{"text":"Second, we propose a probability-based method to guide query generation and show that it can significantly reduce the number of queries required to converge.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.134507024,"dev-research":0.4361693211,"prompt-eng":0.4858435187,"data-quality":0.1222920445,"ml-security":0.1226398125}}
{"text":"We also propose a new technique that allows the use of openly accessible CP solvers in query generation, removing the dependency of existing methods on less well-maintained custom solvers that are not publicly available.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.1233273346,"dev-research":0.5048817469,"prompt-eng":0.4457295437,"data-quality":0.0923222094,"ml-security":0.1729797431}}
{"text":"Experimental results show that our proposed methods outperform state-of-the-art CA methods, reducing the number of queries by up to 60%.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.1223644199,"dev-research":0.3948381391,"prompt-eng":0.4350091742,"data-quality":0.1249575386,"ml-security":0.0840574365}}
{"text":"Our methods work well even in cases where the set of candidate constraints is 50 times larger than the ones commonly used in the literature.","meta":{"url":"http://arxiv.org/abs/2307.06126v1"},"cats":{"new-dataset":0.0498497526,"dev-research":0.4319381229,"prompt-eng":0.3995278033,"data-quality":0.1368308054,"ml-security":0.1274904293}}
{"text":"Existing object-search approaches enable robots to search through free pathways, however, robots operating in unstructured human-centered environments frequently also have to manipulate the environment to their needs.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.0748258642,"dev-research":0.4048055356,"prompt-eng":0.4145813983,"data-quality":0.0432690836,"ml-security":0.0984361815}}
{"text":"In this work, we introduce a novel interactive multi-object search task in which a robot has to open doors to navigate rooms and search inside cabinets and drawers to find target objects.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1761031516,"dev-research":0.4172357296,"prompt-eng":0.478129155,"data-quality":0.0678898246,"ml-security":0.0803804588}}
{"text":"These new challenges require combining manipulation and navigation skills in unexplored environments.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1240858417,"dev-research":0.4180717091,"prompt-eng":0.4226547692,"data-quality":0.0660642345,"ml-security":0.1223384373}}
{"text":"We present HIMOS, a hierarchical reinforcement learning approach that learns to compose exploration, navigation, and manipulation skills.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1390306257,"dev-research":0.4068776962,"prompt-eng":0.4738515722,"data-quality":0.0489586265,"ml-security":0.0755135406}}
{"text":"To achieve this, we design an abstract high-level action space around a semantic map memory and leverage the explored environment as instance navigation points.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1471779189,"dev-research":0.4486727629,"prompt-eng":0.5163571146,"data-quality":0.1139158686,"ml-security":0.112793546}}
{"text":"We perform extensive experiments in simulation and the real-world that demonstrate that HIMOS effectively transfers to new environments in a zero-shot manner.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1035698725,"dev-research":0.4032041665,"prompt-eng":0.4272803007,"data-quality":0.0744677009,"ml-security":0.1447221285}}
{"text":"It shows robustness to unseen subpolicies, failures in their execution, and different robot kinematics.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1137835051,"dev-research":0.4361661763,"prompt-eng":0.4067726911,"data-quality":0.1517410017,"ml-security":0.1396677114}}
{"text":"These capabilities open the door to a wide range of downstream tasks across embodied AI and real-world use cases.","meta":{"url":"http://arxiv.org/abs/2307.06125v1"},"cats":{"new-dataset":0.1235142929,"dev-research":0.4574421375,"prompt-eng":0.4479282363,"data-quality":0.049218868,"ml-security":0.1362806639}}
{"text":"Current signing avatars are often described as unnatural as they cannot accurately reproduce all the subtleties of synchronized body behaviors of a human signer.","meta":{"url":"http://arxiv.org/abs/2307.06124v1"},"cats":{"new-dataset":0.0664112622,"dev-research":0.4170204008,"prompt-eng":0.443439736,"data-quality":0.1848210307,"ml-security":0.1681326528}}
{"text":"In this paper, we propose a new dynamic approach for transitions between signs, focusing on mouthing animations for Portuguese Sign Language.","meta":{"url":"http://arxiv.org/abs/2307.06124v1"},"cats":{"new-dataset":0.1425214476,"dev-research":0.4006438212,"prompt-eng":0.4828572411,"data-quality":0.1409059594,"ml-security":0.0723787784}}
{"text":"Although native signers preferred animations with dynamic transitions, we did not find significant differences in comprehension and perceived naturalness scores.","meta":{"url":"http://arxiv.org/abs/2307.06124v1"},"cats":{"new-dataset":0.0868031571,"dev-research":0.4350689416,"prompt-eng":0.4671955579,"data-quality":0.1323967453,"ml-security":0.0588443051}}
{"text":"On the other hand, we show that including mouthing behaviors improved comprehension and perceived naturalness for novice sign language learners.","meta":{"url":"http://arxiv.org/abs/2307.06124v1"},"cats":{"new-dataset":0.094178968,"dev-research":0.4420425299,"prompt-eng":0.4677112951,"data-quality":0.1637048902,"ml-security":0.1099645863}}
{"text":"Results have implications in computational linguistics, human-computer interaction, and synthetic animation of signing avatars.","meta":{"url":"http://arxiv.org/abs/2307.06124v1"},"cats":{"new-dataset":0.183651307,"dev-research":0.4529235913,"prompt-eng":0.4715374507,"data-quality":0.1948981212,"ml-security":0.1077090386}}
{"text":"Membership inference (MI) attacks threaten user privacy through determining if a given data example has been used to train a target model.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.1001253592,"dev-research":0.4215012144,"prompt-eng":0.4861083731,"data-quality":0.1559200516,"ml-security":0.7903357626}}
{"text":"However, it has been increasingly recognized that the \"comparing different MI attacks\" methodology used in the existing works has serious limitations.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.0420560946,"dev-research":0.413414074,"prompt-eng":0.3866431385,"data-quality":0.0855858046,"ml-security":0.4115205602}}
{"text":"Due to these limitations, we found (through the experiments in this work) that some comparison results reported in the literature are quite misleading.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.1039623018,"dev-research":0.4038102639,"prompt-eng":0.3864334508,"data-quality":0.1447765775,"ml-security":0.0812172933}}
{"text":"In this paper, we seek to develop a comprehensive benchmark for comparing different MI attacks, called MIBench, which consists not only the evaluation metrics, but also the evaluation scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.0730234994,"dev-research":0.409648849,"prompt-eng":0.4419221499,"data-quality":0.1071554894,"ml-security":0.4875415795}}
{"text":"And we design the evaluation scenarios from four perspectives: the distance distribution of data samples in the target dataset, the distance between data samples of the target dataset, the differential distance between two datasets (i.e., the target dataset and a generated dataset with only nonmembers), and the ratio of the samples that are made no inferences by an MI attack.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.2843393738,"dev-research":0.38644737,"prompt-eng":0.4494456026,"data-quality":0.1663712283,"ml-security":0.497944248}}
{"text":"The evaluation metrics consist of ten typical evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.1127904559,"dev-research":0.4218227411,"prompt-eng":0.4835213913,"data-quality":0.1679785339,"ml-security":0.060604902}}
{"text":"We have identified three principles for the proposed \"comparing different MI attacks\" methodology, and we have designed and implemented the MIBench benchmark with 84 evaluation scenarios for each dataset.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.1212924716,"dev-research":0.3831586549,"prompt-eng":0.4432840915,"data-quality":0.1119884003,"ml-security":0.5149079197}}
{"text":"In total, we have used our benchmark to fairly and systematically compare 15 state-of-the-art MI attack algorithms across 588 evaluation scenarios, and these evaluation scenarios cover 7 widely used datasets and 7 representative types of models.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.1056843923,"dev-research":0.3918785031,"prompt-eng":0.4820511639,"data-quality":0.1110895398,"ml-security":0.6511910002}}
{"text":"All codes and evaluations of MIBench are publicly available at https://github.com/MIBench/MIBench.github.io/blob/main/README.md.","meta":{"url":"http://arxiv.org/abs/2307.06123v1"},"cats":{"new-dataset":0.2363990077,"dev-research":0.4395149174,"prompt-eng":0.4723838204,"data-quality":0.0960513483,"ml-security":0.0927270524}}
{"text":"This paper presents an innovative approach to student identification during exams and knowledge tests, which overcomes the limitations of the traditional personal information entry method.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.1460732945,"dev-research":0.4207345998,"prompt-eng":0.4989660572,"data-quality":0.2097166904,"ml-security":0.2447068975}}
{"text":"The proposed method employs a matrix template on the designated section of the exam, where squares containing numbers are selectively blackened.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.1038828017,"dev-research":0.4135896009,"prompt-eng":0.4162285863,"data-quality":0.1684479076,"ml-security":0.1287441946}}
{"text":"The methodology involves the development of a neural network specifically designed for recognizing students' personal identification numbers.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.1890243323,"dev-research":0.411731266,"prompt-eng":0.4593362359,"data-quality":0.208630515,"ml-security":0.354171037}}
{"text":"The neural network utilizes a specially adapted U-Net architecture, trained on an extensive dataset comprising images of blackened tables.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.2622021017,"dev-research":0.3909091695,"prompt-eng":0.4424672862,"data-quality":0.1687327139,"ml-security":0.1632468136}}
{"text":"The network demonstrates proficiency in recognizing the patterns and arrangement of blackened squares, accurately interpreting the information inscribed within them.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.2233420842,"dev-research":0.4120807017,"prompt-eng":0.4374519157,"data-quality":0.3063044234,"ml-security":0.1069243694}}
{"text":"Additionally, the model exhibits high accuracy in correctly identifying entered student personal numbers and effectively detecting erroneous entries within the table.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.201811429,"dev-research":0.4114122015,"prompt-eng":0.4955565531,"data-quality":0.3523619419,"ml-security":0.2265315444}}
{"text":"This approach offers multiple advantages.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.0339927297,"dev-research":0.4638179297,"prompt-eng":0.3511298386,"data-quality":0.0580719556,"ml-security":0.1152776695}}
{"text":"Firstly, it significantly accelerates the exam marking process by automatically extracting identifying information from the blackened tables, eliminating the need for manual entry and minimizing the potential for errors.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.0744856282,"dev-research":0.4642615679,"prompt-eng":0.4964142503,"data-quality":0.2939836555,"ml-security":0.0964918628}}
{"text":"Secondly, the method automates the identification process, thereby reducing administrative effort and expediting data processing.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.0531272512,"dev-research":0.4695868852,"prompt-eng":0.4209477185,"data-quality":0.2385764097,"ml-security":0.1882014887}}
{"text":"The introduction of this innovative identification system represents a notable advancement in the field of exams and knowledge tests, replacing the conventional manual entry of personal data with a streamlined, efficient, and accurate identification process.","meta":{"url":"http://arxiv.org/abs/2307.06120v1"},"cats":{"new-dataset":0.2953700297,"dev-research":0.3959062456,"prompt-eng":0.492558854,"data-quality":0.245619924,"ml-security":0.1892936752}}
{"text":"Automatic tree density estimation and counting using single aerial and satellite images is a challenging task in photogrammetry and remote sensing, yet has an important role in forest management.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.1339592165,"dev-research":0.3926352206,"prompt-eng":0.4232016235,"data-quality":0.1680355421,"ml-security":0.0599955509}}
{"text":"In this paper, we propose the first semisupervised transformer-based framework for tree counting which reduces the expensive tree annotations for remote sensing images.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.2709440454,"dev-research":0.3805109886,"prompt-eng":0.435654903,"data-quality":0.2118364839,"ml-security":0.0864698698}}
{"text":"Our method, termed as TreeFormer, first develops a pyramid tree representation module based on transformer blocks to extract multi-scale features during the encoding stage.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.2073030984,"dev-research":0.4254029406,"prompt-eng":0.4530254176,"data-quality":0.143590426,"ml-security":0.0857761548}}
{"text":"Contextual attention-based feature fusion and tree density regressor modules are further designed to utilize the robust features from the encoder to estimate tree density maps in the decoder.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.1593965986,"dev-research":0.4273830879,"prompt-eng":0.5077903877,"data-quality":0.2417109493,"ml-security":0.1171399027}}
{"text":"Moreover, we propose a pyramid learning strategy that includes local tree density consistency and local tree count ranking losses to utilize unlabeled images into the training process.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.1741202542,"dev-research":0.3828606076,"prompt-eng":0.4613824036,"data-quality":0.363001161,"ml-security":0.142081726}}
{"text":"Finally, the tree counter token is introduced to regulate the network by computing the global tree counts for both labeled and unlabeled images.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.197787413,"dev-research":0.4174253077,"prompt-eng":0.4572051978,"data-quality":0.4153772439,"ml-security":0.14861414}}
{"text":"Our model was evaluated on two benchmark tree counting datasets, Jiangsu, and Yosemite, as well as a new dataset, KCL-London, created by ourselves.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.5715111193,"dev-research":0.389081592,"prompt-eng":0.4537933304,"data-quality":0.1822950441,"ml-security":0.0819343811}}
{"text":"Our TreeFormer outperforms the state of the art semi-supervised methods under the same setting and exceeds the fully-supervised methods using the same number of labeled images.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.1998138417,"dev-research":0.3867768508,"prompt-eng":0.508418387,"data-quality":0.4192455099,"ml-security":0.1201125845}}
{"text":"The codes and datasets are available at https://github.com/HAAClassic/TreeFormer.","meta":{"url":"http://arxiv.org/abs/2307.06118v1"},"cats":{"new-dataset":0.7499093005,"dev-research":0.4152356246,"prompt-eng":0.4709584496,"data-quality":0.1569589777,"ml-security":0.0864197395}}
{"text":"Computing a shortest path between two nodes in an undirected unweighted graph is among the most basic algorithmic tasks.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.0546831743,"dev-research":0.4095372495,"prompt-eng":0.3289655619,"data-quality":0.0879839892,"ml-security":0.107114813}}
{"text":"Breadth first search solves this problem in linear time, which is clearly also a lower bound in the worst case.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.117742969,"dev-research":0.3970046115,"prompt-eng":0.3225766596,"data-quality":0.1108518242,"ml-security":0.162420909}}
{"text":"However, several works have shown how to solve this problem in sublinear time in expectation when the input graph is drawn from one of several classes of random graphs.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.1258321216,"dev-research":0.3881423651,"prompt-eng":0.4005681526,"data-quality":0.1826905844,"ml-security":0.1141139879}}
{"text":"In this work, we extend these results by giving sublinear time shortest path (and short path) algorithms for expander graphs.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.1058148783,"dev-research":0.4274093947,"prompt-eng":0.3541392385,"data-quality":0.0959385291,"ml-security":0.0630001939}}
{"text":"We thus identify a natural deterministic property of a graph (that is satisfied by typical random regular graphs) which suffices for sublinear time shortest paths.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.1182420672,"dev-research":0.4151739517,"prompt-eng":0.3854631928,"data-quality":0.1225659862,"ml-security":0.1635099582}}
{"text":"The algorithms are very simple, involving only bidirectional breadth first search and short random walks.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.0786515758,"dev-research":0.3850075478,"prompt-eng":0.3613836174,"data-quality":0.0723212919,"ml-security":0.117434243}}
{"text":"We also complement our new algorithms by near-matching lower bounds.","meta":{"url":"http://arxiv.org/abs/2307.06113v1"},"cats":{"new-dataset":0.1366843522,"dev-research":0.3914445659,"prompt-eng":0.3583360127,"data-quality":0.1668542051,"ml-security":0.1572612372}}
{"text":"Mart{\\'\\i}nez-Pe{\\~n}as and Kschischang (IEEE Trans.\\ Inf.\\ Theory, 2019)","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.1215964319,"dev-research":0.3866041091,"prompt-eng":0.3808768523,"data-quality":0.1255862223,"ml-security":0.0638657665}}
{"text":"proposed lifted linearized Reed--Solomon codes as suitable codes for error control in multishot network coding.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.1212188784,"dev-research":0.4506430221,"prompt-eng":0.4061379876,"data-quality":0.2504439534,"ml-security":0.1347263522}}
{"text":"We show how to construct and decode \\ac{LILRS} codes.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.2194695243,"dev-research":0.472922432,"prompt-eng":0.4501683616,"data-quality":0.1849451055,"ml-security":0.1300726078}}
{"text":"Compared to the construction by Mart{\\'\\i}nez-Pe{\\~n}as--Kschischang, interleaving allows to increase the decoding region significantly and decreases the overhead due to the lifting (i.e., increases the code rate), at the cost of an increased packet size.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.0513854189,"dev-research":0.4376677768,"prompt-eng":0.3955350084,"data-quality":0.1285803796,"ml-security":0.1298382463}}
{"text":"We propose two decoding schemes for \\ac{LILRS} that are both capable of correcting insertions and deletions beyond half the minimum distance of the code by either allowing a list or a small decoding failure probability.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.1264063272,"dev-research":0.4494792212,"prompt-eng":0.4434743155,"data-quality":0.2917277734,"ml-security":0.1847354125}}
{"text":"We propose a probabilistic unique {\\LOlike} decoder for \\ac{LILRS} codes and an efficient interpolation-based decoding scheme that can be either used as a list decoder (with exponential worst-case list size) or as a probabilistic unique decoder.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.1840371728,"dev-research":0.4200194496,"prompt-eng":0.4398205414,"data-quality":0.1893520092,"ml-security":0.1510245713}}
{"text":"We derive upper bounds on the decoding failure probability of the probabilistic-unique decoders which show that the decoding failure probability is very small for most channel realizations up to the maximal decoding radius.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.0731918378,"dev-research":0.4006783987,"prompt-eng":0.4465947564,"data-quality":0.3073537828,"ml-security":0.1905183266}}
{"text":"The tightness of the bounds is verified by Monte Carlo simulations.","meta":{"url":"http://arxiv.org/abs/2307.06108v1"},"cats":{"new-dataset":0.0736339355,"dev-research":0.3741612193,"prompt-eng":0.3874611418,"data-quality":0.1140819225,"ml-security":0.1572061029}}
{"text":"Recent progress in research on Deep Graph Networks (DGNs) has led to a maturation of the domain of learning on graphs.","meta":{"url":"http://arxiv.org/abs/2307.06104v1"},"cats":{"new-dataset":0.1428745633,"dev-research":0.4008803385,"prompt-eng":0.4119678784,"data-quality":0.1466645316,"ml-security":0.241740851}}
{"text":"Despite the growth of this research field, there are still important challenges that are yet unsolved.","meta":{"url":"http://arxiv.org/abs/2307.06104v1"},"cats":{"new-dataset":0.1301481188,"dev-research":0.4076449709,"prompt-eng":0.3496884054,"data-quality":0.1403817278,"ml-security":0.1472043168}}
{"text":"Specifically, there is an urge of making DGNs suitable for predictive tasks on realworld systems of interconnected entities, which evolve over time.","meta":{"url":"http://arxiv.org/abs/2307.06104v1"},"cats":{"new-dataset":0.077358163,"dev-research":0.4760087371,"prompt-eng":0.4482487055,"data-quality":0.0646660463,"ml-security":0.2209381707}}
{"text":"With the aim of fostering research in the domain of dynamic graphs, at first, we survey recent advantages in learning both temporal and spatial information, providing a comprehensive overview of the current state-of-the-art in the domain of representation learning for dynamic graphs.","meta":{"url":"http://arxiv.org/abs/2307.06104v1"},"cats":{"new-dataset":0.1922620703,"dev-research":0.4062743495,"prompt-eng":0.4444547727,"data-quality":0.1434529672,"ml-security":0.126926891}}
{"text":"Secondly, we conduct a fair performance comparison among the most popular proposed approaches, leveraging rigorous model selection and assessment for all the methods, thus establishing a sound baseline for evaluating new architectures and approaches","meta":{"url":"http://arxiv.org/abs/2307.06104v1"},"cats":{"new-dataset":0.0243693288,"dev-research":0.4025402465,"prompt-eng":0.4199374804,"data-quality":0.0600635033,"ml-security":0.0689160842}}
{"text":"Autonomous navigation in unknown environments with obstacles remains challenging for micro aerial vehicles (MAVs) due to their limited onboard computing and sensing resources.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.0825641198,"dev-research":0.3682289268,"prompt-eng":0.3912093655,"data-quality":0.0780231108,"ml-security":0.1276086121}}
{"text":"Although various collision avoidance methods have been developed, it is still possible for drones to collide with unobserved obstacles due to unpredictable disturbances, sensor limitations, and control uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.0932850759,"dev-research":0.3816147956,"prompt-eng":0.3950380723,"data-quality":0.077514853,"ml-security":0.1886547521}}
{"text":"Instead of completely avoiding collisions, this article proposes Air Bumper, a collision detection and reaction framework, for fully autonomous flight in 3D environments to improve the safety of drones.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.1588075636,"dev-research":0.42237102,"prompt-eng":0.3956256523,"data-quality":0.0794142122,"ml-security":0.1599151405}}
{"text":"Our framework only utilizes the onboard inertial measurement unit (IMU) to detect and estimate collisions.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.1530274195,"dev-research":0.3760772552,"prompt-eng":0.3944521543,"data-quality":0.0808288835,"ml-security":0.1298134056}}
{"text":"We further design a collision recovery control for rapid recovery and collision-aware mapping to integrate collision information into general LiDAR-based sensing and planning frameworks.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.196573929,"dev-research":0.3619732182,"prompt-eng":0.430632493,"data-quality":0.0866872394,"ml-security":0.1157245071}}
{"text":"Our simulation and experimental results show that the quadrotor can rapidly detect, estimate, and recover from collisions with obstacles in 3D space and continue the flight smoothly with the help of the collision-aware map.","meta":{"url":"http://arxiv.org/abs/2307.06101v1"},"cats":{"new-dataset":0.1681005623,"dev-research":0.3793545384,"prompt-eng":0.3952379175,"data-quality":0.0715406373,"ml-security":0.1130421416}}
{"text":"Autonomous, agile quadrotor flight raises fundamental challenges for robotics research in terms of perception, planning, learning, and control.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.1163532038,"dev-research":0.3962167231,"prompt-eng":0.4159652323,"data-quality":0.0666443053,"ml-security":0.1184889842}}
{"text":"A versatile and standardized platform is needed to accelerate research and let practitioners focus on the core problems.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.0956360749,"dev-research":0.4449719289,"prompt-eng":0.3801771853,"data-quality":0.0472120599,"ml-security":0.0755442206}}
{"text":"To this end, we present Agilicious, a co-designed hardware and software framework tailored to autonomous, agile quadrotor flight.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.2230719133,"dev-research":0.4431817181,"prompt-eng":0.4301928619,"data-quality":0.0487495132,"ml-security":0.098158621}}
{"text":"It is completely open-source and open-hardware and supports both model-based and neural-network--based controllers.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.2022475495,"dev-research":0.395607361,"prompt-eng":0.4132532635,"data-quality":0.0419808425,"ml-security":0.1282155187}}
{"text":"Also, it provides high thrust-to-weight and torque-to-inertia ratios for agility, onboard vision sensors, GPU-accelerated compute hardware for real-time perception and neural-network inference, a real-time flight controller, and a versatile software stack.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.198593818,"dev-research":0.4020131496,"prompt-eng":0.4036686787,"data-quality":0.0377371647,"ml-security":0.0669215241}}
{"text":"In contrast to existing frameworks, Agilicious offers a unique combination of flexible software stack and high-performance hardware.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.2407831105,"dev-research":0.4832248103,"prompt-eng":0.4628610578,"data-quality":0.0600320014,"ml-security":0.1144785382}}
{"text":"We compare Agilicious with prior works and demonstrate it on different agile tasks, using both model-based and neural-network--based controllers.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.1403976375,"dev-research":0.486576415,"prompt-eng":0.5113307786,"data-quality":0.0745760274,"ml-security":0.1084378449}}
{"text":"Our demonstrators include trajectory tracking at up to 5g and 70 km/h in a motion-capture system, and vision-based acrobatic flight and obstacle avoidance in both structured and unstructured environments using solely onboard perception.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.2072888909,"dev-research":0.338602615,"prompt-eng":0.4000408441,"data-quality":0.0592008686,"ml-security":0.0829110005}}
{"text":"Finally, we demonstrate its use for hardware-in-the-loop simulation in virtual-reality environments.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.139128788,"dev-research":0.4038632645,"prompt-eng":0.3999918363,"data-quality":0.0743498115,"ml-security":0.0673784472}}
{"text":"Thanks to its versatility, we believe that Agilicious supports the next generation of scientific and industrial quadrotor research.","meta":{"url":"http://arxiv.org/abs/2307.06100v1"},"cats":{"new-dataset":0.1501401202,"dev-research":0.4105914921,"prompt-eng":0.4412866697,"data-quality":0.0586587396,"ml-security":0.0823789009}}
{"text":"Glass-like objects are widespread in daily life but remain intractable to be segmented for most existing methods.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.0767990438,"dev-research":0.3561407346,"prompt-eng":0.3800136826,"data-quality":0.0955225263,"ml-security":0.1222313452}}
{"text":"The transparent property makes it difficult to be distinguished from background, while the tiny separation boundary further impedes the acquisition of their exact contour.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.0427475772,"dev-research":0.4012800556,"prompt-eng":0.3754533094,"data-quality":0.1265448342,"ml-security":0.0936766701}}
{"text":"In this paper, by revealing the key co-evolution demand of semantic and boundary learning, we propose a Selective Mutual Evolution (SME) module to enable the reciprocal feature learning between them.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.0969051182,"dev-research":0.4017837718,"prompt-eng":0.4957454385,"data-quality":0.1480823141,"ml-security":0.1152694283}}
{"text":"Then to exploit the global shape context, we propose a Structurally Attentive Refinement (SAR) module to conduct a fine-grained feature refinement for those ambiguous points around the boundary.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.0715659491,"dev-research":0.3976706962,"prompt-eng":0.4391386013,"data-quality":0.1716885521,"ml-security":0.0610855947}}
{"text":"Finally, to further utilize the multi-scale representation, we integrate the above two modules into a cascaded structure and then introduce a Reciprocal Feature Evolution Network (RFENet) for effective glass-like object segmentation.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.1165470345,"dev-research":0.3437074655,"prompt-eng":0.4518635243,"data-quality":0.1114398184,"ml-security":0.0767807754}}
{"text":"Extensive experiments demonstrate that our RFENet achieves state-of-the-art performance on three popular public datasets.","meta":{"url":"http://arxiv.org/abs/2307.06099v1"},"cats":{"new-dataset":0.430886704,"dev-research":0.3642662061,"prompt-eng":0.4952070623,"data-quality":0.1531196035,"ml-security":0.1411341582}}
{"text":"Stochastic Gumbel graph networks are proposed to learn high-dimensional time series, where the observed dimensions are often spatially correlated.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.1901332392,"dev-research":0.3701511859,"prompt-eng":0.4083310888,"data-quality":0.1030821353,"ml-security":0.1455590691}}
{"text":"To that end, the observed randomness and spatial-correlations are captured by learning the drift and diffusion terms of the stochastic differential equation with a Gumble matrix embedding, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.115917869,"dev-research":0.3778293963,"prompt-eng":0.4427517589,"data-quality":0.1518620007,"ml-security":0.1618080456}}
{"text":"In particular, this novel framework enables us to investigate the implicit regularization effect of the noise terms in S-GGNs.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.0388633443,"dev-research":0.3763070131,"prompt-eng":0.4374539968,"data-quality":0.2684496803,"ml-security":0.2072350378}}
{"text":"We provide a theoretical guarantee for the proposed S-GGNs by deriving the difference between the two corresponding loss functions in a small neighborhood of weight.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.0403169989,"dev-research":0.3698934704,"prompt-eng":0.3964715266,"data-quality":0.1306698938,"ml-security":0.1944564446}}
{"text":"Then, we employ Kuramoto's model to generate data for comparing the spectral density from the Hessian Matrix of the two loss functions.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.1172880038,"dev-research":0.3530883266,"prompt-eng":0.4421361252,"data-quality":0.1287964936,"ml-security":0.1213348992}}
{"text":"Experimental results on real-world data, demonstrate that S-GGNs exhibit superior convergence, robustness, and generalization, compared with state-of-the-arts.","meta":{"url":"http://arxiv.org/abs/2307.06097v1"},"cats":{"new-dataset":0.0913752666,"dev-research":0.3479176998,"prompt-eng":0.3977465765,"data-quality":0.1439321746,"ml-security":0.2116269283}}
{"text":"In relay-enabled cellular networks, the intertwined nature of network agents calls for complex schemes to allocate wireless resources.","meta":{"url":"http://arxiv.org/abs/2307.06095v1"},"cats":{"new-dataset":0.0451542727,"dev-research":0.4280232823,"prompt-eng":0.3794205979,"data-quality":0.0546716268,"ml-security":0.184747043}}
{"text":"Resources need to be distributed among mobile users while considering how relay resources are allocated, and constrained by the traffic rate achievable by base stations and over backhaul links.","meta":{"url":"http://arxiv.org/abs/2307.06095v1"},"cats":{"new-dataset":0.0702913914,"dev-research":0.4151576349,"prompt-eng":0.4059197083,"data-quality":0.0540717381,"ml-security":0.1723262442}}
{"text":"In this work, we derive a resource allocation scheme that achieves max-min fairness across mobile users.","meta":{"url":"http://arxiv.org/abs/2307.06095v1"},"cats":{"new-dataset":0.1198834941,"dev-research":0.4136273163,"prompt-eng":0.4014203294,"data-quality":0.0855512735,"ml-security":0.320313566}}
{"text":"Furthermore, the optimal allocation is found with linear complexity with respect to the number of mobile users and relays.","meta":{"url":"http://arxiv.org/abs/2307.06095v1"},"cats":{"new-dataset":0.0716762224,"dev-research":0.4189968248,"prompt-eng":0.3566724236,"data-quality":0.0521333695,"ml-security":0.1792735021}}
{"text":"The Laplace approximation provides a closed-form model selection objective for neural networks (NN).","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0600433872,"dev-research":0.347119659,"prompt-eng":0.4041196037,"data-quality":0.1000268326,"ml-security":0.2065484637}}
{"text":"Online variants, which optimise NN parameters jointly with hyperparameters, like weight decay strength, have seen renewed interest in the Bayesian deep learning community.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.1210746697,"dev-research":0.3622728881,"prompt-eng":0.4790977968,"data-quality":0.0901352035,"ml-security":0.2201524581}}
{"text":"However, these methods violate Laplace's method's critical assumption that the approximation is performed around a mode of the loss, calling into question their soundness.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0378605255,"dev-research":0.3856496276,"prompt-eng":0.3534741313,"data-quality":0.3001303184,"ml-security":0.2300517923}}
{"text":"This work re-derives online Laplace methods, showing them to target a variational bound on a mode-corrected variant of the Laplace evidence which does not make stationarity assumptions.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0645671563,"dev-research":0.3751217641,"prompt-eng":0.4076177488,"data-quality":0.1588240715,"ml-security":0.1306288977}}
{"text":"Online Laplace and its mode-corrected counterpart share stationary points where 1.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0894576352,"dev-research":0.3542945717,"prompt-eng":0.3702056854,"data-quality":0.1277637071,"ml-security":0.0977932381}}
{"text":"the NN parameters are a maximum a posteriori, satisfying the Laplace method's assumption, and 2.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.104004437,"dev-research":0.3690355473,"prompt-eng":0.3903883513,"data-quality":0.1065637695,"ml-security":0.1192114996}}
{"text":"the hyperparameters maximise the Laplace evidence, motivating online methods.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0510334794,"dev-research":0.3953788447,"prompt-eng":0.4280164472,"data-quality":0.1169067896,"ml-security":0.176131828}}
{"text":"We demonstrate that these optima are roughly attained in practise by online algorithms using full-batch gradient descent on UCI regression datasets.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.1968482701,"dev-research":0.3668227273,"prompt-eng":0.4549093184,"data-quality":0.1090918069,"ml-security":0.2100158322}}
{"text":"The optimised hyperparameters prevent overfitting and outperform validation-based early stopping.","meta":{"url":"http://arxiv.org/abs/2307.06093v1"},"cats":{"new-dataset":0.0547067289,"dev-research":0.4139562218,"prompt-eng":0.4845260151,"data-quality":0.1788434279,"ml-security":0.2332533987}}
{"text":"We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth.","meta":{"url":"http://arxiv.org/abs/2307.06092v1"},"cats":{"new-dataset":0.0996305921,"dev-research":0.3457587352,"prompt-eng":0.3831698039,"data-quality":0.165761572,"ml-security":0.3866522216}}
{"text":"Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\\gamma}$ for $\\gamma>0,$ with the exponent depending on the metric used to measure discrepancy.","meta":{"url":"http://arxiv.org/abs/2307.06092v1"},"cats":{"new-dataset":0.063611892,"dev-research":0.3632009908,"prompt-eng":0.3786260868,"data-quality":0.0978906862,"ml-security":0.1244265285}}
{"text":"Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.","meta":{"url":"http://arxiv.org/abs/2307.06092v1"},"cats":{"new-dataset":0.0759994678,"dev-research":0.4050273626,"prompt-eng":0.324402404,"data-quality":0.0880674096,"ml-security":0.2401265749}}
{"text":"Motivated by the efficiency investigation of the Tranformer-based transform coding framework, namely SwinT-ChARM, we propose to enhance the latter, as first, with a more straightforward yet effective Tranformer-based channel-wise auto-regressive prior model, resulting in an absolute image compression transformer (ICT).","meta":{"url":"http://arxiv.org/abs/2307.06091v1"},"cats":{"new-dataset":0.1076228924,"dev-research":0.4034030144,"prompt-eng":0.4328672276,"data-quality":0.1019729456,"ml-security":0.0842987157}}
{"text":"Current methods that still rely on ConvNet-based entropy coding are limited in long-range modeling dependencies due to their local connectivity and an increasing number of architectural biases and priors.","meta":{"url":"http://arxiv.org/abs/2307.06091v1"},"cats":{"new-dataset":0.1298847882,"dev-research":0.3908544606,"prompt-eng":0.4390981912,"data-quality":0.1102309196,"ml-security":0.1381291926}}
{"text":"On the contrary, the proposed ICT can capture both global and local contexts from the latent representations and better parameterize the distribution of the quantized latents.","meta":{"url":"http://arxiv.org/abs/2307.06091v1"},"cats":{"new-dataset":0.1217282621,"dev-research":0.4070591483,"prompt-eng":0.4841673812,"data-quality":0.1279647822,"ml-security":0.1444564139}}
{"text":"Further, we leverage a learnable scaling module with a sandwich ConvNeXt-based pre/post-processor to accurately extract more compact latent representation while reconstructing higher-quality images.","meta":{"url":"http://arxiv.org/abs/2307.06091v1"},"cats":{"new-dataset":0.2050390424,"dev-research":0.3654566895,"prompt-eng":0.4805653067,"data-quality":0.1458311696,"ml-security":0.0914643226}}
{"text":"Extensive experimental results on benchmark datasets showed that the proposed adaptive image compression transformer (AICT) framework significantly improves the trade-off between coding efficiency and decoder complexity over the versatile video coding (VVC) reference encoder (VTM-18.0) and the neural codec SwinT-ChARM.","meta":{"url":"http://arxiv.org/abs/2307.06091v1"},"cats":{"new-dataset":0.2842743294,"dev-research":0.4011094185,"prompt-eng":0.3910709012,"data-quality":0.1398994207,"ml-security":0.0762376189}}
{"text":"Despite recent advancements in speech emotion recognition (SER) models, state-of-the-art deep learning (DL) approaches face the challenge of the limited availability of annotated data.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.2832375037,"dev-research":0.3596132298,"prompt-eng":0.4925365407,"data-quality":0.2234598794,"ml-security":0.2014455442}}
{"text":"Large language models (LLMs) have revolutionised our understanding of natural language, introducing emergent properties that broaden comprehension in language, speech, and vision.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.1709386262,"dev-research":0.4430421045,"prompt-eng":0.5644699613,"data-quality":0.1331910008,"ml-security":0.1155827655}}
{"text":"This paper examines the potential of LLMs to annotate abundant speech data, aiming to enhance the state-of-the-art in SER.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.289822461,"dev-research":0.3929556022,"prompt-eng":0.593211034,"data-quality":0.3321759184,"ml-security":0.1527703509}}
{"text":"We evaluate this capability across various settings using publicly available speech emotion classification datasets.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.3277715968,"dev-research":0.3507052289,"prompt-eng":0.4762873434,"data-quality":0.1829624056,"ml-security":0.2181292497}}
{"text":"Leveraging ChatGPT, we experimentally demonstrate the promising role of LLMs in speech emotion data annotation.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.3594213349,"dev-research":0.4361893246,"prompt-eng":0.5806191582,"data-quality":0.2640970969,"ml-security":0.1414833023}}
{"text":"Our evaluation encompasses single-shot and few-shots scenarios, revealing performance variability in SER.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.0992876941,"dev-research":0.4068249182,"prompt-eng":0.4693279135,"data-quality":0.0953303923,"ml-security":0.0828495214}}
{"text":"Notably, we achieve improved results through data augmentation, incorporating ChatGPT-annotated samples into existing datasets.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.6029629892,"dev-research":0.4447855632,"prompt-eng":0.5474996006,"data-quality":0.3206142419,"ml-security":0.1081590689}}
{"text":"Our work uncovers new frontiers in speech emotion classification, highlighting the increasing significance of LLMs in this field moving forward.","meta":{"url":"http://arxiv.org/abs/2307.06090v1"},"cats":{"new-dataset":0.208612875,"dev-research":0.3812450929,"prompt-eng":0.5276508195,"data-quality":0.2063135109,"ml-security":0.180016579}}
{"text":"User Experience (UX) professionals need to be able to analyze large amounts of usage data on their own to make evidence-based design decisions.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.2708441051,"dev-research":0.5089418693,"prompt-eng":0.4614909955,"data-quality":0.0813811535,"ml-security":0.1796105988}}
{"text":"However, the design process for In-Vehicle Information Systems (IVIS) lacks data-driven support and effective tools for visualizing and analyzing user interaction data.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.3189039891,"dev-research":0.4630392269,"prompt-eng":0.4659358211,"data-quality":0.0858523641,"ml-security":0.1025236502}}
{"text":"Therefore, we propose ICEBOAT, an interactive visualization tool tailored to the needs of automotive UX experts to effectively and efficiently evaluate driver interactions with IVISs.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.2610343412,"dev-research":0.4613234848,"prompt-eng":0.4657229287,"data-quality":0.0732278406,"ml-security":0.0870117268}}
{"text":"ICEBOAT visualizes telematics data collected from production line vehicles, allowing UX experts to perform task-specific analyses.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.2891802204,"dev-research":0.4565397908,"prompt-eng":0.4481813058,"data-quality":0.0858950574,"ml-security":0.1272705347}}
{"text":"Following a mixed methods User-centered design (UCD) approach, we conducted an interview study (N=4) to extract the domain specific information and interaction needs of automotive UX experts and used a co-design approach (N=4) to develop an interactive analysis tool.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.0978925173,"dev-research":0.4999667253,"prompt-eng":0.4572257531,"data-quality":0.07626349,"ml-security":0.0643877916}}
{"text":"Our evaluation (N=12) shows that ICEBOAT enables UX experts to efficiently generate knowledge that facilitates data-driven design decisions.","meta":{"url":"http://arxiv.org/abs/2307.06089v1"},"cats":{"new-dataset":0.2421728791,"dev-research":0.5086974555,"prompt-eng":0.4523166093,"data-quality":0.0661216893,"ml-security":0.1650261512}}
{"text":"Training deep neural networks (DNNs) is computationally intensive but arrays of non-volatile memories like Charge Trap Flash (CTF) can accelerate DNN operations using in-memory computing.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.1985671947,"dev-research":0.3824709061,"prompt-eng":0.4252888726,"data-quality":0.1127827252,"ml-security":0.3108945017}}
{"text":"Specifically, the Resistive Processing Unit (RPU) architecture uses the voltage-threshold program by stochastic encoded pulse trains and analog memory features to accelerate vector-vector outer product and weight update for the gradient descent algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.0413420472,"dev-research":0.3676522289,"prompt-eng":0.4191533823,"data-quality":0.1226175905,"ml-security":0.2423813661}}
{"text":"Although CTF, offering high precision, has been regarded as an excellent choice for implementing RPU, the accumulation of charge due to the applied stochastic pulse trains is ultimately of critical significance in determining the final weight update.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.0740773214,"dev-research":0.3547751073,"prompt-eng":0.431672001,"data-quality":0.1627433525,"ml-security":0.1303432695}}
{"text":"In this paper, we report the non-ideal program-time conservation in CTF through pulsing input measurements.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.1181185661,"dev-research":0.3933177321,"prompt-eng":0.4122024024,"data-quality":0.1071689343,"ml-security":0.1802778167}}
{"text":"We experimentally measure the effect of pulse width and pulse gap, keeping the total ON-time of the input pulse train constant, and report three non-idealities: (1) Cumulative V_T shift reduces when total ON-time is fragmented into a larger number of shorter pulses, (2) Cumulative V_T shift drops abruptly for pulse widths < 2 {\\mu}s, (3) Cumulative V_T shift depends on the gap between consecutive pulses and the V_T shift reduction gets recovered for smaller gaps.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.0668313798,"dev-research":0.3689501504,"prompt-eng":0.3490286849,"data-quality":0.1027029645,"ml-security":0.0911217676}}
{"text":"We present an explanation based on a transient tunneling field enhancement due to blocking oxide trap-charge dynamics to explain these non-idealities.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.0626783278,"dev-research":0.4270502828,"prompt-eng":0.4032682167,"data-quality":0.0773834358,"ml-security":0.1770412707}}
{"text":"Identifying and modeling the responsible mechanisms and predicting their system-level effects during learning is critical.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.062240077,"dev-research":0.4767754633,"prompt-eng":0.4970938658,"data-quality":0.190856942,"ml-security":0.3575487203}}
{"text":"This non-ideal accumulation is expected to affect algorithms and architectures relying on devices for implementing mathematically equivalent functions for in-memory computing-based acceleration.","meta":{"url":"http://arxiv.org/abs/2307.06088v1"},"cats":{"new-dataset":0.0402137245,"dev-research":0.4057256667,"prompt-eng":0.3333760842,"data-quality":0.0713301976,"ml-security":0.1272391206}}
{"text":"Mixed-signal neuromorphic systems represent a promising solution for solving extreme-edge computing tasks without relying on external computing resources.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.0811857795,"dev-research":0.3830594974,"prompt-eng":0.3491929314,"data-quality":0.0537179013,"ml-security":0.1820527684}}
{"text":"Their spiking neural network circuits are optimized for processing sensory data on-line in continuous-time.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.1280255997,"dev-research":0.3842543514,"prompt-eng":0.3895831144,"data-quality":0.0804135864,"ml-security":0.0917467028}}
{"text":"However, their low precision and high variability can severely limit their performance.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.0704535903,"dev-research":0.3958141745,"prompt-eng":0.4066841551,"data-quality":0.1942639824,"ml-security":0.1745715879}}
{"text":"To address this issue and improve their robustness to inhomogeneities and noise in both their internal state variables and external input signals, we designed on-chip learning circuits with short-term analog dynamics and long-term tristate discretization mechanisms.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.0708369394,"dev-research":0.3858545662,"prompt-eng":0.4069006236,"data-quality":0.1379271875,"ml-security":0.2712172654}}
{"text":"An additional hysteretic stop-learning mechanism is included to improve stability and automatically disable weight updates when necessary, to enable continuous always-on learning.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.0592718197,"dev-research":0.3717878714,"prompt-eng":0.4201094908,"data-quality":0.1065310429,"ml-security":0.1615524923}}
{"text":"We designed a spiking neural network with these learning circuits in a prototype chip using a 180 nm CMOS technology.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.143580814,"dev-research":0.3711928355,"prompt-eng":0.4162264129,"data-quality":0.1097412462,"ml-security":0.2011136974}}
{"text":"Simulation and silicon measurement results from the prototype chip are presented.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.1166372776,"dev-research":0.4024540338,"prompt-eng":0.4224247218,"data-quality":0.1486573498,"ml-security":0.0718653293}}
{"text":"These circuits enable the construction of large-scale spiking neural networks with online learning capabilities for real-world edge computing tasks.","meta":{"url":"http://arxiv.org/abs/2307.06084v1"},"cats":{"new-dataset":0.1357547151,"dev-research":0.3821001317,"prompt-eng":0.3908798385,"data-quality":0.0594777432,"ml-security":0.2160511478}}
{"text":"Incremental decision making in real-world environments is one of the most challenging tasks in embodied artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.0907399092,"dev-research":0.4389136162,"prompt-eng":0.4347458014,"data-quality":0.0560392882,"ml-security":0.1068824248}}
{"text":"One particularly demanding scenario is Vision and Language Navigation~(VLN) which requires visual and natural language understanding as well as spatial and temporal reasoning capabilities.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.2343826746,"dev-research":0.4648076994,"prompt-eng":0.4882147274,"data-quality":0.0948033511,"ml-security":0.0591934227}}
{"text":"The embodied agent needs to ground its understanding of navigation instructions in observations of a real-world environment like Street View.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.1268114738,"dev-research":0.4436289583,"prompt-eng":0.4596981704,"data-quality":0.0633472601,"ml-security":0.0898275642}}
{"text":"Despite the impressive results of LLMs in other research areas, it is an ongoing problem of how to best connect them with an interactive visual environment.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.2129097143,"dev-research":0.4619359731,"prompt-eng":0.5480527365,"data-quality":0.079078232,"ml-security":0.0787444249}}
{"text":"In this work, we propose VELMA, an embodied LLM agent that uses a verbalization of the trajectory and of visual environment observations as contextual prompt for the next action.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.1540373301,"dev-research":0.4754263499,"prompt-eng":0.5634566159,"data-quality":0.0730980775,"ml-security":0.108931095}}
{"text":"Visual information is verbalized by a pipeline that extracts landmarks from the human written navigation instructions and uses CLIP to determine their visibility in the current panorama view.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.1796679228,"dev-research":0.4582546865,"prompt-eng":0.478429613,"data-quality":0.0981236254,"ml-security":0.0769373716}}
{"text":"We show that VELMA is able to successfully follow navigation instructions in Street View with only two in-context examples.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.1263626503,"dev-research":0.435732739,"prompt-eng":0.4745599767,"data-quality":0.0929093432,"ml-security":0.1140381352}}
{"text":"We further finetune the LLM agent on a few thousand examples and achieve 25%-30% relative improvement in task completion over the previous state-of-the-art for two datasets.","meta":{"url":"http://arxiv.org/abs/2307.06082v1"},"cats":{"new-dataset":0.2251641083,"dev-research":0.4309037242,"prompt-eng":0.5567436447,"data-quality":0.1503037759,"ml-security":0.0867040338}}
{"text":"In this paper, the adoption patterns of Generative Artificial Intelligence (AI) tools within software engineering are investigated.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.1663598301,"dev-research":0.5537713823,"prompt-eng":0.5075844524,"data-quality":0.0898527275,"ml-security":0.0881955233}}
{"text":"Influencing factors at the individual, technological, and societal levels are analyzed using a mixed-methods approach for an extensive comprehension of AI adoption.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.1033245776,"dev-research":0.4693835266,"prompt-eng":0.428118796,"data-quality":0.0888305375,"ml-security":0.0760357791}}
{"text":"An initial structured interview was conducted with 100 software engineers, employing the Technology Acceptance Model (TAM), the Diffusion of Innovations theory (DOI), and the Social Cognitive Theory (SCT) as guiding theories.   ","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.0941253215,"dev-research":0.5330545287,"prompt-eng":0.4933717935,"data-quality":0.1035020152,"ml-security":0.0963572847}}
{"text":"A theoretical model named the Human-AI Collaboration and Adaptation Framework (HACAF) was deduced using the Gioia Methodology, characterizing AI adoption in software engineering.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.1269784504,"dev-research":0.5188903134,"prompt-eng":0.4139095516,"data-quality":0.0798294526,"ml-security":0.1001310246}}
{"text":"This model's validity was subsequently tested through Partial Least Squares - Structural Equation Modeling (PLS-SEM), using data collected from 183 software professionals.   ","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.1158089605,"dev-research":0.4758650132,"prompt-eng":0.441111115,"data-quality":0.1172297892,"ml-security":0.1293760189}}
{"text":"The results indicate that the adoption of AI tools in these early integration stages is primarily driven by their compatibility with existing development workflows.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.0905559871,"dev-research":0.52854805,"prompt-eng":0.4637499817,"data-quality":0.0753890263,"ml-security":0.0826149275}}
{"text":"This finding counters the traditional theories of technology acceptance.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.0698559592,"dev-research":0.4842047871,"prompt-eng":0.4310611536,"data-quality":0.1295103456,"ml-security":0.1147295642}}
{"text":"Contrary to expectations, the influence of perceived usefulness, social aspects, and personal innovativeness on adoption appeared to be less significant.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.0455766141,"dev-research":0.4789264264,"prompt-eng":0.386468599,"data-quality":0.1016473721,"ml-security":0.0732182113}}
{"text":"This paper yields significant insights for the design of future AI tools and supplies a structure for devising effective strategies for organizational implementation.","meta":{"url":"http://arxiv.org/abs/2307.06081v1"},"cats":{"new-dataset":0.0961063961,"dev-research":0.4686225087,"prompt-eng":0.4278539894,"data-quality":0.0624253634,"ml-security":0.1203520554}}
{"text":"This paper provides new and improved Singleton-like bounds for Lee metric codes over integer residue rings.","meta":{"url":"http://arxiv.org/abs/2307.06079v1"},"cats":{"new-dataset":0.1361849359,"dev-research":0.4451122468,"prompt-eng":0.3783647429,"data-quality":0.1713052334,"ml-security":0.1176832504}}
{"text":"We derive the bounds using various novel definitions of generalized Lee weights based on different notions of a support of a linear code.","meta":{"url":"http://arxiv.org/abs/2307.06079v1"},"cats":{"new-dataset":0.0530030107,"dev-research":0.4419949335,"prompt-eng":0.3760170575,"data-quality":0.160416723,"ml-security":0.213170211}}
{"text":"In this regard, we introduce three main different support types for codes in the Lee metric and analyze their utility to derive bounds on the minimum Lee distance.","meta":{"url":"http://arxiv.org/abs/2307.06079v1"},"cats":{"new-dataset":0.1286753009,"dev-research":0.4582200225,"prompt-eng":0.3888113291,"data-quality":0.181995346,"ml-security":0.1059389702}}
{"text":"Eventually, we propose a new point of view to generalized weights and give an improved bound on the minimum distance of codes in the Lee metric for which we discuss the density of maximum Lee distance codes with respect to this novel Singleton-like bound.","meta":{"url":"http://arxiv.org/abs/2307.06079v1"},"cats":{"new-dataset":0.1122227888,"dev-research":0.4397736766,"prompt-eng":0.3928964462,"data-quality":0.1976250407,"ml-security":0.1535410953}}
{"text":"We consider a voting model, where a number of candidates need to be selected subject to certain feasibility constraints.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0391011855,"dev-research":0.382247494,"prompt-eng":0.4603294339,"data-quality":0.0896067532,"ml-security":0.1966654301}}
{"text":"The model generalises committee elections (where there is a single constraint on the number of candidates that need to be selected), various elections with diversity constraints, the model of public decisions (where decisions needs to be taken on a number of independent issues), and the model of collective scheduling.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0712958429,"dev-research":0.3871144999,"prompt-eng":0.4299197999,"data-quality":0.0839534523,"ml-security":0.1493075471}}
{"text":"A critical property of voting is that it should be fair -- not only to individuals but also to groups of voters with similar opinions on the subject of the vote; in other words, the outcome of an election should proportionally reflect the voters' preferences.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0480167889,"dev-research":0.390722322,"prompt-eng":0.3987701539,"data-quality":0.114415433,"ml-security":0.1891745301}}
{"text":"We formulate axioms of proportionality in this general model.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0617114431,"dev-research":0.3940566259,"prompt-eng":0.4279237809,"data-quality":0.095073442,"ml-security":0.159927089}}
{"text":"Our axioms do not require predefining groups of voters; to the contrary, we ensure that the opinion of every subset of voters whose preferences are cohesive-enough are taken into account to the extent that is proportional to the size of the subset.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0623110301,"dev-research":0.4377492193,"prompt-eng":0.4282177053,"data-quality":0.1058664297,"ml-security":0.1420490598}}
{"text":"Our axioms are always satisfiable, and generalize the strongest known satisfiable axioms for the more specific models.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0567930467,"dev-research":0.3883600518,"prompt-eng":0.4251184194,"data-quality":0.1120046699,"ml-security":0.1984208103}}
{"text":"We explain how to adapt two prominent committee election rules, Proportional Approval Voting (PAV) and Phragmen Sequential Rule, as well as the concept of stable-priceability to our general model.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.0564137095,"dev-research":0.3724134075,"prompt-eng":0.4356726742,"data-quality":0.08914546,"ml-security":0.1263238441}}
{"text":"The two rules satisfy our proportionality axioms if and only if the feasibility constraints are matroids.","meta":{"url":"http://arxiv.org/abs/2307.06077v1"},"cats":{"new-dataset":0.027870891,"dev-research":0.4006290735,"prompt-eng":0.3557296643,"data-quality":0.0894179309,"ml-security":0.1378980848}}
{"text":"In operator overloading algorithmic differentiation, it can be beneficial to create custom derivative functions for some parts of the code base.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.0366376908,"dev-research":0.4672420635,"prompt-eng":0.4012191812,"data-quality":0.1277551063,"ml-security":0.2661498069}}
{"text":"For manual implementations of the derivative functions, it can be quite cumbersome to derive, implement, test, and maintain these.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.0766224072,"dev-research":0.4854514161,"prompt-eng":0.4426000687,"data-quality":0.1023290842,"ml-security":0.1182647071}}
{"text":"The process can be automated with source transformation algorithmic differentiation tools like Tapenade or compiler-based algorithmic differentiation tools like Enzyme.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.0829091428,"dev-research":0.4874035022,"prompt-eng":0.4554009425,"data-quality":0.124794843,"ml-security":0.126753692}}
{"text":"This eliminates most of the work required from a manual implementation but usually has the same efficiency with respect to timing and memory.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.0205070705,"dev-research":0.5061438925,"prompt-eng":0.3953558963,"data-quality":0.0716085889,"ml-security":0.0743873944}}
{"text":"We present a new helper in CoDiPack that allows Enzyme-generated derivative functions to be automatically added during the recording process of CoDiPack.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.1282888139,"dev-research":0.4838068422,"prompt-eng":0.471728218,"data-quality":0.1771463944,"ml-security":0.1322332899}}
{"text":"The validity of the approach is demonstrated on a synthetic benchmark, which shows promising results.","meta":{"url":"http://arxiv.org/abs/2307.06075v1"},"cats":{"new-dataset":0.0849644794,"dev-research":0.3817299337,"prompt-eng":0.3685328909,"data-quality":0.1149130228,"ml-security":0.0982418214}}
{"text":"The classical Binary Symmetric Channel has a fixed transition probability.","meta":{"url":"http://arxiv.org/abs/2307.06073v1"},"cats":{"new-dataset":0.0498943565,"dev-research":0.3767409548,"prompt-eng":0.4206098839,"data-quality":0.0869490969,"ml-security":0.1100036298}}
{"text":"We discuss the Binary Symmetric Channel with a variable transition probability that depends on a Poisson distribution.","meta":{"url":"http://arxiv.org/abs/2307.06073v1"},"cats":{"new-dataset":0.0898023197,"dev-research":0.3775186719,"prompt-eng":0.457487032,"data-quality":0.1271316615,"ml-security":0.1413751382}}
{"text":"The error rate for this channel is determined and we also give bounds for the channel capacity.","meta":{"url":"http://arxiv.org/abs/2307.06073v1"},"cats":{"new-dataset":0.1356619098,"dev-research":0.3898696168,"prompt-eng":0.4087451527,"data-quality":0.203830946,"ml-security":0.1020407861}}
{"text":"We give a motivation for the model based on the Class-A impulse noise model, as given by Middleton.","meta":{"url":"http://arxiv.org/abs/2307.06073v1"},"cats":{"new-dataset":0.085146948,"dev-research":0.367103096,"prompt-eng":0.4446939322,"data-quality":0.1873300311,"ml-security":0.21635509}}
{"text":"The channel model can be extended to the Additive White Gaussian Channel model, where the noise variance also depends on a Poisson distribution.","meta":{"url":"http://arxiv.org/abs/2307.06073v1"},"cats":{"new-dataset":0.0678901164,"dev-research":0.3466476452,"prompt-eng":0.4468520347,"data-quality":0.1495263358,"ml-security":0.1284270037}}
{"text":"Secure software is a cornerstone to safe and resilient digital ecosystems.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1474258922,"dev-research":0.5120127716,"prompt-eng":0.4137678305,"data-quality":0.1317207934,"ml-security":0.5431113251}}
{"text":"It offers strong foundation to protect users' sensitive data and guard against cyber-threats.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.2373026378,"dev-research":0.4570668523,"prompt-eng":0.4171991737,"data-quality":0.0700816753,"ml-security":0.5995685274}}
{"text":"The rapidly increasing landscape of digital economy has encouraged developers from different socio-technical and socio-economic backgrounds to join online freelance marketplaces.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1720617741,"dev-research":0.5321085462,"prompt-eng":0.4034432903,"data-quality":0.0624926348,"ml-security":0.164436166}}
{"text":"While, secure software practices facilitate software developers in developing secure software, there is paucity of research on how freelance developers adhere to security practices and how they can be facilitated to improve their security behavior in under-resourced environments.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1645695375,"dev-research":0.5741092524,"prompt-eng":0.4408643693,"data-quality":0.1234523035,"ml-security":0.4769373594}}
{"text":"Moreover, freelance developers are often held responsible for producing insecure code.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1682253373,"dev-research":0.5663981365,"prompt-eng":0.4071277695,"data-quality":0.2060593825,"ml-security":0.4829104537}}
{"text":"In this position paper, we review existing literature and argue for the case of distributed security responsibilities in online freelance environment.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.162728725,"dev-research":0.4667172243,"prompt-eng":0.3959315948,"data-quality":0.0845887692,"ml-security":0.398059847}}
{"text":"We propose a research agenda aimed at offering an organized and systematic effort by researchers to address security needs and challenges of online freelance marketplaces.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1929673317,"dev-research":0.4802740624,"prompt-eng":0.4180887458,"data-quality":0.0787457575,"ml-security":0.3092964381}}
{"text":"These include: characterising software security and defining separation of responsibilities, building trust in online freelance development communities, leveraging the potential of online freelancing platforms in the promotion of secure software development and building adaptive security interventions for online freelance software development.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1379001601,"dev-research":0.5338744663,"prompt-eng":0.4010487967,"data-quality":0.0916297131,"ml-security":0.3689229666}}
{"text":"The research has the potential to bring forth existing security solutions to wider developer community and deliver substantial benefits to the broader security ecosystem.","meta":{"url":"http://arxiv.org/abs/2307.06066v1"},"cats":{"new-dataset":0.1824898539,"dev-research":0.5488964716,"prompt-eng":0.4377333979,"data-quality":0.058270513,"ml-security":0.3999363751}}
{"text":"In this work, we propose a novel approach called Operational Support Estimator Networks (OSENs) for the support estimation task.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.2112351128,"dev-research":0.4002505109,"prompt-eng":0.4570245815,"data-quality":0.1786561438,"ml-security":0.1687866562}}
{"text":"Support Estimation (SE) is defined as finding the locations of non-zero elements in a sparse signal.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1174840074,"dev-research":0.3881912179,"prompt-eng":0.3910788826,"data-quality":0.2144672114,"ml-security":0.1325465874}}
{"text":"By its very nature, the mapping between the measurement and sparse signal is a non-linear operation.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.0595667578,"dev-research":0.3774326766,"prompt-eng":0.3621285014,"data-quality":0.1718022171,"ml-security":0.124698905}}
{"text":"Traditional support estimators rely on computationally expensive iterative signal recovery techniques to achieve such non-linearity.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1130503318,"dev-research":0.3477537184,"prompt-eng":0.4073877388,"data-quality":0.2184273209,"ml-security":0.1544311969}}
{"text":"Contrary to the convolution layers, the proposed OSEN approach consists of operational layers that can learn such complex non-linearities without the need for deep networks.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1111596138,"dev-research":0.3728121243,"prompt-eng":0.4177463793,"data-quality":0.0957527508,"ml-security":0.2432581242}}
{"text":"In this way, the performance of the non-iterative support estimation is greatly improved.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1542787262,"dev-research":0.3720842904,"prompt-eng":0.4251306375,"data-quality":0.1651720539,"ml-security":0.0815767256}}
{"text":"Moreover, the operational layers comprise so-called generative \\textit{super neurons} with non-local kernels.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1154196639,"dev-research":0.4281650502,"prompt-eng":0.458910041,"data-quality":0.1001705306,"ml-security":0.1365288758}}
{"text":"The kernel location for each neuron/feature map is optimized jointly for the SE task during the training.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1077520394,"dev-research":0.4168913038,"prompt-eng":0.4358065319,"data-quality":0.1261191738,"ml-security":0.1075729339}}
{"text":"We evaluate the OSENs in three different applications: i. support estimation from Compressive Sensing (CS) measurements, ii. representation-based classification, and iii.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1687159649,"dev-research":0.3714493394,"prompt-eng":0.4410511611,"data-quality":0.2228504396,"ml-security":0.2449461191}}
{"text":"learning-aided CS reconstruction where the output of OSENs is used as prior knowledge to the CS algorithm for an enhanced reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.1881708308,"dev-research":0.3729614659,"prompt-eng":0.4248095244,"data-quality":0.1040057843,"ml-security":0.138619097}}
{"text":"Experimental results show that the proposed approach achieves computational efficiency and outperforms competing methods, especially at low measurement rates by a significant margin.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.0495197963,"dev-research":0.3433161009,"prompt-eng":0.3442393951,"data-quality":0.1050706762,"ml-security":0.0800822243}}
{"text":"The software implementation is publicly shared at https://github.com/meteahishali/OSEN.","meta":{"url":"http://arxiv.org/abs/2307.06065v1"},"cats":{"new-dataset":0.3185149004,"dev-research":0.4820549984,"prompt-eng":0.4555453453,"data-quality":0.0778318057,"ml-security":0.1445220794}}
{"text":"[Context] Systematic Literature Review (SLR) has been a major type of study published in Software Engineering (SE) venues for about two decades.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.1132614769,"dev-research":0.5190847113,"prompt-eng":0.4446655433,"data-quality":0.1361371678,"ml-security":0.0672856005}}
{"text":"However, there is a lack of understanding of whether an SLR is really needed in comparison to a more conventional literature review.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.025163721,"dev-research":0.3969146488,"prompt-eng":0.3657852189,"data-quality":0.1705303131,"ml-security":0.0777989377}}
{"text":"Very often, SE researchers embark on an SLR with such doubts.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.0584043433,"dev-research":0.4115342828,"prompt-eng":0.4222629336,"data-quality":0.1047464881,"ml-security":0.1249004941}}
{"text":"We aspire to provide more understanding of when an SLR in SE should be conducted.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.0737469155,"dev-research":0.4370433177,"prompt-eng":0.4739022913,"data-quality":0.1128470157,"ml-security":0.0899381096}}
{"text":"[Objective] The first step of our investigation was focused on the dataset, i.e., the reviewed papers, in an SLR, which indicates the development of a research topic or area.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.2394232647,"dev-research":0.4249897161,"prompt-eng":0.4200508659,"data-quality":0.1125137728,"ml-security":0.086751409}}
{"text":"The objective of this step is to provide a better understanding of the characteristics of the datasets of SLRs in SE.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.2278321113,"dev-research":0.4086689256,"prompt-eng":0.4569725524,"data-quality":0.1154575798,"ml-security":0.1016908292}}
{"text":"[Method] A research synthesis was conducted on a sample of 170 SLRs published in top-tier SE journals.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.0841500002,"dev-research":0.3924607781,"prompt-eng":0.4375603965,"data-quality":0.0897179269,"ml-security":0.0614965564}}
{"text":"We extracted and analysed the quantitative attributes of the datasets of these SLRs.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.2176127986,"dev-research":0.3489540196,"prompt-eng":0.4525069703,"data-quality":0.1216887525,"ml-security":0.0817020204}}
{"text":"[Results]","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.2260148999,"dev-research":0.4503361232,"prompt-eng":0.4639127397,"data-quality":0.2301331881,"ml-security":0.1091957467}}
{"text":"The findings show that the median size of the datasets in our sample is 57 reviewed papers, and the median review period covered is 14 years.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.5176916281,"dev-research":0.385292395,"prompt-eng":0.4210175741,"data-quality":0.1425374506,"ml-security":0.084855178}}
{"text":"The number of reviewed papers and review period have a very weak and non-significant positive correlation.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.0972357689,"dev-research":0.3688905677,"prompt-eng":0.3852879313,"data-quality":0.1777540081,"ml-security":0.0519414683}}
{"text":"[Conclusions] The results of our study can be used by SE researchers as an indicator or benchmark to understand whether an SLR is conducted at a good time.","meta":{"url":"http://arxiv.org/abs/2307.06056v1"},"cats":{"new-dataset":0.0785670599,"dev-research":0.4000590246,"prompt-eng":0.4348887031,"data-quality":0.1078072071,"ml-security":0.0751841242}}
{"text":"Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.1115051999,"dev-research":0.3727096177,"prompt-eng":0.5225975794,"data-quality":0.2260703206,"ml-security":0.4278545281}}
{"text":"However, weight-space priors are model-specific, can be difficult to interpret and are hard to specify.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.0461955589,"dev-research":0.3893086087,"prompt-eng":0.4717427193,"data-quality":0.1147564579,"ml-security":0.1254478404}}
{"text":"Instead, we apply a Dirichlet prior in predictive space and perform approximate function-space variational inference.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.0975172033,"dev-research":0.3813006715,"prompt-eng":0.4935811801,"data-quality":0.1249112586,"ml-security":0.1226029497}}
{"text":"To this end, we interpret conventional categorical predictions from stochastic neural network classifiers as samples from an implicit Dirichlet distribution.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.1346534791,"dev-research":0.4112179922,"prompt-eng":0.5030642877,"data-quality":0.295106463,"ml-security":0.3009993906}}
{"text":"By adapting the inference, the same function-space prior can be combined with different models without affecting model architecture or size.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.0367133572,"dev-research":0.3837219077,"prompt-eng":0.4326536668,"data-quality":0.0848743066,"ml-security":0.1287233985}}
{"text":"We illustrate the flexibility and efficacy of such a prior with toy experiments and demonstrate scalability, improved uncertainty quantification and adversarial robustness with large-scale image classification experiments.","meta":{"url":"http://arxiv.org/abs/2307.06055v1"},"cats":{"new-dataset":0.1507181352,"dev-research":0.3505076083,"prompt-eng":0.4755102981,"data-quality":0.2569776402,"ml-security":0.3916402094}}
{"text":"This paper introduces a simplified variation of the PaDiM (Pixel-Wise Anomaly Detection through Instance Modeling) method for anomaly detection in images, fitting a single multivariate Gaussian (MVG) distribution to the feature vectors extracted from a backbone convolutional neural network (CNN) and using their Mahalanobis distance as the anomaly score.","meta":{"url":"http://arxiv.org/abs/2307.06052v1"},"cats":{"new-dataset":0.1600851786,"dev-research":0.3756482872,"prompt-eng":0.4335297916,"data-quality":0.2631126614,"ml-security":0.2800851825}}
{"text":"We introduce an intermediate step in this framework by applying a whitening transformation to the feature vectors, which enables the generation of heatmaps capable of visually explaining the features learned by the MVG.","meta":{"url":"http://arxiv.org/abs/2307.06052v1"},"cats":{"new-dataset":0.1696760437,"dev-research":0.4222679064,"prompt-eng":0.4488743945,"data-quality":0.1242751634,"ml-security":0.1156042649}}
{"text":"The proposed technique is evaluated on the MVTec-AD dataset, and the results show the importance of visual model validation, providing insights into issues in this framework that were otherwise invisible.","meta":{"url":"http://arxiv.org/abs/2307.06052v1"},"cats":{"new-dataset":0.2415470321,"dev-research":0.4279743172,"prompt-eng":0.4472927881,"data-quality":0.309357662,"ml-security":0.211590059}}
{"text":"The visualizations generated for this paper are publicly available at https://doi.org/10.5281/zenodo.7937978.","meta":{"url":"http://arxiv.org/abs/2307.06052v1"},"cats":{"new-dataset":0.2717064925,"dev-research":0.4195808262,"prompt-eng":0.4306525002,"data-quality":0.0590101044,"ml-security":0.0609975445}}
{"text":"This study aims to determine the appropriate size of the Mongolian general corpus.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.1860442059,"dev-research":0.3861258802,"prompt-eng":0.467899805,"data-quality":0.2196249981,"ml-security":0.0677653216}}
{"text":"This study used the Heaps function and Type Token Ratio to determine the appropriate size of the Mongolian general corpus.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.1763962735,"dev-research":0.4109713075,"prompt-eng":0.4439753629,"data-quality":0.2073163757,"ml-security":0.0801742245}}
{"text":"The sample corpus of 906,064 tokens comprised texts from 10 domains of newspaper politics, economy, society, culture, sports, world articles and laws, middle and high school literature textbooks, interview articles, and podcast transcripts.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.473882458,"dev-research":0.3925200549,"prompt-eng":0.5020572554,"data-quality":0.2222278815,"ml-security":0.1204947497}}
{"text":"First, we estimated the Heaps function with this sample corpus.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.4087538469,"dev-research":0.4149433264,"prompt-eng":0.4520866455,"data-quality":0.1873604148,"ml-security":0.0894980708}}
{"text":"Next, we observed changes in the number of types and TTR values while increasing the number of tokens by one million using the estimated Heaps function.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.1632867385,"dev-research":0.4521310247,"prompt-eng":0.4738962965,"data-quality":0.1233978133,"ml-security":0.1531505537}}
{"text":"As a result of observation, we found that the TTR value hardly changed when the number of tokens exceeded from 39 to 42 million.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.1402583376,"dev-research":0.4367794924,"prompt-eng":0.4680002297,"data-quality":0.1352675945,"ml-security":0.157915498}}
{"text":"Thus, we conclude that an appropriate size for a Mongolian general corpus is from 39 to 42 million tokens.","meta":{"url":"http://arxiv.org/abs/2307.06050v1"},"cats":{"new-dataset":0.2302723258,"dev-research":0.3869181982,"prompt-eng":0.4640555108,"data-quality":0.1822492636,"ml-security":0.1080014814}}
{"text":"The task of inductive link prediction in (discrete) attributed multigraphs infers missing attributed links (relations) between nodes in new test multigraphs.","meta":{"url":"http://arxiv.org/abs/2307.06046v1"},"cats":{"new-dataset":0.121151145,"dev-research":0.4226143878,"prompt-eng":0.4377267875,"data-quality":0.2838323514,"ml-security":0.1122754326}}
{"text":"Traditional relational learning methods face the challenge of limited generalization to OOD test multigraphs containing both novel nodes and novel relation types not seen in training.","meta":{"url":"http://arxiv.org/abs/2307.06046v1"},"cats":{"new-dataset":0.1565061947,"dev-research":0.3892270197,"prompt-eng":0.4201136303,"data-quality":0.1475793409,"ml-security":0.1370755196}}
{"text":"Recently, under the only assumption that all relation types share the same structural predictive patterns (single task), Gao et al. (2023) proposed an OOD link prediction method using the theoretical concept of double exchangeability (for nodes & relation types), in contrast to the (single) exchangeability (only for nodes) used to design Graph Neural Networks (GNNs).","meta":{"url":"http://arxiv.org/abs/2307.06046v1"},"cats":{"new-dataset":0.1176258018,"dev-research":0.3689997126,"prompt-eng":0.4004741975,"data-quality":0.1039901444,"ml-security":0.151537585}}
{"text":"In this work we further extend the double exchangeability concept to multi-task double exchangeability, where we define link prediction in attributed multigraphs that can have distinct and potentially conflicting predictive patterns for different sets of relation types (multiple tasks).","meta":{"url":"http://arxiv.org/abs/2307.06046v1"},"cats":{"new-dataset":0.1495475683,"dev-research":0.4265165838,"prompt-eng":0.461041415,"data-quality":0.1352756379,"ml-security":0.1127903916}}
{"text":"Our empirical results on real-world datasets demonstrate that our approach can effectively generalize to entirely new relation types in test, without access to additional information, yielding significant performance improvements over existing methods.","meta":{"url":"http://arxiv.org/abs/2307.06046v1"},"cats":{"new-dataset":0.409784925,"dev-research":0.430049321,"prompt-eng":0.4832258714,"data-quality":0.1803168713,"ml-security":0.173598298}}
{"text":"Accurately recovering the dense 3D mesh of both hands from monocular images poses considerable challenges due to occlusions and projection ambiguity.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1210196721,"dev-research":0.3440164253,"prompt-eng":0.3503312816,"data-quality":0.0850535996,"ml-security":0.0787675184}}
{"text":"Most of the existing methods extract features from color images to estimate the root-aligned hand meshes, which neglect the crucial depth and scale information in the real world.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1826086253,"dev-research":0.3858449647,"prompt-eng":0.379514257,"data-quality":0.0723119417,"ml-security":0.0897789697}}
{"text":"Given the noisy sensor measurements with limited resolution, depth-based methods predict 3D keypoints rather than a dense mesh.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1008859466,"dev-research":0.3727040447,"prompt-eng":0.3835072182,"data-quality":0.1593203715,"ml-security":0.1348972884}}
{"text":"These limitations motivate us to take advantage of these two complementary inputs to acquire dense hand meshes on a real-world scale.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.0241468999,"dev-research":0.4200938114,"prompt-eng":0.3429256768,"data-quality":0.0295976569,"ml-security":0.1338587101}}
{"text":"In this work, we propose an end-to-end framework for recovering dense meshes for both hands, which employ single-view RGB-D image pairs as input.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1748306278,"dev-research":0.3585181293,"prompt-eng":0.3859226336,"data-quality":0.0695756413,"ml-security":0.1010273611}}
{"text":"The primary challenge lies in effectively utilizing two different input modalities to mitigate the blurring effects in RGB images and noises in depth images.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.0811352247,"dev-research":0.3494121437,"prompt-eng":0.4189865745,"data-quality":0.2176802817,"ml-security":0.0915716459}}
{"text":"Instead of directly treating depth maps as additional channels for RGB images, we encode the depth information into the unordered point cloud to preserve more geometric details.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1208355032,"dev-research":0.4009059035,"prompt-eng":0.3712802832,"data-quality":0.0852380787,"ml-security":0.0870923449}}
{"text":"Specifically, our framework employs ResNet50 and PointNet++ to derive features from RGB and point cloud, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.2432054596,"dev-research":0.4252959914,"prompt-eng":0.423045889,"data-quality":0.1044973164,"ml-security":0.1035426195}}
{"text":"Additionally, we introduce a novel pyramid deep fusion network (PDFNet) to aggregate features at different scales, which demonstrates superior efficacy compared to previous fusion strategies.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1430834615,"dev-research":0.3672058215,"prompt-eng":0.4330033474,"data-quality":0.1405958249,"ml-security":0.1732446314}}
{"text":"Furthermore, we employ a GCN-based decoder to process the fused features and recover the corresponding 3D pose and dense mesh.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.1548812119,"dev-research":0.376402957,"prompt-eng":0.3980847165,"data-quality":0.0845861233,"ml-security":0.100325316}}
{"text":"Through comprehensive ablation experiments, we have not only demonstrated the effectiveness of our proposed fusion algorithm but also outperformed the state-of-the-art approaches on publicly available datasets.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.19803157,"dev-research":0.3444503955,"prompt-eng":0.4001813017,"data-quality":0.1398855992,"ml-security":0.0631553819}}
{"text":"To reproduce the results, we will make our source code and models publicly available at {\\url{https://github.com/zijinxuxu/PDFNet}}.","meta":{"url":"http://arxiv.org/abs/2307.06038v1"},"cats":{"new-dataset":0.2646013651,"dev-research":0.4223492658,"prompt-eng":0.4953188781,"data-quality":0.2201578373,"ml-security":0.158197181}}
{"text":"In this paper, we study THz simultaneous wireless information and power transfer (SWIPT) systems.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0850466256,"dev-research":0.4104545099,"prompt-eng":0.4162453498,"data-quality":0.0611704938,"ml-security":0.1680082923}}
{"text":"Since coherent information detection is challenging at THz frequencies and Schottky diodes may not be efficient for THz energy harvesting (EH) and information detection, we employ unipolar amplitude shift keying (ASK) modulation at the transmitter (TX) and a resonant tunnelling diode (RTD)-based EH circuit at the receiver (RX) to extract both information and power from the RX signal.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0760680837,"dev-research":0.3916825192,"prompt-eng":0.450555401,"data-quality":0.1068948288,"ml-security":0.1888378544}}
{"text":"We model the dependence of the instantaneous output power at the RX on the instantaneous received power by a non-linear piecewise function, whose parameters are adjusted to fit circuit simulation results.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0554924196,"dev-research":0.4008695743,"prompt-eng":0.3655634364,"data-quality":0.1210272452,"ml-security":0.1091397919}}
{"text":"To determine the rate-power tradeoff in THz SWIPT systems, we derive the distribution of the TX signal that maximizes the mutual information between the TX and RX signals subject to constraints on the required average harvested power at the RX and the peak signal amplitude at the TX.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0728471206,"dev-research":0.4056360325,"prompt-eng":0.4176110031,"data-quality":0.07835154,"ml-security":0.1908260163}}
{"text":"Since the computational complexity of maximizing the mutual information may be too high for real-time THz SWIPT systems, for high and low required average harvested powers, we also obtain the suboptimal input signal distribution that maximizes the achievable information rate numerically and in closed form, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0840691116,"dev-research":0.3801385301,"prompt-eng":0.4012868806,"data-quality":0.0646052596,"ml-security":0.2294406225}}
{"text":"Furthermore, based on the obtained results, we propose a suboptimal closed-form TX distribution which also achieves a desired harvested power at the RX.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.078191555,"dev-research":0.3632122977,"prompt-eng":0.4142550102,"data-quality":0.0911751371,"ml-security":0.1044451573}}
{"text":"Our simulation results show that a lower reverse current flow and a higher breakdown voltage of the employed RTD are preferable when the input signal power at the RX is low and high, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0712634965,"dev-research":0.4018960123,"prompt-eng":0.4236725703,"data-quality":0.1119307533,"ml-security":0.161745215}}
{"text":"Finally, we demonstrate that for low and high received signal powers, the rate-power tradeoff of THz SWIPT systems is determined by the peak amplitude of the TX signal and the maximum instantaneous harvested power, respectively.","meta":{"url":"http://arxiv.org/abs/2307.06036v1"},"cats":{"new-dataset":0.0753081924,"dev-research":0.400380512,"prompt-eng":0.4216053262,"data-quality":0.0692253435,"ml-security":0.1514328314}}
{"text":"While the term `art' defies any concrete definition, this paper aims to examine how digital images produced by generative AI systems, such as Midjourney, have come to be so regularly referred to as such.","meta":{"url":"http://arxiv.org/abs/2307.06033v1"},"cats":{"new-dataset":0.1905314154,"dev-research":0.4559659019,"prompt-eng":0.4710027239,"data-quality":0.1355479026,"ml-security":0.0642535537}}
{"text":"The discourse around the classification of AI-generated imagery as art is currently somewhat homogeneous, lacking the more nuanced aspects that would apply to more traditional modes of artistic media production.","meta":{"url":"http://arxiv.org/abs/2307.06033v1"},"cats":{"new-dataset":0.088510628,"dev-research":0.4490826439,"prompt-eng":0.3954490554,"data-quality":0.1812841995,"ml-security":0.0594909924}}
{"text":"This paper aims to bring important philosophical considerations to the surface of the discussion around AI-generated imagery in the context of art.","meta":{"url":"http://arxiv.org/abs/2307.06033v1"},"cats":{"new-dataset":0.1087243719,"dev-research":0.4602479002,"prompt-eng":0.3928581616,"data-quality":0.1338248969,"ml-security":0.0759024493}}
{"text":"We employ existing philosophical frameworks and theories of language to suggest that some AI-generated imagery, by virtue of its visual properties within these frameworks, can be presented as `readymades' for consideration as art.","meta":{"url":"http://arxiv.org/abs/2307.06033v1"},"cats":{"new-dataset":0.1734945049,"dev-research":0.4894413436,"prompt-eng":0.4594382453,"data-quality":0.1460335811,"ml-security":0.085588363}}
{"text":"Although neural machine translation (NMT) models perform well in the general domain, it remains rather challenging to control their generation behavior to satisfy the requirement of different users.","meta":{"url":"http://arxiv.org/abs/2307.06029v1"},"cats":{"new-dataset":0.1318161062,"dev-research":0.4207399047,"prompt-eng":0.5629164717,"data-quality":0.1769807887,"ml-security":0.0975180428}}
{"text":"Given the expensive training cost and the data scarcity challenge of learning a new model from scratch for each user requirement, we propose a memory-augmented adapter to steer pretrained NMT models in a pluggable manner.","meta":{"url":"http://arxiv.org/abs/2307.06029v1"},"cats":{"new-dataset":0.1445064804,"dev-research":0.3798582388,"prompt-eng":0.5144886227,"data-quality":0.0865289022,"ml-security":0.1779953634}}
{"text":"Specifically, we construct a multi-granular memory based on the user-provided text samples and propose a new adapter architecture to combine the model representations and the retrieved results.","meta":{"url":"http://arxiv.org/abs/2307.06029v1"},"cats":{"new-dataset":0.2825575637,"dev-research":0.4347896888,"prompt-eng":0.5466790978,"data-quality":0.1649713115,"ml-security":0.0919594141}}
{"text":"We also propose a training strategy using memory dropout to reduce spurious dependencies between the NMT model and the memory.","meta":{"url":"http://arxiv.org/abs/2307.06029v1"},"cats":{"new-dataset":0.0764206201,"dev-research":0.3769394857,"prompt-eng":0.494744537,"data-quality":0.1915953682,"ml-security":0.1807803311}}
{"text":"We validate our approach on both style- and domain-specific experiments and the results indicate that our method can outperform several representative pluggable baselines.","meta":{"url":"http://arxiv.org/abs/2307.06029v1"},"cats":{"new-dataset":0.0679987178,"dev-research":0.4464734584,"prompt-eng":0.5010822997,"data-quality":0.2549666603,"ml-security":0.0651121784}}
{"text":"Point cloud, as a 3D representation, is widely used in autonomous driving, virtual reality (VR), and augmented reality (AR).","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.1313312427,"dev-research":0.376957546,"prompt-eng":0.3579471973,"data-quality":0.065207996,"ml-security":0.1018779664}}
{"text":"However, traditional communication systems think that the point cloud's semantic information is irrelevant to communication, which hinders the efficient transmission of point clouds in the era of artificial intelligence (AI).","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.0662092703,"dev-research":0.4215187575,"prompt-eng":0.3863837176,"data-quality":0.1497280834,"ml-security":0.2159677496}}
{"text":"This paper proposes a point cloud based semantic communication system (PCSC), which uses AI-based encoding techniques to extract the semantic information of the point cloud and joint source-channel coding (JSCC) technology to overcome the distortion caused by noise channels and solve the \"cliff effect\" in traditional communication.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.1871959106,"dev-research":0.4415884832,"prompt-eng":0.4452129632,"data-quality":0.2648171615,"ml-security":0.1516803946}}
{"text":"In addition, the system realizes the controllable coding rate without fine-tuning the network.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.053147002,"dev-research":0.4789681981,"prompt-eng":0.4220039754,"data-quality":0.169382449,"ml-security":0.1705067642}}
{"text":"The method analyzes the coded semantic vector's importance and discards semantically-unimportant information, thereby improving the transmission efficiency.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.069581216,"dev-research":0.5051582255,"prompt-eng":0.455743487,"data-quality":0.2752359624,"ml-security":0.1538600627}}
{"text":"Besides, PCSC and the recently proposed non-orthogonal model division multiple access (MDMA) technology are combined to design a point cloud MDMA transmission system (M-PCSC) for multi-user transmission.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.0452650355,"dev-research":0.3604164756,"prompt-eng":0.37109496,"data-quality":0.0698924512,"ml-security":0.167679391}}
{"text":"Relevant experimental results show that the proposed method outperforms the traditional method 10dB in the same channel bandwidth ratio under the PSNR D1 and PSNR D2 metrics.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.0644900671,"dev-research":0.3848114413,"prompt-eng":0.4279943883,"data-quality":0.1974200615,"ml-security":0.083158687}}
{"text":"In terms of transmission, the proposed method can effectively solve the \"cliff effect\" in the traditional methods.","meta":{"url":"http://arxiv.org/abs/2307.06027v1"},"cats":{"new-dataset":0.0613378422,"dev-research":0.4249419291,"prompt-eng":0.3675309279,"data-quality":0.087777132,"ml-security":0.1254779997}}
{"text":"eXplanation Based Learning (XBL) is a form of Interactive Machine Learning (IML) that provides a model refining approach via user feedback collected on model explanations.","meta":{"url":"http://arxiv.org/abs/2307.06026v1"},"cats":{"new-dataset":0.1143330102,"dev-research":0.5124329844,"prompt-eng":0.5222826333,"data-quality":0.1782164785,"ml-security":0.1884461972}}
{"text":"Although the interactivity of XBL promotes model transparency, XBL requires a huge amount of user interaction and can become expensive as feedback is in the form of detailed annotation rather than simple category labelling which is more common in IML.","meta":{"url":"http://arxiv.org/abs/2307.06026v1"},"cats":{"new-dataset":0.0707789868,"dev-research":0.4636776196,"prompt-eng":0.5098047103,"data-quality":0.2131060793,"ml-security":0.1324539725}}
{"text":"This expense is exacerbated in high stakes domains such as medical image classification.","meta":{"url":"http://arxiv.org/abs/2307.06026v1"},"cats":{"new-dataset":0.1071179151,"dev-research":0.4051969458,"prompt-eng":0.4188088302,"data-quality":0.2400585551,"ml-security":0.3310126486}}
{"text":"To reduce the effort and expense of XBL we introduce a new approach that uses two input instances and their corresponding Gradient Weighted Class Activation Mapping (GradCAM) model explanations as exemplary explanations to implement XBL.","meta":{"url":"http://arxiv.org/abs/2307.06026v1"},"cats":{"new-dataset":0.0807616878,"dev-research":0.4778630317,"prompt-eng":0.5296417899,"data-quality":0.1735521076,"ml-security":0.2220400931}}
{"text":"Using a medical image classification task, we demonstrate that, using minimal human input, our approach produces improved explanations (+0.02, +3%) and achieves reduced classification performance (-0.04, -4%) when compared against a model trained without interactions.","meta":{"url":"http://arxiv.org/abs/2307.06026v1"},"cats":{"new-dataset":0.0946574222,"dev-research":0.4200704474,"prompt-eng":0.4720054994,"data-quality":0.2821412772,"ml-security":0.1921313291}}
{"text":"In this paper, we investigate the uplink signal detection approaches in the cell-free massive MIMO systems with unmanned aerial vehicles (UAVs) serving as aerial access points (APs).","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0582558434,"dev-research":0.3944949915,"prompt-eng":0.3691290015,"data-quality":0.0971471135,"ml-security":0.1462890455}}
{"text":"The ground users are equipped with multiple antennas and the ground-to-air propagation channels are subject to correlated Rician fading.","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.1167699361,"dev-research":0.3764037221,"prompt-eng":0.4476310338,"data-quality":0.0908174841,"ml-security":0.1177725025}}
{"text":"To overcome huge signaling overhead in the fully-centralized detection, we propose a two-layer distributed uplink detection scheme, where the uplink signals are first detected in the AP-UAVs by using the minimum mean-squared error (MMSE) detector depending on local channel state information (CSI), and then collected and weighted combined at the CPU-UAV to obtain the refined detection.","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0552862637,"dev-research":0.3950309349,"prompt-eng":0.4235080355,"data-quality":0.1461090006,"ml-security":0.2106600988}}
{"text":"By using the operator-valued free probability theory, the asymptotic expressions of the combining weights are obtained, which only depend on the statistical CSI and show excellent accuracy.","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0478065964,"dev-research":0.3532931367,"prompt-eng":0.4025722151,"data-quality":0.1437576996,"ml-security":0.1999533291}}
{"text":"Based on the proposed distributed scheme, we further investigate the impacts of different distributed deployments on the achieved spectral efficiency (SE).","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0631860849,"dev-research":0.3791985555,"prompt-eng":0.3966801946,"data-quality":0.0979593347,"ml-security":0.1151389648}}
{"text":"Numerical results show that in urban and dense urban environments, it is more beneficial to deploy more AP-UAVs to achieve higher SE.","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0675198267,"dev-research":0.4042351145,"prompt-eng":0.3897438983,"data-quality":0.0439578103,"ml-security":0.1329315182}}
{"text":"On the other hand, in suburban environment, an optimal ratio between the number of deployed UAVs and the number of antennas per UAV exists to maximize the SE.","meta":{"url":"http://arxiv.org/abs/2307.06023v1"},"cats":{"new-dataset":0.0546991981,"dev-research":0.4171963854,"prompt-eng":0.3637191806,"data-quality":0.0519832239,"ml-security":0.1284548174}}
{"text":"Large language models (LLMs) demonstrate remarkable ability to comprehend, reason, and generate following nature language instructions.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.1707943522,"dev-research":0.4860810711,"prompt-eng":0.6086415932,"data-quality":0.1362778858,"ml-security":0.0996600464}}
{"text":"However, the development of LLMs has been primarily focused on high-resource languages, such as English, thereby limiting their applicability and research in other languages.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.091407485,"dev-research":0.4730706427,"prompt-eng":0.5171975959,"data-quality":0.1051748464,"ml-security":0.149870124}}
{"text":"Consequently, we present PolyLM, a multilingual LLM trained on 640 billion (B) tokens, avaliable in two model sizes: 1.7B and 13B. To enhance its multilingual capabilities, we 1) integrate bilingual data into training data; and 2) adopt a curriculum learning strategy that increases the proportion of non-English data from 30% in the first stage to 60% in the final stage during pre-training.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.360453771,"dev-research":0.3997267355,"prompt-eng":0.5660139651,"data-quality":0.1767470718,"ml-security":0.1643947353}}
{"text":"Further, we propose a multilingual self-instruct method which automatically generates 132.7K diverse multilingual instructions for model fine-tuning.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.2456116979,"dev-research":0.4923644127,"prompt-eng":0.5867596689,"data-quality":0.2872044919,"ml-security":0.0944080247}}
{"text":"To assess the model's performance, we collect several existing multilingual tasks, including multilingual understanding, question answering, generation, and translation.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.2331494031,"dev-research":0.4487297927,"prompt-eng":0.5730248341,"data-quality":0.1554781831,"ml-security":0.0394939391}}
{"text":"Extensive experiments show that PolyLM surpasses other open-source models such as LLaMA and BLOOM on multilingual tasks while maintaining comparable performance in English.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.1732090563,"dev-research":0.44523992,"prompt-eng":0.520368661,"data-quality":0.1499256327,"ml-security":0.0892870667}}
{"text":"Our models, alone with the instruction data and multilingual benchmark, are available at: \\url{https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation}.","meta":{"url":"http://arxiv.org/abs/2307.06018v1"},"cats":{"new-dataset":0.3639516553,"dev-research":0.4219325765,"prompt-eng":0.5493431342,"data-quality":0.1725762352,"ml-security":0.0766111468}}
{"text":"The safety-liveness dichotomy is a fundamental concept in formal languages which plays a key role in verification.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.0902234962,"dev-research":0.4597257125,"prompt-eng":0.4476649638,"data-quality":0.2859940156,"ml-security":0.2513837815}}
{"text":"Recently, this dichotomy has been lifted to quantitative properties, which are arbitrary functions from infinite words to partially-ordered domains.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1099044524,"dev-research":0.3935667302,"prompt-eng":0.3885200313,"data-quality":0.1217186963,"ml-security":0.119552321}}
{"text":"We look into harnessing the dichotomy for the specific classes of quantitative properties expressed by quantitative automata.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1217586024,"dev-research":0.4205853765,"prompt-eng":0.4641862694,"data-quality":0.176490741,"ml-security":0.140394876}}
{"text":"These automata contain finitely many states and rational-valued transition weights, and their common value functions Inf, Sup, LimInf, LimSup, LimInfAvg, LimSupAvg, and DSum map infinite words into the totally-ordered domain of real numbers.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1512414651,"dev-research":0.3785462298,"prompt-eng":0.4373881358,"data-quality":0.1052266523,"ml-security":0.1204359539}}
{"text":"In this automata-theoretic setting, we establish a connection between quantitative safety and topological continuity and provide an alternative characterization of quantitative safety and liveness in terms of their boolean counterparts.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1037492189,"dev-research":0.4317244656,"prompt-eng":0.4028421012,"data-quality":0.1761921915,"ml-security":0.2168504031}}
{"text":"For all common value functions, we show how the safety closure of a quantitative automaton can be constructed in PTime, and we provide PSpace-complete checks of whether a given quantitative automaton is safe or live, with the exception of LimInfAvg and LimSupAvg automata, for which the safety check is in ExpSpace.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1445281219,"dev-research":0.4487988402,"prompt-eng":0.442070365,"data-quality":0.1704833924,"ml-security":0.2746066802}}
{"text":"Moreover, for deterministic Sup, LimInf, and LimSup automata, we give PTime decompositions into safe and live automata.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1194034313,"dev-research":0.4300071166,"prompt-eng":0.4151328941,"data-quality":0.1209286241,"ml-security":0.2860069496}}
{"text":"These decompositions enable the separation of techniques for safety and liveness verification for quantitative specifications.","meta":{"url":"http://arxiv.org/abs/2307.06016v1"},"cats":{"new-dataset":0.1164304457,"dev-research":0.4638461493,"prompt-eng":0.4087313802,"data-quality":0.1795290231,"ml-security":0.220624447}}
{"text":"Entity alignment (EA) aims to find the equivalent entity pairs between different knowledge graphs (KGs), which is crucial to promote knowledge fusion.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.1760293833,"dev-research":0.4423385306,"prompt-eng":0.4769944117,"data-quality":0.2236463808,"ml-security":0.071643127}}
{"text":"With the wide use of temporal knowledge graphs (TKGs), time-aware EA (TEA) methods appear to enhance EA.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.1930025742,"dev-research":0.4916145063,"prompt-eng":0.4785207714,"data-quality":0.0950082126,"ml-security":0.0952071686}}
{"text":"Existing TEA models are based on Graph Neural Networks (GNN) and achieve state-of-the-art (SOTA) performance, but it is difficult to transfer them to large-scale TKGs due to the scalability issue of GNN.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.2616234782,"dev-research":0.3595513422,"prompt-eng":0.4422794191,"data-quality":0.0823375222,"ml-security":0.1572603713}}
{"text":"In this paper, we propose an effective and efficient non-neural EA framework between TKGs, namely LightTEA, which consists of four essential components: (1) Two-aspect Three-view Label Propagation, (2) Sparse Similarity with Temporal Constraints, (3) Sinkhorn Operator, and (4) Temporal Iterative Learning.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.1300020504,"dev-research":0.4003621021,"prompt-eng":0.4349235529,"data-quality":0.2013730593,"ml-security":0.0847204952}}
{"text":"All of these modules work together to improve the performance of EA while reducing the time consumption of the model.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.0531657984,"dev-research":0.453871034,"prompt-eng":0.4185319417,"data-quality":0.0736351738,"ml-security":0.0637962239}}
{"text":"Extensive experiments on public datasets indicate that our proposed model significantly outperforms the SOTA methods for EA between TKGs, and the time consumed by LightTEA is only dozens of seconds at most, no more than 10% of the most efficient TEA method.","meta":{"url":"http://arxiv.org/abs/2307.06013v1"},"cats":{"new-dataset":0.1094967999,"dev-research":0.4110510375,"prompt-eng":0.411192885,"data-quality":0.0776731945,"ml-security":0.1077037834}}
{"text":"Can social power endow social robots with the capacity to persuade?","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.0776284855,"dev-research":0.4155036807,"prompt-eng":0.455570501,"data-quality":0.0714374977,"ml-security":0.2151691004}}
{"text":"This paper represents our recent endeavor to design persuasive social robots.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.1771159332,"dev-research":0.4311105799,"prompt-eng":0.5163397549,"data-quality":0.1055219434,"ml-security":0.1691612517}}
{"text":"We have designed and run three different user studies to investigate the effectiveness of different bases of social power (inspired by French and Raven's theory) on peoples' compliance to the requests of social robots.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.1157013738,"dev-research":0.4230872985,"prompt-eng":0.4691254843,"data-quality":0.0690658455,"ml-security":0.1997199706}}
{"text":"The results show that robotic persuaders that exert social power (specifically from expert, reward, and coercion bases) demonstrate increased ability to influence humans.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.075003015,"dev-research":0.4440828097,"prompt-eng":0.4639671771,"data-quality":0.0641463453,"ml-security":0.2369107569}}
{"text":"The first study provides a positive answer and shows that under the same circumstances, people with different personalities prefer robots using a specific social power base.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.0803645334,"dev-research":0.4429641121,"prompt-eng":0.4267040259,"data-quality":0.0596392081,"ml-security":0.1245500764}}
{"text":"In addition, social rewards can be useful in persuading individuals.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.0793000108,"dev-research":0.4650565043,"prompt-eng":0.4383725015,"data-quality":0.1063997128,"ml-security":0.2020304044}}
{"text":"The second study suggests that by employing social power, social robots are capable of persuading people objectively to select a less desirable choice among others.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.0559986021,"dev-research":0.4344473625,"prompt-eng":0.4556265399,"data-quality":0.0800217239,"ml-security":0.1357793563}}
{"text":"Finally, the third study shows that the effect of power on persuasion does not decay over time and might strengthen under specific circumstances.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.054220135,"dev-research":0.4310813748,"prompt-eng":0.3825488695,"data-quality":0.1066959934,"ml-security":0.1978535408}}
{"text":"Moreover, exerting stronger social power does not necessarily lead to higher persuasion.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.0399066556,"dev-research":0.4263784687,"prompt-eng":0.3709022519,"data-quality":0.0685223504,"ml-security":0.2175170841}}
{"text":"Overall, we argue that the results of these studies are relevant for designing human--robot-interaction scenarios especially the ones aiming at behavioral change.","meta":{"url":"http://arxiv.org/abs/2307.06007v1"},"cats":{"new-dataset":0.1152567427,"dev-research":0.4420170918,"prompt-eng":0.4830598948,"data-quality":0.0753603543,"ml-security":0.1264285553}}
{"text":"The pretrain-finetune paradigm usually improves downstream performance over training a model from scratch on the same task, becoming commonplace across many areas of machine learning.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.0559082317,"dev-research":0.4413739114,"prompt-eng":0.4774084968,"data-quality":0.1305501666,"ml-security":0.1612105821}}
{"text":"While pretraining is empirically observed to be beneficial for a range of tasks, there is not a clear understanding yet of the reasons for this effect.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.0406020637,"dev-research":0.4582820857,"prompt-eng":0.4270988171,"data-quality":0.0832899888,"ml-security":0.1300272097}}
{"text":"In this work, we examine the relationship between pretrained vision transformers and the corresponding finetuned versions on several benchmark datasets and tasks.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.3403288637,"dev-research":0.3847133057,"prompt-eng":0.455539289,"data-quality":0.1184274829,"ml-security":0.0806538927}}
{"text":"We present new metrics that specifically investigate the degree to which invariances learned by a pretrained model are retained or forgotten during finetuning.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.1023310127,"dev-research":0.4190976587,"prompt-eng":0.5106140847,"data-quality":0.2283486811,"ml-security":0.1430684358}}
{"text":"Using these metrics, we present a suite of empirical findings, including that pretraining induces transferable invariances in shallow layers and that invariances from deeper pretrained layers are compressed towards shallower layers during finetuning.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.0706835733,"dev-research":0.3996504689,"prompt-eng":0.4920242366,"data-quality":0.1634932438,"ml-security":0.1613741232}}
{"text":"Together, these findings contribute to understanding some of the reasons for the successes of pretrained models and the changes that a pretrained model undergoes when finetuned on a downstream task.","meta":{"url":"http://arxiv.org/abs/2307.06006v1"},"cats":{"new-dataset":0.0536477746,"dev-research":0.4757751412,"prompt-eng":0.5057283657,"data-quality":0.1177173551,"ml-security":0.134858085}}
{"text":"Neural Architecture Search (NAS) has shown promising capability in learning text representation.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.1575599608,"dev-research":0.3995552498,"prompt-eng":0.4775463868,"data-quality":0.1570048679,"ml-security":0.1336383883}}
{"text":"However, existing text-based NAS neither performs a learnable fusion of neural operations to optimize the architecture, nor encodes the latent hierarchical categorization behind text input.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.1481924437,"dev-research":0.4209415205,"prompt-eng":0.4694914378,"data-quality":0.2183805624,"ml-security":0.1572415135}}
{"text":"This paper presents a novel NAS method, Discretized Differentiable Neural Architecture Search (DDNAS), for text representation learning and classification.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.1410390315,"dev-research":0.3756497431,"prompt-eng":0.4305549419,"data-quality":0.1742512403,"ml-security":0.1595539901}}
{"text":"With the continuous relaxation of architecture representation, DDNAS can use gradient descent to optimize the search.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.0443694902,"dev-research":0.3995546104,"prompt-eng":0.3988041064,"data-quality":0.0834485027,"ml-security":0.1521637316}}
{"text":"We also propose a novel discretization layer via mutual information maximization, which is imposed on every search node to model the latent hierarchical categorization in text representation.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.0955789803,"dev-research":0.4048497679,"prompt-eng":0.4695773133,"data-quality":0.1688777993,"ml-security":0.1451976531}}
{"text":"Extensive experiments conducted on eight diverse real datasets exhibit that DDNAS can consistently outperform the state-of-the-art NAS methods.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.2207843019,"dev-research":0.3782976363,"prompt-eng":0.4108924963,"data-quality":0.1831580894,"ml-security":0.1571235067}}
{"text":"While DDNAS relies on only three basic operations, i.e., convolution, pooling, and none, to be the candidates of NAS building blocks, its promising performance is noticeable and extensible to obtain further improvement by adding more different operations.","meta":{"url":"http://arxiv.org/abs/2307.06005v1"},"cats":{"new-dataset":0.0398004685,"dev-research":0.3980333635,"prompt-eng":0.3638103372,"data-quality":0.0820551517,"ml-security":0.103651697}}
{"text":"Efficiently selecting an appropriate spike stream data length to extract precise information is the key to the spike vision tasks.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.1827940301,"dev-research":0.3803501434,"prompt-eng":0.407848144,"data-quality":0.1783443686,"ml-security":0.1717161634}}
{"text":"To address this issue, we propose a dynamic timing representation for spike streams.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.1503258769,"dev-research":0.3929025401,"prompt-eng":0.4169335183,"data-quality":0.1948412265,"ml-security":0.1864161817}}
{"text":"Based on multi-layers architecture, it applies dilated convolutions on temporal dimension to extract features on multi-temporal scales with few parameters.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.1360189433,"dev-research":0.3501314463,"prompt-eng":0.4068051901,"data-quality":0.0753341471,"ml-security":0.0821444511}}
{"text":"And we design layer attention to dynamically fuse these features.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.0519867078,"dev-research":0.4757499192,"prompt-eng":0.4959651106,"data-quality":0.1650953652,"ml-security":0.2502379862}}
{"text":"Moreover, we propose an unsupervised learning method for optical flow estimation in a spike-based manner to break the dependence on labeled data.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.2201394785,"dev-research":0.3708487477,"prompt-eng":0.4352440218,"data-quality":0.283708162,"ml-security":0.1189343041}}
{"text":"In addition, to verify the robustness, we also build a spike-based synthetic validation dataset for extreme scenarios in autonomous driving, denoted as SSES dataset.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.3837984852,"dev-research":0.3484807836,"prompt-eng":0.4577411501,"data-quality":0.1976020356,"ml-security":0.3638482612}}
{"text":"It consists of various corner cases.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.2096820642,"dev-research":0.4332780203,"prompt-eng":0.3820801441,"data-quality":0.0572097482,"ml-security":0.1266024393}}
{"text":"Experiments show that our method can predict optical flow from spike streams in different high-speed scenes, including real scenes.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.1746678639,"dev-research":0.3740216365,"prompt-eng":0.417040586,"data-quality":0.1611986876,"ml-security":0.114898249}}
{"text":"For instance, our method gets $15\\%$ and $19\\%$ error reduction from the best spike-based work, SCFlow, in $\\Delta t=10$ and $\\Delta t=20$ respectively which are the same settings as the previous works.","meta":{"url":"http://arxiv.org/abs/2307.06003v1"},"cats":{"new-dataset":0.0543227624,"dev-research":0.4171563999,"prompt-eng":0.4068433506,"data-quality":0.2064528996,"ml-security":0.1014257115}}
{"text":"This paper investigates the planning and control problems for multi-robot systems under linear temporal logic (LTL) specifications.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.117304448,"dev-research":0.4199978994,"prompt-eng":0.4108755414,"data-quality":0.0418839906,"ml-security":0.062573372}}
{"text":"In contrast to most of existing literature, which presumes a static and known environment, our study focuses on dynamic environments that can have unknown moving obstacles like humans walking through.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.2664902418,"dev-research":0.4095798393,"prompt-eng":0.395536552,"data-quality":0.0516274697,"ml-security":0.1424745097}}
{"text":"Depending on whether local communication is allowed between robots, we consider two different online re-planning approaches.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.0910415555,"dev-research":0.4180117327,"prompt-eng":0.4121349856,"data-quality":0.0532422519,"ml-security":0.0764157349}}
{"text":"When local communication is allowed, we propose a local trajectory generation algorithm for each robot to resolve conflicts that are detected on-line.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.167806351,"dev-research":0.4269428597,"prompt-eng":0.4631992066,"data-quality":0.0942099913,"ml-security":0.1186875464}}
{"text":"In the other case, i.e., no communication is allowed, we develop a model predictive controller to reactively avoid potential collisions.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.0550959497,"dev-research":0.4156018784,"prompt-eng":0.410445969,"data-quality":0.0606475569,"ml-security":0.4204101865}}
{"text":"In both cases, task satisfaction is guaranteed whenever it is feasible.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.0438599508,"dev-research":0.4563982482,"prompt-eng":0.3616599495,"data-quality":0.0841537404,"ml-security":0.0653516513}}
{"text":"In addition, we consider the human-in-the-loop scenario where humans may additionally take control of one or multiple robots.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.0891802404,"dev-research":0.420890035,"prompt-eng":0.460982587,"data-quality":0.0624542557,"ml-security":0.1167099298}}
{"text":"We design a mixed initiative controller for each robot to prevent unsafe human behaviors while guarantee the LTL satisfaction.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.1072464172,"dev-research":0.4036534509,"prompt-eng":0.4686033661,"data-quality":0.0719184172,"ml-security":0.1735764847}}
{"text":"Using our previous developed ROS software package, several experiments are conducted to demonstrate the effectiveness and the applicability of the proposed strategies.","meta":{"url":"http://arxiv.org/abs/2307.06000v1"},"cats":{"new-dataset":0.0907246577,"dev-research":0.4270223242,"prompt-eng":0.455188406,"data-quality":0.0687157507,"ml-security":0.1011326165}}
{"text":"This paper deploys and explores variants of TinyissimoYOLO, a highly flexible and fully quantized ultra-lightweight object detection network designed for edge systems with a power envelope of a few milliwatts.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.1150350412,"dev-research":0.34130621,"prompt-eng":0.3718224977,"data-quality":0.1149120504,"ml-security":0.2495661443}}
{"text":"With experimental measurements, we present a comprehensive characterization of the network's detection performance, exploring the impact of various parameters, including input resolution, number of object classes, and hidden layer adjustments.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.0707985722,"dev-research":0.3716708157,"prompt-eng":0.420678712,"data-quality":0.2216469915,"ml-security":0.3244955679}}
{"text":"We deploy variants of TinyissimoYOLO on state-of-the-art ultra-low-power extreme edge platforms, presenting an in-depth a comparison on latency, energy efficiency, and their ability to efficiently parallelize the workload.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.131669398,"dev-research":0.3846422411,"prompt-eng":0.3653712695,"data-quality":0.0485388538,"ml-security":0.1200473985}}
{"text":"In particular, the paper presents a comparison between a novel parallel RISC-V processor (GAP9 from Greenwaves) with and without use of its on-chip hardware accelerator, an ARM Cortex-M7 core (STM32H7 from ST Microelectronics), two ARM Cortex-M4 cores (STM32L4 from STM and Apollo4b from Ambiq), and a multi-core platform with a CNN hardware accelerator (Analog Devices MAX78000).","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.1003966838,"dev-research":0.3679842785,"prompt-eng":0.3809571722,"data-quality":0.0609699427,"ml-security":0.0895482115}}
{"text":"Experimental results show that the GAP9's hardware accelerator achieves the lowest inference latency and energy at 2.12ms and 150uJ respectively, which is around 2x faster and 20% more efficient than the next best platform, the MAX78000.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.107907861,"dev-research":0.3848276162,"prompt-eng":0.4292852347,"data-quality":0.0710169472,"ml-security":0.081603578}}
{"text":"The hardware accelerator of GAP9 can even run an increased resolution version of TinyissimoYOLO with 112x112 pixels and 10 detection classes within 3.2ms, consuming 245uJ. To showcase the competitiveness of a versatile general-purpose system we also deployed and profiled a multi-core implementation on GAP9 at different operating points, achieving 11.3ms with the lowest-latency and 490uJ with the most energy-efficient configuration.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.1041993968,"dev-research":0.3864575944,"prompt-eng":0.4053030074,"data-quality":0.1066886234,"ml-security":0.1021992357}}
{"text":"With this paper, we demonstrate the suitability and flexibility of TinyissimoYOLO on state-of-the-art detection datasets for real-time ultra-low-power edge inference.","meta":{"url":"http://arxiv.org/abs/2307.05999v1"},"cats":{"new-dataset":0.239357347,"dev-research":0.348133592,"prompt-eng":0.3987180943,"data-quality":0.1143703444,"ml-security":0.1554415631}}
{"text":"In this article we show that Theorem 2 in Lie et al.","meta":{"url":"http://arxiv.org/abs/2307.05992v1"},"cats":{"new-dataset":0.0879281444,"dev-research":0.4383269562,"prompt-eng":0.3857090386,"data-quality":0.1476251125,"ml-security":0.1745998913}}
{"text":"(2023) is incorrect.","meta":{"url":"http://arxiv.org/abs/2307.05992v1"},"cats":{"new-dataset":0.2573009198,"dev-research":0.4386229158,"prompt-eng":0.4103629919,"data-quality":0.1762408197,"ml-security":0.114035861}}
{"text":"Since Wombat Exchange, a decentralized exchange, is built upon Lie et al. (2023) and Theorem 2 is fundamental to Wombat Finance, we show that an undesirable phenomenon, which we call the robbed withdrawal, can happen as a consequence.","meta":{"url":"http://arxiv.org/abs/2307.05992v1"},"cats":{"new-dataset":0.1056402787,"dev-research":0.4390478793,"prompt-eng":0.3918004275,"data-quality":0.0991048032,"ml-security":0.276341281}}
{"text":"Human Activity Recognition (HAR) has become one of the leading research topics of the last decade.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.1771630376,"dev-research":0.3740283404,"prompt-eng":0.411553094,"data-quality":0.092488918,"ml-security":0.0958148492}}
{"text":"As sensing technologies have matured and their economic costs have declined, a host of novel applications, e.g., in healthcare, industry, sports, and daily life activities have become popular.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.1693172439,"dev-research":0.3758998155,"prompt-eng":0.3833541465,"data-quality":0.053556486,"ml-security":0.1127413587}}
{"text":"The design of HAR systems requires different time-consuming processing steps, such as data collection, annotation, and model training and optimization.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.069068406,"dev-research":0.3960072278,"prompt-eng":0.3983497367,"data-quality":0.0668552433,"ml-security":0.0790044426}}
{"text":"In particular, data annotation represents the most labor-intensive and cumbersome step in HAR, since it requires extensive and detailed manual work from human annotators.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.2292394519,"dev-research":0.4751660603,"prompt-eng":0.4724290846,"data-quality":0.2391926184,"ml-security":0.0796605536}}
{"text":"Therefore, different methodologies concerning the automation of the annotation procedure in HAR have been proposed.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.1155085995,"dev-research":0.4990842421,"prompt-eng":0.5394656054,"data-quality":0.489932362,"ml-security":0.0622493802}}
{"text":"The annotation problem occurs in different notions and scenarios, which all require individual solutions.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.1605800533,"dev-research":0.4937424712,"prompt-eng":0.4566651842,"data-quality":0.4637314223,"ml-security":0.1123951847}}
{"text":"In this paper, we provide the first systematic review on data annotation techniques for HAR.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.3511453837,"dev-research":0.4471570434,"prompt-eng":0.4928348248,"data-quality":0.4145779738,"ml-security":0.0993259083}}
{"text":"By grouping existing approaches into classes and providing a taxonomy, our goal is to support the decision on which techniques can be beneficially used in a given scenario.","meta":{"url":"http://arxiv.org/abs/2307.05988v1"},"cats":{"new-dataset":0.081903322,"dev-research":0.505578977,"prompt-eng":0.4082814505,"data-quality":0.1118529676,"ml-security":0.1717029782}}
{"text":"Our interactions with technology do not just shape our individual experiences.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.0750012245,"dev-research":0.4535081106,"prompt-eng":0.3848843133,"data-quality":0.0844388933,"ml-security":0.1444855316}}
{"text":"They also affect people around us.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.1152409075,"dev-research":0.4233332152,"prompt-eng":0.3975148987,"data-quality":0.1387057769,"ml-security":0.230396494}}
{"text":"Although previous research has addressed such \"witness\" experiences, the actual effect of interaction design on the witness experience remains largely unknown.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.0443423926,"dev-research":0.4277020436,"prompt-eng":0.4113835093,"data-quality":0.0524692359,"ml-security":0.1161577089}}
{"text":"In an online study (n = 407), we explored how witnesses perceive mid-air gesture-based interactions with a hearing aid, using four video vignettes.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.1533983382,"dev-research":0.3974121716,"prompt-eng":0.4485328259,"data-quality":0.0772658024,"ml-security":0.0700482822}}
{"text":"We studied witnesses' subjective visibility of manipulations and effects (following Reeves and colleagues' taxonomy), perceived form of interaction, subjective experience, and relationships between these measures.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.0856434027,"dev-research":0.4434795672,"prompt-eng":0.4224736537,"data-quality":0.0854228818,"ml-security":0.1101546818}}
{"text":"Although visibility patterns matched the intended form, they did not lead to the supposed experience (i.e., \"suspenseful\" gestures did not lead to suspenseful experiences).","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.0548777721,"dev-research":0.4156433095,"prompt-eng":0.3813622099,"data-quality":0.0822729374,"ml-security":0.1344246131}}
{"text":"The paper illustrates gaps in current research about witness experiences, demonstrates the need to overcome basic hiding/revealing profiles, and indicates a path forward by focusing on aesthetic forms and experiences.","meta":{"url":"http://arxiv.org/abs/2307.05986v1"},"cats":{"new-dataset":0.0826346275,"dev-research":0.4002954087,"prompt-eng":0.4021205186,"data-quality":0.085810883,"ml-security":0.152477929}}
{"text":"Transformers have significantly impacted domains like natural language processing, computer vision, and robotics, where they improve performance compared to other neural networks.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.073789212,"dev-research":0.3966547627,"prompt-eng":0.4473521673,"data-quality":0.1177609223,"ml-security":0.1463416674}}
{"text":"This survey explores how transformers are used in reinforcement learning (RL), where they are seen as a promising solution for addressing challenges such as unstable training, credit assignment, lack of interpretability, and partial observability.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.0727496081,"dev-research":0.3999942849,"prompt-eng":0.4549136844,"data-quality":0.1089490658,"ml-security":0.3406838173}}
{"text":"We begin by providing a brief domain overview of RL, followed by a discussion on the challenges of classical RL algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.0888287171,"dev-research":0.3847881969,"prompt-eng":0.3807896505,"data-quality":0.1161333668,"ml-security":0.1407618781}}
{"text":"Next, we delve into the properties of the transformer and its variants and discuss the characteristics that make them well-suited to address the challenges inherent in RL.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.076198077,"dev-research":0.3842215309,"prompt-eng":0.3980642174,"data-quality":0.0965594971,"ml-security":0.1131456828}}
{"text":"We examine the application of transformers to various aspects of RL, including representation learning, transition and reward function modeling, and policy optimization.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.0596916612,"dev-research":0.387104918,"prompt-eng":0.4354728886,"data-quality":0.0556315742,"ml-security":0.1381584148}}
{"text":"We also discuss recent research that aims to enhance the interpretability and efficiency of transformers in RL, using visualization techniques and efficient training strategies.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.1250077743,"dev-research":0.4221830438,"prompt-eng":0.4588784707,"data-quality":0.1277858914,"ml-security":0.1269676668}}
{"text":"Often, the transformer architecture must be tailored to the specific needs of a given application.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.0463571293,"dev-research":0.4054925607,"prompt-eng":0.3950034054,"data-quality":0.0510817917,"ml-security":0.0952199524}}
{"text":"We present a broad overview of how transformers have been adapted for several applications, including robotics, medicine, language modeling, cloud computing, and combinatorial optimization.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.1140353807,"dev-research":0.4058598214,"prompt-eng":0.4311328745,"data-quality":0.0466084762,"ml-security":0.1151160452}}
{"text":"We conclude by discussing the limitations of using transformers in RL and assess their potential for catalyzing future breakthroughs in this field.","meta":{"url":"http://arxiv.org/abs/2307.05979v1"},"cats":{"new-dataset":0.0414834114,"dev-research":0.4310574015,"prompt-eng":0.4050657233,"data-quality":0.0683878501,"ml-security":0.1512173193}}
{"text":"Large-scale image generation models, with impressive quality made possible by the vast amount of data available on the Internet, raise social concerns that these models may generate harmful or copyrighted content.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.2790989633,"dev-research":0.41425864,"prompt-eng":0.4600917461,"data-quality":0.1863483317,"ml-security":0.2664889623}}
{"text":"The biases and harmfulness arise throughout the entire training process and are hard to completely remove, which have become significant hurdles to the safe deployment of these models.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.0307969627,"dev-research":0.4060572857,"prompt-eng":0.4194121571,"data-quality":0.231611866,"ml-security":0.544292778}}
{"text":"In this paper, we propose a method called SDD to prevent problematic content generation in text-to-image diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.1189807622,"dev-research":0.434652948,"prompt-eng":0.4933961361,"data-quality":0.2996941113,"ml-security":0.1404775268}}
{"text":"We self-distill the diffusion model to guide the noise estimate conditioned on the target removal concept to match the unconditional one.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.0373232101,"dev-research":0.3635026063,"prompt-eng":0.4223553741,"data-quality":0.2260283358,"ml-security":0.1766874397}}
{"text":"Compared to the previous methods, our method eliminates a much greater proportion of harmful content from the generated images without degrading the overall image quality.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.121100843,"dev-research":0.4273812949,"prompt-eng":0.3965996129,"data-quality":0.31164726,"ml-security":0.1885274784}}
{"text":"Furthermore, our method allows the removal of multiple concepts at once, whereas previous works are limited to removing a single concept at a time.","meta":{"url":"http://arxiv.org/abs/2307.05977v1"},"cats":{"new-dataset":0.0511159816,"dev-research":0.4847215569,"prompt-eng":0.4054720214,"data-quality":0.1796044195,"ml-security":0.1007477195}}
{"text":"Conversion rate (CVR) prediction plays an important role in advertising systems.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.0674668043,"dev-research":0.4003794096,"prompt-eng":0.4816707433,"data-quality":0.2107410231,"ml-security":0.1914218152}}
{"text":"Recently, supervised deep neural network-based models have shown promising performance in CVR prediction.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.1536383059,"dev-research":0.3591607023,"prompt-eng":0.4754838868,"data-quality":0.1474737042,"ml-security":0.230615042}}
{"text":"However, they are data hungry and require an enormous amount of training data.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.2459847242,"dev-research":0.3908181546,"prompt-eng":0.4291544284,"data-quality":0.1442024017,"ml-security":0.225451665}}
{"text":"In online advertising systems, although there are millions to billions of ads, users tend to click only a small set of them and to convert on an even smaller set.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.0459536209,"dev-research":0.4472907988,"prompt-eng":0.449795389,"data-quality":0.1964281185,"ml-security":0.1809351814}}
{"text":"This data sparsity issue restricts the power of these deep models.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.1659643769,"dev-research":0.3367667343,"prompt-eng":0.4314473019,"data-quality":0.2057979333,"ml-security":0.286983946}}
{"text":"In this paper, we propose the Contrastive Learning for CVR prediction (CL4CVR) framework.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.2187446571,"dev-research":0.3661206309,"prompt-eng":0.4585617908,"data-quality":0.1614721153,"ml-security":0.1225074653}}
{"text":"It associates the supervised CVR prediction task with a contrastive learning task, which can learn better data representations exploiting abundant unlabeled data and improve the CVR prediction performance.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.1631507914,"dev-research":0.4134239822,"prompt-eng":0.4653517494,"data-quality":0.1902102458,"ml-security":0.1427082633}}
{"text":"To tailor the contrastive learning task to the CVR prediction problem, we propose embedding masking (EM), rather than feature masking, to create two views of augmented samples.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.1613746388,"dev-research":0.3626629717,"prompt-eng":0.4550287359,"data-quality":0.1738619686,"ml-security":0.2029536266}}
{"text":"We also propose a false negative elimination (FNE) component to eliminate samples with the same feature as the anchor sample, to account for the natural property in user behavior data.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.1166539902,"dev-research":0.4301829307,"prompt-eng":0.4860513125,"data-quality":0.2559317374,"ml-security":0.2396357769}}
{"text":"We further propose a supervised positive inclusion (SPI) component to include additional positive samples for each anchor sample, in order to make full use of sparse but precious user conversion events.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.0877045973,"dev-research":0.4002270927,"prompt-eng":0.5101646347,"data-quality":0.2893576723,"ml-security":0.1827254631}}
{"text":"Experimental results on two real-world conversion datasets demonstrate the superior performance of CL4CVR.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.2484760206,"dev-research":0.3714276742,"prompt-eng":0.4471421905,"data-quality":0.1335368511,"ml-security":0.0883902098}}
{"text":"The source code is available at https://github.com/DongRuiHust/CL4CVR.","meta":{"url":"http://arxiv.org/abs/2307.05974v1"},"cats":{"new-dataset":0.291137461,"dev-research":0.4597575214,"prompt-eng":0.4452929314,"data-quality":0.1052263011,"ml-security":0.0723510702}}
{"text":"Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.195911508,"dev-research":0.43942845,"prompt-eng":0.5538438986,"data-quality":0.0773259383,"ml-security":0.1193784687}}
{"text":"Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.0778471359,"dev-research":0.4205279337,"prompt-eng":0.4050812987,"data-quality":0.0317350731,"ml-security":0.0660254693}}
{"text":"In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.2115204087,"dev-research":0.4192632708,"prompt-eng":0.4443052733,"data-quality":0.0471863906,"ml-security":0.077780106}}
{"text":"We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.243322966,"dev-research":0.5061589995,"prompt-eng":0.5552976083,"data-quality":0.0959448126,"ml-security":0.117286243}}
{"text":"More importantly, by leveraging their code-writing capabilities, they can interact with a visual-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.2802482388,"dev-research":0.5236292604,"prompt-eng":0.521230045,"data-quality":0.1150595192,"ml-security":0.1205801842}}
{"text":"The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.1392461382,"dev-research":0.3968566945,"prompt-eng":0.4224587105,"data-quality":0.0822184279,"ml-security":0.1365772094}}
{"text":"We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.168170859,"dev-research":0.3812021793,"prompt-eng":0.4561736749,"data-quality":0.0578913179,"ml-security":0.1088916686}}
{"text":"We present a large-scale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language.","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.1955047107,"dev-research":0.4371415647,"prompt-eng":0.4814356282,"data-quality":0.1023379556,"ml-security":0.0950068793}}
{"text":"Project website: https://voxposer.github.io","meta":{"url":"http://arxiv.org/abs/2307.05973v1"},"cats":{"new-dataset":0.3960937306,"dev-research":0.4431578713,"prompt-eng":0.410296643,"data-quality":0.0756565077,"ml-security":0.0543950386}}
{"text":"We investigate the effects of post-training quantization and quantization-aware training on the generalization of Transformer language models.","meta":{"url":"http://arxiv.org/abs/2307.05972v1"},"cats":{"new-dataset":0.0801526372,"dev-research":0.4108469856,"prompt-eng":0.5315121043,"data-quality":0.2326699128,"ml-security":0.2132149727}}
{"text":"We present a new method called self-distilled quantization (SDQ) that minimizes accumulative quantization errors and outperforms baselines.","meta":{"url":"http://arxiv.org/abs/2307.05972v1"},"cats":{"new-dataset":0.0668029562,"dev-research":0.3912167454,"prompt-eng":0.453710003,"data-quality":0.331072264,"ml-security":0.1364349656}}
{"text":"We apply SDQ to multilingual models XLM-R-Base and InfoXLM-Base and demonstrate that both models can be reduced from 32-bit floating point weights to 8-bit integer weights while maintaining a high level of performance on the XGLUE benchmark.","meta":{"url":"http://arxiv.org/abs/2307.05972v1"},"cats":{"new-dataset":0.1686164493,"dev-research":0.3995851893,"prompt-eng":0.4696448316,"data-quality":0.1547626002,"ml-security":0.1344947015}}
{"text":"Our results also highlight the challenges of quantizing multilingual models, which must generalize to languages they were not fine-tuned on.","meta":{"url":"http://arxiv.org/abs/2307.05972v1"},"cats":{"new-dataset":0.1680191429,"dev-research":0.4122471366,"prompt-eng":0.4801016892,"data-quality":0.2678788026,"ml-security":0.1239730006}}
{"text":"Language-Guided Robotic Manipulation (LGRM) is a challenging task as it requires a robot to understand human instructions to manipulate everyday objects.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.0972739936,"dev-research":0.4207525015,"prompt-eng":0.5401195077,"data-quality":0.1081241133,"ml-security":0.0683780493}}
{"text":"Recent approaches in LGRM rely on pre-trained Visual Grounding (VG) models to detect objects without adapting to manipulation environments.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.1120137086,"dev-research":0.3760136577,"prompt-eng":0.4946333778,"data-quality":0.1152413145,"ml-security":0.0974679281}}
{"text":"This results in a performance drop due to a substantial domain gap between the pre-training and real-world data.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.1928391798,"dev-research":0.393096712,"prompt-eng":0.4770779924,"data-quality":0.1709550101,"ml-security":0.1595901245}}
{"text":"A straightforward solution is to collect additional training data, but the cost of human-annotation is extortionate.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.340194617,"dev-research":0.4606750345,"prompt-eng":0.5160052802,"data-quality":0.3873519019,"ml-security":0.4330494357}}
{"text":"In this paper, we propose Grounding Vision to Ceaselessly Created Instructions (GVCCI), a lifelong learning framework for LGRM, which continuously learns VG without human supervision.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.176937937,"dev-research":0.4201462821,"prompt-eng":0.4923334237,"data-quality":0.1254964603,"ml-security":0.1469845715}}
{"text":"GVCCI iteratively generates synthetic instruction via object detection and trains the VG model with the generated data.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.1512662165,"dev-research":0.4465908442,"prompt-eng":0.5100768006,"data-quality":0.1273826524,"ml-security":0.1210904469}}
{"text":"We validate our framework in offline and online settings across diverse environments on different VG models.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.1443339792,"dev-research":0.4380268652,"prompt-eng":0.4810999849,"data-quality":0.0928621069,"ml-security":0.1273202555}}
{"text":"Experimental results show that accumulating synthetic data from GVCCI leads to a steady improvement in VG by up to 56.7% and improves resultant LGRM by up to 29.4%.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.1039537382,"dev-research":0.3735642362,"prompt-eng":0.4596606816,"data-quality":0.1278775781,"ml-security":0.0776642194}}
{"text":"Furthermore, the qualitative analysis shows that the unadapted VG model often fails to find correct objects due to a strong bias learned from the pre-training data.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.0673611397,"dev-research":0.3956869845,"prompt-eng":0.4722203763,"data-quality":0.2667082015,"ml-security":0.2070021219}}
{"text":"Finally, we introduce a novel VG dataset for LGRM, consisting of nearly 252k triplets of image-object-instruction from diverse manipulation environments.","meta":{"url":"http://arxiv.org/abs/2307.05963v1"},"cats":{"new-dataset":0.3757310214,"dev-research":0.39574466,"prompt-eng":0.5050673229,"data-quality":0.0886136309,"ml-security":0.0782683329}}
{"text":"Traditional coverage grey-box fuzzers perform a breadth-first search of the state space of Program Under Test (PUT).","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.1056395561,"dev-research":0.5075615811,"prompt-eng":0.4659111132,"data-quality":0.1473233008,"ml-security":0.1599728603}}
{"text":"This aimlessness wastes a lot of computing resources.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.1199421068,"dev-research":0.475706825,"prompt-eng":0.4134101663,"data-quality":0.0889899685,"ml-security":0.1728816719}}
{"text":"Directed grey-box fuzzing focuses on the target of PUT and becomes one of the most popular topics of software testing.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.108046858,"dev-research":0.546718975,"prompt-eng":0.4952918955,"data-quality":0.1872669681,"ml-security":0.2371492041}}
{"text":"The early termination of unreachable test cases is a method to improve directed grey-box fuzzing.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.0599948929,"dev-research":0.4661616348,"prompt-eng":0.4341997122,"data-quality":0.243733576,"ml-security":0.2307299072}}
{"text":"However, existing solutions have two problems: firstly, reachability analysis needs to introduce extra technologies (e.g., static analysis); secondly, the performance of reachability analysis and auxiliary technologies lack versatility.   ","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.1080394346,"dev-research":0.4600523709,"prompt-eng":0.3839876399,"data-quality":0.0939911254,"ml-security":0.0972279685}}
{"text":"We propose FGo, a probabilistic exponential cut-the-loss directed grey-box fuzzer.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.1140138075,"dev-research":0.4078981634,"prompt-eng":0.3984535372,"data-quality":0.1413615614,"ml-security":0.1790155929}}
{"text":"FGo terminates unreachable test cases early with exponentially increasing probability.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.0769940188,"dev-research":0.3636997661,"prompt-eng":0.3846972493,"data-quality":0.1250664608,"ml-security":0.2403076324}}
{"text":"Compared to other technologies, FGo makes full use of the unreachable information contained in iCFG and doesn't generate any additional overhead caused by reachability analysis.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.1241745117,"dev-research":0.3989951078,"prompt-eng":0.3993110426,"data-quality":0.1083262628,"ml-security":0.1518278546}}
{"text":"Moreover, it is easy to generalize to all PUT.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.070621107,"dev-research":0.4507845278,"prompt-eng":0.4055730047,"data-quality":0.1739386814,"ml-security":0.1212676112}}
{"text":"This strategy based on probability is perfectly adapted to the randomness of fuzzing.   ","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.0965152865,"dev-research":0.4486645568,"prompt-eng":0.471438113,"data-quality":0.2444483525,"ml-security":0.3760835462}}
{"text":"The experiment results show that FGo is 106% faster than AFLGo in reproducing crashes.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.2675016774,"dev-research":0.4122827743,"prompt-eng":0.4250427643,"data-quality":0.12158276,"ml-security":0.1296901572}}
{"text":"We compare multiple parameters of probabilistic exponential cut-the-loss algorithm and analyze them in detail.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.0951679647,"dev-research":0.3696640597,"prompt-eng":0.3768907854,"data-quality":0.156010341,"ml-security":0.1519406847}}
{"text":"In addition, for enhancing the inerpretability of FGo, this paper discusses the difference between the theoretical performance and the practical performance of probabilistic exponential cut-the-loss algorithm.","meta":{"url":"http://arxiv.org/abs/2307.05961v1"},"cats":{"new-dataset":0.0817889046,"dev-research":0.3385291476,"prompt-eng":0.3666566319,"data-quality":0.107588169,"ml-security":0.1759803558}}
{"text":"Smoothed Particle Hydrodynamics (SPH) is plagued by the phenomenon of tensile instability, which is the occurrence of short wavelength zero energy modes resulting in unphysical clustering of particles.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0937781811,"dev-research":0.3665061217,"prompt-eng":0.3979010248,"data-quality":0.0929240021,"ml-security":0.0892274466}}
{"text":"The root cause of the instability is the shape of derivative of the compactly supported kernel function which may yield negative stiffness in the particle interaction under certain circumstances.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0571322082,"dev-research":0.4128976706,"prompt-eng":0.4002346863,"data-quality":0.2063134377,"ml-security":0.1777066703}}
{"text":"In this work, an adaptive algorithm is developed to remove tensile instability in SPH for weakly compressible fluids.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0775587399,"dev-research":0.3747066186,"prompt-eng":0.3558645661,"data-quality":0.0967248249,"ml-security":0.1306542516}}
{"text":"Herein, a B-spline function is used as the SPH kernel and the knots of the B-spline are adapted to change the shape of the kernel, thereby satisfying the condition associated with stability.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.1178034503,"dev-research":0.4083759041,"prompt-eng":0.3533133446,"data-quality":0.0948224791,"ml-security":0.0876040869}}
{"text":"The knot-shifting criterion is based on the particle movement within the influence domain.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0415925466,"dev-research":0.3875959319,"prompt-eng":0.3779902728,"data-quality":0.0729026295,"ml-security":0.0512265209}}
{"text":"This enables the prevention of instability in fluid problems where excessive rearrangement of particle positions occurs.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0290289177,"dev-research":0.4324544482,"prompt-eng":0.3568354716,"data-quality":0.1006627777,"ml-security":0.1640821617}}
{"text":"A 1D dispersion analysis of an Oldroyd B fluid material model is performed to show how the algorithm prevents instabilities for short wavelengths but ensures accuracy at large wavelengths.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.1070151408,"dev-research":0.3552995489,"prompt-eng":0.3727907697,"data-quality":0.0919663439,"ml-security":0.098696998}}
{"text":"The efficacy of the approach is demonstrated through a few benchmark fluid dynamics simulations where a visco-elastic Oldroyd B material model and a non-viscous Eulerian fluid material model are considered.","meta":{"url":"http://arxiv.org/abs/2307.05960v1"},"cats":{"new-dataset":0.0968979756,"dev-research":0.3738561138,"prompt-eng":0.395194632,"data-quality":0.062804881,"ml-security":0.0846723923}}
{"text":"Eye-in-hand cameras have shown promise in enabling greater sample efficiency and generalization in vision-based robotic manipulation.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.0816433526,"dev-research":0.374534709,"prompt-eng":0.4094704156,"data-quality":0.0719315275,"ml-security":0.0484999743}}
{"text":"However, for robotic imitation, it is still expensive to have a human teleoperator collect large amounts of expert demonstrations with a real robot.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.0867764966,"dev-research":0.4112171641,"prompt-eng":0.4699232675,"data-quality":0.0594327651,"ml-security":0.1184111927}}
{"text":"Videos of humans performing tasks, on the other hand, are much cheaper to collect since they eliminate the need for expertise in robotic teleoperation and can be quickly captured in a wide range of scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.1363530928,"dev-research":0.4122557148,"prompt-eng":0.4258322417,"data-quality":0.0635426799,"ml-security":0.0680475825}}
{"text":"Therefore, human video demonstrations are a promising data source for learning generalizable robotic manipulation policies at scale.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.2557821323,"dev-research":0.4003925148,"prompt-eng":0.5041390637,"data-quality":0.0763549057,"ml-security":0.1612859525}}
{"text":"In this work, we augment narrow robotic imitation datasets with broad unlabeled human video demonstrations to greatly enhance the generalization of eye-in-hand visuomotor policies.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.2597483735,"dev-research":0.3902486565,"prompt-eng":0.4862753466,"data-quality":0.0877550555,"ml-security":0.0929907247}}
{"text":"Although a clear visual domain gap exists between human and robot data, our framework does not need to employ any explicit domain adaptation method, as we leverage the partial observability of eye-in-hand cameras as well as a simple fixed image masking scheme.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.1337355398,"dev-research":0.3980155173,"prompt-eng":0.4327867458,"data-quality":0.1137534668,"ml-security":0.1463625639}}
{"text":"On a suite of eight real-world tasks involving both 3-DoF and 6-DoF robot arm control, our method improves the success rates of eye-in-hand manipulation policies by 58% (absolute) on average, enabling robots to generalize to both new environment configurations and new tasks that are unseen in the robot demonstration data.","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.1555266479,"dev-research":0.4226256563,"prompt-eng":0.4531308131,"data-quality":0.0641377336,"ml-security":0.0682180642}}
{"text":"See video results at https://giving-robots-a-hand.github.io/ .","meta":{"url":"http://arxiv.org/abs/2307.05959v1"},"cats":{"new-dataset":0.2199321147,"dev-research":0.4420846351,"prompt-eng":0.4620772986,"data-quality":0.0818995346,"ml-security":0.074748037}}
{"text":"Multilingual speech recognition for both monolingual and code-switching speech is a challenging task.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.1969521607,"dev-research":0.3886322017,"prompt-eng":0.5086752022,"data-quality":0.2090620754,"ml-security":0.0895744116}}
{"text":"Recently, based on the Mixture of Experts (MoE), many works have made good progress in multilingual and code-switching ASR, but present huge computational complexity with the increase of supported languages.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.1878753902,"dev-research":0.469116796,"prompt-eng":0.4849533552,"data-quality":0.1445148749,"ml-security":0.0759827962}}
{"text":"In this work, we propose a computation-efficient network named Language-Routing Mixture of Experts (LR-MoE) for multilingual and code-switching ASR.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.1859790737,"dev-research":0.4670562567,"prompt-eng":0.4851810968,"data-quality":0.1761090844,"ml-security":0.0924924788}}
{"text":"LR-MoE extracts language-specific representations through the Mixture of Language Experts (MLE), which is guided to learn by a frame-wise language routing mechanism.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.1112383891,"dev-research":0.4392345825,"prompt-eng":0.5507842825,"data-quality":0.1968046515,"ml-security":0.1012062013}}
{"text":"The weight-shared frame-level language identification (LID) network is jointly trained as the shared pre-router of each MoE layer.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.1236842827,"dev-research":0.3830326141,"prompt-eng":0.5307674646,"data-quality":0.2773466734,"ml-security":0.2139709993}}
{"text":"Experiments show that the proposed method significantly improves multilingual and code-switching speech recognition performances over baseline with comparable computational efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05956v1"},"cats":{"new-dataset":0.134638575,"dev-research":0.4111106721,"prompt-eng":0.4843640648,"data-quality":0.2185707778,"ml-security":0.0761467804}}
{"text":"We study a fundamental problem in optimization under uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.0601234003,"dev-research":0.402752241,"prompt-eng":0.3855588374,"data-quality":0.185010765,"ml-security":0.2065806236}}
{"text":"There are $n$ boxes; each box $i$ contains a hidden reward $x_i$.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.1599525193,"dev-research":0.4163893347,"prompt-eng":0.3776182536,"data-quality":0.0886963633,"ml-security":0.2478566371}}
{"text":"Rewards are drawn i.i.d.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.1172871476,"dev-research":0.438276471,"prompt-eng":0.4276501124,"data-quality":0.1024965085,"ml-security":0.1120966991}}
{"text":"from an unknown distribution $\\mathcal{D}$. For each box $i$, we see $y_i$, an unbiased estimate of its reward, which is drawn from a Normal distribution with known standard deviation $\\sigma_i$ (and an unknown mean $x_i$).","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.1715861994,"dev-research":0.3983469809,"prompt-eng":0.4258943398,"data-quality":0.1157260139,"ml-security":0.1970435515}}
{"text":"Our task is to select a single box, with the goal of maximizing our reward.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.102040427,"dev-research":0.4330716646,"prompt-eng":0.4264167731,"data-quality":0.0448359632,"ml-security":0.099572511}}
{"text":"This problem captures a wide range of applications, e.g. ad auctions, where the hidden reward is the click-through rate of an ad.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.0871230006,"dev-research":0.4524776274,"prompt-eng":0.4533797523,"data-quality":0.1279867716,"ml-security":0.2115174597}}
{"text":"Previous work in this model [BKMR12] proves that the naive policy, which selects the box with the largest estimate $y_i$, is suboptimal, and suggests a linear policy, which selects the box $i$ with the largest $y_i - c \\cdot \\sigma_i$, for some $c > 0$.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.1027464358,"dev-research":0.3892009591,"prompt-eng":0.41828627,"data-quality":0.0834709167,"ml-security":0.1757599034}}
{"text":"However, no formal guarantees are given about the performance of either policy (e.g., whether their expected reward is within some factor of the optimal policy's reward).   ","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.0310416073,"dev-research":0.3883811704,"prompt-eng":0.375064707,"data-quality":0.0886336301,"ml-security":0.1520757078}}
{"text":"In this work, we prove that both the naive policy and the linear policy are arbitrarily bad compared to the optimal policy, even when $\\mathcal{D}$ is well-behaved, e.g. has monotone hazard rate (MHR), and even under a \"small tail\" condition, which requires that not too many boxes have arbitrarily large noise.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.1488941548,"dev-research":0.3907742099,"prompt-eng":0.3945279784,"data-quality":0.2152825026,"ml-security":0.3136243625}}
{"text":"On the flip side, we propose a simple threshold policy that gives a constant approximation to the reward of a prophet (who knows the realized values $x_1, \\dots, x_n$) under the same \"small tail\" condition.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.0768254773,"dev-research":0.4134026289,"prompt-eng":0.4122397902,"data-quality":0.0745789101,"ml-security":0.2545291063}}
{"text":"We prove that when this condition is not satisfied, even an optimal clairvoyant policy (that knows $\\mathcal{D}$) cannot get a constant approximation to the prophet, even for MHR distributions, implying that our threshold policy is optimal against the prophet benchmark, up to constants.","meta":{"url":"http://arxiv.org/abs/2307.05953v1"},"cats":{"new-dataset":0.0605827165,"dev-research":0.3795413041,"prompt-eng":0.4362866278,"data-quality":0.0857774507,"ml-security":0.2055375239}}
{"text":"Automated logging statement generation techniques facilitate developers in writing appropriate logging statements that document software behaviors.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1234444915,"dev-research":0.6088816493,"prompt-eng":0.558738633,"data-quality":0.2274118546,"ml-security":0.1241809371}}
{"text":"Current retrieval-based and learning-based logging methods fail to provide accurate logging statements in complex software.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1614112647,"dev-research":0.5122240328,"prompt-eng":0.4774457248,"data-quality":0.3596597621,"ml-security":0.1883114751}}
{"text":"Although existing large language models (LLMs) might be a good fit for the task due to their great success in natural language generation and programming language comprehension, their effectiveness and generalization capabilities have not been explored.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1631463344,"dev-research":0.4746074004,"prompt-eng":0.5864845435,"data-quality":0.1369933493,"ml-security":0.1220061444}}
{"text":"To this end, this paper performs the first extensive study on applying LLMs for logging statement generation.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1338344201,"dev-research":0.5001707731,"prompt-eng":0.5665794296,"data-quality":0.1882896945,"ml-security":0.1439962913}}
{"text":"We build LogBench, the first logging statement generation dataset.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.6505243651,"dev-research":0.4882350347,"prompt-eng":0.5289335877,"data-quality":0.1819882885,"ml-security":0.1240321863}}
{"text":"On LogBench, we evaluate the effectiveness and generalization capabilities of eight state-of-the-art LLMs, which include general-purpose and code-specific models ranging from 60M to 175B in size.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.0951816128,"dev-research":0.4617845933,"prompt-eng":0.5340328949,"data-quality":0.084097495,"ml-security":0.1443089766}}
{"text":"Specifically, we evaluate LLM's logging effectiveness by studying 1) their ability to decide logging ingredients, 2) the impact of the internal characteristics of LLMs, and 3) the influence of external factors.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1022978506,"dev-research":0.4823837199,"prompt-eng":0.5135909283,"data-quality":0.1245602665,"ml-security":0.1382384193}}
{"text":"We further evaluate LLM's logging generalization capabilities using unseen data derived from code transformation techniques.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1305577752,"dev-research":0.5442047443,"prompt-eng":0.5188871832,"data-quality":0.1819589021,"ml-security":0.2470537511}}
{"text":"Our study demonstrates that existing LLMs fall short of practical requirements for generating proper logging statement texts.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1779837112,"dev-research":0.5028852661,"prompt-eng":0.566243806,"data-quality":0.2278925014,"ml-security":0.1571049361}}
{"text":"We also disclose the impact of internal characteristics and external factors for LLMs in automated logging.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.0936020997,"dev-research":0.4949228236,"prompt-eng":0.5338787774,"data-quality":0.1993137605,"ml-security":0.1707742563}}
{"text":"In addition, we observe that existing LLMs cannot generalize to logging unseen code, revealing their unsatisfactory generalization capabilities.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.0772770604,"dev-research":0.5231996695,"prompt-eng":0.4933721943,"data-quality":0.2490631527,"ml-security":0.357807683}}
{"text":"Based on our findings, we further discuss three implications that can enhance logging statement generation in the future, such as developing a unified metric for logging quality, incorporating shareable code knowledge into LLMs, and devising suitable prompts.","meta":{"url":"http://arxiv.org/abs/2307.05950v1"},"cats":{"new-dataset":0.1545820178,"dev-research":0.563862423,"prompt-eng":0.5738515313,"data-quality":0.2594393616,"ml-security":0.1734268169}}
{"text":"Deep learning (DL) models for spatio-temporal traffic flow forecasting employ convolutional or graph-convolutional filters along with recurrent neural networks to capture spatial and temporal dependencies in traffic data.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.2202115448,"dev-research":0.3692271699,"prompt-eng":0.4071950579,"data-quality":0.0766760405,"ml-security":0.1686383147}}
{"text":"These models, such as CNN-LSTM, utilize traffic flows from neighboring detector stations to predict flows at a specific location of interest.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.1416246838,"dev-research":0.3645274864,"prompt-eng":0.4788606662,"data-quality":0.1023424778,"ml-security":0.1875405595}}
{"text":"However, these models are limited in their ability to capture the broader dynamics of the traffic system, as they primarily learn features specific to the detector configuration and traffic characteristics at the target location.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.0854477498,"dev-research":0.3718556482,"prompt-eng":0.4497350859,"data-quality":0.0818805624,"ml-security":0.2945967752}}
{"text":"Hence, the transferability of these models to different locations becomes challenging, particularly when data is unavailable at the new location for model training.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.1293646342,"dev-research":0.3677316484,"prompt-eng":0.419219066,"data-quality":0.1612291269,"ml-security":0.2876179942}}
{"text":"To address this limitation, we propose a traffic flow physics-based feature transformation for spatio-temporal DL models.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.1267570188,"dev-research":0.3802966561,"prompt-eng":0.4005378798,"data-quality":0.0621087059,"ml-security":0.1255341055}}
{"text":"This transformation incorporates Newell's uncongested and congested-state estimators of traffic flows at the target locations, enabling the models to learn broader dynamics of the system.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.12536012,"dev-research":0.4028136391,"prompt-eng":0.444470088,"data-quality":0.0846079291,"ml-security":0.1618607738}}
{"text":"Our methodology is empirically validated using traffic data from two different locations.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.1490756219,"dev-research":0.3817171898,"prompt-eng":0.4060634077,"data-quality":0.161605848,"ml-security":0.1446864245}}
{"text":"The results demonstrate that the proposed feature transformation improves the models' performance in predicting traffic flows over different prediction horizons, as indicated by better goodness-of-fit statistics.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.0962181905,"dev-research":0.3806014677,"prompt-eng":0.4351289771,"data-quality":0.1153181801,"ml-security":0.1786299744}}
{"text":"An important advantage of our framework is its ability to be transferred to new locations where data is unavailable.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.2200873682,"dev-research":0.4493251716,"prompt-eng":0.3768494462,"data-quality":0.0819535406,"ml-security":0.2817611388}}
{"text":"This is achieved by appropriately accounting for spatial dependencies based on station distances and various traffic parameters.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.0910463609,"dev-research":0.3992626039,"prompt-eng":0.4120788744,"data-quality":0.100501272,"ml-security":0.0752679451}}
{"text":"In contrast, regular DL models are not easily transferable as their inputs remain fixed.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.04110492,"dev-research":0.3847839901,"prompt-eng":0.4204951307,"data-quality":0.1118679308,"ml-security":0.1922623863}}
{"text":"It should be noted that due to data limitations, we were unable to perform spatial sensitivity analysis, which calls for further research using simulated data.","meta":{"url":"http://arxiv.org/abs/2307.05949v1"},"cats":{"new-dataset":0.1894092119,"dev-research":0.358862962,"prompt-eng":0.3720204759,"data-quality":0.1708137058,"ml-security":0.1241591117}}
{"text":"Generating unlabeled data has been recently shown to help address the few-shot hypothesis adaptation (FHA) problem, where we aim to train a classifier for the target domain with a few labeled target-domain data and a well-trained source-domain classifier (i.e., a source hypothesis), for the additional information of the highly-compatible unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.1939715721,"dev-research":0.41644781,"prompt-eng":0.5239901117,"data-quality":0.4582565829,"ml-security":0.3015322914}}
{"text":"However, the generated data of the existing methods are extremely similar or even the same.","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.1741531815,"dev-research":0.4794269923,"prompt-eng":0.3940583937,"data-quality":0.1955625677,"ml-security":0.1237570757}}
{"text":"The strong dependency among the generated data will lead the learning to fail.","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.164448818,"dev-research":0.4245264221,"prompt-eng":0.5070950106,"data-quality":0.4031682846,"ml-security":0.3160010996}}
{"text":"In this paper, we propose a diversity-enhancing generative network (DEG-Net) for the FHA problem, which can generate diverse unlabeled data with the help of a kernel independence measure: the Hilbert-Schmidt independence criterion (HSIC).","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.1596390351,"dev-research":0.3687586121,"prompt-eng":0.4269096783,"data-quality":0.2380236023,"ml-security":0.1491172624}}
{"text":"Specifically, DEG-Net will generate data via minimizing the HSIC value (i.e., maximizing the independence) among the semantic features of the generated data.","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.2014588793,"dev-research":0.4505143005,"prompt-eng":0.4862931123,"data-quality":0.1644192243,"ml-security":0.1660689746}}
{"text":"By DEG-Net, the generated unlabeled data are more diverse and more effective for addressing the FHA problem.","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.2152422318,"dev-research":0.4282622211,"prompt-eng":0.4273600081,"data-quality":0.2606961925,"ml-security":0.2383332778}}
{"text":"Experimental results show that the DEG-Net outperforms existing FHA baselines and further verifies that generating diverse data plays a vital role in addressing the FHA problem","meta":{"url":"http://arxiv.org/abs/2307.05948v1"},"cats":{"new-dataset":0.1130778206,"dev-research":0.3869656962,"prompt-eng":0.4026780489,"data-quality":0.122218938,"ml-security":0.1876498178}}
{"text":"Deep-learning models for traffic data prediction can have superior performance in modeling complex functions using a multi-layer architecture.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.1732089078,"dev-research":0.3451917228,"prompt-eng":0.4103274424,"data-quality":0.0716832038,"ml-security":0.2810199787}}
{"text":"However, a major drawback of these approaches is that most of these approaches do not offer forecasts with uncertainty estimates, which are essential for traffic operations and control.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.0592555872,"dev-research":0.385664052,"prompt-eng":0.3567957686,"data-quality":0.095869522,"ml-security":0.2420796061}}
{"text":"Without uncertainty estimates, it is difficult to place any level of trust to the model predictions, and operational strategies relying on overconfident predictions can lead to worsening traffic conditions.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.0483290853,"dev-research":0.3924166632,"prompt-eng":0.4275691928,"data-quality":0.1954275064,"ml-security":0.4821275298}}
{"text":"In this study, we propose a Bayesian recurrent neural network framework for uncertainty quantification in traffic prediction with higher generalizability by introducing spectral normalization to its hidden layers.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.1831845175,"dev-research":0.3475008321,"prompt-eng":0.4654678136,"data-quality":0.2048905658,"ml-security":0.3530507618}}
{"text":"In our paper, we have shown that normalization alters the training process of deep neural networks by controlling the model's complexity and reducing the risk of overfitting to the training data.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.066624654,"dev-research":0.3784037266,"prompt-eng":0.4127241759,"data-quality":0.185681134,"ml-security":0.4774490059}}
{"text":"This, in turn, helps improve the generalization performance of the model on out-of-distribution datasets.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.2490090036,"dev-research":0.3931551722,"prompt-eng":0.464151071,"data-quality":0.2155467641,"ml-security":0.2525609389}}
{"text":"Results demonstrate that spectral normalization improves uncertainty estimates and significantly outperforms both the layer normalization and model without normalization in single-step prediction horizons.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.0779124003,"dev-research":0.3325113236,"prompt-eng":0.4279779909,"data-quality":0.1863934115,"ml-security":0.1812355819}}
{"text":"This improved performance can be attributed to the ability of spectral normalization to better localize the feature space of the data under perturbations.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.1050514011,"dev-research":0.3705651424,"prompt-eng":0.4090024279,"data-quality":0.2777529967,"ml-security":0.1768003277}}
{"text":"Our findings are especially relevant to traffic management applications, where predicting traffic conditions across multiple locations is the goal, but the availability of training data from multiple locations is limited.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.1928452187,"dev-research":0.3746320932,"prompt-eng":0.4428175764,"data-quality":0.1232166431,"ml-security":0.2601353307}}
{"text":"Spectral normalization, therefore, provides a more generalizable approach that can effectively capture the underlying patterns in traffic data without requiring location-specific models.","meta":{"url":"http://arxiv.org/abs/2307.05946v1"},"cats":{"new-dataset":0.1548512724,"dev-research":0.3710641065,"prompt-eng":0.4054322683,"data-quality":0.1409080178,"ml-security":0.2463755385}}
{"text":"We introduce YOGA, a deep learning based yet lightweight object detection model that can operate on low-end edge devices while still achieving competitive accuracy.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.161171311,"dev-research":0.3483601362,"prompt-eng":0.4032145061,"data-quality":0.1377390442,"ml-security":0.2596802593}}
{"text":"The YOGA architecture consists of a two-phase feature learning pipeline with a cheap linear transformation, which learns feature maps using only half of the convolution filters required by conventional convolutional neural networks.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.1850668815,"dev-research":0.3589851716,"prompt-eng":0.421976973,"data-quality":0.1063013611,"ml-security":0.1348862396}}
{"text":"In addition, it performs multi-scale feature fusion in its neck using an attention mechanism instead of the naive concatenation used by conventional detectors.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.1024900881,"dev-research":0.3768550345,"prompt-eng":0.4590512878,"data-quality":0.1768631691,"ml-security":0.0812166622}}
{"text":"YOGA is a flexible model that can be easily scaled up or down by several orders of magnitude to fit a broad range of hardware constraints.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.1016165042,"dev-research":0.3924623788,"prompt-eng":0.3825037613,"data-quality":0.0542019109,"ml-security":0.0982221308}}
{"text":"We evaluate YOGA on COCO-val and COCO-testdev datasets with other over 10 state-of-the-art object detectors.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.4641145311,"dev-research":0.3793599843,"prompt-eng":0.4606668892,"data-quality":0.2181448234,"ml-security":0.1157028081}}
{"text":"The results show that YOGA strikes the best trade-off between model size and accuracy (up to 22% increase of AP and 23-34% reduction of parameters and FLOPs), making it an ideal choice for deployment in the wild on low-end edge devices.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.096400855,"dev-research":0.4017953517,"prompt-eng":0.4035964434,"data-quality":0.0864966676,"ml-security":0.1131495479}}
{"text":"This is further affirmed by our hardware implementation and evaluation on NVIDIA Jetson Nano.","meta":{"url":"http://arxiv.org/abs/2307.05945v1"},"cats":{"new-dataset":0.1671570599,"dev-research":0.4177462343,"prompt-eng":0.383237424,"data-quality":0.1042401805,"ml-security":0.0974750114}}
{"text":"In this paper, we propose a high-precision SRAM-based CIM macro that can perform 4x4-bit MAC operations and yield 9-bit signed output.","meta":{"url":"http://arxiv.org/abs/2307.05944v1"},"cats":{"new-dataset":0.0779100861,"dev-research":0.4229091197,"prompt-eng":0.4310117317,"data-quality":0.110199168,"ml-security":0.1299460826}}
{"text":"The inherent discharge branches of SRAM cells are utilized to apply time-modulated MAC and 9-bit ADC readout operations on two bit-line capacitors.","meta":{"url":"http://arxiv.org/abs/2307.05944v1"},"cats":{"new-dataset":0.0650232627,"dev-research":0.4193034029,"prompt-eng":0.4393708918,"data-quality":0.1648540559,"ml-security":0.1308763215}}
{"text":"The same principle is used for both MAC and A-to-D conversion ensuring high linearity and thus supporting large number of analog MAC accumulations.","meta":{"url":"http://arxiv.org/abs/2307.05944v1"},"cats":{"new-dataset":0.0477376292,"dev-research":0.43006467,"prompt-eng":0.4247266289,"data-quality":0.1343248466,"ml-security":0.169988437}}
{"text":"The memory cell-embedded ADC eliminates the use of separate ADCs and enhances energy and area efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05944v1"},"cats":{"new-dataset":0.0367044297,"dev-research":0.4350334115,"prompt-eng":0.3976861,"data-quality":0.1091461753,"ml-security":0.1158242829}}
{"text":"Additionally, two signal margin enhancement techniques, namely the MAC-folding and boosted-clipping schemes, are proposed to further improve the CIM computation accuracy.","meta":{"url":"http://arxiv.org/abs/2307.05944v1"},"cats":{"new-dataset":0.1054973849,"dev-research":0.3701226808,"prompt-eng":0.4148362359,"data-quality":0.1535200716,"ml-security":0.0882886772}}
{"text":"Although domestic service robots are expected to assist individuals who require support, they cannot currently interact smoothly with people through natural language.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.10911895,"dev-research":0.4169978198,"prompt-eng":0.507582964,"data-quality":0.2043894902,"ml-security":0.1548768034}}
{"text":"For example, given the instruction \"Bring me a bottle from the kitchen,\" it is difficult for such robots to specify the bottle in an indoor environment.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.0848966182,"dev-research":0.4287478194,"prompt-eng":0.4774602801,"data-quality":0.1480186069,"ml-security":0.1567170048}}
{"text":"Most conventional models have been trained on real-world datasets that are labor-intensive to collect, and they have not fully leveraged simulation data through a transfer learning framework.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.4113495295,"dev-research":0.348296137,"prompt-eng":0.4545446118,"data-quality":0.0996581089,"ml-security":0.2472471801}}
{"text":"In this study, we propose a novel transfer learning approach for multimodal language understanding called Prototypical Contrastive Transfer Learning (PCTL), which uses a new contrastive loss called Dual ProtoNCE.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.1928475615,"dev-research":0.3929069726,"prompt-eng":0.498398141,"data-quality":0.1554553865,"ml-security":0.0830929973}}
{"text":"We introduce PCTL to the task of identifying target objects in domestic environments according to free-form natural language instructions.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.2871650115,"dev-research":0.5156654015,"prompt-eng":0.5451859022,"data-quality":0.2321096995,"ml-security":0.2004790169}}
{"text":"To validate PCTL, we built new real-world and simulation datasets.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.5144518837,"dev-research":0.4059804785,"prompt-eng":0.4337794932,"data-quality":0.1055506926,"ml-security":0.153349098}}
{"text":"Our experiment demonstrated that PCTL outperformed existing methods.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.0963380608,"dev-research":0.4319345356,"prompt-eng":0.391293519,"data-quality":0.1175251289,"ml-security":0.138846653}}
{"text":"Specifically, PCTL achieved an accuracy of 78.1%, whereas simple fine-tuning achieved an accuracy of 73.4%.","meta":{"url":"http://arxiv.org/abs/2307.05942v1"},"cats":{"new-dataset":0.0956451693,"dev-research":0.411507317,"prompt-eng":0.4177062017,"data-quality":0.1980520784,"ml-security":0.0514908825}}
{"text":"Prescriptive business process monitoring provides decision support to process managers on when and how to adapt an ongoing business process to prevent or mitigate an undesired process outcome.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.06043457,"dev-research":0.4555328125,"prompt-eng":0.4951323688,"data-quality":0.0774902499,"ml-security":0.0977683902}}
{"text":"We focus on the problem of automatically reconciling the trade-off between prediction accuracy and prediction earliness in determining when to adapt.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0806007687,"dev-research":0.4574145694,"prompt-eng":0.5373961539,"data-quality":0.2979995629,"ml-security":0.2334452264}}
{"text":"Adaptations should happen sufficiently early to provide enough lead time for the adaptation to become effective.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.030515413,"dev-research":0.4544129721,"prompt-eng":0.4257350194,"data-quality":0.0912145171,"ml-security":0.154025307}}
{"text":"However, earlier predictions are typically less accurate than later predictions.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0605753214,"dev-research":0.4392147217,"prompt-eng":0.4350087783,"data-quality":0.1740596084,"ml-security":0.1591644049}}
{"text":"This means that acting on less accurate predictions may lead to unnecessary adaptations or missed adaptations.   ","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0415884165,"dev-research":0.4673552308,"prompt-eng":0.4131177037,"data-quality":0.1714884145,"ml-security":0.1586011202}}
{"text":"Different approaches were presented in the literature to reconcile the trade-off between prediction accuracy and earliness.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0693639058,"dev-research":0.4352117853,"prompt-eng":0.4281649142,"data-quality":0.2373645528,"ml-security":0.1240203666}}
{"text":"So far, these approaches were compared with different baselines, and evaluated using different data sets or even confidential data sets.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.2582356944,"dev-research":0.421836912,"prompt-eng":0.4207767573,"data-quality":0.1002655785,"ml-security":0.1184114285}}
{"text":"This limits the comparability and replicability of the approaches and makes it difficult to choose a concrete approach in practice.   ","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0296998822,"dev-research":0.4359103606,"prompt-eng":0.3630472554,"data-quality":0.054557723,"ml-security":0.1950352603}}
{"text":"We perform a comparative evaluation of the main alternative approaches for reconciling the trade-off between prediction accuracy and earliness.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.0817746762,"dev-research":0.4300876337,"prompt-eng":0.4600263794,"data-quality":0.2807553411,"ml-security":0.1301650628}}
{"text":"Using four public real-world event log data sets and two types of prediction models, we assess and compare the cost savings of these approaches.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.2754814904,"dev-research":0.3957981229,"prompt-eng":0.4393299443,"data-quality":0.0742953751,"ml-security":0.1638108516}}
{"text":"The experimental results indicate which criteria affect the effectiveness of an approach and help us state initial recommendations for the selection of a concrete approach in practice.","meta":{"url":"http://arxiv.org/abs/2307.05939v1"},"cats":{"new-dataset":0.04712378,"dev-research":0.4656665119,"prompt-eng":0.4150559934,"data-quality":0.0927604331,"ml-security":0.0713463579}}
{"text":"We present ${\\bf decalf}$, a ${\\bf d}$irected, ${\\bf e}$ffectful ${\\bf c}$ost-${\\bf a}$ware ${\\bf l}$ogical ${\\bf f}$ramework for studying quantitative aspects of functional programs with effects.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0477525241,"dev-research":0.4791435598,"prompt-eng":0.4338846152,"data-quality":0.0903076149,"ml-security":0.1481286513}}
{"text":"Like ${\\bf calf}$, the language is based on a formal phase distinction between the extension and the intension of a program, its pure behavior as distinct from its cost measured by an effectful step-counting primitive.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0517472026,"dev-research":0.4899816184,"prompt-eng":0.4361590637,"data-quality":0.105544681,"ml-security":0.0922458895}}
{"text":"The type theory ensures that the behavior is unaffected by the cost accounting.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0391096522,"dev-research":0.4530185018,"prompt-eng":0.3677176987,"data-quality":0.0958727329,"ml-security":0.1852686257}}
{"text":"Unlike ${\\bf calf}$, the present language takes account of effects, such as probabilistic choice and mutable state; this extension requires a reformulation of ${\\bf calf}$'s approach to cost accounting: rather than rely on a \"separable\" notion of cost, here a cost bound is simply another program.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0730555624,"dev-research":0.4593778328,"prompt-eng":0.396298233,"data-quality":0.0945044693,"ml-security":0.1191542632}}
{"text":"To make this formal, we equip every type with an intrinsic preorder, relaxing the precise cost accounting intrinsic to a program to a looser","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0410588838,"dev-research":0.5009813072,"prompt-eng":0.4701366771,"data-quality":0.1016781862,"ml-security":0.1342771838}}
{"text":"but nevertheless informative estimate.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.155628613,"dev-research":0.4333726492,"prompt-eng":0.413245262,"data-quality":0.1779903197,"ml-security":0.1197288284}}
{"text":"For example, the cost bound of a probabilistic program is itself a probabilistic program that specifies the distribution of costs.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.105495718,"dev-research":0.4593171429,"prompt-eng":0.4181714724,"data-quality":0.1226646003,"ml-security":0.2264530352}}
{"text":"This approach serves as a streamlined alternative to the standard method of isolating a recurrence that bounds the cost in a manner that readily extends to higher-order, effectful programs.   ","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0327912966,"dev-research":0.499654214,"prompt-eng":0.3703300611,"data-quality":0.0568236222,"ml-security":0.2267614083}}
{"text":"The development proceeds by first introducing the ${\\bf decalf}$ type system, which is based on an intrinsic ordering among terms that restricts in the extensional phase to extensional equality, but in the intensional phase reflects an approximation of the cost of a program of interest.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0340152482,"dev-research":0.4836895272,"prompt-eng":0.3860376724,"data-quality":0.0503663481,"ml-security":0.1280893052}}
{"text":"This formulation is then applied to a number of illustrative examples, including pure and effectful sorting algorithms, simple probabilistic programs, and higher-order functions.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.0712777597,"dev-research":0.4402320141,"prompt-eng":0.3885300515,"data-quality":0.1052854288,"ml-security":0.1338234624}}
{"text":"Finally, we justify ${\\bf decalf}$ via a model in the topos of augmented simplicial sets.","meta":{"url":"http://arxiv.org/abs/2307.05938v1"},"cats":{"new-dataset":0.1197070582,"dev-research":0.410452435,"prompt-eng":0.4305377068,"data-quality":0.1166909742,"ml-security":0.1151289942}}
{"text":"Programmable data planes offer precise control over the low-level processing steps applied to network packets, serving as a valuable tool for analysing malicious flows in the field of intrusion detection.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.1433667581,"dev-research":0.4673883605,"prompt-eng":0.4149266668,"data-quality":0.1015885748,"ml-security":0.5782113423}}
{"text":"Albeit with limitations on physical resources and capabilities, they allow for the efficient extraction of detailed traffic information, which can then be utilised by Machine Learning (ML) algorithms responsible for identifying security threats.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.115448075,"dev-research":0.4042550467,"prompt-eng":0.4176228738,"data-quality":0.1257994642,"ml-security":0.7048860414}}
{"text":"In addressing resource constraints, existing solutions in the literature rely on compressing network data through the collection of statistical traffic features in the data plane.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.2255556054,"dev-research":0.3937862133,"prompt-eng":0.3686999149,"data-quality":0.1224367669,"ml-security":0.2764824409}}
{"text":"While this compression saves memory resources in switches and minimises the burden on the control channel between the data and the control plane, it also results in a loss of information available to the Network Intrusion Detection System (NIDS), limiting access to packet payload, categorical features, and the semantic understanding of network communications, such as the behaviour of packets within traffic flows.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.0886229213,"dev-research":0.4643223209,"prompt-eng":0.4005799639,"data-quality":0.1709490634,"ml-security":0.4543654563}}
{"text":"This paper proposes P4DDLe, a framework that exploits the flexibility of P4-based programmable data planes for packet-level feature extraction and pre-processing.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.287678082,"dev-research":0.4654160325,"prompt-eng":0.4325998397,"data-quality":0.1050403997,"ml-security":0.1457511988}}
{"text":"P4DDLe leverages the programmable data plane to extract raw packet features from the network traffic, categorical features included, and to organise them in a way that the semantics of traffic flows is preserved.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.2207006674,"dev-research":0.4780891162,"prompt-eng":0.4146115916,"data-quality":0.0862009347,"ml-security":0.1753588577}}
{"text":"To minimise memory and control channel overheads, P4DDLe selectively processes and filters packet-level data, so that all and only the relevant features required by the NIDS are collected.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.0732049594,"dev-research":0.4365851113,"prompt-eng":0.406900645,"data-quality":0.0704836116,"ml-security":0.1187821406}}
{"text":"The experimental evaluation with recent Distributed Denial of Service (DDoS) attack data demonstrates that the proposed approach is very efficient in collecting compact and high-quality representations of network flows, ensuring precise detection of DDoS attacks.","meta":{"url":"http://arxiv.org/abs/2307.05936v1"},"cats":{"new-dataset":0.1285020975,"dev-research":0.4230260093,"prompt-eng":0.416568722,"data-quality":0.1585165269,"ml-security":0.4674369622}}
{"text":"Proximity sensing detects an object's presence without contact.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.0619414942,"dev-research":0.3875900711,"prompt-eng":0.3967821929,"data-quality":0.0749748431,"ml-security":0.1499870611}}
{"text":"However, research has rarely explored proximity sensing in granular materials (GM) due to GM's lack of visual and complex properties.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.0509146436,"dev-research":0.3856254398,"prompt-eng":0.3695430534,"data-quality":0.0662455824,"ml-security":0.0814803883}}
{"text":"In this paper, we propose a granular-material-embedded autonomous proximity sensing system (GRAINS) based on three granular phenomena (fluidization, jamming, and failure wedge zone).","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.0878181445,"dev-research":0.3909901363,"prompt-eng":0.4119550255,"data-quality":0.098285518,"ml-security":0.101378556}}
{"text":"GRAINS can automatically sense buried objects beneath GM in real-time manner (at least ~20 hertz) and perceive them 0.5 ~ 7 centimeters ahead in different granules without the use of vision or touch.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.1375512769,"dev-research":0.3696591241,"prompt-eng":0.4076251204,"data-quality":0.1039765252,"ml-security":0.0657731379}}
{"text":"We introduce a new spiral trajectory for the probe raking in GM, combining linear and circular motions, inspired by a common granular fluidization technique.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.076373894,"dev-research":0.3891163117,"prompt-eng":0.425239844,"data-quality":0.0715406663,"ml-security":0.0870947614}}
{"text":"Based on the observation of force-raising when granular jamming occurs in the failure wedge zone in front of the probe during its raking, we employ Gaussian process regression to constantly learn and predict the force patterns and detect the force anomaly resulting from granular jamming to identify the proximity sensing of buried objects.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.0888845343,"dev-research":0.3816158109,"prompt-eng":0.450935458,"data-quality":0.1379246236,"ml-security":0.1768425054}}
{"text":"Finally, we apply GRAINS to a Bayesian-optimization-algorithm-guided exploration strategy to successfully localize underground objects and outline their distribution using proximity sensing without contact or digging.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.082581239,"dev-research":0.3767382367,"prompt-eng":0.4356648827,"data-quality":0.0933381264,"ml-security":0.1281842482}}
{"text":"This work offers a simple yet reliable method with potential for safe operation in building habitation infrastructure on an alien planet without human intervention.","meta":{"url":"http://arxiv.org/abs/2307.05935v1"},"cats":{"new-dataset":0.1518337087,"dev-research":0.4220732177,"prompt-eng":0.4129536891,"data-quality":0.1315752632,"ml-security":0.2030698438}}
{"text":"CLIPStyler demonstrated image style transfer with realistic textures using only a style text description (instead of requiring a reference style image).","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.1956089957,"dev-research":0.408188066,"prompt-eng":0.4911883881,"data-quality":0.2179765957,"ml-security":0.0687123579}}
{"text":"However, the ground semantics of objects in the style transfer output is lost due to style spill-over on salient and background objects (content mismatch) or over-stylization.","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.0652844297,"dev-research":0.4549936113,"prompt-eng":0.4671596689,"data-quality":0.3543050284,"ml-security":0.100637018}}
{"text":"To solve this, we propose Semantic CLIPStyler (Sem-CS), that performs semantic style transfer.","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.1141765371,"dev-research":0.4576754522,"prompt-eng":0.5267420438,"data-quality":0.2609985508,"ml-security":0.0712347567}}
{"text":"Sem-CS first segments the content image into salient and non-salient objects and then transfers artistic style based on a given style text description.","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.2064706352,"dev-research":0.4275918296,"prompt-eng":0.499109773,"data-quality":0.1633171321,"ml-security":0.0476608425}}
{"text":"The semantic style transfer is achieved using global foreground loss (for salient objects) and global background loss (for non-salient objects).","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.109953111,"dev-research":0.4208808543,"prompt-eng":0.4777493896,"data-quality":0.2232251663,"ml-security":0.0677310378}}
{"text":"Our empirical results, including DISTS, NIMA and user study scores, show that our proposed framework yields superior qualitative and quantitative performance.","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.2529849918,"dev-research":0.4546811492,"prompt-eng":0.4530026968,"data-quality":0.1128794964,"ml-security":0.1244456561}}
{"text":"Our code is available at github.com/chandagrover/sem-cs.","meta":{"url":"http://arxiv.org/abs/2307.05934v1"},"cats":{"new-dataset":0.3712961467,"dev-research":0.4814959795,"prompt-eng":0.5040915244,"data-quality":0.1136755451,"ml-security":0.0910936575}}
{"text":"Human bimanual manipulation can perform more complex tasks than a simple combination of two single arms, which is credited to the spatio-temporal coordination between the arms.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.0360778685,"dev-research":0.4129667844,"prompt-eng":0.3870611005,"data-quality":0.0415609358,"ml-security":0.0482351978}}
{"text":"However, the description of bimanual coordination is still an open topic in robotics.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.0706292216,"dev-research":0.4105842632,"prompt-eng":0.3965025312,"data-quality":0.0676491556,"ml-security":0.0428581751}}
{"text":"This makes it difficult to give an explainable coordination paradigm, let alone applied to robotics.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.0231969203,"dev-research":0.4462987093,"prompt-eng":0.3864112136,"data-quality":0.0743788684,"ml-security":0.1080422869}}
{"text":"In this work, we divide the main bimanual tasks in human daily activities into two types: leader-follower and synergistic coordination.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.1665263677,"dev-research":0.4049271542,"prompt-eng":0.4057976143,"data-quality":0.0387190222,"ml-security":0.0401622651}}
{"text":"Then we propose a relative parameterization method to learn these types of coordination from human demonstration.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.1083023552,"dev-research":0.431492609,"prompt-eng":0.4943976058,"data-quality":0.0664899797,"ml-security":0.0985834802}}
{"text":"It represents coordination as Gaussian mixture models from bimanual demonstration to describe the change in the importance of coordination throughout the motions by probability.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.0979662083,"dev-research":0.4116440647,"prompt-eng":0.4337987618,"data-quality":0.0622792017,"ml-security":0.054716715}}
{"text":"The learned coordinated representation can be generalized to new task parameters while ensuring spatio-temporal coordination.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.142133412,"dev-research":0.423951816,"prompt-eng":0.4640056736,"data-quality":0.0717369441,"ml-security":0.101107161}}
{"text":"We demonstrate the method using synthetic motions and human demonstration data and deploy it to a humanoid robot to perform a generalized bimanual coordination motion.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.2018325021,"dev-research":0.3664659232,"prompt-eng":0.4523244976,"data-quality":0.0445605256,"ml-security":0.0601990307}}
{"text":"We believe that this easy-to-use bimanual learning from demonstration (LfD) method has the potential to be used as a data augmentation plugin for robot large manipulation model training.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.1892506857,"dev-research":0.3916375238,"prompt-eng":0.5164662597,"data-quality":0.0857793993,"ml-security":0.0759432932}}
{"text":"The corresponding codes are open-sourced in https://github.com/Skylark0924/Rofunc.","meta":{"url":"http://arxiv.org/abs/2307.05933v1"},"cats":{"new-dataset":0.5515171969,"dev-research":0.4533097495,"prompt-eng":0.449719817,"data-quality":0.1240103495,"ml-security":0.127989869}}
{"text":"Aphids are one of the main threats to crops, rural families, and global food security.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.1895747201,"dev-research":0.4462793817,"prompt-eng":0.3807011348,"data-quality":0.1504501725,"ml-security":0.4687007145}}
{"text":"Chemical pest control is a necessary component of crop production for maximizing yields, however, it is unnecessary to apply the chemical approaches to the entire fields in consideration of the environmental pollution and the cost.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.0634387145,"dev-research":0.4683600153,"prompt-eng":0.4124514541,"data-quality":0.1018423426,"ml-security":0.1973371287}}
{"text":"Thus, accurately localizing the aphid and estimating the infestation level is crucial to the precise local application of pesticides.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.0987448741,"dev-research":0.4797658292,"prompt-eng":0.4243718036,"data-quality":0.2572512717,"ml-security":0.2420010355}}
{"text":"Aphid detection is very challenging as each individual aphid is really small and all aphids are crowded together as clusters.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.1041259486,"dev-research":0.4055129797,"prompt-eng":0.4008079836,"data-quality":0.2027039505,"ml-security":0.2274845508}}
{"text":"In this paper, we propose to estimate the infection level by detecting aphid clusters.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.2146587062,"dev-research":0.4318159634,"prompt-eng":0.4233565709,"data-quality":0.1861582723,"ml-security":0.2418364863}}
{"text":"We have taken millions of images in the sorghum fields, manually selected 5,447 images that contain aphids, and annotated each aphid cluster in the image.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.416236043,"dev-research":0.4089598092,"prompt-eng":0.433772053,"data-quality":0.242417688,"ml-security":0.1271405849}}
{"text":"To use these images for machine learning models, we crop the images into patches and created a labeled dataset with over 151,000 image patches.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.6570176924,"dev-research":0.4225478061,"prompt-eng":0.4792265601,"data-quality":0.2543409903,"ml-security":0.2209658631}}
{"text":"Then, we implement and compare the performance of four state-of-the-art object detection models.","meta":{"url":"http://arxiv.org/abs/2307.05929v1"},"cats":{"new-dataset":0.1183367148,"dev-research":0.3556715154,"prompt-eng":0.4321520399,"data-quality":0.1583148687,"ml-security":0.1099295699}}
{"text":"Building energy prediction and management has become increasingly important in recent decades, driven by the growth of Internet of Things (IoT) devices and the availability of more energy data.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.2707234646,"dev-research":0.4114061097,"prompt-eng":0.4519699771,"data-quality":0.0556597368,"ml-security":0.1356863654}}
{"text":"However, energy data is often collected from multiple sources and can be incomplete or inconsistent, which can hinder accurate predictions and management of energy systems and limit the usefulness of the data for decision-making and research.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.2219085038,"dev-research":0.3998451562,"prompt-eng":0.4118540229,"data-quality":0.2749616218,"ml-security":0.1480269813}}
{"text":"To address this issue, past studies have focused on imputing missing gaps in energy data, including random and continuous gaps.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1292875722,"dev-research":0.3731998006,"prompt-eng":0.4026957413,"data-quality":0.1565687585,"ml-security":0.0634896254}}
{"text":"One of the main challenges in this area is the lack of validation on a benchmark dataset with various building and meter types, making it difficult to accurately evaluate the performance of different imputation methods.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1929811777,"dev-research":0.3626393823,"prompt-eng":0.4053998954,"data-quality":0.2758449795,"ml-security":0.1678297087}}
{"text":"Another challenge is the lack of application of state-of-the-art imputation methods for missing gaps in energy data.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1902861667,"dev-research":0.3750256536,"prompt-eng":0.3904697529,"data-quality":0.224811751,"ml-security":0.0896877584}}
{"text":"Contemporary image-inpainting methods, such as Partial Convolution (PConv), have been widely used in the computer vision domain and have demonstrated their effectiveness in dealing with complex missing patterns.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1061242233,"dev-research":0.3776183589,"prompt-eng":0.3585144388,"data-quality":0.2041827001,"ml-security":0.0627237172}}
{"text":"To study whether energy data imputation can benefit from the image-based deep learning method, this study compared PConv, Convolutional neural networks (CNNs), and weekly persistence method using one of the biggest publicly available whole building energy datasets, consisting of 1479 power meters worldwide, as the benchmark.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.3412837901,"dev-research":0.3621526207,"prompt-eng":0.4145348195,"data-quality":0.2056209207,"ml-security":0.1815412408}}
{"text":"The results show that, compared to the CNN with the raw time series (1D-CNN) and the weekly persistence method, neural network models with reshaped energy data with two dimensions reduced the Mean Squared Error (MSE) by 10% to 30%.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1337675248,"dev-research":0.3519422453,"prompt-eng":0.402389526,"data-quality":0.1392217687,"ml-security":0.1304935013}}
{"text":"The advanced deep learning method, Partial convolution (PConv), has further reduced the MSE by 20-30% than 2D-CNN and stands out among all models.","meta":{"url":"http://arxiv.org/abs/2307.05926v1"},"cats":{"new-dataset":0.1174016314,"dev-research":0.385241906,"prompt-eng":0.4272248076,"data-quality":0.1139166528,"ml-security":0.1540594569}}
{"text":"The recently introduced independent fluctuating two-ray (IFTR) fading model, consisting of two specular components fluctuating independently plus a diffuse component, has proven to provide an excellent fit to different wireless environments, including the millimeter-wave band.","meta":{"url":"http://arxiv.org/abs/2307.05925v1"},"cats":{"new-dataset":0.0517989819,"dev-research":0.3882253669,"prompt-eng":0.4472596746,"data-quality":0.099570617,"ml-security":0.0906483199}}
{"text":"However, the original formulations of the probability density function (PDF) and cumulative distribution function (CDF) of this model are not applicable to all possible values of its defining parameters, and are given in terms of multifold generalized hypergeometric functions, which prevents their widespread use for the derivation of performance metric expressions.","meta":{"url":"http://arxiv.org/abs/2307.05925v1"},"cats":{"new-dataset":0.0728488191,"dev-research":0.390194668,"prompt-eng":0.4086918717,"data-quality":0.1170370932,"ml-security":0.0800435772}}
{"text":"In this paper we present a new formulation of the IFTR model as a countable mixture of Gamma distributions which greatly facilitates the performance evaluation for this model in terms of the metrics already known for the much simpler and widely used Nakagami-m fading.","meta":{"url":"http://arxiv.org/abs/2307.05925v1"},"cats":{"new-dataset":0.1045159344,"dev-research":0.3661482867,"prompt-eng":0.4932052703,"data-quality":0.1272852443,"ml-security":0.0656916917}}
{"text":"Additionally, a closed-form expression is presented for the generalized moment generating function (GMGF), which permits to readily obtain all the moments of the distribution of the model, as well as several relevant performance metrics.","meta":{"url":"http://arxiv.org/abs/2307.05925v1"},"cats":{"new-dataset":0.085772768,"dev-research":0.3789848025,"prompt-eng":0.4651014105,"data-quality":0.0713807137,"ml-security":0.0966638466}}
{"text":"Based on these new derivations, the IFTR model is evaluated for the average channel capacity, the outage probability with and without co-channel interference, and the bit error rate (BER), which are verified by Monte Carlo simulations.","meta":{"url":"http://arxiv.org/abs/2307.05925v1"},"cats":{"new-dataset":0.0637356812,"dev-research":0.4071443853,"prompt-eng":0.4601778487,"data-quality":0.1574553734,"ml-security":0.1148127835}}
{"text":"The upcoming Sixth Generation (6G) mobile communications system envisions supporting a variety of use cases with differing characteristics, e.g., very low to extremely high data rates, diverse latency needs, ultra massive connectivity, sustainable communications, ultra-wide coverage etc.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.1697554421,"dev-research":0.4083131103,"prompt-eng":0.4111685524,"data-quality":0.0707337757,"ml-security":0.1089667422}}
{"text":"To accommodate these diverse use cases, the 6G system architecture needs to be scalable, modular, and flexible; both in its user plane and the control plane.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0692586537,"dev-research":0.3928534841,"prompt-eng":0.3981510895,"data-quality":0.0491880345,"ml-security":0.0868689955}}
{"text":"In this paper, we identify some limitations of the existing Fifth Generation System (5GS) architecture, especially that of its control plane.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0868950107,"dev-research":0.4175090851,"prompt-eng":0.3876294826,"data-quality":0.0546285527,"ml-security":0.1034861579}}
{"text":"Further, we propose a novel architecture for the 6G System (6GS) employing Software Defined Networking (SDN) technology to address these limitations of the control plane.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.1231582967,"dev-research":0.4222834748,"prompt-eng":0.370931711,"data-quality":0.0795427236,"ml-security":0.1207878177}}
{"text":"The control plane in existing 5GS supports two different categories of functionalities handling end user signalling (e.g., user registration, authentication) and control of user plane functions.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0641812459,"dev-research":0.4399982101,"prompt-eng":0.4632705267,"data-quality":0.0531584702,"ml-security":0.1544049231}}
{"text":"We propose to move the end-user signalling functionality out of the mobile network control plane and treat it as user service, i.e., as payload or data.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.1260872123,"dev-research":0.4576850831,"prompt-eng":0.4711199626,"data-quality":0.1015386014,"ml-security":0.2424849493}}
{"text":"This proposal results in an evolved service-driven architecture for mobile networks bringing increased simplicity, modularity, scalability, flexibility and security to its control plane.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0850854949,"dev-research":0.4287978099,"prompt-eng":0.398151302,"data-quality":0.0772279486,"ml-security":0.3202652247}}
{"text":"The proposed architecture can also support service specific signalling support, if needed, making it better suited for diverse 6GS use cases.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0662745983,"dev-research":0.41081793,"prompt-eng":0.4241827349,"data-quality":0.0650282925,"ml-security":0.1044930889}}
{"text":"To demonstrate the advantages of the proposed architecture, we also compare its performance with the 5GS using a process algebra-based simulation tool.","meta":{"url":"http://arxiv.org/abs/2307.05924v1"},"cats":{"new-dataset":0.0627364903,"dev-research":0.3991099968,"prompt-eng":0.405004999,"data-quality":0.0433620859,"ml-security":0.0532699716}}
{"text":"Pairs-trading is a trading strategy that involves matching a long position with a short position in two stocks aiming at market-neutral profits.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.0959807023,"dev-research":0.3981078666,"prompt-eng":0.3530307434,"data-quality":0.0680489222,"ml-security":0.1196599231}}
{"text":"While a typical pairs-trading system monitors the prices of two statistically correlated stocks for detecting a temporary divergence, monitoring and analyzing the prices of more stocks would potentially lead to finding more trading opportunities.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.0719626015,"dev-research":0.4036254504,"prompt-eng":0.409052829,"data-quality":0.0877732439,"ml-security":0.1180182918}}
{"text":"Here we report a stock pairs-trading system that finds trading opportunities for any two stocks in an $N$-stock universe using a combinatorial optimization accelerator based on a quantum-inspired algorithm called simulated bifurcation.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.1335985483,"dev-research":0.3667838786,"prompt-eng":0.3698893377,"data-quality":0.0512584505,"ml-security":0.0925781536}}
{"text":"The trading opportunities are detected through solving an optimal path search problem in an $N$-node directed graph with edge weights corresponding to the products of instantaneous price differences and statistical correlation factors between two stocks.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.0559508465,"dev-research":0.3907921966,"prompt-eng":0.3679832858,"data-quality":0.0677547863,"ml-security":0.1005666897}}
{"text":"The accelerator is one of Ising machines and operates consecutively to find multiple opportunities in a market situation with avoiding duplicate detections by a tabu search technique.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.0842482001,"dev-research":0.4108923491,"prompt-eng":0.4295739181,"data-quality":0.0903297794,"ml-security":0.0991082241}}
{"text":"It has been demonstrated in the Tokyo Stock Exchange that the FPGA (field-programmable gate array)-based trading system has a sufficiently low latency (33 $\\mu$s for $N$=15 or 210 pairs) to execute the pairs-trading strategy based on optimal path search in market graphs.","meta":{"url":"http://arxiv.org/abs/2307.05923v1"},"cats":{"new-dataset":0.1261372758,"dev-research":0.3698146693,"prompt-eng":0.379554386,"data-quality":0.046311869,"ml-security":0.1123807261}}
{"text":"This paper studies the message complexity of authenticated Byzantine agreement (BA) in synchronous, fully-connected distributed networks under an honest majority.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.0717152767,"dev-research":0.3928210119,"prompt-eng":0.3733414035,"data-quality":0.1428097785,"ml-security":0.190897568}}
{"text":"We focus on the so-called {\\em implicit} Byzantine agreement problem where each node starts with an input value and at the end a non-empty subset of the honest nodes should agree on a common input value by satisfying the BA properties (i.e., there can be undecided nodes).","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.0588027875,"dev-research":0.4102642577,"prompt-eng":0.4067340421,"data-quality":0.2174938961,"ml-security":0.2382109436}}
{"text":"We show that a sublinear (in $n$, number of nodes) message complexity BA protocol under honest majority is possible in the standard PKI model when the nodes have access to an unbiased global coin and hash function.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.1020192196,"dev-research":0.4080833487,"prompt-eng":0.3957816976,"data-quality":0.102083088,"ml-security":0.251887219}}
{"text":"In particular, we present a randomized Byzantine agreement algorithm which, with high probability achieves implicit agreement, uses $\\tilde{O}(\\sqrt{n})$ messages, and runs in $\\tilde{O}(1)$ rounds while tolerating $(1/2 - \\epsilon)n$ Byzantine nodes for any fixed $\\epsilon > 0$, the notation $\\Tilde{O}$ hides a $O(\\polylog{n})$ factor.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.0732951311,"dev-research":0.4071791392,"prompt-eng":0.3968259574,"data-quality":0.2350777562,"ml-security":0.2612049077}}
{"text":"The algorithm requires standard cryptographic setup PKI and hash function with a static Byzantine adversary.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.0860761926,"dev-research":0.3856409516,"prompt-eng":0.3693741471,"data-quality":0.0824920422,"ml-security":0.2901594478}}
{"text":"The algorithm works in the CONGEST model and each node does not need to know the identity of its neighbors, i.e., works in the $KT_0$ model.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.078598282,"dev-research":0.3743728,"prompt-eng":0.3668185343,"data-quality":0.1503734372,"ml-security":0.1175140367}}
{"text":"The message complexity (and also the time complexity) of our algorithm is optimal up to a $\\polylog n$ factor, as we show a $\\Omega(\\sqrt{n})$ lower bound on the message complexity.","meta":{"url":"http://arxiv.org/abs/2307.05922v1"},"cats":{"new-dataset":0.0960692623,"dev-research":0.4050307588,"prompt-eng":0.3518975926,"data-quality":0.1009839476,"ml-security":0.1958054187}}
{"text":"Automated radiology report generation aims to generate radiology reports that contain rich, fine-grained descriptions of radiology imaging.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.3119721665,"dev-research":0.4502254416,"prompt-eng":0.538576481,"data-quality":0.2457878057,"ml-security":0.0518014429}}
{"text":"Compared with image captioning in the natural image domain, medical images are very similar to each other, with only minor differences in the occurrence of diseases.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.2129211165,"dev-research":0.4102525098,"prompt-eng":0.4612461616,"data-quality":0.1904721999,"ml-security":0.0851707112}}
{"text":"Given the importance of these minor differences in the radiology report, it is crucial to encourage the model to focus more on the subtle regions of disease occurrence.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.0948912767,"dev-research":0.4243330838,"prompt-eng":0.4498732345,"data-quality":0.145507405,"ml-security":0.0624355848}}
{"text":"Secondly, the problem of visual and textual data biases is serious.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.1889402715,"dev-research":0.4526324717,"prompt-eng":0.4211639931,"data-quality":0.338285436,"ml-security":0.1905650223}}
{"text":"Not only do normal cases make up the majority of the dataset, but sentences describing areas with pathological changes also constitute only a small part of the paragraph.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.1625655172,"dev-research":0.4179709087,"prompt-eng":0.4151340664,"data-quality":0.2509580614,"ml-security":0.1435920481}}
{"text":"Lastly, generating medical image reports involves the challenge of long text generation, which requires more expertise and empirical training in medical knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.3313373317,"dev-research":0.4540570458,"prompt-eng":0.485115114,"data-quality":0.1557407907,"ml-security":0.0822665002}}
{"text":"As a result, the difficulty of generating such reports is increased.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.1752333552,"dev-research":0.498896097,"prompt-eng":0.4532020009,"data-quality":0.2017028556,"ml-security":0.101596481}}
{"text":"To address these challenges, we propose a disease-oriented retrieval framework that utilizes similar reports as prior knowledge references.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.4585491667,"dev-research":0.4380030568,"prompt-eng":0.4998938223,"data-quality":0.1769495315,"ml-security":0.100398414}}
{"text":"We design a factual consistency captioning generator to generate more accurate and factually consistent disease descriptions.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.3531101541,"dev-research":0.4768978714,"prompt-eng":0.5682143078,"data-quality":0.465944237,"ml-security":0.0821809964}}
{"text":"Our framework can find most similar reports for a given disease from the CXR database by retrieving a disease-oriented mask consisting of the position and morphological characteristics.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.3706256803,"dev-research":0.4126782778,"prompt-eng":0.4456221272,"data-quality":0.1787632122,"ml-security":0.1128811584}}
{"text":"By referencing the disease-oriented similar report and the visual features, the factual consistency model can generate a more accurate radiology report.","meta":{"url":"http://arxiv.org/abs/2307.05921v1"},"cats":{"new-dataset":0.2142971956,"dev-research":0.4302244184,"prompt-eng":0.470697055,"data-quality":0.3187719614,"ml-security":0.0452007679}}
{"text":"The widespread use of graph data in various applications and the highly dynamic nature of today's networks have made it imperative to analyze structural trends in dynamic graphs on a continual basis.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.2224553474,"dev-research":0.4081450714,"prompt-eng":0.3742111772,"data-quality":0.0950509682,"ml-security":0.1618509484}}
{"text":"The shortest path is a fundamental concept in graph analysis and recent research shows that counting the number of shortest paths between two vertices is crucial in applications like potential friend recommendation and betweenness analysis.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.1075393658,"dev-research":0.4322178657,"prompt-eng":0.3616215371,"data-quality":0.0874488996,"ml-security":0.0967540636}}
{"text":"However, current studies that use hub labeling techniques for real-time shortest path counting are limited by their reliance on a pre-computed index, which cannot tackle frequent updates over dynamic graphs.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.1244430464,"dev-research":0.392260994,"prompt-eng":0.3641609194,"data-quality":0.1533560592,"ml-security":0.0757448871}}
{"text":"To address this, we propose a novel approach for maintaining the index in response to changes in the graph structure and develop incremental (IncSPC) and decremental (DecSPC) update algorithms for inserting and deleting vertices/edges, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.0915211368,"dev-research":0.4390401294,"prompt-eng":0.3548581982,"data-quality":0.1204407866,"ml-security":0.0885702165}}
{"text":"The main idea of these two algorithms is that we only locate the affected vertices to update the index.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.0374349602,"dev-research":0.4278698826,"prompt-eng":0.3085114835,"data-quality":0.1045162623,"ml-security":0.1229027008}}
{"text":"Our experiments demonstrate that our dynamic algorithms are up to four orders of magnitude faster processing for incremental updates and up to three orders of magnitude faster processing for hybrid updates than reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.05918v1"},"cats":{"new-dataset":0.1571714761,"dev-research":0.4053528388,"prompt-eng":0.3749876731,"data-quality":0.0894214395,"ml-security":0.1301469244}}
{"text":"The modeling of spatiotemporal brain dynamics from high-dimensional data, such as 4D functional MRI, is a formidable task in neuroscience.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.1248974853,"dev-research":0.352188446,"prompt-eng":0.4008460616,"data-quality":0.0451245777,"ml-security":0.071630071}}
{"text":"To address this challenge, we present SwiFT (Swin 4D fMRI Transformer), a Swin Transformer architecture that can learn brain dynamics directly from 4D functional brain MRI data in a memory and computation-efficient manner.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.2684442585,"dev-research":0.3567831374,"prompt-eng":0.4231669911,"data-quality":0.0781142534,"ml-security":0.1102834421}}
{"text":"SwiFT achieves this by implementing a 4D window multi-head self-attention mechanism and absolute positional embeddings.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.1541987896,"dev-research":0.4113946985,"prompt-eng":0.4979141392,"data-quality":0.1223335202,"ml-security":0.0879861108}}
{"text":"We evaluate SwiFT using multiple largest-scale human functional brain imaging datasets in tasks such as predicting sex, age, and cognitive intelligence.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.4336732101,"dev-research":0.3750937084,"prompt-eng":0.4634310958,"data-quality":0.1580950607,"ml-security":0.1064599855}}
{"text":"Our experimental outcomes reveal that SwiFT consistently outperforms recent state-of-the-art models.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.2322779457,"dev-research":0.3984293104,"prompt-eng":0.4920816581,"data-quality":0.1922685509,"ml-security":0.2107120122}}
{"text":"To the best of our knowledge, SwiFT is the first Swin Transformer architecture that can process dimensional spatiotemporal brain functional data in an end-to-end fashion.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.2911633548,"dev-research":0.3743815937,"prompt-eng":0.4307430785,"data-quality":0.0588835911,"ml-security":0.1076846375}}
{"text":"Furthermore, due to the end-to-end learning capability, we also show that contrastive loss-based self-supervised pre-training of SwiFT is also feasible for achieving improved performance on a downstream task.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.2413240885,"dev-research":0.3852586629,"prompt-eng":0.5086494216,"data-quality":0.2076371347,"ml-security":0.1899525932}}
{"text":"We believe that our work holds substantial potential in facilitating scalable learning of functional brain imaging in neuroscience research by reducing the hurdles associated with applying Transformer models to high-dimensional fMRI.","meta":{"url":"http://arxiv.org/abs/2307.05916v1"},"cats":{"new-dataset":0.0729268257,"dev-research":0.3373352888,"prompt-eng":0.4210652065,"data-quality":0.0861863336,"ml-security":0.1180680397}}
{"text":"We present a framework - Prompt, Generate, Train (PGT) - to efficiently develop a generative question-answering model for open-book question-answering over a proprietary collection of text documents.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.3661840205,"dev-research":0.4590310621,"prompt-eng":0.5773090429,"data-quality":0.1010135719,"ml-security":0.1389545551}}
{"text":"The framework adapts a retriever augmented generation model to the target domain using supervised finetuning and reinforcement learning with synthetic feedback in a few-shot setting.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.1480079447,"dev-research":0.4385708536,"prompt-eng":0.5657497381,"data-quality":0.1280483698,"ml-security":0.1495520126}}
{"text":"This yields an aligned, uncertainty calibrated model that is competitive with GPT-4 based in-context retrieval augmented generation in generating relevant answers at lower serving costs.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.1960252263,"dev-research":0.4436394169,"prompt-eng":0.5342572878,"data-quality":0.1554117539,"ml-security":0.0484442073}}
{"text":"The synthetic generation pipeline generates high quality synthetic training data musing a medium sized LLM, Flan-T5 XXL, and a novel consistency filtering scheme.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.2702918964,"dev-research":0.3746973841,"prompt-eng":0.5102583526,"data-quality":0.1785300123,"ml-security":0.1226617967}}
{"text":"The pipeline is designed to generate both abstractive and extractive questions that span the entire corpus.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.1902431462,"dev-research":0.458927116,"prompt-eng":0.5271821529,"data-quality":0.2095452793,"ml-security":0.0794021714}}
{"text":"Using samples from this dataset, the framework fine-tunes a smaller RAG model comprising a dense retriever and a smaller sized LLM on samples from the dataset.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.3120279562,"dev-research":0.3836839521,"prompt-eng":0.4875349445,"data-quality":0.1300363372,"ml-security":0.1202359863}}
{"text":"In parallel, the framework trains a Reward model to score domain grounded answers higher than hallucinated answers.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.114640075,"dev-research":0.4674215988,"prompt-eng":0.484189105,"data-quality":0.0733589902,"ml-security":0.1014797521}}
{"text":"In the next phase, the framework aligns to the RAG model with the target domain using reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.0516619104,"dev-research":0.399004456,"prompt-eng":0.4595717491,"data-quality":0.0768881531,"ml-security":0.1338265776}}
{"text":"This step improves the RAG model's ability to generate grounded answers and ignore out of domain questions.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.0638414444,"dev-research":0.4843099484,"prompt-eng":0.5039007141,"data-quality":0.1325777332,"ml-security":0.1236180805}}
{"text":"In the final phase, the framework calibrates the model uncertainty for extractive question-answers.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.1242559306,"dev-research":0.4198616749,"prompt-eng":0.5102046657,"data-quality":0.2278170115,"ml-security":0.1204928302}}
{"text":"This is a desirable feature since the model can be integrated into a cascading system where the RAG model's answer is surfaced only when the model is confident of its answer.","meta":{"url":"http://arxiv.org/abs/2307.05915v1"},"cats":{"new-dataset":0.0441621104,"dev-research":0.4234202939,"prompt-eng":0.4884188841,"data-quality":0.1326884236,"ml-security":0.1043509949}}
{"text":"Floor labels of crowdsourced RF signals are crucial for many smart-city applications, such as multi-floor indoor localization, geofencing, and robot surveillance.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.2013162334,"dev-research":0.3891163483,"prompt-eng":0.4720684225,"data-quality":0.2389780987,"ml-security":0.2225950018}}
{"text":"To build a prediction model to identify the floor number of a new RF signal upon its measurement, conventional approaches using the crowdsourced RF signals assume that at least few labeled signal samples are available on each floor.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.2317939314,"dev-research":0.3959686925,"prompt-eng":0.4932474012,"data-quality":0.2396054726,"ml-security":0.1893474207}}
{"text":"In this work, we push the envelope further and demonstrate that it is technically feasible to enable such floor identification with only one floor-labeled signal sample on the bottom floor while having the rest of signal samples unlabeled.   ","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.1855449383,"dev-research":0.3526360839,"prompt-eng":0.4732346147,"data-quality":0.2806538102,"ml-security":0.1625828977}}
{"text":"We propose FIS-ONE, a novel floor identification system with only one labeled sample.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.284430415,"dev-research":0.3416282545,"prompt-eng":0.452944502,"data-quality":0.2581557585,"ml-security":0.1059961198}}
{"text":"FIS-ONE consists of two steps, namely signal clustering and cluster indexing.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.0958981504,"dev-research":0.3861772168,"prompt-eng":0.4040763617,"data-quality":0.0931999102,"ml-security":0.0492506311}}
{"text":"We first build a bipartite graph to model the RF signal samples and obtain a latent representation of each node (each signal sample) using our attention-based graph neural network model so that the RF signal samples can be clustered more accurately.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.1872846321,"dev-research":0.3674988834,"prompt-eng":0.4420570394,"data-quality":0.1887398976,"ml-security":0.1237079206}}
{"text":"Then, we tackle the problem of indexing the clusters with proper floor labels, by leveraging the observation that signals from an access point can be detected on different floors, i.e., signal spillover.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.1183469972,"dev-research":0.3798248536,"prompt-eng":0.4224121851,"data-quality":0.2089559884,"ml-security":0.1528989298}}
{"text":"Specifically, we formulate a cluster indexing problem as a combinatorial optimization problem and show that it is equivalent to solving a traveling salesman problem, whose (near-)optimal solution can be found efficiently.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.0868826369,"dev-research":0.3949050129,"prompt-eng":0.3611716802,"data-quality":0.0776149889,"ml-security":0.0855987968}}
{"text":"We have implemented FIS-ONE and validated its effectiveness on the Microsoft dataset and in three large shopping malls.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.4822800431,"dev-research":0.4162404306,"prompt-eng":0.4736659217,"data-quality":0.1793037028,"ml-security":0.1634697702}}
{"text":"Our results show that FIS-ONE outperforms other baseline algorithms significantly, with up to 23% improvement in adjusted rand index and 25% improvement in normalized mutual information using only one floor-labeled signal sample.","meta":{"url":"http://arxiv.org/abs/2307.05914v1"},"cats":{"new-dataset":0.1277769622,"dev-research":0.3395321547,"prompt-eng":0.423518197,"data-quality":0.1904399621,"ml-security":0.0937026798}}
{"text":"The virtual viewpoint is perceived as a new technique in virtual navigation, as yet not supported due to the lack of depth information and obscure camera parameters.","meta":{"url":"http://arxiv.org/abs/2307.05913v1"},"cats":{"new-dataset":0.1016296141,"dev-research":0.4058451436,"prompt-eng":0.3660008549,"data-quality":0.0748712887,"ml-security":0.0751174473}}
{"text":"In this paper, a method for achieving close-up virtual view is proposed and it only uses optical flow to build parallax effects to realize pseudo 3D projection without using depth sensor.","meta":{"url":"http://arxiv.org/abs/2307.05913v1"},"cats":{"new-dataset":0.1008873384,"dev-research":0.3730445357,"prompt-eng":0.3827142253,"data-quality":0.0520451239,"ml-security":0.0701933718}}
{"text":"We develop a bidirectional optical flow method to obtain any virtual viewpoint by proportional interpolation of optical flow.","meta":{"url":"http://arxiv.org/abs/2307.05913v1"},"cats":{"new-dataset":0.1225053538,"dev-research":0.3729357407,"prompt-eng":0.3636779948,"data-quality":0.0452401563,"ml-security":0.0334127741}}
{"text":"Moreover, with the ingenious application of the optical-flow-value, we achieve clear and visual-fidelity magnified results through lens stretching in any corner, which overcomes the visual distortion and image blur through viewpoint magnification and transition in Google Street View system.","meta":{"url":"http://arxiv.org/abs/2307.05913v1"},"cats":{"new-dataset":0.0889905211,"dev-research":0.3825192774,"prompt-eng":0.3785853075,"data-quality":0.1042594811,"ml-security":0.0590898598}}
{"text":"AI Tool is designed to generate human-like responses in natural language conversations.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.275216987,"dev-research":0.4725301788,"prompt-eng":0.5947577482,"data-quality":0.2188294301,"ml-security":0.1270209467}}
{"text":"Using deep learning techniques, AI Tool has been trained on a diverse range of internet text to understand and generate coherent responses to a wide array of prompts and questions.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.2137828583,"dev-research":0.4385447729,"prompt-eng":0.592661993,"data-quality":0.1950744476,"ml-security":0.1640140232}}
{"text":"It can provide information, engage in conversations, assist with tasks, and even offer creative suggestions.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.1629440042,"dev-research":0.5097052473,"prompt-eng":0.4745371212,"data-quality":0.0867304477,"ml-security":0.0786182762}}
{"text":"The underlying technology behind AI Tool is a transformer neural network.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.0971478414,"dev-research":0.4401106573,"prompt-eng":0.426526184,"data-quality":0.0758850096,"ml-security":0.1613540199}}
{"text":"Transformers excel at capturing long-range dependencies in text, making them well-suited for language-related tasks.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.3552791592,"dev-research":0.464410349,"prompt-eng":0.5163998909,"data-quality":0.1731671881,"ml-security":0.0972514787}}
{"text":"AI Tool, has 175 billion parameters, making it one of the largest and most powerful language models to date.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.304385512,"dev-research":0.4776593334,"prompt-eng":0.5440933055,"data-quality":0.1108597616,"ml-security":0.1306490887}}
{"text":"AI Tool has been trained on a massive corpus of text from the internet, which allows it to leverage a broad understanding of language, general knowledge, and various domains.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.3587611296,"dev-research":0.4490276943,"prompt-eng":0.5286064742,"data-quality":0.1665578245,"ml-security":0.1350317416}}
{"text":"While AI Tool aims to provide accurate and helpful responses, it may occasionally produce incorrect or nonsensical answers.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.0966841921,"dev-research":0.4804056612,"prompt-eng":0.5008767822,"data-quality":0.297971719,"ml-security":0.1070762468}}
{"text":"It's essential to critically evaluate the information it provides and verify it from reliable sources when necessary.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.1401916082,"dev-research":0.457856517,"prompt-eng":0.437039348,"data-quality":0.2087364579,"ml-security":0.1288360478}}
{"text":"This work presents an overview on AI Tool.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.2536547606,"dev-research":0.4714436334,"prompt-eng":0.4983927397,"data-quality":0.1487436407,"ml-security":0.1147731195}}
{"text":"It will helps to research community and others users to understand the uses of AI Tool and its interaction pattern.","meta":{"url":"http://arxiv.org/abs/2307.05909v1"},"cats":{"new-dataset":0.1795191895,"dev-research":0.5218327335,"prompt-eng":0.4791425748,"data-quality":0.0912584151,"ml-security":0.1054576126}}
{"text":"This paper presents \"Predictive Pipelined Decoding (PPD),\" an approach that speeds up greedy decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.1727695523,"dev-research":0.3974526248,"prompt-eng":0.5572283814,"data-quality":0.1455046974,"ml-security":0.2392888172}}
{"text":"Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.0576314013,"dev-research":0.4393789896,"prompt-eng":0.4726654607,"data-quality":0.1041094983,"ml-security":0.139663405}}
{"text":"This innovative method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.0574561089,"dev-research":0.4161284405,"prompt-eng":0.4907079779,"data-quality":0.1239908213,"ml-security":0.1582430616}}
{"text":"We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.0538720915,"dev-research":0.4345266121,"prompt-eng":0.3644992825,"data-quality":0.0624065787,"ml-security":0.1003607329}}
{"text":"Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as p_correct.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.0521388812,"dev-research":0.3536874504,"prompt-eng":0.3975853868,"data-quality":0.1155910084,"ml-security":0.0919764723}}
{"text":"The results demonstrate that the use of extra computational resources has the potential to accelerate LLM greedy decoding.","meta":{"url":"http://arxiv.org/abs/2307.05908v1"},"cats":{"new-dataset":0.0949717124,"dev-research":0.4115526985,"prompt-eng":0.494901208,"data-quality":0.1203067305,"ml-security":0.2127980517}}
{"text":"Contrastive learning has gained significant attention as a method for self-supervised learning.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.1250519583,"dev-research":0.3961403682,"prompt-eng":0.4733195195,"data-quality":0.1934751468,"ml-security":0.1159618025}}
{"text":"The contrastive loss function ensures that embeddings of positive sample pairs (e.g., different samples from the same class or different views of the same object) are similar, while embeddings of negative pairs are dissimilar.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.0778164828,"dev-research":0.3642586927,"prompt-eng":0.3852439661,"data-quality":0.1890561924,"ml-security":0.1291769982}}
{"text":"Practical constraints such as large memory requirements make it challenging to consider all possible positive and negative pairs, leading to the use of mini-batch optimization.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.0409101848,"dev-research":0.3866092706,"prompt-eng":0.3948286755,"data-quality":0.1021779155,"ml-security":0.1557166518}}
{"text":"In this paper, we investigate the theoretical aspects of mini-batch optimization in contrastive learning.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.067019529,"dev-research":0.3605834669,"prompt-eng":0.4306071441,"data-quality":0.1437002692,"ml-security":0.1316290275}}
{"text":"We show that mini-batch optimization is equivalent to full-batch optimization if and only if all $\\binom{N}{B}$ mini-batches are selected, while sub-optimality may arise when examining only a subset.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.062256434,"dev-research":0.4105228164,"prompt-eng":0.4111442971,"data-quality":0.1046772802,"ml-security":0.1366074638}}
{"text":"We then demonstrate that utilizing high-loss mini-batches can speed up SGD convergence and propose a spectral clustering-based approach for identifying these high-loss mini-batches.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.0667715728,"dev-research":0.3660908051,"prompt-eng":0.4580674316,"data-quality":0.2116391558,"ml-security":0.1667634922}}
{"text":"Our experimental results validate our theoretical findings and demonstrate that our proposed algorithm outperforms vanilla SGD in practically relevant settings, providing a better understanding of mini-batch optimization in contrastive learning.","meta":{"url":"http://arxiv.org/abs/2307.05906v1"},"cats":{"new-dataset":0.0672635323,"dev-research":0.3551763463,"prompt-eng":0.4534616281,"data-quality":0.1515003864,"ml-security":0.1349074824}}
{"text":"Explanation methods for machine learning models tend to not provide any formal guarantees and may not reflect the underlying decision-making process.","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.0333000996,"dev-research":0.461747045,"prompt-eng":0.3925341692,"data-quality":0.2402967906,"ml-security":0.3822603035}}
{"text":"In this work, we analyze stability as a property for reliable feature attribution methods.","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.1078250334,"dev-research":0.4434188104,"prompt-eng":0.4547836751,"data-quality":0.4200236152,"ml-security":0.271527982}}
{"text":"We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features.","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.0829797427,"dev-research":0.3839631356,"prompt-eng":0.3954609629,"data-quality":0.2238782213,"ml-security":0.3178446513}}
{"text":"To achieve such a model, we develop a smoothing method called Multiplicative Smoothing (MuS).","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.1241813566,"dev-research":0.3611161703,"prompt-eng":0.4449324101,"data-quality":0.1084911727,"ml-security":0.0546395174}}
{"text":"We show that MuS overcomes theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method.","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.0958062487,"dev-research":0.3771794781,"prompt-eng":0.4761596114,"data-quality":0.2618259659,"ml-security":0.1751816375}}
{"text":"We evaluate MuS on vision and language models with a variety of feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees.","meta":{"url":"http://arxiv.org/abs/2307.05902v1"},"cats":{"new-dataset":0.101009007,"dev-research":0.4195704618,"prompt-eng":0.517297361,"data-quality":0.3050791828,"ml-security":0.2144382515}}
{"text":"Deep learning techniques often perform poorly in the presence of domain shift, where the test data follows a different distribution than the training data.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.0995552631,"dev-research":0.3582479242,"prompt-eng":0.4378555218,"data-quality":0.2888219044,"ml-security":0.2855993027}}
{"text":"The most practically desirable approach to address this issue is Single Domain Generalization (S-DG), which aims to train robust models using data from a single source.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.1187835285,"dev-research":0.3868278617,"prompt-eng":0.5175357758,"data-quality":0.2771629248,"ml-security":0.3026416764}}
{"text":"Prior work on S-DG has primarily focused on using data augmentation techniques to generate diverse training data.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.1483404374,"dev-research":0.4163862626,"prompt-eng":0.5120583073,"data-quality":0.1472295278,"ml-security":0.1331760164}}
{"text":"In this paper, we explore an alternative approach by investigating the robustness of linear operators, such as convolution and dense layers commonly used in deep learning.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.0887406357,"dev-research":0.3550267538,"prompt-eng":0.4017419334,"data-quality":0.2689424026,"ml-security":0.3670528126}}
{"text":"We propose a novel operator called XCNorm that computes the normalized cross-correlation between weights and an input feature patch.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.1169273172,"dev-research":0.366085806,"prompt-eng":0.4642248851,"data-quality":0.1984803655,"ml-security":0.1988834616}}
{"text":"This approach is invariant to both affine shifts and changes in energy within a local feature patch and eliminates the need for commonly used non-linear activation functions.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.0495606756,"dev-research":0.4101841883,"prompt-eng":0.3697224036,"data-quality":0.1614087232,"ml-security":0.1436226374}}
{"text":"We show that deep neural networks composed of this operator are robust to common semantic distribution shifts.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.1801037038,"dev-research":0.3854578092,"prompt-eng":0.4906207591,"data-quality":0.3529228179,"ml-security":0.2389321644}}
{"text":"Furthermore, our empirical results on single-domain generalization benchmarks demonstrate that our proposed technique performs comparably to the state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.05901v1"},"cats":{"new-dataset":0.0763032788,"dev-research":0.3947196675,"prompt-eng":0.47464043,"data-quality":0.1915767167,"ml-security":0.1446010211}}
{"text":"Diffusion probabilistic models (DPMs) have shown remarkable results on various image synthesis tasks such as text-to-image generation and image inpainting.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.1237914768,"dev-research":0.4082727313,"prompt-eng":0.4755479696,"data-quality":0.1456831705,"ml-security":0.0791741954}}
{"text":"However, compared to other generative methods like VAEs and GANs, DPMs lack a low-dimensional, interpretable, and well-decoupled latent code.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.0576683161,"dev-research":0.4109303707,"prompt-eng":0.4405460272,"data-quality":0.1393419072,"ml-security":0.1247821663}}
{"text":"Recently, diffusion autoencoders (Diff-AE) were proposed to explore the potential of DPMs for representation learning via autoencoding.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.1062049997,"dev-research":0.3818238729,"prompt-eng":0.4952804979,"data-quality":0.1644370697,"ml-security":0.1897660443}}
{"text":"Diff-AE provides an accessible latent space that exhibits remarkable interpretability, allowing us to manipulate image attributes based on latent codes from the space.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.2438950041,"dev-research":0.4399205226,"prompt-eng":0.4685828491,"data-quality":0.1617960034,"ml-security":0.110178439}}
{"text":"However, previous works are not generic as they only operated on a few limited attributes.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.0890903749,"dev-research":0.4501601769,"prompt-eng":0.4179635519,"data-quality":0.1007313695,"ml-security":0.0920756643}}
{"text":"To further explore the latent space of Diff-AE and achieve a generic editing pipeline, we proposed a module called Group-supervised AutoEncoder(dubbed GAE) for Diff-AE to achieve better disentanglement on the latent code.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.1796992162,"dev-research":0.4623008735,"prompt-eng":0.4979331017,"data-quality":0.1955585131,"ml-security":0.0769412833}}
{"text":"Our proposed GAE has trained via an attribute-swap strategy to acquire the latent codes for multi-attribute image manipulation based on examples.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.1115006114,"dev-research":0.4253541799,"prompt-eng":0.5003047904,"data-quality":0.1569399755,"ml-security":0.084719909}}
{"text":"We empirically demonstrate that our method enables multiple-attributes manipulation and achieves convincing sample quality and attribute alignments, while significantly reducing computational requirements compared to pixel-based approaches for representational decoupling.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.1580983754,"dev-research":0.4179411548,"prompt-eng":0.5186702748,"data-quality":0.2824035681,"ml-security":0.0972362876}}
{"text":"Code will be released soon.","meta":{"url":"http://arxiv.org/abs/2307.05899v1"},"cats":{"new-dataset":0.3337655563,"dev-research":0.5615628757,"prompt-eng":0.481416729,"data-quality":0.1335685568,"ml-security":0.1793790014}}
{"text":"Noisy label problems are inevitably in existence within medical image segmentation causing severe performance degradation.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.0904295242,"dev-research":0.3557817752,"prompt-eng":0.4153280801,"data-quality":0.6870024835,"ml-security":0.1543112962}}
{"text":"Previous segmentation methods for noisy label problems only utilize a single image while the potential of leveraging the correlation between images has been overlooked.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1254411087,"dev-research":0.3551580834,"prompt-eng":0.4601759064,"data-quality":0.7711471728,"ml-security":0.1108649439}}
{"text":"Especially for video segmentation, adjacent frames contain rich contextual information beneficial in cognizing noisy labels.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1395994718,"dev-research":0.4158418368,"prompt-eng":0.4497104511,"data-quality":0.5295976043,"ml-security":0.0771539537}}
{"text":"Based on two insights, we propose a Multi-Scale Temporal Feature Affinity Learning (MS-TFAL) framework to resolve noisy-labeled medical video segmentation issues.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1295424128,"dev-research":0.3680723824,"prompt-eng":0.4387430533,"data-quality":0.2952204579,"ml-security":0.1255010843}}
{"text":"First, we argue the sequential prior of videos is an effective reference, i.e., pixel-level features from adjacent frames are close in distance for the same class and far in distance otherwise.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1635936485,"dev-research":0.3979824796,"prompt-eng":0.4272433525,"data-quality":0.1361576841,"ml-security":0.0657308962}}
{"text":"Therefore, Temporal Feature Affinity Learning (TFAL) is devised to indicate possible noisy labels by evaluating the affinity between pixels in two adjacent frames.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1186977144,"dev-research":0.3914395089,"prompt-eng":0.458393371,"data-quality":0.3815551266,"ml-security":0.1336884368}}
{"text":"We also notice that the noise distribution exhibits considerable variations across video, image, and pixel levels.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1947560177,"dev-research":0.3855222254,"prompt-eng":0.4461024602,"data-quality":0.3170801063,"ml-security":0.1016364843}}
{"text":"In this way, we introduce Multi-Scale Supervision (MSS) to supervise the network from three different perspectives by re-weighting and refining the samples.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.1061129127,"dev-research":0.4041188212,"prompt-eng":0.5009246059,"data-quality":0.2119141023,"ml-security":0.1161569029}}
{"text":"This design enables the network to concentrate on clean samples in a coarse-to-fine manner.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.0721524757,"dev-research":0.404288957,"prompt-eng":0.4022482569,"data-quality":0.1453925718,"ml-security":0.143574821}}
{"text":"Experiments with both synthetic and real-world label noise demonstrate that our method outperforms recent state-of-the-art robust segmentation approaches.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.2045930917,"dev-research":0.3325080341,"prompt-eng":0.4417811506,"data-quality":0.7354469112,"ml-security":0.1782413141}}
{"text":"Code is available at https://github.com/BeileiCui/MS-TFAL.","meta":{"url":"http://arxiv.org/abs/2307.05898v1"},"cats":{"new-dataset":0.3533009334,"dev-research":0.4779915067,"prompt-eng":0.5102226763,"data-quality":0.0921408659,"ml-security":0.1039667691}}
{"text":"It is necessary to analyze the whole-body kinematics (including joint locations and joint angles) to assess risks of fatal and musculoskeletal injuries in occupational tasks.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.112838755,"dev-research":0.424958043,"prompt-eng":0.3676612033,"data-quality":0.0831910888,"ml-security":0.1683051012}}
{"text":"Human pose estimation has gotten more attention in recent years as a method to minimize the errors in determining joint locations.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.1108645485,"dev-research":0.3938516513,"prompt-eng":0.4128483649,"data-quality":0.1912019946,"ml-security":0.0901379588}}
{"text":"However, the joint angles are not often estimated, nor is the quality of joint angle estimation assessed.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.0783670719,"dev-research":0.3797821479,"prompt-eng":0.3629215066,"data-quality":0.1588817841,"ml-security":0.0551368809}}
{"text":"In this paper, we presented an end-to-end approach on direct joint angle estimation from multi-view images.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.2085242054,"dev-research":0.379546349,"prompt-eng":0.4155553099,"data-quality":0.112915573,"ml-security":0.0647563309}}
{"text":"Our method leveraged the volumetric pose representation and mapped the rotation representation to a continuous space where each rotation was uniquely represented.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.1290776912,"dev-research":0.3716777392,"prompt-eng":0.3847900168,"data-quality":0.0777114844,"ml-security":0.0804434054}}
{"text":"We also presented a new kinematic dataset in the domain of residential roofing with a data processing pipeline to generate necessary annotations for the supervised training procedure on direct joint angle estimation.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.249580728,"dev-research":0.3978013783,"prompt-eng":0.4721290371,"data-quality":0.1755788808,"ml-security":0.1050892808}}
{"text":"We achieved a mean angle error of $7.19^\\circ$ on the new Roofing dataset and $8.41^\\circ$ on the Human3.6M dataset, paving the way for employment of on-site kinematic analysis using multi-view images.","meta":{"url":"http://arxiv.org/abs/2307.05896v1"},"cats":{"new-dataset":0.242255245,"dev-research":0.3875843484,"prompt-eng":0.3987530467,"data-quality":0.0972940244,"ml-security":0.0760521623}}
{"text":"The recent neural surface reconstruction by volume rendering approaches have made much progress by achieving impressive surface reconstruction quality, but are still limited to dense and highly accurate posed views.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.1149523729,"dev-research":0.3584071089,"prompt-eng":0.3823985804,"data-quality":0.072798425,"ml-security":0.0777797069}}
{"text":"To overcome such drawbacks, this paper pays special attention on the consistent surface reconstruction from sparse views with noisy camera poses.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.1574623307,"dev-research":0.3502499993,"prompt-eng":0.3858675721,"data-quality":0.1538012862,"ml-security":0.079373038}}
{"text":"Unlike previous approaches, the key difference of this paper is to exploit the multi-view constraints directly from the explicit geometry of the neural surface, which can be used as effective regularization to jointly learn the neural surface and refine the camera poses.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.1786243524,"dev-research":0.3671819525,"prompt-eng":0.434324368,"data-quality":0.1217891848,"ml-security":0.1392008368}}
{"text":"To build effective multi-view constraints, we introduce a fast differentiable on-surface intersection to generate on-surface points, and propose view-consistent losses based on such differentiable points to regularize the neural surface learning.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.1231177748,"dev-research":0.3623142055,"prompt-eng":0.4193665278,"data-quality":0.1389602993,"ml-security":0.1479564824}}
{"text":"Based on this point, we propose a jointly learning strategy for neural surface and camera poses, named SC-NeuS, to perform geometry-consistent surface reconstruction in an end-to-end manner.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.1769183049,"dev-research":0.3492097394,"prompt-eng":0.4135444728,"data-quality":0.0941246791,"ml-security":0.0876908775}}
{"text":"With extensive evaluation on public datasets, our SC-NeuS can achieve consistently better surface reconstruction results with fine-grained details than previous state-of-the-art neural surface reconstruction approaches, especially from sparse and noisy camera views.","meta":{"url":"http://arxiv.org/abs/2307.05892v1"},"cats":{"new-dataset":0.3053379287,"dev-research":0.3355225145,"prompt-eng":0.4196973355,"data-quality":0.1104261535,"ml-security":0.1040208124}}
{"text":"Deep reinforcement learning (RL) has shown immense potential for learning to control systems through data alone.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.1746978305,"dev-research":0.384271273,"prompt-eng":0.457213182,"data-quality":0.0745836839,"ml-security":0.2827749507}}
{"text":"However, one challenge deep RL faces is that the full state of the system is often not observable.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.0614213313,"dev-research":0.3777915599,"prompt-eng":0.4015753844,"data-quality":0.1342662091,"ml-security":0.249531576}}
{"text":"When this is the case, the policy needs to leverage the history of observations to infer the current state.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.0993241018,"dev-research":0.4159082944,"prompt-eng":0.4293483786,"data-quality":0.1401103867,"ml-security":0.1897914464}}
{"text":"At the same time, differences between the training and testing environments makes it critical for the policy not to overfit to the sequence of observations it sees at training time.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.072602147,"dev-research":0.4117739274,"prompt-eng":0.4344734126,"data-quality":0.1558529556,"ml-security":0.3145451961}}
{"text":"As such, there is an important balancing act between having the history encoder be flexible enough to extract relevant information, yet be robust to changes in the environment.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.1790441068,"dev-research":0.4543140758,"prompt-eng":0.4666424355,"data-quality":0.1384496271,"ml-security":0.1810023254}}
{"text":"To strike this balance, we look to the PID controller for inspiration.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.0789704825,"dev-research":0.4046768783,"prompt-eng":0.4176884013,"data-quality":0.0546176579,"ml-security":0.1172381658}}
{"text":"We assert the PID controller's success shows that only summing and differencing are needed to accumulate information over time for many control tasks.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.0911931241,"dev-research":0.450052721,"prompt-eng":0.4508217523,"data-quality":0.0718253326,"ml-security":0.100303065}}
{"text":"Following this principle, we propose two architectures for encoding history: one that directly uses PID features and another that extends these core ideas and can be used in arbitrary control tasks.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.1492632606,"dev-research":0.4588260914,"prompt-eng":0.5063878954,"data-quality":0.1207006861,"ml-security":0.1418482647}}
{"text":"When compared with prior approaches, our encoders produce policies that are often more robust and achieve better performance on a variety of tracking tasks.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.1408870469,"dev-research":0.4356328499,"prompt-eng":0.4515474307,"data-quality":0.1160927282,"ml-security":0.1376055398}}
{"text":"Going beyond tracking tasks, our policies achieve 1.7x better performance on average over previous state-of-the-art methods on a suite of high dimensional control tasks.","meta":{"url":"http://arxiv.org/abs/2307.05891v1"},"cats":{"new-dataset":0.1233672364,"dev-research":0.4106249395,"prompt-eng":0.4485174715,"data-quality":0.0563877137,"ml-security":0.1229621142}}
{"text":"Mitosis detection is one of the fundamental tasks in computational pathology, which is extremely challenging due to the heterogeneity of mitotic cell.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.1183036378,"dev-research":0.3857899189,"prompt-eng":0.3869884543,"data-quality":0.1417972335,"ml-security":0.1133241364}}
{"text":"Most of the current studies solve the heterogeneity in the technical aspect by increasing the model complexity.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.0320432113,"dev-research":0.4389700575,"prompt-eng":0.3465765822,"data-quality":0.0523475814,"ml-security":0.063332259}}
{"text":"However, lacking consideration of the biological knowledge and the complex model design may lead to the overfitting problem while limited the generalizability of the detection model.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.0819464944,"dev-research":0.3733621991,"prompt-eng":0.3977334677,"data-quality":0.2195711833,"ml-security":0.3037250253}}
{"text":"In this paper, we systematically study the morphological appearances in different mitotic phases as well as the ambiguous non-mitotic cells and identify that balancing the data and feature diversity can achieve better generalizability.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.1384731304,"dev-research":0.3782684771,"prompt-eng":0.4095271228,"data-quality":0.1949694726,"ml-security":0.0967177622}}
{"text":"Based on this observation, we propose a novel generalizable framework (MitDet) for mitosis detection.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.0869751594,"dev-research":0.3912173933,"prompt-eng":0.4321934203,"data-quality":0.1855243137,"ml-security":0.1512111534}}
{"text":"The data diversity is considered by the proposed diversity-guided sample balancing (DGSB).","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.2495037891,"dev-research":0.359622805,"prompt-eng":0.4266600743,"data-quality":0.1711476244,"ml-security":0.1312913118}}
{"text":"And the feature diversity is preserved by inter- and intra- class feature diversity-preserved module (InCDP).","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.1639474352,"dev-research":0.4403730253,"prompt-eng":0.4425180184,"data-quality":0.1537058444,"ml-security":0.0690665406}}
{"text":"Stain enhancement (SE) module is introduced to enhance the domain-relevant diversity of both data and features simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.1880137386,"dev-research":0.4117400346,"prompt-eng":0.4126281109,"data-quality":0.1788561394,"ml-security":0.0686156439}}
{"text":"Extensive experiments have demonstrated that our proposed model outperforms all the SOTA approaches in several popular mitosis detection datasets in both internal and external test sets using minimal annotation efforts with point annotations only.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.273967208,"dev-research":0.4039436052,"prompt-eng":0.4896442204,"data-quality":0.3195711145,"ml-security":0.1696048556}}
{"text":"Comprehensive ablation studies have also proven the effectiveness of the rethinking of data and feature diversity balancing.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.1575883116,"dev-research":0.3784767594,"prompt-eng":0.4083138807,"data-quality":0.150240857,"ml-security":0.0878691161}}
{"text":"By analyzing the results quantitatively and qualitatively, we believe that our proposed model not only achieves SOTA performance but also might inspire the future studies in new perspectives.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.0630626126,"dev-research":0.3880722463,"prompt-eng":0.3989331165,"data-quality":0.0619163954,"ml-security":0.0940620593}}
{"text":"Source code is at https://github.com/Onehour0108/MitDet.","meta":{"url":"http://arxiv.org/abs/2307.05889v1"},"cats":{"new-dataset":0.2324640894,"dev-research":0.4754387836,"prompt-eng":0.4677918763,"data-quality":0.128454701,"ml-security":0.110759381}}
{"text":"In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to empower various areas as a bridge between physical objects and the digital world.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.0942528872,"dev-research":0.4281074392,"prompt-eng":0.3997811262,"data-quality":0.08450965,"ml-security":0.200829966}}
{"text":"Through virtualization and simulation techniques, multiple functions can be achieved by leveraging computing resources.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.0741717845,"dev-research":0.4421328324,"prompt-eng":0.399115415,"data-quality":0.0406393458,"ml-security":0.1015407674}}
{"text":"In this process, Mobile Cloud Computing (MCC) and Mobile Edge Computing (MEC) have become two of the key factors to achieve real-time feedback.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.0836831178,"dev-research":0.4220691073,"prompt-eng":0.3956667741,"data-quality":0.0858188459,"ml-security":0.116341715}}
{"text":"However, current works only considered edge servers or cloud servers in the DT system models.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.1087434114,"dev-research":0.3914507448,"prompt-eng":0.36298051,"data-quality":0.0962635893,"ml-security":0.1760535959}}
{"text":"Besides, The models ignore the DT with not only one data resource.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.1272932024,"dev-research":0.3820646837,"prompt-eng":0.4310188391,"data-quality":0.1224157069,"ml-security":0.1563988079}}
{"text":"In this paper, we propose a new DT system model considering a heterogeneous MEC/MCC environment.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.066872865,"dev-research":0.3856634669,"prompt-eng":0.4188545594,"data-quality":0.0860313233,"ml-security":0.1041202143}}
{"text":"Each DT in the model is maintained in one of the servers via multiple data collection devices.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.2381391971,"dev-research":0.3955015905,"prompt-eng":0.4641533828,"data-quality":0.0809767284,"ml-security":0.1313065725}}
{"text":"The offloading decision-making problem is also considered and a new offloading scheme is proposed based on Distributed Deep Learning (DDL).","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.1282162298,"dev-research":0.3737470615,"prompt-eng":0.391876727,"data-quality":0.0928984956,"ml-security":0.3668060857}}
{"text":"Simulation results demonstrate that our proposed algorithm can effectively and efficiently decrease the system's average latency and energy consumption.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.0544900843,"dev-research":0.3759540571,"prompt-eng":0.3670977894,"data-quality":0.0857950099,"ml-security":0.1023809803}}
{"text":"Significant improvement is achieved compared with the baselines under the dynamic environment of DTs.","meta":{"url":"http://arxiv.org/abs/2307.05888v1"},"cats":{"new-dataset":0.0632884368,"dev-research":0.4327703858,"prompt-eng":0.4499298717,"data-quality":0.0855249984,"ml-security":0.0821129881}}
{"text":"We propose a conceptually simple and thus fast multi-object tracking (MOT) model that does not require any attached modules, such as the Kalman filter, Hungarian algorithm, transformer blocks, or graph networks.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.1578498054,"dev-research":0.353507125,"prompt-eng":0.3827880462,"data-quality":0.095199122,"ml-security":0.0747794537}}
{"text":"Conventional MOT models are built upon the multi-step modules listed above, and thus the computational cost is high.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.0374699336,"dev-research":0.4007899319,"prompt-eng":0.4204018076,"data-quality":0.033405031,"ml-security":0.0735458993}}
{"text":"Our proposed end-to-end MOT model, \\textit{TicrossNet}, is composed of a base detector and a cross-attention module only.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.1634831124,"dev-research":0.4033567698,"prompt-eng":0.5156964134,"data-quality":0.1015464076,"ml-security":0.1293275729}}
{"text":"As a result, the overhead of tracking does not increase significantly even when the number of instances ($N_t$) increases.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.0877353693,"dev-research":0.3908973844,"prompt-eng":0.3495064031,"data-quality":0.085425159,"ml-security":0.1063537426}}
{"text":"We show that TicrossNet runs \\textit{in real-time}; specifically, it achieves 32.6 FPS on MOT17 and 31.0 FPS on MOT20 (Tesla V100), which includes as many as $>$100 instances per frame.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.2624281246,"dev-research":0.3992047385,"prompt-eng":0.3884335447,"data-quality":0.061381137,"ml-security":0.1065918849}}
{"text":"We also demonstrate that TicrossNet is robust to $N_t$; thus, it does not have to change the size of the base detector, depending on $N_t$, as is often done by other models for real-time processing.","meta":{"url":"http://arxiv.org/abs/2307.05874v1"},"cats":{"new-dataset":0.1068170708,"dev-research":0.3757254249,"prompt-eng":0.3672618953,"data-quality":0.0934301793,"ml-security":0.1809837196}}
{"text":"Occupancy prediction tasks focus on the inference of both geometry and semantic labels for each voxel, which is an important perception mission.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.1305125984,"dev-research":0.3687190386,"prompt-eng":0.451027718,"data-quality":0.1653698025,"ml-security":0.0724865092}}
{"text":"However, it is still a semantic segmentation task without distinguishing various instances.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.1448054554,"dev-research":0.4133588147,"prompt-eng":0.4531475759,"data-quality":0.3092599586,"ml-security":0.0866896097}}
{"text":"Further, although some existing works, such as Open-Vocabulary Occupancy (OVO), have already solved the problem of open vocabulary detection, visual grounding in occupancy has not been solved to the best of our knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.2819780873,"dev-research":0.4386439623,"prompt-eng":0.4844579146,"data-quality":0.2712401626,"ml-security":0.1292212758}}
{"text":"To tackle the above two limitations, this paper proposes Occupancy Grounding (OG), a novel method that equips vanilla occupancy instance segmentation ability and could operate visual grounding in a voxel manner with the help of grounded-SAM.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.1461093857,"dev-research":0.3731567487,"prompt-eng":0.4346391027,"data-quality":0.1509813054,"ml-security":0.0862533016}}
{"text":"Keys to our approach are (1) affinity field prediction for instance clustering and (2) association strategy for aligning 2D instance masks and 3D occupancy instances.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.1220142368,"dev-research":0.3579655203,"prompt-eng":0.4194099164,"data-quality":0.1089863443,"ml-security":0.1621504997}}
{"text":"Extensive experiments have been conducted whose visualization results and analysis are shown below.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.2603355239,"dev-research":0.4262786927,"prompt-eng":0.4410048181,"data-quality":0.0678532307,"ml-security":0.0699378314}}
{"text":"Our code will be publicly released soon.","meta":{"url":"http://arxiv.org/abs/2307.05873v1"},"cats":{"new-dataset":0.3930387158,"dev-research":0.5355903646,"prompt-eng":0.4773648483,"data-quality":0.1350761635,"ml-security":0.2774568868}}
{"text":"Captions provide language learners with a scaffold for comprehension and vocabulary acquisition.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.2261749054,"dev-research":0.4582629884,"prompt-eng":0.5520848415,"data-quality":0.2347930271,"ml-security":0.0842786707}}
{"text":"Past work has proposed several enhancements such as keyword highlights for increased learning gains.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.0567065774,"dev-research":0.4771261748,"prompt-eng":0.4307784471,"data-quality":0.1327682672,"ml-security":0.1407101592}}
{"text":"However, little is known about learners' experience with enhanced captions, although this is critical for adoption in everyday life.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.139377395,"dev-research":0.480546317,"prompt-eng":0.4962264423,"data-quality":0.2656925271,"ml-security":0.125877858}}
{"text":"We conducted a survey and focus group to elicit learner preferences and requirements and implemented a processing pipeline for enhanced captions with keyword highlights, time-synchronized keyword highlights, and keyword captions.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.2644669459,"dev-research":0.4793421091,"prompt-eng":0.568740664,"data-quality":0.2165747497,"ml-security":0.0883521886}}
{"text":"A subsequent online study (n = 49) showed that time-synchronized keyword highlights were the preferred design for learning but were perceived as too distracting to replace standard captions in everyday viewing scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.094431088,"dev-research":0.4500201689,"prompt-eng":0.4558986251,"data-quality":0.1694584644,"ml-security":0.0945870213}}
{"text":"We conclude that keyword highlights and time-synchronization are suitable for integrating learning into an entertaining everyday-life activity, but the design should be optimized to provide a more seamless experience.","meta":{"url":"http://arxiv.org/abs/2307.05870v1"},"cats":{"new-dataset":0.2020488209,"dev-research":0.4590551244,"prompt-eng":0.4338672976,"data-quality":0.1005367619,"ml-security":0.0782716983}}
{"text":"Memory is an important cognitive function for humans.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.1052518539,"dev-research":0.4478162956,"prompt-eng":0.4250851471,"data-quality":0.088920715,"ml-security":0.1080227558}}
{"text":"How a brain with such a small power can complete such a complex memory function, the working mechanism behind this is undoubtedly fascinating.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0597726301,"dev-research":0.4172092079,"prompt-eng":0.4042478368,"data-quality":0.0678336569,"ml-security":0.1320629509}}
{"text":"Engram theory views memory as the co-activation of specific neuronal clusters.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0580103047,"dev-research":0.3981064269,"prompt-eng":0.4466758878,"data-quality":0.0968855288,"ml-security":0.1285258968}}
{"text":"From the perspective of graph theory, nodes represent neurons, and directed edges represent synapses.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0676752665,"dev-research":0.4550754109,"prompt-eng":0.3679713709,"data-quality":0.1204823552,"ml-security":0.1322803907}}
{"text":"Then the memory engram is the connected subgraph formed between the activated nodes.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0962009345,"dev-research":0.4295156092,"prompt-eng":0.4381591131,"data-quality":0.1288549416,"ml-security":0.1078045646}}
{"text":"In this paper, we use subgraphs as physical carriers of information and propose a parallel distributed information storage algorithm based on node scale in active-directed graphs.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.1835634283,"dev-research":0.399694326,"prompt-eng":0.348472627,"data-quality":0.1097455621,"ml-security":0.1159599138}}
{"text":"An active-directed graph is defined as a graph in which each node has autonomous and independent behavior and relies only on information obtained within the local field of view to make decisions.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0732048157,"dev-research":0.4401708647,"prompt-eng":0.3694126411,"data-quality":0.1190805245,"ml-security":0.1266932953}}
{"text":"Unlike static directed graphs used for recording facts, active-directed graphs are decentralized like biological neuron networks and do not have a super manager who has a global view and can control the behavior of each node.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.097114065,"dev-research":0.4368633173,"prompt-eng":0.390970486,"data-quality":0.0917419615,"ml-security":0.1354304527}}
{"text":"Distinct from traditional algorithms with a global field of view, this algorithm is characterized by nodes collaborating globally on resource usage through their limited local field of view.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.1007252804,"dev-research":0.4225174433,"prompt-eng":0.3495030166,"data-quality":0.0635925513,"ml-security":0.0935063715}}
{"text":"While this strategy may not achieve global optimality as well as algorithms with a global field of view, it offers better robustness, concurrency, decentralization, and bioviability.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0454108405,"dev-research":0.3761597055,"prompt-eng":0.3126228353,"data-quality":0.0727336332,"ml-security":0.2213428202}}
{"text":"Finally, it was tested in network capacity, fault tolerance, and robustness.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.0976538003,"dev-research":0.409269772,"prompt-eng":0.3942750386,"data-quality":0.1945484407,"ml-security":0.2249606417}}
{"text":"It was found that the algorithm exhibits a larger network capacity in a more sparse network structure because the subgraph generated by a single sample is not a whole but consists of multiple weakly connected components.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.10131815,"dev-research":0.361029632,"prompt-eng":0.3411112582,"data-quality":0.1353295108,"ml-security":0.1037518183}}
{"text":"In this case, the network capacity can be understood as the number of permutations of several weakly connected components in the network.","meta":{"url":"http://arxiv.org/abs/2307.05869v1"},"cats":{"new-dataset":0.1014726099,"dev-research":0.3982326616,"prompt-eng":0.3613259016,"data-quality":0.0995164974,"ml-security":0.1068027876}}
{"text":"Machine learning is traditionally studied at the model level: researchers measure and improve the accuracy, robustness, bias, efficiency, and other dimensions of specific models.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.0683689386,"dev-research":0.3935354843,"prompt-eng":0.4513133821,"data-quality":0.1989024073,"ml-security":0.3560779687}}
{"text":"In practice, the societal impact of machine learning is determined by the surrounding context of machine learning deployments.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1043568706,"dev-research":0.4548047423,"prompt-eng":0.46784266,"data-quality":0.1838163098,"ml-security":0.5044874176}}
{"text":"To capture this, we introduce ecosystem-level analysis: rather than analyzing a single model, we consider the collection of models that are deployed in a given context.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1385147955,"dev-research":0.4368124363,"prompt-eng":0.4391599971,"data-quality":0.1198347438,"ml-security":0.1147062108}}
{"text":"For example, ecosystem-level analysis in hiring recognizes that a job candidate's outcomes are not only determined by a single hiring algorithm or firm but instead by the collective decisions of all the firms they applied to.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.0494781728,"dev-research":0.4451208251,"prompt-eng":0.3755396397,"data-quality":0.0909684122,"ml-security":0.1049439585}}
{"text":"Across three modalities (text, images, speech) and 11 datasets, we establish a clear trend: deployed machine learning is prone to systemic failure, meaning some users are exclusively misclassified by all models available.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1877427206,"dev-research":0.3898616413,"prompt-eng":0.5246972784,"data-quality":0.5090052865,"ml-security":0.5118089383}}
{"text":"Even when individual models improve at the population level over time, we find these improvements rarely reduce the prevalence of systemic failure.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.0406114234,"dev-research":0.4091885284,"prompt-eng":0.4522350777,"data-quality":0.2344835267,"ml-security":0.2591991046}}
{"text":"Instead, the benefits of these improvements predominantly accrue to individuals who are already correctly classified by other models.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.0259577971,"dev-research":0.4623072389,"prompt-eng":0.4314013078,"data-quality":0.1844654258,"ml-security":0.274382246}}
{"text":"In light of these trends, we consider medical imaging for dermatology where the costs of systemic failure are especially high.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1212409861,"dev-research":0.3720039554,"prompt-eng":0.4089092649,"data-quality":0.1832738775,"ml-security":0.1563384653}}
{"text":"While traditional analyses reveal racial performance disparities for both models and humans, ecosystem-level analysis reveals new forms of racial disparity in model predictions that do not present in human predictions.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1065963335,"dev-research":0.3889788019,"prompt-eng":0.4042106823,"data-quality":0.1148363246,"ml-security":0.1593331966}}
{"text":"These examples demonstrate ecosystem-level analysis has unique strengths for characterizing the societal impact of machine learning.","meta":{"url":"http://arxiv.org/abs/2307.05862v1"},"cats":{"new-dataset":0.1330525194,"dev-research":0.4450345624,"prompt-eng":0.4288362636,"data-quality":0.1779321757,"ml-security":0.3054546457}}
{"text":"Storing tabular data in a way that balances storage and query efficiencies is a long standing research question in the database community.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.3049662997,"dev-research":0.4139460071,"prompt-eng":0.390070809,"data-quality":0.065104961,"ml-security":0.1131487689}}
{"text":"While there are several lossless compression techniques in the literature, in this work we argue and show that a novel Deep Learned Data Mapping (or DeepMapping) abstraction, which relies on the impressive memorization capabilities of deep neural networks, can provide better storage cost, better latency, and better run-time memory footprint, all at the same time.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.3197470676,"dev-research":0.3968875589,"prompt-eng":0.4137194545,"data-quality":0.150682868,"ml-security":0.2605848136}}
{"text":"Our proposed DeepMapping abstraction transforms a data set into multiple key-value mappings and constructs a multi-tasking neural network model that outputs the corresponding values for a given input key.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.2827597206,"dev-research":0.411715768,"prompt-eng":0.4920876101,"data-quality":0.1112635814,"ml-security":0.1233830971}}
{"text":"In order to deal with the memorization errors, DeepMapping couples the learned neural network with a light-weight auxiliary data structure capable of correcting errors.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.1906198361,"dev-research":0.3982072119,"prompt-eng":0.4957560615,"data-quality":0.3535922555,"ml-security":0.2223814192}}
{"text":"The auxiliary structure further enables DeepMapping to efficiently deal with insertions, deletions, and updates, without having to re-train the mapping.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.177481591,"dev-research":0.4442458737,"prompt-eng":0.4525334057,"data-quality":0.1542372724,"ml-security":0.0971856938}}
{"text":"Since the shape of the network has a significant impact on the overall size of the DeepMapping structure, we further propose a multi-task hybrid architecture search strategy to identify DeepMapping architectures that strike a desirable balance among memorization capacity, size, and efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.1329957114,"dev-research":0.3658363762,"prompt-eng":0.4359333371,"data-quality":0.096637143,"ml-security":0.1360014285}}
{"text":"Extensive experiments with synthetic and benchmark datasets, including TPC-H and TPC-DS, demonstrated that the proposed DeepMapping approach can significantly reduce the latency of the key-based queries, while simultaneously improving both offline and run-time storage requirements against several cutting-edge competitors.","meta":{"url":"http://arxiv.org/abs/2307.05861v1"},"cats":{"new-dataset":0.4143116216,"dev-research":0.370640728,"prompt-eng":0.4209071183,"data-quality":0.0889259141,"ml-security":0.1746038387}}
{"text":"Achieving fairness in sequential-decision making systems within Human-in-the-Loop (HITL) environments is a critical concern, especially when multiple humans with different behavior and expectations are affected by the same adaptation decisions in the system.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.08862447,"dev-research":0.4466307673,"prompt-eng":0.4621304759,"data-quality":0.084445748,"ml-security":0.2269532011}}
{"text":"This human variability factor adds more complexity since policies deemed fair at one point in time may become discriminatory over time due to variations in human preferences resulting from inter- and intra-human variability.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.0672534894,"dev-research":0.43719791,"prompt-eng":0.3948525126,"data-quality":0.0843602546,"ml-security":0.1655392548}}
{"text":"This paper addresses the fairness problem from an equity lens, considering human behavior variability, and the changes in human preferences over time.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.0994496935,"dev-research":0.4139964522,"prompt-eng":0.4077409302,"data-quality":0.1025832392,"ml-security":0.2142416752}}
{"text":"We propose FAIRO, a novel algorithm for fairness-aware sequential-decision making in HITL adaptation, which incorporates these notions into the decision-making process.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.1050314307,"dev-research":0.4334588245,"prompt-eng":0.4381695932,"data-quality":0.1113195383,"ml-security":0.230840627}}
{"text":"In particular, FAIRO decomposes this complex fairness task into adaptive sub-tasks based on individual human preferences through leveraging the Options reinforcement learning framework.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.120412481,"dev-research":0.3997025411,"prompt-eng":0.4484966691,"data-quality":0.0686388837,"ml-security":0.2137687912}}
{"text":"We design FAIRO to generalize to three types of HITL application setups that have the shared adaptation decision problem.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.1026195015,"dev-research":0.4547903658,"prompt-eng":0.4510107251,"data-quality":0.1137972453,"ml-security":0.1911421357}}
{"text":"Furthermore, we recognize that fairness-aware policies can sometimes conflict with the application's utility.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.0679606185,"dev-research":0.4704206955,"prompt-eng":0.4312588566,"data-quality":0.1993497524,"ml-security":0.4289382099}}
{"text":"To address this challenge, we provide a fairness-utility tradeoff in FAIRO, allowing system designers to balance the objectives of fairness and utility based on specific application requirements.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.0946950574,"dev-research":0.4564822019,"prompt-eng":0.4106004321,"data-quality":0.0952986344,"ml-security":0.3154875944}}
{"text":"Extensive evaluations of FAIRO on the three HITL applications demonstrate its generalizability and effectiveness in promoting fairness while accounting for human variability.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.127483089,"dev-research":0.4385583311,"prompt-eng":0.4430896773,"data-quality":0.1195224921,"ml-security":0.2396116839}}
{"text":"On average, FAIRO can improve fairness compared with other methods across all three applications by 35.36%.","meta":{"url":"http://arxiv.org/abs/2307.05857v1"},"cats":{"new-dataset":0.0895736351,"dev-research":0.4124684157,"prompt-eng":0.3879029464,"data-quality":0.1090034007,"ml-security":0.1871949026}}
{"text":"3D human pose estimation has been researched for decades with promising fruits.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.3803350091,"dev-research":0.3763600068,"prompt-eng":0.3994975342,"data-quality":0.0708750198,"ml-security":0.1026391614}}
{"text":"3D human pose lifting is one of the promising research directions toward the task where both estimated pose and ground truth pose data are used for training.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.2088975719,"dev-research":0.3572668176,"prompt-eng":0.4399201375,"data-quality":0.0781800175,"ml-security":0.1630225257}}
{"text":"Existing pose lifting works mainly focus on improving the performance of estimated pose, but they usually underperform when testing on the ground truth pose data.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.1180486371,"dev-research":0.3496511922,"prompt-eng":0.4326443163,"data-quality":0.0993372619,"ml-security":0.1773169018}}
{"text":"We observe that the performance of the estimated pose can be easily improved by preparing good quality 2D pose, such as fine-tuning the 2D pose or using advanced 2D pose detectors.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.1270037242,"dev-research":0.3663595796,"prompt-eng":0.4266544273,"data-quality":0.1377657938,"ml-security":0.1176102172}}
{"text":"As such, we concentrate on improving the 3D human pose lifting via ground truth data for the future improvement of more quality estimated pose data.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.2849646773,"dev-research":0.3623670971,"prompt-eng":0.4384058454,"data-quality":0.1030606851,"ml-security":0.1485085982}}
{"text":"Towards this goal, a simple yet effective model called Global-local Adaptive Graph Convolutional Network (GLA-GCN) is proposed in this work.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.1156370411,"dev-research":0.3537999505,"prompt-eng":0.3762267736,"data-quality":0.1912951785,"ml-security":0.1042527451}}
{"text":"Our GLA-GCN globally models the spatiotemporal structure via a graph representation and backtraces local joint features for 3D human pose estimation via individually connected layers.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.2149265406,"dev-research":0.3564372112,"prompt-eng":0.4109519587,"data-quality":0.0849093567,"ml-security":0.0993778482}}
{"text":"To validate our model design, we conduct extensive experiments on three benchmark datasets: Human3.6M, HumanEva-I, and MPI-INF-3DHP.","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.3297539934,"dev-research":0.3684081654,"prompt-eng":0.4446196189,"data-quality":0.0648941312,"ml-security":0.08714381}}
{"text":"Experimental results show that our GLA-GCN implemented with ground truth 2D poses significantly outperforms state-of-the-art methods (e.g., up to around 3%, 17%, and 13% error reductions on Human3.6M, HumanEva-I, and MPI-INF-3DHP, respectively).","meta":{"url":"http://arxiv.org/abs/2307.05853v1"},"cats":{"new-dataset":0.0947372524,"dev-research":0.3550742556,"prompt-eng":0.3790519281,"data-quality":0.0969335004,"ml-security":0.1160471966}}
{"text":"The advent of a new breed of enhanced multimedia services has put network operators into a position where they must support innovative services while ensuring both end-to-end Quality of Service requirements and profitability.","meta":{"url":"http://arxiv.org/abs/2307.06488v1"},"cats":{"new-dataset":0.0784592567,"dev-research":0.4716338422,"prompt-eng":0.421993713,"data-quality":0.160523349,"ml-security":0.1088062215}}
{"text":"Recently, Network Function Virtualization (NFV) has been touted as a cost-effective underlying technology in 5G networks to efficiently provision novel services.","meta":{"url":"http://arxiv.org/abs/2307.06488v1"},"cats":{"new-dataset":0.0754781472,"dev-research":0.3965484511,"prompt-eng":0.3364167558,"data-quality":0.0883603268,"ml-security":0.1211322999}}
{"text":"These NFV-based services have been increasingly associated with multi-domain networks.","meta":{"url":"http://arxiv.org/abs/2307.06488v1"},"cats":{"new-dataset":0.144478469,"dev-research":0.3856918446,"prompt-eng":0.3779049924,"data-quality":0.1267600831,"ml-security":0.1206552938}}
{"text":"However, several orchestration issues, linked to cross-domain interactions and emphasized by the heterogeneity of underlying technologies and administrative authorities, present an important challenge.","meta":{"url":"http://arxiv.org/abs/2307.06488v1"},"cats":{"new-dataset":0.0765555562,"dev-research":0.4541353137,"prompt-eng":0.4427610651,"data-quality":0.1220003153,"ml-security":0.1134627364}}
{"text":"In this paper, we tackle the cross-domain interaction issue by proposing an intelligent and profitable auction-based approach to allow inter-domains resource allocation.","meta":{"url":"http://arxiv.org/abs/2307.06488v1"},"cats":{"new-dataset":0.0985632106,"dev-research":0.4233449246,"prompt-eng":0.4346020621,"data-quality":0.0759824283,"ml-security":0.1216934096}}
{"text":"In this paper, we present a novel Single-class target-specific Adversarial attack called SingleADV.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.0981200469,"dev-research":0.4044986739,"prompt-eng":0.4384034064,"data-quality":0.1959686132,"ml-security":0.8075655795}}
{"text":"The goal of SingleADV is to generate a universal perturbation that deceives the target model into confusing a specific category of objects with a target category while ensuring highly relevant and accurate interpretations.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.0515075377,"dev-research":0.4379060368,"prompt-eng":0.4543724128,"data-quality":0.1750104478,"ml-security":0.1918723527}}
{"text":"The universal perturbation is stochastically and iteratively optimized by minimizing the adversarial loss that is designed to consider both the classifier and interpreter costs in targeted and non-targeted categories.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.0487524064,"dev-research":0.4059809074,"prompt-eng":0.4653919763,"data-quality":0.3106984157,"ml-security":0.5400680927}}
{"text":"In this optimization framework, ruled by the first- and second-moment estimations, the desired loss surface promotes high confidence and interpretation score of adversarial samples.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.1050182737,"dev-research":0.3774760029,"prompt-eng":0.4755019958,"data-quality":0.2313503915,"ml-security":0.5390161412}}
{"text":"By avoiding unintended misclassification of samples from other categories, SingleADV enables more effective targeted attacks on interpretable deep learning systems in both white-box and black-box scenarios.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.1049588833,"dev-research":0.390861515,"prompt-eng":0.4565663032,"data-quality":0.2599112102,"ml-security":0.6931329713}}
{"text":"To evaluate the effectiveness of SingleADV, we conduct experiments using four different model architectures (ResNet-50, VGG-16, DenseNet-169, and Inception-V3) coupled with three interpretation models (CAM, Grad, and MASK).","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.0954578567,"dev-research":0.4040683502,"prompt-eng":0.4816971945,"data-quality":0.1452515869,"ml-security":0.1708726631}}
{"text":"Through extensive empirical evaluation, we demonstrate that SingleADV effectively deceives the target deep learning models and their associated interpreters under various conditions and settings.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.0859771562,"dev-research":0.4264181694,"prompt-eng":0.5124798695,"data-quality":0.2336024132,"ml-security":0.4340332421}}
{"text":"Our experimental results show that the performance of SingleADV is effective, with an average fooling ratio of 0.74 and an adversarial confidence level of 0.78 in generating deceptive adversarial samples.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.1187040083,"dev-research":0.4030140418,"prompt-eng":0.4517890239,"data-quality":0.2793129949,"ml-security":0.6247277747}}
{"text":"Furthermore, we discuss several countermeasures against SingleADV, including a transfer-based learning approach and existing preprocessing defenses.","meta":{"url":"http://arxiv.org/abs/2307.06484v1"},"cats":{"new-dataset":0.1039266103,"dev-research":0.4443326292,"prompt-eng":0.4541747499,"data-quality":0.1581657309,"ml-security":0.7308030186}}
{"text":"Automated classifiers (ACs), often built via supervised machine learning (SML), can categorize large, statistically powerful samples of data ranging from text to images and video, and have become widely popular measurement devices in communication science and related fields.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.2061869819,"dev-research":0.4071954952,"prompt-eng":0.5086766618,"data-quality":0.254733087,"ml-security":0.2875614463}}
{"text":"Despite this popularity, even highly accurate classifiers make errors that cause misclassification bias and misleading results in downstream analyses-unless such analyses account for these errors.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.0681546797,"dev-research":0.4276506593,"prompt-eng":0.4417240017,"data-quality":0.6474171016,"ml-security":0.3432037706}}
{"text":"As we show in a systematic literature review of SML applications, communication scholars largely ignore misclassification bias.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.0578199671,"dev-research":0.4548638193,"prompt-eng":0.4735292909,"data-quality":0.4092377775,"ml-security":0.1905603773}}
{"text":"In principle, existing statistical methods can use \"gold standard\" validation data, such as that created by human annotators, to correct misclassification bias and produce consistent estimates.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.1416545485,"dev-research":0.4137365426,"prompt-eng":0.4896505512,"data-quality":0.519157254,"ml-security":0.2312528659}}
{"text":"We introduce and test such methods, including a new method we design and implement in the R package misclassificationmodels, via Monte Carlo simulations designed to reveal each method's limitations, which we also release.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.1385263099,"dev-research":0.3689618045,"prompt-eng":0.4928779749,"data-quality":0.2827859288,"ml-security":0.1499426418}}
{"text":"Based on our results, we recommend our new error correction method as it is versatile and efficient.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.1405787833,"dev-research":0.4363413686,"prompt-eng":0.4487753735,"data-quality":0.5517950935,"ml-security":0.1028045804}}
{"text":"In sum, automated classifiers, even those below common accuracy standards or making systematic misclassifications, can be useful for measurement with careful study design and appropriate error correction methods.","meta":{"url":"http://arxiv.org/abs/2307.06483v1"},"cats":{"new-dataset":0.0658391943,"dev-research":0.414041913,"prompt-eng":0.4600654242,"data-quality":0.480697498,"ml-security":0.2015952665}}
{"text":"Physical interaction between individuals plays an important role in human motor learning and performance during shared tasks.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0937319078,"dev-research":0.4164240472,"prompt-eng":0.4270333728,"data-quality":0.0543188843,"ml-security":0.1261431941}}
{"text":"Using robotic devices, researchers have studied the effects of dyadic haptic interaction mostly focusing on the upper-limb.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0406234076,"dev-research":0.3787682752,"prompt-eng":0.4022898882,"data-quality":0.0509928708,"ml-security":0.0787933967}}
{"text":"Developing infrastructure that enables physical interactions between multiple individuals' lower limbs can extend the previous work and facilitate investigation of new dyadic lower-limb rehabilitation schemes.   ","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.1101270557,"dev-research":0.4069256921,"prompt-eng":0.3675241088,"data-quality":0.0459608996,"ml-security":0.0890326179}}
{"text":"We designed a system to render haptic interactions between two users while they walk in multi-joint lower-limb exoskeletons.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0849816498,"dev-research":0.392556805,"prompt-eng":0.418456465,"data-quality":0.0447004384,"ml-security":0.0848100268}}
{"text":"Specifically, we developed an infrastructure where desired interaction torques are commanded to the individual lower-limb exoskeletons based on the users' kinematics and the properties of the virtual coupling.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0569166717,"dev-research":0.395659732,"prompt-eng":0.4239501633,"data-quality":0.0411864932,"ml-security":0.1099035899}}
{"text":"In this pilot study, we demonstrated the capacity of the platform to render different haptic properties (e.g., soft and hard), different haptic connection types (e.g., bidirectional and unidirectional), and connections expressed in joint space and in task space.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0859766933,"dev-research":0.3798130478,"prompt-eng":0.3877200203,"data-quality":0.0368052143,"ml-security":0.056240871}}
{"text":"With haptic connection, dyads generated synchronized movement, and the difference between joint angles decreased as the virtual stiffness increased.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.0432274665,"dev-research":0.3936820966,"prompt-eng":0.3744486078,"data-quality":0.0765626795,"ml-security":0.0577560915}}
{"text":"This is the first study where multi-joint dyadic haptic interactions are created between lower-limb exoskeletons.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.063392821,"dev-research":0.3866195421,"prompt-eng":0.387362967,"data-quality":0.0536691051,"ml-security":0.0895347322}}
{"text":"This platform will be used to investigate effects of haptic interaction on motor learning and task performance during walking, a complex and meaningful task for gait rehabilitation.","meta":{"url":"http://arxiv.org/abs/2307.06479v1"},"cats":{"new-dataset":0.1739919067,"dev-research":0.3896413422,"prompt-eng":0.4322380384,"data-quality":0.0665234133,"ml-security":0.0753525976}}
{"text":"We present WiscSort, a new approach to high-performance concurrent sorting for existing and future byte-addressable storage (BAS) devices.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.1731975882,"dev-research":0.4155805044,"prompt-eng":0.3941282161,"data-quality":0.0712184625,"ml-security":0.0995862795}}
{"text":"WiscSort carefully reduces writes, exploits random reads by splitting keys and values during sorting, and performs interference-aware scheduling with thread pool sizing to avoid I/O bandwidth degradation.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.0913248886,"dev-research":0.4281312175,"prompt-eng":0.399943626,"data-quality":0.0709483162,"ml-security":0.1153001546}}
{"text":"We introduce the BRAID model which encompasses the unique characteristics of BAS devices.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.05647789,"dev-research":0.3958038881,"prompt-eng":0.4182701965,"data-quality":0.0946871125,"ml-security":0.0547920329}}
{"text":"Many state-of-the-art sorting systems do not comply with the BRAID model and deliver sub-optimal performance, whereas WiscSort demonstrates the effectiveness of complying with BRAID.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.0841570649,"dev-research":0.4086078015,"prompt-eng":0.3846710526,"data-quality":0.0739610986,"ml-security":0.0553042752}}
{"text":"We show that WiscSort is 2-7x faster than competing approaches on a standard sort benchmark.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.1018107672,"dev-research":0.4033041392,"prompt-eng":0.3626031004,"data-quality":0.0626214835,"ml-security":0.0862388453}}
{"text":"We evaluate the effectiveness of key-value separation on different key-value sizes and compare our concurrency optimizations with various other concurrency models.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.0899499713,"dev-research":0.4133930495,"prompt-eng":0.3872883221,"data-quality":0.0945305906,"ml-security":0.1156919771}}
{"text":"Finally, we emulate generic BAS devices and show how our techniques perform well with various combinations of hardware properties.","meta":{"url":"http://arxiv.org/abs/2307.06476v1"},"cats":{"new-dataset":0.0822888567,"dev-research":0.4041599484,"prompt-eng":0.4506785955,"data-quality":0.0645142654,"ml-security":0.075745145}}
{"text":"Autism Spectrum Disorder (ASD) has been emerging as a growing public health threat.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.1221499326,"dev-research":0.3979009375,"prompt-eng":0.4181389603,"data-quality":0.1005847886,"ml-security":0.2960212393}}
{"text":"Early diagnosis of ASD is crucial for timely, effective intervention and treatment.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.062322372,"dev-research":0.3986383028,"prompt-eng":0.4271170602,"data-quality":0.1258638465,"ml-security":0.08068048}}
{"text":"However, conventional diagnosis methods based on communications and behavioral patterns are unreliable for children younger than 2 years of age.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.0864108855,"dev-research":0.3927204007,"prompt-eng":0.4368596408,"data-quality":0.3081386109,"ml-security":0.1703309211}}
{"text":"Given evidences of neurodevelopmental abnormalities in ASD infants, we resort to a novel deep learning-based method to extract key features from the inherently scarce, class-imbalanced, and heterogeneous structural MR images for early autism diagnosis.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.181168212,"dev-research":0.3547998886,"prompt-eng":0.4243692106,"data-quality":0.1630236228,"ml-security":0.1639398051}}
{"text":"Specifically, we propose a Siamese verification framework to extend the scarce data, and an unsupervised compressor to alleviate data imbalance by extracting key features.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.2535872356,"dev-research":0.3731799995,"prompt-eng":0.442908031,"data-quality":0.2302068694,"ml-security":0.1991062161}}
{"text":"We also proposed weight constraints to cope with sample heterogeneity by giving different samples different voting weights during validation, and we used Path Signature to unravel meaningful developmental features from the two-time point data longitudinally.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.083400959,"dev-research":0.3561571722,"prompt-eng":0.4354421353,"data-quality":0.1660291737,"ml-security":0.1439740457}}
{"text":"Extensive experiments have shown that our method performed well under practical scenarios, transcending existing machine learning methods.","meta":{"url":"http://arxiv.org/abs/2307.06472v1"},"cats":{"new-dataset":0.0943501336,"dev-research":0.4124397389,"prompt-eng":0.4506737386,"data-quality":0.1700541374,"ml-security":0.3965427784}}
{"text":"By organizing knowledge within a research field, Systematic Reviews (SR) provide valuable leads to steer research.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.0984910249,"dev-research":0.4761299328,"prompt-eng":0.4379766614,"data-quality":0.1284861928,"ml-security":0.0519691717}}
{"text":"Evidence suggests that SRs have become first-class artifacts in software engineering.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.0750362384,"dev-research":0.5217599433,"prompt-eng":0.4512144077,"data-quality":0.1445968867,"ml-security":0.154738586}}
{"text":"However, the tedious manual effort associated with the screening phase of SRs renders these studies a costly and error-prone endeavor.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.0609397193,"dev-research":0.4114363666,"prompt-eng":0.4508517048,"data-quality":0.1735598877,"ml-security":0.1197937211}}
{"text":"While screening has traditionally been considered not amenable to automation, the advent of generative AI-driven chatbots, backed with large language models is set to disrupt the field.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.1715889551,"dev-research":0.4664758839,"prompt-eng":0.6052743751,"data-quality":0.1707540823,"ml-security":0.1869961108}}
{"text":"In this report, we propose an approach to leverage these novel technological developments for automating the screening of SRs.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.0692574238,"dev-research":0.4158078717,"prompt-eng":0.4903912718,"data-quality":0.1505247491,"ml-security":0.1436153881}}
{"text":"We assess the consistency, classification performance, and generalizability of ChatGPT in screening articles for SRs and compare these figures with those of traditional classifiers used in SR automation.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.148525866,"dev-research":0.4337838958,"prompt-eng":0.55948955,"data-quality":0.2522958305,"ml-security":0.1116893815}}
{"text":"Our results indicate that ChatGPT is a viable option to automate the SR processes, but requires careful considerations from developers when integrating ChatGPT into their SR tools.","meta":{"url":"http://arxiv.org/abs/2307.06464v1"},"cats":{"new-dataset":0.2064762732,"dev-research":0.4948291933,"prompt-eng":0.5431793399,"data-quality":0.1017923193,"ml-security":0.0709706731}}
{"text":"We advance the Cohn-Umans framework for developing fast matrix multiplication algorithms.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.0920524903,"dev-research":0.3891104159,"prompt-eng":0.3604652314,"data-quality":0.083502623,"ml-security":0.1238592138}}
{"text":"We introduce, analyze, and search for a new subclass of strong uniquely solvable puzzles (SUSP), which we call simplifiable SUSPs.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.2362314561,"dev-research":0.4230866987,"prompt-eng":0.3820025875,"data-quality":0.085158702,"ml-security":0.1904378073}}
{"text":"We show that these puzzles are efficiently verifiable, which remains an open question for general SUSPs.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.1213018916,"dev-research":0.4370549018,"prompt-eng":0.4271569973,"data-quality":0.1050326948,"ml-security":0.1536499882}}
{"text":"We also show that individual simplifiable SUSPs can achieve the same strength of bounds on the matrix multiplication exponent $\\omega$ that infinite families of SUSPs can.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.0855192661,"dev-research":0.3818859245,"prompt-eng":0.3669835233,"data-quality":0.0584544847,"ml-security":0.2406281328}}
{"text":"We report on the construction, by computer search, of larger SUSPs than previously known for small width.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.1456294126,"dev-research":0.4059123109,"prompt-eng":0.3865847812,"data-quality":0.0550924133,"ml-security":0.0781430023}}
{"text":"This, combined with our tighter analysis, strengthens the upper bound on the matrix multiplication exponent from $2.66$ to $2.505$ obtainable via this computational approach, and nears the results of the handcrafted constructions of Cohn et al.","meta":{"url":"http://arxiv.org/abs/2307.06463v1"},"cats":{"new-dataset":0.1059075016,"dev-research":0.4023220114,"prompt-eng":0.3582329483,"data-quality":0.0730510584,"ml-security":0.1524791441}}
{"text":"Understanding the spread of images across the web helps us understand the reuse of scientific visualizations and their relationship with the public.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.2509572445,"dev-research":0.4590286861,"prompt-eng":0.4324374933,"data-quality":0.1787752207,"ml-security":0.1266653573}}
{"text":"The \"Flatten the Curve\" graphic was heavily used during the COVID-19 pandemic to convey a complex concept in a simple form.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.2774151012,"dev-research":0.4392442942,"prompt-eng":0.4045016178,"data-quality":0.0849146338,"ml-security":0.1050841634}}
{"text":"It displays two curves comparing the impact on case loads for medical facilities if the populace either adopts or fails to adopt protective measures during a pandemic.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.2793568646,"dev-research":0.4553986698,"prompt-eng":0.4415279213,"data-quality":0.0799534789,"ml-security":0.2023142955}}
{"text":"We use five variants of the \"Flatten the Curve\" image as a case study for viewing the spread of an image online.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.3603433963,"dev-research":0.4010150825,"prompt-eng":0.4133792961,"data-quality":0.1176574737,"ml-security":0.0915276387}}
{"text":"To evaluate its spread, we leverage three information channels: reverse image search engines, social media, and web archives.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.2967450983,"dev-research":0.4383560389,"prompt-eng":0.491669963,"data-quality":0.1700394446,"ml-security":0.1718331006}}
{"text":"Reverse image searches give us a current view into image reuse.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.2580699656,"dev-research":0.4212530152,"prompt-eng":0.4598843792,"data-quality":0.1097401045,"ml-security":0.1419528781}}
{"text":"Social media helps us understand a variant's popularity over time.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.1931730733,"dev-research":0.4547652829,"prompt-eng":0.4597898117,"data-quality":0.1553063692,"ml-security":0.1526281855}}
{"text":"Web archives help us see when it was preserved, highlighting a view of popularity for future researchers.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.3849215245,"dev-research":0.4512787234,"prompt-eng":0.4201420129,"data-quality":0.1029553034,"ml-security":0.1029555943}}
{"text":"Our case study leverages document URLs can be used as a proxy for images when studying the spread of images online.","meta":{"url":"http://arxiv.org/abs/2307.06458v1"},"cats":{"new-dataset":0.1785069777,"dev-research":0.4319948986,"prompt-eng":0.4700528062,"data-quality":0.1460614176,"ml-security":0.231138941}}
{"text":"Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area.","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.06725234,"dev-research":0.379748053,"prompt-eng":0.4411285941,"data-quality":0.1330245799,"ml-security":0.2563884845}}
{"text":"We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution.","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.1741895113,"dev-research":0.4032669998,"prompt-eng":0.4537657787,"data-quality":0.3158664965,"ml-security":0.3223473307}}
{"text":"Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\\mathbb{E}[z \\mid x,y ]=","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.1195630151,"dev-research":0.3801016468,"prompt-eng":0.4669243891,"data-quality":0.3804346568,"ml-security":0.1027755762}}
{"text":"\\langle f_{\\star}(x),g_{\\star}(y)\\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.   ","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.0855544608,"dev-research":0.3832506447,"prompt-eng":0.4307978257,"data-quality":0.1933792316,"ml-security":0.1787327855}}
{"text":"Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results require the ground-truth matrices to be either exactly low-rank, or to exhibit very sharp spectral cutoffs.","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.1056783072,"dev-research":0.3512454793,"prompt-eng":0.4332686908,"data-quality":0.265438339,"ml-security":0.1597618286}}
{"text":"In this work, we develop a series of theoretical results that enable bilinear combinatorial extrapolation under gradual spectral decay as observed in typical high-dimensional data, including novel algorithms, generalization guarantees, and linear-algebraic results.","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.1339599139,"dev-research":0.3677139168,"prompt-eng":0.343463159,"data-quality":0.1140445826,"ml-security":0.1607123528}}
{"text":"A key tool is a novel perturbation bound for the rank-$k$ singular value decomposition approximations between two matrices that depends on the relative spectral gap rather than the absolute spectral gap, a result that may be of broader independent interest.","meta":{"url":"http://arxiv.org/abs/2307.06457v1"},"cats":{"new-dataset":0.0551472921,"dev-research":0.3995303414,"prompt-eng":0.3777653004,"data-quality":0.1644498353,"ml-security":0.1736389408}}
{"text":"Efforts to secure computing systems via software traditionally focus on the operating system and application levels.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0595805736,"dev-research":0.5288379948,"prompt-eng":0.4210482091,"data-quality":0.0641676529,"ml-security":0.4429577873}}
{"text":"In contrast, the Security Protocol and Data Model (SPDM) tackles firmware level security challenges, which are much harder (if at all possible) to detect with regular protection software.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0841691763,"dev-research":0.4219195501,"prompt-eng":0.4329609525,"data-quality":0.0801112666,"ml-security":0.4437329808}}
{"text":"SPDM includes key features like enabling peripheral authentication, authenticated hardware measurements retrieval, and secure session establishment.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0575887806,"dev-research":0.4269461808,"prompt-eng":0.4745983154,"data-quality":0.0625490867,"ml-security":0.1819105615}}
{"text":"Since SPDM is a relatively recent proposal, there is a lack of studies evaluating its performance impact on real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0358218569,"dev-research":0.4125371269,"prompt-eng":0.3870933535,"data-quality":0.1038802147,"ml-security":0.1553345636}}
{"text":"In this article, we address this gap by: (1) implementing the protocol on a simple virtual device, and then investigating the overhead introduced by each SDPM message; and (2) creating an SPDM-capable virtual hard drive based on VirtIO, and comparing the resulting read/write performance with a regular, unsecured implementation.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.1188201556,"dev-research":0.4042325507,"prompt-eng":0.4244959648,"data-quality":0.0709250975,"ml-security":0.1589269339}}
{"text":"Our results suggest that SPDM bootstrap time takes the order of tens of milliseconds, while the toll of introducing SPDM on hard drive communication highly depends on specific workload patterns.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0673609959,"dev-research":0.4046640149,"prompt-eng":0.4279202185,"data-quality":0.0707683054,"ml-security":0.1413153967}}
{"text":"For example, for mixed random read/write operations, the slowdown is negligible in comparison to the baseline unsecured setup.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0477456281,"dev-research":0.3976049049,"prompt-eng":0.3799445261,"data-quality":0.086181527,"ml-security":0.2657284479}}
{"text":"Conversely, for sequential read or write operations, the data encryption process becomes the bottleneck, reducing the performance indicators by several orders of magnitude.","meta":{"url":"http://arxiv.org/abs/2307.06456v1"},"cats":{"new-dataset":0.0720999156,"dev-research":0.4249043137,"prompt-eng":0.377488094,"data-quality":0.0631901534,"ml-security":0.2611908687}}
{"text":"Primal logic arose in access control; it has a remarkably efficient (linear time) decision procedure for its entailment problem.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.0571293302,"dev-research":0.4653029235,"prompt-eng":0.3927646525,"data-quality":0.0473117577,"ml-security":0.1680977787}}
{"text":"But primal logic is a general logic of information.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.0854706203,"dev-research":0.4572440737,"prompt-eng":0.4074540881,"data-quality":0.089643108,"ml-security":0.1626375169}}
{"text":"In the realm of arbitrary items of information (infons), conjunction, disjunction, and implication may seem to correspond (set-theoretically) to union, intersection, and relative complementation.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.2070332007,"dev-research":0.4858115241,"prompt-eng":0.4536147005,"data-quality":0.1552451577,"ml-security":0.1398745566}}
{"text":"But, while infons are closed under union, they are not closed under intersection or relative complementation.   ","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.1352955238,"dev-research":0.4553792196,"prompt-eng":0.405954672,"data-quality":0.258505447,"ml-security":0.148407926}}
{"text":"It turns out that there is a systematic transformation of propositional intuitionistic calculi to the original (propositional) primal calculi; we call it Flatting.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.0710498393,"dev-research":0.4672253378,"prompt-eng":0.4310543926,"data-quality":0.0939998941,"ml-security":0.1001341083}}
{"text":"We extend Flatting to quantifier rules, obtaining arguably the right quantified primal logic, QPL.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.0979180258,"dev-research":0.4338022867,"prompt-eng":0.4181970689,"data-quality":0.117590716,"ml-security":0.1418778731}}
{"text":"The QPL entailment problem is exponential-time complete, but it is polynomial-time complete in the case, of importance to applications (at least to access control), where the number of quantifiers is bounded.","meta":{"url":"http://arxiv.org/abs/2307.06454v1"},"cats":{"new-dataset":0.1145788105,"dev-research":0.4195106455,"prompt-eng":0.3974525289,"data-quality":0.060862122,"ml-security":0.1114392824}}
{"text":"Parametricity is a property of the syntax of type theory implying e.g. that there is only one function having the type of the polymorphic identity function.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0730899228,"dev-research":0.4410381146,"prompt-eng":0.3880789831,"data-quality":0.0659178713,"ml-security":0.1335015839}}
{"text":"Parametricity is usually proven externally, and does not hold internally.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0793225558,"dev-research":0.4093061528,"prompt-eng":0.363103512,"data-quality":0.1051918624,"ml-security":0.1064607561}}
{"text":"Internalising it is difficult because once there is a term witnessing parametricity, it also has to be parametric itself and this results in the appearance of higher dimensional cubes.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0458868505,"dev-research":0.4221857637,"prompt-eng":0.3590925671,"data-quality":0.0598526634,"ml-security":0.0895697452}}
{"text":"In previous theories with internal parametricity, either an explicit syntax for higher cubes is present or the theory is extended with a new sort for the interval.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0721815133,"dev-research":0.4350758406,"prompt-eng":0.3545110162,"data-quality":0.0593725175,"ml-security":0.0689292778}}
{"text":"In this paper we present a type theory with internal parametricity which is a simple extension of Martin-L\\\"of type thoery: there are a few new type formers, term formers and equations.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0879088936,"dev-research":0.4426156523,"prompt-eng":0.4046671447,"data-quality":0.1008777261,"ml-security":0.1075565605}}
{"text":"Geometry is not explicit in this syntax, but emergent: the new operations and equations only refer to objects up to dimension 3.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.1146333411,"dev-research":0.4859519236,"prompt-eng":0.3578371338,"data-quality":0.0775725972,"ml-security":0.0781171087}}
{"text":"We show that this theory is modelled by presheaves over the BCH cube category.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.090167774,"dev-research":0.4004719928,"prompt-eng":0.4347060241,"data-quality":0.0750443942,"ml-security":0.1038339435}}
{"text":"Fibrancy conditions are not needed because we use span-based rather than relational parametricity.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0385507796,"dev-research":0.3977576996,"prompt-eng":0.3823954509,"data-quality":0.0838036035,"ml-security":0.0678599998}}
{"text":"We define a gluing model for this theory implying that external parametricity and canonicity hold.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0352479107,"dev-research":0.3972758083,"prompt-eng":0.4361418189,"data-quality":0.1349639698,"ml-security":0.1050250884}}
{"text":"The theory can be seen as a special case of a new kind of modal type theory, and it is the simplest setting in which the computational properties of higher observational type theory can be demonstrated.","meta":{"url":"http://arxiv.org/abs/2307.06448v1"},"cats":{"new-dataset":0.0406452378,"dev-research":0.3832399529,"prompt-eng":0.404515166,"data-quality":0.0781382586,"ml-security":0.084243691}}
{"text":"Video frame interpolation is an increasingly important research task with several key industrial applications in the video coding, broadcast and production sectors.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.1401860776,"dev-research":0.4039119546,"prompt-eng":0.3973341432,"data-quality":0.1649730594,"ml-security":0.0371617474}}
{"text":"Recently, transformers have been introduced to the field resulting in substantial performance gains.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.0560765294,"dev-research":0.4072024521,"prompt-eng":0.3988460699,"data-quality":0.0458421395,"ml-security":0.090265134}}
{"text":"However, this comes at a cost of greatly increased memory usage, training and inference time.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.0550304439,"dev-research":0.4327690985,"prompt-eng":0.4454150394,"data-quality":0.0859152031,"ml-security":0.1725011647}}
{"text":"In this paper, a novel method integrating a transformer encoder and convolutional features is proposed.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.0971701505,"dev-research":0.3819810915,"prompt-eng":0.3894511677,"data-quality":0.131955508,"ml-security":0.1045232953}}
{"text":"This network reduces the memory burden by close to 50% and runs up to four times faster during inference time compared to existing transformer-based interpolation methods.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.1257102075,"dev-research":0.359084965,"prompt-eng":0.4137541951,"data-quality":0.0607831658,"ml-security":0.0930494757}}
{"text":"A dual-encoder architecture is introduced which combines the strength of convolutions in modelling local correlations with those of the transformer for long-range dependencies.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.1376559165,"dev-research":0.3543429226,"prompt-eng":0.4242140582,"data-quality":0.1293916313,"ml-security":0.1092479265}}
{"text":"Quantitative evaluations are conducted on various benchmarks with complex motion to showcase the robustness of the proposed method, achieving competitive performance compared to state-of-the-art interpolation networks.","meta":{"url":"http://arxiv.org/abs/2307.06443v1"},"cats":{"new-dataset":0.1369179875,"dev-research":0.3348833494,"prompt-eng":0.3642800254,"data-quality":0.0764400237,"ml-security":0.0379418747}}
{"text":"We study sensor/agent data collection and collaboration policies for parameter estimation, accounting for resource constraints and correlation between observations collected by distinct sensors/agents.","meta":{"url":"http://arxiv.org/abs/2307.06442v1"},"cats":{"new-dataset":0.353776517,"dev-research":0.3917863322,"prompt-eng":0.4693664266,"data-quality":0.0772795716,"ml-security":0.1407897765}}
{"text":"Specifically, we consider a group of sensors/agents each samples from different variables of a multivariate Gaussian distribution and has different estimation objectives, and we formulate a sensor/agent's data collection and collaboration policy design problem as a Fisher information maximization (or Cramer-Rao bound minimization) problem.","meta":{"url":"http://arxiv.org/abs/2307.06442v1"},"cats":{"new-dataset":0.2061935711,"dev-research":0.3546799405,"prompt-eng":0.4383523927,"data-quality":0.0980727654,"ml-security":0.2033006591}}
{"text":"When the knowledge of correlation between variables is available, we analytically identify two particular scenarios: (1) where the knowledge of the correlation between samples cannot be leveraged for collaborative estimation purposes and (2) where the optimal data collection policy involves investing scarce resources to collaboratively sample and transfer information that is not of immediate interest and whose statistics are already known, with the sole goal of increasing the confidence on the estimate of the parameter of interest.","meta":{"url":"http://arxiv.org/abs/2307.06442v1"},"cats":{"new-dataset":0.2576402704,"dev-research":0.3874377051,"prompt-eng":0.4404810407,"data-quality":0.1280945004,"ml-security":0.1868875169}}
{"text":"When the knowledge of certain correlation is unavailable but collaboration may still be worthwhile, we propose novel ways to apply multi-armed bandit algorithms to learn the optimal data collection and collaboration policy in our distributed parameter estimation problem and demonstrate that the proposed algorithms, DOUBLE-F, DOUBLE-Z, UCB-F, UCB-Z, are effective through simulations.","meta":{"url":"http://arxiv.org/abs/2307.06442v1"},"cats":{"new-dataset":0.1697141401,"dev-research":0.3721212663,"prompt-eng":0.478056499,"data-quality":0.1081603345,"ml-security":0.2690956883}}
{"text":"The computation necessary for training Transformer-based language models has skyrocketed in recent years.","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.128855002,"dev-research":0.4041384362,"prompt-eng":0.5170766307,"data-quality":0.2319045742,"ml-security":0.2333047179}}
{"text":"This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training.","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.0566679728,"dev-research":0.3726581753,"prompt-eng":0.3750977805,"data-quality":0.0951300998,"ml-security":0.1751176339}}
{"text":"In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia).","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.0478237432,"dev-research":0.3500077535,"prompt-eng":0.3938352275,"data-quality":0.058069038,"ml-security":0.1261861451}}
{"text":"When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate.","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.1058954673,"dev-research":0.4317666184,"prompt-eng":0.4643926421,"data-quality":0.1667686086,"ml-security":0.2246315103}}
{"text":"We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time.","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.097114679,"dev-research":0.4533893988,"prompt-eng":0.4395229692,"data-quality":0.0794784319,"ml-security":0.1689444181}}
{"text":"We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.","meta":{"url":"http://arxiv.org/abs/2307.06440v1"},"cats":{"new-dataset":0.1116355247,"dev-research":0.4450611609,"prompt-eng":0.445824011,"data-quality":0.1549712896,"ml-security":0.2228819085}}
{"text":"Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1754194632,"dev-research":0.4341490063,"prompt-eng":0.5563626545,"data-quality":0.0928945953,"ml-security":0.1245573258}}
{"text":"In this paper, we study how LLMs can be used to scale biomedical knowledge curation.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1152852362,"dev-research":0.4557891731,"prompt-eng":0.4967697294,"data-quality":0.1190198038,"ml-security":0.1409849964}}
{"text":"We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.   ","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1154745916,"dev-research":0.4318951699,"prompt-eng":0.5599492017,"data-quality":0.1508593063,"ml-security":0.1901246965}}
{"text":"We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1285808829,"dev-research":0.4540992851,"prompt-eng":0.4703559214,"data-quality":0.2102485291,"ml-security":0.1850672193}}
{"text":"On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1181819122,"dev-research":0.411642178,"prompt-eng":0.5178355789,"data-quality":0.2124287332,"ml-security":0.1102205729}}
{"text":"Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.   ","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1054321597,"dev-research":0.3958891396,"prompt-eng":0.4368210283,"data-quality":0.1949871579,"ml-security":0.1456854984}}
{"text":"Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT) and ADE extraction architecture shed light on best practice for biomedical knowledge extraction.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1311725177,"dev-research":0.4129557565,"prompt-eng":0.4659764645,"data-quality":0.1449083281,"ml-security":0.073121675}}
{"text":"Similar gains were attained by distillation for other standard biomedical knowledge extraction tasks such as gene-disease associations and protected health information, further illustrating the promise of this approach.","meta":{"url":"http://arxiv.org/abs/2307.06439v1"},"cats":{"new-dataset":0.1949392358,"dev-research":0.4464032498,"prompt-eng":0.4469276682,"data-quality":0.1216844185,"ml-security":0.1365608826}}
{"text":"This paper presents the main features of a system that aims to transform regular expressions into shorter equivalent expressions.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0814161216,"dev-research":0.4469565716,"prompt-eng":0.4549605832,"data-quality":0.2523358188,"ml-security":0.1251919287}}
{"text":"The system is also capable of computing other operations useful for simplification, such as checking the inclusion of regular languages.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0413727626,"dev-research":0.4929625353,"prompt-eng":0.4352647277,"data-quality":0.1408850584,"ml-security":0.1210028934}}
{"text":"The main novelty of this work is that it combines known but distinct ways of representing regular languages into a global unified data structure that makes the operations more efficient.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.1832465361,"dev-research":0.4523544328,"prompt-eng":0.4535741236,"data-quality":0.1617423297,"ml-security":0.1352507949}}
{"text":"In addition, representations of regular languages are dynamically reduced as operations are performed on them.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0367331064,"dev-research":0.4656760927,"prompt-eng":0.4335830824,"data-quality":0.164846097,"ml-security":0.1936680355}}
{"text":"Expressions are normalized and represented by a unique identifier (an integer).","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0764700706,"dev-research":0.4804578696,"prompt-eng":0.400509443,"data-quality":0.1852200578,"ml-security":0.1371711642}}
{"text":"Expressions found to be equivalent (i.e. denoting the same regular language) are grouped into equivalence classes from which a shortest representative is chosen.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0940341845,"dev-research":0.4313294373,"prompt-eng":0.4328363034,"data-quality":0.1956607691,"ml-security":0.0950702096}}
{"text":"The article briefly describes the main algorithms working on the global data structure.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.3505619819,"dev-research":0.3834614874,"prompt-eng":0.3757523168,"data-quality":0.1074334458,"ml-security":0.1125332515}}
{"text":"Some of them are direct adaptations of well-known algorithms, but most of them incorporate new ideas, which are really necessary to make the system efficient.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0494236142,"dev-research":0.4805121594,"prompt-eng":0.3540429139,"data-quality":0.0748184404,"ml-security":0.1787542115}}
{"text":"Finally, to show its usefulness, the system is applied to some examples from the literature.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.0968662336,"dev-research":0.4675769757,"prompt-eng":0.428307002,"data-quality":0.1426953743,"ml-security":0.1164949275}}
{"text":"Statistics on randomly generated sets of expressions are also provided.","meta":{"url":"http://arxiv.org/abs/2307.06436v1"},"cats":{"new-dataset":0.3582871691,"dev-research":0.4645375345,"prompt-eng":0.506169367,"data-quality":0.2366121484,"ml-security":0.11457238}}
{"text":"Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.0824613391,"dev-research":0.4205389214,"prompt-eng":0.5708657259,"data-quality":0.1425473007,"ml-security":0.1622027102}}
{"text":"These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.1230113464,"dev-research":0.3725280376,"prompt-eng":0.4778934558,"data-quality":0.1115626133,"ml-security":0.1862700097}}
{"text":"Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.056548526,"dev-research":0.4248025717,"prompt-eng":0.5206102873,"data-quality":0.1695688561,"ml-security":0.2559110557}}
{"text":"This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.1395021355,"dev-research":0.3608627612,"prompt-eng":0.5408169091,"data-quality":0.1009484011,"ml-security":0.2045087248}}
{"text":"Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.0833893734,"dev-research":0.4402822434,"prompt-eng":0.5211155913,"data-quality":0.0619381325,"ml-security":0.1310272814}}
{"text":"Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strategies for developing advanced LLMs.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.0537707725,"dev-research":0.4320849967,"prompt-eng":0.5092387384,"data-quality":0.0504123731,"ml-security":0.1273709821}}
{"text":"Given the continuous advancements in LLMs, we intend to regularly update this paper by incorporating new sections and featuring the latest LLM models.","meta":{"url":"http://arxiv.org/abs/2307.06435v1"},"cats":{"new-dataset":0.067893268,"dev-research":0.3713025734,"prompt-eng":0.5460088232,"data-quality":0.0761024683,"ml-security":0.1070885296}}
{"text":"Scientific institutions play a crucial role in driving intellectual, social, and technological progress.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.1323953719,"dev-research":0.4302852351,"prompt-eng":0.3795708397,"data-quality":0.095151128,"ml-security":0.0875234577}}
{"text":"Their capacity to innovate depends mainly on their ability to attract, retain, and nurture scientific talent and ultimately make it available to other organizations, industries, or the economy.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.1104227757,"dev-research":0.4565872235,"prompt-eng":0.3962603911,"data-quality":0.0866001811,"ml-security":0.0775123768}}
{"text":"As researchers change institutions during their careers, their skills are also transferred.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.1290142065,"dev-research":0.4457925693,"prompt-eng":0.4254393582,"data-quality":0.0958086523,"ml-security":0.1253605728}}
{"text":"The extent and mechanisms by which academic institutions manage their internal portfolio of scientific skills by attracting and sending researchers are far from being understood.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.0967030841,"dev-research":0.4415500337,"prompt-eng":0.3738312455,"data-quality":0.1156220845,"ml-security":0.1553682286}}
{"text":"We examine 25 million publication histories of 9.2 million scientists extracted from a large-scale bibliographic database covering thousands of research institutions worldwide to understand how the skills of mobile scientists align with those present in-house.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.4387880081,"dev-research":0.4232018191,"prompt-eng":0.4701414835,"data-quality":0.0973893879,"ml-security":0.097808734}}
{"text":"We find a clear association between top-ranked institutions and greater skill alignment, i.e., the degree to which skills of incoming academics match those of their colleagues at the institution.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.0956273235,"dev-research":0.4425649853,"prompt-eng":0.4381743329,"data-quality":0.1048923478,"ml-security":0.0937079386}}
{"text":"We uncover similar high-alignment for scientists leaving top-ranked institutions.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.1539931932,"dev-research":0.4085089761,"prompt-eng":0.4236443335,"data-quality":0.1418477923,"ml-security":0.0892113571}}
{"text":"This type of academic alignment is more pronounced in engineering and life, health, earth, and physical sciences than in mathematics, computer science, social sciences, and the humanities.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.1214157069,"dev-research":0.4261878613,"prompt-eng":0.3768456042,"data-quality":0.1172099605,"ml-security":0.066496064}}
{"text":"We show that over the past two decades, institutions generally have become more closely aligned in their overall skill profiles.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.0836079541,"dev-research":0.4268086618,"prompt-eng":0.4063993218,"data-quality":0.0989357509,"ml-security":0.0992037578}}
{"text":"We interpret these results in terms of levels of proactive management of the composition of the scientific workforce, diversity, and internal collaboration strategies at the institutional level.","meta":{"url":"http://arxiv.org/abs/2307.06426v1"},"cats":{"new-dataset":0.13930012,"dev-research":0.4499934941,"prompt-eng":0.4034275305,"data-quality":0.1289304021,"ml-security":0.0514176291}}
{"text":"Bimanual manipulation with tactile feedback will be key to human-level robot dexterity.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.0600403418,"dev-research":0.4048303372,"prompt-eng":0.4408899253,"data-quality":0.0500051596,"ml-security":0.0610712517}}
{"text":"However, this topic is less explored than single-arm settings, partly due to the availability of suitable hardware along with the complexity of designing effective controllers for tasks with relatively large state-action spaces.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.0442504395,"dev-research":0.3944069162,"prompt-eng":0.3926571416,"data-quality":0.026847309,"ml-security":0.0969168551}}
{"text":"Here we introduce a dual-arm tactile robotic system (Bi-Touch) based on the Tactile Gym 2.0 setup that integrates two affordable industrial-level robot arms with low-cost high-resolution tactile sensors (TacTips).","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.1685952134,"dev-research":0.3795504169,"prompt-eng":0.4560845496,"data-quality":0.0759804319,"ml-security":0.121361684}}
{"text":"We present a suite of bimanual manipulation tasks tailored towards tactile feedback: bi-pushing, bi-reorienting and bi-gathering.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.0844251912,"dev-research":0.3955880882,"prompt-eng":0.451788996,"data-quality":0.0515599318,"ml-security":0.0432774405}}
{"text":"To learn effective policies, we introduce appropriate reward functions for these tasks and propose a novel goal-update mechanism with deep reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.1902882605,"dev-research":0.4062868773,"prompt-eng":0.484094312,"data-quality":0.0972773563,"ml-security":0.1952680959}}
{"text":"We also apply these policies to real-world settings with a tactile sim-to-real approach.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.1160191015,"dev-research":0.4441318189,"prompt-eng":0.4366499672,"data-quality":0.0918380184,"ml-security":0.2024369684}}
{"text":"Our analysis highlights and addresses some challenges met during the sim-to-real application, e.g. the learned policy tended to squeeze an object in the bi-reorienting task due to the sim-to-real gap.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.1083531123,"dev-research":0.4173024247,"prompt-eng":0.4016936144,"data-quality":0.109553485,"ml-security":0.1437889156}}
{"text":"Finally, we demonstrate the generalizability and robustness of this system by experimenting with different unseen objects with applied perturbations in the real world.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.0748837397,"dev-research":0.3675099594,"prompt-eng":0.3723412732,"data-quality":0.1562705663,"ml-security":0.2763828201}}
{"text":"Code and videos are available at https://sites.google.com/view/bi-touch/.","meta":{"url":"http://arxiv.org/abs/2307.06423v1"},"cats":{"new-dataset":0.5305283401,"dev-research":0.4733437484,"prompt-eng":0.4677459869,"data-quality":0.0722015911,"ml-security":0.0654916852}}
{"text":"Graph learning methods, such as Graph Neural Networks (GNNs) based on graph convolutions, are highly successful in solving real-world learning problems involving graph-structured data.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2185506176,"dev-research":0.3645132288,"prompt-eng":0.3800666387,"data-quality":0.2394873185,"ml-security":0.1916031244}}
{"text":"However, graph learning methods expose sensitive user information and interactions not only through their model parameters but also through their model predictions.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.0966401413,"dev-research":0.425680465,"prompt-eng":0.4507891021,"data-quality":0.1877542315,"ml-security":0.5296014217}}
{"text":"Consequently, standard Differential Privacy (DP) techniques that merely offer model weight privacy are inadequate.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.0621224981,"dev-research":0.3964555524,"prompt-eng":0.3826403213,"data-quality":0.1326484029,"ml-security":0.5325654359}}
{"text":"This is especially the case for node predictions that leverage neighboring node attributes directly via graph convolutions that create additional risks of privacy leakage.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.1043597924,"dev-research":0.4193196066,"prompt-eng":0.4259088698,"data-quality":0.2650334066,"ml-security":0.5959001852}}
{"text":"To address this problem, we introduce Graph Differential Privacy (GDP), a new formal DP framework tailored to graph learning settings that ensures both provably private model parameters and predictions.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2949145368,"dev-research":0.4033461395,"prompt-eng":0.4136969028,"data-quality":0.1336786761,"ml-security":0.6365212066}}
{"text":"Furthermore, since there may be different privacy requirements for the node attributes and graph structure, we introduce a novel notion of relaxed node-level data adjacency.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2376103638,"dev-research":0.421289482,"prompt-eng":0.3811149603,"data-quality":0.1511253688,"ml-security":0.4722293833}}
{"text":"This relaxation can be used for establishing guarantees for different degrees of graph topology privacy while maintaining node attribute privacy.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.0740143518,"dev-research":0.4344331955,"prompt-eng":0.3604051188,"data-quality":0.1156225341,"ml-security":0.3751237835}}
{"text":"Importantly, this relaxation reveals a useful trade-off between utility and topology privacy for graph learning methods.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.1227189801,"dev-research":0.4057128597,"prompt-eng":0.3676157655,"data-quality":0.1569213505,"ml-security":0.4598142226}}
{"text":"In addition, our analysis of GDP reveals that existing DP-GNNs fail to exploit this trade-off due to the complex interplay between graph topology and attribute data in standard graph convolution designs.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2464827808,"dev-research":0.3570134842,"prompt-eng":0.3823964521,"data-quality":0.1820731998,"ml-security":0.1823920327}}
{"text":"To mitigate this problem, we introduce the Differentially Private Decoupled Graph Convolution (DPDGC) model, which benefits from decoupled graph convolution while providing GDP guarantees.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2647626225,"dev-research":0.359914433,"prompt-eng":0.3628616079,"data-quality":0.1291193906,"ml-security":0.3652599729}}
{"text":"Extensive experiments on seven node classification benchmarking datasets demonstrate the superior privacy-utility trade-off of DPDGC over existing DP-GNNs based on standard graph convolution design.","meta":{"url":"http://arxiv.org/abs/2307.06422v1"},"cats":{"new-dataset":0.2769281417,"dev-research":0.3570811162,"prompt-eng":0.386994767,"data-quality":0.1917956047,"ml-security":0.4675377727}}
{"text":"Automatic and accurate segmentation of colon polyps is essential for early diagnosis of colorectal cancer.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.1481842324,"dev-research":0.3762634612,"prompt-eng":0.4547387242,"data-quality":0.1728900629,"ml-security":0.0636413723}}
{"text":"Advanced deep learning models have shown promising results in polyp segmentation.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.1228798881,"dev-research":0.345342756,"prompt-eng":0.4506878771,"data-quality":0.1422741768,"ml-security":0.1544077429}}
{"text":"However, they still have limitations in representing multi-scale features and generalization capability.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.0606775391,"dev-research":0.3908447624,"prompt-eng":0.3717372671,"data-quality":0.0902102217,"ml-security":0.1258890396}}
{"text":"To address these issues, this paper introduces RaBiT, an encoder-decoder model that incorporates a lightweight Transformer-based architecture in the encoder to model multiple-level global semantic relationships.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.2077480243,"dev-research":0.4313691364,"prompt-eng":0.4959704679,"data-quality":0.164721231,"ml-security":0.1146402387}}
{"text":"The decoder consists of several bidirectional feature pyramid layers with reverse attention modules to better fuse feature maps at various levels and incrementally refine polyp boundaries.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.1258782922,"dev-research":0.4472883892,"prompt-eng":0.498132595,"data-quality":0.1119879587,"ml-security":0.1341251279}}
{"text":"We also propose ideas to lighten the reverse attention module and make it more suitable for multi-class segmentation.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.1927997736,"dev-research":0.3900572247,"prompt-eng":0.5190338483,"data-quality":0.2744746627,"ml-security":0.1375973112}}
{"text":"Extensive experiments on several benchmark datasets show that our method outperforms existing methods across all datasets while maintaining low computational complexity.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.4332641379,"dev-research":0.3786963652,"prompt-eng":0.3833956505,"data-quality":0.1960337165,"ml-security":0.1445104136}}
{"text":"Moreover, our method demonstrates high generalization capability in cross-dataset experiments, even when the training and test sets have different characteristics.","meta":{"url":"http://arxiv.org/abs/2307.06420v1"},"cats":{"new-dataset":0.2449501018,"dev-research":0.3846527265,"prompt-eng":0.4706251158,"data-quality":0.1591169755,"ml-security":0.2206452656}}
{"text":"The study of semantic relationships has revealed a close connection between these relationships and the morphological characteristics of a language.","meta":{"url":"http://arxiv.org/abs/2307.06419v1"},"cats":{"new-dataset":0.1415149295,"dev-research":0.4573607891,"prompt-eng":0.491339768,"data-quality":0.2998286837,"ml-security":0.0720817224}}
{"text":"Morphology, as a subfield of linguistics, investigates the internal structure and formation of words.","meta":{"url":"http://arxiv.org/abs/2307.06419v1"},"cats":{"new-dataset":0.1302146507,"dev-research":0.4439109857,"prompt-eng":0.4619631184,"data-quality":0.2816427154,"ml-security":0.0687941361}}
{"text":"By delving into the relationship between semantic relationships and language morphology, we can gain deeper insights into how the underlying structure of words contributes to the interpretation and comprehension of language.","meta":{"url":"http://arxiv.org/abs/2307.06419v1"},"cats":{"new-dataset":0.1271812469,"dev-research":0.4551845472,"prompt-eng":0.4851119297,"data-quality":0.2555183804,"ml-security":0.0801546284}}
{"text":"This paper explores the dynamic interplay between semantic relationships and the morphological aspects of different languages, by examining the intricate relationship between language morphology and semantic relationships, valuable insights can be gained regarding how the structure of words influences language comprehension.","meta":{"url":"http://arxiv.org/abs/2307.06419v1"},"cats":{"new-dataset":0.0978044155,"dev-research":0.4496416451,"prompt-eng":0.493467896,"data-quality":0.2454360866,"ml-security":0.0763518138}}
{"text":"Given a set of calibrated images of a scene, we present an approach that produces a simple, compact, and actionable 3D world representation by means of 3D primitives.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.2732980957,"dev-research":0.3781564215,"prompt-eng":0.402262,"data-quality":0.0739713725,"ml-security":0.0533266813}}
{"text":"While many approaches focus on recovering high-fidelity 3D scenes, we focus on parsing a scene into mid-level 3D representations made of a small set of textured primitives.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.1863173527,"dev-research":0.3927242325,"prompt-eng":0.4653701794,"data-quality":0.1558864869,"ml-security":0.0793051254}}
{"text":"Such representations are interpretable, easy to manipulate and suited for physics-based simulations.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.1344272705,"dev-research":0.378704291,"prompt-eng":0.4232997232,"data-quality":0.0647665203,"ml-security":0.1028853065}}
{"text":"Moreover, unlike existing primitive decomposition methods that rely on 3D input data, our approach operates directly on images through differentiable rendering.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.1024252699,"dev-research":0.3770157627,"prompt-eng":0.3291258952,"data-quality":0.0719056065,"ml-security":0.0900186892}}
{"text":"Specifically, we model primitives as textured superquadric meshes and optimize their parameters from scratch with an image rendering loss.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.0639051421,"dev-research":0.4031159426,"prompt-eng":0.4148499367,"data-quality":0.064346045,"ml-security":0.0830106176}}
{"text":"We highlight the importance of modeling transparency for each primitive, which is critical for optimization and also enables handling varying numbers of primitives.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.0329089019,"dev-research":0.4284397664,"prompt-eng":0.4133831214,"data-quality":0.0865290438,"ml-security":0.2254510026}}
{"text":"We show that the resulting textured primitives faithfully reconstruct the input images and accurately model the visible 3D points, while providing amodal shape completions of unseen object regions.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.0973249533,"dev-research":0.3811588204,"prompt-eng":0.403601049,"data-quality":0.1432616584,"ml-security":0.0740570144}}
{"text":"We compare our approach to the state of the art on diverse scenes from DTU, and demonstrate its robustness on real-life captures from BlendedMVS and Nerfstudio.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.2528641731,"dev-research":0.3810401375,"prompt-eng":0.4804133231,"data-quality":0.1961955266,"ml-security":0.0771211251}}
{"text":"We also showcase how our results can be used to effortlessly edit a scene or perform physical simulations.","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.2006308656,"dev-research":0.4576909384,"prompt-eng":0.4825880464,"data-quality":0.1080804258,"ml-security":0.0690673316}}
{"text":"Code and video results are available at https://www.tmonnier.com/DBW .","meta":{"url":"http://arxiv.org/abs/2307.05473v1"},"cats":{"new-dataset":0.6160929005,"dev-research":0.4674298821,"prompt-eng":0.4909745123,"data-quality":0.1100382837,"ml-security":0.0775874585}}
{"text":"In light of the recent widespread adoption of AI systems, understanding the internal information processing of neural networks has become increasingly critical.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.0812865637,"dev-research":0.4371969132,"prompt-eng":0.4425458039,"data-quality":0.1456077305,"ml-security":0.1911440564}}
{"text":"Most recently, machine vision has seen remarkable progress by scaling neural networks to unprecedented levels in dataset and model size.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.1637572292,"dev-research":0.3725667562,"prompt-eng":0.413693004,"data-quality":0.0932367417,"ml-security":0.1729127082}}
{"text":"We here ask whether this extraordinary increase in scale also positively impacts the field of mechanistic interpretability.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.078710818,"dev-research":0.4312115572,"prompt-eng":0.4374336082,"data-quality":0.1134099169,"ml-security":0.0866684756}}
{"text":"In other words, has our understanding of the inner workings of scaled neural networks improved as well?","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.0245722218,"dev-research":0.4149923007,"prompt-eng":0.3901497756,"data-quality":0.1012768969,"ml-security":0.1562857879}}
{"text":"We here use a psychophysical paradigm to quantify mechanistic interpretability for a diverse suite of models and find no scaling effect for interpretability - neither for model nor dataset size.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.1061877023,"dev-research":0.3865495474,"prompt-eng":0.4287633027,"data-quality":0.1407223087,"ml-security":0.1374064228}}
{"text":"Specifically, none of the nine investigated state-of-the-art models are easier to interpret than the GoogLeNet model from almost a decade ago.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.0895885927,"dev-research":0.421542142,"prompt-eng":0.4087354936,"data-quality":0.1291307529,"ml-security":0.1409387513}}
{"text":"Latest-generation vision models appear even less interpretable than older architectures, hinting at a regression rather than improvement, with modern models sacrificing interpretability for accuracy.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.0946806174,"dev-research":0.4271540747,"prompt-eng":0.4288028149,"data-quality":0.1998204616,"ml-security":0.136447546}}
{"text":"These results highlight the need for models explicitly designed to be mechanistically interpretable and the need for more helpful interpretability methods to increase our understanding of networks at an atomic level.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.0562944556,"dev-research":0.4446003038,"prompt-eng":0.454730239,"data-quality":0.1831549617,"ml-security":0.1944964039}}
{"text":"We release a dataset containing more than 120'000 human responses from our psychophysical evaluation of 767 units across nine models.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.3550320444,"dev-research":0.3900119317,"prompt-eng":0.5499870347,"data-quality":0.1163449567,"ml-security":0.1495655358}}
{"text":"This dataset is meant to facilitate research on automated instead of human-based interpretability evaluations that can ultimately be leveraged to directly optimize the mechanistic interpretability of models.","meta":{"url":"http://arxiv.org/abs/2307.05471v1"},"cats":{"new-dataset":0.3867551589,"dev-research":0.4470516429,"prompt-eng":0.5157442892,"data-quality":0.1828547948,"ml-security":0.1466798618}}
{"text":"Our paper presents My3DGen, a practical system for creating a personalized and lightweight 3D generative prior using as few as 10 images.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.2300091682,"dev-research":0.4293150065,"prompt-eng":0.4944736476,"data-quality":0.0755286109,"ml-security":0.0733019957}}
{"text":"My3DGen can reconstruct multi-view consistent images from an input test image, and generate novel appearances by interpolating between any two images of the same individual.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.2257190992,"dev-research":0.3848496572,"prompt-eng":0.438055265,"data-quality":0.1206633692,"ml-security":0.0500746505}}
{"text":"While recent studies have demonstrated the effectiveness of personalized generative priors in producing high-quality 2D portrait reconstructions and syntheses, to the best of our knowledge, we are the first to develop a personalized 3D generative prior.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.1525793726,"dev-research":0.3952867801,"prompt-eng":0.4690302175,"data-quality":0.068026758,"ml-security":0.0979279497}}
{"text":"Instead of fine-tuning a large pre-trained generative model with millions of parameters to achieve personalization, we propose a parameter-efficient approach.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.2209828886,"dev-research":0.4042771007,"prompt-eng":0.5837265091,"data-quality":0.1193248168,"ml-security":0.1407243393}}
{"text":"Our method involves utilizing a pre-trained model with fixed weights as a generic prior, while training a separate personalized prior through low-rank decomposition of the weights in each convolution and fully connected layer.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.1132697776,"dev-research":0.3751668604,"prompt-eng":0.5142943511,"data-quality":0.1168694217,"ml-security":0.1410351986}}
{"text":"However, parameter-efficient few-shot fine-tuning on its own often leads to overfitting.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0525158932,"dev-research":0.4126636774,"prompt-eng":0.4446635562,"data-quality":0.2106251484,"ml-security":0.1848129688}}
{"text":"To address this, we introduce a regularization technique based on symmetry of human faces.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0738105475,"dev-research":0.3686173054,"prompt-eng":0.4242042376,"data-quality":0.1638053286,"ml-security":0.173292929}}
{"text":"This regularization enforces that novel view renderings of a training sample, rendered from symmetric poses, exhibit the same identity.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0843201131,"dev-research":0.3770304367,"prompt-eng":0.4080737127,"data-quality":0.2106789484,"ml-security":0.2723136338}}
{"text":"By incorporating this symmetry prior, we enhance the quality of reconstruction and synthesis, particularly for non-frontal (profile) faces.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0499946598,"dev-research":0.3941861809,"prompt-eng":0.4136987244,"data-quality":0.0809269805,"ml-security":0.1267337355}}
{"text":"Our final system combines low-rank fine-tuning with symmetry regularization and significantly surpasses the performance of pre-trained models, e.g. EG3D. It introduces only approximately 0.6 million additional parameters per identity compared to 31 million for full finetuning of the original model.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0802623368,"dev-research":0.3797475939,"prompt-eng":0.516738003,"data-quality":0.1208459728,"ml-security":0.1652592756}}
{"text":"As a result, our system achieves a 50-fold reduction in model size without sacrificing the quality of the generated 3D faces.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.0429952731,"dev-research":0.4008845694,"prompt-eng":0.3693204456,"data-quality":0.0613750488,"ml-security":0.1070030263}}
{"text":"Code will be available at our project page: https://luchaoqi.github.io/my3dgen.","meta":{"url":"http://arxiv.org/abs/2307.05468v1"},"cats":{"new-dataset":0.3729094002,"dev-research":0.496040261,"prompt-eng":0.4848658548,"data-quality":0.1051413609,"ml-security":0.0742578417}}
{"text":"Video-language pre-training (VLP) has become increasingly important due to its ability to generalize to various vision and language tasks.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.1462573478,"dev-research":0.4282807396,"prompt-eng":0.5150751763,"data-quality":0.2081739303,"ml-security":0.0835403269}}
{"text":"However, existing egocentric VLP frameworks utilize separate video and language encoders and learn task-specific cross-modal information only during fine-tuning, limiting the development of a unified system.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.121842003,"dev-research":0.4495384715,"prompt-eng":0.4844720442,"data-quality":0.1223932825,"ml-security":0.0780172637}}
{"text":"In this work, we introduce the second generation of egocentric video-language pre-training (EgoVLPv2), a significant improvement from the previous generation, by incorporating cross-modal fusion directly into the video and language backbones.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.185720441,"dev-research":0.4314780917,"prompt-eng":0.5450608807,"data-quality":0.1925421922,"ml-security":0.0857685599}}
{"text":"EgoVLPv2 learns strong video-text representation during pre-training and reuses the cross-modal attention modules to support different downstream tasks in a flexible and efficient manner, reducing fine-tuning costs.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.1441524131,"dev-research":0.4247191626,"prompt-eng":0.5357527432,"data-quality":0.2069996035,"ml-security":0.0889275565}}
{"text":"Moreover, our proposed fusion in the backbone strategy is more lightweight and compute-efficient than stacking additional fusion-specific layers.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.048940813,"dev-research":0.3736516844,"prompt-eng":0.3806986745,"data-quality":0.0374058513,"ml-security":0.134967363}}
{"text":"Extensive experiments on a wide range of VL tasks demonstrate the effectiveness of EgoVLPv2 by achieving consistent state-of-the-art performance over strong baselines across all downstream.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.0550277295,"dev-research":0.4314685204,"prompt-eng":0.4657180386,"data-quality":0.1270814158,"ml-security":0.089457712}}
{"text":"Our project page can be found at https://shramanpramanick.github.io/EgoVLPv2/.","meta":{"url":"http://arxiv.org/abs/2307.05463v1"},"cats":{"new-dataset":0.3363775702,"dev-research":0.4650293729,"prompt-eng":0.4582408633,"data-quality":0.0956081691,"ml-security":0.0787362084}}
{"text":"Access to high-quality and diverse 3D articulated digital human assets is crucial in various applications, ranging from virtual reality to social platforms.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.2197718539,"dev-research":0.381228306,"prompt-eng":0.3832047789,"data-quality":0.0468960578,"ml-security":0.0870238244}}
{"text":"Generative approaches, such as 3D generative adversarial networks (GANs), are rapidly replacing laborious manual content creation tools.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.1380013103,"dev-research":0.45913119,"prompt-eng":0.4673401942,"data-quality":0.1452972546,"ml-security":0.1018466312}}
{"text":"However, existing 3D GAN frameworks typically rely on scene representations that leverage either template meshes, which are fast but offer limited quality, or volumes, which offer high capacity but are slow to render, thereby limiting the 3D fidelity in GAN settings.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.0485023021,"dev-research":0.3812461506,"prompt-eng":0.3664032653,"data-quality":0.0955917549,"ml-security":0.0989590966}}
{"text":"In this work, we introduce layered surface volumes (LSVs) as a new 3D object representation for articulated digital humans.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.1434729928,"dev-research":0.3574849606,"prompt-eng":0.4101090876,"data-quality":0.0462776851,"ml-security":0.0795005294}}
{"text":"LSVs represent a human body using multiple textured mesh layers around a conventional template.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.1104200982,"dev-research":0.3745099978,"prompt-eng":0.423596656,"data-quality":0.0571775533,"ml-security":0.1069468512}}
{"text":"These layers are rendered using alpha compositing with fast differentiable rasterization, and they can be interpreted as a volumetric representation that allocates its capacity to a manifold of finite thickness around the template.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.1329831488,"dev-research":0.3823643307,"prompt-eng":0.4101767213,"data-quality":0.0623034912,"ml-security":0.1132071805}}
{"text":"Unlike conventional single-layer templates that struggle with representing fine off-surface details like hair or accessories, our surface volumes naturally capture such details.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.0926432395,"dev-research":0.3894270209,"prompt-eng":0.4483994773,"data-quality":0.0878335455,"ml-security":0.0994059244}}
{"text":"LSVs can be articulated, and they exhibit exceptional efficiency in GAN settings, where a 2D generator learns to synthesize the RGBA textures for the individual layers.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.0863102901,"dev-research":0.3963448392,"prompt-eng":0.433169839,"data-quality":0.0781005788,"ml-security":0.096429383}}
{"text":"Trained on unstructured, single-view 2D image datasets, our LSV-GAN generates high-quality and view-consistent 3D articulated digital humans without the need for view-inconsistent 2D upsampling networks.","meta":{"url":"http://arxiv.org/abs/2307.05462v1"},"cats":{"new-dataset":0.2698483412,"dev-research":0.3586740972,"prompt-eng":0.4129389992,"data-quality":0.0875302794,"ml-security":0.114890456}}
{"text":"A challenge towards developing NLP systems for the world's languages is understanding how they generalize to typological differences relevant for real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.2100783029,"dev-research":0.4792570798,"prompt-eng":0.5004198545,"data-quality":0.2678232461,"ml-security":0.1266512078}}
{"text":"To this end, we propose M2C, a morphologically-aware framework for behavioral testing of NLP models.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.0989586598,"dev-research":0.4395967629,"prompt-eng":0.5853045634,"data-quality":0.421014645,"ml-security":0.1290893304}}
{"text":"We use M2C to generate tests that probe models' behavior in light of specific linguistic features in 12 typologically diverse languages.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.1614070779,"dev-research":0.4226352888,"prompt-eng":0.5766418401,"data-quality":0.2680120973,"ml-security":0.1165179604}}
{"text":"We evaluate state-of-the-art language models on the generated tests.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.1599527198,"dev-research":0.4804904078,"prompt-eng":0.5958785949,"data-quality":0.2805442814,"ml-security":0.0925605833}}
{"text":"While models excel at most tests in English, we highlight generalization failures to specific typological characteristics such as temporal expressions in Swahili and compounding possessives in Finish.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.1176820718,"dev-research":0.4311228269,"prompt-eng":0.5148516102,"data-quality":0.2770643969,"ml-security":0.0862321383}}
{"text":"Our findings motivate the development of models that address these blind spots.","meta":{"url":"http://arxiv.org/abs/2307.05454v1"},"cats":{"new-dataset":0.0529866311,"dev-research":0.465525507,"prompt-eng":0.420257888,"data-quality":0.1847926288,"ml-security":0.2113547168}}
{"text":"In order to provide perceptually accurate multimodal feedback during driving situations, it is vital to understand the threshold at which drivers are able to recognize asyncrony between multiple incoming Stimuli.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.1036548928,"dev-research":0.3874304846,"prompt-eng":0.4601783595,"data-quality":0.182487031,"ml-security":0.1235587275}}
{"text":"In this work, we investigated and report the \\textit{detection threshold} (DT) of asynchrony between audio and haptic feedback, in the context of a force feedback steering wheel.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.1140463509,"dev-research":0.3979724455,"prompt-eng":0.450062062,"data-quality":0.1640704171,"ml-security":0.1052587632}}
{"text":"We designed the experiment to loosely resemble a driving situation where the haptic feedback was provided through a steering wheel (\\textit{Sensodrive}), while the accompanying audio was played through noise cancelling headphones.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.0988307574,"dev-research":0.4009741465,"prompt-eng":0.4637222814,"data-quality":0.1627810354,"ml-security":0.1005531646}}
{"text":"Both feedbacks were designed to resemble rumble strips, that are generally installed on the side of major roadways as a safety tool.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.0931628218,"dev-research":0.4296983727,"prompt-eng":0.4564966761,"data-quality":0.2293383951,"ml-security":0.1352840711}}
{"text":"The results indicate that, for $50\\%$ of the participants, asynchrony was detectable outside the range of -75 ms and 110 ms, where the former is related to perceiving audio before haptic and vice versa for the latter.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.0932370475,"dev-research":0.3610317386,"prompt-eng":0.4252601477,"data-quality":0.1344201732,"ml-security":0.0933735797}}
{"text":"We were also able to concur with previous studies, which state that latency is perceivable at a lower threshold when audio precedes haptic stimuli.","meta":{"url":"http://arxiv.org/abs/2307.05451v1"},"cats":{"new-dataset":0.0520928235,"dev-research":0.3885954739,"prompt-eng":0.4542499265,"data-quality":0.1350166033,"ml-security":0.0701116227}}
{"text":"We study one generator quasi-cyclic codes and four-circulant codes, which are also quasi-cyclic but have two generators.","meta":{"url":"http://arxiv.org/abs/2307.05449v1"},"cats":{"new-dataset":0.1787365252,"dev-research":0.4770695912,"prompt-eng":0.3834936681,"data-quality":0.1242590399,"ml-security":0.0807398519}}
{"text":"We state the hull dimensions for both classes of codes in terms of the polynomials in their generating elements.","meta":{"url":"http://arxiv.org/abs/2307.05449v1"},"cats":{"new-dataset":0.1845482081,"dev-research":0.4707553785,"prompt-eng":0.383159545,"data-quality":0.1196492708,"ml-security":0.1382853966}}
{"text":"We prove results such as the hull dimension of a four-circulant code is even and one-dimensional hull for double-circulant codes, which are special one generator codes, is not possible when the alphabet size $q$ is congruent to 3 mod 4.","meta":{"url":"http://arxiv.org/abs/2307.05449v1"},"cats":{"new-dataset":0.1650153692,"dev-research":0.4664352302,"prompt-eng":0.3924402163,"data-quality":0.1303712759,"ml-security":0.1115133282}}
{"text":"We also characterize linear complementary pairs among both classes of codes.","meta":{"url":"http://arxiv.org/abs/2307.05449v1"},"cats":{"new-dataset":0.1604283836,"dev-research":0.4459488357,"prompt-eng":0.4097056543,"data-quality":0.2211162581,"ml-security":0.1838720231}}
{"text":"Computational results on the code families in consideration are provided as well.","meta":{"url":"http://arxiv.org/abs/2307.05449v1"},"cats":{"new-dataset":0.2276874293,"dev-research":0.518953103,"prompt-eng":0.3932743981,"data-quality":0.1130710969,"ml-security":0.0793076972}}
{"text":"No-regret learners seek to minimize the difference between the loss they cumulated through the actions they played, and the loss they would have cumulated in hindsight had they consistently modified their behavior according to some strategy transformation function.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0455672561,"dev-research":0.4370676997,"prompt-eng":0.409849586,"data-quality":0.0867492161,"ml-security":0.1927997992}}
{"text":"The size of the set of transformations considered by the learner determines a natural notion of rationality.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0917267768,"dev-research":0.4488651772,"prompt-eng":0.3596359804,"data-quality":0.1228598689,"ml-security":0.1855104686}}
{"text":"As the set of transformations each learner considers grows, the strategies played by the learners recover more complex game-theoretic equilibria, including correlated equilibria in normal-form games and extensive-form correlated equilibria in extensive-form games.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0913226193,"dev-research":0.4335956729,"prompt-eng":0.3779594384,"data-quality":0.0501302788,"ml-security":0.2471065862}}
{"text":"At the extreme, a no-swap-regret agent is one that minimizes regret against the set of all functions from the set of strategies to itself.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0787857146,"dev-research":0.4183555817,"prompt-eng":0.3667750632,"data-quality":0.0547802427,"ml-security":0.1314594812}}
{"text":"While it is known that the no-swap-regret condition can be attained efficiently in nonsequential (normal-form) games, understanding what is the strongest notion of rationality that can be attained efficiently in the worst case in sequential (extensive-form) games is a longstanding open problem.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0459895655,"dev-research":0.3960595883,"prompt-eng":0.3106536268,"data-quality":0.0588622051,"ml-security":0.2152218157}}
{"text":"In this paper we provide a positive result, by showing that it is possible, in any sequential game, to retain polynomial-time (in the game tree size) iterations while achieving sublinear regret with respect to all linear transformations of the mixed strategy space, a notion called no-linear-swap regret.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0540094219,"dev-research":0.4116576485,"prompt-eng":0.3428494659,"data-quality":0.0554275023,"ml-security":0.1713806318}}
{"text":"This notion of hindsight rationality is as strong as no-swap-regret in nonsequential games, and stronger than no-trigger-regret in sequential games -- thereby proving the existence of a subset of extensive-form correlated equilibria robust to linear deviations, which we call linear-deviation correlated equilibria, that can be approached efficiently.","meta":{"url":"http://arxiv.org/abs/2307.05448v1"},"cats":{"new-dataset":0.0589251058,"dev-research":0.4112910696,"prompt-eng":0.3637284117,"data-quality":0.0702053091,"ml-security":0.228897362}}
{"text":"Due to the low accuracy of object detection and recognition in many intelligent surveillance systems at nighttime, the quality of night images is crucial.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.1322458008,"dev-research":0.3622333908,"prompt-eng":0.3825191666,"data-quality":0.2349237048,"ml-security":0.1290666949}}
{"text":"Compared with the corresponding daytime image, nighttime image is characterized as low brightness, low contrast and high noise.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.2095675686,"dev-research":0.3779844283,"prompt-eng":0.3970347262,"data-quality":0.1652330837,"ml-security":0.0544133806}}
{"text":"In this paper, a bio-inspired image enhancement algorithm is proposed to convert a low illuminance image to a brighter and clear one.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.0641644255,"dev-research":0.3880316369,"prompt-eng":0.3699182187,"data-quality":0.0875136982,"ml-security":0.0663801392}}
{"text":"Different from existing bio-inspired algorithm, the proposed method doesn't use any training sequences, we depend on a novel chain of contrast enhancement and denoising algorithms without using any forms of recursive functions.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.1164608254,"dev-research":0.3478002687,"prompt-eng":0.3485904687,"data-quality":0.1005753045,"ml-security":0.0927391475}}
{"text":"Our method can largely improve the brightness and contrast of night images, besides, suppress noise.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.0513090345,"dev-research":0.3938380644,"prompt-eng":0.3880320087,"data-quality":0.1843321214,"ml-security":0.0862142485}}
{"text":"Then we implement on real experiment, and simulation experiment to test our algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.0606692027,"dev-research":0.4319479544,"prompt-eng":0.3890290309,"data-quality":0.1059415931,"ml-security":0.1785483761}}
{"text":"Both results show the advantages of proposed algorithm over contrast pair, Meylan and Retinex.","meta":{"url":"http://arxiv.org/abs/2307.05447v1"},"cats":{"new-dataset":0.1437890683,"dev-research":0.3708383694,"prompt-eng":0.3652346385,"data-quality":0.1194993845,"ml-security":0.0424114156}}
{"text":"A matching $M$ in a graph $G$ is an \\emph{acyclic matching} if the subgraph of $G$ induced by the endpoints of the edges of $M$ is a forest.","meta":{"url":"http://arxiv.org/abs/2307.05446v1"},"cats":{"new-dataset":0.1010993796,"dev-research":0.4040490929,"prompt-eng":0.4174777934,"data-quality":0.1860554789,"ml-security":0.0872887835}}
{"text":"Given a graph $G$ and a positive integer $\\ell$, Acyclic Matching asks whether $G$ has an acyclic matching of size (i.e., the number of edges) at least $\\ell$. In this paper, we first prove that assuming $\\mathsf{W[1]\\nsubseteq FPT}$, there does not exist any $\\mathsf{FPT}$-approximation algorithm for Acyclic Matching that approximates it within a constant factor when the parameter is the size of the matching.","meta":{"url":"http://arxiv.org/abs/2307.05446v1"},"cats":{"new-dataset":0.0569636289,"dev-research":0.3752885791,"prompt-eng":0.3510406799,"data-quality":0.1567175532,"ml-security":0.1044196219}}
{"text":"Our reduction is general in the sense that it also asserts $\\mathsf{FPT}$-inapproximability for Induced Matching and Uniquely Restricted Matching as well.","meta":{"url":"http://arxiv.org/abs/2307.05446v1"},"cats":{"new-dataset":0.0338547359,"dev-research":0.3681422568,"prompt-eng":0.3695443071,"data-quality":0.1831304596,"ml-security":0.2051092977}}
{"text":"We also consider three below-guarantee parameters for Acyclic Matching, viz.","meta":{"url":"http://arxiv.org/abs/2307.05446v1"},"cats":{"new-dataset":0.0825440181,"dev-research":0.3586437801,"prompt-eng":0.4003479742,"data-quality":0.133774172,"ml-security":0.0549391367}}
{"text":"$\\frac{n}{2}-\\ell$, $\\mathsf{MM(G)}-\\ell$, and $\\mathsf{IS(G)}-\\ell$, where $n$ is the number of vertices in $G$, $\\mathsf{MM(G)}$ is the matching number of $G$, and $\\mathsf{IS(G)}$ is the independence number of $G$. Furthermore, we show that Acyclic Matching does not exhibit a polynomial kernel with respect to vertex cover number (or vertex deletion distance to clique) plus the size of the matching unless $\\mathsf{NP}\\subseteq\\mathsf{coNP}\\slash\\mathsf{poly}$.","meta":{"url":"http://arxiv.org/abs/2307.05446v1"},"cats":{"new-dataset":0.0615224927,"dev-research":0.3977623523,"prompt-eng":0.3485242932,"data-quality":0.1356447445,"ml-security":0.1141468607}}
{"text":"Peer review frequently follows a process where reviewers first provide initial reviews, authors respond to these reviews, then reviewers update their reviews based on the authors' response.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0740826898,"dev-research":0.4916154582,"prompt-eng":0.5133535768,"data-quality":0.169630536,"ml-security":0.0724083608}}
{"text":"There is mixed evidence regarding whether this process is useful, including frequent anecdotal complaints that reviewers insufficiently update their scores.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0499056257,"dev-research":0.4843225507,"prompt-eng":0.4453047156,"data-quality":0.2773238331,"ml-security":0.1081887164}}
{"text":"In this study, we aim to investigate whether reviewers anchor to their original scores when updating their reviews, which serves as a potential explanation for the lack of updates in reviewer scores.   ","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.1118728301,"dev-research":0.5072408546,"prompt-eng":0.4773093503,"data-quality":0.2973796243,"ml-security":0.09109004}}
{"text":"We design a novel randomized controlled trial to test if reviewers exhibit anchoring.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0633173991,"dev-research":0.4235038966,"prompt-eng":0.4877031945,"data-quality":0.2080690415,"ml-security":0.1317902066}}
{"text":"In the experimental condition, participants initially see a flawed version of a paper that is later corrected, while in the control condition, participants only see the correct version.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0492542923,"dev-research":0.443434165,"prompt-eng":0.4333658717,"data-quality":0.3009243974,"ml-security":0.1590940903}}
{"text":"We take various measures to ensure that in the absence of anchoring, reviewers in the experimental group should revise their scores to be identically distributed to the scores from the control group.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0747279755,"dev-research":0.4443994628,"prompt-eng":0.5167186179,"data-quality":0.2335887257,"ml-security":0.1107099588}}
{"text":"Furthermore, we construct the reviewed paper to maximize the difference between the flawed and corrected versions, and employ deception to hide the true experiment purpose.   ","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0736569643,"dev-research":0.4706539738,"prompt-eng":0.4288815812,"data-quality":0.3600161342,"ml-security":0.1755098182}}
{"text":"Our randomized controlled trial consists of 108 researchers as participants.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.350343149,"dev-research":0.4109374429,"prompt-eng":0.4662027982,"data-quality":0.0953275582,"ml-security":0.134790458}}
{"text":"First, we find that our intervention was successful at creating a difference in perceived paper quality between the flawed and corrected versions: Using a permutation test with the Mann-Whitney U statistic, we find that the experimental group's initial scores are lower than the control group's scores in both the Evaluation category (Vargha-Delaney A=0.64, p=0.0096) and Overall score (A=0.59, p=0.058).","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0917486963,"dev-research":0.4406201342,"prompt-eng":0.4603630784,"data-quality":0.3813887998,"ml-security":0.0740942119}}
{"text":"Next, we test for anchoring by comparing the experimental group's revised scores with the control group's scores.","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0791292968,"dev-research":0.4478273626,"prompt-eng":0.4861712175,"data-quality":0.1145268525,"ml-security":0.084652186}}
{"text":"We find no significant evidence of anchoring in either the Overall (A=0.50, p=0.61) or Evaluation category (A=0.49, p=0.61).","meta":{"url":"http://arxiv.org/abs/2307.05443v1"},"cats":{"new-dataset":0.0544107894,"dev-research":0.4196098347,"prompt-eng":0.3821233011,"data-quality":0.2642738698,"ml-security":0.0842301612}}
{"text":"Sign languages are the primary means of communication for many hard-of-hearing people worldwide.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.1709326991,"dev-research":0.413101751,"prompt-eng":0.4647494902,"data-quality":0.1624532028,"ml-security":0.0979308677}}
{"text":"Recently, to bridge the communication gap between the hard-of-hearing community and the rest of the population, several sign language translation datasets have been proposed to enable the development of statistical sign language translation systems.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.5618466119,"dev-research":0.3827398425,"prompt-eng":0.5169952839,"data-quality":0.2096429162,"ml-security":0.0838442363}}
{"text":"However, there is a dearth of sign language resources for the Indian sign language.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.275916883,"dev-research":0.4189368363,"prompt-eng":0.4441077915,"data-quality":0.0994424971,"ml-security":0.0769988783}}
{"text":"This resource paper introduces ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.5692325047,"dev-research":0.4126966607,"prompt-eng":0.4861184173,"data-quality":0.1714587058,"ml-security":0.0696124833}}
{"text":"To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.7190933236,"dev-research":0.4064347024,"prompt-eng":0.4601795867,"data-quality":0.1279155375,"ml-security":0.0813955122}}
{"text":"We provide a detailed analysis of the dataset.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.7942529453,"dev-research":0.4261575449,"prompt-eng":0.4817771386,"data-quality":0.1671561423,"ml-security":0.1481321481}}
{"text":"To validate the performance of existing end-to-end Sign language to spoken language translation systems, we benchmark the created dataset with a transformer-based model for ISL translation.","meta":{"url":"http://arxiv.org/abs/2307.05440v1"},"cats":{"new-dataset":0.4116875165,"dev-research":0.39651654,"prompt-eng":0.5294844767,"data-quality":0.1783642624,"ml-security":0.0953390692}}
{"text":"Denoising diffusion models have recently emerged as the predominant paradigm for generative modelling.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0645532433,"dev-research":0.3788121167,"prompt-eng":0.4637253508,"data-quality":0.1075454292,"ml-security":0.1369670614}}
{"text":"Their extension to Riemannian manifolds has facilitated their application to an array of problems in the natural sciences.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.1004593769,"dev-research":0.3862414103,"prompt-eng":0.3776754923,"data-quality":0.1217208432,"ml-security":0.105728268}}
{"text":"Yet, in many practical settings, such manifolds are defined by a set of constraints and are not covered by the existing (Riemannian) diffusion model methodology.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0624025306,"dev-research":0.3557198535,"prompt-eng":0.3745239628,"data-quality":0.0617461031,"ml-security":0.1432089611}}
{"text":"Recent work has attempted to address this issue by employing novel noising processes based on logarithmic barrier methods or reflected Brownian motions.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0775611696,"dev-research":0.3539331315,"prompt-eng":0.3651470183,"data-quality":0.1060965204,"ml-security":0.1243473667}}
{"text":"However, the associated samplers are computationally burdensome as the complexity of the constraints increases.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0865984493,"dev-research":0.3823808283,"prompt-eng":0.3690649497,"data-quality":0.0929284545,"ml-security":0.1379203241}}
{"text":"In this paper, we introduce an alternative simple noising scheme based on Metropolis sampling that affords substantial gains in computational efficiency and empirical performance compared to the earlier samplers.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.1289344428,"dev-research":0.3269389494,"prompt-eng":0.4019114065,"data-quality":0.2072730599,"ml-security":0.0972403037}}
{"text":"Of independent interest, we prove that this new process corresponds to a valid discretisation of the reflected Brownian motion.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0676319451,"dev-research":0.3901554174,"prompt-eng":0.4157768741,"data-quality":0.0701680454,"ml-security":0.0849311828}}
{"text":"We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modelling, robotics and protein design.","meta":{"url":"http://arxiv.org/abs/2307.05439v1"},"cats":{"new-dataset":0.0770089343,"dev-research":0.3806897302,"prompt-eng":0.3788013424,"data-quality":0.0567466992,"ml-security":0.1111001951}}
{"text":"Making contactless payments using a smartwatch is increasingly popular, but this payment medium lacks traditional biometric security measures such as facial or fingerprint recognition.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1260581176,"dev-research":0.3747721874,"prompt-eng":0.3794981256,"data-quality":0.0925616193,"ml-security":0.2438291619}}
{"text":"In 2022, Sturgess et al. proposed WatchAuth, a system for authenticating smartwatch payments using the physical gesture of reaching towards a payment terminal.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1318219853,"dev-research":0.4344390362,"prompt-eng":0.4173638174,"data-quality":0.0596004679,"ml-security":0.1441755019}}
{"text":"While effective, the system requires the user to undergo a burdensome enrolment period to achieve acceptable error levels.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.0497689854,"dev-research":0.4649807862,"prompt-eng":0.45866199,"data-quality":0.1933700578,"ml-security":0.1804576113}}
{"text":"In this dissertation, we explore whether applications of deep learning can reduce the number of gestures a user must provide to enrol into an authentication system for smartwatch payment.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1784880506,"dev-research":0.3830686226,"prompt-eng":0.4272433878,"data-quality":0.0810915467,"ml-security":0.3463721466}}
{"text":"We firstly construct a deep-learned authentication system that outperforms the current state-of-the-art, including in a scenario where the target user has provided a limited number of gestures.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1983652577,"dev-research":0.4183949452,"prompt-eng":0.483917059,"data-quality":0.0887463664,"ml-security":0.4489038367}}
{"text":"We then develop a regularised autoencoder model for generating synthetic user-specific gestures.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1951025582,"dev-research":0.4468629828,"prompt-eng":0.5140913065,"data-quality":0.0899160469,"ml-security":0.1262915372}}
{"text":"We show that using these gestures in training improves classification ability for an authentication system.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.1031562008,"dev-research":0.4218594004,"prompt-eng":0.4703266068,"data-quality":0.142933889,"ml-security":0.3630054512}}
{"text":"Through this technique we can reduce the number of gestures required to enrol a user into a WatchAuth-like system without negatively impacting its error rates.","meta":{"url":"http://arxiv.org/abs/2307.05437v1"},"cats":{"new-dataset":0.0626388265,"dev-research":0.4669446661,"prompt-eng":0.4376032902,"data-quality":0.0826131008,"ml-security":0.1817336557}}
{"text":"Multimodal learning models have become increasingly important as they surpass single-modality approaches on diverse tasks ranging from question-answering to autonomous driving.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.1446218459,"dev-research":0.3803451985,"prompt-eng":0.5234933947,"data-quality":0.1068229702,"ml-security":0.1116968575}}
{"text":"Despite the importance of multimodal learning, existing efforts focus on NLP applications, where the number of modalities is typically less than four (audio, video, text, images).","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.1932146453,"dev-research":0.4298301247,"prompt-eng":0.4931692402,"data-quality":0.2206011753,"ml-security":0.0730761957}}
{"text":"However, data inputs in other domains, such as the medical field, may include X-rays, PET scans, MRIs, genetic screening, clinical notes, and more, creating a need for both efficient and accurate information fusion.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.1865086983,"dev-research":0.4093255466,"prompt-eng":0.4199667642,"data-quality":0.1363877837,"ml-security":0.1939602307}}
{"text":"Many state-of-the-art models rely on pairwise cross-modal attention, which does not scale well for applications with more than three modalities.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.0697965082,"dev-research":0.3655619984,"prompt-eng":0.5068056508,"data-quality":0.1051380524,"ml-security":0.072031594}}
{"text":"For $n$ modalities, computing attention will result in $n \\choose 2$ operations, potentially requiring considerable amounts of computational resources.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.0437283454,"dev-research":0.4154187015,"prompt-eng":0.4238016459,"data-quality":0.0774540421,"ml-security":0.1019170941}}
{"text":"To address this, we propose a new domain-neutral attention mechanism, One-Versus-Others (OvO) attention, that scales linearly with the number of modalities and requires only $n$ attention operations, thus offering a significant reduction in computational complexity compared to existing cross-modal attention algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.0832788443,"dev-research":0.412448326,"prompt-eng":0.4735342396,"data-quality":0.1137118752,"ml-security":0.1129910474}}
{"text":"Using three diverse real-world datasets as well as an additional simulation experiment, we show that our method improves performance compared to popular fusion techniques while decreasing computation costs.","meta":{"url":"http://arxiv.org/abs/2307.05435v1"},"cats":{"new-dataset":0.2662714559,"dev-research":0.3425096397,"prompt-eng":0.3890074799,"data-quality":0.0944830815,"ml-security":0.1285964596}}
{"text":"Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering.","meta":{"url":"http://arxiv.org/abs/2307.05432v1"},"cats":{"new-dataset":0.0769083509,"dev-research":0.3973025077,"prompt-eng":0.4039620096,"data-quality":0.093602059,"ml-security":0.3024316607}}
{"text":"Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete.","meta":{"url":"http://arxiv.org/abs/2307.05432v1"},"cats":{"new-dataset":0.1729034377,"dev-research":0.3763800506,"prompt-eng":0.4179045497,"data-quality":0.1459280895,"ml-security":0.2829855971}}
{"text":"In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision.","meta":{"url":"http://arxiv.org/abs/2307.05432v1"},"cats":{"new-dataset":0.1935431063,"dev-research":0.3903808063,"prompt-eng":0.4543114998,"data-quality":0.1878494342,"ml-security":0.1932205027}}
{"text":"Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers.","meta":{"url":"http://arxiv.org/abs/2307.05432v1"},"cats":{"new-dataset":0.0568855773,"dev-research":0.439023427,"prompt-eng":0.4580910069,"data-quality":0.102898297,"ml-security":0.1444537998}}
{"text":"We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs.","meta":{"url":"http://arxiv.org/abs/2307.05432v1"},"cats":{"new-dataset":0.0482190655,"dev-research":0.4151348829,"prompt-eng":0.4415549415,"data-quality":0.0649942603,"ml-security":0.1694071847}}
{"text":"A shared secret key is necessary for encrypted communications.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.0852471841,"dev-research":0.4241183336,"prompt-eng":0.3907327221,"data-quality":0.0669341441,"ml-security":0.3328974382}}
{"text":"Since Wi-Fi relies on OFDM, we suggest a method to generate such a key by utilizing Wi-Fi's channel state information (CSI).","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.1720461521,"dev-research":0.4292759032,"prompt-eng":0.4722335742,"data-quality":0.0802462406,"ml-security":0.1819777925}}
{"text":"CSI is typically reciprocal but very sensitive to location: While the legitimate Alice and Bob observe the same CSI, an eavesdropper Eve observes an uncorrelated CSI when positioned over 0.5 wavelength away.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.180520394,"dev-research":0.3771169728,"prompt-eng":0.409512117,"data-quality":0.1200286648,"ml-security":0.2578367425}}
{"text":"We show that if endpoint Bob is shaken, sufficient diversity is induced in the CSI so that it can serve as a source of true randomness.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.1422825777,"dev-research":0.4161763314,"prompt-eng":0.4736697877,"data-quality":0.1529926137,"ml-security":0.2365469448}}
{"text":"Then we show that the CSI among neighboring sub-carriers is correlated, so we select a small set of judiciously-spaced sub-carriers, and use a majority rule around each.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.122646911,"dev-research":0.3985634455,"prompt-eng":0.4370710748,"data-quality":0.1377266442,"ml-security":0.1338726404}}
{"text":"We demonstrate that Alice and Bob observe a 5-15\\% bit mismatch rate (BMR) in the extracted bitstream while Eve observes a BMR of around 50\\% even when placed within 10cm of Alice.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.137754417,"dev-research":0.4365323311,"prompt-eng":0.4169583268,"data-quality":0.2254860617,"ml-security":0.1893929533}}
{"text":"We employ the cryptography-oriented definition of min-entropy to estimate the number of secure bits within the bitstream, and use the Cascade algorithm of quantum-key-distribution to reconcile Alice and Bob's bitstreams, while quantifying the number of bits leaked by the algorithm.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.0962825674,"dev-research":0.4066322687,"prompt-eng":0.3903556755,"data-quality":0.1056950249,"ml-security":0.2882784648}}
{"text":"Accounting for both the min-entropy and the cascade leakage we quantify the Secured Bit Generation Rate of our method.   ","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.0532831768,"dev-research":0.4506913846,"prompt-eng":0.4232257149,"data-quality":0.1694783745,"ml-security":0.3583181077}}
{"text":"We conducted extensive tests in an indoor environment.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.1379011038,"dev-research":0.4248499614,"prompt-eng":0.4507323413,"data-quality":0.1132261995,"ml-security":0.1226443869}}
{"text":"Our system exhibits a secure bit generation rate of 1.2--1.6 %secure bits per packet, at distances ranging from 0.5m--9m, and can generate a secure shared 128-bit key with 20sec of device shaking.","meta":{"url":"http://arxiv.org/abs/2307.05423v1"},"cats":{"new-dataset":0.1721982514,"dev-research":0.4286764894,"prompt-eng":0.4420417331,"data-quality":0.0896518421,"ml-security":0.2487435589}}
{"text":"This paper proposes a data-efficient detection method for deep neural networks against backdoor attacks under a black-box scenario.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1242524211,"dev-research":0.3881341305,"prompt-eng":0.4164187542,"data-quality":0.2089848335,"ml-security":0.8177020775}}
{"text":"The proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining the backdoored network output than any other benign features.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.0260883519,"dev-research":0.4823008275,"prompt-eng":0.4321607251,"data-quality":0.2024183924,"ml-security":0.5753878585}}
{"text":"To quantitatively measure the effects of triggers and benign features on determining the backdoored network output, we introduce five metrics.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.0715272778,"dev-research":0.4544421805,"prompt-eng":0.4517998706,"data-quality":0.2303750594,"ml-security":0.5617039251}}
{"text":"To calculate the five-metric values for a given input, we first generate several synthetic samples by injecting the input's partial contents into clean validation samples.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1777908339,"dev-research":0.3944016951,"prompt-eng":0.4471408183,"data-quality":0.2155876623,"ml-security":0.0992231638}}
{"text":"Then, the five metrics are computed by using the output labels of the corresponding synthetic samples.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.2060541461,"dev-research":0.3979564073,"prompt-eng":0.413817533,"data-quality":0.1936879672,"ml-security":0.0557221871}}
{"text":"One contribution of this work is the use of a tiny clean validation dataset.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.2617050324,"dev-research":0.4184217593,"prompt-eng":0.472419825,"data-quality":0.4438458179,"ml-security":0.2799346159}}
{"text":"Having the computed five metrics, five novelty detectors are trained from the validation dataset.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1603339513,"dev-research":0.3984375368,"prompt-eng":0.4551899475,"data-quality":0.4343540498,"ml-security":0.2026535794}}
{"text":"A meta novelty detector fuses the output of the five trained novelty detectors to generate a meta confidence score.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1006296055,"dev-research":0.4150454913,"prompt-eng":0.5041534619,"data-quality":0.3546073312,"ml-security":0.2004135617}}
{"text":"During online testing, our method determines if online samples are poisoned or not via assessing their meta confidence scores output by the meta novelty detector.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1347643013,"dev-research":0.4350113758,"prompt-eng":0.4749309197,"data-quality":0.3133159605,"ml-security":0.3270695169}}
{"text":"We show the efficacy of our methodology through a broad range of backdoor attacks, including ablation studies and comparison to existing approaches.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.0979772106,"dev-research":0.4167011296,"prompt-eng":0.4339140228,"data-quality":0.1509521119,"ml-security":0.575204809}}
{"text":"Our methodology is promising since the proposed five metrics quantify the inherent differences between clean and poisoned samples.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.1484821109,"dev-research":0.4103968524,"prompt-eng":0.4165770142,"data-quality":0.2436597407,"ml-security":0.293176535}}
{"text":"Additionally, our detection method can be incrementally improved by appending more metrics that may be proposed to address future advanced attacks.","meta":{"url":"http://arxiv.org/abs/2307.05422v1"},"cats":{"new-dataset":0.0767713049,"dev-research":0.471963144,"prompt-eng":0.4579962949,"data-quality":0.187206577,"ml-security":0.625610193}}
{"text":"Dense and unplanned IEEE 802.11 Wireless Fidelity(Wi-Fi) deployments and the continuous increase of throughput and latency stringent services for users have led to machine learning algorithms to be considered as promising techniques in the industry and the academia.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.092211553,"dev-research":0.3859919026,"prompt-eng":0.4267119179,"data-quality":0.1747905456,"ml-security":0.2766874147}}
{"text":"Specifically, the ongoing IEEE 802.11be EHT -- Extremely High Throughput, known as Wi-Fi 7 -- amendment propose, for the first time, Multi-Link Operation (MLO).","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.08772493,"dev-research":0.4093477334,"prompt-eng":0.4330299719,"data-quality":0.0633413504,"ml-security":0.131571509}}
{"text":"Among others, this new feature will increase the complexity of channel selection due the novel multiple interfaces proposal.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.0315672408,"dev-research":0.4125689011,"prompt-eng":0.4204143201,"data-quality":0.0564164244,"ml-security":0.0553937196}}
{"text":"In this paper, we present a Parallel Transfer Reinforcement Learning (PTRL)-based cooperative Multi-Agent Reinforcement Learning (MARL) algorithm named Parallel Transfer Reinforcement Learning Optimistic-Weighted Value Decomposition Networks (oVDN) to improve intelligent channel selection in IEEE 802.11be MLO-capable networks.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.1005000901,"dev-research":0.3854971542,"prompt-eng":0.430747861,"data-quality":0.0712280002,"ml-security":0.179915367}}
{"text":"Additionally, we compare the impact of different parallel transfer learning alternatives and a centralized non-transfer MARL baseline.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.1209382535,"dev-research":0.3792205175,"prompt-eng":0.438050038,"data-quality":0.1048533786,"ml-security":0.144036936}}
{"text":"Two PTRL methods are presented: Multi-Agent System (MAS) Joint Q-function Transfer, where the joint Q-function is transferred and MAS Best/Worst Experience Transfer where the best and worst experiences are transferred among MASs.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.0828396251,"dev-research":0.3999820392,"prompt-eng":0.4474334991,"data-quality":0.0551826345,"ml-security":0.0783129044}}
{"text":"Simulation results show that oVDNg -- only the best experiences are utilized -- is the best algorithm variant.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.07604988,"dev-research":0.3881636506,"prompt-eng":0.3534825284,"data-quality":0.0875874478,"ml-security":0.0609572589}}
{"text":"Moreover, oVDNg offers a gain up to 3%, 7.2% and 11% when compared with VDN, VDN-nonQ and non-PTRL baselines.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.0669491338,"dev-research":0.4195721417,"prompt-eng":0.4247113511,"data-quality":0.1181983868,"ml-security":0.0729964978}}
{"text":"Furthermore, oVDNg experienced a reward convergence gain in the 5 GHz interface of 33.3% over oVDNb and oVDN where only worst and both types of experiences are considered, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.0566698566,"dev-research":0.4273138309,"prompt-eng":0.3757199794,"data-quality":0.0916802252,"ml-security":0.1090475005}}
{"text":"Finally, our best PTRL alternative showed an improvement over the non-PTRL baseline in terms of speed of convergence up to 40 episodes and reward up to 135%.","meta":{"url":"http://arxiv.org/abs/2307.05419v1"},"cats":{"new-dataset":0.07439011,"dev-research":0.4114273817,"prompt-eng":0.4815597731,"data-quality":0.0775411339,"ml-security":0.0666365991}}
{"text":"The increasing volume and velocity of science data necessitate the frequent movement of enormous data volumes as part of routine research activities.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.3165442666,"dev-research":0.3770251662,"prompt-eng":0.3980445945,"data-quality":0.0811507231,"ml-security":0.0918756745}}
{"text":"As a result, limited wide-area bandwidth often leads to bottlenecks in research progress.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.072995927,"dev-research":0.4150425304,"prompt-eng":0.3559458416,"data-quality":0.061765844,"ml-security":0.1325621069}}
{"text":"However, in many cases, consuming applications (e.g., for analysis, visualization, and machine learning) can achieve acceptable performance on reduced-precision data, and thus researchers may wish to compromise on data precision to reduce transfer and storage costs.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.1334757731,"dev-research":0.4197895152,"prompt-eng":0.3583439338,"data-quality":0.1412776033,"ml-security":0.2719229149}}
{"text":"Error-bounded lossy compression presents a promising approach as it can significantly reduce data volumes while preserving data integrity based on user-specified error bounds.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.1647040011,"dev-research":0.4016865208,"prompt-eng":0.373308255,"data-quality":0.3480369215,"ml-security":0.3262080223}}
{"text":"In this paper, we propose a novel data transfer framework called Ocelot that integrates error-bounded lossy compression into the Globus data transfer infrastructure.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.2929778481,"dev-research":0.3672771664,"prompt-eng":0.3771494933,"data-quality":0.1804288086,"ml-security":0.2151275053}}
{"text":"We note four key contributions: (1) Ocelot is the first integration of lossy compression in Globus to significantly improve scientific data transfer performance over wide area network (WAN).","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.2376824641,"dev-research":0.359807959,"prompt-eng":0.366969554,"data-quality":0.1352775332,"ml-security":0.1154712256}}
{"text":"(2) We propose an effective machine-learning based lossy compression quality estimation model that can predict the quality of error-bounded lossy compressors, which is fundamental to ensure that transferred data are acceptable to users.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.1798634921,"dev-research":0.4087472752,"prompt-eng":0.4436178928,"data-quality":0.3422477035,"ml-security":0.2859376757}}
{"text":"(3) We develop optimized strategies to reduce the compression time overhead, counter the compute-node waiting time, and improve transfer speed for compressed files.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.1198529123,"dev-research":0.4072913438,"prompt-eng":0.3381246512,"data-quality":0.0777313203,"ml-security":0.1486171661}}
{"text":"(4) We perform evaluations using many real-world scientific applications across different domains and distributed Globus endpoints.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.1595548627,"dev-research":0.3757371528,"prompt-eng":0.4428038628,"data-quality":0.133579868,"ml-security":0.0696612784}}
{"text":"Our experiments show that Ocelot can improve dataset transfer performance substantially, and the quality of lossy compression (time, ratio and data distortion) can be predicted accurately for the purpose of quality assurance.","meta":{"url":"http://arxiv.org/abs/2307.05416v1"},"cats":{"new-dataset":0.4197174311,"dev-research":0.4026263286,"prompt-eng":0.4270305879,"data-quality":0.2936122759,"ml-security":0.2144941197}}
{"text":"This paper investigates the employment of various encoders in text transformation, converting characters into bytes.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.156683922,"dev-research":0.4709674627,"prompt-eng":0.4372057524,"data-quality":0.1519378554,"ml-security":0.1558312967}}
{"text":"It discusses local encoders such as ASCII and GB-2312, which encode specific characters into shorter bytes, and universal encoders like UTF-8 and UTF-16, which can encode the complete Unicode set with greater space requirements and are gaining widespread acceptance.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.2727190568,"dev-research":0.4551391984,"prompt-eng":0.4559181913,"data-quality":0.1531662851,"ml-security":0.1541884111}}
{"text":"Other encoders, including SCSU, BOCU-1, and binary encoders, however, lack self-synchronizing capabilities.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.1518912011,"dev-research":0.3971335615,"prompt-eng":0.433229711,"data-quality":0.113857908,"ml-security":0.1109869845}}
{"text":"Duncode is introduced as an innovative encoding method that aims to encode the entire Unicode character set with high space efficiency, akin to local encoders.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.1647188594,"dev-research":0.4614422553,"prompt-eng":0.4425187496,"data-quality":0.1537491244,"ml-security":0.189009547}}
{"text":"It has the potential to compress multiple characters of a string into a Duncode unit using fewer bytes.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.0776588945,"dev-research":0.4543716604,"prompt-eng":0.3983667676,"data-quality":0.1704679485,"ml-security":0.1574462721}}
{"text":"Despite offering less self-synchronizing identification information, Duncode surpasses UTF8 in terms of space efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.1629558573,"dev-research":0.4112862348,"prompt-eng":0.4654888966,"data-quality":0.1954313149,"ml-security":0.1845747146}}
{"text":"The application is available at \\url{https://github.com/laohur/duncode}.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.3036963888,"dev-research":0.4548913012,"prompt-eng":0.4650679591,"data-quality":0.1276637315,"ml-security":0.1360303527}}
{"text":"Additionally, we have developed a benchmark for evaluating character encoders across different languages.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.2368187355,"dev-research":0.4385477452,"prompt-eng":0.5056423733,"data-quality":0.1822277438,"ml-security":0.1143305777}}
{"text":"It encompasses 179 languages and can be accessed at \\url{https://github.com/laohur/wiki2txt}.","meta":{"url":"http://arxiv.org/abs/2307.05414v1"},"cats":{"new-dataset":0.4924639011,"dev-research":0.4675556426,"prompt-eng":0.5095889662,"data-quality":0.1320060824,"ml-security":0.1013525918}}
{"text":"One common trend in recent studies of language models (LMs) is the use of standardized tests for evaluation.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.0512229452,"dev-research":0.4246487598,"prompt-eng":0.5633408483,"data-quality":0.2544009615,"ml-security":0.0869935002}}
{"text":"However, despite being the fifth most spoken language worldwide, few such evaluations have been conducted in Portuguese.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.1657297874,"dev-research":0.4278032516,"prompt-eng":0.5022903381,"data-quality":0.2333416941,"ml-security":0.0743261792}}
{"text":"This is mainly due to the lack of high-quality datasets available to the community for carrying out evaluations in Portuguese.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.336245566,"dev-research":0.4151243355,"prompt-eng":0.4512785182,"data-quality":0.2136779539,"ml-security":0.1284897397}}
{"text":"To address this gap, we introduce the Brazilian Leading Universities Entrance eXams (BLUEX), a dataset of entrance exams from the two leading universities in Brazil: UNICAMP and USP.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.3935323985,"dev-research":0.3993898869,"prompt-eng":0.489658852,"data-quality":0.1082188928,"ml-security":0.0997436163}}
{"text":"The dataset includes annotated metadata for evaluating the performance of NLP models on a variety of subjects.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.4158641119,"dev-research":0.4386685566,"prompt-eng":0.5602094126,"data-quality":0.340996618,"ml-security":0.0818969766}}
{"text":"Furthermore, BLUEX includes a collection of recently administered exams that are unlikely to be included in the training data of many popular LMs as of 2023.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.1909282778,"dev-research":0.3961341625,"prompt-eng":0.4448833127,"data-quality":0.1309195236,"ml-security":0.1843786031}}
{"text":"The dataset is also annotated to indicate the position of images in each question, providing a valuable resource for advancing the state-of-the-art in multimodal language understanding and reasoning.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.6457368149,"dev-research":0.4658602035,"prompt-eng":0.529741517,"data-quality":0.2053131894,"ml-security":0.056107848}}
{"text":"We describe the creation and characteristics of BLUEX and establish a benchmark through experiments with state-of-the-art LMs, demonstrating its potential for advancing the state-of-the-art in natural language understanding and reasoning in Portuguese.","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.2581847779,"dev-research":0.4907339807,"prompt-eng":0.5499730504,"data-quality":0.1968748175,"ml-security":0.0928378267}}
{"text":"The data and relevant code can be found at https://github.com/Portuguese-Benchmark-Datasets/BLUEX","meta":{"url":"http://arxiv.org/abs/2307.05410v1"},"cats":{"new-dataset":0.6562356446,"dev-research":0.3901114851,"prompt-eng":0.4303955773,"data-quality":0.1018089169,"ml-security":0.0759276969}}
{"text":"Reconstructing urban areas in 3D out of satellite raster images has been a long-standing and challenging goal of both academical and industrial research.","meta":{"url":"http://arxiv.org/abs/2307.05409v1"},"cats":{"new-dataset":0.2032830539,"dev-research":0.3747313497,"prompt-eng":0.3677789875,"data-quality":0.0906827446,"ml-security":0.0745696789}}
{"text":"The rare methods today achieving this objective at a Level Of Details $2$ rely on procedural approaches based on geometry, and need stereo images and/or LIDAR data as input.","meta":{"url":"http://arxiv.org/abs/2307.05409v1"},"cats":{"new-dataset":0.1218140861,"dev-research":0.3887785868,"prompt-eng":0.3969933914,"data-quality":0.0919548943,"ml-security":0.0704951019}}
{"text":"We here propose a method for urban 3D reconstruction named KIBS(\\textit{Keypoints Inference By Segmentation}), which comprises two novel features: i) a full deep learning approach for the 3D detection of the roof sections, and ii) only one single (non-orthogonal) satellite raster image as model input.","meta":{"url":"http://arxiv.org/abs/2307.05409v1"},"cats":{"new-dataset":0.1812269048,"dev-research":0.371812816,"prompt-eng":0.4118398401,"data-quality":0.1281215028,"ml-security":0.14359781}}
{"text":"This is achieved in two steps: i) by a Mask R-CNN model performing a 2D segmentation of the buildings' roof sections, and after blending these latter segmented pixels within the RGB satellite raster image, ii) by another identical Mask R-CNN model inferring the heights-to-ground of the roof sections' corners via panoptic segmentation, unto full 3D reconstruction of the buildings and city.","meta":{"url":"http://arxiv.org/abs/2307.05409v1"},"cats":{"new-dataset":0.1894275781,"dev-research":0.3902762199,"prompt-eng":0.4231493875,"data-quality":0.0899117993,"ml-security":0.1099608464}}
{"text":"We demonstrate the potential of the KIBS method by reconstructing different urban areas in a few minutes, with a Jaccard index for the 2D segmentation of individual roof sections of $88.55\\%$ and $75.21\\%$ on our two data sets resp., and a height's mean error of such correctly segmented pixels for the 3D reconstruction of $1.60$ m and $2.06$ m on our two data sets resp., hence within the LOD2 precision range.","meta":{"url":"http://arxiv.org/abs/2307.05409v1"},"cats":{"new-dataset":0.1745885478,"dev-research":0.3500398139,"prompt-eng":0.3818604687,"data-quality":0.1140954506,"ml-security":0.0637123889}}
{"text":"Interactive reinforcement learning has shown promise in learning complex robotic tasks.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0881875002,"dev-research":0.4034917059,"prompt-eng":0.4667945894,"data-quality":0.0737082345,"ml-security":0.1152799526}}
{"text":"However, the process can be human-intensive due to the requirement of large amount of interactive feedback.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0722167271,"dev-research":0.4657538472,"prompt-eng":0.4786254691,"data-quality":0.0677214384,"ml-security":0.0824171822}}
{"text":"This paper presents a new method that uses scores provided by humans, instead of pairwise preferences, to improve the feedback efficiency of interactive reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0950393529,"dev-research":0.4112112875,"prompt-eng":0.500936303,"data-quality":0.0862428395,"ml-security":0.0912638209}}
{"text":"Our key insight is that scores can yield significantly more data than pairwise preferences.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.1664588299,"dev-research":0.4183355657,"prompt-eng":0.4176559714,"data-quality":0.068512156,"ml-security":0.1199576114}}
{"text":"Specifically, we require a teacher to interactively score the full trajectories of an agent to train a behavioral policy in a sparse reward environment.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0988054954,"dev-research":0.4516343804,"prompt-eng":0.495459902,"data-quality":0.0823624885,"ml-security":0.1441970593}}
{"text":"To avoid unstable scores given by human negatively impact the training process, we propose an adaptive learning scheme.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0821683312,"dev-research":0.4050087089,"prompt-eng":0.4664244969,"data-quality":0.2238227619,"ml-security":0.3339350182}}
{"text":"This enables the learning paradigm to be insensitive to imperfect or unreliable scores.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0507734743,"dev-research":0.4435399845,"prompt-eng":0.4727169678,"data-quality":0.4240739309,"ml-security":0.2297098777}}
{"text":"We extensively evaluate our method on robotic locomotion and manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0706491206,"dev-research":0.4190314697,"prompt-eng":0.4261911486,"data-quality":0.0686239687,"ml-security":0.043016943}}
{"text":"The results show that the proposed method can efficiently learn near-optimal policies by adaptive learning from scores, while requiring less feedback compared to pairwise preference learning methods.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.0989747233,"dev-research":0.3893591461,"prompt-eng":0.4662964266,"data-quality":0.1020015044,"ml-security":0.1681823183}}
{"text":"The source codes are publicly available at https://github.com/SSKKai/Interactive-Scoring-IRL.","meta":{"url":"http://arxiv.org/abs/2307.05405v1"},"cats":{"new-dataset":0.3860152039,"dev-research":0.4741969493,"prompt-eng":0.5210682792,"data-quality":0.1222838011,"ml-security":0.1078450751}}
{"text":"In a graph, a (perfect) matching cut is an edge cut that is a (perfect) matching.","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.0813894784,"dev-research":0.400950776,"prompt-eng":0.3512748724,"data-quality":0.1987661302,"ml-security":0.0673397707}}
{"text":"Matching Cut (MC), respectively, Perfect Matching Cut (PMC), is the problem of deciding whether a given graph has a matching cut, respectively, a perfect matching cut.","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.0759332733,"dev-research":0.3875267801,"prompt-eng":0.3978321886,"data-quality":0.1670647725,"ml-security":0.0533709739}}
{"text":"The Disconnected Perfect Matching problem (DPM) is to decide if a graph has a perfect matching that contains a matching cut.","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.1065074305,"dev-research":0.3816567886,"prompt-eng":0.3756725969,"data-quality":0.1989978808,"ml-security":0.0798682251}}
{"text":"Solving an open problem recently posed in [Lucke, Paulusma, Ries (ISAAC 2022), and Feghali, Lucke, Paulusma, Ries (arXiv:2212.12317)], we show that PMC is NP-complete in graphs without induced 14-vertex path $P_{14}$. Our reduction also works simultaneously for MC and DPM, improving the previous hardness results of MC on $P_{19}$-free graphs and of DPM on $P_{23}$-free graphs to $P_{14}$-free graphs for both problems.   ","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.1059265435,"dev-research":0.4223084249,"prompt-eng":0.3812069327,"data-quality":0.1495482224,"ml-security":0.1560624204}}
{"text":"Actually, we prove a slightly stronger result: within $P_{14}$-free graphs, it is hard to distinguish between (i) those without matching cuts and those in which every matching cut is a perfect matching cut, (ii) those without perfect matching cuts and those in which every matching cut is a perfect matching cut, and (iii) those without disconnected perfect matchings and those in which every matching cut is a perfect matching cut.   ","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.1892818329,"dev-research":0.3975635835,"prompt-eng":0.347324761,"data-quality":0.1654570631,"ml-security":0.1247123421}}
{"text":"Moreover, assuming the Exponential Time Hypothesis, none of these problems can be solved in time $2^{o(n)}$ for $n$-vertex $P_{14}$-free input graphs.   ","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.1290760389,"dev-research":0.4018490017,"prompt-eng":0.3345247266,"data-quality":0.1026650048,"ml-security":0.1954036568}}
{"text":"We also consider the problems in graphs without long induced cycles.","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.085527699,"dev-research":0.4176742397,"prompt-eng":0.3189147758,"data-quality":0.1593017817,"ml-security":0.1567984813}}
{"text":"It is known that MC is polynomially solvable in graphs without induced cycles of length at least 5 [Moshi (JGT 1989)].","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.1157978667,"dev-research":0.3960209389,"prompt-eng":0.3326108116,"data-quality":0.1029771632,"ml-security":0.0911699264}}
{"text":"We point out that the same holds for DPM.","meta":{"url":"http://arxiv.org/abs/2307.05402v1"},"cats":{"new-dataset":0.0952186421,"dev-research":0.3987405303,"prompt-eng":0.4406371402,"data-quality":0.1380063498,"ml-security":0.1512184212}}
{"text":"Production deployments in complex systems require ML architectures to be highly efficient and usable against multiple tasks.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.0753355699,"dev-research":0.4599506597,"prompt-eng":0.4271000506,"data-quality":0.071276397,"ml-security":0.1430355798}}
{"text":"Particularly demanding are classification problems in which data arrives in a streaming fashion and each class is presented separately.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.2134429386,"dev-research":0.3987985859,"prompt-eng":0.4309250256,"data-quality":0.2311574913,"ml-security":0.2510032999}}
{"text":"Recent methods with stochastic gradient learning have been shown to struggle in such setups or have limitations like memory buffers, and being restricted to specific domains that disable its usage in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.0770107496,"dev-research":0.3305159266,"prompt-eng":0.4221910611,"data-quality":0.1567800456,"ml-security":0.3926240067}}
{"text":"For this reason, we present a fully differentiable architecture based on the Mixture of Experts model, that enables the training of high-performance classifiers when examples from each class are presented separately.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.1918100016,"dev-research":0.3719026154,"prompt-eng":0.4803741531,"data-quality":0.2043507157,"ml-security":0.245609478}}
{"text":"We conducted exhaustive experiments that proved its applicability in various domains and ability to learn online in production environments.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.1746610037,"dev-research":0.4706798202,"prompt-eng":0.4754299329,"data-quality":0.1048768599,"ml-security":0.1559040033}}
{"text":"The proposed technique achieves SOTA results without a memory buffer and clearly outperforms the reference methods.","meta":{"url":"http://arxiv.org/abs/2307.05399v1"},"cats":{"new-dataset":0.1613372294,"dev-research":0.420442118,"prompt-eng":0.4147552724,"data-quality":0.1313609925,"ml-security":0.1031648654}}
{"text":"The detection of malicious Deepfakes is a constantly evolving problem, that requires continuous monitoring of detectors, to ensure they are able to detect image manipulations generated by the latest emerging models.","meta":{"url":"http://arxiv.org/abs/2307.05397v1"},"cats":{"new-dataset":0.1338368329,"dev-research":0.4013922989,"prompt-eng":0.4910671799,"data-quality":0.2730205752,"ml-security":0.4564296762}}
{"text":"In this paper, we present a preliminary study that investigates the vulnerability of single-image Deepfake detectors to attacks created by a representative of the newest generation of generative methods, i.e. Denoising Diffusion Models (DDMs).","meta":{"url":"http://arxiv.org/abs/2307.05397v1"},"cats":{"new-dataset":0.1161582813,"dev-research":0.3789387464,"prompt-eng":0.4942712898,"data-quality":0.2719458164,"ml-security":0.5371462416}}
{"text":"Our experiments are run on FaceForensics++, a commonly used benchmark dataset, consisting of Deepfakes generated with various techniques for face swapping and face reenactment.","meta":{"url":"http://arxiv.org/abs/2307.05397v1"},"cats":{"new-dataset":0.3074929328,"dev-research":0.374031542,"prompt-eng":0.4418151105,"data-quality":0.1248962514,"ml-security":0.1625552294}}
{"text":"The analysis shows, that reconstructing existing Deepfakes with only one denoising diffusion step significantly decreases the accuracy of all tested detectors, without introducing visually perceptible image changes.","meta":{"url":"http://arxiv.org/abs/2307.05397v1"},"cats":{"new-dataset":0.1376297326,"dev-research":0.3494485533,"prompt-eng":0.4560146877,"data-quality":0.285778305,"ml-security":0.160288744}}
{"text":"OCR (Optical Character Recognition) is a technology that offers comprehensive alphanumeric recognition of handwritten and printed characters at electronic speed by merely scanning the document.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.1609076837,"dev-research":0.402495988,"prompt-eng":0.4376121047,"data-quality":0.1334416321,"ml-security":0.0872938472}}
{"text":"Recently, the understanding of visual data has been termed Intelligent Character Recognition (ICR).","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.3194051999,"dev-research":0.4102414723,"prompt-eng":0.4414024497,"data-quality":0.2104561676,"ml-security":0.1032225638}}
{"text":"Intelligent Character Recognition (ICR) is the OCR module that can convert scans of handwritten or printed characters into ASCII text.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.2617509762,"dev-research":0.4183353383,"prompt-eng":0.4772295449,"data-quality":0.2036507568,"ml-security":0.0871008915}}
{"text":"ASCII data is the standard format for data encoding in electronic communication.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.295779262,"dev-research":0.4199059518,"prompt-eng":0.442700082,"data-quality":0.1886837847,"ml-security":0.1556296418}}
{"text":"ASCII assigns standard numeric values to letters, numeral, symbols, white-spaces and other characters.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.2605566765,"dev-research":0.4480747417,"prompt-eng":0.4644364753,"data-quality":0.1727727174,"ml-security":0.1134881042}}
{"text":"In more technical terms, OCR is the process of using an electronic device to transform 2-Dimensional textual information into machine-encoded text.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.1342345693,"dev-research":0.4427801436,"prompt-eng":0.4712122413,"data-quality":0.1631829875,"ml-security":0.0905221886}}
{"text":"Anything that contains text both machine written or handwritten can be scanned either through a scanner or just simply a picture of the text is enough for the recognition system to distinguish the text.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.154900753,"dev-research":0.3929111442,"prompt-eng":0.4670314015,"data-quality":0.2630436335,"ml-security":0.127455217}}
{"text":"The goal of this papers is to show the results of a Convolutional Neural Network model which has been trained on National Institute of Science and Technology (NIST) dataset containing over a 100,000 images.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.510056741,"dev-research":0.3338633594,"prompt-eng":0.4362925693,"data-quality":0.1699430134,"ml-security":0.1298914204}}
{"text":"The network learns from the features extracted from the images and use it to generate the probability of each class to which the picture belongs to.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.2150105741,"dev-research":0.412092251,"prompt-eng":0.4774205361,"data-quality":0.2017386897,"ml-security":0.16824283}}
{"text":"We have achieved an accuracy of 90.54% with a loss of 2.53%.","meta":{"url":"http://arxiv.org/abs/2307.05396v1"},"cats":{"new-dataset":0.1108873812,"dev-research":0.3885212998,"prompt-eng":0.4573206539,"data-quality":0.3087843296,"ml-security":0.1135715387}}
{"text":"Universities face increasing demands to improve their visibility, public outreach, and online presence.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.0811032397,"dev-research":0.4206673496,"prompt-eng":0.4126520784,"data-quality":0.061221171,"ml-security":0.1554354438}}
{"text":"There is a broad consensus that scientific reputation significantly increases the attention universities receive.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.0933105174,"dev-research":0.4182815654,"prompt-eng":0.449291059,"data-quality":0.2049189958,"ml-security":0.1561467966}}
{"text":"However, in most cases estimates of scientific reputation are based on composite or weighted indicators and absolute positions in university rankings.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.1098285355,"dev-research":0.407047152,"prompt-eng":0.4418716901,"data-quality":0.2105485097,"ml-security":0.1257408253}}
{"text":"In this study, we adopt a more granular approach to assessment of universities' scientific performance using a multidimensional set of indicators from the Leiden Ranking and testing their individual effects on university Wikipedia page views.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.0990664739,"dev-research":0.434059483,"prompt-eng":0.4700305776,"data-quality":0.1296636642,"ml-security":0.050503927}}
{"text":"We distinguish between international and local attention and find a positive association between research performance and Wikipedia attention which holds for regions and linguistic areas.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.1059776996,"dev-research":0.4457705176,"prompt-eng":0.4659128147,"data-quality":0.2239791643,"ml-security":0.0422962325}}
{"text":"Additional analysis shows that productivity, scientific impact, and international collaboration have a curvilinear effect on universities' Wikipedia attention.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.0872578213,"dev-research":0.4659424442,"prompt-eng":0.4204290897,"data-quality":0.128740109,"ml-security":0.0749477575}}
{"text":"This finding suggests that there may be other factors than scientific reputation driving the general public's interest in universities.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.1032040105,"dev-research":0.4275104803,"prompt-eng":0.4079054237,"data-quality":0.1780302588,"ml-security":0.1946250581}}
{"text":"Our study adds to a growing stream of work which views altmetrics as tools to deepen science-society interactions rather than direct measures of impact and recognition of scientific outputs.","meta":{"url":"http://arxiv.org/abs/2307.05366v1"},"cats":{"new-dataset":0.2242445662,"dev-research":0.4576194531,"prompt-eng":0.454661766,"data-quality":0.1676002108,"ml-security":0.1068035714}}
{"text":"Federated learning has become a popular method to learn from decentralized heterogeneous data.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.2306602387,"dev-research":0.3864431302,"prompt-eng":0.419810652,"data-quality":0.0986823121,"ml-security":0.2354817834}}
{"text":"Federated semi-supervised learning (FSSL) emerges to train models from a small fraction of labeled data due to label scarcity on decentralized clients.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.2314932902,"dev-research":0.3963681081,"prompt-eng":0.4815716435,"data-quality":0.318596808,"ml-security":0.3447655602}}
{"text":"Existing FSSL methods assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.2293249411,"dev-research":0.4088584137,"prompt-eng":0.4702735385,"data-quality":0.4595339408,"ml-security":0.2395858384}}
{"text":"This work studies a more practical and challenging scenario of FSSL, where data distribution is different not only across clients but also within a client between labeled and unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.3239369313,"dev-research":0.4282930449,"prompt-eng":0.4662421518,"data-quality":0.3939991492,"ml-security":0.263845943}}
{"text":"To address this challenge, we propose a novel FSSL framework with dual regulators, FedDure.}","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.0931452015,"dev-research":0.4105624008,"prompt-eng":0.4256360467,"data-quality":0.0987360254,"ml-security":0.1571541622}}
{"text":"FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of the local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored for unlabeled instances in each client.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.1108509499,"dev-research":0.4161660799,"prompt-eng":0.5232477492,"data-quality":0.3675052911,"ml-security":0.29727813}}
{"text":"We further formulate the client model training as bi-level optimization that adaptively optimizes the model in the client with two regulators.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.045197332,"dev-research":0.4162649138,"prompt-eng":0.4396737846,"data-quality":0.0954786746,"ml-security":0.20933557}}
{"text":"Theoretically, we show the convergence guarantee of the dual regulators.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.0398009898,"dev-research":0.3885419156,"prompt-eng":0.4046194834,"data-quality":0.1246350598,"ml-security":0.1764534439}}
{"text":"Empirically, we demonstrate that FedDure is superior to the existing methods across a wide range of settings, notably by more than 11% on CIFAR-10 and CINIC-10 datasets.","meta":{"url":"http://arxiv.org/abs/2307.05358v1"},"cats":{"new-dataset":0.3237258344,"dev-research":0.4136624712,"prompt-eng":0.4979963482,"data-quality":0.1557004626,"ml-security":0.1228089435}}
{"text":"In the context of the rapid development of large language models, we have meticulously trained and introduced the GujiBERT and GujiGPT language models, which are foundational models specifically designed for intelligent information processing of ancient texts.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.2260167704,"dev-research":0.4317582847,"prompt-eng":0.5311535814,"data-quality":0.1888962285,"ml-security":0.1162876153}}
{"text":"These models have been trained on an extensive dataset that encompasses both simplified and traditional Chinese characters, allowing them to effectively handle various natural language processing tasks related to ancient books, including but not limited to automatic sentence segmentation, punctuation, word segmentation, part-of-speech tagging, entity recognition, and automatic translation.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.4017261614,"dev-research":0.4053996795,"prompt-eng":0.5471994073,"data-quality":0.2751374508,"ml-security":0.0996818312}}
{"text":"Notably, these models have exhibited exceptional performance across a range of validation tasks using publicly available datasets.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.3154703474,"dev-research":0.3661719181,"prompt-eng":0.4902535088,"data-quality":0.1640714746,"ml-security":0.2598511531}}
{"text":"Our research findings highlight the efficacy of employing self-supervised methods to further train the models using classical text corpora, thus enhancing their capability to tackle downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.1548258238,"dev-research":0.4504880947,"prompt-eng":0.5626155792,"data-quality":0.3173337182,"ml-security":0.1182746055}}
{"text":"Moreover, it is worth emphasizing that the choice of font, the scale of the corpus, and the initial model selection all exert significant influence over the ultimate experimental outcomes.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.0890806701,"dev-research":0.4246742332,"prompt-eng":0.4912835075,"data-quality":0.1883918066,"ml-security":0.1039933734}}
{"text":"To cater to the diverse text processing preferences of researchers in digital humanities and linguistics, we have developed three distinct categories comprising a total of nine model variations.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.1489682328,"dev-research":0.4433993168,"prompt-eng":0.5096236663,"data-quality":0.2318608566,"ml-security":0.0565155075}}
{"text":"We believe that by sharing these foundational language models specialized in the domain of ancient texts, we can facilitate the intelligent processing and scholarly exploration of ancient literary works and, consequently, contribute to the global dissemination of China's rich and esteemed traditional culture in this new era.","meta":{"url":"http://arxiv.org/abs/2307.05354v1"},"cats":{"new-dataset":0.233221374,"dev-research":0.4164753082,"prompt-eng":0.4884509228,"data-quality":0.1854135557,"ml-security":0.0813319247}}
{"text":"In this paper, we approach competitive-level programming problem-solving as a composite task of reasoning and code generation.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.157820881,"dev-research":0.5546502118,"prompt-eng":0.4372707141,"data-quality":0.0754924078,"ml-security":0.1012989432}}
{"text":"We propose a novel method to automatically annotate natural language explanations to \\textit{<problem, solution>} pairs.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.197627683,"dev-research":0.5663080848,"prompt-eng":0.5656046458,"data-quality":0.5025265941,"ml-security":0.150145268}}
{"text":"We show that despite poor performance in solving competitive-level programming problems, state-of-the-art LLMs exhibit a strong capacity in describing and explaining solutions.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.0834552566,"dev-research":0.522431674,"prompt-eng":0.4497379827,"data-quality":0.0986568007,"ml-security":0.1521512715}}
{"text":"Our explanation generation methodology can generate a structured solution explanation for the problem containing descriptions and analysis.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.1775696334,"dev-research":0.5712550304,"prompt-eng":0.5119013234,"data-quality":0.2138513401,"ml-security":0.1019807004}}
{"text":"To evaluate the quality of the annotated explanations, we examine their effectiveness in two aspects: 1) satisfying the human programming expert who authored the oracle solution, and 2) aiding LLMs in solving problems more effectively.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.1181826593,"dev-research":0.6025371949,"prompt-eng":0.521611355,"data-quality":0.3589527833,"ml-security":0.1513429976}}
{"text":"The experimental results on the CodeContests dataset demonstrate that while LLM GPT3.5's and GPT-4's abilities in describing the solution are comparable, GPT-4 shows a better understanding of the key idea behind the solution.","meta":{"url":"http://arxiv.org/abs/2307.05337v1"},"cats":{"new-dataset":0.1262985297,"dev-research":0.4750270144,"prompt-eng":0.4423507198,"data-quality":0.1150901074,"ml-security":0.0981390215}}
{"text":"Recent work in the field of symbolic music generation has shown value in using a tokenization based on the GuitarPro format, a symbolic representation supporting guitar expressive attributes, as an input and output representation.","meta":{"url":"http://arxiv.org/abs/2307.05328v1"},"cats":{"new-dataset":0.1009914426,"dev-research":0.465192838,"prompt-eng":0.4786504826,"data-quality":0.2313277774,"ml-security":0.096776634}}
{"text":"We extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a custom dataset of 173 progressive metal songs, for the purposes of creating compositions from that genre through a human-AI partnership.","meta":{"url":"http://arxiv.org/abs/2307.05328v1"},"cats":{"new-dataset":0.2085396923,"dev-research":0.3986836881,"prompt-eng":0.503502238,"data-quality":0.2052976993,"ml-security":0.0989737968}}
{"text":"Our model is able to generate multiple guitar, bass guitar, drums, piano and orchestral parts.","meta":{"url":"http://arxiv.org/abs/2307.05328v1"},"cats":{"new-dataset":0.2177865609,"dev-research":0.4083149888,"prompt-eng":0.4733606891,"data-quality":0.084931897,"ml-security":0.0648484298}}
{"text":"We examine the validity of the generated music using a mixed methods approach by combining quantitative analyses following a computational musicology paradigm and qualitative analyses following a practice-based research paradigm.","meta":{"url":"http://arxiv.org/abs/2307.05328v1"},"cats":{"new-dataset":0.1134945202,"dev-research":0.4323034028,"prompt-eng":0.3673270534,"data-quality":0.1829027398,"ml-security":0.0484235477}}
{"text":"Finally, we demonstrate the value of the model by using it as a tool to create a progressive metal song, fully produced and mixed by a human metal producer based on AI-generated music.","meta":{"url":"http://arxiv.org/abs/2307.05328v1"},"cats":{"new-dataset":0.125642717,"dev-research":0.4398790438,"prompt-eng":0.4646899728,"data-quality":0.1491899916,"ml-security":0.0807851697}}
{"text":"Self-supervised methods have been proven effective for learning deep representations of 3D point cloud data.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.1975781285,"dev-research":0.3685210862,"prompt-eng":0.4098133715,"data-quality":0.176903007,"ml-security":0.1621360611}}
{"text":"Although recent methods in this domain often rely on random masking of inputs, the results of this approach can be improved.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.0730472535,"dev-research":0.3814936085,"prompt-eng":0.4348110554,"data-quality":0.2917834255,"ml-security":0.4025976316}}
{"text":"We introduce PointCAM, a novel adversarial method for learning a masking function for point clouds.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.1729689907,"dev-research":0.3817860853,"prompt-eng":0.3698358717,"data-quality":0.2198243695,"ml-security":0.4907274202}}
{"text":"Our model utilizes a self-distillation framework with an online tokenizer for 3D point clouds.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.0691388299,"dev-research":0.3789648634,"prompt-eng":0.4225170782,"data-quality":0.1076408292,"ml-security":0.1002917506}}
{"text":"Compared to previous techniques that optimize patch-level and object-level objectives, we postulate applying an auxiliary network that learns how to select masks instead of choosing them randomly.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.0857908965,"dev-research":0.4228610446,"prompt-eng":0.4718986666,"data-quality":0.1587110122,"ml-security":0.328643681}}
{"text":"Our results show that the learned masking function achieves state-of-the-art or competitive performance on various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.0669788923,"dev-research":0.3841951496,"prompt-eng":0.3976347281,"data-quality":0.1478543096,"ml-security":0.3569865049}}
{"text":"The source code is available at https://github.com/szacho/pointcam.","meta":{"url":"http://arxiv.org/abs/2307.05325v1"},"cats":{"new-dataset":0.2936932835,"dev-research":0.4624677553,"prompt-eng":0.4117555486,"data-quality":0.0955261829,"ml-security":0.0788096361}}
{"text":"GuitarPro format tablatures are a type of digital music notation that encapsulates information about guitar playing techniques and fingerings.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1335182332,"dev-research":0.4492811692,"prompt-eng":0.4672621129,"data-quality":0.1549023189,"ml-security":0.0796459036}}
{"text":"We introduce ShredGP, a GuitarPro tablature generative Transformer-based model conditioned to imitate the style of four distinct iconic electric guitarists.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1051928287,"dev-research":0.3892211145,"prompt-eng":0.4540361916,"data-quality":0.1027770613,"ml-security":0.108072248}}
{"text":"In order to assess the idiosyncrasies of each guitar player, we adopt a computational musicology methodology by analysing features computed from the tokens yielded by the DadaGP encoding scheme.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1622300845,"dev-research":0.432574184,"prompt-eng":0.4419557081,"data-quality":0.2445818803,"ml-security":0.1084921344}}
{"text":"Statistical analyses of the features evidence significant differences between the four guitarists.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1866948958,"dev-research":0.4058147632,"prompt-eng":0.420046823,"data-quality":0.1618145344,"ml-security":0.1052446901}}
{"text":"We trained two variants of the ShredGP model, one using a multi-instrument corpus, the other using solo guitar data.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.3070398939,"dev-research":0.3586878172,"prompt-eng":0.4775365545,"data-quality":0.1639256758,"ml-security":0.1159499042}}
{"text":"We present a BERT-based model for guitar player classification and use it to evaluate the generated examples.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.2612132326,"dev-research":0.4436334345,"prompt-eng":0.5090345282,"data-quality":0.2636677112,"ml-security":0.1545447656}}
{"text":"Overall, results from the classifier show that ShredGP is able to generate content congruent with the style of the targeted guitar player.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1564735746,"dev-research":0.4278533918,"prompt-eng":0.4382380347,"data-quality":0.1496889366,"ml-security":0.1423137431}}
{"text":"Finally, we reflect on prospective applications for ShredGP for human-AI music interaction.","meta":{"url":"http://arxiv.org/abs/2307.05324v1"},"cats":{"new-dataset":0.1411416642,"dev-research":0.4127298287,"prompt-eng":0.4652715096,"data-quality":0.1310345485,"ml-security":0.1302974349}}
{"text":"The long-tailed image classification task remains important in the development of deep neural networks as it explicitly deals with large imbalances in the class frequencies of the training data.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.2079459222,"dev-research":0.349238035,"prompt-eng":0.4295296533,"data-quality":0.1925482111,"ml-security":0.3158594972}}
{"text":"While uncommon in engineered datasets, this imbalance is almost always present in real-world data.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.3388330394,"dev-research":0.3849066145,"prompt-eng":0.4186972877,"data-quality":0.2251546176,"ml-security":0.2862065185}}
{"text":"Previous approaches have shown that combining cross-entropy and contrastive learning can improve performance on the long-tailed task, but they do not explore the tradeoff between head and tail classes.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.0913863708,"dev-research":0.3651824052,"prompt-eng":0.4367478091,"data-quality":0.0784842186,"ml-security":0.1583087867}}
{"text":"We propose a novel class instance balanced loss (CIBL), which reweights the relative contributions of a cross-entropy and a contrastive loss as a function of the frequency of class instances in the training batch.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.1584030149,"dev-research":0.3631119179,"prompt-eng":0.4701027189,"data-quality":0.2411226391,"ml-security":0.269337158}}
{"text":"This balancing favours the contrastive loss for more common classes, leading to a learned classifier with a more balanced performance across all class frequencies.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.0898659108,"dev-research":0.3638429238,"prompt-eng":0.3908328447,"data-quality":0.1885721084,"ml-security":0.2377183769}}
{"text":"Furthermore, increasing the relative weight on the contrastive head shifts performance from common (head) to rare (tail) classes, allowing the user to skew the performance towards these classes if desired.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.0378967394,"dev-research":0.3808139363,"prompt-eng":0.4293971526,"data-quality":0.107426998,"ml-security":0.0914884043}}
{"text":"We also show that changing the linear classifier head with a cosine classifier yields a network that can be trained to similar performance in substantially fewer epochs.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.0963339628,"dev-research":0.3850463191,"prompt-eng":0.411513717,"data-quality":0.2714545275,"ml-security":0.289398721}}
{"text":"We obtain competitive results on both CIFAR-100-LT and ImageNet-LT.","meta":{"url":"http://arxiv.org/abs/2307.05322v1"},"cats":{"new-dataset":0.1898193127,"dev-research":0.360230771,"prompt-eng":0.4007266143,"data-quality":0.1218016509,"ml-security":0.111771032}}
{"text":"Semantic image synthesis (SIS) refers to the problem of generating realistic imagery given a semantic segmentation mask that defines the spatial layout of object classes.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.2012064305,"dev-research":0.432336413,"prompt-eng":0.4523400311,"data-quality":0.1674784807,"ml-security":0.0846135995}}
{"text":"Most of the approaches in the literature, other than the quality of the generated images, put effort in finding solutions to increase the generation diversity in terms of style i.e. texture.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.1193439117,"dev-research":0.4610928671,"prompt-eng":0.4161441742,"data-quality":0.1352799276,"ml-security":0.0452051967}}
{"text":"However, they all neglect a different feature, which is the possibility of manipulating the layout provided by the mask.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.0374498906,"dev-research":0.4427005836,"prompt-eng":0.3888985302,"data-quality":0.1099791657,"ml-security":0.1147710506}}
{"text":"Currently, the only way to do so is manually by means of graphical users interfaces.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.0974687183,"dev-research":0.452676671,"prompt-eng":0.4936969241,"data-quality":0.1082934243,"ml-security":0.1252849625}}
{"text":"In this paper, we describe a network architecture to address the problem of automatically manipulating or generating the shape of object classes in semantic segmentation masks, with specific focus on human faces.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.1403504745,"dev-research":0.4018164763,"prompt-eng":0.4592813975,"data-quality":0.1896000334,"ml-security":0.2372303986}}
{"text":"Our proposed model allows embedding the mask class-wise into a latent space where each class embedding can be independently edited.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.1063375934,"dev-research":0.3943597996,"prompt-eng":0.4588662411,"data-quality":0.2186362055,"ml-security":0.261790975}}
{"text":"Then, a bi-directional LSTM block and a convolutional decoder output a new, locally manipulated mask.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.154953429,"dev-research":0.3924537115,"prompt-eng":0.4488591648,"data-quality":0.1297255394,"ml-security":0.1707305727}}
{"text":"We report quantitative and qualitative results on the CelebMask-HQ dataset, which show our model can both faithfully reconstruct and modify a segmentation mask at the class level.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.5163993867,"dev-research":0.3790354642,"prompt-eng":0.4809241439,"data-quality":0.2812226278,"ml-security":0.2018904201}}
{"text":"Also, we show our model can be put before a SIS generator, opening the way to a fully automatic generation control of both shape and texture.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.1453166696,"dev-research":0.4234964282,"prompt-eng":0.5135793882,"data-quality":0.0966102872,"ml-security":0.0639514921}}
{"text":"Code available at https://github.com/TFonta/Semantic-VAE.","meta":{"url":"http://arxiv.org/abs/2307.05317v1"},"cats":{"new-dataset":0.0965156928,"dev-research":0.4546405292,"prompt-eng":0.5109187044,"data-quality":0.2312792179,"ml-security":0.0647952973}}
{"text":"Medical visual question answering (VQA) is a challenging task that requires answering clinical questions of a given medical image, by taking consider of both visual and language information.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.2076845036,"dev-research":0.4271824464,"prompt-eng":0.4488820496,"data-quality":0.1569290268,"ml-security":0.079790611}}
{"text":"However, due to the small scale of training data for medical VQA, pre-training fine-tuning paradigms have been a commonly used solution to improve model generalization performance.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.071983485,"dev-research":0.4039498671,"prompt-eng":0.4749104261,"data-quality":0.1338369558,"ml-security":0.1841708946}}
{"text":"In this paper, we present a novel self-supervised approach that learns unimodal and multimodal feature representations of input images and text using medical image caption datasets, by leveraging both unimodal and multimodal contrastive losses, along with masked language modeling and image text matching as pretraining objectives.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.3417824159,"dev-research":0.3993825447,"prompt-eng":0.5392614081,"data-quality":0.2905045852,"ml-security":0.1909018399}}
{"text":"The pre-trained model is then transferred to downstream medical VQA tasks.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.0947945355,"dev-research":0.4226198487,"prompt-eng":0.4801335513,"data-quality":0.0734061668,"ml-security":0.1134622447}}
{"text":"The proposed approach achieves state-of-the-art (SOTA) performance on three publicly available medical VQA datasets with significant accuracy improvements of 2.2%, 14.7%, and 1.7% respectively.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.4941112803,"dev-research":0.3591289899,"prompt-eng":0.4147781178,"data-quality":0.1158529223,"ml-security":0.1203065525}}
{"text":"Besides, we conduct a comprehensive analysis to validate the effectiveness of different components of the approach and study different pre-training settings.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.0747445173,"dev-research":0.4229016883,"prompt-eng":0.4751695705,"data-quality":0.1168911235,"ml-security":0.1146000489}}
{"text":"Our codes and models are available at https://github.com/pengfeiliHEU/MUMC.","meta":{"url":"http://arxiv.org/abs/2307.05314v1"},"cats":{"new-dataset":0.5143085928,"dev-research":0.4373414846,"prompt-eng":0.5231679617,"data-quality":0.0759337103,"ml-security":0.0810169588}}
{"text":"Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.0900894082,"dev-research":0.4723066675,"prompt-eng":0.4406983919,"data-quality":0.0978064074,"ml-security":0.0762100046}}
{"text":"Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.0944432329,"dev-research":0.4511736109,"prompt-eng":0.5335675503,"data-quality":0.0836599804,"ml-security":0.1007220151}}
{"text":"In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.1171348958,"dev-research":0.4436041611,"prompt-eng":0.5857925968,"data-quality":0.069886575,"ml-security":0.0817663864}}
{"text":"A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.097225607,"dev-research":0.4718194234,"prompt-eng":0.4590315981,"data-quality":0.0818397221,"ml-security":0.078272576}}
{"text":"By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.1059335671,"dev-research":0.4590414923,"prompt-eng":0.5847163929,"data-quality":0.094539069,"ml-security":0.1742673008}}
{"text":"We have discovered that assigning multiple, fine-grained personas in LLMs elicits better problem-solving abilities compared to using a single or fixed number of personas.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.0855594605,"dev-research":0.4827330321,"prompt-eng":0.5299704019,"data-quality":0.0983429341,"ml-security":0.14375333}}
{"text":"We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.2852417352,"dev-research":0.538796464,"prompt-eng":0.4819243348,"data-quality":0.1547196682,"ml-security":0.0671135514}}
{"text":"Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP effectively elicits internal knowledge acquisition abilities, reduces hallucination, and maintains strong reasoning capabilities.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.0665681418,"dev-research":0.4795495956,"prompt-eng":0.507180487,"data-quality":0.0798338889,"ml-security":0.101679201}}
{"text":"Code, data, and prompts can be found at: https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.","meta":{"url":"http://arxiv.org/abs/2307.05300v1"},"cats":{"new-dataset":0.3344325763,"dev-research":0.4905490887,"prompt-eng":0.5791394019,"data-quality":0.1196368599,"ml-security":0.0661142855}}
{"text":"The time evolution of physical systems is described by differential equations, which depend on abstract quantities like energy and force.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.124341293,"dev-research":0.4464092889,"prompt-eng":0.3803158302,"data-quality":0.0576123585,"ml-security":0.1780626442}}
{"text":"Traditionally, these quantities are derived as functionals based on observables such as positions and velocities.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.0921001235,"dev-research":0.3938097679,"prompt-eng":0.3813581726,"data-quality":0.066412767,"ml-security":0.0925439854}}
{"text":"Discovering these governing symbolic laws is the key to comprehending the interactions in nature.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.1195763222,"dev-research":0.4961728589,"prompt-eng":0.4349601814,"data-quality":0.0868013623,"ml-security":0.1115963038}}
{"text":"Here, we present a Hamiltonian graph neural network (HGNN), a physics-enforced GNN that learns the dynamics of systems directly from their trajectory.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.2516921993,"dev-research":0.3618641349,"prompt-eng":0.4020536472,"data-quality":0.0845189227,"ml-security":0.1847620257}}
{"text":"We demonstrate the performance of HGNN on n-springs, n-pendulums, gravitational systems, and binary Lennard Jones systems; HGNN learns the dynamics in excellent agreement with the ground truth from small amounts of data.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.1295091347,"dev-research":0.3717472694,"prompt-eng":0.4094499211,"data-quality":0.095669446,"ml-security":0.1526345444}}
{"text":"We also evaluate the ability of HGNN to generalize to larger system sizes, and to hybrid spring-pendulum system that is a combination of two original systems (spring and pendulum) on which the models are trained independently.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.0448409237,"dev-research":0.3706067515,"prompt-eng":0.4372544341,"data-quality":0.0695769309,"ml-security":0.1454226843}}
{"text":"Finally, employing symbolic regression on the learned HGNN, we infer the underlying equations relating the energy functionals, even for complex systems such as the binary Lennard-Jones liquid.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.0864448467,"dev-research":0.4246063221,"prompt-eng":0.4353788021,"data-quality":0.109127783,"ml-security":0.1601337799}}
{"text":"Our framework facilitates the interpretable discovery of interaction laws directly from physical system trajectories.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.1379954894,"dev-research":0.4384192529,"prompt-eng":0.4602297505,"data-quality":0.0546632249,"ml-security":0.1652712093}}
{"text":"Furthermore, this approach can be extended to other systems with topology-dependent dynamics, such as cells, polydisperse gels, or deformable bodies.","meta":{"url":"http://arxiv.org/abs/2307.05299v1"},"cats":{"new-dataset":0.0351593128,"dev-research":0.3882216559,"prompt-eng":0.3699333845,"data-quality":0.0453647399,"ml-security":0.105972724}}
{"text":"This paper proposes a general optimization framework for rate splitting multiple access (RSMA) in beyond diagonal (BD) reconfigurable intelligent surface (RIS) assisted ultra-reliable low-latency communications (URLLC) systems.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.061281411,"dev-research":0.3623285899,"prompt-eng":0.3768417044,"data-quality":0.0576158964,"ml-security":0.1176021385}}
{"text":"This framework can solve a large family of optimization problems in which the objective and/or constraints are linear functions of the rates and/or energy efficiency (EE) of users.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.1042512087,"dev-research":0.4124432177,"prompt-eng":0.3866146148,"data-quality":0.0758182027,"ml-security":0.1510823976}}
{"text":"Using this framework, we show that RSMA and RIS can be mutually beneficial tools when the system is overloaded, i.e., when the number of users per cell is higher than the number of base station (BS) antennas.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.047841142,"dev-research":0.4086915995,"prompt-eng":0.4071297216,"data-quality":0.073987948,"ml-security":0.2052768551}}
{"text":"Additionally, we show that the benefits of RSMA increase when the packets are shorter and/or the reliability constraint is more stringent.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.0705826393,"dev-research":0.41281933,"prompt-eng":0.390413167,"data-quality":0.134766719,"ml-security":0.1591541451}}
{"text":"Furthermore, we show that the RSMA benefits increase with the number of users per cell and decrease with the number of BS antennas.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.0832369459,"dev-research":0.404979238,"prompt-eng":0.3881694544,"data-quality":0.0499467925,"ml-security":0.1514612136}}
{"text":"Finally, we show that RIS (either diagonal or BD) can highly improve the system performance, and BD-RIS outperforms regular RIS.","meta":{"url":"http://arxiv.org/abs/2307.05295v1"},"cats":{"new-dataset":0.042923535,"dev-research":0.3762800358,"prompt-eng":0.4376574406,"data-quality":0.1048031603,"ml-security":0.1259494905}}
{"text":"Autonomous vehicles require accurate and reliable short-term trajectory predictions for safe and efficient driving.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.1477865531,"dev-research":0.3595135646,"prompt-eng":0.411171201,"data-quality":0.1097855759,"ml-security":0.1890300642}}
{"text":"While most commercial automated vehicles currently use state machine-based algorithms for trajectory forecasting, recent efforts have focused on end-to-end data-driven systems.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.2484464211,"dev-research":0.3696783596,"prompt-eng":0.448147992,"data-quality":0.067451322,"ml-security":0.1491360609}}
{"text":"Often, the design of these models is limited by the availability of datasets, which are typically restricted to generic scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.2120886936,"dev-research":0.3871350998,"prompt-eng":0.406097549,"data-quality":0.0534942631,"ml-security":0.2556231636}}
{"text":"To address this limitation, we have developed a synthetic dataset for short-term trajectory prediction tasks using the CARLA simulator.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.4533321941,"dev-research":0.3565064874,"prompt-eng":0.4696366542,"data-quality":0.0620501921,"ml-security":0.149611454}}
{"text":"This dataset is extensive and incorporates what is considered complex scenarios - pedestrians crossing the road, vehicles overtaking - and comprises 6000 perspective view images with corresponding IMU and odometry information for each frame.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.7761144927,"dev-research":0.3616071036,"prompt-eng":0.4188757298,"data-quality":0.0660738715,"ml-security":0.0934131076}}
{"text":"Furthermore, an end-to-end short-term trajectory prediction model using convolutional neural networks (CNN) and long short-term memory (LSTM) networks has also been developed.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.3135436135,"dev-research":0.338869798,"prompt-eng":0.4381819679,"data-quality":0.0622469064,"ml-security":0.1499350698}}
{"text":"This model can handle corner cases, such as slowing down near zebra crossings and stopping when pedestrians cross the road, without the need for explicit encoding of the surrounding environment.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.1582038206,"dev-research":0.4093025932,"prompt-eng":0.390615409,"data-quality":0.0694216451,"ml-security":0.1935106233}}
{"text":"In an effort to accelerate this research and assist others, we are releasing our dataset and model to the research community.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.6848603773,"dev-research":0.4431202468,"prompt-eng":0.4876115091,"data-quality":0.120326885,"ml-security":0.1828093617}}
{"text":"Our datasets are publicly available on https://github.com/navigatinguncertainty.","meta":{"url":"http://arxiv.org/abs/2307.05288v1"},"cats":{"new-dataset":0.8385569008,"dev-research":0.392459767,"prompt-eng":0.5050234378,"data-quality":0.0853064026,"ml-security":0.1476329616}}
{"text":"Different distribution shifts require different algorithmic and operational interventions.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.0449221548,"dev-research":0.3758197948,"prompt-eng":0.3644951737,"data-quality":0.0723764065,"ml-security":0.1291292282}}
{"text":"Methodological research must be grounded by the specific shifts they address.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.0880533368,"dev-research":0.4541374298,"prompt-eng":0.3701057601,"data-quality":0.1056486561,"ml-security":0.0846459791}}
{"text":"Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.0511425023,"dev-research":0.401155291,"prompt-eng":0.3809645922,"data-quality":0.1036057716,"ml-security":0.1699925928}}
{"text":"We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.3613748016,"dev-research":0.3899423816,"prompt-eng":0.4211576948,"data-quality":0.1012002808,"ml-security":0.1364264329}}
{"text":"To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.1866181374,"dev-research":0.4563551876,"prompt-eng":0.4657768842,"data-quality":0.123323552,"ml-security":0.1059568141}}
{"text":"Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithmic and data-based interventions.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.1092926795,"dev-research":0.4113411412,"prompt-eng":0.3994617738,"data-quality":0.1002237112,"ml-security":0.1454142702}}
{"text":"Our testbed highlights the importance of future research that builds an understanding of how distributions differ.","meta":{"url":"http://arxiv.org/abs/2307.05284v1"},"cats":{"new-dataset":0.1548202,"dev-research":0.4384591343,"prompt-eng":0.4779572583,"data-quality":0.1257591108,"ml-security":0.1301107173}}
{"text":"We study the Identity Problem, the problem of determining if a finitely generated semigroup of matrices contains the identity matrix; see Problem 3 (Chapter 10.3) in ``Unsolved Problems in Mathematical Systems and Control Theory'' by Blondel and Megretski (2004).","meta":{"url":"http://arxiv.org/abs/2307.05283v1"},"cats":{"new-dataset":0.0785834301,"dev-research":0.3973293046,"prompt-eng":0.3890379833,"data-quality":0.1436847383,"ml-security":0.2378169545}}
{"text":"This fundamental problem is known to be undecidable for $\\mathbb{Z}^{4 \\times 4}$ and decidable for $\\mathbb{Z}^{2 \\times 2}$.","meta":{"url":"http://arxiv.org/abs/2307.05283v1"},"cats":{"new-dataset":0.0788582665,"dev-research":0.3978772598,"prompt-eng":0.3740215769,"data-quality":0.1547494636,"ml-security":0.1763785519}}
{"text":"The Identity Problem has been recently shown to be in polynomial time by Dong for the Heisenberg group over complex numbers in any fixed dimension with the use of Lie algebra and the Baker-Campbell-Hausdorff formula.","meta":{"url":"http://arxiv.org/abs/2307.05283v1"},"cats":{"new-dataset":0.091662771,"dev-research":0.3782884817,"prompt-eng":0.355009775,"data-quality":0.1017346514,"ml-security":0.1788443045}}
{"text":"We develop alternative proof techniques for the problem making a step forward towards more general problems such as the Membership Problem.","meta":{"url":"http://arxiv.org/abs/2307.05283v1"},"cats":{"new-dataset":0.0723875299,"dev-research":0.4592630451,"prompt-eng":0.3862083937,"data-quality":0.2320950305,"ml-security":0.2551760064}}
{"text":"We extend our techniques to show that the fundamental problem of determining if a given set of Heisenberg matrices generates a group, can also be decided in polynomial time.","meta":{"url":"http://arxiv.org/abs/2307.05283v1"},"cats":{"new-dataset":0.0707747553,"dev-research":0.3985318448,"prompt-eng":0.3860280971,"data-quality":0.0726803678,"ml-security":0.1589713567}}
{"text":"Probabilistic hyperproperties express probabilistic relations between different executions of systems with uncertain behavior.","meta":{"url":"http://arxiv.org/abs/2307.05282v1"},"cats":{"new-dataset":0.0360597741,"dev-research":0.4814189901,"prompt-eng":0.4631194436,"data-quality":0.1630988018,"ml-security":0.19986942}}
{"text":"HyperPCTL allows to formalize such properties, where quantification over probabilistic schedulers resolves potential non-determinism.","meta":{"url":"http://arxiv.org/abs/2307.05282v1"},"cats":{"new-dataset":0.0642647375,"dev-research":0.4499773938,"prompt-eng":0.4109082376,"data-quality":0.0890421962,"ml-security":0.1976636533}}
{"text":"In this paper we propose an extension named AHyperPCTL to additionally introduce asynchronicity between the observed executions by quantifying over stutter-schedulers, which may randomly decide to delay scheduler decisions by idling.","meta":{"url":"http://arxiv.org/abs/2307.05282v1"},"cats":{"new-dataset":0.0702436528,"dev-research":0.4396493185,"prompt-eng":0.4628791085,"data-quality":0.2167373664,"ml-security":0.1878963924}}
{"text":"To our knowledge, this is the first asynchronous extension of a probabilistic branching-time hyperlogic.","meta":{"url":"http://arxiv.org/abs/2307.05282v1"},"cats":{"new-dataset":0.0786412002,"dev-research":0.4512621596,"prompt-eng":0.4450184848,"data-quality":0.0978742392,"ml-security":0.0886032386}}
{"text":"We show that AHyperPCTL can express interesting information-flow security policies, and propose a model checking algorithm for a decidable fragment.","meta":{"url":"http://arxiv.org/abs/2307.05282v1"},"cats":{"new-dataset":0.1085975243,"dev-research":0.4738058949,"prompt-eng":0.4654641251,"data-quality":0.1452691633,"ml-security":0.4143523782}}
{"text":"Hands-on computing education requires a realistic learning environment that enables students to gain and deepen their skills.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1833655682,"dev-research":0.4959944308,"prompt-eng":0.4253448882,"data-quality":0.0728850977,"ml-security":0.3254112102}}
{"text":"Available learning environments, including virtual and physical labs, provide students with real-world computer systems but rarely adapt the learning environment to individual students of various proficiency and background.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1865967471,"dev-research":0.4531605139,"prompt-eng":0.4314206872,"data-quality":0.0934364835,"ml-security":0.2506952865}}
{"text":"We designed a unique and novel smart environment for adaptive training of cybersecurity skills.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1618027587,"dev-research":0.468709401,"prompt-eng":0.4858331815,"data-quality":0.0958300319,"ml-security":0.5878902765}}
{"text":"The environment collects a variety of student data to assign a suitable learning path through the training.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.4001346464,"dev-research":0.4586621707,"prompt-eng":0.4945252944,"data-quality":0.0891605936,"ml-security":0.2191851027}}
{"text":"To enable such adaptiveness, we proposed, developed, and deployed a new tutor model and a training format.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1220433163,"dev-research":0.4599705014,"prompt-eng":0.5381686331,"data-quality":0.1606421602,"ml-security":0.1569347835}}
{"text":"We evaluated the learning environment using two different adaptive trainings attended by 114 students of various proficiency.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1207710758,"dev-research":0.4343129937,"prompt-eng":0.4273335501,"data-quality":0.1156712895,"ml-security":0.1447588751}}
{"text":"The results show students were assigned tasks with a more appropriate difficulty, which enabled them to successfully complete the training.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.0799261043,"dev-research":0.4622807648,"prompt-eng":0.4358581492,"data-quality":0.1632189332,"ml-security":0.1107353774}}
{"text":"Students reported that they enjoyed the training, felt the training difficulty was appropriately designed, and would attend more training sessions like these.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1065098056,"dev-research":0.4470611293,"prompt-eng":0.438576719,"data-quality":0.1830998922,"ml-security":0.1463166592}}
{"text":"Instructors can use the environment for teaching any topic involving real-world computer networks and systems because it is not tailored to particular training.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.1192771971,"dev-research":0.4815355988,"prompt-eng":0.4114572691,"data-quality":0.094726942,"ml-security":0.3457400789}}
{"text":"We freely released the software along with exemplary training so that other instructors can adopt the innovations in their teaching practice.","meta":{"url":"http://arxiv.org/abs/2307.05281v1"},"cats":{"new-dataset":0.3572527415,"dev-research":0.5334502736,"prompt-eng":0.485739201,"data-quality":0.0875879551,"ml-security":0.1718618549}}
{"text":"The growing spread of robots for service and industrial purposes calls for versatile, intuitive and portable interaction approaches.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0630809555,"dev-research":0.4446528308,"prompt-eng":0.4362443139,"data-quality":0.037997713,"ml-security":0.0766305731}}
{"text":"In particular, in industrial environments, operators should be able to interact with robots in a fast, effective, and possibly effortless manner.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0391698976,"dev-research":0.4475489171,"prompt-eng":0.4411725173,"data-quality":0.0578875237,"ml-security":0.0981669537}}
{"text":"To this end, reality enhancement techniques have been used to achieve efficient management and simplify interactions, in particular in manufacturing and logistics processes.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0535389367,"dev-research":0.4496789798,"prompt-eng":0.387024229,"data-quality":0.0710488538,"ml-security":0.0578749477}}
{"text":"Building upon this, in this paper we propose a system based on mixed reality that allows a ubiquitous interface for heterogeneous robotic systems in dynamic scenarios, where users are involved in different tasks and need to interact with different robots.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.1331162489,"dev-research":0.4055752023,"prompt-eng":0.4295205952,"data-quality":0.0469930284,"ml-security":0.0561372792}}
{"text":"By means of mixed reality, users can interact with a robot through manipulation of its virtual replica, which is always colocated with the user and is extracted when interaction is needed.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0926364733,"dev-research":0.4130301855,"prompt-eng":0.4373764328,"data-quality":0.0439636871,"ml-security":0.0637199399}}
{"text":"The system has been tested in a simulated intralogistics setting, where different robots are present and require sporadic intervention by human operators, who are involved in other tasks.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0666462997,"dev-research":0.3861124751,"prompt-eng":0.4736631313,"data-quality":0.0715116791,"ml-security":0.086894001}}
{"text":"In our setting we consider the presence of drones and AGVs with different levels of autonomy, calling for different user interventions.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.114782462,"dev-research":0.4415952993,"prompt-eng":0.4686388132,"data-quality":0.0615052146,"ml-security":0.1163219759}}
{"text":"The proposed approach has been validated in virtual reality, considering quantitative and qualitative assessment of performance and user's feedback.","meta":{"url":"http://arxiv.org/abs/2307.05280v1"},"cats":{"new-dataset":0.0563309724,"dev-research":0.424416098,"prompt-eng":0.4098707757,"data-quality":0.1118297731,"ml-security":0.0470968339}}
{"text":"Despite the impressive performance of recent unbiased Scene Graph Generation (SGG) methods, the current debiasing literature mainly focuses on the long-tailed distribution problem, whereas it overlooks another source of bias, i.e., semantic confusion, which makes the SGG model prone to yield false predictions for similar relationships.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.2403367193,"dev-research":0.3960962449,"prompt-eng":0.4638968227,"data-quality":0.3083454117,"ml-security":0.079781335}}
{"text":"In this paper, we explore a debiasing procedure for the SGG task leveraging causal inference.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.0951999902,"dev-research":0.446543078,"prompt-eng":0.5202976388,"data-quality":0.1630016398,"ml-security":0.1213923043}}
{"text":"Our central insight is that the Sparse Mechanism Shift (SMS) in causality allows independent intervention on multiple biases, thereby potentially preserving head category performance while pursuing the prediction of high-informative tail relationships.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.0513929885,"dev-research":0.4206381671,"prompt-eng":0.4848892214,"data-quality":0.117966119,"ml-security":0.145856106}}
{"text":"However, the noisy datasets lead to unobserved confounders for the SGG task, and thus the constructed causal models are always causal-insufficient to benefit from SMS.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.1173384324,"dev-research":0.4402792506,"prompt-eng":0.5020018368,"data-quality":0.234986742,"ml-security":0.2341158801}}
{"text":"To remedy this, we propose Two-stage Causal Modeling (TsCM) for the SGG task, which takes the long-tailed distribution and semantic confusion as confounders to the Structural Causal Model (SCM) and then decouples the causal intervention into two stages.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.0779012714,"dev-research":0.4398765363,"prompt-eng":0.5425342969,"data-quality":0.1844088024,"ml-security":0.1153808362}}
{"text":"The first stage is causal representation learning, where we use a novel Population Loss (P-Loss) to intervene in the semantic confusion confounder.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.1386213195,"dev-research":0.4502547661,"prompt-eng":0.5346234048,"data-quality":0.4608591234,"ml-security":0.2025827534}}
{"text":"The second stage introduces the Adaptive Logit Adjustment (AL-Adjustment) to eliminate the long-tailed distribution confounder to complete causal calibration learning.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.0863704252,"dev-research":0.4051883056,"prompt-eng":0.4899120456,"data-quality":0.1792057058,"ml-security":0.1906972133}}
{"text":"These two stages are model agnostic and thus can be used in any SGG model that seeks unbiased predictions.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.0506837259,"dev-research":0.354274709,"prompt-eng":0.4572429973,"data-quality":0.073092357,"ml-security":0.0895166606}}
{"text":"Comprehensive experiments conducted on the popular SGG backbones and benchmarks show that our TsCM can achieve state-of-the-art performance in terms of mean recall rate.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.1064553292,"dev-research":0.3700702965,"prompt-eng":0.5304812464,"data-quality":0.0992561518,"ml-security":0.1029493553}}
{"text":"Furthermore, TsCM can maintain a higher recall rate than other debiasing methods, which indicates that our method can achieve a better tradeoff between head and tail relationships.","meta":{"url":"http://arxiv.org/abs/2307.05276v1"},"cats":{"new-dataset":0.082428355,"dev-research":0.4139753862,"prompt-eng":0.5002898982,"data-quality":0.1164372558,"ml-security":0.1157009921}}
{"text":"The aging population has led to a growing number of falls in our society, affecting global public health worldwide.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.3414842247,"dev-research":0.4110228385,"prompt-eng":0.4179062295,"data-quality":0.0766724841,"ml-security":0.1537943896}}
{"text":"This paper presents CareFall, an automatic Fall Detection System (FDS) based on wearable devices and Artificial Intelligence (AI) methods.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.3080221698,"dev-research":0.3883394927,"prompt-eng":0.4349302361,"data-quality":0.0995164009,"ml-security":0.1152842822}}
{"text":"CareFall considers the accelerometer and gyroscope time signals extracted from a smartwatch.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.1581222273,"dev-research":0.4066083221,"prompt-eng":0.4164051443,"data-quality":0.1014913067,"ml-security":0.0990721468}}
{"text":"Two different approaches are used for feature extraction and classification: i) threshold-based, and ii) machine learning-based.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.1095292484,"dev-research":0.4251685213,"prompt-eng":0.4090784839,"data-quality":0.2218619926,"ml-security":0.1595478091}}
{"text":"Experimental results on two public databases show that the machine learning-based approach, which combines accelerometer and gyroscope information, outperforms the threshold-based approach in terms of accuracy, sensitivity, and specificity.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.1570479032,"dev-research":0.360985319,"prompt-eng":0.4383351766,"data-quality":0.1485307478,"ml-security":0.2364484643}}
{"text":"This research contributes to the design of smart and user-friendly solutions to mitigate the negative consequences of falls among older people.","meta":{"url":"http://arxiv.org/abs/2307.05275v1"},"cats":{"new-dataset":0.2319998016,"dev-research":0.4554895781,"prompt-eng":0.4304937595,"data-quality":0.0940918496,"ml-security":0.1806379064}}
{"text":"Temporal graphs have become an essential tool for analyzing complex dynamic systems with multiple agents.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.1790664109,"dev-research":0.4571432675,"prompt-eng":0.4093477519,"data-quality":0.0535148322,"ml-security":0.1125521597}}
{"text":"Detecting anomalies in temporal graphs is crucial for various applications, including identifying emerging trends, monitoring network security, understanding social dynamics, tracking disease outbreaks, and understanding financial dynamics.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.1589808466,"dev-research":0.4251244472,"prompt-eng":0.3898399977,"data-quality":0.2223974081,"ml-security":0.2931942912}}
{"text":"In this paper, we present a comprehensive benchmarking study that compares 12 data-driven methods for anomaly detection in temporal graphs.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.2246884087,"dev-research":0.4117209085,"prompt-eng":0.3896140201,"data-quality":0.2361157195,"ml-security":0.2499416335}}
{"text":"We conduct experiments on two temporal graphs extracted from Twitter and Facebook, aiming to identify anomalies in group interactions.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.160316003,"dev-research":0.4321828921,"prompt-eng":0.4600296083,"data-quality":0.1691530027,"ml-security":0.1603895988}}
{"text":"Surprisingly, our study reveals an unclear pattern regarding the best method for such tasks, highlighting the complexity and challenges involved in anomaly emergence detection in large and dynamic systems.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.0942491217,"dev-research":0.4416837678,"prompt-eng":0.4132755602,"data-quality":0.1553653921,"ml-security":0.3647078671}}
{"text":"The results underscore the need for further research and innovative approaches to effectively detect emerging anomalies in dynamic systems represented as temporal graphs.","meta":{"url":"http://arxiv.org/abs/2307.05268v1"},"cats":{"new-dataset":0.1027425679,"dev-research":0.4396488105,"prompt-eng":0.4019379018,"data-quality":0.1980849563,"ml-security":0.2231413677}}
{"text":"We study the problem of computing minimal distinguishing formulas for non-bisimilar states in finite LTSs.","meta":{"url":"http://arxiv.org/abs/2307.05265v1"},"cats":{"new-dataset":0.0548502896,"dev-research":0.3713942437,"prompt-eng":0.3956735283,"data-quality":0.116931133,"ml-security":0.1222446612}}
{"text":"We show that this is NP-hard if the size of the formula must be minimal.","meta":{"url":"http://arxiv.org/abs/2307.05265v1"},"cats":{"new-dataset":0.0908776602,"dev-research":0.3938597241,"prompt-eng":0.3542085996,"data-quality":0.1283055616,"ml-security":0.1089247119}}
{"text":"Similarly, the existence of a short distinguishing trace is NP-complete.","meta":{"url":"http://arxiv.org/abs/2307.05265v1"},"cats":{"new-dataset":0.1058367999,"dev-research":0.4411668207,"prompt-eng":0.3878411735,"data-quality":0.1781490581,"ml-security":0.1232232711}}
{"text":"However, we can provide polynomial algorithms, if minimality is formulated as the minimal number of nested modalities, and it can even be extended by recursively requiring a minimal number of nested negations.","meta":{"url":"http://arxiv.org/abs/2307.05265v1"},"cats":{"new-dataset":0.0455930752,"dev-research":0.4256385582,"prompt-eng":0.381242161,"data-quality":0.1530069792,"ml-security":0.135539936}}
{"text":"A prototype implementation shows that the generated formulas are much smaller than those generated by the method introduced by Cleaveland.","meta":{"url":"http://arxiv.org/abs/2307.05265v1"},"cats":{"new-dataset":0.0702293026,"dev-research":0.4745081344,"prompt-eng":0.3495129604,"data-quality":0.0909910252,"ml-security":0.0990403447}}
{"text":"Developing and testing novel control and motion planning algorithms for aerial vehicles can be a challenging task, with the robotics community relying more than ever on 3D simulation technologies to evaluate the performance of new algorithms in a variety of conditions and environments.","meta":{"url":"http://arxiv.org/abs/2307.05263v1"},"cats":{"new-dataset":0.1042994817,"dev-research":0.3878563579,"prompt-eng":0.3801971118,"data-quality":0.0409272446,"ml-security":0.0646928313}}
{"text":"In this work, we introduce the Pegasus Simulator, a modular framework implemented as an NVIDIA Isaac Sim extension that enables real-time simulation of multiple multirotor vehicles in photo-realistic environments, while providing out-of-the-box integration with the widely adopted PX4-Autopilot and ROS2 through its modular implementation and intuitive graphical user interface.","meta":{"url":"http://arxiv.org/abs/2307.05263v1"},"cats":{"new-dataset":0.1932436256,"dev-research":0.3726463746,"prompt-eng":0.3874521724,"data-quality":0.057882948,"ml-security":0.0770827211}}
{"text":"To demonstrate some of its capabilities, a nonlinear controller was implemented and simulation results for two drones performing aggressive flight maneuvers are presented.","meta":{"url":"http://arxiv.org/abs/2307.05263v1"},"cats":{"new-dataset":0.1010979717,"dev-research":0.3994447186,"prompt-eng":0.414374745,"data-quality":0.0738858411,"ml-security":0.1471274903}}
{"text":"Code and documentation for this framework are also provided as supplementary material.","meta":{"url":"http://arxiv.org/abs/2307.05263v1"},"cats":{"new-dataset":0.3398807813,"dev-research":0.513249149,"prompt-eng":0.4892439941,"data-quality":0.085842913,"ml-security":0.0860116501}}
{"text":"The task of Prior Case Retrieval (PCR) in the legal domain is about automatically citing relevant (based on facts and precedence) prior legal cases in a given query case.","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.1492742914,"dev-research":0.4618434879,"prompt-eng":0.4706590291,"data-quality":0.168145499,"ml-security":0.1091094922}}
{"text":"To further promote research in PCR, in this paper, we propose a new large benchmark (in English) for the PCR task: IL-PCR (Indian Legal Prior Case Retrieval) corpus.","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.3401835058,"dev-research":0.4118994729,"prompt-eng":0.4676125641,"data-quality":0.1953868708,"ml-security":0.0951303762}}
{"text":"Given the complex nature of case relevance and the long size of legal documents, BM25 remains a strong baseline for ranking the cited prior documents.","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.1456804159,"dev-research":0.4539094681,"prompt-eng":0.423371421,"data-quality":0.1428828688,"ml-security":0.0944680946}}
{"text":"In this work, we explore the role of events in legal case retrieval and propose an unsupervised retrieval method-based pipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction).","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.2443713949,"dev-research":0.4170120147,"prompt-eng":0.4623848826,"data-quality":0.1163505196,"ml-security":0.0872143993}}
{"text":"We find that the proposed unsupervised retrieval method significantly increases performance compared to BM25 and makes retrieval faster by a considerable margin, making it applicable to real-time case retrieval systems.","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.2158392633,"dev-research":0.4218439105,"prompt-eng":0.4498258312,"data-quality":0.093343305,"ml-security":0.0859078899}}
{"text":"Our proposed system is generic, we show that it generalizes across two different legal systems (Indian and Canadian), and it shows state-of-the-art performance on the benchmarks for both the legal systems (IL-PCR and COLIEE corpora).","meta":{"url":"http://arxiv.org/abs/2307.05260v1"},"cats":{"new-dataset":0.2506341238,"dev-research":0.4493782466,"prompt-eng":0.4272175884,"data-quality":0.119372255,"ml-security":0.1275358228}}
{"text":"Efficient planning of scarce resources in hospitals is a challenging task for which a large variety of Operations Research and Management Science approaches have been developed since the 1950s.","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.0719448936,"dev-research":0.4043078747,"prompt-eng":0.3595820565,"data-quality":0.0333586502,"ml-security":0.06851567}}
{"text":"While efficient planning of single resources such as operating rooms, beds, or specific types of staff can already lead to enormous efficiency gains, integrated planning of several resources has been shown to hold even greater potential, and a large number of integrated planning approaches have been presented in the literature over the past decades.   ","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.0542625385,"dev-research":0.4222503769,"prompt-eng":0.3953859452,"data-quality":0.037030575,"ml-security":0.0453380531}}
{"text":"This paper provides the first literature review that focuses specifically on the Operations Research and Management Science literature related to integrated planning of different resources in hospitals.","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.0905245563,"dev-research":0.4295052532,"prompt-eng":0.4193162296,"data-quality":0.0501149311,"ml-security":0.0476758725}}
{"text":"We collect the relevant literature and analyze it regarding different aspects such as uncertainty modeling and the use of real-life data.","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.3599132329,"dev-research":0.3960385889,"prompt-eng":0.4412944739,"data-quality":0.1429324741,"ml-security":0.1163746024}}
{"text":"Several cross comparisons reveal interesting insights concerning, e.g., relations between the modeling and solution methods used and the practical implementation of the approaches developed.","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.0463020608,"dev-research":0.4652470548,"prompt-eng":0.3879453353,"data-quality":0.0562857068,"ml-security":0.0558125827}}
{"text":"Moreover, we provide a high-level taxonomy for classifying different resource-focused integration approaches and point out gaps in the literature as well as promising directions for future research.","meta":{"url":"http://arxiv.org/abs/2307.05258v1"},"cats":{"new-dataset":0.0840167809,"dev-research":0.4589420494,"prompt-eng":0.4211737808,"data-quality":0.1153983475,"ml-security":0.0624127942}}
{"text":"Active learning (AL) is an effective approach to select the most informative samples to label so as to reduce the annotation cost.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.1258818081,"dev-research":0.4250447761,"prompt-eng":0.4649443331,"data-quality":0.3128868857,"ml-security":0.1927902777}}
{"text":"Existing AL methods typically work under the closed-set assumption, i.e., all classes existing in the unlabeled sample pool need to be classified by the target model.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.1110175348,"dev-research":0.3850105395,"prompt-eng":0.4246749314,"data-quality":0.3156711826,"ml-security":0.2096725192}}
{"text":"However, in some practical clinical tasks, the unlabeled pool may contain not only the target classes that need to be fine-grainedly classified, but also non-target classes that are irrelevant to the clinical tasks.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.0592076013,"dev-research":0.3813048423,"prompt-eng":0.3970400285,"data-quality":0.3426579392,"ml-security":0.1772377698}}
{"text":"Existing AL methods cannot work well in this scenario because they tend to select a large number of non-target samples.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.0770890515,"dev-research":0.3694404066,"prompt-eng":0.3894999532,"data-quality":0.1997912488,"ml-security":0.1968025146}}
{"text":"In this paper, we formulate this scenario as an open-set AL problem and propose an efficient framework, OpenAL, to address the challenge of querying samples from an unlabeled pool with both target class and non-target class samples.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.239061867,"dev-research":0.390971815,"prompt-eng":0.4333605301,"data-quality":0.2790997655,"ml-security":0.2602761159}}
{"text":"Experiments on fine-grained classification of pathology images show that OpenAL can significantly improve the query quality of target class samples and achieve higher performance than current state-of-the-art AL methods.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.2009232521,"dev-research":0.3693450338,"prompt-eng":0.4400406642,"data-quality":0.2512714558,"ml-security":0.1614867129}}
{"text":"Code is available at https://github.com/miccaiif/OpenAL.","meta":{"url":"http://arxiv.org/abs/2307.05254v1"},"cats":{"new-dataset":0.2610818764,"dev-research":0.4591990196,"prompt-eng":0.4609097523,"data-quality":0.0865697818,"ml-security":0.0849791169}}
{"text":"Imagine a learner L who tries to infer a hidden concept from a collection of observations.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.2433800683,"dev-research":0.43054772,"prompt-eng":0.4722454653,"data-quality":0.2251266298,"ml-security":0.339455577}}
{"text":"Building on the work [4] of Ferri et al., we assume the learner to be parameterized by priors P(c) and by c-conditional likelihoods P(z|c) where c ranges over all concepts in a given class C and z ranges over all observations in an observation set Z. L is called a MAP-learner (resp.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1505428297,"dev-research":0.4083178449,"prompt-eng":0.4846044614,"data-quality":0.1909524408,"ml-security":0.260304354}}
{"text":"an MLE-learner) if it thinks of a collection S of observations as a random sample and returns the concept with the maximum a-posteriori probability (resp.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1447121631,"dev-research":0.3722617439,"prompt-eng":0.4750026473,"data-quality":0.1663134486,"ml-security":0.1859188428}}
{"text":"the concept which maximizes the c-conditional likelihood of S).","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.056090865,"dev-research":0.411364909,"prompt-eng":0.4527080832,"data-quality":0.1306742867,"ml-security":0.1957706532}}
{"text":"Depending on whether L assumes that S is obtained from ordered or unordered sampling resp.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.108013051,"dev-research":0.3485774148,"prompt-eng":0.4157241408,"data-quality":0.1321902951,"ml-security":0.0798038169}}
{"text":"from sampling with or without replacement, we can distinguish four different sampling modes.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.0665814362,"dev-research":0.3668024636,"prompt-eng":0.4136722679,"data-quality":0.1481865312,"ml-security":0.0639122633}}
{"text":"Given a target concept c in C, a teacher for a MAP-learner L aims at finding a smallest collection of observations that causes L to return c.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.2159292895,"dev-research":0.4320928045,"prompt-eng":0.4220247709,"data-quality":0.1731924096,"ml-security":0.1760000984}}
{"text":"This approach leads in a natural manner to various notions of a MAP- or MLE-teaching dimension of a concept class C. Our main results are: We show that this teaching model has some desirable monotonicity properties.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.0981794835,"dev-research":0.4296718757,"prompt-eng":0.4458949643,"data-quality":0.1388308244,"ml-security":0.2009354544}}
{"text":"We clarify how the four sampling modes are related to each other.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.0989338869,"dev-research":0.3624064725,"prompt-eng":0.4108372561,"data-quality":0.0810796525,"ml-security":0.0493277352}}
{"text":"As for the (important!)","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1227535452,"dev-research":0.4376583104,"prompt-eng":0.4330733978,"data-quality":0.1334092412,"ml-security":0.1172902231}}
{"text":"special case, where concepts are subsets of a domain and observations are 0,1-labeled examples, we obtain some additional results.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1776065167,"dev-research":0.4244495628,"prompt-eng":0.4481335563,"data-quality":0.4683906587,"ml-security":0.1488655469}}
{"text":"First of all, we characterize the MAP- and MLE-teaching dimension associated with an optimally parameterized MAP-learner graph-theoretically.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1135771935,"dev-research":0.4169559283,"prompt-eng":0.4626073649,"data-quality":0.1373114967,"ml-security":0.1992670808}}
{"text":"From this central result, some other ones are easy to derive.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.0952961032,"dev-research":0.4613589439,"prompt-eng":0.3908459924,"data-quality":0.1493823801,"ml-security":0.1226695767}}
{"text":"It is shown, for instance, that the MLE-teaching dimension is either equal to the MAP-teaching dimension or exceeds the latter by 1.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1172653562,"dev-research":0.4246400177,"prompt-eng":0.4413567863,"data-quality":0.1344217706,"ml-security":0.1843469057}}
{"text":"It is shown furthermore that these dimensions can be bounded from above by the so-called antichain number, the VC-dimension and related combinatorial parameters.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.1576980831,"dev-research":0.4423933076,"prompt-eng":0.3766973432,"data-quality":0.0711110613,"ml-security":0.1712107273}}
{"text":"Moreover they can be computed in polynomial time.","meta":{"url":"http://arxiv.org/abs/2307.05252v1"},"cats":{"new-dataset":0.0522131522,"dev-research":0.4169746685,"prompt-eng":0.327262364,"data-quality":0.0904712594,"ml-security":0.1456606261}}
{"text":"Brain age prediction using neuroimaging data has shown great potential as an indicator of overall brain health and successful aging, as well as a disease biomarker.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.2340234887,"dev-research":0.3810883201,"prompt-eng":0.4206561198,"data-quality":0.1980603504,"ml-security":0.1400010042}}
{"text":"Deep learning models have been established as reliable and efficient brain age estimators, being trained to predict the chronological age of healthy subjects.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.2276771029,"dev-research":0.3705620308,"prompt-eng":0.4173909291,"data-quality":0.172299327,"ml-security":0.1873413882}}
{"text":"In this paper, we investigate the impact of a pre-training step on deep learning models for brain age prediction.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.2013652879,"dev-research":0.3858157717,"prompt-eng":0.4798943931,"data-quality":0.1409570927,"ml-security":0.2421927806}}
{"text":"More precisely, instead of the common approach of pre-training on natural imaging classification, we propose pre-training the models on brain-related tasks, which led to state-of-the-art results in our experiments on ADNI data.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.1813381152,"dev-research":0.3712828921,"prompt-eng":0.5123337918,"data-quality":0.1961131828,"ml-security":0.1872173671}}
{"text":"Furthermore, we validate the resulting brain age biomarker on images of patients with mild cognitive impairment and Alzheimer's disease.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.1721255531,"dev-research":0.3851693189,"prompt-eng":0.4463643891,"data-quality":0.2728462491,"ml-security":0.0933035916}}
{"text":"Interestingly, our results indicate that better-performing deep learning models in terms of brain age prediction on healthy patients do not result in more reliable biomarkers.","meta":{"url":"http://arxiv.org/abs/2307.05241v1"},"cats":{"new-dataset":0.1564007908,"dev-research":0.3806894741,"prompt-eng":0.4198817793,"data-quality":0.2509822376,"ml-security":0.2739589034}}
{"text":"We compare the performance of three nearest neighbor search algorithms: the Orchard, ball tree, and VP-tree algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05235v1"},"cats":{"new-dataset":0.2168135744,"dev-research":0.3914594733,"prompt-eng":0.3644393066,"data-quality":0.0947481704,"ml-security":0.0757089861}}
{"text":"These algorithms are commonly used for nearest-neighbor searches and are known for their efficiency in large datasets.","meta":{"url":"http://arxiv.org/abs/2307.05235v1"},"cats":{"new-dataset":0.2051800858,"dev-research":0.4096854629,"prompt-eng":0.3715888994,"data-quality":0.1140231064,"ml-security":0.1524959855}}
{"text":"We analyze the fraction of distances computed in relation to the size of the dataset and its dimension.","meta":{"url":"http://arxiv.org/abs/2307.05235v1"},"cats":{"new-dataset":0.481396995,"dev-research":0.3878165583,"prompt-eng":0.3594747895,"data-quality":0.11450408,"ml-security":0.1177980057}}
{"text":"For each algorithm we derive a fitting function for the efficiency as a function to set size and dimension.","meta":{"url":"http://arxiv.org/abs/2307.05235v1"},"cats":{"new-dataset":0.0822381223,"dev-research":0.3960202982,"prompt-eng":0.3511764083,"data-quality":0.0820796987,"ml-security":0.1004645542}}
{"text":"The article aims to provide a comprehensive analysis of the performance of these algorithms and help researchers and practitioners choose the best algorithm for their specific application.","meta":{"url":"http://arxiv.org/abs/2307.05235v1"},"cats":{"new-dataset":0.1208486492,"dev-research":0.3667307936,"prompt-eng":0.36210174,"data-quality":0.117954731,"ml-security":0.0717560821}}
{"text":"Artificial intelligence has achieved significant success in handling complex tasks in recent years.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.1229360582,"dev-research":0.4378984297,"prompt-eng":0.4330910076,"data-quality":0.0670210141,"ml-security":0.0668156233}}
{"text":"This success is due to advances in machine learning algorithms and hardware acceleration.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.0905040914,"dev-research":0.3631060483,"prompt-eng":0.4121738226,"data-quality":0.1349226808,"ml-security":0.1690613519}}
{"text":"In order to obtain more accurate results and solve more complex problems, algorithms must be trained with more data.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.1091198062,"dev-research":0.4391307697,"prompt-eng":0.3794975971,"data-quality":0.16500356,"ml-security":0.2356096263}}
{"text":"This huge amount of data could be time-consuming to process and require a great deal of computation.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.4176921423,"dev-research":0.3795558992,"prompt-eng":0.381982768,"data-quality":0.0680399789,"ml-security":0.1392593608}}
{"text":"This solution could be achieved by distributing the data and algorithm across several machines, which is known as distributed machine learning.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.208997853,"dev-research":0.3921507574,"prompt-eng":0.4444629259,"data-quality":0.1510922899,"ml-security":0.2937055836}}
{"text":"There has been considerable effort put into distributed machine learning algorithms, and different methods have been proposed so far.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.1334050056,"dev-research":0.3740424718,"prompt-eng":0.4463189004,"data-quality":0.1358670449,"ml-security":0.2893319877}}
{"text":"In this article, we present a comprehensive summary of the current state-of-the-art in the field through the review of these algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.2352094854,"dev-research":0.3543975351,"prompt-eng":0.3799854351,"data-quality":0.1550000892,"ml-security":0.090561407}}
{"text":"We divide this algorithms in classification and clustering (traditional machine learning), deep learning and deep reinforcement learning groups.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.1781120566,"dev-research":0.364097328,"prompt-eng":0.4121754665,"data-quality":0.0823262203,"ml-security":0.1946509}}
{"text":"Distributed deep learning has gained more attention in recent years and most of studies worked on this algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.1468341975,"dev-research":0.3672470387,"prompt-eng":0.4253087354,"data-quality":0.1189226198,"ml-security":0.2164752454}}
{"text":"As a result, most of the articles we discussed here belong to this category.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.211044707,"dev-research":0.4616111724,"prompt-eng":0.4357178335,"data-quality":0.1546669072,"ml-security":0.0932520391}}
{"text":"Based on our investigation of algorithms, we highlight limitations that should be addressed in future research.","meta":{"url":"http://arxiv.org/abs/2307.05232v1"},"cats":{"new-dataset":0.0732345803,"dev-research":0.4118091874,"prompt-eng":0.3335702388,"data-quality":0.0924303011,"ml-security":0.1995510423}}
{"text":"Prompt-tuning has become an increasingly popular parameter-efficient method for adapting large pretrained language models to downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.05228v1"},"cats":{"new-dataset":0.0833998375,"dev-research":0.4474367809,"prompt-eng":0.653979786,"data-quality":0.184674654,"ml-security":0.1245134332}}
{"text":"However, both discrete prompting and continuous prompting assume fixed prompts for all data samples within a task, neglecting the fact that inputs vary greatly in some tasks such as open-domain dialogue generation.","meta":{"url":"http://arxiv.org/abs/2307.05228v1"},"cats":{"new-dataset":0.0872829938,"dev-research":0.4624363763,"prompt-eng":0.5904873339,"data-quality":0.1604599058,"ml-security":0.1432910729}}
{"text":"In this paper, we present a novel, instance-specific prompt-tuning algorithm for dialogue generation.","meta":{"url":"http://arxiv.org/abs/2307.05228v1"},"cats":{"new-dataset":0.1678403661,"dev-research":0.4713598174,"prompt-eng":0.6665358632,"data-quality":0.1714340652,"ml-security":0.1070596651}}
{"text":"Specifically, we generate prompts based on instance-level control code, rather than the conversation history, to explore their impact on controlled dialogue generation.","meta":{"url":"http://arxiv.org/abs/2307.05228v1"},"cats":{"new-dataset":0.1584132222,"dev-research":0.5276279506,"prompt-eng":0.6728502775,"data-quality":0.1487729064,"ml-security":0.1815937816}}
{"text":"Experiments on popular open-domain dialogue datasets, evaluated on both automated metrics and human evaluation, demonstrate that our method is superior to prompting baselines and comparable to fine-tuning with only 5%-6% of total parameters.","meta":{"url":"http://arxiv.org/abs/2307.05228v1"},"cats":{"new-dataset":0.3276585618,"dev-research":0.4599123687,"prompt-eng":0.6393880384,"data-quality":0.2216913901,"ml-security":0.0971806982}}
{"text":"Hand gestures are a form of non-verbal communication that is used in social interaction and it is therefore required for more natural human-robot interaction.","meta":{"url":"http://arxiv.org/abs/2307.05225v1"},"cats":{"new-dataset":0.1252779558,"dev-research":0.4179883093,"prompt-eng":0.4239892202,"data-quality":0.0707140163,"ml-security":0.0745063424}}
{"text":"Neuromorphic (brain-inspired) computing offers a low-power solution for Spiking neural networks (SNNs) that can be used for the classification and recognition of gestures.","meta":{"url":"http://arxiv.org/abs/2307.05225v1"},"cats":{"new-dataset":0.1743040028,"dev-research":0.3693906849,"prompt-eng":0.3968537011,"data-quality":0.0757542644,"ml-security":0.145525813}}
{"text":"This article introduces the preliminary results of a novel methodology for training spiking convolutional neural networks for hand-gesture recognition so that a humanoid robot with integrated neuromorphic hardware will be able to personalise the interaction with a user according to the shown hand gesture.","meta":{"url":"http://arxiv.org/abs/2307.05225v1"},"cats":{"new-dataset":0.2195561003,"dev-research":0.3557216988,"prompt-eng":0.4373812923,"data-quality":0.0948184179,"ml-security":0.1255530945}}
{"text":"It also describes other approaches that could improve the overall performance of the model.","meta":{"url":"http://arxiv.org/abs/2307.05225v1"},"cats":{"new-dataset":0.0394754798,"dev-research":0.4603872166,"prompt-eng":0.4110694253,"data-quality":0.0882541764,"ml-security":0.0773264151}}
{"text":"This paper reexamines and fundamentally improves the Schmidl-and-Cox (S&C) algorithm, which is extensively used for packet detection in wireless networks, and enhances its adaptability for multi-antenna receivers.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0499759615,"dev-research":0.3975510751,"prompt-eng":0.3562065621,"data-quality":0.0961606622,"ml-security":0.1669641396}}
{"text":"First, we introduce a new \"compensated autocorrelation\" metric, providing a more analytically tractable solution with precise expressions for false-alarm and missed-detection probabilities.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.094811984,"dev-research":0.3831092322,"prompt-eng":0.4885479439,"data-quality":0.4027691161,"ml-security":0.2794214137}}
{"text":"Second, this paper proposes the Pareto comparison principle for fair benchmarking packet-detection algorithms, considering both false alarms and missed detections simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0865032592,"dev-research":0.4092664715,"prompt-eng":0.4160124645,"data-quality":0.1793948153,"ml-security":0.2698503792}}
{"text":"Third, with the Pareto benchmarking scheme, we experimentally confirm that the performance of S&C can be greatly improved by taking only the real part and discarding the imaginary part of the autocorrelation, leading to the novel real-part S&C (RP-S&C) scheme.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0595694531,"dev-research":0.3693827746,"prompt-eng":0.392805873,"data-quality":0.0950011319,"ml-security":0.1148796507}}
{"text":"Fourth, and perhaps most importantly, we utilize the compensated autocorrelation metric we newly put forth to extend the single-antenna algorithm to multi-antenna scenarios through a weighted-sum approach.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0497863653,"dev-research":0.3619120388,"prompt-eng":0.3938123707,"data-quality":0.1299816623,"ml-security":0.113865009}}
{"text":"Two optimization problems, minimizing false-alarm and missed-detection probabilities respectively, are formulated and solutions are provided.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0652848329,"dev-research":0.3963244963,"prompt-eng":0.4679766194,"data-quality":0.3695924039,"ml-security":0.3527828146}}
{"text":"Our experimental results reveal that the optimal weights for false alarms (WFA) scheme is more desirable than the optimal weights for missed detections (WMD) due to its simplicity, reliability, and superior performance.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0415595879,"dev-research":0.3781664219,"prompt-eng":0.4774112256,"data-quality":0.2580122977,"ml-security":0.4272217811}}
{"text":"This study holds considerable implications for the design and deployment of packet-detection schemes in random-access networks.","meta":{"url":"http://arxiv.org/abs/2307.05224v1"},"cats":{"new-dataset":0.0626310052,"dev-research":0.3995732907,"prompt-eng":0.3681864435,"data-quality":0.1362881603,"ml-security":0.4568079115}}
{"text":"We present Emu, a Transformer-based multimodal foundation model, which can seamlessly generate images and texts in multimodal context.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.3247452198,"dev-research":0.4210398082,"prompt-eng":0.5264450998,"data-quality":0.1115980902,"ml-security":0.0604475744}}
{"text":"This omnivore model can take in any single-modality or multimodal data input indiscriminately (e.g., interleaved image, text and video) through a one-model-for-all autoregressive training process.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.2155876727,"dev-research":0.3738044943,"prompt-eng":0.4994772572,"data-quality":0.1042410738,"ml-security":0.0902656869}}
{"text":"First, visual signals are encoded into embeddings, and together with text tokens form an interleaved input sequence.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.1243128933,"dev-research":0.4713883809,"prompt-eng":0.4814842058,"data-quality":0.17044971,"ml-security":0.0990791305}}
{"text":"Emu is then end-to-end trained with a unified objective of classifying the next text token or regressing the next visual embedding in the multimodal sequence.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.1618453363,"dev-research":0.4211774756,"prompt-eng":0.5315709755,"data-quality":0.186352834,"ml-security":0.0959882537}}
{"text":"This versatile multimodality empowers the exploration of diverse pretraining data sources at scale, such as videos with interleaved frames and text, webpages with interleaved images and text, as well as web-scale image-text pairs and video-text pairs.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.3028452878,"dev-research":0.4232517549,"prompt-eng":0.5005584902,"data-quality":0.1159896749,"ml-security":0.0757122755}}
{"text":"Emu can serve as a generalist multimodal interface for both image-to-text and text-to-image tasks, and supports in-context image and text generation.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.2513543365,"dev-research":0.4453808402,"prompt-eng":0.5541583639,"data-quality":0.1302025262,"ml-security":0.0429874186}}
{"text":"Across a broad range of zero-shot/few-shot tasks including image captioning, visual question answering, video question answering and text-to-image generation, Emu demonstrates superb performance compared to state-of-the-art large multimodal models.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.1871775683,"dev-research":0.4044525505,"prompt-eng":0.5428106238,"data-quality":0.1218224171,"ml-security":0.052542583}}
{"text":"Extended capabilities such as multimodal assistants via instruction tuning are also demonstrated with impressive performance.","meta":{"url":"http://arxiv.org/abs/2307.05222v1"},"cats":{"new-dataset":0.0906532768,"dev-research":0.476572325,"prompt-eng":0.5136392802,"data-quality":0.0662176992,"ml-security":0.0668560486}}
{"text":"The agro-food industry is turning to robots to address the challenge of labour shortage.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.1294016227,"dev-research":0.4247791329,"prompt-eng":0.4302990121,"data-quality":0.081741474,"ml-security":0.1127162742}}
{"text":"However, agro-food environments pose difficulties for robots due to high variation and occlusions.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.0958608532,"dev-research":0.3943682333,"prompt-eng":0.4069164465,"data-quality":0.0882873896,"ml-security":0.1003211996}}
{"text":"In the presence of these challenges, accurate world models, with information about object location, shape, and properties, are crucial for robots to perform tasks accurately.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.1239648496,"dev-research":0.3663395777,"prompt-eng":0.4437517194,"data-quality":0.1118615923,"ml-security":0.0942212135}}
{"text":"Building such models is challenging due to the complex and unique nature of agro-food environments, and errors in the model can lead to task execution issues.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.1119805309,"dev-research":0.4139368759,"prompt-eng":0.4650483865,"data-quality":0.1045798791,"ml-security":0.117709337}}
{"text":"In this paper, we propose MinkSORT, a novel method for generating tracking features using a 3D sparse convolutional network in a deepSORT-like approach to improve the accuracy of world models in agro-food environments.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.2963111034,"dev-research":0.3768933819,"prompt-eng":0.4112657017,"data-quality":0.1317470153,"ml-security":0.1012086157}}
{"text":"We evaluated our feature extractor network using real-world data collected in a tomato greenhouse, which significantly improved the performance of our baseline model that tracks tomato positions in 3D using a Kalman filter and Mahalanobis distance.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.2431519986,"dev-research":0.3695048083,"prompt-eng":0.4098840523,"data-quality":0.1256037554,"ml-security":0.0810154352}}
{"text":"Our deep learning feature extractor improved the HOTA from 42.8% to 44.77%, the association accuracy from 32.55% to 35.55%, and the MOTA from 57.63% to 58.81%.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.2144055934,"dev-research":0.395397915,"prompt-eng":0.4786152117,"data-quality":0.1789994486,"ml-security":0.1419898267}}
{"text":"We also evaluated different contrastive loss functions for training our deep learning feature extractor and demonstrated that our approach leads to improved performance in terms of three separate precision and recall detection outcomes.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.1586648677,"dev-research":0.3509797499,"prompt-eng":0.4586953094,"data-quality":0.2773781552,"ml-security":0.1882082058}}
{"text":"Our method improves world model accuracy, enabling robots to perform tasks such as harvesting and plant maintenance with greater efficiency and accuracy, which is essential for meeting the growing demand for food in a sustainable manner.","meta":{"url":"http://arxiv.org/abs/2307.05219v1"},"cats":{"new-dataset":0.1319160721,"dev-research":0.3902462159,"prompt-eng":0.4460320042,"data-quality":0.1004542302,"ml-security":0.0546354342}}
{"text":"Encodings are the main way to compare process calculi.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.1089129707,"dev-research":0.4866264247,"prompt-eng":0.454935193,"data-quality":0.14738712,"ml-security":0.0713563682}}
{"text":"By applying quality criteria to encodings we analyse their quality and rule out trivial or meaningless encodings.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0903449251,"dev-research":0.4486013891,"prompt-eng":0.4499257386,"data-quality":0.4243775155,"ml-security":0.1213222237}}
{"text":"Thereby, operational correspondence is one of the most common and most important quality criteria.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0959053739,"dev-research":0.4219335547,"prompt-eng":0.422199579,"data-quality":0.1197722884,"ml-security":0.0476362468}}
{"text":"It ensures that processes and their translations have the same abstract behaviour.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0399483394,"dev-research":0.5032534373,"prompt-eng":0.4403370509,"data-quality":0.133512925,"ml-security":0.0874936695}}
{"text":"We analyse probabilistic versions of operational correspondence to enable such a verification for probabilistic systems.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0984096318,"dev-research":0.4158610751,"prompt-eng":0.4684070871,"data-quality":0.1545619754,"ml-security":0.1410184814}}
{"text":"Concretely, we present three versions of probabilistic operational correspondence: weak, middle, and strong.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.1165870243,"dev-research":0.4023400591,"prompt-eng":0.459817995,"data-quality":0.1246165981,"ml-security":0.1320257397}}
{"text":"We show the relevance of the weaker version using an encoding from a sublanguage of probabilistic CCS into the probabilistic pi-calculus.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0997858896,"dev-research":0.4373662767,"prompt-eng":0.4660272008,"data-quality":0.1761564586,"ml-security":0.1147437563}}
{"text":"Moreover, we map this version of probabilistic operational correspondence onto a probabilistic behavioural relation that directly relates source and target terms.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0809681768,"dev-research":0.4492955203,"prompt-eng":0.4843481132,"data-quality":0.1317674204,"ml-security":0.1712119783}}
{"text":"Then we can analyse the quality of the criterion by analysing the relation it induces between a source term and its translation.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0678260426,"dev-research":0.4643743732,"prompt-eng":0.4876419733,"data-quality":0.3563351532,"ml-security":0.0737958946}}
{"text":"For the second version of probabilistic operational correspondence we proceed in the opposite direction.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.1077033416,"dev-research":0.4065475181,"prompt-eng":0.448367941,"data-quality":0.1225062105,"ml-security":0.123824726}}
{"text":"We start with a standard simulation relation for probabilistic systems and map it onto a probabilistic operational correspondence criterion.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.0948366366,"dev-research":0.3891932522,"prompt-eng":0.4614567715,"data-quality":0.1019395977,"ml-security":0.1294399992}}
{"text":"This technical report contains the proofs to the lemmata and theorems of [8] as well as some additional material.","meta":{"url":"http://arxiv.org/abs/2307.05218v1"},"cats":{"new-dataset":0.1429676315,"dev-research":0.4113171538,"prompt-eng":0.3978980589,"data-quality":0.1198654518,"ml-security":0.0965190938}}
{"text":"Graph neural networks have become the standard approach for dealing with learning problems on graphs.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.1314225478,"dev-research":0.402373969,"prompt-eng":0.4021692147,"data-quality":0.2741612056,"ml-security":0.2724291938}}
{"text":"Among the different variants of graph neural networks, graph attention networks (GATs) have been applied with great success to different tasks.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.1596662117,"dev-research":0.3819618662,"prompt-eng":0.4355297892,"data-quality":0.149119621,"ml-security":0.0896599941}}
{"text":"In the GAT model, each node assigns an importance score to its neighbors using an attention mechanism.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.1006939487,"dev-research":0.4292166248,"prompt-eng":0.4879846335,"data-quality":0.100364101,"ml-security":0.0658378736}}
{"text":"However, similar to other graph neural networks, GATs aggregate messages from nodes that belong to different classes, and therefore produce node representations that are not well separated with respect to the different classes, which might hurt their performance.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.0766534508,"dev-research":0.3926101899,"prompt-eng":0.4206245406,"data-quality":0.2053698464,"ml-security":0.1662304642}}
{"text":"In this work, to alleviate this problem, we propose a new technique that can be incorporated into any graph attention model to encourage higher attention scores between nodes that share the same class label.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.1123583017,"dev-research":0.4057455327,"prompt-eng":0.4980252833,"data-quality":0.3757274683,"ml-security":0.1817524687}}
{"text":"We evaluate the proposed method on several node classification datasets demonstrating increased performance over standard baseline models.","meta":{"url":"http://arxiv.org/abs/2307.05217v1"},"cats":{"new-dataset":0.1430316248,"dev-research":0.3746735705,"prompt-eng":0.4269611711,"data-quality":0.241181835,"ml-security":0.166962531}}
{"text":"The simple greedy algorithm to find a maximal independent set of a graph can be viewed as a sequential update of a Boolean network, where the update function at each vertex is the conjunction of all the negated variables in its neighbourhood.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.1777771078,"dev-research":0.4226704051,"prompt-eng":0.3621976955,"data-quality":0.1380471327,"ml-security":0.2236084501}}
{"text":"In general, the convergence of the so-called kernel network is complex.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.0677829152,"dev-research":0.3903027309,"prompt-eng":0.3566556029,"data-quality":0.103320566,"ml-security":0.1536968191}}
{"text":"A word (sequence of vertices) fixes the kernel network if applying the updates sequentially according to that word.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.0659883415,"dev-research":0.4601657396,"prompt-eng":0.3836306994,"data-quality":0.2952489409,"ml-security":0.1448352261}}
{"text":"We prove that determining whether a word fixes the kernel network is coNP-complete.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.093783433,"dev-research":0.4398430059,"prompt-eng":0.4429343131,"data-quality":0.3363030871,"ml-security":0.1554974608}}
{"text":"We also consider the so-called permis, which are permutation words that fix the kernel network.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.0832506869,"dev-research":0.4428124874,"prompt-eng":0.4120577933,"data-quality":0.2524948961,"ml-security":0.3000568515}}
{"text":"We exhibit large classes of graphs that have a permis, but we also construct many graphs without a permis.","meta":{"url":"http://arxiv.org/abs/2307.05216v1"},"cats":{"new-dataset":0.1436103922,"dev-research":0.4164033489,"prompt-eng":0.3697877849,"data-quality":0.1726702101,"ml-security":0.314312703}}
{"text":"Many real-world optimization problems contain unknown parameters that must be predicted prior to solving.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.0564437449,"dev-research":0.4286151753,"prompt-eng":0.4036965645,"data-quality":0.1010373487,"ml-security":0.2701304774}}
{"text":"To train the predictive machine learning (ML) models involved, the commonly adopted approach focuses on maximizing predictive accuracy.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.1268132449,"dev-research":0.4027910583,"prompt-eng":0.4758218869,"data-quality":0.182085847,"ml-security":0.363444817}}
{"text":"However, this approach does not always lead to the minimization of the downstream task loss.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.025607613,"dev-research":0.4315674905,"prompt-eng":0.3481877996,"data-quality":0.1359245973,"ml-security":0.1670263036}}
{"text":"Decision-focused learning (DFL) is a recently proposed paradigm whose goal is to train the ML model by directly minimizing the task loss.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.0623596977,"dev-research":0.404974568,"prompt-eng":0.4298690187,"data-quality":0.1355657515,"ml-security":0.2343066846}}
{"text":"However, state-of-the-art DFL methods are limited by the assumptions they make about the structure of the optimization problem (e.g., that the problem is linear) and by the fact that can only predict parameters that appear in the objective function.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.0466685472,"dev-research":0.3750261692,"prompt-eng":0.3494414076,"data-quality":0.0761057051,"ml-security":0.2094536552}}
{"text":"In this work, we address these limitations by instead predicting \\textit{distributions} over parameters and adopting score function gradient estimation (SFGE) to compute decision-focused updates to the predictive model, thereby widening the applicability of DFL.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.1386899146,"dev-research":0.4058598221,"prompt-eng":0.520539454,"data-quality":0.1649186511,"ml-security":0.2230822978}}
{"text":"Our experiments show that by using SFGE we can: (1) deal with predictions that occur both in the objective function and in the constraints; and (2) effectively tackle two-stage stochastic optimization problems.","meta":{"url":"http://arxiv.org/abs/2307.05213v1"},"cats":{"new-dataset":0.0523864253,"dev-research":0.396842855,"prompt-eng":0.450309537,"data-quality":0.1156027315,"ml-security":0.1605900219}}
{"text":"Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes.","meta":{"url":"http://arxiv.org/abs/2307.05209v1"},"cats":{"new-dataset":0.0793936577,"dev-research":0.4246292942,"prompt-eng":0.4625249899,"data-quality":0.1300566831,"ml-security":0.2798819216}}
{"text":"To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics.","meta":{"url":"http://arxiv.org/abs/2307.05209v1"},"cats":{"new-dataset":0.122105803,"dev-research":0.4263927102,"prompt-eng":0.4816297405,"data-quality":0.0921584475,"ml-security":0.1594289935}}
{"text":"Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions.","meta":{"url":"http://arxiv.org/abs/2307.05209v1"},"cats":{"new-dataset":0.0423755918,"dev-research":0.4528148279,"prompt-eng":0.4329596075,"data-quality":0.0494645526,"ml-security":0.0842997436}}
{"text":"These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer.","meta":{"url":"http://arxiv.org/abs/2307.05209v1"},"cats":{"new-dataset":0.0900190179,"dev-research":0.5020428178,"prompt-eng":0.4830800335,"data-quality":0.0734615297,"ml-security":0.1549048011}}
{"text":"Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.","meta":{"url":"http://arxiv.org/abs/2307.05209v1"},"cats":{"new-dataset":0.1251972083,"dev-research":0.4087568745,"prompt-eng":0.5008609151,"data-quality":0.2001334957,"ml-security":0.1218666229}}
{"text":"We study how to mitigate the effects of energy attacks in the batteryless Internet of Things (IoT).","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0612649497,"dev-research":0.4427700348,"prompt-eng":0.4114696058,"data-quality":0.1625241421,"ml-security":0.4955769799}}
{"text":"Battery-less IoT devices live and die with ambient energy, as they use energy harvesting to power their operation.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.1224630367,"dev-research":0.4452620262,"prompt-eng":0.4166802684,"data-quality":0.1001887308,"ml-security":0.1302232199}}
{"text":"They are employed in a multitude of applications, including safety-critical ones such as biomedical implants.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0414776835,"dev-research":0.4058860612,"prompt-eng":0.3662749013,"data-quality":0.097181464,"ml-security":0.1528770432}}
{"text":"Due to scarce energy intakes and limited energy buffers, their executions become intermittent, alternating periods of active operation with periods of recharging their energy buffers.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0499989784,"dev-research":0.411322935,"prompt-eng":0.3867737592,"data-quality":0.080428222,"ml-security":0.1794117995}}
{"text":"Experimental evidence exists that shows how controlling ambient energy allows an attacker to steer a device execution in unintended ways: energy provisioning effectively becomes an attack vector.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0616620715,"dev-research":0.4930549399,"prompt-eng":0.4660325907,"data-quality":0.0923414391,"ml-security":0.5161454968}}
{"text":"We design, implement, and evaluate a mitigation system for energy attacks.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0559728226,"dev-research":0.4385591164,"prompt-eng":0.4365718186,"data-quality":0.142649538,"ml-security":0.689748566}}
{"text":"By taking into account the specific application requirements and the output of an attack detection module, we tune task execution rates and optimize energy management.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0619593637,"dev-research":0.4691270325,"prompt-eng":0.4631400458,"data-quality":0.1031811391,"ml-security":0.4220807548}}
{"text":"This ensures continued application execution in the event of an energy attack.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0250583475,"dev-research":0.5000452652,"prompt-eng":0.4274619174,"data-quality":0.0976767492,"ml-security":0.3546402147}}
{"text":"When a device is under attack, our solution ensures the execution of 23.3% additional application cycles compared to the baselines we consider and increases task schedulability by at least 21%, while enabling a 34% higher peripheral availability.","meta":{"url":"http://arxiv.org/abs/2307.05206v1"},"cats":{"new-dataset":0.0896383355,"dev-research":0.4614695598,"prompt-eng":0.4139447701,"data-quality":0.061228165,"ml-security":0.2793023208}}
{"text":"In the context of label-efficient learning on video data, the distillation method and the structural design of the teacher-student architecture have a significant impact on knowledge distillation.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.1745676332,"dev-research":0.4079904376,"prompt-eng":0.4477695868,"data-quality":0.1861401073,"ml-security":0.1351831102}}
{"text":"However, the relationship between these factors has been overlooked in previous research.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.0495434838,"dev-research":0.4345225158,"prompt-eng":0.365164459,"data-quality":0.1316245291,"ml-security":0.0701197736}}
{"text":"To address this gap, we propose a new weakly supervised learning framework for knowledge distillation in video classification that is designed to improve the efficiency and accuracy of the student model.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.1885963533,"dev-research":0.3841809651,"prompt-eng":0.4919148194,"data-quality":0.3255518886,"ml-security":0.1161379445}}
{"text":"Our approach leverages the concept of substage-based learning to distill knowledge based on the combination of student substages and the correlation of corresponding substages.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.1294195553,"dev-research":0.4283999579,"prompt-eng":0.457265103,"data-quality":0.1045317148,"ml-security":0.1350055085}}
{"text":"We also employ the progressive cascade training method to address the accuracy loss caused by the large capacity gap between the teacher and the student.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.0733037922,"dev-research":0.3888976179,"prompt-eng":0.413372941,"data-quality":0.2023463525,"ml-security":0.1669491279}}
{"text":"Additionally, we propose a pseudo-label optimization strategy to improve the initial data label.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.1866558267,"dev-research":0.3909856305,"prompt-eng":0.4928072659,"data-quality":0.5041968629,"ml-security":0.1702216181}}
{"text":"To optimize the loss functions of different distillation substages during the training process, we introduce a new loss method based on feature distribution.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.075738239,"dev-research":0.3695547729,"prompt-eng":0.4520815356,"data-quality":0.2393160757,"ml-security":0.2082296241}}
{"text":"We conduct extensive experiments on both real and simulated data sets, demonstrating that our proposed approach outperforms existing distillation methods in terms of knowledge distillation for video classification tasks.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.2966367339,"dev-research":0.3902659606,"prompt-eng":0.4814558578,"data-quality":0.2876028121,"ml-security":0.1357877079}}
{"text":"Our proposed substage-based distillation approach has the potential to inform future research on label-efficient learning for video data.","meta":{"url":"http://arxiv.org/abs/2307.05201v1"},"cats":{"new-dataset":0.1450844883,"dev-research":0.3742168168,"prompt-eng":0.4661148131,"data-quality":0.3659856693,"ml-security":0.087691306}}
{"text":"The optimal prediction strategy for out-of-distribution (OOD) setups is a fundamental question in machine learning.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0786884192,"dev-research":0.3603836298,"prompt-eng":0.4132694124,"data-quality":0.160912489,"ml-security":0.3347847985}}
{"text":"In this paper, we address this question and present several contributions.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0516532321,"dev-research":0.420719655,"prompt-eng":0.4041984619,"data-quality":0.1199834462,"ml-security":0.1213737788}}
{"text":"We propose three reject option models for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the Bounded Precision-Recall model.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0647298481,"dev-research":0.386122986,"prompt-eng":0.473465408,"data-quality":0.1503458783,"ml-security":0.1626590612}}
{"text":"These models extend the standard reject option models used in non-OOD setups and define the notion of an optimal OOD selective classifier.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0469556038,"dev-research":0.391790617,"prompt-eng":0.4803792653,"data-quality":0.2162945423,"ml-security":0.2225827034}}
{"text":"We establish that all the proposed models, despite their different formulations, share a common class of optimal strategies.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0521706176,"dev-research":0.3704691983,"prompt-eng":0.374436389,"data-quality":0.0525925814,"ml-security":0.1798073033}}
{"text":"Motivated by the optimal strategy, we introduce double-score OOD methods that leverage uncertainty scores from two chosen OOD detectors: one focused on OOD/ID discrimination and the other on misclassification detection.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.1568563,"dev-research":0.3632241867,"prompt-eng":0.4989620766,"data-quality":0.5389765109,"ml-security":0.2502229588}}
{"text":"The experimental results consistently demonstrate the superior performance of this simple strategy compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0282826454,"dev-research":0.3814379165,"prompt-eng":0.3938355035,"data-quality":0.1235954778,"ml-security":0.0834968364}}
{"text":"Additionally, we propose novel evaluation metrics derived from the definition of the optimal strategy under the proposed OOD rejection models.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0288131184,"dev-research":0.3613407228,"prompt-eng":0.4287181762,"data-quality":0.1985896881,"ml-security":0.194463293}}
{"text":"These new metrics provide a comprehensive and reliable assessment of OOD methods without the deficiencies observed in existing evaluation approaches.","meta":{"url":"http://arxiv.org/abs/2307.05199v1"},"cats":{"new-dataset":0.0673581922,"dev-research":0.3973033225,"prompt-eng":0.4002351276,"data-quality":0.1756971499,"ml-security":0.0561679051}}
{"text":"Several membership inference (MI) attacks have been proposed to audit a target DNN.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.0850011989,"dev-research":0.4011661753,"prompt-eng":0.4932844222,"data-quality":0.236841458,"ml-security":0.6426328641}}
{"text":"Given a set of subjects, MI attacks tell which subjects the target DNN has seen during training.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.1340295966,"dev-research":0.3997966724,"prompt-eng":0.5015492136,"data-quality":0.1620087353,"ml-security":0.4639655014}}
{"text":"This work focuses on the post-training MI attacks emphasizing high confidence membership detection -- True Positive Rates (TPR) at low False Positive Rates (FPR).","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.0982391374,"dev-research":0.3810060461,"prompt-eng":0.524154797,"data-quality":0.2801989026,"ml-security":0.6873824931}}
{"text":"Current works in this category -- likelihood ratio attack (LiRA) and enhanced MI attack (EMIA) -- only perform well on complex datasets (e.g., CIFAR-10 and Imagenet) where the target DNN overfits its train set, but perform poorly on simpler datasets (0% TPR by both attacks on Fashion-MNIST, 2% and 0% TPR respectively by LiRA and EMIA on MNIST at 1% FPR).","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.1592032622,"dev-research":0.3593527143,"prompt-eng":0.4579395211,"data-quality":0.193136291,"ml-security":0.6064957514}}
{"text":"To address this, firstly, we unify current MI attacks by presenting a framework divided into three stages -- preparation, indication and decision.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.057906207,"dev-research":0.4599908557,"prompt-eng":0.4811122368,"data-quality":0.1679099329,"ml-security":0.5690781246}}
{"text":"Secondly, we utilize the framework to propose two novel attacks: (1) Adversarial Membership Inference Attack (AMIA) efficiently utilizes the membership and the non-membership information of the subjects while adversarially minimizing a novel loss function, achieving 6% TPR on both Fashion-MNIST and MNIST datasets; and (2) Enhanced AMIA (E-AMIA) combines EMIA and AMIA to achieve 8% and 4% TPRs on Fashion-MNIST and MNIST datasets respectively, at 1% FPR.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.2138317359,"dev-research":0.3829468118,"prompt-eng":0.4944825564,"data-quality":0.2772165994,"ml-security":0.6896762774}}
{"text":"Thirdly, we introduce two novel augmented indicators that positively leverage the loss information in the Gaussian neighborhood of a subject.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.0752950957,"dev-research":0.3893086428,"prompt-eng":0.4731477148,"data-quality":0.2220198316,"ml-security":0.1471063999}}
{"text":"This improves TPR of all four attacks on average by 2.5% and 0.25% respectively on Fashion-MNIST and MNIST datasets at 1% FPR.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.1380662659,"dev-research":0.4164109455,"prompt-eng":0.4979289759,"data-quality":0.1618961411,"ml-security":0.4698403109}}
{"text":"Finally, we propose simple, yet novel, evaluation metric, the running TPR average (RTA) at a given FPR, that better distinguishes different MI attacks in the low FPR region.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.0782945719,"dev-research":0.3989273731,"prompt-eng":0.4809006579,"data-quality":0.1026717777,"ml-security":0.4345675489}}
{"text":"We also show that AMIA and E-AMIA are more transferable to the unknown DNNs (other than the target DNN) and are more robust to DP-SGD training as compared to LiRA and EMIA.","meta":{"url":"http://arxiv.org/abs/2307.05193v1"},"cats":{"new-dataset":0.0994539693,"dev-research":0.3744128025,"prompt-eng":0.4454609481,"data-quality":0.1449052817,"ml-security":0.2176175913}}
{"text":"We present a simple linear regression based approach for learning the weights and biases of a neural network, as an alternative to standard gradient based backpropagation.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.1104691418,"dev-research":0.3614005402,"prompt-eng":0.4537132545,"data-quality":0.1800640342,"ml-security":0.3075985476}}
{"text":"The present work is exploratory in nature, and we restrict the description and experiments to (i) simple feedforward neural networks, (ii) scalar (single output) regression problems, and (iii) invertible activation functions.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.1210081248,"dev-research":0.3723073578,"prompt-eng":0.4302659654,"data-quality":0.1777396378,"ml-security":0.2984419667}}
{"text":"However, the approach is intended to be extensible to larger, more complex architectures.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.0198798683,"dev-research":0.4619467707,"prompt-eng":0.3383229346,"data-quality":0.0394718205,"ml-security":0.1437776617}}
{"text":"The key idea is the observation that the input to every neuron in a neural network is a linear combination of the activations of neurons in the previous layer, as well as the parameters (weights and biases) of the layer.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.040486123,"dev-research":0.4273271032,"prompt-eng":0.3945196978,"data-quality":0.1542118137,"ml-security":0.3052063215}}
{"text":"If we are able to compute the ideal total input values to every neuron by working backwards from the output, we can formulate the learning problem as a linear least squares problem which iterates between updating the parameters and the activation values.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.0627524863,"dev-research":0.3971183744,"prompt-eng":0.4250591099,"data-quality":0.1813693302,"ml-security":0.3847587943}}
{"text":"We present an explicit algorithm that implements this idea, and we show that (at least for simple problems)","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.1260181691,"dev-research":0.4170085666,"prompt-eng":0.3631791932,"data-quality":0.1996215362,"ml-security":0.1446023949}}
{"text":"the approach is more stable and faster than gradient-based backpropagation.","meta":{"url":"http://arxiv.org/abs/2307.05189v1"},"cats":{"new-dataset":0.0454362594,"dev-research":0.3705585804,"prompt-eng":0.3818218469,"data-quality":0.0926728138,"ml-security":0.1591496359}}
{"text":"Medical students and junior surgeons often rely on senior surgeons and specialists to answer their questions when learning surgery.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.0772451057,"dev-research":0.4322831116,"prompt-eng":0.4368902314,"data-quality":0.0799575728,"ml-security":0.1248453092}}
{"text":"However, experts are often busy with clinical and academic work, and have little time to give guidance.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.0929644898,"dev-research":0.4339863519,"prompt-eng":0.4018523158,"data-quality":0.0805026254,"ml-security":0.1005872835}}
{"text":"Meanwhile, existing deep learning (DL)-based surgical Visual Question Answering (VQA) systems can only provide simple answers without the location of the answers.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.1580121104,"dev-research":0.4189652046,"prompt-eng":0.4376511096,"data-quality":0.1259741234,"ml-security":0.1265321732}}
{"text":"In addition, vision-language (ViL) embedding is still a less explored research in these kinds of tasks.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.1266628208,"dev-research":0.4430627827,"prompt-eng":0.4583099383,"data-quality":0.1641873839,"ml-security":0.0579811382}}
{"text":"Therefore, a surgical Visual Question Localized-Answering (VQLA) system would be helpful for medical students and junior surgeons to learn and understand from recorded surgical videos.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.2130424785,"dev-research":0.4300426917,"prompt-eng":0.4728166842,"data-quality":0.1199611814,"ml-security":0.0725576464}}
{"text":"We propose an end-to-end Transformer with Co-Attention gaTed Vision-Language (CAT-ViL) for VQLA in surgical scenarios, which does not require feature extraction through detection models.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.1444709028,"dev-research":0.3893986785,"prompt-eng":0.4796870491,"data-quality":0.1316729539,"ml-security":0.0830261432}}
{"text":"The CAT-ViL embedding module is designed to fuse heterogeneous features from visual and textual sources.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.2110768669,"dev-research":0.4703264892,"prompt-eng":0.4688428896,"data-quality":0.2214642029,"ml-security":0.0746047667}}
{"text":"The fused embedding will feed a standard Data-Efficient Image Transformer (DeiT) module, before the parallel classifier and detector for joint prediction.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.2066895538,"dev-research":0.3783249341,"prompt-eng":0.454515097,"data-quality":0.1305258694,"ml-security":0.1288658304}}
{"text":"We conduct the experimental validation on public surgical videos from MICCAI EndoVis Challenge 2017 and 2018.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.2338117506,"dev-research":0.3651938884,"prompt-eng":0.4552750861,"data-quality":0.1495294052,"ml-security":0.0954622246}}
{"text":"The experimental results highlight the superior performance and robustness of our proposed model compared to the state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.0616869756,"dev-research":0.3313963253,"prompt-eng":0.434336576,"data-quality":0.1535159459,"ml-security":0.1294356341}}
{"text":"Ablation studies further prove the outstanding performance of all the proposed components.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.099854068,"dev-research":0.3706402175,"prompt-eng":0.3853822238,"data-quality":0.096980048,"ml-security":0.0402672127}}
{"text":"The proposed method provides a promising solution for surgical scene understanding, and opens up a primary step in the Artificial Intelligence (AI)-based VQLA system for surgical training.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.1583886792,"dev-research":0.4044015614,"prompt-eng":0.4553616606,"data-quality":0.1194037446,"ml-security":0.0731496312}}
{"text":"Our code is publicly available.","meta":{"url":"http://arxiv.org/abs/2307.05182v1"},"cats":{"new-dataset":0.4249107436,"dev-research":0.5208914518,"prompt-eng":0.4586847548,"data-quality":0.1271775132,"ml-security":0.3049443701}}
{"text":"Attention-based graph neural networks have made great progress in feature matching learning.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.1905977832,"dev-research":0.3891644802,"prompt-eng":0.4323691885,"data-quality":0.1997847401,"ml-security":0.0937197988}}
{"text":"However, insight of how attention mechanism works for feature matching is lacked in the literature.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.0536749172,"dev-research":0.4568282308,"prompt-eng":0.4268352386,"data-quality":0.2727421487,"ml-security":0.096473744}}
{"text":"In this paper, we rethink cross- and self-attention from the viewpoint of traditional feature matching and filtering.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.1314686928,"dev-research":0.4278657699,"prompt-eng":0.4894861705,"data-quality":0.2521673386,"ml-security":0.114213705}}
{"text":"In order to facilitate the learning of matching and filtering, we inject the similarity of descriptors and relative positions into cross- and self-attention score, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.2048038456,"dev-research":0.4034802928,"prompt-eng":0.4937052326,"data-quality":0.1957923384,"ml-security":0.0938472428}}
{"text":"In this way, the attention can focus on learning residual matching and filtering functions with reference to the basic functions of measuring visual and spatial correlation.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.1181964682,"dev-research":0.3945879807,"prompt-eng":0.439895898,"data-quality":0.1515065535,"ml-security":0.0633903702}}
{"text":"Moreover, we mine intra- and inter-neighbors according to the similarity of descriptors and relative positions.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.2889296956,"dev-research":0.4328158636,"prompt-eng":0.4177115029,"data-quality":0.1787256241,"ml-security":0.0699233002}}
{"text":"Then sparse attention for each point can be performed only within its neighborhoods to acquire higher computation efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.0273403638,"dev-research":0.3968832036,"prompt-eng":0.3555470243,"data-quality":0.1083517618,"ml-security":0.1278441281}}
{"text":"Feature matching networks equipped with our full and sparse residual attention learning strategies are termed ResMatch and sResMatch respectively.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.1217219312,"dev-research":0.3697696859,"prompt-eng":0.4558384112,"data-quality":0.1934253083,"ml-security":0.1248881023}}
{"text":"Extensive experiments, including feature matching, pose estimation and visual localization, confirm the superiority of our networks.","meta":{"url":"http://arxiv.org/abs/2307.05180v1"},"cats":{"new-dataset":0.1381854397,"dev-research":0.4119798012,"prompt-eng":0.4460470977,"data-quality":0.1864916162,"ml-security":0.1666563805}}
{"text":"The study of human values is essential in both practical and theoretical domains.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.1613314094,"dev-research":0.4450643344,"prompt-eng":0.402269244,"data-quality":0.1134564067,"ml-security":0.0945999439}}
{"text":"With the development of computational linguistics, the creation of large-scale datasets has made it possible to automatically recognize human values accurately.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.5237345913,"dev-research":0.4319912833,"prompt-eng":0.5343761257,"data-quality":0.3826859788,"ml-security":0.1540509371}}
{"text":"SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of arguments and 20 types of human values that are implicitly expressed in each argument.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.3553931813,"dev-research":0.4704552934,"prompt-eng":0.4811757373,"data-quality":0.1226021389,"ml-security":0.0959883458}}
{"text":"In this paper, we present our team's solution.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.1892923458,"dev-research":0.4764533532,"prompt-eng":0.4243356786,"data-quality":0.1271102554,"ml-security":0.1513023306}}
{"text":"We use the Roberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the document and propose a multi-head attention mechanism to establish connections between specific labels and semantic components.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.1869080363,"dev-research":0.455066543,"prompt-eng":0.5443671012,"data-quality":0.3058708495,"ml-security":0.0622997558}}
{"text":"Furthermore, we use a contrastive learning-enhanced K-nearest neighbor mechanism\\cite{su_contrastive_2022} to leverage existing instance information for prediction.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.2656030863,"dev-research":0.3760164843,"prompt-eng":0.4909497042,"data-quality":0.1673628253,"ml-security":0.1733441954}}
{"text":"Our approach achieved an F1 score of 0.533 on the test set and ranked fourth on the leaderboard.","meta":{"url":"http://arxiv.org/abs/2307.05174v1"},"cats":{"new-dataset":0.1529169517,"dev-research":0.421535366,"prompt-eng":0.4456493475,"data-quality":0.1581287603,"ml-security":0.0942525866}}
{"text":"The think aloud method is an important and commonly used tool for usability optimization.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.0644222783,"dev-research":0.4963997128,"prompt-eng":0.4971286997,"data-quality":0.1475488334,"ml-security":0.0888816547}}
{"text":"However, analyzing think aloud data could be time consuming.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.1776456984,"dev-research":0.4406002168,"prompt-eng":0.4506667383,"data-quality":0.1408121149,"ml-security":0.1634232641}}
{"text":"In this paper, we put forth an automatic analysis of verbal protocols and test the link between spoken feedback and the stimulus using eye tracking and mouse tracking.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.1380292968,"dev-research":0.4631781967,"prompt-eng":0.5580064203,"data-quality":0.1778372817,"ml-security":0.0445245606}}
{"text":"The gained data - user feedback linked to a specific area of the stimulus - could be used to let an expert review the feedback on specific web page elements or to visualize on which parts of the web page the feedback was given.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.1198845585,"dev-research":0.4886181529,"prompt-eng":0.52063405,"data-quality":0.1969279233,"ml-security":0.1253512205}}
{"text":"Specifically, we test if participants fixate on or point with the mouse to the content of the webpage that they are verbalizing.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.0602530735,"dev-research":0.4863064892,"prompt-eng":0.5602264056,"data-quality":0.330437426,"ml-security":0.1295538683}}
{"text":"During the testing, participants were shown three websites and asked to verbally give their opinion.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.168236481,"dev-research":0.4774970084,"prompt-eng":0.4951353693,"data-quality":0.1906025478,"ml-security":0.1096706126}}
{"text":"The verbal responses, along with the eye and cursor movements were recorded.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.2091883959,"dev-research":0.4332693433,"prompt-eng":0.5340030044,"data-quality":0.1385645512,"ml-security":0.0440012029}}
{"text":"We compared the hit rate, defined as the percentage of verbally mentioned areas of interest (AOIs) that were fixated with gaze or pointed to with the mouse.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.0610723589,"dev-research":0.4619148271,"prompt-eng":0.4531125792,"data-quality":0.1438776895,"ml-security":0.0705345074}}
{"text":"The results revealed a significantly higher hit rate for the gaze compared to the mouse data.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.1583871492,"dev-research":0.4497328724,"prompt-eng":0.4335471585,"data-quality":0.1062494569,"ml-security":0.0938877792}}
{"text":"Further investigation revealed that, while the mouse was mostly used passively to scroll, the gaze was often directed towards relevant AOIs, thus establishing a strong association between spoken words and stimuli.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.0781330296,"dev-research":0.4585854565,"prompt-eng":0.4741991999,"data-quality":0.1212742377,"ml-security":0.0729095169}}
{"text":"Therefore, eye tracking data possibly provides more detailed information and more valuable insights about the verbalizations compared to the mouse data.","meta":{"url":"http://arxiv.org/abs/2307.05171v1"},"cats":{"new-dataset":0.2313747293,"dev-research":0.470129544,"prompt-eng":0.4689839433,"data-quality":0.1716022088,"ml-security":0.0741862789}}
{"text":"We seek the best traffic allocation scheme for the edge-cloud computing network that satisfies constraints and minimizes the cost based on burstable billing.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.1303320507,"dev-research":0.3764555862,"prompt-eng":0.3495809782,"data-quality":0.0787832718,"ml-security":0.2447650159}}
{"text":"First, for a fixed network topology, we formulate a family of integer programming problems with random parameters describing the various traffic demands.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.0924195986,"dev-research":0.3883642207,"prompt-eng":0.3703436797,"data-quality":0.1027814015,"ml-security":0.2276206105}}
{"text":"Then, to overcome the difficulty caused by the discrete feature of the problem, we generalize the Gumbel-softmax reparameterization method to induce an unconstrained continuous optimization problem as a regularized continuation of the discrete problem.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.0626748624,"dev-research":0.3494640488,"prompt-eng":0.3946812413,"data-quality":0.1591066911,"ml-security":0.1411633172}}
{"text":"Finally, we introduce the Gumbel-softmax sampling network to solve the optimization problems via unsupervised learning.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.2122629163,"dev-research":0.3681122025,"prompt-eng":0.4424841846,"data-quality":0.1364066985,"ml-security":0.2228803378}}
{"text":"The network structure reflects the edge-cloud computing topology and is trained to minimize the expectation of the cost function for unconstrained continuous optimization problems.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.09617646,"dev-research":0.3839416324,"prompt-eng":0.3519087558,"data-quality":0.0684696887,"ml-security":0.2325515482}}
{"text":"The trained network works as an efficient traffic allocation scheme sampler, remarkably outperforming the random strategy in feasibility and cost function value.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.1059321571,"dev-research":0.3610086728,"prompt-eng":0.4198758384,"data-quality":0.1382543743,"ml-security":0.2887849417}}
{"text":"Besides testing the quality of the output allocation scheme, we examine the generalization property of the network by increasing the time steps and the number of users.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.0377358289,"dev-research":0.4300140228,"prompt-eng":0.3922092676,"data-quality":0.1024384074,"ml-security":0.239660236}}
{"text":"We also feed the solution to existing integer optimization solvers as initial conditions and verify the warm-starts can accelerate the short-time iteration process.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.0542653184,"dev-research":0.4310878149,"prompt-eng":0.3814359261,"data-quality":0.0529428,"ml-security":0.1186689969}}
{"text":"The framework is general with solid performance, and the decoupled feature of the random neural networks is adequate for practical implementations.","meta":{"url":"http://arxiv.org/abs/2307.05170v1"},"cats":{"new-dataset":0.1134009515,"dev-research":0.3583208774,"prompt-eng":0.4220125258,"data-quality":0.0859096696,"ml-security":0.2196727274}}
{"text":"Central Bank Digital Currency (CBDC) is a novel form of money that could be issued and regulated by central banks, offering benefits such as programmability, security, and privacy.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.1448185134,"dev-research":0.4332322246,"prompt-eng":0.4055864583,"data-quality":0.1116862667,"ml-security":0.1987273165}}
{"text":"However, the design of a CBDC system presents numerous technical and social challenges.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.1180714242,"dev-research":0.4599149499,"prompt-eng":0.4232298303,"data-quality":0.0801560364,"ml-security":0.1110193683}}
{"text":"This paper presents the design and prototype of a non-custodial wallet, a device that enables users to store and spend CBDC in various contexts.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.2272854152,"dev-research":0.4305534197,"prompt-eng":0.4316746187,"data-quality":0.0660107952,"ml-security":0.1384316766}}
{"text":"To address the challenges of designing a CBDC system, we conducted a series of workshops with internal and external stakeholders, using methods such as storytelling, metaphors, and provotypes to communicate CBDC concepts, elicit user feedback and critique, and incorporate normative values into the technical design.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.2318966114,"dev-research":0.5457774156,"prompt-eng":0.4823999367,"data-quality":0.116932326,"ml-security":0.0674167803}}
{"text":"We derived basic guidelines for designing CBDC systems that balance technical and social aspects, and reflect user needs and values.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.1456747142,"dev-research":0.5097959732,"prompt-eng":0.4779208696,"data-quality":0.0958916851,"ml-security":0.0730484224}}
{"text":"Our paper contributes to the CBDC discourse by demonstrating a practical example of how CBDC could be used in everyday life and by highlighting the importance of a user-centred approach.","meta":{"url":"http://arxiv.org/abs/2307.05167v1"},"cats":{"new-dataset":0.1741866248,"dev-research":0.5079847994,"prompt-eng":0.4392446302,"data-quality":0.1077305572,"ml-security":0.1044715479}}
{"text":"Energy storage solutions play an increasingly important role in modern infrastructure and lead-acid batteries are among the most commonly used in the rechargeable category.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1159442213,"dev-research":0.4114955031,"prompt-eng":0.40198235,"data-quality":0.1376009806,"ml-security":0.1308337231}}
{"text":"Due to normal degradation over time, correctly determining the battery's State of Health (SoH) and Remaining Useful Life (RUL) contributes to enhancing predictive maintenance, reliability, and longevity of battery systems.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1185023901,"dev-research":0.4137645184,"prompt-eng":0.402607657,"data-quality":0.1292902289,"ml-security":0.0942881139}}
{"text":"Besides improving the cost savings, correct estimation of the SoH can lead to reduced pollution though reuse of retired batteries.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.0496372714,"dev-research":0.4220083919,"prompt-eng":0.4043059273,"data-quality":0.1445476044,"ml-security":0.1225090085}}
{"text":"This paper presents a mapping study of the state-of-the-art in machine learning methods for estimating the SoH and RUL of lead-acid batteries.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1111572575,"dev-research":0.37850905,"prompt-eng":0.4643335818,"data-quality":0.2121771466,"ml-security":0.1676254599}}
{"text":"These two indicators are critical in the battery management systems of electric vehicles, renewable energy systems, and other applications that rely heavily on this battery technology.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.0397399696,"dev-research":0.4405294055,"prompt-eng":0.4212049905,"data-quality":0.1880255889,"ml-security":0.1059063034}}
{"text":"In this study, we analyzed the types of machine learning algorithms employed for estimating SoH and RUL, and evaluated their performance in terms of accuracy and inference time.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1225198306,"dev-research":0.3634718569,"prompt-eng":0.4286962931,"data-quality":0.0928698952,"ml-security":0.1545010368}}
{"text":"Additionally, this mapping identifies and analyzes the most commonly used combinations of sensors in specific applications, such as vehicular batteries.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1059861448,"dev-research":0.4128568467,"prompt-eng":0.4332135567,"data-quality":0.1277840196,"ml-security":0.1246026858}}
{"text":"The mapping concludes by highlighting potential gaps and opportunities for future research, which lays the foundation for further advancements in the field.","meta":{"url":"http://arxiv.org/abs/2307.05163v1"},"cats":{"new-dataset":0.1162550218,"dev-research":0.4318324266,"prompt-eng":0.4026959832,"data-quality":0.080105174,"ml-security":0.0498786527}}
{"text":"Finetuning Large Language Models helps improve the results for domain-specific use cases.","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.1392554883,"dev-research":0.4783334321,"prompt-eng":0.5564657194,"data-quality":0.2652139618,"ml-security":0.1596419053}}
{"text":"End-to-end finetuning of large language models is time and resource intensive and has high storage requirements to store the finetuned version of the large language model.","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.2904170589,"dev-research":0.4322541464,"prompt-eng":0.5312877589,"data-quality":0.1639413195,"ml-security":0.1251317583}}
{"text":"Parameter Efficient Fine Tuning (PEFT) methods address the time and resource challenges by keeping the large language model as a fixed base and add additional layers, which the PEFT methods finetune.","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.0556740783,"dev-research":0.4453111053,"prompt-eng":0.4771869295,"data-quality":0.1481902998,"ml-security":0.1126473291}}
{"text":"This paper demonstrates the evaluation results for one such PEFT method Low Rank Adaptation (LoRA), for Clinical Dialogue Summarization.","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.136610485,"dev-research":0.4198414591,"prompt-eng":0.5345247046,"data-quality":0.1823165822,"ml-security":0.0546218727}}
{"text":"The evaluation results show that LoRA works at par with end-to-end finetuning for a large language model.","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.1639658781,"dev-research":0.4374665892,"prompt-eng":0.5450369951,"data-quality":0.2322077416,"ml-security":0.1089404437}}
{"text":"The paper presents the evaluations done for solving both the Subtask A and B from ImageCLEFmedical {https://www.imageclef.org/2023/medical}","meta":{"url":"http://arxiv.org/abs/2307.05162v1"},"cats":{"new-dataset":0.1601127597,"dev-research":0.4170069903,"prompt-eng":0.3930847887,"data-quality":0.1069434966,"ml-security":0.0354367791}}
{"text":"Self-supervised learning (SSL) has shown promising results in various speech and natural language processing applications.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.1837882869,"dev-research":0.3875725247,"prompt-eng":0.5328032681,"data-quality":0.291389881,"ml-security":0.2206555463}}
{"text":"However, its efficacy in music information retrieval (MIR) still remains largely unexplored.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.1726674123,"dev-research":0.3936631485,"prompt-eng":0.4070354451,"data-quality":0.3040305578,"ml-security":0.1111560815}}
{"text":"While previous SSL models pre-trained on music recordings may have been mostly closed-sourced, recent speech models such as wav2vec2.0 have shown promise in music modelling.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.1735047457,"dev-research":0.3775490867,"prompt-eng":0.4985850535,"data-quality":0.1949694331,"ml-security":0.3060751489}}
{"text":"Nevertheless, research exploring the effectiveness of applying speech SSL models to music recordings has been limited.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.0992184888,"dev-research":0.3602261438,"prompt-eng":0.4597213485,"data-quality":0.2115493697,"ml-security":0.2358401327}}
{"text":"We explore the music adaption of SSL with two distinctive speech-related models, data2vec1.0 and Hubert, and refer to them as music2vec and musicHuBERT, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.220291431,"dev-research":0.3714957281,"prompt-eng":0.4954274065,"data-quality":0.2011337513,"ml-security":0.2741327788}}
{"text":"We train $12$ SSL models with 95M parameters under various pre-training configurations and systematically evaluate the MIR task performances with 13 different MIR tasks.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.1991355762,"dev-research":0.3877151882,"prompt-eng":0.501919235,"data-quality":0.0768830245,"ml-security":0.2143574608}}
{"text":"Our findings suggest that training with music data can generally improve performance on MIR tasks, even when models are trained using paradigms designed for speech.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.1223722743,"dev-research":0.3943873865,"prompt-eng":0.4704237383,"data-quality":0.2114850732,"ml-security":0.125788801}}
{"text":"However, we identify the limitations of such existing speech-oriented designs, especially in modelling polyphonic information.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.0840149447,"dev-research":0.4193686742,"prompt-eng":0.4866651757,"data-quality":0.1767922568,"ml-security":0.1716258036}}
{"text":"Based on the experimental results, empirical suggestions are also given for designing future musical SSL strategies and paradigms.","meta":{"url":"http://arxiv.org/abs/2307.05161v1"},"cats":{"new-dataset":0.0804526508,"dev-research":0.4071827151,"prompt-eng":0.4180149248,"data-quality":0.1140294811,"ml-security":0.2134160447}}
{"text":"Predicting where a person is looking is a complex task, requiring to understand not only the person's gaze and scene content, but also the 3D scene structure and the person's situation (are they manipulating?","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.1029534807,"dev-research":0.4156950073,"prompt-eng":0.4172288847,"data-quality":0.0665699694,"ml-security":0.096273662}}
{"text":"interacting or observing others?","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.0920044075,"dev-research":0.4278956702,"prompt-eng":0.4169433229,"data-quality":0.0589904197,"ml-security":0.0888374603}}
{"text":"attentive?) to detect obstructions in the line of sight or apply attention priors that humans typically have when observing others.","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.0608507808,"dev-research":0.4089649208,"prompt-eng":0.4424304725,"data-quality":0.1558660697,"ml-security":0.1298147595}}
{"text":"In this paper, we hypothesize that identifying and leveraging such priors can be better achieved through the exploitation of explicitly derived multimodal cues such as depth and pose.","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.1545539738,"dev-research":0.4203968277,"prompt-eng":0.481539453,"data-quality":0.127669119,"ml-security":0.1227745344}}
{"text":"We thus propose a modular multimodal architecture allowing to combine these cues using an attention mechanism.","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.1346845092,"dev-research":0.4433915269,"prompt-eng":0.5500642509,"data-quality":0.1663328874,"ml-security":0.0541542952}}
{"text":"The architecture can naturally be exploited in privacy-sensitive situations such as surveillance and health, where personally identifiable information cannot be released.","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.1179339775,"dev-research":0.4169553336,"prompt-eng":0.3851558984,"data-quality":0.1090337109,"ml-security":0.7473853002}}
{"text":"We perform extensive experiments on the GazeFollow and VideoAttentionTarget public datasets, obtaining state-of-the-art performance and demonstrating very competitive results in the privacy setting case.","meta":{"url":"http://arxiv.org/abs/2307.05158v1"},"cats":{"new-dataset":0.5612390999,"dev-research":0.4018177572,"prompt-eng":0.4534060077,"data-quality":0.1489251498,"ml-security":0.3282110793}}
{"text":"This paper examines how a notion of stable explanation developed elsewhere in Defeasible Logic can be expressed in the context of formal argumentation.","meta":{"url":"http://arxiv.org/abs/2307.05156v1"},"cats":{"new-dataset":0.092928767,"dev-research":0.5203404281,"prompt-eng":0.4794734267,"data-quality":0.19409549,"ml-security":0.1505760099}}
{"text":"With this done, we discuss the deontic meaning of this reconstruction and show how to build from argumentation neighborhood structures for deontic logic where this notion of explanation can be characterised.","meta":{"url":"http://arxiv.org/abs/2307.05156v1"},"cats":{"new-dataset":0.1210616234,"dev-research":0.5090384796,"prompt-eng":0.4751692499,"data-quality":0.1465020705,"ml-security":0.1366493244}}
{"text":"Some direct complexity results are offered.","meta":{"url":"http://arxiv.org/abs/2307.05156v1"},"cats":{"new-dataset":0.1056261018,"dev-research":0.483745466,"prompt-eng":0.3682165636,"data-quality":0.0790279982,"ml-security":0.0924463446}}
{"text":"Deep generative models have recently presented impressive results in generating realistic face images of random synthetic identities.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.2036627766,"dev-research":0.3938198779,"prompt-eng":0.4837031614,"data-quality":0.1901257133,"ml-security":0.2623238662}}
{"text":"To generate multiple samples of a certain synthetic identity, several previous works proposed to disentangle the latent space of GANs by incorporating additional supervision or regularization, enabling the manipulation of certain attributes, e.g. identity, hairstyle, pose, or expression.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.077434486,"dev-research":0.405247119,"prompt-eng":0.4730163832,"data-quality":0.2204468919,"ml-security":0.1887840069}}
{"text":"Most of these works require designing special loss functions and training dedicated network architectures.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.0755621703,"dev-research":0.4025720622,"prompt-eng":0.3818352641,"data-quality":0.087783372,"ml-security":0.1877920073}}
{"text":"Others proposed to disentangle specific factors in unconditional pretrained GANs latent spaces to control their output, which also requires supervision by attribute classifiers.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.0523056916,"dev-research":0.4278938404,"prompt-eng":0.4860247898,"data-quality":0.1711432794,"ml-security":0.1925040736}}
{"text":"Moreover, these attributes are entangled in GAN's latent space, making it difficult to manipulate them without affecting the identity information.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.0464424111,"dev-research":0.4294605068,"prompt-eng":0.4296508963,"data-quality":0.1669156841,"ml-security":0.2282708762}}
{"text":"We propose in this work a framework, ExFaceGAN, to disentangle identity information in state-of-the-art pretrained GANs latent spaces, enabling the generation of multiple samples of any synthetic identity.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.1178355987,"dev-research":0.3897953723,"prompt-eng":0.4737039794,"data-quality":0.2102592456,"ml-security":0.254245149}}
{"text":"The variations in our generated images are not limited to specific attributes as ExFaceGAN explicitly aims at disentangling identity information, while other visual attributes are randomly drawn from a learned GAN latent space.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.1420154427,"dev-research":0.4377546806,"prompt-eng":0.4523475392,"data-quality":0.1777320046,"ml-security":0.1892189684}}
{"text":"As an example of the practical benefit of our ExFaceGAN, we empirically prove that data generated by ExFaceGAN can be successfully used to train face recognition models.","meta":{"url":"http://arxiv.org/abs/2307.05151v1"},"cats":{"new-dataset":0.2133638368,"dev-research":0.4073380942,"prompt-eng":0.4532614868,"data-quality":0.1857378046,"ml-security":0.3419878039}}
{"text":"In this paper, we propose a modal logic in which counting modalities appear in linear inequalities.","meta":{"url":"http://arxiv.org/abs/2307.05150v1"},"cats":{"new-dataset":0.1051138416,"dev-research":0.4578341402,"prompt-eng":0.4238141314,"data-quality":0.1342129075,"ml-security":0.0893403561}}
{"text":"We show that each formula can be transformed into an equivalent graph neural network (GNN).","meta":{"url":"http://arxiv.org/abs/2307.05150v1"},"cats":{"new-dataset":0.20646072,"dev-research":0.3712041597,"prompt-eng":0.3916088398,"data-quality":0.1574812778,"ml-security":0.1273825982}}
{"text":"We also show that each GNN can be transformed into a formula.","meta":{"url":"http://arxiv.org/abs/2307.05150v1"},"cats":{"new-dataset":0.148337694,"dev-research":0.4008921796,"prompt-eng":0.413768705,"data-quality":0.141392081,"ml-security":0.1547450793}}
{"text":"We show that the satisfiability problem is decidable.","meta":{"url":"http://arxiv.org/abs/2307.05150v1"},"cats":{"new-dataset":0.1160902077,"dev-research":0.4131968529,"prompt-eng":0.4162221161,"data-quality":0.1581963555,"ml-security":0.1547366295}}
{"text":"We also discuss some variants that are in PSPACE.","meta":{"url":"http://arxiv.org/abs/2307.05150v1"},"cats":{"new-dataset":0.1881959094,"dev-research":0.4929819011,"prompt-eng":0.4920506925,"data-quality":0.140384389,"ml-security":0.1097006075}}
{"text":"Benchmarks are among the main drivers of progress in software engineering research, especially in software testing and debugging.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.1296756376,"dev-research":0.5420421624,"prompt-eng":0.4346167093,"data-quality":0.0933878108,"ml-security":0.1097730125}}
{"text":"However, current benchmarks in this field could be better suited for specific research tasks, as they rely on weak system oracles like crash detection, come with few unit tests only, need more elaborative research, or cannot verify the outcome of system tests.   ","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.1027605256,"dev-research":0.4092419133,"prompt-eng":0.4160843576,"data-quality":0.11809523,"ml-security":0.1375782473}}
{"text":"Our Tests4Py benchmark addresses these issues.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.2266853573,"dev-research":0.4095863312,"prompt-eng":0.4460234386,"data-quality":0.2259425369,"ml-security":0.1012720115}}
{"text":"It is derived from the popular BugsInPy benchmark, including 30 bugs from 5 real-world Python applications.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.2184963913,"dev-research":0.4918720062,"prompt-eng":0.4351898059,"data-quality":0.2143602455,"ml-security":0.1543031546}}
{"text":"Each subject in Tests4Py comes with an oracle to verify the functional correctness of system inputs.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.1006901802,"dev-research":0.461292332,"prompt-eng":0.4918377251,"data-quality":0.1897326704,"ml-security":0.0914892417}}
{"text":"Besides, it enables the generation of system tests and unit tests, allowing for qualitative studies by investigating essential aspects of test sets and extensive evaluations.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.1205382143,"dev-research":0.4973456029,"prompt-eng":0.4680118389,"data-quality":0.0953972824,"ml-security":0.108096626}}
{"text":"These opportunities make Tests4Py a next-generation benchmark for research in test generation, debugging, and automatic program repair.","meta":{"url":"http://arxiv.org/abs/2307.05147v1"},"cats":{"new-dataset":0.247254004,"dev-research":0.5043491677,"prompt-eng":0.4870324291,"data-quality":0.1623148702,"ml-security":0.0836661355}}
{"text":"We present process-algebraic models of multi-writer multi-reader safe, regular and atomic registers.","meta":{"url":"http://arxiv.org/abs/2307.05143v1"},"cats":{"new-dataset":0.0709174601,"dev-research":0.4384460257,"prompt-eng":0.4403212099,"data-quality":0.1160833649,"ml-security":0.1688714197}}
{"text":"We establish the relationship between our models and alternative versions presented in the literature.","meta":{"url":"http://arxiv.org/abs/2307.05143v1"},"cats":{"new-dataset":0.0814998374,"dev-research":0.4677811606,"prompt-eng":0.4602326732,"data-quality":0.1539619614,"ml-security":0.1087106818}}
{"text":"We use our models to formally analyse by model checking to what extent several well-known mutual exclusion algorithms are robust for relaxed atomicity requirements.","meta":{"url":"http://arxiv.org/abs/2307.05143v1"},"cats":{"new-dataset":0.0371102636,"dev-research":0.3987031996,"prompt-eng":0.4008432543,"data-quality":0.1850332806,"ml-security":0.1838577687}}
{"text":"Our analyses refute correctness claims made about some of these algorithms in the literature.","meta":{"url":"http://arxiv.org/abs/2307.05143v1"},"cats":{"new-dataset":0.0987682997,"dev-research":0.4214805654,"prompt-eng":0.3884278973,"data-quality":0.4042050564,"ml-security":0.1827358178}}
{"text":"Movement primitives are trainable parametric models that reproduce robotic movements starting from a limited set of demonstrations.","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.1156758748,"dev-research":0.414152232,"prompt-eng":0.4907256746,"data-quality":0.051362411,"ml-security":0.1100968341}}
{"text":"Previous works proposed simple linear models that exhibited high sample efficiency and generalization power by allowing temporal modulation of movements (reproducing movements faster or slower), blending (merging two movements into one), via-point conditioning (constraining a movement to meet some particular via-points) and context conditioning (generation of movements based on an observed variable, e.g., position of an object).","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.0541530474,"dev-research":0.3731907459,"prompt-eng":0.4484997392,"data-quality":0.0575553067,"ml-security":0.091552495}}
{"text":"Previous works have proposed neural network-based motor primitive models, having demonstrated their capacity to perform tasks with some forms of input conditioning or time-modulation representations.","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.0665852635,"dev-research":0.3827606163,"prompt-eng":0.4482503111,"data-quality":0.055134245,"ml-security":0.1147093288}}
{"text":"However, there has not been a single unified deep motor primitive's model proposed that is capable of all previous operations, limiting neural motor primitive's potential applications.","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.0387379382,"dev-research":0.3676050162,"prompt-eng":0.422874972,"data-quality":0.051870341,"ml-security":0.103215742}}
{"text":"This paper proposes a deep movement primitive architecture that encodes all the operations above and uses a Bayesian context aggregator that allows a more sound context conditioning and blending.","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.12070084,"dev-research":0.4004176436,"prompt-eng":0.5047841673,"data-quality":0.0976818089,"ml-security":0.084110627}}
{"text":"Our results demonstrate our approach can scale to reproduce complex motions on a larger variety of input choices compared to baselines while maintaining operations of linear movement primitives provide.","meta":{"url":"http://arxiv.org/abs/2307.05141v1"},"cats":{"new-dataset":0.0852886793,"dev-research":0.4183029018,"prompt-eng":0.4248169053,"data-quality":0.0523529013,"ml-security":0.0413113673}}
{"text":"In this paper, we propose an architecture for a security-aware workflow management system (WfMS) we call SecFlow in answer to the recent developments of combining workflow management systems with Cloud environments and the still lacking abilities of such systems to ensure the security and privacy of cloud-based workflows.","meta":{"url":"http://arxiv.org/abs/2307.05137v1"},"cats":{"new-dataset":0.2006382512,"dev-research":0.4388414907,"prompt-eng":0.451009608,"data-quality":0.0834684495,"ml-security":0.3184348427}}
{"text":"The SecFlow architecture focuses on full workflow life cycle coverage as, in addition to the existing approaches to design security-aware processes, there is a need to fill in the gap of maintaining security properties of workflows during their execution phase.","meta":{"url":"http://arxiv.org/abs/2307.05137v1"},"cats":{"new-dataset":0.1190684644,"dev-research":0.4639668451,"prompt-eng":0.44547859,"data-quality":0.063383919,"ml-security":0.2808387904}}
{"text":"To address this gap, we derive the requirements for such a security-aware WfMS and design a system architecture that meets these requirements.","meta":{"url":"http://arxiv.org/abs/2307.05137v1"},"cats":{"new-dataset":0.1154195846,"dev-research":0.4503681703,"prompt-eng":0.447464572,"data-quality":0.0761612681,"ml-security":0.372741662}}
{"text":"SecFlow integrates key functional components such as secure model construction, security-aware service selection, security violation detection, and adaptive response mechanisms while considering all potential malicious parties in multi-tenant and cloud-based WfMS.","meta":{"url":"http://arxiv.org/abs/2307.05137v1"},"cats":{"new-dataset":0.0639574601,"dev-research":0.4327517297,"prompt-eng":0.4587336329,"data-quality":0.108457671,"ml-security":0.4671547255}}
{"text":"Solar Photovoltaic (PV) is increasingly being used to address the global concern of energy security.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0758407632,"dev-research":0.4219323907,"prompt-eng":0.4020010145,"data-quality":0.1481707363,"ml-security":0.2756568158}}
{"text":"However, hot spot and snail trails in PV modules caused mostly by crakes reduce their efficiency and power capacity.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0396381027,"dev-research":0.4276194483,"prompt-eng":0.3766525196,"data-quality":0.1458931855,"ml-security":0.0792899501}}
{"text":"This article presents a groundbreaking methodology for automatically identifying and analyzing anomalies like hot spots and snail trails in Solar Photovoltaic (PV) modules, leveraging unsupervised sensing algorithms and 3D Augmented Reality (AR) visualization.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.1270595916,"dev-research":0.4349192394,"prompt-eng":0.4190858482,"data-quality":0.2322426366,"ml-security":0.0820600141}}
{"text":"By transforming the traditional methods of diagnosis and repair, our approach not only enhances efficiency but also substantially cuts down the cost of PV system maintenance.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0359107966,"dev-research":0.4282254707,"prompt-eng":0.410540751,"data-quality":0.2214632001,"ml-security":0.0840999601}}
{"text":"Validated through computer simulations and real-world image datasets, the proposed framework accurately identifies dirty regions, emphasizing the critical role of regular maintenance in optimizing the power capacity of solar PV modules.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.1361724339,"dev-research":0.3949622018,"prompt-eng":0.3888641898,"data-quality":0.32537644,"ml-security":0.1037637052}}
{"text":"Our immediate objective is to leverage drone technology for real-time, automatic solar panel detection, significantly boosting the efficacy of PV maintenance.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0693033942,"dev-research":0.4032523243,"prompt-eng":0.4319684203,"data-quality":0.2485458797,"ml-security":0.0761471876}}
{"text":"The proposed methodology could revolutionize solar PV maintenance, enabling swift, precise anomaly detection without human intervention.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0758108986,"dev-research":0.4206192234,"prompt-eng":0.4239509532,"data-quality":0.3946398567,"ml-security":0.2262790273}}
{"text":"This could result in significant cost savings, heightened energy production, and improved overall performance of solar PV systems.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.0328157011,"dev-research":0.4595925647,"prompt-eng":0.3859314144,"data-quality":0.0967553374,"ml-security":0.0720308659}}
{"text":"Moreover, the novel combination of unsupervised sensing algorithms with 3D AR visualization heralds new opportunities for further research and development in solar PV maintenance.","meta":{"url":"http://arxiv.org/abs/2307.05136v1"},"cats":{"new-dataset":0.1263453018,"dev-research":0.3778020731,"prompt-eng":0.3892978569,"data-quality":0.1145516898,"ml-security":0.0746735653}}
{"text":"The progress in the generation of synthetic images has made it crucial to assess their quality.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.1932333694,"dev-research":0.4089539522,"prompt-eng":0.4349376204,"data-quality":0.1983199236,"ml-security":0.0483312217}}
{"text":"While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.178931295,"dev-research":0.4353004809,"prompt-eng":0.5674421912,"data-quality":0.1957235246,"ml-security":0.0607836666}}
{"text":"Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.0870543894,"dev-research":0.4120360626,"prompt-eng":0.4013892407,"data-quality":0.2355434349,"ml-security":0.1140739307}}
{"text":"In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.2243869689,"dev-research":0.4668024505,"prompt-eng":0.5963748828,"data-quality":0.2027134806,"ml-security":0.0529430097}}
{"text":"It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.0870343202,"dev-research":0.4594790834,"prompt-eng":0.3813534188,"data-quality":0.1171745719,"ml-security":0.0721180941}}
{"text":"We conducted a study on several recent T2I models about various aspects.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.0557547535,"dev-research":0.3954886121,"prompt-eng":0.4627037737,"data-quality":0.0565635775,"ml-security":0.0764003835}}
{"text":"An additional interesting result we obtained with our approach is that image quality can vary drastically depending on the latent noise used as a seed for the images.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.1203132728,"dev-research":0.3754916742,"prompt-eng":0.4391508635,"data-quality":0.3236244116,"ml-security":0.0694528988}}
{"text":"We also quantify the influence of the number of concepts in the prompt, their order as well as their (color) attributes.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.136316892,"dev-research":0.4905468471,"prompt-eng":0.5699310056,"data-quality":0.174400744,"ml-security":0.1156528471}}
{"text":"Finally, our method allows us to identify some latent seeds that produce better images than others, opening novel directions of research on this understudied topic.","meta":{"url":"http://arxiv.org/abs/2307.05134v1"},"cats":{"new-dataset":0.2103957167,"dev-research":0.4408663035,"prompt-eng":0.4695729518,"data-quality":0.2332577516,"ml-security":0.0866253063}}
{"text":"This is an overview of the eleventh edition of the BioASQ challenge in the context of the Conference and Labs of the Evaluation Forum (CLEF) 2023.","meta":{"url":"http://arxiv.org/abs/2307.05131v1"},"cats":{"new-dataset":0.2302408865,"dev-research":0.3970864097,"prompt-eng":0.4707343818,"data-quality":0.1175110603,"ml-security":0.085570872}}
{"text":"BioASQ is a series of international challenges promoting advances in large-scale biomedical semantic indexing and question answering.","meta":{"url":"http://arxiv.org/abs/2307.05131v1"},"cats":{"new-dataset":0.2903166053,"dev-research":0.4230284489,"prompt-eng":0.4814587348,"data-quality":0.1626034413,"ml-security":0.0596696115}}
{"text":"This year, BioASQ consisted of new editions of the two established tasks b and Synergy, and a new task (MedProcNER) on semantic annotation of clinical content in Spanish with medical procedures, which have a critical role in medical practice.","meta":{"url":"http://arxiv.org/abs/2307.05131v1"},"cats":{"new-dataset":0.3249403659,"dev-research":0.4923270187,"prompt-eng":0.5033626603,"data-quality":0.2465292543,"ml-security":0.0441253236}}
{"text":"In this edition of BioASQ, 28 competing teams submitted the results of more than 150 distinct systems in total for the three different shared tasks of the challenge.","meta":{"url":"http://arxiv.org/abs/2307.05131v1"},"cats":{"new-dataset":0.3689505519,"dev-research":0.4125591066,"prompt-eng":0.4568029882,"data-quality":0.0756738053,"ml-security":0.0797496504}}
{"text":"Similarly to previous editions, most of the participating systems achieved competitive performance, suggesting the continuous advancement of the state-of-the-art in the field.","meta":{"url":"http://arxiv.org/abs/2307.05131v1"},"cats":{"new-dataset":0.0805282587,"dev-research":0.4278342938,"prompt-eng":0.4032467611,"data-quality":0.0493347669,"ml-security":0.0672062416}}
{"text":"Despite the increasing prevalence of rotating-style capture (e.g., surveillance cameras), conventional stereo rectification techniques frequently fail due to the rotation-dominant motion and small baseline between views.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.1210031368,"dev-research":0.351994867,"prompt-eng":0.3899872746,"data-quality":0.1455984166,"ml-security":0.0648761449}}
{"text":"In this paper, we tackle the challenge of performing stereo rectification for uncalibrated rotating cameras.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.1325692436,"dev-research":0.3487620595,"prompt-eng":0.3897688978,"data-quality":0.1342830302,"ml-security":0.0623109406}}
{"text":"To that end, we propose Depth-from-Rotation (DfR), a novel image rectification solution that analytically rectifies two images with two-point correspondences and serves for further depth estimation.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.2017625241,"dev-research":0.3579323147,"prompt-eng":0.3859026464,"data-quality":0.1062720534,"ml-security":0.0571930672}}
{"text":"Specifically, we model the motion of a rotating camera as the camera rotates on a sphere with fixed latitude.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.1635899776,"dev-research":0.3673954844,"prompt-eng":0.3978622951,"data-quality":0.073176698,"ml-security":0.0599199521}}
{"text":"The camera's optical axis lies perpendicular to the sphere's surface.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.1771312603,"dev-research":0.4026270579,"prompt-eng":0.3948220987,"data-quality":0.0981160005,"ml-security":0.0684784072}}
{"text":"We call this latitudinal motion assumption.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.1367666373,"dev-research":0.4205036987,"prompt-eng":0.3911302449,"data-quality":0.105131159,"ml-security":0.0842084116}}
{"text":"Then we derive a 2-point analytical solver from directly computing the rectified transformations on the two images.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.0860389181,"dev-research":0.3932614015,"prompt-eng":0.3679987212,"data-quality":0.0845813179,"ml-security":0.0697642475}}
{"text":"We also present a self-adaptive strategy to reduce the geometric distortion after rectification.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.0397097272,"dev-research":0.368412175,"prompt-eng":0.374391072,"data-quality":0.155321307,"ml-security":0.0591052826}}
{"text":"Extensive synthetic and real data experiments demonstrate that the proposed method outperforms existing works in effectiveness and efficiency by a significant margin.","meta":{"url":"http://arxiv.org/abs/2307.05129v1"},"cats":{"new-dataset":0.108369005,"dev-research":0.4010417138,"prompt-eng":0.4109589518,"data-quality":0.1618400675,"ml-security":0.1675521082}}
{"text":"One weakness of machine-learning algorithms is the need to train the models for a new task.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.0678499105,"dev-research":0.4113341816,"prompt-eng":0.4621612493,"data-quality":0.2241193758,"ml-security":0.4436010592}}
{"text":"This presents a specific challenge for biometric recognition due to the dynamic nature of databases and, in some instances, the reliance on subject collaboration for data collection.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.4708892485,"dev-research":0.3675335943,"prompt-eng":0.4812254012,"data-quality":0.1304284328,"ml-security":0.2186831097}}
{"text":"In this paper, we investigate the behavior of deep representations in widely used CNN models under extreme data scarcity for One-Shot periocular recognition, a biometric recognition task.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.2214011734,"dev-research":0.3323437078,"prompt-eng":0.4218860023,"data-quality":0.1601284327,"ml-security":0.3295974692}}
{"text":"We analyze the outputs of CNN layers as identity-representing feature vectors.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.1010866078,"dev-research":0.4184980598,"prompt-eng":0.4558641154,"data-quality":0.2924596527,"ml-security":0.2464848942}}
{"text":"We examine the impact of Domain Adaptation on the network layers' output for unseen data and evaluate the method's robustness concerning data normalization and generalization of the best-performing layer.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.1071230507,"dev-research":0.3866277524,"prompt-eng":0.4206273569,"data-quality":0.3066898649,"ml-security":0.3442681681}}
{"text":"We improved state-of-the-art results that made use of networks trained with biometric datasets with millions of images and fine-tuned for the target periocular dataset by utilizing out-of-the-box CNNs trained for the ImageNet Recognition Challenge and standard computer vision algorithms.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.286888517,"dev-research":0.3480183514,"prompt-eng":0.4335421121,"data-quality":0.165300573,"ml-security":0.2478026775}}
{"text":"For example, for the Cross-Eyed dataset, we could reduce the EER by 67% and 79% (from 1.70% and 3.41% to 0.56% and 0.71%) in the Close-World and Open-World protocols, respectively, for the periocular case.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.137501468,"dev-research":0.3501506285,"prompt-eng":0.4120441592,"data-quality":0.1140011546,"ml-security":0.117200772}}
{"text":"We also demonstrate that traditional algorithms like SIFT can outperform CNNs in situations with limited data or scenarios where the network has not been trained with the test classes like the Open-World mode.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.1230449097,"dev-research":0.3352469541,"prompt-eng":0.4213061041,"data-quality":0.187932593,"ml-security":0.3032206378}}
{"text":"SIFT alone was able to reduce the EER by 64% and 71.6% (from 1.7% and 3.41% to 0.6% and 0.97%) for Cross-Eyed in the Close-World and Open-World protocols, respectively, and a reduction of 4.6% (from 3.94% to 3.76%) in the PolyU database for the Open-World and single biometric case.","meta":{"url":"http://arxiv.org/abs/2307.05128v1"},"cats":{"new-dataset":0.0900459345,"dev-research":0.3546364121,"prompt-eng":0.4260055417,"data-quality":0.0975055027,"ml-security":0.10629043}}
{"text":"This paper studies a multi-antenna networked integrated sensing and communications (ISAC) system, in which a set of multi-antenna base stations (BSs) employ the coordinated transmit beamforming to serve multiple single-antenna communication users (CUs) and perform joint target detection by exploiting the reflected signals simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0561536755,"dev-research":0.3701766665,"prompt-eng":0.4315357581,"data-quality":0.1089085178,"ml-security":0.1856497688}}
{"text":"To facilitate target sensing, the BSs transmit dedicated sensing signals combined with their information signals.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0916560176,"dev-research":0.3976559731,"prompt-eng":0.4342670839,"data-quality":0.0784001149,"ml-security":0.1831693927}}
{"text":"Accordingly, we consider two types of CU receivers with and without the capability of canceling the interference from the dedicated sensing signals, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0641125826,"dev-research":0.3660781477,"prompt-eng":0.4243800153,"data-quality":0.2048145037,"ml-security":0.2312021964}}
{"text":"In addition, we investigate two scenarios with and without time synchronization among the BSs.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0909277425,"dev-research":0.3941594257,"prompt-eng":0.4043834786,"data-quality":0.0955150606,"ml-security":0.154853669}}
{"text":"For the scenario with synchronization, the BSs can exploit the target-reflected signals over both the direct links (BS-to-target-to-originated BS links) and the cross-links (BS-to-target-to-other BSs links) for joint detection, while in the unsynchronized scenario, the BSs can only utilize the target-reflected signals over the direct links.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0440805676,"dev-research":0.3714165894,"prompt-eng":0.3963987616,"data-quality":0.1407634374,"ml-security":0.2260073732}}
{"text":"For each scenario under different types of CU receivers, we optimize the coordinated transmit beamforming at the BSs to maximize the minimum detection probability over a particular targeted area, while guaranteeing the required minimum signal-to-interference-plus-noise ratio (SINR) constraints at the CUs.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0282027153,"dev-research":0.3522666228,"prompt-eng":0.416279762,"data-quality":0.194242441,"ml-security":0.1982105834}}
{"text":"These SINR-constrained detection probability maximization problems are recast as non-convex quadratically constrained quadratic programs (QCQPs), which are then optimally solved via the semi-definite relaxation (SDR) technique.","meta":{"url":"http://arxiv.org/abs/2307.05127v1"},"cats":{"new-dataset":0.0631743125,"dev-research":0.3749401828,"prompt-eng":0.4016404139,"data-quality":0.13343732,"ml-security":0.1810512222}}
{"text":"Due to their dynamic properties such as irregular sampling rate and high-frequency sampling, Continuous Time Series (CTS) are found in many applications.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1166812421,"dev-research":0.332871384,"prompt-eng":0.3840442553,"data-quality":0.0989982941,"ml-security":0.1287239054}}
{"text":"Since CTS with irregular sampling rate are difficult to model with standard Recurrent Neural Networks (RNNs), RNNs have been generalised to have continuous-time hidden dynamics defined by a Neural Ordinary Differential Equation (Neural ODE), leading to the ODE-RNN model.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1934425097,"dev-research":0.3452635651,"prompt-eng":0.4297638688,"data-quality":0.0744139196,"ml-security":0.2209097226}}
{"text":"Another approach that provides a better modelling is that of the Latent ODE model, which constructs a continuous-time model where a latent state is defined at all times.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.066152575,"dev-research":0.3982854342,"prompt-eng":0.4146168482,"data-quality":0.0701360717,"ml-security":0.134024487}}
{"text":"The Latent ODE model uses a standard RNN as the encoder and a Neural ODE as the decoder.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1482728954,"dev-research":0.4081280785,"prompt-eng":0.473107601,"data-quality":0.0814502277,"ml-security":0.1317456956}}
{"text":"However, since the RNN encoder leads to difficulties with missing data and ill-defined latent variables, a Latent ODE-RNN model has recently been proposed that uses a ODE-RNN model as the encoder instead.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1951487894,"dev-research":0.3884343741,"prompt-eng":0.4705574851,"data-quality":0.1086927654,"ml-security":0.1456471668}}
{"text":"Both the Latent ODE and Latent ODE-RNN models are difficult to train due to the vanishing and exploding gradients problem.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.0875900898,"dev-research":0.370191473,"prompt-eng":0.4302255779,"data-quality":0.1211702356,"ml-security":0.2209838711}}
{"text":"To overcome this problem, the main contribution of this paper is to propose and illustrate a new model based on a new Latent ODE using an ODE-LSTM (Long Short-Term Memory) network as an encoder -- the Latent ODE-LSTM model.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1750170138,"dev-research":0.3873961394,"prompt-eng":0.4716903882,"data-quality":0.1080734789,"ml-security":0.1912525455}}
{"text":"To limit the growth of the gradients the Norm Gradient Clipping strategy was embedded on the Latent ODE-LSTM model.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.0504101038,"dev-research":0.3540529639,"prompt-eng":0.4462907649,"data-quality":0.1028833745,"ml-security":0.230554426}}
{"text":"The performance evaluation of the new Latent ODE-LSTM (with and without Norm Gradient Clipping) for modelling CTS with regular and irregular sampling rates is then demonstrated.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1341434932,"dev-research":0.3320380099,"prompt-eng":0.4740343147,"data-quality":0.1216903141,"ml-security":0.144919784}}
{"text":"Numerical experiments show that the new Latent ODE-LSTM performs better than Latent ODE-RNNs and can avoid the vanishing and exploding gradients during training.","meta":{"url":"http://arxiv.org/abs/2307.05126v1"},"cats":{"new-dataset":0.1141582709,"dev-research":0.3647079512,"prompt-eng":0.463130771,"data-quality":0.1280226402,"ml-security":0.2252639807}}
{"text":"How to obtain informative representations of transactions and then perform the identification of fraudulent transactions is a crucial part of ensuring financial security.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1806174929,"dev-research":0.4236111035,"prompt-eng":0.4545515295,"data-quality":0.2907170461,"ml-security":0.3441566963}}
{"text":"Recent studies apply Graph Neural Networks (GNNs) to the transaction fraud detection problem.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1836933314,"dev-research":0.3641891498,"prompt-eng":0.3634546244,"data-quality":0.3046584642,"ml-security":0.4025924106}}
{"text":"Nevertheless, they encounter challenges in effectively learning spatial-temporal information due to structural limitations.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1536329878,"dev-research":0.3981888243,"prompt-eng":0.4260317697,"data-quality":0.1125997894,"ml-security":0.1321492896}}
{"text":"Moreover, few prior GNN-based detectors have recognized the significance of incorporating global information, which encompasses similar behavioral patterns and offers valuable insights for discriminative representation learning.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1934854404,"dev-research":0.3841740176,"prompt-eng":0.5213158565,"data-quality":0.2763067405,"ml-security":0.1844841125}}
{"text":"Therefore, we propose a novel heterogeneous graph neural network called Spatial-Temporal-Aware Graph Transformer (STA-GT) for transaction fraud detection problems.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1689218436,"dev-research":0.3618695874,"prompt-eng":0.3551624194,"data-quality":0.1971149416,"ml-security":0.2493937733}}
{"text":"Specifically, we design a temporal encoding strategy to capture temporal dependencies and incorporate it into the graph neural network framework, enhancing spatial-temporal information modeling and improving expressive ability.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.1968156572,"dev-research":0.4158352609,"prompt-eng":0.4296818183,"data-quality":0.1567010688,"ml-security":0.1369402921}}
{"text":"Furthermore, we introduce a transformer module to learn local and global information.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.3755878565,"dev-research":0.4375354643,"prompt-eng":0.5178555278,"data-quality":0.1357182428,"ml-security":0.1231511021}}
{"text":"Pairwise node-node interactions overcome the limitation of the GNN structure and build up the interactions with the target node and long-distance ones.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.0837697756,"dev-research":0.3607448912,"prompt-eng":0.3945538142,"data-quality":0.0717308152,"ml-security":0.1512225545}}
{"text":"Experimental results on two financial datasets compared to general GNN models and GNN-based fraud detectors demonstrate that our proposed method STA-GT is effective on the transaction fraud detection task.","meta":{"url":"http://arxiv.org/abs/2307.05121v1"},"cats":{"new-dataset":0.2591463094,"dev-research":0.353855338,"prompt-eng":0.4415810389,"data-quality":0.2941338617,"ml-security":0.3077266303}}
{"text":"We consider the randomized communication complexity of the distributed $\\ell_p$-regression problem in the coordinator model, for $p\\in (0,2]$. In this problem, there is a coordinator and $s$ servers.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.0987096316,"dev-research":0.3851083976,"prompt-eng":0.3922018585,"data-quality":0.0997510947,"ml-security":0.2631931456}}
{"text":"The $i$-th server receives $A^i\\in\\{-M, -M+1, \\ldots, M\\}^{n\\times d}$ and $b^i\\in\\{-M, -M+1, \\ldots, M\\}^n$ and the coordinator would like to find a $(1+\\epsilon)$-approximate solution to $\\min_{x\\in\\mathbb{R}^n} \\|(\\sum_i A^i)x - (\\sum_i b^i)\\|_p$.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.081616453,"dev-research":0.3875735212,"prompt-eng":0.3624449564,"data-quality":0.1136460876,"ml-security":0.1158572555}}
{"text":"Here $M \\leq \\mathrm{poly}(nd)$ for convenience.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.0788935217,"dev-research":0.4056516116,"prompt-eng":0.3782308942,"data-quality":0.0806081274,"ml-security":0.0973163718}}
{"text":"This model, where the data is additively shared across servers, is commonly referred to as the arbitrary partition model.   ","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.2033933873,"dev-research":0.4022069047,"prompt-eng":0.4224958297,"data-quality":0.1034361257,"ml-security":0.2372559475}}
{"text":"We obtain significantly improved bounds for this problem.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.2255312544,"dev-research":0.4216127152,"prompt-eng":0.3582066172,"data-quality":0.1531604578,"ml-security":0.1374341353}}
{"text":"For $p = 2$, i.e., least squares regression, we give the first optimal bound of $\\tilde{\\Theta}(sd^2 + sd/\\epsilon)$ bits.   ","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.0917146288,"dev-research":0.3987929001,"prompt-eng":0.3776477441,"data-quality":0.1177994792,"ml-security":0.2026104748}}
{"text":"For $p \\in (1,2)$,we obtain an $\\tilde{O}(sd^2/\\epsilon + sd/\\mathrm{poly}(\\epsilon))$ upper bound.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.0908509122,"dev-research":0.4000102868,"prompt-eng":0.3677732218,"data-quality":0.1380734136,"ml-security":0.1304383506}}
{"text":"Notably, for $d$ sufficiently large, our leading order term only depends linearly on $1/\\epsilon$ rather than quadratically.","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.0506464557,"dev-research":0.4141803214,"prompt-eng":0.3805328165,"data-quality":0.1480764249,"ml-security":0.1571914534}}
{"text":"We also show communication lower bounds of $\\Omega(sd^2 + sd/\\epsilon^2)$ for $p\\in (0,1]$ and $\\Omega(sd^2 + sd/\\epsilon)$ for $p\\in (1,2]$. Our bounds considerably improve previous bounds due to (Woodruff et al. COLT, 2013) and (Vempala et al., SODA, 2020).","meta":{"url":"http://arxiv.org/abs/2307.05117v1"},"cats":{"new-dataset":0.1330656738,"dev-research":0.3913722984,"prompt-eng":0.4019884101,"data-quality":0.1566544984,"ml-security":0.2135787544}}
{"text":"This paper introduces the Life Scapes Reasoning Benchmark (LSR-Benchmark), a novel dataset targeting real-life scenario reasoning, aiming to close the gap in artificial neural networks' ability to reason in everyday contexts.","meta":{"url":"http://arxiv.org/abs/2307.05113v1"},"cats":{"new-dataset":0.3999312712,"dev-research":0.4425979749,"prompt-eng":0.4503723401,"data-quality":0.0930593199,"ml-security":0.138569771}}
{"text":"In contrast to domain knowledge reasoning datasets, LSR-Benchmark comprises free-text formatted questions with rich information on real-life scenarios, human behaviors, and character roles.","meta":{"url":"http://arxiv.org/abs/2307.05113v1"},"cats":{"new-dataset":0.4419450265,"dev-research":0.4311094264,"prompt-eng":0.4995475022,"data-quality":0.1019073956,"ml-security":0.1171213156}}
{"text":"The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its quality.","meta":{"url":"http://arxiv.org/abs/2307.05113v1"},"cats":{"new-dataset":0.8561166873,"dev-research":0.4766629013,"prompt-eng":0.5221345012,"data-quality":0.3104895514,"ml-security":0.1273267144}}
{"text":"Experiments are conducted using state-of-the-art language models, such as gpt3.5-turbo and instruction fine-tuned llama models, to test the performance in LSR-Benchmark.","meta":{"url":"http://arxiv.org/abs/2307.05113v1"},"cats":{"new-dataset":0.0946310801,"dev-research":0.4258291726,"prompt-eng":0.5222511286,"data-quality":0.1050988248,"ml-security":0.0922896336}}
{"text":"The results reveal that humans outperform these models significantly, indicating a persisting challenge for machine learning models in comprehending daily human life.","meta":{"url":"http://arxiv.org/abs/2307.05113v1"},"cats":{"new-dataset":0.207665081,"dev-research":0.4033085299,"prompt-eng":0.5197106281,"data-quality":0.2104627137,"ml-security":0.1973276614}}
{"text":"Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$, the conformal prediction method estimates a confidence set for $y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely assuming that the joint distribution of the data is permutation invariant.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.1335703298,"dev-research":0.359906629,"prompt-eng":0.4310188525,"data-quality":0.1288485543,"ml-security":0.2033912927}}
{"text":"Although attractive, computing such a set is computationally infeasible in most regression problems.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.1794236666,"dev-research":0.3644882625,"prompt-eng":0.3547835679,"data-quality":0.0912924715,"ml-security":0.2456358518}}
{"text":"Indeed, in these cases, the unknown variable $y_{n+1}$ can take an infinite number of possible candidate values, and generating conformal sets requires retraining a predictive model for each candidate.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.1095798726,"dev-research":0.3776369908,"prompt-eng":0.4296412551,"data-quality":0.0935174032,"ml-security":0.1922911575}}
{"text":"In this paper, we focus on a sparse linear model with only a subset of variables for prediction and use numerical continuation techniques to approximate the solution path efficiently.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.0861179317,"dev-research":0.3746850689,"prompt-eng":0.4035109473,"data-quality":0.0983430017,"ml-security":0.1453092817}}
{"text":"The critical property we exploit is that the set of selected variables is invariant under a small perturbation of the input data.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.069173363,"dev-research":0.396991092,"prompt-eng":0.432191134,"data-quality":0.1814782757,"ml-security":0.3116272202}}
{"text":"Therefore, it is sufficient to enumerate and refit the model only at the change points of the set of active features and smoothly interpolate the rest of the solution via a Predictor-Corrector mechanism.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.0774086811,"dev-research":0.3866945167,"prompt-eng":0.4332855074,"data-quality":0.1292658462,"ml-security":0.1122444257}}
{"text":"We show how our path-following algorithm accurately approximates conformal prediction sets and illustrate its performance using synthetic and real data examples.","meta":{"url":"http://arxiv.org/abs/2307.05109v1"},"cats":{"new-dataset":0.1616790488,"dev-research":0.3562811079,"prompt-eng":0.4047576513,"data-quality":0.103377855,"ml-security":0.1428378583}}
{"text":"This paper presents a comprehensive investigation of existing feature extraction tools for symbolic music and contrasts their performance to determine the set of features that best characterizes the musical style of a given music score.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.1312758302,"dev-research":0.4512919544,"prompt-eng":0.4580080874,"data-quality":0.2680562291,"ml-security":0.0560785651}}
{"text":"In this regard, we propose a novel feature extraction tool, named musif, and evaluate its efficacy on various repertoires and file formats, including MIDI, MusicXML, and **kern.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.2716563887,"dev-research":0.4415129589,"prompt-eng":0.4823891436,"data-quality":0.2142169932,"ml-security":0.093333778}}
{"text":"Musif approximates existing tools such as jSymbolic and music21 in terms of computational efficiency while attempting to enhance the usability for custom feature development.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.168021672,"dev-research":0.4843969213,"prompt-eng":0.462019145,"data-quality":0.1164589996,"ml-security":0.0668382231}}
{"text":"The proposed tool also enhances classification accuracy when combined with other sets of features.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.0962230426,"dev-research":0.4330209569,"prompt-eng":0.4451706355,"data-quality":0.2875776093,"ml-security":0.1388303024}}
{"text":"We demonstrate the contribution of each set of features and the computational resources they require.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.2721942235,"dev-research":0.4128622413,"prompt-eng":0.4249723277,"data-quality":0.1327086949,"ml-security":0.1243787602}}
{"text":"Our findings indicate that the optimal tool for feature extraction is a combination of the best features from each tool rather than those of a single one.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.0773091074,"dev-research":0.4388707485,"prompt-eng":0.4288867552,"data-quality":0.2033694053,"ml-security":0.105758446}}
{"text":"To facilitate future research in music information retrieval, we release the source code of the tool and benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.05107v1"},"cats":{"new-dataset":0.290132145,"dev-research":0.4346939054,"prompt-eng":0.438286979,"data-quality":0.2629285921,"ml-security":0.0744217314}}
{"text":"Scenario-based testing is envisioned as a key approach for the safety assurance of autonomous vehicles.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.1605732825,"dev-research":0.4205169439,"prompt-eng":0.4519314672,"data-quality":0.1072168988,"ml-security":0.2642004878}}
{"text":"In scenario-based testing, relevant (driving) scenarios are the basis of tests.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.1096441331,"dev-research":0.4613608977,"prompt-eng":0.4607023612,"data-quality":0.1224722676,"ml-security":0.1722864706}}
{"text":"Many recent works focus on specification, variation, generation and execution of individual scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.1892239227,"dev-research":0.5155523876,"prompt-eng":0.4809157458,"data-quality":0.0447024272,"ml-security":0.08056464}}
{"text":"In this work, we address the open challenges of classifying sets of scenarios and measuring coverage of theses scenarios in recorded test drives.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.3304071864,"dev-research":0.4149926132,"prompt-eng":0.5039883812,"data-quality":0.2416611889,"ml-security":0.2967508965}}
{"text":"Technically, we define logic-based classifiers that compute features of scenarios on complex data streams and combine these classifiers into feature trees that describe sets of scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.2456819585,"dev-research":0.4319589804,"prompt-eng":0.4351972662,"data-quality":0.1571864121,"ml-security":0.1919943297}}
{"text":"We demonstrate the expressiveness and effectiveness of our approach by defining a scenario classifier for urban driving and evaluating it on data recorded from simulations.","meta":{"url":"http://arxiv.org/abs/2307.05106v1"},"cats":{"new-dataset":0.3524620783,"dev-research":0.4086168404,"prompt-eng":0.4777616691,"data-quality":0.1682183874,"ml-security":0.2247631202}}
{"text":"Explainable Artificial Intelligence (XAI) has gained significant attention recently as the demand for transparency and interpretability of machine learning models has increased.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.1515665048,"dev-research":0.4748545378,"prompt-eng":0.4804753678,"data-quality":0.17529302,"ml-security":0.2955216679}}
{"text":"In particular, XAI for time series data has become increasingly important in finance, healthcare, and climate science.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.3740569676,"dev-research":0.3946545541,"prompt-eng":0.3968246923,"data-quality":0.0783770775,"ml-security":0.1496733089}}
{"text":"However, evaluating the quality of explanations, such as attributions provided by XAI techniques, remains challenging.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.1019297931,"dev-research":0.5090675837,"prompt-eng":0.494316959,"data-quality":0.3819024494,"ml-security":0.2000141827}}
{"text":"This paper provides an in-depth analysis of using perturbations to evaluate attributions extracted from time series models.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.0761273298,"dev-research":0.4121304821,"prompt-eng":0.463502031,"data-quality":0.2688049857,"ml-security":0.2766747445}}
{"text":"A perturbation analysis involves systematically modifying the input data and evaluating the impact on the attributions generated by the XAI method.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.0821936358,"dev-research":0.4474288685,"prompt-eng":0.4518130919,"data-quality":0.2963111014,"ml-security":0.2610016773}}
{"text":"We apply this approach to several state-of-the-art XAI techniques and evaluate their performance on three time series classification datasets.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.2677923433,"dev-research":0.3512591773,"prompt-eng":0.4270407638,"data-quality":0.2185077306,"ml-security":0.1503052777}}
{"text":"Our results demonstrate that the perturbation analysis approach can effectively evaluate the quality of attributions and provide insights into the strengths and limitations of XAI techniques.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.0757826084,"dev-research":0.4479670992,"prompt-eng":0.4586199419,"data-quality":0.3659107056,"ml-security":0.2277542469}}
{"text":"Such an approach can guide the selection of XAI methods for time series data, e.g., focusing on return time rather than precision, and facilitate the development of more reliable and interpretable machine learning models for time series analysis.","meta":{"url":"http://arxiv.org/abs/2307.05104v1"},"cats":{"new-dataset":0.1267297724,"dev-research":0.3784255336,"prompt-eng":0.4065121689,"data-quality":0.1244205279,"ml-security":0.1612987864}}
{"text":"In this paper we give a procedure for finding rational solutions of a given first-order ODE with functional and constant coefficients which occur in a rational way.","meta":{"url":"http://arxiv.org/abs/2307.05102v1"},"cats":{"new-dataset":0.1209798487,"dev-research":0.4208290357,"prompt-eng":0.3714846745,"data-quality":0.1751511473,"ml-security":0.1211588948}}
{"text":"We derive an associated system with the same solvability, and sufficient and necessary conditions for the existence of rational solutions are given.","meta":{"url":"http://arxiv.org/abs/2307.05102v1"},"cats":{"new-dataset":0.1195036169,"dev-research":0.4287726731,"prompt-eng":0.3773962224,"data-quality":0.129679286,"ml-security":0.1512860656}}
{"text":"In the case where all parametric coefficients are constant, we give an algorithm to compute the rational solutions.","meta":{"url":"http://arxiv.org/abs/2307.05102v1"},"cats":{"new-dataset":0.1188289496,"dev-research":0.4302579616,"prompt-eng":0.3415443159,"data-quality":0.0771345175,"ml-security":0.1711094348}}
{"text":"In the case where one functional coefficient appears, we algorithmically find rational general solutions which rationally depend on the appearing transcendental constant.","meta":{"url":"http://arxiv.org/abs/2307.05102v1"},"cats":{"new-dataset":0.066771907,"dev-research":0.420432572,"prompt-eng":0.3468828031,"data-quality":0.1261205698,"ml-security":0.1750959483}}
{"text":"In the other cases, the presented procedure is not completely algorithmic.","meta":{"url":"http://arxiv.org/abs/2307.05102v1"},"cats":{"new-dataset":0.04269652,"dev-research":0.4217224418,"prompt-eng":0.3242413455,"data-quality":0.1386315915,"ml-security":0.0971970546}}
{"text":"By treating users' interactions as a user-item graph, graph learning models have been widely deployed in Collaborative Filtering(CF) based recommendation.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.1607739109,"dev-research":0.4225655494,"prompt-eng":0.4780404328,"data-quality":0.1312820919,"ml-security":0.1865351138}}
{"text":"Recently, researchers have introduced Graph Contrastive Learning(GCL) techniques into CF to alleviate the sparse supervision issue, which first constructs contrastive views by data augmentations and then provides self-supervised signals by maximizing the mutual information between contrastive views.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.1977290921,"dev-research":0.3798177984,"prompt-eng":0.4554891553,"data-quality":0.2588553373,"ml-security":0.1059638143}}
{"text":"Despite the effectiveness, we argue that current GCL-based recommendation models are still limited as current data augmentation techniques, either structure augmentation or feature augmentation.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.1433721563,"dev-research":0.4095697486,"prompt-eng":0.4760739606,"data-quality":0.1768159623,"ml-security":0.1537282447}}
{"text":"First, structure augmentation randomly dropout nodes or edges, which is easy to destroy the intrinsic nature of the user-item graph.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.0707629148,"dev-research":0.4225510255,"prompt-eng":0.4310275668,"data-quality":0.1848962934,"ml-security":0.1073419494}}
{"text":"Second, feature augmentation imposes the same scale noise augmentation on each node, which neglects the unique characteristics of nodes on the graph.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.0297614516,"dev-research":0.3986767047,"prompt-eng":0.4133955261,"data-quality":0.2838534477,"ml-security":0.0938190289}}
{"text":"To tackle the above limitations, we propose a novel Variational Graph Generative-Contrastive Learning(VGCL) framework for recommendation.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.1827884041,"dev-research":0.3922394016,"prompt-eng":0.445539177,"data-quality":0.1282348406,"ml-security":0.0750494951}}
{"text":"Specifically, we leverage variational graph reconstruction to estimate a Gaussian distribution of each node, then generate multiple contrastive views through multiple samplings from the estimated distributions, which builds a bridge between generative and contrastive learning.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.214429606,"dev-research":0.3532131707,"prompt-eng":0.4519399889,"data-quality":0.1343871433,"ml-security":0.0840209522}}
{"text":"Besides, the estimated variances are tailored to each node, which regulates the scale of contrastive loss for each node on optimization.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.0333564544,"dev-research":0.3691927351,"prompt-eng":0.4014279186,"data-quality":0.1038191031,"ml-security":0.1009465186}}
{"text":"Considering the similarity of the estimated distributions, we propose a cluster-aware twofold contrastive learning, a node-level to encourage consistency of a node's contrastive views and a cluster-level to encourage consistency of nodes in a cluster.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.1502069331,"dev-research":0.3638318844,"prompt-eng":0.4535719282,"data-quality":0.2211711247,"ml-security":0.0973864691}}
{"text":"Finally, extensive experimental results on three public datasets clearly demonstrate the effectiveness of the proposed model.","meta":{"url":"http://arxiv.org/abs/2307.05100v1"},"cats":{"new-dataset":0.3610725726,"dev-research":0.383145669,"prompt-eng":0.4763843968,"data-quality":0.2021571102,"ml-security":0.2809007927}}
{"text":"Harnessing the power of Artificial Intelligence (AI) and m-health towards detecting new bio-markers indicative of the onset and progress of respiratory abnormalities/conditions has greatly attracted the scientific and research interest especially during COVID-19 pandemic.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.2518134287,"dev-research":0.3976158624,"prompt-eng":0.4628755844,"data-quality":0.0859152883,"ml-security":0.141344115}}
{"text":"The smarty4covid dataset contains audio signals of cough (4,676), regular breathing (4,665), deep breathing (4,695) and voice (4,291) as recorded by means of mobile devices following a crowd-sourcing approach.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.6132558118,"dev-research":0.3789362915,"prompt-eng":0.4467367836,"data-quality":0.1422024959,"ml-security":0.187667382}}
{"text":"Other self reported information is also included (e.g. COVID-19 virus tests), thus providing a comprehensive dataset for the development of COVID-19 risk detection models.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.6606681485,"dev-research":0.4546404512,"prompt-eng":0.5082638719,"data-quality":0.1737941314,"ml-security":0.2861081813}}
{"text":"The smarty4covid dataset is released in the form of a web-ontology language (OWL) knowledge base enabling data consolidation from other relevant datasets, complex queries and reasoning.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.6058102934,"dev-research":0.4556970619,"prompt-eng":0.4708824275,"data-quality":0.1416294404,"ml-security":0.124945233}}
{"text":"It has been utilized towards the development of models able to: (i) extract clinically informative respiratory indicators from regular breathing records, and (ii) identify cough, breath and voice segments in crowd-sourced audio recordings.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.2088875918,"dev-research":0.3634888866,"prompt-eng":0.473882066,"data-quality":0.1274837971,"ml-security":0.1521634605}}
{"text":"A new framework utilizing the smarty4covid OWL knowledge base towards generating counterfactual explanations in opaque AI-based COVID-19 risk detection models is proposed and validated.","meta":{"url":"http://arxiv.org/abs/2307.05096v1"},"cats":{"new-dataset":0.3124585939,"dev-research":0.4668648639,"prompt-eng":0.5072291664,"data-quality":0.2573361293,"ml-security":0.4504579971}}
{"text":"Deep learning technology has made great achievements in the field of image.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.1940499126,"dev-research":0.3750128744,"prompt-eng":0.4296105112,"data-quality":0.1163675525,"ml-security":0.1300487835}}
{"text":"In order to defend against malware attacks, researchers have proposed many Windows malware detection models based on deep learning.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.137386054,"dev-research":0.4438745303,"prompt-eng":0.4620878079,"data-quality":0.1126122526,"ml-security":0.6177754996}}
{"text":"However, deep learning models are vulnerable to adversarial example attacks.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.0688587299,"dev-research":0.388788487,"prompt-eng":0.4624221636,"data-quality":0.3318675861,"ml-security":0.8668986769}}
{"text":"Malware can generate adversarial malware with the same malicious function to attack the malware detection model and evade detection of the model.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.0512250176,"dev-research":0.4858109871,"prompt-eng":0.4680134345,"data-quality":0.1672164717,"ml-security":0.7265642331}}
{"text":"Currently, many adversarial defense studies have been proposed, but existing adversarial defense studies are based on image sample and cannot be directly applied to malware sample.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.1980474787,"dev-research":0.4294517941,"prompt-eng":0.455023038,"data-quality":0.2048619289,"ml-security":0.767808552}}
{"text":"Therefore, this paper proposes an adversarial malware defense method based on adversarial training.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.1312125688,"dev-research":0.4722535591,"prompt-eng":0.4387122843,"data-quality":0.2019232458,"ml-security":0.8154658574}}
{"text":"This method uses preprocessing to defend simple adversarial examples to reduce the difficulty of adversarial training.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.0956368961,"dev-research":0.4540564217,"prompt-eng":0.4537925492,"data-quality":0.2674354863,"ml-security":0.7152809382}}
{"text":"Moreover, this method improves the adversarial defense capability of the model through adversarial training.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.0843574023,"dev-research":0.4234680607,"prompt-eng":0.4382612705,"data-quality":0.1887407727,"ml-security":0.7658194387}}
{"text":"We experimented with three attack methods in two sets of datasets, and the results show that the method in this paper can improve the adversarial defense capability of the model without reducing the accuracy of the model.","meta":{"url":"http://arxiv.org/abs/2307.05095v1"},"cats":{"new-dataset":0.2018308353,"dev-research":0.3891865124,"prompt-eng":0.42729588,"data-quality":0.2397364349,"ml-security":0.8915106556}}
{"text":"In this paper, we propose to estimate the forward dynamics equations of mechanical systems by learning a model of the inverse dynamics and estimating individual dynamics components from it.","meta":{"url":"http://arxiv.org/abs/2307.05093v1"},"cats":{"new-dataset":0.2258721053,"dev-research":0.3967559503,"prompt-eng":0.4654361938,"data-quality":0.0840657008,"ml-security":0.2515692851}}
{"text":"We revisit the classical formulation of rigid body dynamics in order to extrapolate the physical dynamical components, such as inertial and gravitational components, from an inverse dynamics model.","meta":{"url":"http://arxiv.org/abs/2307.05093v1"},"cats":{"new-dataset":0.1399083066,"dev-research":0.373761466,"prompt-eng":0.3958982683,"data-quality":0.0812468865,"ml-security":0.1234970698}}
{"text":"After estimating the dynamical components, the forward dynamics can be computed in closed form as a function of the learned inverse dynamics.","meta":{"url":"http://arxiv.org/abs/2307.05093v1"},"cats":{"new-dataset":0.1599344805,"dev-research":0.3731217486,"prompt-eng":0.4537901221,"data-quality":0.0799644445,"ml-security":0.2202438656}}
{"text":"We tested the proposed method with several machine learning models based on Gaussian Process Regression and compared them with the standard approach of learning the forward dynamics directly.","meta":{"url":"http://arxiv.org/abs/2307.05093v1"},"cats":{"new-dataset":0.131642677,"dev-research":0.3393970022,"prompt-eng":0.4601325166,"data-quality":0.0942530756,"ml-security":0.196194629}}
{"text":"Results on two simulated robotic manipulators, a PANDA Franka Emika and a UR10, show the effectiveness of the proposed method in learning the forward dynamics, both in terms of accuracy as well as in opening the possibility of using more structured~models.","meta":{"url":"http://arxiv.org/abs/2307.05093v1"},"cats":{"new-dataset":0.1986369254,"dev-research":0.3611413007,"prompt-eng":0.4330742296,"data-quality":0.0788748985,"ml-security":0.1255201926}}
{"text":"Video compression relies heavily on exploiting the temporal redundancy between video frames, which is usually achieved by estimating and using the motion information.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.0936354484,"dev-research":0.4085458453,"prompt-eng":0.3875739054,"data-quality":0.1676861036,"ml-security":0.1218990497}}
{"text":"The motion information is represented as optical flows in most of the existing deep video compression networks.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.2335118911,"dev-research":0.4023014527,"prompt-eng":0.4006463546,"data-quality":0.0921736062,"ml-security":0.0760858599}}
{"text":"Indeed, these networks often adopt pre-trained optical flow estimation networks for motion estimation.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.2093887094,"dev-research":0.3892815228,"prompt-eng":0.4458021548,"data-quality":0.0972093119,"ml-security":0.0898200534}}
{"text":"The optical flows, however, may be less suitable for video compression due to the following two factors.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.0545318284,"dev-research":0.3863126811,"prompt-eng":0.3357862417,"data-quality":0.0843528984,"ml-security":0.0442444719}}
{"text":"First, the optical flow estimation networks were trained to perform inter-frame prediction as accurately as possible, but the optical flows themselves may cost too many bits to encode.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.1088664366,"dev-research":0.395123996,"prompt-eng":0.4098527771,"data-quality":0.0980502839,"ml-security":0.0946511137}}
{"text":"Second, the optical flow estimation networks were trained on synthetic data, and may not generalize well enough to real-world videos.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.2459620792,"dev-research":0.379710962,"prompt-eng":0.402660314,"data-quality":0.1458371343,"ml-security":0.1328005889}}
{"text":"We address the twofold limitations by enhancing the optical flows in two stages: offline and online.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.1034664863,"dev-research":0.3664668075,"prompt-eng":0.3819991453,"data-quality":0.0326901198,"ml-security":0.0440776186}}
{"text":"In the offline stage, we fine-tune a trained optical flow estimation network with the motion information provided by a traditional (non-deep) video compression scheme, e.g. H.266/VVC, as we believe the motion information of H.266/VVC achieves a better rate-distortion trade-off.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.2502246322,"dev-research":0.3748539153,"prompt-eng":0.4140341683,"data-quality":0.135213528,"ml-security":0.0840544877}}
{"text":"In the online stage, we further optimize the latent features of the optical flows with a gradient descent-based algorithm for the video to be compressed, so as to enhance the adaptivity of the optical flows.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.0736458558,"dev-research":0.3622952227,"prompt-eng":0.3985684306,"data-quality":0.0909094338,"ml-security":0.0570634003}}
{"text":"We conduct experiments on a state-of-the-art deep video compression scheme, DCVC.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.1732693086,"dev-research":0.3857352609,"prompt-eng":0.4301951106,"data-quality":0.1830825078,"ml-security":0.1358240028}}
{"text":"Experimental results demonstrate that the proposed offline and online enhancement together achieves on average 12.8% bitrate saving on the tested videos, without increasing the model or computational complexity of the decoder side.","meta":{"url":"http://arxiv.org/abs/2307.05092v1"},"cats":{"new-dataset":0.1342506571,"dev-research":0.4180048091,"prompt-eng":0.3938750819,"data-quality":0.0863576666,"ml-security":0.0812404951}}
{"text":"SAR images are highly sensitive to observation configurations, and they exhibit significant variations across different viewing angles, making it challenging to represent and learn their anisotropic features.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.1456781611,"dev-research":0.3507717072,"prompt-eng":0.4076811545,"data-quality":0.1063392279,"ml-security":0.0945060443}}
{"text":"As a result, deep learning methods often generalize poorly across different view angles.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.0556920755,"dev-research":0.3990041351,"prompt-eng":0.3949532006,"data-quality":0.2376235173,"ml-security":0.2119876205}}
{"text":"Inspired by the concept of neural radiance fields (NeRF), this study combines SAR imaging mechanisms with neural networks to propose a novel NeRF model for SAR image generation.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.1432016488,"dev-research":0.338691825,"prompt-eng":0.3984992274,"data-quality":0.1248845948,"ml-security":0.1780593855}}
{"text":"Following the mapping and projection pinciples, a set of SAR images is modeled implicitly as a function of attenuation coefficients and scattering intensities in the 3D imaging space through a differentiable rendering equation.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.1432152305,"dev-research":0.3563935983,"prompt-eng":0.3780877375,"data-quality":0.0639703314,"ml-security":0.0830626905}}
{"text":"SAR-NeRF is then constructed to learn the distribution of attenuation coefficients and scattering intensities of voxels, where the vectorized form of 3D voxel SAR rendering equation and the sampling relationship between the 3D space voxels and the 2D view ray grids are analytically derived.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.1181392633,"dev-research":0.342716783,"prompt-eng":0.3729199316,"data-quality":0.0857798449,"ml-security":0.0978069211}}
{"text":"Through quantitative experiments on various datasets, we thoroughly assess the multi-view representation and generalization capabilities of SAR-NeRF.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.0964615924,"dev-research":0.3644139253,"prompt-eng":0.416867877,"data-quality":0.1960511252,"ml-security":0.2014082278}}
{"text":"Additionally, it is found that SAR-NeRF augumented dataset can significantly improve SAR target classification performance under few-shot learning setup, where a 10-type classification accuracy of 91.6\\% can be achieved by using only 12 images per class.","meta":{"url":"http://arxiv.org/abs/2307.05087v1"},"cats":{"new-dataset":0.128614309,"dev-research":0.358318376,"prompt-eng":0.4191114652,"data-quality":0.1989825611,"ml-security":0.2333387027}}
{"text":"Bangla (or Bengali) is the fifth most spoken language globally; yet, the state-of-the-art NLP in Bangla is lagging for even simple tasks such as lemmatization, POS tagging, etc.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.203014158,"dev-research":0.4620882307,"prompt-eng":0.4748861067,"data-quality":0.2518634528,"ml-security":0.0960883786}}
{"text":"This is partly due to lack of a varied quality corpus.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.2150135967,"dev-research":0.4102412515,"prompt-eng":0.4534536587,"data-quality":0.4993778289,"ml-security":0.0654679364}}
{"text":"To alleviate this need, we build Vacaspati, a diverse corpus of Bangla literature.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.3667468503,"dev-research":0.427193259,"prompt-eng":0.454505835,"data-quality":0.1484956145,"ml-security":0.0726753599}}
{"text":"The literary works are collected from various websites; only those works that are publicly available without copyright violations or restrictions are collected.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.4477014261,"dev-research":0.3960007093,"prompt-eng":0.4074458133,"data-quality":0.1220538422,"ml-security":0.1518850981}}
{"text":"We believe that published literature captures the features of a language much better than newspapers, blogs or social media posts which tend to follow only a certain literary pattern and, therefore, miss out on language variety.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.1321436302,"dev-research":0.4495055682,"prompt-eng":0.4643333488,"data-quality":0.3161071072,"ml-security":0.0838358185}}
{"text":"Our corpus Vacaspati is varied from multiple aspects, including type of composition, topic, author, time, space, etc.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.1370732164,"dev-research":0.4160966057,"prompt-eng":0.4640023801,"data-quality":0.1968943599,"ml-security":0.0550801483}}
{"text":"It contains more than 11 million sentences and 115 million words.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.4197540103,"dev-research":0.4330821284,"prompt-eng":0.4710915247,"data-quality":0.1734489904,"ml-security":0.078582027}}
{"text":"We also built a word embedding model, Vac-FT, using FastText from Vacaspati as well as trained an Electra model, Vac-BERT, using the corpus.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.2180657946,"dev-research":0.4033936262,"prompt-eng":0.5307193837,"data-quality":0.2512243246,"ml-security":0.1120292815}}
{"text":"Vac-BERT has far fewer parameters and requires only a fraction of resources compared to other state-of-the-art transformer models and yet performs either better or similar on various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.0500887076,"dev-research":0.4119167176,"prompt-eng":0.4345829698,"data-quality":0.088851594,"ml-security":0.0996519422}}
{"text":"On multiple downstream tasks, Vac-FT outperforms other FastText-based models.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.075612581,"dev-research":0.4021235281,"prompt-eng":0.4869603629,"data-quality":0.1857878126,"ml-security":0.0813472999}}
{"text":"We also demonstrate the efficacy of Vacaspati as a corpus by showing that similar models built from other corpora are not as effective.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.1692491343,"dev-research":0.4017122703,"prompt-eng":0.5075648379,"data-quality":0.3134224529,"ml-security":0.1092499447}}
{"text":"The models are available at https://bangla.iitk.ac.in/.","meta":{"url":"http://arxiv.org/abs/2307.05083v1"},"cats":{"new-dataset":0.4244835499,"dev-research":0.3950850738,"prompt-eng":0.4645979051,"data-quality":0.0716984402,"ml-security":0.0688742432}}
{"text":"This research presents a comprehensive methodology for utilizing an ontology-driven structured prompts system in interplay with ChatGPT, a widely used large language model (LLM).","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.3189761549,"dev-research":0.5100345721,"prompt-eng":0.657727801,"data-quality":0.1238325978,"ml-security":0.0772859875}}
{"text":"The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT's meta-learning capabilities.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1711200875,"dev-research":0.4942110855,"prompt-eng":0.5848095407,"data-quality":0.1226199336,"ml-security":0.0943078224}}
{"text":"The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1363097572,"dev-research":0.5187070681,"prompt-eng":0.4933646865,"data-quality":0.0676127391,"ml-security":0.0790770076}}
{"text":"The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1679255412,"dev-research":0.4476320267,"prompt-eng":0.4704486354,"data-quality":0.1468921933,"ml-security":0.0800432888}}
{"text":"By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1978731551,"dev-research":0.4875499205,"prompt-eng":0.5480768967,"data-quality":0.2148000176,"ml-security":0.1183189236}}
{"text":"The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2 LLM.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.2181721082,"dev-research":0.4725841775,"prompt-eng":0.5441716348,"data-quality":0.1085309904,"ml-security":0.118097256}}
{"text":"The underlying principles of meta-learning, structured prompts, and ontology-driven information retrieval form the core of the proposed methodology, enabling their adaptation and utilization in various LLM-based systems.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1569901255,"dev-research":0.4511082256,"prompt-eng":0.5745491701,"data-quality":0.1508382483,"ml-security":0.0982783115}}
{"text":"This versatile approach opens up new possibilities for NLP and dialogue systems, empowering developers to enhance the performance and functionality of chatbot systems across different domains and languages.","meta":{"url":"http://arxiv.org/abs/2307.05082v1"},"cats":{"new-dataset":0.1990180083,"dev-research":0.522912672,"prompt-eng":0.5800443413,"data-quality":0.1557617953,"ml-security":0.1423300889}}
{"text":"We use the combination of argumentative zoning [1] and a legal argumentative scheme to create legal argumentative segments.","meta":{"url":"http://arxiv.org/abs/2307.05081v1"},"cats":{"new-dataset":0.1290715731,"dev-research":0.4715768897,"prompt-eng":0.4359491795,"data-quality":0.1703128575,"ml-security":0.093949076}}
{"text":"Based on the argumentative segmentation, we propose a novel task of classifying argumentative segments of legal case decisions.","meta":{"url":"http://arxiv.org/abs/2307.05081v1"},"cats":{"new-dataset":0.2159599618,"dev-research":0.449464009,"prompt-eng":0.467897698,"data-quality":0.2211074322,"ml-security":0.1148314068}}
{"text":"GPT-3.5 is used to generate summaries based on argumentative segments.","meta":{"url":"http://arxiv.org/abs/2307.05081v1"},"cats":{"new-dataset":0.2767668253,"dev-research":0.4838427229,"prompt-eng":0.4715616284,"data-quality":0.138512407,"ml-security":0.0404390914}}
{"text":"In terms of automatic evaluation metrics, our method generates higher quality argumentative summaries while leaving out less relevant context as compared to GPT-4 and non-GPT models.","meta":{"url":"http://arxiv.org/abs/2307.05081v1"},"cats":{"new-dataset":0.1233101921,"dev-research":0.4756903056,"prompt-eng":0.5165991055,"data-quality":0.2069327287,"ml-security":0.041661408}}
{"text":"The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.189398078,"dev-research":0.4273144654,"prompt-eng":0.5043019288,"data-quality":0.7333739445,"ml-security":0.1204106656}}
{"text":"We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.1576560338,"dev-research":0.4441456752,"prompt-eng":0.5456125014,"data-quality":0.9115304829,"ml-security":0.1297550854}}
{"text":"This helps prioritize what data to review in order to ensure a high-quality training/evaluation dataset, which is critical in sensitive applications such as medical imaging and autonomous vehicles.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.2407834178,"dev-research":0.3999962427,"prompt-eng":0.4712846963,"data-quality":0.1697627646,"ml-security":0.2344814594}}
{"text":"Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.208465056,"dev-research":0.3763840223,"prompt-eng":0.5278630198,"data-quality":0.7441978242,"ml-security":0.1357846336}}
{"text":"Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.4579379873,"dev-research":0.4177380553,"prompt-eng":0.5212993536,"data-quality":0.8334919384,"ml-security":0.1301380256}}
{"text":"Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error.","meta":{"url":"http://arxiv.org/abs/2307.05080v1"},"cats":{"new-dataset":0.14100246,"dev-research":0.4231551151,"prompt-eng":0.5353133187,"data-quality":0.772507692,"ml-security":0.1400275295}}
{"text":"We study the costs and benefits of selling data to a competitor.","meta":{"url":"http://arxiv.org/abs/2307.05078v1"},"cats":{"new-dataset":0.477298453,"dev-research":0.4483881027,"prompt-eng":0.3993393151,"data-quality":0.075138651,"ml-security":0.2501291834}}
{"text":"Although selling all consumers' data may decrease total firm profits, there exist other selling mechanisms -- in which only some consumers' data is sold -- that render both firms better off.","meta":{"url":"http://arxiv.org/abs/2307.05078v1"},"cats":{"new-dataset":0.2135141222,"dev-research":0.4277220908,"prompt-eng":0.3771221238,"data-quality":0.1174704294,"ml-security":0.1790385269}}
{"text":"We identify the profit-maximizing mechanism, and show that the benefit to firms comes at a cost to consumers.","meta":{"url":"http://arxiv.org/abs/2307.05078v1"},"cats":{"new-dataset":0.0771443574,"dev-research":0.4942097337,"prompt-eng":0.4079377943,"data-quality":0.0885839637,"ml-security":0.1592860733}}
{"text":"We then construct Pareto-improving mechanisms, in which each consumers' welfare, as well as both firms' profits, increase.","meta":{"url":"http://arxiv.org/abs/2307.05078v1"},"cats":{"new-dataset":0.0859867336,"dev-research":0.4729521915,"prompt-eng":0.4272819785,"data-quality":0.0915285945,"ml-security":0.1380398766}}
{"text":"Finally, we show that consumer opt-in can serve as an instrument to induce firms to choose a Pareto-improving mechanism over a profit-maximizing one.","meta":{"url":"http://arxiv.org/abs/2307.05078v1"},"cats":{"new-dataset":0.0507747922,"dev-research":0.4633744041,"prompt-eng":0.4304128985,"data-quality":0.0864750613,"ml-security":0.1191581224}}
{"text":"We consider the problem of incentivising desirable behaviours in multi-agent systems by way of taxation schemes.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0765885099,"dev-research":0.4479962736,"prompt-eng":0.4071033916,"data-quality":0.0836940618,"ml-security":0.2064646303}}
{"text":"Our study employs the concurrent games model: in this model, each agent is primarily motivated to seek the satisfaction of a goal, expressed as a Linear Temporal Logic (LTL) formula; secondarily, agents seek to minimise costs, where costs are imposed based on the actions taken by agents in different states of the game.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0751016169,"dev-research":0.4389793031,"prompt-eng":0.3864448283,"data-quality":0.0306662584,"ml-security":0.087880486}}
{"text":"In this setting, we consider an external principal who can influence agents' preferences by imposing taxes (additional costs) on the actions chosen by agents in different states.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0973514043,"dev-research":0.4344129052,"prompt-eng":0.4240580482,"data-quality":0.0626840294,"ml-security":0.1633236608}}
{"text":"The principal imposes taxation schemes to motivate agents to choose a course of action that will lead to the satisfaction of their goal, also expressed as an LTL formula.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0482476281,"dev-research":0.4606873976,"prompt-eng":0.4249803812,"data-quality":0.0505903673,"ml-security":0.1106381615}}
{"text":"However, taxation schemes are limited in their ability to influence agents' preferences: an agent will always prefer to satisfy its goal rather than otherwise, no matter what the costs.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.044307507,"dev-research":0.4339620111,"prompt-eng":0.383026334,"data-quality":0.0483364085,"ml-security":0.1592572675}}
{"text":"The fundamental question that we study is whether the principal can impose a taxation scheme such that, in the resulting game, the principal's goal is satisfied in at least one or all runs of the game that could arise by agents choosing to follow game-theoretic equilibrium strategies.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0997661823,"dev-research":0.4228169758,"prompt-eng":0.3860941699,"data-quality":0.0550398709,"ml-security":0.2025924032}}
{"text":"We consider two different types of taxation schemes: in a static scheme, the same tax is imposed on a state-action profile pair in all circumstances, while in a dynamic scheme, the principal can choose to vary taxes depending on the circumstances.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0562894294,"dev-research":0.4136655005,"prompt-eng":0.4013289998,"data-quality":0.0699100141,"ml-security":0.1376835512}}
{"text":"We investigate the main game-theoretic properties of this model as well as the computational complexity of the relevant decision problems.","meta":{"url":"http://arxiv.org/abs/2307.05076v1"},"cats":{"new-dataset":0.0742253519,"dev-research":0.396471024,"prompt-eng":0.3423844815,"data-quality":0.0584207612,"ml-security":0.2088102302}}
{"text":"Removing multiple degradations, such as haze, rain, and blur, from real-world images poses a challenging and illposed problem.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.1431734448,"dev-research":0.391134436,"prompt-eng":0.3777759458,"data-quality":0.2247837041,"ml-security":0.1467922628}}
{"text":"Recently, unified models that can handle different degradations have been proposed and yield promising results.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.0676748024,"dev-research":0.3671709293,"prompt-eng":0.4243744722,"data-quality":0.1762974826,"ml-security":0.1688173163}}
{"text":"However, these approaches focus on synthetic images and experience a significant performance drop when applied to realworld images.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.0948458536,"dev-research":0.3887575625,"prompt-eng":0.3961090031,"data-quality":0.0928223882,"ml-security":0.0620646587}}
{"text":"In this paper, we introduce Uni-Removal, a twostage semi-supervised framework for addressing the removal of multiple degradations in real-world images using a unified model and parameters.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.1424442312,"dev-research":0.3574680312,"prompt-eng":0.4254547463,"data-quality":0.318496011,"ml-security":0.1091391696}}
{"text":"In the knowledge transfer stage, Uni-Removal leverages a supervised multi-teacher and student architecture in the knowledge transfer stage to facilitate learning from pretrained teacher networks specialized in different degradation types.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.0887377207,"dev-research":0.4145573055,"prompt-eng":0.4756748206,"data-quality":0.1821474105,"ml-security":0.188502312}}
{"text":"A multi-grained contrastive loss is introduced to enhance learning from feature and image spaces.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.1325964652,"dev-research":0.380464111,"prompt-eng":0.4573946587,"data-quality":0.1810762545,"ml-security":0.100651196}}
{"text":"In the domain adaptation stage, unsupervised fine-tuning is performed by incorporating an adversarial discriminator on real-world images.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.2067831557,"dev-research":0.3911500487,"prompt-eng":0.4877301617,"data-quality":0.2471768915,"ml-security":0.2443661265}}
{"text":"The integration of an extended multi-grained contrastive loss and generative adversarial loss enables the adaptation of the student network from synthetic to real-world domains.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.1874281825,"dev-research":0.3962721884,"prompt-eng":0.4782922735,"data-quality":0.1428153356,"ml-security":0.3062242509}}
{"text":"Extensive experiments on real-world degraded datasets demonstrate the effectiveness of our proposed method.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.4781984303,"dev-research":0.3743104725,"prompt-eng":0.4307733713,"data-quality":0.3892927535,"ml-security":0.3305515004}}
{"text":"We compare our Uni-Removal framework with state-of-the-art supervised and unsupervised methods, showcasing its promising results in real-world image dehazing, deraining, and deblurring simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.05075v1"},"cats":{"new-dataset":0.1357455413,"dev-research":0.3812888091,"prompt-eng":0.4063872031,"data-quality":0.2169059538,"ml-security":0.1359876013}}
{"text":"Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.3596574527,"dev-research":0.5053223902,"prompt-eng":0.5699829997,"data-quality":0.2076931556,"ml-security":0.1221006652}}
{"text":"Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.1803050327,"dev-research":0.4731039407,"prompt-eng":0.668226722,"data-quality":0.145923153,"ml-security":0.2397780077}}
{"text":"However, it faces challenges with strict SQL syntax requirements.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.1481965038,"dev-research":0.4744550446,"prompt-eng":0.4491391584,"data-quality":0.1876126661,"ml-security":0.1568125648}}
{"text":"Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the fixed prompts can hardly handle the scenario where the semantic gap between the retrieved demonstration and the input question is large.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.1299448914,"dev-research":0.5034944143,"prompt-eng":0.6422893664,"data-quality":0.1871063216,"ml-security":0.1775345032}}
{"text":"In this paper, we propose a retrieval-augmented prompting method for a LLM-based Text-to-SQL framework, involving sample-aware prompting and a dynamic revision chain.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.2444301239,"dev-research":0.4960858801,"prompt-eng":0.6487410078,"data-quality":0.2098093908,"ml-security":0.0980790911}}
{"text":"Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and fine-grained information related to the given question.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.1784012335,"dev-research":0.4686319379,"prompt-eng":0.5551308769,"data-quality":0.1582877778,"ml-security":0.0955367441}}
{"text":"To retrieve questions sharing similar intents with input questions, we propose two strategies for assisting retrieval.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.1363726201,"dev-research":0.4586896316,"prompt-eng":0.5571680073,"data-quality":0.1552479895,"ml-security":0.1004697431}}
{"text":"Firstly, we leverage LLMs to simplify the original questions, unifying the syntax and thereby clarifying the users' intentions.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.075619019,"dev-research":0.5513676784,"prompt-eng":0.5752109215,"data-quality":0.1669018323,"ml-security":0.1338321729}}
{"text":"To generate executable and accurate SQLs without human intervention, we design a dynamic revision chain which iteratively adapts fine-grained feedback from the previously generated SQL.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.2314066599,"dev-research":0.5246590822,"prompt-eng":0.5313413783,"data-quality":0.2006828416,"ml-security":0.1314324824}}
{"text":"Experimental results on three Text-to-SQL benchmarks demonstrate the superiority of our method over strong baseline models.","meta":{"url":"http://arxiv.org/abs/2307.05074v1"},"cats":{"new-dataset":0.2255362037,"dev-research":0.4382406492,"prompt-eng":0.5192006176,"data-quality":0.1770788634,"ml-security":0.0830047811}}
{"text":"In epistemic logic, a way to deal with knowledge-wh is to interpret them as a kind of mention-some knowledge (MS-knowledge).","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.1863679088,"dev-research":0.4881422909,"prompt-eng":0.4715032715,"data-quality":0.1772551077,"ml-security":0.1018759868}}
{"text":"But philosophers and linguists have challenged both the sufficiency and necessity of such an account: some argue that knowledge-wh has, in addition to MS-knowledge, also a sensitivity to false belief (FS); others argue that knowledge-wh might only imply mention-some true belief (MS-true belief).","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.0730412762,"dev-research":0.4263923754,"prompt-eng":0.4212292362,"data-quality":0.1526226426,"ml-security":0.1817602361}}
{"text":"In this paper, we offer a logical study for all these different accounts.","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.1365162316,"dev-research":0.4539089212,"prompt-eng":0.4359617927,"data-quality":0.123874395,"ml-security":0.0841040363}}
{"text":"We apply the technique of bundled operators, and introduce four different bundled operators: $[\\mathsf{tB}^\\mathtt{MS}]^x \\phi := \\exists x (\\mathsf{[B]} \\phi \\wedge \\phi)$, $[\\mathsf{tB}^\\mathtt{MS}_\\mathtt{FS}]^x \\phi := \\exists x (\\mathsf{[B]} \\phi \\wedge \\phi)","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.0579366262,"dev-research":0.4394215338,"prompt-eng":0.4353072366,"data-quality":0.1119062538,"ml-security":0.1198590285}}
{"text":"\\wedge \\forall x (\\mathsf{[B]} \\phi \\to \\phi)$, $[\\mathsf{K}^\\mathtt{MS}]^x \\phi := \\exists x \\mathsf{[K]} \\phi$ and $[\\mathsf{K}^\\mathtt{MS}_\\mathtt{FS}]^x \\phi := \\exists x \\mathsf{[K]} \\phi \\wedge \\forall x (\\mathsf{[B]} \\phi \\to \\phi)$, which characterize the notions of MS-true belief, MS-true belief with FS, MS-knowledge and MS-knowledge with FS respectively.","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.0511324757,"dev-research":0.434830497,"prompt-eng":0.4349649983,"data-quality":0.101357136,"ml-security":0.1502437107}}
{"text":"We axiomatize the four logics which take the above operators (as well as $\\mathsf{[K]}$) as primitive modalities on the class of $S4.2$-constant-domain models, and compare the patterns of reasoning in the obtained logics, in order to show how the four accounts of knowledge-wh differ from each other, as well as what they have in common.","meta":{"url":"http://arxiv.org/abs/2307.05073v1"},"cats":{"new-dataset":0.101971195,"dev-research":0.4465014156,"prompt-eng":0.4351017143,"data-quality":0.0893938463,"ml-security":0.1267429678}}
{"text":"Binarizing belief aggregation addresses how to rationally aggregate individual probabilistic beliefs into collective binary beliefs.","meta":{"url":"http://arxiv.org/abs/2307.05072v1"},"cats":{"new-dataset":0.0745842901,"dev-research":0.4445731029,"prompt-eng":0.4708214211,"data-quality":0.1681669118,"ml-security":0.1330778194}}
{"text":"Similar to the development of judgment aggregation theory, formulating axiomatic requirements, proving impossibility theorems, and identifying exact agenda conditions of impossibility theorems are natural and important research topics in binarizing belief aggregation.","meta":{"url":"http://arxiv.org/abs/2307.05072v1"},"cats":{"new-dataset":0.0495931873,"dev-research":0.4494091074,"prompt-eng":0.43493898,"data-quality":0.1630503099,"ml-security":0.1311678751}}
{"text":"Building on our previous research on impossibility theorems, we use an agenda-theoretic approach to generalize the results and to determine the necessary and sufficient level of logical interconnection between the issues in an agenda for the impossibility theorems to arise.","meta":{"url":"http://arxiv.org/abs/2307.05072v1"},"cats":{"new-dataset":0.0599394179,"dev-research":0.442197563,"prompt-eng":0.3764993694,"data-quality":0.1237972145,"ml-security":0.1336217351}}
{"text":"We demonstrate that (1) path-connectedness and even-negatability constitute the exact agenda condition for the oligarchy result stating that binarizing belief aggregation satisfying proposition-wise independence and deductive closure of collective beliefs yields the oligarchies under minor conditions; (2) negation-connectedness is the condition for the triviality result obtained by adding anonymity to the oligarchy result; and (3) blockedness is the condition for the impossibility result, which follows by adding completeness and consistency of collective beliefs.","meta":{"url":"http://arxiv.org/abs/2307.05072v1"},"cats":{"new-dataset":0.0733400076,"dev-research":0.4260323095,"prompt-eng":0.4002483077,"data-quality":0.1769732277,"ml-security":0.1527721649}}
{"text":"Moreover, we compare these novel findings with existing agenda-theoretic characterization theorems in judgment aggregation and belief binarization.","meta":{"url":"http://arxiv.org/abs/2307.05072v1"},"cats":{"new-dataset":0.0563466364,"dev-research":0.4430498381,"prompt-eng":0.4524705641,"data-quality":0.1782975451,"ml-security":0.1014715487}}
{"text":"Unknown unknowns are future relevant contingencies that lack an ex ante description.","meta":{"url":"http://arxiv.org/abs/2307.05071v1"},"cats":{"new-dataset":0.1510666134,"dev-research":0.5171354821,"prompt-eng":0.4509333834,"data-quality":0.2323940475,"ml-security":0.2399252556}}
{"text":"While there are numerous retrospective accounts showing that significant gains or losses might have been achieved or avoided had such contingencies been previously uncovered, getting hold of unknown unknowns still remains elusive, both in practice and conceptually.","meta":{"url":"http://arxiv.org/abs/2307.05071v1"},"cats":{"new-dataset":0.0680908861,"dev-research":0.4436551352,"prompt-eng":0.3871028793,"data-quality":0.1858580309,"ml-security":0.2374132281}}
{"text":"Using Formal Concept Analysis (FCA) - a subfield of lattice theory which is increasingly applied for mining and organizing data - this paper introduces a simple framework to systematically think out of the box and direct the search for unknown unknowns.","meta":{"url":"http://arxiv.org/abs/2307.05071v1"},"cats":{"new-dataset":0.1624672823,"dev-research":0.4347677973,"prompt-eng":0.4330489203,"data-quality":0.1830339958,"ml-security":0.1603596926}}
{"text":"This paper presents a logic-based framework to analyze responsibility, which I refer to as intentional epistemic act-utilitarian stit theory (IEAUST).","meta":{"url":"http://arxiv.org/abs/2307.05070v1"},"cats":{"new-dataset":0.1495136651,"dev-research":0.4749662097,"prompt-eng":0.3998301534,"data-quality":0.0985305087,"ml-security":0.0966566335}}
{"text":"To be precise, IEAUST is used to model and syntactically characterize various modes of responsibility, where by 'modes of responsibility' I mean instances of Broersen's three categories of responsibility (causal, informational, and motivational responsibility), cast against the background of particular deontic contexts.","meta":{"url":"http://arxiv.org/abs/2307.05070v1"},"cats":{"new-dataset":0.1005430003,"dev-research":0.4664581372,"prompt-eng":0.4378575784,"data-quality":0.086199068,"ml-security":0.1049424621}}
{"text":"IEAUST is obtained by integrating a modal language to express the following components of responsibility on stit models: agency, epistemic notions, intentionality, and different senses of obligation.","meta":{"url":"http://arxiv.org/abs/2307.05070v1"},"cats":{"new-dataset":0.1242227787,"dev-research":0.475355536,"prompt-eng":0.4750341304,"data-quality":0.1397541682,"ml-security":0.0820929802}}
{"text":"With such a language, I characterize the components of responsibility using particular formulas.","meta":{"url":"http://arxiv.org/abs/2307.05070v1"},"cats":{"new-dataset":0.2700168139,"dev-research":0.4766359011,"prompt-eng":0.4635900974,"data-quality":0.1203167448,"ml-security":0.0870187775}}
{"text":"Then, adopting a compositional approach -- where complex modalities are built out of more basic ones -- these characterizations of the components are used to formalize the aforementioned modes of responsibility.","meta":{"url":"http://arxiv.org/abs/2307.05070v1"},"cats":{"new-dataset":0.056761304,"dev-research":0.4681900164,"prompt-eng":0.428012682,"data-quality":0.0970927652,"ml-security":0.0782441512}}
{"text":"In this paper we formalise three types of cognitive bias within the framework of belief revision: confirmation bias, framing bias, and anchoring bias.","meta":{"url":"http://arxiv.org/abs/2307.05069v1"},"cats":{"new-dataset":0.0710884035,"dev-research":0.4808598722,"prompt-eng":0.4853291099,"data-quality":0.3376014945,"ml-security":0.1402929167}}
{"text":"We interpret them generally, as restrictions on the process of iterated revision, and we apply them to three well-known belief revision methods: conditioning, lexicographic revision, and minimal revision.","meta":{"url":"http://arxiv.org/abs/2307.05069v1"},"cats":{"new-dataset":0.1028556695,"dev-research":0.4619980564,"prompt-eng":0.4893235914,"data-quality":0.2155175877,"ml-security":0.0919195832}}
{"text":"We investigate the reliability of biased belief revision methods in truth tracking.","meta":{"url":"http://arxiv.org/abs/2307.05069v1"},"cats":{"new-dataset":0.1777256653,"dev-research":0.4296287749,"prompt-eng":0.4887862285,"data-quality":0.3946427535,"ml-security":0.1263943982}}
{"text":"We also run computer simulations to assess the performance of biased belief revision in random scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05069v1"},"cats":{"new-dataset":0.1181632939,"dev-research":0.4375681575,"prompt-eng":0.5192036675,"data-quality":0.2124450865,"ml-security":0.2264696834}}
{"text":"The dominant theories of rational choice assume logical omniscience.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0548983387,"dev-research":0.4689196502,"prompt-eng":0.391372512,"data-quality":0.1011859047,"ml-security":0.1440130029}}
{"text":"That is, they assume that when facing a decision problem, an agent can perform all relevant computations and determine the truth value of all relevant logical/mathematical claims.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0687069762,"dev-research":0.4817374469,"prompt-eng":0.4250222985,"data-quality":0.1013477553,"ml-security":0.2147433087}}
{"text":"This assumption is unrealistic when, for example, we offer bets on remote digits of pi or when an agent faces a computationally intractable planning problem.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0725776248,"dev-research":0.4266228841,"prompt-eng":0.3782949073,"data-quality":0.0595834243,"ml-security":0.2170831671}}
{"text":"Furthermore, the assumption of logical omniscience creates contradictions in cases where the environment can contain descriptions of the agent itself.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0610574055,"dev-research":0.5027527455,"prompt-eng":0.4069632911,"data-quality":0.1755769052,"ml-security":0.2188794889}}
{"text":"Importantly, strategic interactions as studied in game theory are decision problems in which a rational agent is predicted by its environment (the other players).","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.1046361176,"dev-research":0.4763985835,"prompt-eng":0.4204169039,"data-quality":0.0673832617,"ml-security":0.2699210376}}
{"text":"In this paper, we develop a theory of rational decision making that does not assume logical omniscience.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0466768453,"dev-research":0.4717946442,"prompt-eng":0.3587294267,"data-quality":0.1438926506,"ml-security":0.1915747903}}
{"text":"We consider agents who repeatedly face decision problems (including ones like betting on digits of pi or games against other agents).","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.08307463,"dev-research":0.4428406853,"prompt-eng":0.4276899098,"data-quality":0.1363002657,"ml-security":0.3109596039}}
{"text":"The main contribution of this paper is to provide a sensible theory of rationality for such agents.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0500206534,"dev-research":0.4483895422,"prompt-eng":0.3887237772,"data-quality":0.0644870247,"ml-security":0.1904857218}}
{"text":"Roughly, we require that a boundedly rational inductive agent tests each efficiently computable hypothesis infinitely often and follows those hypotheses that keep their promises of high rewards.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0447060295,"dev-research":0.4297498833,"prompt-eng":0.4059828395,"data-quality":0.078545452,"ml-security":0.204730873}}
{"text":"We then prove that agents that are rational in this sense have other desirable properties.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0886965833,"dev-research":0.4476829343,"prompt-eng":0.3997086999,"data-quality":0.1021131187,"ml-security":0.2204285376}}
{"text":"For example, they learn to value random and pseudo-random lotteries at their expected reward.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0965787011,"dev-research":0.4204396381,"prompt-eng":0.4645146662,"data-quality":0.1220237777,"ml-security":0.2358519517}}
{"text":"Finally, we consider strategic interactions between different agents and prove a folk theorem for what strategies bounded rational inductive agents can converge to.","meta":{"url":"http://arxiv.org/abs/2307.05068v1"},"cats":{"new-dataset":0.0690678515,"dev-research":0.4575507764,"prompt-eng":0.3974006596,"data-quality":0.064415628,"ml-security":0.2086480328}}
{"text":"Binary decision diagrams (BDDs) are widely used to mitigate the state-explosion problem in model checking.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.0512436731,"dev-research":0.4566929765,"prompt-eng":0.4504837633,"data-quality":0.1331893273,"ml-security":0.2429573019}}
{"text":"A variation of BDDs are Zero-suppressed Decision Diagrams (ZDDs) which omit variables that must be false, instead of omitting variables that do not matter.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.0476451287,"dev-research":0.453569759,"prompt-eng":0.4181044962,"data-quality":0.1480937454,"ml-security":0.2240460997}}
{"text":"We use ZDDs to symbolically encode Kripke models used in Dynamic Epistemic Logic, a framework to reason about knowledge and information dynamics in multi-agent systems.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.1779013173,"dev-research":0.4764615539,"prompt-eng":0.472534983,"data-quality":0.1302754219,"ml-security":0.1444039408}}
{"text":"We compare the memory usage of different ZDD variants for three well-known examples from the literature: the Muddy Children, the Sum and Product puzzle and the Dining Cryptographers.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.1876020694,"dev-research":0.4486166439,"prompt-eng":0.4374862163,"data-quality":0.1713722966,"ml-security":0.2750983657}}
{"text":"Our implementation is based on the existing model checker SMCDEL and the CUDD library.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.1473001776,"dev-research":0.4478632563,"prompt-eng":0.5155570648,"data-quality":0.1731742222,"ml-security":0.1433260783}}
{"text":"Our results show that replacing BDDs with the right variant of ZDDs can significantly reduce memory usage.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.0857209874,"dev-research":0.4388748111,"prompt-eng":0.4143738895,"data-quality":0.145101921,"ml-security":0.2104460685}}
{"text":"This suggests that ZDDs are a useful tool for model checking multi-agent systems.","meta":{"url":"http://arxiv.org/abs/2307.05067v1"},"cats":{"new-dataset":0.0668595409,"dev-research":0.4454287961,"prompt-eng":0.4695126354,"data-quality":0.0942671594,"ml-security":0.1566097503}}
{"text":"The logic of goal-directed knowing-how extends the standard epistemic logic with an operator of knowing-how.","meta":{"url":"http://arxiv.org/abs/2307.05066v1"},"cats":{"new-dataset":0.1181074396,"dev-research":0.4958750118,"prompt-eng":0.4618126477,"data-quality":0.0972671022,"ml-security":0.1239510155}}
{"text":"The knowing-how operator is interpreted as that there exists a strategy such that the agent knows that the strategy can make sure that p.","meta":{"url":"http://arxiv.org/abs/2307.05066v1"},"cats":{"new-dataset":0.1020656447,"dev-research":0.4786348133,"prompt-eng":0.4539096962,"data-quality":0.0854822608,"ml-security":0.1986215409}}
{"text":"This paper presents a tableau procedure for the multi-agent version of the logic of strategically knowing-how and shows the soundness and completeness of this tableau procedure.","meta":{"url":"http://arxiv.org/abs/2307.05066v1"},"cats":{"new-dataset":0.0932157983,"dev-research":0.4789286264,"prompt-eng":0.4796451624,"data-quality":0.0731738869,"ml-security":0.1372764178}}
{"text":"This paper also shows that the satisfiability problem of the logic can be decided in PSPACE.","meta":{"url":"http://arxiv.org/abs/2307.05066v1"},"cats":{"new-dataset":0.078895599,"dev-research":0.4290880015,"prompt-eng":0.4208660239,"data-quality":0.1128200668,"ml-security":0.1064390808}}
{"text":"The prescriptions of our two most prominent strands of decision theory, evidential and causal, differ in a general class of problems known as Newcomb problems.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0593650207,"dev-research":0.4494716559,"prompt-eng":0.3899741114,"data-quality":0.1412120231,"ml-security":0.2181862016}}
{"text":"In these, evidential decision theory prescribes choosing a dominated act.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0256075296,"dev-research":0.3890633592,"prompt-eng":0.4366445742,"data-quality":0.1068681234,"ml-security":0.166472084}}
{"text":"Attempts have been made at reconciling the two theories by relying on additional requirements such as ratification (Jeffrey 1983) or \"tickles\" (Eells 1982).","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0462407756,"dev-research":0.4721028621,"prompt-eng":0.3884467087,"data-quality":0.1367202574,"ml-security":0.0806440239}}
{"text":"It has been argued that such attempts have failed (Lewis 1981a; Skyrms 1982).","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0451153425,"dev-research":0.3901657002,"prompt-eng":0.3840426395,"data-quality":0.1746560726,"ml-security":0.1210439693}}
{"text":"More recently, Huttegger (forthcoming) has developed a version of deliberative decision theory that reconciles the prescriptions of the evidentialist and causalist.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0521549381,"dev-research":0.4343447855,"prompt-eng":0.4214500458,"data-quality":0.1338347507,"ml-security":0.1532990584}}
{"text":"In this paper, I extend this framework to problems characterised by decision instability, and show that it cannot deliver a resolute answer under a plausible specification of the tickle.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.09911805,"dev-research":0.4655754814,"prompt-eng":0.3841683999,"data-quality":0.2310095607,"ml-security":0.2695579422}}
{"text":"I prove that there exists a robust method of determining whether the specification of the tickle matters for all two-state, two-act problems whose payoff tables exhibit some basic mathematical relationships.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0691271175,"dev-research":0.4335033486,"prompt-eng":0.367097243,"data-quality":0.1022142353,"ml-security":0.1402529825}}
{"text":"One upshot is that we have a principled way of knowing ex-ante whether a reconciliation of evidential and causal decision theory is plausible for a wide range of decision problems under this framework.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.0384313259,"dev-research":0.4340217982,"prompt-eng":0.4534157333,"data-quality":0.1808649241,"ml-security":0.258699093}}
{"text":"Another upshot is that the tickle approach needs further work to achieve full reconciliation.","meta":{"url":"http://arxiv.org/abs/2307.05065v1"},"cats":{"new-dataset":0.2320462513,"dev-research":0.4663838115,"prompt-eng":0.4296554206,"data-quality":0.2245689458,"ml-security":0.0798489666}}
{"text":"We observe some puzzling linguistic data concerning ordinary knowledge ascriptions that embed an epistemic (im)possibility claim.","meta":{"url":"http://arxiv.org/abs/2307.05064v1"},"cats":{"new-dataset":0.2630957202,"dev-research":0.4836820664,"prompt-eng":0.4613315323,"data-quality":0.2945085955,"ml-security":0.1057218593}}
{"text":"We conclude that it is untenable to jointly endorse both classical logic and a pair of intuitively attractive theses: the thesis that knowledge ascriptions are always veridical and a `negative transparency' thesis that reduces knowledge of a simple negated `might' claim to an epistemic claim without modal content.","meta":{"url":"http://arxiv.org/abs/2307.05064v1"},"cats":{"new-dataset":0.0548873275,"dev-research":0.4692120136,"prompt-eng":0.4367666449,"data-quality":0.1826093087,"ml-security":0.1762157783}}
{"text":"We motivate a strategy for answering the trade-off: preserve veridicality and (generalized) negative transparency, while abandoning the general validity of contraposition.","meta":{"url":"http://arxiv.org/abs/2307.05064v1"},"cats":{"new-dataset":0.0427183673,"dev-research":0.4695406989,"prompt-eng":0.4133991341,"data-quality":0.178366298,"ml-security":0.2031294497}}
{"text":"We survey and criticize various approaches for incorporating veridicality into domain semantics, a paradigmatic `information-sensitive' framework for capturing negative transparency and, more generally, the non-classical behavior of sentences with epistemic modals.","meta":{"url":"http://arxiv.org/abs/2307.05064v1"},"cats":{"new-dataset":0.088353843,"dev-research":0.4572634067,"prompt-eng":0.510517073,"data-quality":0.2918524121,"ml-security":0.1795526201}}
{"text":"We then present a novel information-sensitive semantics that successfully executes our favored strategy: stable acceptance semantics.","meta":{"url":"http://arxiv.org/abs/2307.05064v1"},"cats":{"new-dataset":0.0799915852,"dev-research":0.4869726401,"prompt-eng":0.5337010556,"data-quality":0.363351288,"ml-security":0.3040557504}}
{"text":"We argue that behavioral science models of online content-sharing overlook the role of strategic interactions between users.","meta":{"url":"http://arxiv.org/abs/2307.05063v1"},"cats":{"new-dataset":0.0854965795,"dev-research":0.4465497233,"prompt-eng":0.4368057309,"data-quality":0.0956767867,"ml-security":0.1923124339}}
{"text":"Borrowing from accuracy-nudges studies decision-theoretic models, we propose a basic game model and explore special cases with idealized parameter settings to identify refinements necessary to capture real-world online social network behavior.","meta":{"url":"http://arxiv.org/abs/2307.05063v1"},"cats":{"new-dataset":0.1031004403,"dev-research":0.4161466313,"prompt-eng":0.4420877681,"data-quality":0.1425890912,"ml-security":0.2430889089}}
{"text":"Anticipating those refinements, we sketch a strategic analysis of content amplification and draw a connection between Keynes's beauty contest analogy and recent social-epistemological work on echo chambers.","meta":{"url":"http://arxiv.org/abs/2307.05063v1"},"cats":{"new-dataset":0.1631882706,"dev-research":0.4413292409,"prompt-eng":0.4120961538,"data-quality":0.1830175734,"ml-security":0.1069730393}}
{"text":"We conclude on the model's prospects from analytical and empirical perspectives.","meta":{"url":"http://arxiv.org/abs/2307.05063v1"},"cats":{"new-dataset":0.0359367596,"dev-research":0.4258068847,"prompt-eng":0.4082009193,"data-quality":0.0826242015,"ml-security":0.1441454391}}
{"text":"Two level credibility-limited revision is a non-prioritized revision operation.","meta":{"url":"http://arxiv.org/abs/2307.05062v1"},"cats":{"new-dataset":0.0712145526,"dev-research":0.4461164762,"prompt-eng":0.4419505083,"data-quality":0.1630455633,"ml-security":0.1523042377}}
{"text":"When revising by a two level credibility-limited revision, two levels of credibility and one level of incredibility are considered.","meta":{"url":"http://arxiv.org/abs/2307.05062v1"},"cats":{"new-dataset":0.0889489555,"dev-research":0.4194777465,"prompt-eng":0.4510290518,"data-quality":0.2985239918,"ml-security":0.1451853225}}
{"text":"When revising by a sentence at the highest level of credibility, the operator behaves as a standard revision, if the sentence is at the second level of credibility, then the outcome of the revision process coincides with a standard contraction by the negation of that sentence.","meta":{"url":"http://arxiv.org/abs/2307.05062v1"},"cats":{"new-dataset":0.0570510397,"dev-research":0.4284080343,"prompt-eng":0.4653630894,"data-quality":0.3639932979,"ml-security":0.1106539141}}
{"text":"If the sentence is not credible, then the original belief set remains unchanged.","meta":{"url":"http://arxiv.org/abs/2307.05062v1"},"cats":{"new-dataset":0.1353866664,"dev-research":0.4068792871,"prompt-eng":0.4310900175,"data-quality":0.3030038967,"ml-security":0.1178507446}}
{"text":"In this paper, we propose a construction for two level credibility-limited revision operators based on Grove's systems of spheres and present an axiomatic characterization for these operators.","meta":{"url":"http://arxiv.org/abs/2307.05062v1"},"cats":{"new-dataset":0.0923352168,"dev-research":0.433134098,"prompt-eng":0.4656469168,"data-quality":0.2651168737,"ml-security":0.1737438922}}
{"text":"Social distance games have been extensively studied as a coalition formation model where the utilities of agents in each coalition were captured using a utility function u that took into account distances in a given social network.","meta":{"url":"http://arxiv.org/abs/2307.05061v1"},"cats":{"new-dataset":0.146486784,"dev-research":0.4027111199,"prompt-eng":0.3986840871,"data-quality":0.0559124127,"ml-security":0.172355172}}
{"text":"In this paper, we consider a non-normalized score-based definition of social distance games where the utility function u_v depends on a generic scoring vector v, which may be customized to match the specifics of each individual application scenario.   ","meta":{"url":"http://arxiv.org/abs/2307.05061v1"},"cats":{"new-dataset":0.1151794816,"dev-research":0.4071415219,"prompt-eng":0.3924305159,"data-quality":0.0832347022,"ml-security":0.1512250462}}
{"text":"As our main technical contribution, we establish the tractability of computing a welfare-maximizing partitioning of the agents into coalitions on tree-like networks, for every score-based function u_v.","meta":{"url":"http://arxiv.org/abs/2307.05061v1"},"cats":{"new-dataset":0.1350814188,"dev-research":0.3973156263,"prompt-eng":0.3996927092,"data-quality":0.0804896603,"ml-security":0.1907468834}}
{"text":"We provide more efficient algorithms when dealing with specific choices of u_v or simpler networks, and also extend all of these results to computing coalitions that are Nash stable or individually rational.","meta":{"url":"http://arxiv.org/abs/2307.05061v1"},"cats":{"new-dataset":0.0814438413,"dev-research":0.3913585074,"prompt-eng":0.3541321866,"data-quality":0.0936687601,"ml-security":0.1803715592}}
{"text":"We view these results as a further strong indication of the usefulness of the proposed score-based utility function: even on very simple networks, the problem of computing a welfare-maximizing partitioning into coalitions remains open for the originally considered canonical function u.","meta":{"url":"http://arxiv.org/abs/2307.05061v1"},"cats":{"new-dataset":0.0863420582,"dev-research":0.4031720757,"prompt-eng":0.3932193783,"data-quality":0.1094936896,"ml-security":0.1909750001}}
{"text":"Arbitrary Public Announcement Logic with Common Knowledge (APALC) is an extension of Public Announcement Logic with common knowledge modality and quantifiers over announcements.","meta":{"url":"http://arxiv.org/abs/2307.05060v1"},"cats":{"new-dataset":0.1633433549,"dev-research":0.4747049434,"prompt-eng":0.4987708665,"data-quality":0.1797752551,"ml-security":0.1391089291}}
{"text":"We show that the satisfiability problem of APALC on S5-models, as well as that of two other related logics with quantification and common knowledge, is $\\Sigma^1_1$-hard.","meta":{"url":"http://arxiv.org/abs/2307.05060v1"},"cats":{"new-dataset":0.1034893345,"dev-research":0.4021088696,"prompt-eng":0.4549972281,"data-quality":0.1496638688,"ml-security":0.1354684489}}
{"text":"This implies that neither the validities nor the satisfiable formulas of APALC are recursively enumerable.","meta":{"url":"http://arxiv.org/abs/2307.05060v1"},"cats":{"new-dataset":0.0655460614,"dev-research":0.4002758496,"prompt-eng":0.3826001715,"data-quality":0.1589869019,"ml-security":0.1055362067}}
{"text":"Which, in turn, implies that APALC is not finitely axiomatisable.","meta":{"url":"http://arxiv.org/abs/2307.05060v1"},"cats":{"new-dataset":0.0428748386,"dev-research":0.4135939192,"prompt-eng":0.380506198,"data-quality":0.1242568434,"ml-security":0.1146953041}}
{"text":"Multi-agent influence diagrams (MAIDs) are a popular game-theoretic model based on Bayesian networks.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1897131809,"dev-research":0.4361757011,"prompt-eng":0.4745237103,"data-quality":0.0733953998,"ml-security":0.1542038476}}
{"text":"In some settings, MAIDs offer significant advantages over extensive-form game representations.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1407971372,"dev-research":0.4493531679,"prompt-eng":0.4068308352,"data-quality":0.0680660416,"ml-security":0.1349238486}}
{"text":"Previous work on MAIDs has assumed that agents employ behavioural policies, which set independent conditional probability distributions over actions for each of their decisions.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1200265625,"dev-research":0.4310501402,"prompt-eng":0.4850919446,"data-quality":0.0877011356,"ml-security":0.1378003507}}
{"text":"In settings with imperfect recall, however, a Nash equilibrium in behavioural policies may not exist.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1288209964,"dev-research":0.4122494997,"prompt-eng":0.4004141367,"data-quality":0.1868940778,"ml-security":0.2380389473}}
{"text":"We overcome this by showing how to solve MAIDs with forgetful and absent-minded agents using mixed policies and two types of correlated equilibrium.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1103175519,"dev-research":0.4105752256,"prompt-eng":0.4207954937,"data-quality":0.1174626384,"ml-security":0.1275987203}}
{"text":"We also analyse the computational complexity of key decision problems in MAIDs, and explore tractable cases.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1019448693,"dev-research":0.4234056141,"prompt-eng":0.3644587937,"data-quality":0.0895792153,"ml-security":0.1311328143}}
{"text":"Finally, we describe applications of MAIDs to Markov games and team situations, where imperfect recall is often unavoidable.","meta":{"url":"http://arxiv.org/abs/2307.05059v1"},"cats":{"new-dataset":0.1601176212,"dev-research":0.415996385,"prompt-eng":0.4566211877,"data-quality":0.1651444776,"ml-security":0.2640742485}}
{"text":"Any kind of dynamics in dynamic epistemic logic can be represented as an action model.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1070774009,"dev-research":0.4362875857,"prompt-eng":0.4579878697,"data-quality":0.0836384444,"ml-security":0.1228602081}}
{"text":"Right?","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.236338176,"dev-research":0.4352334005,"prompt-eng":0.3972720607,"data-quality":0.1396790304,"ml-security":0.1283751387}}
{"text":"Wrong!","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1852196885,"dev-research":0.4032633593,"prompt-eng":0.3910182264,"data-quality":0.1900685065,"ml-security":0.1170424789}}
{"text":"In this contribution we prove that the update expressivity of communication patterns is incomparable to that of action models.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.0893728397,"dev-research":0.4358598203,"prompt-eng":0.4735383072,"data-quality":0.150238855,"ml-security":0.2593770746}}
{"text":"Action models, as update mechanisms, were proposed by Baltag, Moss, and Solecki in 1998 and have remained the nearly universally accepted update mechanism in dynamic epistemic logics since then.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.0923550178,"dev-research":0.4808916692,"prompt-eng":0.4511459934,"data-quality":0.1368214244,"ml-security":0.168132548}}
{"text":"Alternatives, such as arrow updates that were proposed by Kooi and Renne in 2011, have update equivalent action models.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1220152745,"dev-research":0.4481261199,"prompt-eng":0.4604766044,"data-quality":0.0764687872,"ml-security":0.1252917176}}
{"text":"More recently, the picture is shifting.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.2447542495,"dev-research":0.4044294851,"prompt-eng":0.3870113234,"data-quality":0.1220804897,"ml-security":0.0608620951}}
{"text":"Communication patterns are update mechanisms originally proposed in some form or other by Agotnes and Wang in 2017 (as resolving distributed knowledge), by Baltag and Smets in 2020 (as reading events), and by Velazquez, Castaneda, and Rosenblueth in 2021 (as communication patterns).","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1893599278,"dev-research":0.4673783515,"prompt-eng":0.4684086523,"data-quality":0.1031684663,"ml-security":0.2050524637}}
{"text":"All these logics have the same expressivity as the base logic of distributed knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1464459161,"dev-research":0.4476170494,"prompt-eng":0.4270528098,"data-quality":0.0709854952,"ml-security":0.0934925774}}
{"text":"However, their update expressivity, the relation between pointed epistemic models induced by such an update, was conjectured to be different from that of action model logic.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.1010807902,"dev-research":0.4896022839,"prompt-eng":0.4465948653,"data-quality":0.1399012158,"ml-security":0.1301791798}}
{"text":"Indeed, we show that action model logic and communication pattern logic are incomparable in update expressivity.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.0922328314,"dev-research":0.4806963372,"prompt-eng":0.4521994083,"data-quality":0.111029636,"ml-security":0.1852017043}}
{"text":"We also show that, given a history-based semantics and when restricted to (static) interpreted systems, action model logic is (strictly) more update expressive than communication pattern logic.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.0989380755,"dev-research":0.4877066711,"prompt-eng":0.473268359,"data-quality":0.0947958781,"ml-security":0.2090470312}}
{"text":"Our results are relevant for distributed computing wherein oblivious models involve arbitrary iteration of communication patterns.","meta":{"url":"http://arxiv.org/abs/2307.05057v1"},"cats":{"new-dataset":0.0988948818,"dev-research":0.434797682,"prompt-eng":0.4003963221,"data-quality":0.118363892,"ml-security":0.4010136977}}
{"text":"Epistemic logics of intensional groups lift the assumption that membership in a group of agents is common knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05056v1"},"cats":{"new-dataset":0.1259036613,"dev-research":0.4689580957,"prompt-eng":0.4673947605,"data-quality":0.1060206296,"ml-security":0.151107615}}
{"text":"Instead of being represented directly as a set of agents, intensional groups are represented by a property that may change its extension from world to world.","meta":{"url":"http://arxiv.org/abs/2307.05056v1"},"cats":{"new-dataset":0.1421681363,"dev-research":0.4589048608,"prompt-eng":0.4398484546,"data-quality":0.0753780682,"ml-security":0.1133748571}}
{"text":"Several authors have considered versions of the intensional group framework where group-specifying properties are articulated using structured terms of a language, such as the language of Boolean algebras or of description logic.","meta":{"url":"http://arxiv.org/abs/2307.05056v1"},"cats":{"new-dataset":0.1633124827,"dev-research":0.4683426762,"prompt-eng":0.4928559496,"data-quality":0.1204346565,"ml-security":0.1102941408}}
{"text":"In this paper we formulate a general semantic framework for epistemic logics of structured intensional groups, develop the basic theory leading to completeness-via-canonicity results, and show that several frameworks presented in the literature correspond to special cases of the general framework.","meta":{"url":"http://arxiv.org/abs/2307.05056v1"},"cats":{"new-dataset":0.1425341094,"dev-research":0.4602401951,"prompt-eng":0.4704773449,"data-quality":0.180860359,"ml-security":0.0749511965}}
{"text":"Numerous logics have been developed to reason either about threshold-induced opinion diffusion in a network, or about similarity-driven network structure evolution, or about both.","meta":{"url":"http://arxiv.org/abs/2307.05055v1"},"cats":{"new-dataset":0.0359848432,"dev-research":0.4607651414,"prompt-eng":0.4429302813,"data-quality":0.1251924215,"ml-security":0.1812091411}}
{"text":"In this paper, we first introduce a logic containing different dynamic operators to capture changes that are 'asynchronous' (opinion change only, network-link change only) and changes that are 'synchronous' (both at the same time).","meta":{"url":"http://arxiv.org/abs/2307.05055v1"},"cats":{"new-dataset":0.0746930432,"dev-research":0.475701669,"prompt-eng":0.4467882276,"data-quality":0.1479242644,"ml-security":0.1756200715}}
{"text":"Second, we show that synchronous operators cannot, in general, be replaced by asynchronous operators and vice versa.","meta":{"url":"http://arxiv.org/abs/2307.05055v1"},"cats":{"new-dataset":0.0507874349,"dev-research":0.4194564938,"prompt-eng":0.395270604,"data-quality":0.157985203,"ml-security":0.185917138}}
{"text":"Third, we characterise the class of models on which the synchronous operator can be reduced to sequences of asynchronous operators.","meta":{"url":"http://arxiv.org/abs/2307.05055v1"},"cats":{"new-dataset":0.0945726614,"dev-research":0.379214389,"prompt-eng":0.4198294995,"data-quality":0.107523882,"ml-security":0.208441268}}
{"text":"We investigate the role of various demonstration components in the in-context learning (ICL) performance of large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0907374945,"dev-research":0.4362490192,"prompt-eng":0.5582079464,"data-quality":0.1772445305,"ml-security":0.1376782487}}
{"text":"Specifically, we explore the impacts of ground-truth labels, input distribution, and complementary explanations, particularly when these are altered or perturbed.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0922045131,"dev-research":0.4715966212,"prompt-eng":0.5138296904,"data-quality":0.4393236704,"ml-security":0.3254165933}}
{"text":"We build on previous work, which offers mixed findings on how these elements influence ICL.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0926661824,"dev-research":0.4853759405,"prompt-eng":0.4358562115,"data-quality":0.1062671064,"ml-security":0.0717941515}}
{"text":"To probe these questions, we employ explainable NLP (XNLP) methods and utilize saliency maps of contrastive demonstrations for both qualitative and quantitative analysis.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.1520335254,"dev-research":0.4488397478,"prompt-eng":0.4975499801,"data-quality":0.157741687,"ml-security":0.0537182167}}
{"text":"Our findings reveal that flipping ground-truth labels significantly affects the saliency, though it's more noticeable in larger LLMs.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.1351015715,"dev-research":0.3855685465,"prompt-eng":0.5184538651,"data-quality":0.2795632918,"ml-security":0.0875364312}}
{"text":"Our analysis of the input distribution at a granular level reveals that changing sentiment-indicative terms in a sentiment analysis task to neutral ones does not have as substantial an impact as altering ground-truth labels.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0747265308,"dev-research":0.4510851301,"prompt-eng":0.5075965007,"data-quality":0.4445104997,"ml-security":0.1674785565}}
{"text":"Finally, we find that the effectiveness of complementary explanations in boosting ICL performance is task-dependent, with limited benefits seen in sentiment analysis tasks compared to symbolic reasoning tasks.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0562754142,"dev-research":0.522630281,"prompt-eng":0.5079915156,"data-quality":0.2748583028,"ml-security":0.1344329171}}
{"text":"These insights are critical for understanding the functionality of LLMs and guiding the development of effective demonstrations, which is increasingly relevant in light of the growing use of LLMs in applications such as ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.0947375236,"dev-research":0.4611796893,"prompt-eng":0.5658640655,"data-quality":0.0599354848,"ml-security":0.0994784781}}
{"text":"Our research code is publicly available at https://github.com/paihengxu/XICL.","meta":{"url":"http://arxiv.org/abs/2307.05052v1"},"cats":{"new-dataset":0.5105733524,"dev-research":0.4645018841,"prompt-eng":0.4724934503,"data-quality":0.0976460133,"ml-security":0.1058270042}}
{"text":"This work builds upon a well-established research tradition on modal logics of awareness.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1098404608,"dev-research":0.4900877159,"prompt-eng":0.5089933504,"data-quality":0.1324205671,"ml-security":0.101680543}}
{"text":"One of its aims is to export tools and techniques to other areas within modal logic.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1189343622,"dev-research":0.5567000504,"prompt-eng":0.5223311328,"data-quality":0.073927752,"ml-security":0.0487657923}}
{"text":"To this end, we illustrate a number of significant bridges with abstract argumentation, justification logics, the epistemic logic of knowing-what and deontic logic, where basic notions and definitional concepts can be expressed in terms of the awareness operator combined with the box modality.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1424689861,"dev-research":0.5047466729,"prompt-eng":0.5036642466,"data-quality":0.119404279,"ml-security":0.1237555268}}
{"text":"Furthermore, these conceptual links point to interesting properties of awareness sets beyond those standardly assumed in awareness logics, i.e. positive and negative introspection.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1019130187,"dev-research":0.485667897,"prompt-eng":0.4625906959,"data-quality":0.1339165461,"ml-security":0.1310792996}}
{"text":"We show that the properties we list are characterised by corresponding canonical formulas, so as to obtain a series of off-the-shelf axiomatisations for them.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.099343028,"dev-research":0.4337019726,"prompt-eng":0.4164238362,"data-quality":0.092215152,"ml-security":0.1354756593}}
{"text":"As a second focus, we investigate the general dynamics of this framework by means of event models.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.0767703905,"dev-research":0.4080144788,"prompt-eng":0.4515450454,"data-quality":0.0829836928,"ml-security":0.144723391}}
{"text":"Of specific interest in this context is to know under which conditions, given a model that satisfies some property, the update with an event model keeps it within the intended class.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.0855388627,"dev-research":0.4734997923,"prompt-eng":0.4290780624,"data-quality":0.149137898,"ml-security":0.2264502791}}
{"text":"This is known as the closure problem in general dynamic epistemic logics.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1039938096,"dev-research":0.4581889049,"prompt-eng":0.4401396652,"data-quality":0.2303465092,"ml-security":0.2042009209}}
{"text":"As a main contribution, we prove a number of closure theorems providing sufficient conditions for the preservation of our properties.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.1111361904,"dev-research":0.4439009633,"prompt-eng":0.4304034269,"data-quality":0.1829586453,"ml-security":0.161283423}}
{"text":"Again, these results enable us to axiomatize our dynamic logics by means of reduction axioms.","meta":{"url":"http://arxiv.org/abs/2307.05049v1"},"cats":{"new-dataset":0.0583502958,"dev-research":0.4886310399,"prompt-eng":0.4388524825,"data-quality":0.1156040177,"ml-security":0.1429953478}}
{"text":"This paper extends and advances our recently introduced two-factor Honeytoken authentication method by incorporating blockchain technology.","meta":{"url":"http://arxiv.org/abs/2307.05047v1"},"cats":{"new-dataset":0.0687258935,"dev-research":0.419394423,"prompt-eng":0.4002773569,"data-quality":0.1019314373,"ml-security":0.2124298332}}
{"text":"This novel approach strengthens the authentication method to prevent many attacks including tampering attacks.","meta":{"url":"http://arxiv.org/abs/2307.05047v1"},"cats":{"new-dataset":0.0387806957,"dev-research":0.451072515,"prompt-eng":0.4329047487,"data-quality":0.1647552766,"ml-security":0.6566231703}}
{"text":"Evaluation results show that integrating blockchain into the Honeytoken method could improve performance and operational efficiency.","meta":{"url":"http://arxiv.org/abs/2307.05047v1"},"cats":{"new-dataset":0.0529780982,"dev-research":0.4377006605,"prompt-eng":0.35899171,"data-quality":0.0902964982,"ml-security":0.135343858}}
{"text":"Aristotle's discussions on modal syllogistic have often been viewed as error-prone and have garnered significant attention in the literature due to historical and philosophical interests.","meta":{"url":"http://arxiv.org/abs/2307.05043v1"},"cats":{"new-dataset":0.0552568075,"dev-research":0.4567556424,"prompt-eng":0.4596123929,"data-quality":0.2959932489,"ml-security":0.0687745462}}
{"text":"However, from a contemporary standpoint, they also introduced natural fragments of first-order modal logic, warranting a comprehensive technical analysis.","meta":{"url":"http://arxiv.org/abs/2307.05043v1"},"cats":{"new-dataset":0.0492662881,"dev-research":0.5008127033,"prompt-eng":0.4427066947,"data-quality":0.0756034987,"ml-security":0.0596737209}}
{"text":"In this paper, drawing inspiration from the natural logic program, we propose and examine several variants of modal syllogistic within the epistemic context, thereby coining the term Epistemic Syllogistic.","meta":{"url":"http://arxiv.org/abs/2307.05043v1"},"cats":{"new-dataset":0.1161536477,"dev-research":0.4920360561,"prompt-eng":0.490235865,"data-quality":0.2035671109,"ml-security":0.0731619518}}
{"text":"Specifically, we concentrate on the de re interpretation of epistemic syllogisms containing non-trivial yet natural expressions such as \"all things known to be A are also known to be not B.\" We explore the epistemic apodeictic syllogistic and its extensions, which accommodate more complex terms.","meta":{"url":"http://arxiv.org/abs/2307.05043v1"},"cats":{"new-dataset":0.1375342117,"dev-research":0.4685141484,"prompt-eng":0.4353055916,"data-quality":0.2640429152,"ml-security":0.1196775137}}
{"text":"Our main contributions include several axiomatizations of these logics, with completeness proofs that may be of independent interest.","meta":{"url":"http://arxiv.org/abs/2307.05043v1"},"cats":{"new-dataset":0.0587395449,"dev-research":0.4538368879,"prompt-eng":0.4190052383,"data-quality":0.1138389056,"ml-security":0.1181356442}}
{"text":"Awareness structures by Fagin and Halpern (1988) (FH) feature a syntactic awareness correspondence and accessibility relations modeling implicit knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.1838761851,"dev-research":0.4680720282,"prompt-eng":0.5526052876,"data-quality":0.1983285846,"ml-security":0.088713433}}
{"text":"They are a flexible model of unawareness, and best interpreted from a outside modeler's perspective.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.059087972,"dev-research":0.4579356658,"prompt-eng":0.4650555901,"data-quality":0.2435818059,"ml-security":0.2638840647}}
{"text":"Unawareness structures by Heifetz, Meier, and Schipper (2006, 2008) (HMS) model awareness by a lattice of state-spaces and explicit knowledge via a possibility correspondence.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.1057403396,"dev-research":0.422775295,"prompt-eng":0.5300991452,"data-quality":0.1974231575,"ml-security":0.2429624687}}
{"text":"They can be interpreted as providing the subjective views of agents.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.107386634,"dev-research":0.4766280182,"prompt-eng":0.4394724177,"data-quality":0.1071792884,"ml-security":0.1250915559}}
{"text":"Open questions include (1) how implicit knowledge can be defined in HMS structures, and (2) in which way FH structures can be extended to model the agents' subjective views.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.140579413,"dev-research":0.4681247807,"prompt-eng":0.4659191752,"data-quality":0.0994435053,"ml-security":0.17879576}}
{"text":"In this paper, we address (1) by showing how to derive implicit knowledge from explicit knowledge in HMS models.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.0938263434,"dev-research":0.4526456273,"prompt-eng":0.4841082821,"data-quality":0.1524861392,"ml-security":0.2135720169}}
{"text":"We also introduce a variant of HMS models that instead of explicit knowledge, takes implicit knowledge and awareness as primitives.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.0926120709,"dev-research":0.4524512159,"prompt-eng":0.5057120742,"data-quality":0.1243917183,"ml-security":0.2241526951}}
{"text":"Further, we address (2) by introducing a category of FH models that are modally equivalent relative to sublanguages and can be interpreted as agents' subjective views depending on their awareness.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.1167019038,"dev-research":0.4536741663,"prompt-eng":0.5285138095,"data-quality":0.1768616792,"ml-security":0.1188766337}}
{"text":"These constructions allow us to show an equivalence between HMS and FH models.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.0718559169,"dev-research":0.3872300755,"prompt-eng":0.4530050916,"data-quality":0.0940305314,"ml-security":0.1058077362}}
{"text":"As a corollary, we obtain soundness and completeness of HMS models with respect to the Logic of Propositional Awareness, based on a language featuring both implicit and explicit knowledge.","meta":{"url":"http://arxiv.org/abs/2307.05041v1"},"cats":{"new-dataset":0.0851648908,"dev-research":0.4457750509,"prompt-eng":0.5571154222,"data-quality":0.1640076431,"ml-security":0.1340905868}}
{"text":"Correspondence theory allows us to create sound and complete axiomatizations for modal logic on frames with certain properties.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0710411223,"dev-research":0.4004957779,"prompt-eng":0.4525318861,"data-quality":0.0886302527,"ml-security":0.0681440096}}
{"text":"For example, if we restrict ourselves to transitive frames we should add the axiom $\\square \\phi \\rightarrow \\square\\square\\phi$ which, among other things, can be interpreted as positive introspection.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0544645905,"dev-research":0.4542180954,"prompt-eng":0.4398762036,"data-quality":0.1809828942,"ml-security":0.1550395576}}
{"text":"One limitation of this technique is that the frame property and the axiom are assumed to hold globally, i.e., the relation is transitive throughout the frame, and the agent's knowledge satisfies positive introspection in every world.   ","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0656935399,"dev-research":0.4322735448,"prompt-eng":0.3869916811,"data-quality":0.0980265889,"ml-security":0.1688537138}}
{"text":"In a modal logic with local properties, we can reason about properties that are not global.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0607045504,"dev-research":0.4369041452,"prompt-eng":0.460824373,"data-quality":0.151447536,"ml-security":0.0969775849}}
{"text":"So, for example, transitivity might hold only in certain parts of the model and, as a result, the agent's knowledge might satisfy positive introspection in some worlds but not in others.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0620010344,"dev-research":0.4280235108,"prompt-eng":0.4446932539,"data-quality":0.1161375777,"ml-security":0.1467540687}}
{"text":"Van Ditmarsch et al. (2012) introduced sound and complete axiomatizations for modal logics with certain local properties.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0748371083,"dev-research":0.4289056686,"prompt-eng":0.4705469028,"data-quality":0.1199309204,"ml-security":0.0901214883}}
{"text":"Unfortunately, those axiomatizations are rather complex.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.0477796707,"dev-research":0.4282060512,"prompt-eng":0.3766503748,"data-quality":0.1050427248,"ml-security":0.1172881054}}
{"text":"Here, we introduce far simpler axiomatizations for a wide range of local properties.","meta":{"url":"http://arxiv.org/abs/2307.05040v1"},"cats":{"new-dataset":0.1137312651,"dev-research":0.4365696579,"prompt-eng":0.4321965824,"data-quality":0.1709739897,"ml-security":0.138309237}}
{"text":"Nighttime surveillance suffers from degradation due to poor illumination and arduous human annotations.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.2135430731,"dev-research":0.401821318,"prompt-eng":0.4235821898,"data-quality":0.2879831635,"ml-security":0.1905554176}}
{"text":"It is challengable and remains a security risk at night.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.1242059246,"dev-research":0.3883791308,"prompt-eng":0.3971568911,"data-quality":0.1192892684,"ml-security":0.5152448469}}
{"text":"Existing methods rely on multi-spectral images to perceive objects in the dark, which are troubled by low resolution and color absence.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.1138940329,"dev-research":0.3483327343,"prompt-eng":0.3696351562,"data-quality":0.1879942479,"ml-security":0.077839251}}
{"text":"We argue that the ultimate solution for nighttime surveillance is night-to-day translation, or Night2Day, which aims to translate a surveillance scene from nighttime to the daytime while maintaining semantic consistency.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.2531616779,"dev-research":0.4312517163,"prompt-eng":0.4240945256,"data-quality":0.2047292781,"ml-security":0.1154134928}}
{"text":"To achieve this, this paper presents a Disentangled Contrastive (DiCo) learning method.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.1352979043,"dev-research":0.3576921647,"prompt-eng":0.4142950382,"data-quality":0.1409869802,"ml-security":0.1255070352}}
{"text":"Specifically, to address the poor and complex illumination in the nighttime scenes, we propose a learnable physical prior, i.e., the color invariant, which provides a stable perception of a highly dynamic night environment and can be incorporated into the learning pipeline of neural networks.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.1332115401,"dev-research":0.3708428912,"prompt-eng":0.4163976451,"data-quality":0.1219259285,"ml-security":0.1793801867}}
{"text":"Targeting the surveillance scenes, we develop a disentangled representation, which is an auxiliary pretext task that separates surveillance scenes into the foreground and background with contrastive learning.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.2071458972,"dev-research":0.3994204488,"prompt-eng":0.4453929039,"data-quality":0.1372822615,"ml-security":0.1597869306}}
{"text":"Such a strategy can extract the semantics without supervision and boost our model to achieve instance-aware translation.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.1328835636,"dev-research":0.4400566486,"prompt-eng":0.5504342136,"data-quality":0.2430872298,"ml-security":0.1109251756}}
{"text":"Finally, we incorporate all the modules above into generative adversarial networks and achieve high-fidelity translation.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.2382778128,"dev-research":0.3960030696,"prompt-eng":0.5217491415,"data-quality":0.2386507055,"ml-security":0.173769061}}
{"text":"This paper also contributes a new surveillance dataset called NightSuR.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.7096506924,"dev-research":0.3613688626,"prompt-eng":0.4069151439,"data-quality":0.112593481,"ml-security":0.2355847303}}
{"text":"It includes six scenes to support the study on nighttime surveillance.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.3429664364,"dev-research":0.3998384755,"prompt-eng":0.3972066198,"data-quality":0.1002986446,"ml-security":0.0874028987}}
{"text":"This dataset collects nighttime images with different properties of nighttime environments, such as flare and extreme darkness.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.6965908076,"dev-research":0.367106201,"prompt-eng":0.4049930546,"data-quality":0.1210352731,"ml-security":0.1444254319}}
{"text":"Extensive experiments demonstrate that our method outperforms existing works significantly.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.0482138558,"dev-research":0.4468260135,"prompt-eng":0.4300722545,"data-quality":0.1937986597,"ml-security":0.1067964212}}
{"text":"The dataset and source code will be released on GitHub soon.","meta":{"url":"http://arxiv.org/abs/2307.05038v1"},"cats":{"new-dataset":0.8787252755,"dev-research":0.4623146219,"prompt-eng":0.484580868,"data-quality":0.1355079629,"ml-security":0.161893922}}
{"text":"The recommendation system is not only a problem of inductive statistics from data but also a cognitive task that requires reasoning ability.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.1574544081,"dev-research":0.468908416,"prompt-eng":0.4830847631,"data-quality":0.1510263013,"ml-security":0.1597132599}}
{"text":"The most advanced graph neural networks have been widely used in recommendation systems because they can capture implicit structured information from graph-structured data.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.2340563978,"dev-research":0.3933869608,"prompt-eng":0.4587864102,"data-quality":0.1777679024,"ml-security":0.1989010214}}
{"text":"However, like most neural network algorithms, they only learn matching patterns from a perception perspective.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.0805883425,"dev-research":0.3690197292,"prompt-eng":0.3820523567,"data-quality":0.1666936408,"ml-security":0.1786824016}}
{"text":"Some researchers use user behavior for logic reasoning to achieve recommendation prediction from the perspective of cognitive reasoning, but this kind of reasoning is a local one and ignores implicit information on a global scale.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.1004371819,"dev-research":0.4809094733,"prompt-eng":0.4830388698,"data-quality":0.0831592517,"ml-security":0.1674454869}}
{"text":"In this work, we combine the advantages of graph neural networks and propositional logic operations to construct a neuro-symbolic recommendation model with both global implicit reasoning ability and local explicit logic reasoning ability.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.1314044063,"dev-research":0.4490562651,"prompt-eng":0.4760191611,"data-quality":0.1248999143,"ml-security":0.1240446136}}
{"text":"We first build an item-item graph based on the principle of adjacent interaction and use graph neural networks to capture implicit information in global data.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.346938754,"dev-research":0.4346939355,"prompt-eng":0.4919213322,"data-quality":0.1977626536,"ml-security":0.1174923054}}
{"text":"Then we transform user behavior into propositional logic expressions to achieve recommendations from the perspective of cognitive reasoning.","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.0864186522,"dev-research":0.5184720316,"prompt-eng":0.5413764846,"data-quality":0.063489768,"ml-security":0.1111345964}}
{"text":"Extensive experiments on five public datasets show that our proposed model outperforms several state-of-the-art methods, source code is avaliable at [https://github.com/hanzo2020/GNNLR].","meta":{"url":"http://arxiv.org/abs/2307.05036v1"},"cats":{"new-dataset":0.5152437118,"dev-research":0.4019273187,"prompt-eng":0.4702648278,"data-quality":0.1843309956,"ml-security":0.2211919763}}
{"text":"Deep neural networks (DNNs) have become an enabling component for a myriad of artificial intelligence applications.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1974361372,"dev-research":0.3969366168,"prompt-eng":0.4427053253,"data-quality":0.0936206407,"ml-security":0.2492958871}}
{"text":"DNNs have shown sometimes superior performance, even compared to humans, in cases such as self-driving, health applications, etc.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.095337447,"dev-research":0.391033842,"prompt-eng":0.3991894108,"data-quality":0.1160029976,"ml-security":0.1523317126}}
{"text":"Because of their computational complexity, deploying DNNs in resource-constrained devices still faces many challenges related to computing complexity, energy efficiency, latency, and cost.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.0954329776,"dev-research":0.3927544445,"prompt-eng":0.388703246,"data-quality":0.0763512582,"ml-security":0.1549976827}}
{"text":"To this end, several research directions are being pursued by both academia and industry to accelerate and efficiently implement DNNs.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1143399799,"dev-research":0.4227005547,"prompt-eng":0.4305230868,"data-quality":0.0778147929,"ml-security":0.1421938709}}
{"text":"One important direction is determining the appropriate data representation for the massive amount of data involved in DNN processing.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.269401913,"dev-research":0.4088149643,"prompt-eng":0.4556399338,"data-quality":0.1639265127,"ml-security":0.14383081}}
{"text":"Using conventional number systems has been found to be sub-optimal for DNNs.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1635054584,"dev-research":0.361088695,"prompt-eng":0.416398882,"data-quality":0.1544732629,"ml-security":0.224263026}}
{"text":"Alternatively, a great body of research focuses on exploring suitable number systems.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1814437441,"dev-research":0.4214987004,"prompt-eng":0.380800207,"data-quality":0.0516483106,"ml-security":0.1226036762}}
{"text":"This article aims to provide a comprehensive survey and discussion about alternative number systems for more efficient representations of DNN data.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.3315293969,"dev-research":0.3722079932,"prompt-eng":0.4306282575,"data-quality":0.1436636115,"ml-security":0.1925036059}}
{"text":"Various number systems (conventional/unconventional) exploited for DNNs are discussed.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1503301283,"dev-research":0.3805964692,"prompt-eng":0.4212785747,"data-quality":0.130480833,"ml-security":0.3084391382}}
{"text":"The impact of these number systems on the performance and hardware design of DNNs is considered.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1436104577,"dev-research":0.397985982,"prompt-eng":0.4062742302,"data-quality":0.1051645674,"ml-security":0.226264273}}
{"text":"In addition, this paper highlights the challenges associated with each number system and various solutions that are proposed for addressing them.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1354085569,"dev-research":0.4009107355,"prompt-eng":0.3632262619,"data-quality":0.122984442,"ml-security":0.2281839819}}
{"text":"The reader will be able to understand the importance of an efficient number system for DNN, learn about the widely used number systems for DNN, understand the trade-offs between various number systems, and consider various design aspects that affect the impact of number systems on DNN performance.","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.2561557846,"dev-research":0.4137018466,"prompt-eng":0.4496613048,"data-quality":0.1347926923,"ml-security":0.2422927671}}
{"text":"In addition, the recent trends and related research opportunities will be highlighted","meta":{"url":"http://arxiv.org/abs/2307.05035v1"},"cats":{"new-dataset":0.1647564559,"dev-research":0.4328565424,"prompt-eng":0.4149439172,"data-quality":0.0641348911,"ml-security":0.068104484}}
{"text":"We introduce a synthetic dataset called Sentences Involving Complex Compositional Knowledge (SICCK) and a novel analysis that investigates the performance of Natural Language Inference (NLI) models to understand compositionality in logic.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.3193140177,"dev-research":0.4514025153,"prompt-eng":0.526743552,"data-quality":0.1297634815,"ml-security":0.1137355752}}
{"text":"We produce 1,304 sentence pairs by modifying 15 examples from the SICK dataset (Marelli et al., 2014).","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.653687341,"dev-research":0.4236670885,"prompt-eng":0.4928763907,"data-quality":0.3039994304,"ml-security":0.1224610829}}
{"text":"To this end, we modify the original texts using a set of phrases - modifiers that correspond to universal quantifiers, existential quantifiers, negation, and other concept modifiers in Natural Logic (NL) (MacCartney, 2009).","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.2041885031,"dev-research":0.4885602603,"prompt-eng":0.4705187813,"data-quality":0.228298924,"ml-security":0.112845803}}
{"text":"We use these phrases to modify the subject, verb, and object parts of the premise and hypothesis.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.0954709218,"dev-research":0.5168872998,"prompt-eng":0.4811704111,"data-quality":0.1920741306,"ml-security":0.140628517}}
{"text":"Lastly, we annotate these modified texts with the corresponding entailment labels following NL rules.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.2874983722,"dev-research":0.5127093911,"prompt-eng":0.532690398,"data-quality":0.373405556,"ml-security":0.0802936794}}
{"text":"We conduct a preliminary verification of how well the change in the structural and semantic composition is captured by neural NLI models, in both zero-shot and fine-tuned scenarios.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.1128545202,"dev-research":0.4039456119,"prompt-eng":0.5298983209,"data-quality":0.3361287425,"ml-security":0.1120192711}}
{"text":"We found that the performance of NLI models under the zero-shot setting is poor, especially for modified sentences with negation and existential quantifiers.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.0985348776,"dev-research":0.3978313129,"prompt-eng":0.4489268888,"data-quality":0.2656979522,"ml-security":0.1090616379}}
{"text":"After fine-tuning this dataset, we observe that models continue to perform poorly over negation, existential and universal modifiers.","meta":{"url":"http://arxiv.org/abs/2307.05034v2"},"cats":{"new-dataset":0.209214186,"dev-research":0.3983620226,"prompt-eng":0.4756613603,"data-quality":0.2871096984,"ml-security":0.123898113}}
{"text":"Event cameras are capable of responding to log-brightness changes in microseconds.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.1197324858,"dev-research":0.4140368352,"prompt-eng":0.4490442792,"data-quality":0.0895673656,"ml-security":0.0650935701}}
{"text":"Its characteristic of producing responses only to the changing region is particularly suitable for optical flow estimation.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.0797910205,"dev-research":0.3780083824,"prompt-eng":0.3832048442,"data-quality":0.0921056436,"ml-security":0.0647758245}}
{"text":"In contrast to the super low-latency response speed of event cameras, existing datasets collected via event cameras, however, only provide limited frame rate optical flow ground truth, (e.g., at 10Hz), greatly restricting the potential of event-driven optical flow.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.2665348719,"dev-research":0.3647495708,"prompt-eng":0.4165547678,"data-quality":0.0786581959,"ml-security":0.082747592}}
{"text":"To address this challenge, we put forward a high-frame-rate, low-latency event representation Unified Voxel Grid, sequentially fed into the network bin by bin.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.2080270466,"dev-research":0.368932942,"prompt-eng":0.44441008,"data-quality":0.0889023082,"ml-security":0.0666671874}}
{"text":"We then propose EVA-Flow, an EVent-based Anytime Flow estimation network to produce high-frame-rate event optical flow with only low-frame-rate optical flow ground truth for supervision.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.2013361808,"dev-research":0.4019671864,"prompt-eng":0.4561705118,"data-quality":0.1004606286,"ml-security":0.0696498931}}
{"text":"The key component of our EVA-Flow is the stacked Spatiotemporal Motion Refinement (SMR) module, which predicts temporally-dense optical flow and enhances the accuracy via spatial-temporal motion refinement.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.1320943344,"dev-research":0.3913561928,"prompt-eng":0.44531225,"data-quality":0.0732900176,"ml-security":0.0404832845}}
{"text":"The time-dense feature warping utilized in the SMR module provides implicit supervision for the intermediate optical flow.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.0683841895,"dev-research":0.4181995981,"prompt-eng":0.4565340428,"data-quality":0.1321004286,"ml-security":0.0407142042}}
{"text":"Additionally, we introduce the Rectified Flow Warp Loss (RFWL) for the unsupervised evaluation of intermediate optical flow in the absence of ground truth.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.1333197401,"dev-research":0.3652309505,"prompt-eng":0.4050939626,"data-quality":0.1369233403,"ml-security":0.0610793115}}
{"text":"This is, to the best of our knowledge, the first work focusing on anytime optical flow estimation via event cameras.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.2036665576,"dev-research":0.3784771847,"prompt-eng":0.4293177865,"data-quality":0.0814210966,"ml-security":0.037838124}}
{"text":"A comprehensive variety of experiments on MVSEC, DESC, and our EVA-FlowSet demonstrates that EVA-Flow achieves competitive performance, super-low-latency (5ms), fastest inference (9.2ms), time-dense motion estimation (200Hz), and strong generalization.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.1179649788,"dev-research":0.3635701289,"prompt-eng":0.4444527088,"data-quality":0.0586114344,"ml-security":0.104526862}}
{"text":"Our code will be available at https://github.com/Yaozhuwa/EVA-Flow.","meta":{"url":"http://arxiv.org/abs/2307.05033v1"},"cats":{"new-dataset":0.2278809863,"dev-research":0.4836299272,"prompt-eng":0.4947935935,"data-quality":0.0899746484,"ml-security":0.1116153011}}
{"text":"This thesis explores open-sourced machine learning (ML) model explanation tools to understand whether these tools can allow a layman to visualize, understand, and suggest intuitive remedies to unfairness in ML-based decision-support systems.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.1563802169,"dev-research":0.4878979188,"prompt-eng":0.4479387676,"data-quality":0.1942918406,"ml-security":0.4882480673}}
{"text":"Machine learning models trained on datasets biased against minority groups are increasingly used to guide life-altering social decisions, prompting the urgent need to study their logic for unfairness.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.1681927409,"dev-research":0.387686419,"prompt-eng":0.4152036846,"data-quality":0.1785678798,"ml-security":0.5521813163}}
{"text":"Due to this problem's impact on vast populations of the general public, it is critical for the layperson -- not just subject matter experts in social justice or machine learning experts -- to understand the nature of unfairness within these algorithms and the potential trade-offs.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.0938541671,"dev-research":0.4053166182,"prompt-eng":0.3573397372,"data-quality":0.1672830594,"ml-security":0.4601032238}}
{"text":"Existing research on fairness in machine learning focuses mostly on the mathematical definitions and tools to understand and remedy unfair models, with some directly citing user-interactive tools as necessary for future work.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.0822323225,"dev-research":0.4287957285,"prompt-eng":0.4306886702,"data-quality":0.1938194104,"ml-security":0.4993381411}}
{"text":"This thesis presents FairLay-ML, a proof-of-concept GUI integrating some of the most promising tools to provide intuitive explanations for unfair logic in ML models by integrating existing research tools (e.g. Local Interpretable Model-Agnostic Explanations) with existing ML-focused GUI (e.g. Python Streamlit).","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.124582219,"dev-research":0.5045682062,"prompt-eng":0.4957621991,"data-quality":0.1978693075,"ml-security":0.3305628813}}
{"text":"We test FairLay-ML using models of various accuracy and fairness generated by an unfairness detector tool, Parfait-ML, and validate our results using Themis.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.1836418006,"dev-research":0.4065377833,"prompt-eng":0.4818180383,"data-quality":0.3204402512,"ml-security":0.3691437495}}
{"text":"Our study finds that the technology stack used for FairLay-ML makes it easy to install and provides real-time black-box explanations of pre-trained models to users.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.1977082775,"dev-research":0.4769861782,"prompt-eng":0.548058821,"data-quality":0.1216084206,"ml-security":0.2498972594}}
{"text":"Furthermore, the explanations provided translate to actionable remedies.","meta":{"url":"http://arxiv.org/abs/2307.05029v1"},"cats":{"new-dataset":0.1241352201,"dev-research":0.5458778481,"prompt-eng":0.4709140352,"data-quality":0.148386926,"ml-security":0.1653830909}}
{"text":"In recent years, research on learning with noisy labels has focused on devising novel algorithms that can achieve robustness to noisy training labels while generalizing to clean data.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.1067064742,"dev-research":0.3862404202,"prompt-eng":0.4602912065,"data-quality":0.8334993085,"ml-security":0.4548855099}}
{"text":"These algorithms often incorporate sophisticated techniques, such as noise modeling, label correction, and co-training.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.0926874875,"dev-research":0.3993914299,"prompt-eng":0.4586631167,"data-quality":0.5589258185,"ml-security":0.1571113608}}
{"text":"In this study, we demonstrate that a simple baseline using cross-entropy loss, combined with widely used regularization strategies like learning rate decay, model weights average, and data augmentations, can outperform state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.1415076791,"dev-research":0.3609074201,"prompt-eng":0.5018603615,"data-quality":0.2402921969,"ml-security":0.2589664173}}
{"text":"Our findings suggest that employing a combination of regularization strategies can be more effective than intricate algorithms in tackling the challenges of learning with noisy labels.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.06450359,"dev-research":0.3759887024,"prompt-eng":0.4782463498,"data-quality":0.7302610834,"ml-security":0.3714909968}}
{"text":"While some of these regularization strategies have been utilized in previous noisy label learning research, their full potential has not been thoroughly explored.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.0825995984,"dev-research":0.3540170518,"prompt-eng":0.4743815466,"data-quality":0.7906344625,"ml-security":0.2648294534}}
{"text":"Our results encourage a reevaluation of benchmarks for learning with noisy labels and prompt reconsideration of the role of specialized learning algorithms designed for training with noisy labels.","meta":{"url":"http://arxiv.org/abs/2307.05025v1"},"cats":{"new-dataset":0.0990599273,"dev-research":0.3936451221,"prompt-eng":0.4693241607,"data-quality":0.601121852,"ml-security":0.2686823347}}
{"text":"We study the initial beam acquisition problem in millimeter wave (mm-wave) networks from the perspective of best arm identification in multi-armed bandits (MABs).","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0715693381,"dev-research":0.3692139457,"prompt-eng":0.4157897734,"data-quality":0.1268087482,"ml-security":0.2728067109}}
{"text":"For the stationary environment, we propose a novel algorithm called concurrent beam exploration, CBE, in which multiple beams are grouped based on the beam indices and are simultaneously activated to detect the presence of the user.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0585489603,"dev-research":0.3756077201,"prompt-eng":0.4129948479,"data-quality":0.0480571917,"ml-security":0.0870719828}}
{"text":"The best beam is then identified using a Hamming decoding strategy.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0890217558,"dev-research":0.3913851238,"prompt-eng":0.4602723995,"data-quality":0.1928932717,"ml-security":0.1518828613}}
{"text":"For the case of orthogonal and highly directional thin beams, we characterize the performance of CBE in terms of the probability of missed detection and false alarm in a beam group (BG).","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0408579487,"dev-research":0.3689737686,"prompt-eng":0.4371639392,"data-quality":0.1967541194,"ml-security":0.1565808777}}
{"text":"Leveraging this, we derive the probability of beam selection error and prove that CBE outperforms the state-of-the-art strategies in this metric.   ","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0340337055,"dev-research":0.3661824913,"prompt-eng":0.4574649549,"data-quality":0.1923984704,"ml-security":0.0733864285}}
{"text":"Then, for the abruptly changing environments, e.g., in the case of moving blockages, we characterize the performance of the classical sequential halving (SH) algorithm.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0884579095,"dev-research":0.358993562,"prompt-eng":0.3302970598,"data-quality":0.0619388893,"ml-security":0.1037794508}}
{"text":"In particular, we derive the conditions on the distribution of the change for which the beam selection error is exponentially bounded.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0393757678,"dev-research":0.3660906509,"prompt-eng":0.3911675975,"data-quality":0.1345362083,"ml-security":0.1706227151}}
{"text":"In case the change is restricted to a subset of the beams, we devise a strategy called K-sequential halving and exhaustive search, K-SHES, that leads to an improved bound for the beam selection error as compared to SH.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0401424058,"dev-research":0.3728614863,"prompt-eng":0.3929877419,"data-quality":0.0997573763,"ml-security":0.0997473744}}
{"text":"This policy is particularly useful when a near-optimal beam becomes optimal during the beam-selection procedure due to abruptly changing channel conditions.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0228856726,"dev-research":0.3791190683,"prompt-eng":0.4199022857,"data-quality":0.0688159804,"ml-security":0.0970167125}}
{"text":"Finally, we demonstrate the efficacy of the proposed scheme by employing it in a tandem beam refinement and data transmission scheme.","meta":{"url":"http://arxiv.org/abs/2307.05023v1"},"cats":{"new-dataset":0.0842534598,"dev-research":0.3384097105,"prompt-eng":0.4197530308,"data-quality":0.1177154389,"ml-security":0.1239591584}}
{"text":"Decisions made by convolutional neural networks(CNN) can be understood and explained by visualizing discriminative regions on images.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.201458179,"dev-research":0.4366761867,"prompt-eng":0.4567735464,"data-quality":0.1674639987,"ml-security":0.1407902237}}
{"text":"To this end, Class Activation Map (CAM) based methods were proposed as powerful interpretation tools, making the prediction of deep learning models more explainable, transparent, and trustworthy.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.1360999128,"dev-research":0.4315099701,"prompt-eng":0.4759738548,"data-quality":0.2398746592,"ml-security":0.3690471696}}
{"text":"However, all the CAM-based methods (e.g., CAM, Grad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with fully-connected (FC) layers as a classifier.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.1080067005,"dev-research":0.3849035898,"prompt-eng":0.4204865339,"data-quality":0.1729808258,"ml-security":0.1192476285}}
{"text":"It is worth noting that many deep learning models classify images without FC layers, e.g., few-shot learning image classification, contrastive learning image classification, and image retrieval tasks.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.1223139011,"dev-research":0.3534279482,"prompt-eng":0.4250432363,"data-quality":0.1574846913,"ml-security":0.1574615632}}
{"text":"In this work, a post-hoc interpretation tool named feature activation map (FAM) is proposed, which can interpret deep learning models without FC layers as a classifier.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.1448253924,"dev-research":0.4224240083,"prompt-eng":0.5192973682,"data-quality":0.2468146615,"ml-security":0.2575197179}}
{"text":"In the proposed FAM algorithm, the channel-wise contribution weights are derived from the similarity scores between two image embeddings.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.0925284235,"dev-research":0.3766153233,"prompt-eng":0.4670671035,"data-quality":0.1523759938,"ml-security":0.1044502246}}
{"text":"The activation maps are linearly combined with the corresponding normalized contribution weights, forming the explanation map for visualization.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.0719297457,"dev-research":0.4587106099,"prompt-eng":0.4293913392,"data-quality":0.105172426,"ml-security":0.1260491219}}
{"text":"The quantitative and qualitative experiments conducted on ten deep learning models for few-shot image classification, contrastive learning image classification and image retrieval tasks demonstrate the effectiveness of the proposed FAM algorithm.","meta":{"url":"http://arxiv.org/abs/2307.05017v1"},"cats":{"new-dataset":0.1277595187,"dev-research":0.3473047109,"prompt-eng":0.4624080941,"data-quality":0.1597308962,"ml-security":0.154685507}}
{"text":"Transparent objects are encountered frequently in our daily lives, yet recognizing them poses challenges for conventional vision sensors due to their unique material properties, not being well perceived from RGB or depth cameras.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.1574960102,"dev-research":0.3539634635,"prompt-eng":0.4166293299,"data-quality":0.1506529701,"ml-security":0.1542985653}}
{"text":"Overcoming this limitation, thermal infrared cameras have emerged as a solution, offering improved visibility and shape information for transparent objects.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.2009181852,"dev-research":0.3635935823,"prompt-eng":0.3985894394,"data-quality":0.07413149,"ml-security":0.1420761613}}
{"text":"In this paper, we present TRansPose, the first large-scale multispectral dataset that combines stereo RGB-D, thermal infrared (TIR) images, and object poses to promote transparent object research.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.5365919394,"dev-research":0.3426048666,"prompt-eng":0.4313086881,"data-quality":0.0709430826,"ml-security":0.1326275801}}
{"text":"The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.686868564,"dev-research":0.3909341043,"prompt-eng":0.4330767836,"data-quality":0.1681545577,"ml-security":0.1827124489}}
{"text":"It comprises a vast collection of 333,819 images and 4,000,056 annotations, providing instance-level segmentation masks, ground-truth poses, and completed depth information.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.66801264,"dev-research":0.4012958732,"prompt-eng":0.4788662059,"data-quality":0.1707559677,"ml-security":0.0908710677}}
{"text":"The data was acquired using a FLIR A65 thermal infrared (TIR) camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.6991621542,"dev-research":0.3647036572,"prompt-eng":0.426657956,"data-quality":0.0768428117,"ml-security":0.0665543476}}
{"text":"Spanning 87 sequences, TRansPose covers various challenging real-life scenarios, including objects filled with water, diverse lighting conditions, heavy clutter, non-transparent or translucent containers, objects in plastic bags, and multi-stacked objects.","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.194187455,"dev-research":0.382239638,"prompt-eng":0.3815279011,"data-quality":0.0679064864,"ml-security":0.1193355511}}
{"text":"TRansPose dataset can be accessed from the following link: https://sites.google.com/view/transpose-dataset","meta":{"url":"http://arxiv.org/abs/2307.05016v1"},"cats":{"new-dataset":0.7206132319,"dev-research":0.3628686399,"prompt-eng":0.4246274662,"data-quality":0.0602621952,"ml-security":0.1182579913}}
{"text":"Prior work has established test-time training (TTT) as a general framework to further improve a trained model at test time.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.0791887417,"dev-research":0.4378335978,"prompt-eng":0.5110561059,"data-quality":0.1006267873,"ml-security":0.1683500382}}
{"text":"Before making a prediction on each test instance, the model is trained on the same instance using a self-supervised task, such as image reconstruction with masked autoencoders.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1513804216,"dev-research":0.3948957788,"prompt-eng":0.5400862743,"data-quality":0.23648575,"ml-security":0.2161270298}}
{"text":"We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1531809302,"dev-research":0.4280560705,"prompt-eng":0.4998481621,"data-quality":0.1021631766,"ml-security":0.0923467734}}
{"text":"Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1043858875,"dev-research":0.4198786085,"prompt-eng":0.5406874243,"data-quality":0.0866946541,"ml-security":0.1184888375}}
{"text":"Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.2423722377,"dev-research":0.4123971197,"prompt-eng":0.5095560806,"data-quality":0.1167835475,"ml-security":0.1082785089}}
{"text":"The relative improvement is 45% and 66% for instance and panoptic segmentation.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1228924491,"dev-research":0.3964246184,"prompt-eng":0.4447109875,"data-quality":0.1607531908,"ml-security":0.0366694511}}
{"text":"Surprisingly, online TTT also outperforms its offline variant that accesses more information, training on all frames from the entire test video regardless of temporal order.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1361599353,"dev-research":0.4139365472,"prompt-eng":0.4760024236,"data-quality":0.1028366912,"ml-security":0.1114511728}}
{"text":"This differs from previous findings using synthetic videos.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.2421943213,"dev-research":0.4100396442,"prompt-eng":0.3976667577,"data-quality":0.1858922406,"ml-security":0.0698697481}}
{"text":"We conceptualize locality as the advantage of online over offline TTT.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.1119705439,"dev-research":0.4618933257,"prompt-eng":0.4330433243,"data-quality":0.0747111911,"ml-security":0.1308756048}}
{"text":"We analyze the role of locality with ablations and a theory based on bias-variance trade-off.","meta":{"url":"http://arxiv.org/abs/2307.05014v1"},"cats":{"new-dataset":0.0595746234,"dev-research":0.3715386919,"prompt-eng":0.4034131219,"data-quality":0.1578015638,"ml-security":0.0794733937}}
{"text":"RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end model for speech to text conversion because of their high accuracy and streaming capabilities.","meta":{"url":"http://arxiv.org/abs/2307.05006v1"},"cats":{"new-dataset":0.276284152,"dev-research":0.3603722348,"prompt-eng":0.5275640978,"data-quality":0.1669151332,"ml-security":0.0911235374}}
{"text":"A typical RNN-T independently encodes the input audio and the text context, and combines the two encodings by a thin joint network.","meta":{"url":"http://arxiv.org/abs/2307.05006v1"},"cats":{"new-dataset":0.1721671993,"dev-research":0.3900405873,"prompt-eng":0.4812520244,"data-quality":0.1532129318,"ml-security":0.104585429}}
{"text":"While this architecture provides SOTA streaming accuracy, it also makes the model vulnerable to strong LM biasing which manifests as multi-step hallucination of text without acoustic evidence.","meta":{"url":"http://arxiv.org/abs/2307.05006v1"},"cats":{"new-dataset":0.1127916923,"dev-research":0.3655747293,"prompt-eng":0.4819725726,"data-quality":0.2191743632,"ml-security":0.1289164336}}
{"text":"In this paper we propose LookAhead that makes text representations more acoustically grounded by looking ahead into the future within the audio input.","meta":{"url":"http://arxiv.org/abs/2307.05006v1"},"cats":{"new-dataset":0.1806960362,"dev-research":0.4283511958,"prompt-eng":0.4926032626,"data-quality":0.149936626,"ml-security":0.0875643078}}
{"text":"This technique yields a significant 5%-20% relative reduction in word error rate on both in-domain and out-of-domain evaluation sets.","meta":{"url":"http://arxiv.org/abs/2307.05006v1"},"cats":{"new-dataset":0.0874315349,"dev-research":0.4484098321,"prompt-eng":0.5227408571,"data-quality":0.5144770105,"ml-security":0.0875222345}}
{"text":"This paper proposes a generative probabilistic model integrating emergent communication and multi-agent reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.1562854604,"dev-research":0.4248005912,"prompt-eng":0.5165048273,"data-quality":0.0763188835,"ml-security":0.1175371944}}
{"text":"The agents plan their actions by probabilistic inference, called control as inference, and communicate using messages that are latent variables and estimated based on the planned actions.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.142262989,"dev-research":0.4719137091,"prompt-eng":0.5486015513,"data-quality":0.0658814143,"ml-security":0.1578261164}}
{"text":"Through these messages, each agent can send information about its actions and know information about the actions of another agent.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.2432906803,"dev-research":0.4824146446,"prompt-eng":0.5317113928,"data-quality":0.1003163771,"ml-security":0.1739762261}}
{"text":"Therefore, the agents change their actions according to the estimated messages to achieve cooperative tasks.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.1225371753,"dev-research":0.4668238223,"prompt-eng":0.4920728356,"data-quality":0.0903711514,"ml-security":0.1556074483}}
{"text":"This inference of messages can be considered as communication, and this procedure can be formulated by the Metropolis-Hasting naming game.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.2025930857,"dev-research":0.4543579511,"prompt-eng":0.5221119762,"data-quality":0.2197241534,"ml-security":0.1730645417}}
{"text":"Through experiments in the grid world environment, we show that the proposed PGM can infer meaningful messages to achieve the cooperative task.","meta":{"url":"http://arxiv.org/abs/2307.05004v1"},"cats":{"new-dataset":0.1801917725,"dev-research":0.4315100488,"prompt-eng":0.4979306847,"data-quality":0.100469144,"ml-security":0.1596511454}}
{"text":"Rendering photorealistic and dynamically moving human heads is crucial for ensuring a pleasant and immersive experience in AR/VR and video conferencing applications.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.1169926849,"dev-research":0.3788817545,"prompt-eng":0.3850874648,"data-quality":0.0395220597,"ml-security":0.0570803622}}
{"text":"However, existing methods often struggle to model challenging facial regions (e.g., mouth interior, eyes, hair/beard), resulting in unrealistic and blurry results.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.0616787858,"dev-research":0.3590987472,"prompt-eng":0.3963723284,"data-quality":0.1197011028,"ml-security":0.1192362734}}
{"text":"In this paper, we propose {\\fullname} ({\\name}), a method that adopts the neural point representation as well as the neural volume rendering process and discards the predefined connectivity and hard correspondence imposed by mesh-based approaches.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.0621369874,"dev-research":0.3798133537,"prompt-eng":0.3785515662,"data-quality":0.1462093662,"ml-security":0.1378438121}}
{"text":"Specifically, the neural points are strategically constrained around the surface of the target expression via a high-resolution UV displacement map, achieving increased modeling capacity and more accurate control.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.0333558294,"dev-research":0.4076897304,"prompt-eng":0.4056350218,"data-quality":0.0847041959,"ml-security":0.1650009536}}
{"text":"We introduce three technical innovations to improve the rendering and training efficiency: a patch-wise depth-guided (shading point) sampling strategy, a lightweight radiance decoding process, and a Grid-Error-Patch (GEP) ray sampling strategy during training.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.1615799371,"dev-research":0.3691310141,"prompt-eng":0.4230696439,"data-quality":0.1198387822,"ml-security":0.1088711024}}
{"text":"By design, our {\\name} is better equipped to handle topologically changing regions and thin structures while also ensuring accurate expression control when animating avatars.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.0893494938,"dev-research":0.4334528011,"prompt-eng":0.4585711606,"data-quality":0.1927171519,"ml-security":0.1533279036}}
{"text":"Experiments conducted on three subjects from the Multiface dataset demonstrate the effectiveness of our designs, outperforming previous state-of-the-art methods, especially in handling challenging facial regions.","meta":{"url":"http://arxiv.org/abs/2307.05000v1"},"cats":{"new-dataset":0.1508748394,"dev-research":0.3701337623,"prompt-eng":0.3927207771,"data-quality":0.0870240476,"ml-security":0.1547625776}}
{"text":"We consider the problem of Imitation Learning (IL) by actively querying noisy expert for feedback.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.0931372847,"dev-research":0.4031158428,"prompt-eng":0.5283554961,"data-quality":0.2302801916,"ml-security":0.1317998009}}
{"text":"While imitation learning has been empirically successful, much of prior work assumes access to noiseless expert feedback which is not practical in many applications.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.0572448095,"dev-research":0.3946475393,"prompt-eng":0.4689924245,"data-quality":0.1743696799,"ml-security":0.1526252002}}
{"text":"In fact, when one only has access to noisy expert feedback, algorithms that rely on purely offline data (non-interactive IL) can be shown to need a prohibitively large number of samples to be successful.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.1307162061,"dev-research":0.385259356,"prompt-eng":0.4534550575,"data-quality":0.2052749665,"ml-security":0.2709007141}}
{"text":"In contrast, in this work, we provide an interactive algorithm for IL that uses selective sampling to actively query the noisy expert for feedback.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.1544714026,"dev-research":0.4189011875,"prompt-eng":0.5435552888,"data-quality":0.2577186086,"ml-security":0.1369902779}}
{"text":"Our contributions are twofold:","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.13106244,"dev-research":0.4462897975,"prompt-eng":0.3963384325,"data-quality":0.1007704137,"ml-security":0.1010980384}}
{"text":"First, we provide a new selective sampling algorithm that works with general function classes and multiple actions, and obtains the best-known bounds for the regret and the number of queries.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.1442012287,"dev-research":0.3698516973,"prompt-eng":0.4326947201,"data-quality":0.0961324353,"ml-security":0.2051456884}}
{"text":"Next, we extend this analysis to the problem of IL with noisy expert feedback and provide a new IL algorithm that makes limited queries.   ","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.131966954,"dev-research":0.4265459311,"prompt-eng":0.4596594777,"data-quality":0.2620718597,"ml-security":0.2267406679}}
{"text":"Our algorithm for selective sampling leverages function approximation, and relies on an online regression oracle w.r.t.~the given model class to predict actions, and to decide whether to query the expert for its label.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.156648463,"dev-research":0.3853509711,"prompt-eng":0.4969898954,"data-quality":0.1592974939,"ml-security":0.2064572527}}
{"text":"On the theoretical side, the regret bound of our algorithm is upper bounded by the regret of the online regression oracle, while the query complexity additionally depends on the eluder dimension of the model class.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.0624041542,"dev-research":0.3829534036,"prompt-eng":0.3701076319,"data-quality":0.061057066,"ml-security":0.2035620873}}
{"text":"We complement this with a lower bound that demonstrates that our results are tight.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.0824314435,"dev-research":0.4369792024,"prompt-eng":0.4057904552,"data-quality":0.1999114238,"ml-security":0.183825205}}
{"text":"We extend our selective sampling algorithm for IL with general function approximation and provide bounds on both the regret and the number of queries made to the noisy expert.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.1187348021,"dev-research":0.3671924906,"prompt-eng":0.4393106768,"data-quality":0.1699121451,"ml-security":0.2049183978}}
{"text":"A key novelty here is that our regret and query complexity bounds only depend on the number of times the optimal policy (and not the noisy expert, or the learner) go to states that have a small margin.","meta":{"url":"http://arxiv.org/abs/2307.04998v1"},"cats":{"new-dataset":0.0526561736,"dev-research":0.4163652709,"prompt-eng":0.3817480791,"data-quality":0.0885634706,"ml-security":0.2340310019}}
{"text":"Personalized recommendations have a growing importance in direct marketing, which motivates research to enhance customer experiences by knowledge graph (KG) applications.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.1719267849,"dev-research":0.4434833239,"prompt-eng":0.4511925398,"data-quality":0.0938503691,"ml-security":0.149037846}}
{"text":"For example, in financial services, companies may benefit from providing relevant financial articles to their customers to cultivate relationships, foster client engagement and promote informed financial decisions.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.0793790251,"dev-research":0.4591850239,"prompt-eng":0.4171590672,"data-quality":0.1303726919,"ml-security":0.1270306614}}
{"text":"While several approaches center on KG-based recommender systems for improved content, in this study we focus on interpretable KG-based recommender systems for decision making.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.1130967543,"dev-research":0.4339313469,"prompt-eng":0.4504627104,"data-quality":0.1521188372,"ml-security":0.1201197539}}
{"text":"To this end, we present two knowledge graph-based approaches for personalized article recommendations for a set of customers of a large multinational financial services company.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.2751989766,"dev-research":0.4314362635,"prompt-eng":0.4622617527,"data-quality":0.116740488,"ml-security":0.0769802239}}
{"text":"The first approach employs Reinforcement Learning and the second approach uses the XGBoost algorithm for recommending articles to the customers.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.090464277,"dev-research":0.4394629252,"prompt-eng":0.4478793292,"data-quality":0.0999907691,"ml-security":0.0905953437}}
{"text":"Both approaches make use of a KG generated from both structured (tabular data) and unstructured data (a large body of text data).Using the Reinforcement Learning-based recommender system we could leverage the graph traversal path leading to the recommendation as a way to generate interpretations (Path Directed Reasoning (PDR)).","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.2221193275,"dev-research":0.4495140793,"prompt-eng":0.4762368061,"data-quality":0.0997306725,"ml-security":0.1177938394}}
{"text":"In the XGBoost-based approach, one can also provide explainable results using post-hoc methods such as SHAP (SHapley Additive exPlanations) and ELI5 (Explain Like I am Five).Importantly, our approach offers explainable results, promoting better decision-making.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.0767178414,"dev-research":0.498382698,"prompt-eng":0.4669694207,"data-quality":0.217728769,"ml-security":0.1640901144}}
{"text":"This study underscores the potential of combining advanced machine learning techniques with KG-driven insights to bolster experience in customer relationship management.","meta":{"url":"http://arxiv.org/abs/2307.04996v1"},"cats":{"new-dataset":0.1175988327,"dev-research":0.3976498559,"prompt-eng":0.4504605597,"data-quality":0.117934251,"ml-security":0.1859375506}}
{"text":"Deep neural networks (DNNs) are of critical use in different domains.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.0735001124,"dev-research":0.4083314046,"prompt-eng":0.4146460139,"data-quality":0.1346368037,"ml-security":0.2841698581}}
{"text":"To accelerate DNN computation, tensor compilers are proposed to generate efficient code on different domain-specific accelerators.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.1163419277,"dev-research":0.4070948846,"prompt-eng":0.4145583325,"data-quality":0.093160001,"ml-security":0.1408433718}}
{"text":"Existing tensor compilers mainly focus on optimizing computation efficiency.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.0545185092,"dev-research":0.4186629079,"prompt-eng":0.3891005405,"data-quality":0.0640001497,"ml-security":0.1164799828}}
{"text":"However, memory access is becoming a key performance bottleneck because the computational performance of accelerators is increasing much faster than memory performance.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.0571586188,"dev-research":0.3986137504,"prompt-eng":0.3748495286,"data-quality":0.0634948861,"ml-security":0.1686445755}}
{"text":"The lack of direct description of memory access and data dependence in current tensor compilers' intermediate representation (IR) brings significant challenges to generate memory-efficient code.   ","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.0999192239,"dev-research":0.4292490878,"prompt-eng":0.4215431123,"data-quality":0.1085516754,"ml-security":0.1761503353}}
{"text":"In this paper, we propose IntelliGen, a tensor compiler that can generate high-performance code for memory-intensive operators by considering both computation and data movement optimizations.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.1412701776,"dev-research":0.4178012718,"prompt-eng":0.4129791779,"data-quality":0.0741776527,"ml-security":0.1435693483}}
{"text":"IntelliGen represent a DNN program using GIR, which includes primitives indicating its computation, data movement, and parallel strategies.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.2932464059,"dev-research":0.4903530679,"prompt-eng":0.465958229,"data-quality":0.0949869453,"ml-security":0.0843173092}}
{"text":"This information will be further composed as an instruction-level dataflow graph to perform holistic optimizations by searching different memory access patterns and computation operations, and generating memory-efficient code on different hardware.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.181708434,"dev-research":0.4744591694,"prompt-eng":0.4179956092,"data-quality":0.0511580705,"ml-security":0.1002025544}}
{"text":"We evaluate IntelliGen on NVIDIA GPU, AMD GPU, and Cambricon MLU, showing speedup up to 1.97x, 2.93x, and 16.91x(1.28x, 1.23x, and 2.31x on average), respectively, compared to current most performant frameworks.","meta":{"url":"http://arxiv.org/abs/2307.04995v1"},"cats":{"new-dataset":0.1957499639,"dev-research":0.4269794711,"prompt-eng":0.4036562466,"data-quality":0.0786128974,"ml-security":0.0788663111}}
{"text":"Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.1211617741,"dev-research":0.3578485419,"prompt-eng":0.4677289673,"data-quality":0.1038990398,"ml-security":0.2068121836}}
{"text":"In practice, DBMs are often constrained, i.e., via the \\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.0394372378,"dev-research":0.3577668569,"prompt-eng":0.4229697064,"data-quality":0.076935678,"ml-security":0.1718460634}}
{"text":"In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference?","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.0575823842,"dev-research":0.3688170611,"prompt-eng":0.4189179048,"data-quality":0.0837128519,"ml-security":0.1211660067}}
{"text":"In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \\emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.0831912351,"dev-research":0.359902934,"prompt-eng":0.4279875622,"data-quality":0.1286721457,"ml-security":0.2511119651}}
{"text":"To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular choice of activation results in a fixed-point iteration that gives a variational mean-field solution.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.104672204,"dev-research":0.3923877303,"prompt-eng":0.4427440316,"data-quality":0.0767731933,"ml-security":0.1348845443}}
{"text":"While this approach is still largely conceptual, it is the first architecture that allows for efficient approximate inference in fully-general weight structures for DBMs.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.0463079377,"dev-research":0.3814084783,"prompt-eng":0.4537389539,"data-quality":0.1202923471,"ml-security":0.1444256304}}
{"text":"We apply this approach to simple deep convolutional Boltzmann architectures and demonstrate that it allows for tasks such as the joint completion and classification of images, within a single deep probabilistic setting, while avoiding the pitfalls of mean-field inference in traditional RBMs.","meta":{"url":"http://arxiv.org/abs/2307.04990v1"},"cats":{"new-dataset":0.226975241,"dev-research":0.3534430469,"prompt-eng":0.4842120289,"data-quality":0.1576157572,"ml-security":0.1106073655}}
{"text":"The practical utility of causality in decision-making is widely recognized, with causal discovery and inference being inherently intertwined.","meta":{"url":"http://arxiv.org/abs/2307.04988v1"},"cats":{"new-dataset":0.0565832896,"dev-research":0.489462862,"prompt-eng":0.4208679418,"data-quality":0.089817658,"ml-security":0.1827743249}}
{"text":"Nevertheless, a notable gap exists in the evaluation of causal discovery methods, where insufficient emphasis is placed on downstream inference.","meta":{"url":"http://arxiv.org/abs/2307.04988v1"},"cats":{"new-dataset":0.0485554104,"dev-research":0.4639395902,"prompt-eng":0.4136359017,"data-quality":0.1762241849,"ml-security":0.116898133}}
{"text":"To address this gap, we evaluate six established baseline causal discovery methods and a newly proposed method based on GFlowNets, on the downstream task of treatment effect estimation.","meta":{"url":"http://arxiv.org/abs/2307.04988v1"},"cats":{"new-dataset":0.1189595931,"dev-research":0.4264819467,"prompt-eng":0.433197395,"data-quality":0.1333941161,"ml-security":0.1333769143}}
{"text":"Through the implementation of a robust evaluation procedure, we offer valuable insights into the efficacy of these causal discovery methods for treatment effect estimation, considering both synthetic and real-world scenarios, as well as low-data scenarios.","meta":{"url":"http://arxiv.org/abs/2307.04988v1"},"cats":{"new-dataset":0.1245489564,"dev-research":0.4222294006,"prompt-eng":0.4463006806,"data-quality":0.2101647546,"ml-security":0.2493313477}}
{"text":"Furthermore, the results of our study demonstrate that GFlowNets possess the capability to effectively capture a wide range of useful and diverse ATE modes.","meta":{"url":"http://arxiv.org/abs/2307.04988v1"},"cats":{"new-dataset":0.0795210637,"dev-research":0.3588894161,"prompt-eng":0.4279323255,"data-quality":0.059088374,"ml-security":0.0933039453}}
{"text":"This study offers a new paradigm of individual-level modeling to address the grand challenge of incorporating human behavior in epidemic models.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.1556022048,"dev-research":0.4079097279,"prompt-eng":0.4938772157,"data-quality":0.0915084284,"ml-security":0.2964670837}}
{"text":"Using generative artificial intelligence in an agent-based epidemic model, each agent is empowered to make its own reasonings and decisions via connecting to a large language model such as ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.3518048585,"dev-research":0.4816277741,"prompt-eng":0.5379126289,"data-quality":0.0974425764,"ml-security":0.2115509422}}
{"text":"Through various simulation experiments, we present compelling evidence that generative agents mimic real-world behaviors such as quarantining when sick and self-isolation when cases rise.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.1104471978,"dev-research":0.4407992366,"prompt-eng":0.4943197297,"data-quality":0.0788005527,"ml-security":0.2817999064}}
{"text":"Collectively, the agents demonstrate patterns akin to multiple waves observed in recent pandemics followed by an endemic period.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.2897643722,"dev-research":0.4179919745,"prompt-eng":0.4307319349,"data-quality":0.0517963759,"ml-security":0.1435372991}}
{"text":"Moreover, the agents successfully flatten the epidemic curve.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.1583727361,"dev-research":0.4325710501,"prompt-eng":0.440153771,"data-quality":0.0883543368,"ml-security":0.2680536298}}
{"text":"This study creates potential to improve dynamic system modeling by offering a way to represent human brain, reasoning, and decision making.","meta":{"url":"http://arxiv.org/abs/2307.04986v1"},"cats":{"new-dataset":0.1250540719,"dev-research":0.4698893687,"prompt-eng":0.4708298072,"data-quality":0.0556934252,"ml-security":0.1162672504}}
{"text":"Frontotemporal Dementia (FTD) diagnosis has been successfully progress using deep learning techniques.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.183595262,"dev-research":0.3749719348,"prompt-eng":0.4725491315,"data-quality":0.1887801181,"ml-security":0.1621243757}}
{"text":"However, current FTD identification methods suffer from two limitations.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.1149272816,"dev-research":0.3650853618,"prompt-eng":0.3805085318,"data-quality":0.1772413659,"ml-security":0.2054150276}}
{"text":"Firstly, they do not exploit the potential of multi-view functional magnetic resonance imaging (fMRI) for classifying FTD.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.0724899313,"dev-research":0.3552749758,"prompt-eng":0.3814965706,"data-quality":0.1286818766,"ml-security":0.0790985796}}
{"text":"Secondly, they do not consider the reliability of the multi-view FTD diagnosis.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.0792097704,"dev-research":0.3718714789,"prompt-eng":0.3724402227,"data-quality":0.2010002084,"ml-security":0.0897775718}}
{"text":"To address these limitations, we propose a reliable multi-view impartial decision network (MID-Net) for FTD diagnosis in fMRI.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.101565036,"dev-research":0.394256833,"prompt-eng":0.4333525243,"data-quality":0.1877437714,"ml-security":0.0832199012}}
{"text":"Our MID-Net provides confidence for each view and generates a reliable prediction without any conflict.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.128513104,"dev-research":0.4191804313,"prompt-eng":0.455737643,"data-quality":0.1805093648,"ml-security":0.1866927094}}
{"text":"To achieve this, we employ multiple expert models to extract evidence from the abundant neural network information contained in fMRI images.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.1648827816,"dev-research":0.3995857525,"prompt-eng":0.4939881863,"data-quality":0.1951253293,"ml-security":0.1092482728}}
{"text":"We then introduce the Dirichlet Distribution to characterize the expert class probability distribution from an evidence level.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.2053786319,"dev-research":0.4085371237,"prompt-eng":0.5085388944,"data-quality":0.2439830317,"ml-security":0.2097893713}}
{"text":"Additionally, a novel Impartial Decision Maker (IDer) is proposed to combine the different opinions inductively to arrive at an unbiased prediction without additional computation cost.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.0787078077,"dev-research":0.4603907697,"prompt-eng":0.4534845661,"data-quality":0.2026840283,"ml-security":0.1221102701}}
{"text":"Overall, our MID-Net dynamically integrates the decisions of different experts on FTD disease, especially when dealing with multi-view high-conflict cases.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.1243304498,"dev-research":0.4603425449,"prompt-eng":0.4539450172,"data-quality":0.0988840742,"ml-security":0.1715063392}}
{"text":"Extensive experiments on a high-quality FTD fMRI dataset demonstrate that our model outperforms previous methods and provides high uncertainty for hard-to-classify examples.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.1551912726,"dev-research":0.3606021378,"prompt-eng":0.4716186265,"data-quality":0.2931293809,"ml-security":0.1374454157}}
{"text":"We believe that our approach represents a significant step toward the deployment of reliable FTD decision-making under multi-expert conditions.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.0740481542,"dev-research":0.4622971544,"prompt-eng":0.4609471785,"data-quality":0.1404866998,"ml-security":0.131370332}}
{"text":"We will release the codes for reproduction after acceptance.","meta":{"url":"http://arxiv.org/abs/2307.04981v1"},"cats":{"new-dataset":0.3752676062,"dev-research":0.4984287771,"prompt-eng":0.4946175888,"data-quality":0.1495079566,"ml-security":0.1210629636}}
{"text":"Cross-Modal learning tasks have picked up pace in recent times.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.0952913951,"dev-research":0.4044475973,"prompt-eng":0.479221119,"data-quality":0.0841137406,"ml-security":0.096148439}}
{"text":"With plethora of applications in diverse areas, generation of novel content using multiple modalities of data has remained a challenging problem.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.3787887598,"dev-research":0.4343034348,"prompt-eng":0.4560410473,"data-quality":0.1828782661,"ml-security":0.0818067085}}
{"text":"To address the same, various generative modelling techniques have been proposed for specific tasks.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.0896913485,"dev-research":0.4239131848,"prompt-eng":0.5317575281,"data-quality":0.0940993356,"ml-security":0.0494161103}}
{"text":"Novel and creative image generation is one important aspect for industrial application which could help as an arm for novel content generation.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.1729944029,"dev-research":0.5084145706,"prompt-eng":0.4422070994,"data-quality":0.1391547881,"ml-security":0.0437468755}}
{"text":"Techniques proposed previously used Generative Adversarial Network(GAN), autoregressive models and Variational Autoencoders (VAE) for accomplishing similar tasks.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.1626555574,"dev-research":0.3627573188,"prompt-eng":0.4822440141,"data-quality":0.1092756688,"ml-security":0.1177294376}}
{"text":"These approaches are limited in their capability to produce images guided by either text instructions or rough sketch images decreasing the overall performance of image generator.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.1281021795,"dev-research":0.463590565,"prompt-eng":0.4322468902,"data-quality":0.097299094,"ml-security":0.0486804653}}
{"text":"We used state of the art diffusion models to generate creative art by primarily leveraging text with additional support of rough sketches.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.0870913517,"dev-research":0.4634261576,"prompt-eng":0.4539934168,"data-quality":0.1264365129,"ml-security":0.061936273}}
{"text":"Diffusion starts with a pattern of random dots and slowly converts that pattern into a design image using the guiding information fed into the model.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.0714268272,"dev-research":0.4335757232,"prompt-eng":0.4497046154,"data-quality":0.0857898236,"ml-security":0.1514029577}}
{"text":"Diffusion models have recently outperformed other generative models in image generation tasks using cross modal data as guiding information.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.145130321,"dev-research":0.3950657031,"prompt-eng":0.5203327694,"data-quality":0.1293441946,"ml-security":0.07255855}}
{"text":"The initial experiments for this task of novel image generation demonstrated promising qualitative results.","meta":{"url":"http://arxiv.org/abs/2307.04978v1"},"cats":{"new-dataset":0.208787978,"dev-research":0.4312728584,"prompt-eng":0.4568610179,"data-quality":0.1122574995,"ml-security":0.058887408}}
{"text":"Maneuvering target tracking will be an important service of future wireless networks to assist innovative applications such as intelligent transportation.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0595698381,"dev-research":0.3973444738,"prompt-eng":0.4395199157,"data-quality":0.0883370462,"ml-security":0.1721215959}}
{"text":"However, tracking maneuvering targets by cellular networks faces many challenges.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0668237512,"dev-research":0.3864929317,"prompt-eng":0.4078272055,"data-quality":0.0955507966,"ml-security":0.2454666453}}
{"text":"For example, the dense network and high-speed targets make the selection of the sensing nodes (SNs), e.g., base stations, and the associated power allocation very difficult, given the stringent latency requirement of sensing applications.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0438382763,"dev-research":0.3484372543,"prompt-eng":0.394354112,"data-quality":0.083657677,"ml-security":0.158133002}}
{"text":"Existing methods have demonstrated engaging tracking performance, but with very high computational complexity.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.1096741391,"dev-research":0.3920287985,"prompt-eng":0.4032778844,"data-quality":0.07101725,"ml-security":0.0901912853}}
{"text":"In this paper, we propose a model-driven deep learning approach for SN selection to meet the latency requirement.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.1105924672,"dev-research":0.3255613045,"prompt-eng":0.456141216,"data-quality":0.0969373043,"ml-security":0.2174882013}}
{"text":"To this end, we first propose an iterative SN selection method by jointly exploiting the majorization-minimization (MM) framework and the alternating direction method of multipliers (ADMM).","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0566949438,"dev-research":0.371483793,"prompt-eng":0.4020889071,"data-quality":0.1018151303,"ml-security":0.1459064256}}
{"text":"Then, we unfold the iterative algorithm as a deep neural network (DNN) and prove its convergence.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.1127811408,"dev-research":0.4054954895,"prompt-eng":0.3917878341,"data-quality":0.128547564,"ml-security":0.1567508787}}
{"text":"The proposed model-driven method has a low computational complexity, because the number of layers is less than the number of iterations required by the original algorithm, and each layer only involves simple matrix-vector additions/multiplications.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0310227956,"dev-research":0.3729658176,"prompt-eng":0.351484907,"data-quality":0.0623138831,"ml-security":0.154996217}}
{"text":"Finally, we propose an efficient power allocation method based on fixed point (FP) water filling (WF) and solve the joint SN selection and power allocation problem under the alternative optimization framework.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0437437283,"dev-research":0.3787412791,"prompt-eng":0.3654914357,"data-quality":0.1000572488,"ml-security":0.1816556299}}
{"text":"Simulation results show that the proposed method achieves better performance than the conventional optimization-based methods with much lower computational complexity.","meta":{"url":"http://arxiv.org/abs/2307.04977v1"},"cats":{"new-dataset":0.0277454087,"dev-research":0.3405372391,"prompt-eng":0.3118098413,"data-quality":0.0829992369,"ml-security":0.0678192238}}
{"text":"Recently, Segmenting Anything has taken an important step towards general artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0870552184,"dev-research":0.4257048292,"prompt-eng":0.4449341872,"data-quality":0.1270253341,"ml-security":0.1004524318}}
{"text":"At the same time, its reliability and fairness have also attracted great attention, especially in the field of health care.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0664473265,"dev-research":0.396820325,"prompt-eng":0.3870435261,"data-quality":0.1064654302,"ml-security":0.1375369416}}
{"text":"In this study, we propose multi-box prompts triggered uncertainty estimation for SAM cues to demonstrate the reliability of segmented lesions or tissues.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0755938581,"dev-research":0.3677723479,"prompt-eng":0.5134006166,"data-quality":0.2247208097,"ml-security":0.0957320461}}
{"text":"We estimate the distribution of SAM predictions via Monte Carlo with prior distribution parameters, which employs different prompts as formulation of test-time augmentation.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0719214437,"dev-research":0.3950612325,"prompt-eng":0.5577981515,"data-quality":0.110669635,"ml-security":0.1532293133}}
{"text":"Our experimental results found that multi-box prompts augmentation improve the SAM performance, and endowed each pixel with uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0466049882,"dev-research":0.4105645346,"prompt-eng":0.5376917041,"data-quality":0.1149679981,"ml-security":0.0897885472}}
{"text":"This provides the first paradigm for a reliable SAM.","meta":{"url":"http://arxiv.org/abs/2307.04973v1"},"cats":{"new-dataset":0.0533724832,"dev-research":0.4099327677,"prompt-eng":0.4581577128,"data-quality":0.096890701,"ml-security":0.1429700548}}
{"text":"Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.1361119307,"dev-research":0.4566547354,"prompt-eng":0.5532844888,"data-quality":0.1026566834,"ml-security":0.1364728606}}
{"text":"Its primary objective is to function as a human-centric (helpful, honest, and harmless) assistant.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.0990993495,"dev-research":0.4628813482,"prompt-eng":0.4572126158,"data-quality":0.1381240394,"ml-security":0.2023077506}}
{"text":"Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.090057015,"dev-research":0.4265135087,"prompt-eng":0.4587356184,"data-quality":0.0817473105,"ml-security":0.0718125979}}
{"text":"Current technical routes usually include \\textbf{reward models} to measure human preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize policy model outputs, and \\textbf{process supervision} to improve step-by-step reasoning capabilities.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.071734446,"dev-research":0.5155123228,"prompt-eng":0.5086630476,"data-quality":0.0804250149,"ml-security":0.1021236241}}
{"text":"However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.0953176006,"dev-research":0.4703979371,"prompt-eng":0.5425396362,"data-quality":0.1310520281,"ml-security":0.2436001621}}
{"text":"The stable training of RLHF has still been a puzzle.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.0926194549,"dev-research":0.3949922179,"prompt-eng":0.3876293589,"data-quality":0.1269746029,"ml-security":0.152482803}}
{"text":"In the first report, we dissect the framework of RLHF, re-evaluate the inner workings of PPO, and explore how the parts comprising PPO algorithms impact policy agent training.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.1102306118,"dev-research":0.4431940614,"prompt-eng":0.4666133516,"data-quality":0.0902104045,"ml-security":0.1945985019}}
{"text":"We identify policy constraints being the key factor for the effective implementation of the PPO algorithm.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.0577893332,"dev-research":0.4292848973,"prompt-eng":0.3915188015,"data-quality":0.0736837288,"ml-security":0.1304703115}}
{"text":"Therefore, we explore the PPO-max, an advanced version of PPO algorithm, to efficiently improve the training stability of the policy model.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.1165749658,"dev-research":0.3870143607,"prompt-eng":0.4346621199,"data-quality":0.1034091716,"ml-security":0.2559730595}}
{"text":"Based on our main results, we perform a comprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.1422365041,"dev-research":0.3809561853,"prompt-eng":0.4675003468,"data-quality":0.072944418,"ml-security":0.065427123}}
{"text":"The absence of open-source implementations has posed significant challenges to the investigation of LLMs alignment.","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.1260456695,"dev-research":0.4237535846,"prompt-eng":0.4943257552,"data-quality":0.153352496,"ml-security":0.0871709467}}
{"text":"Therefore, we are eager to release technical reports, reward models and PPO codes","meta":{"url":"http://arxiv.org/abs/2307.04964v1"},"cats":{"new-dataset":0.2424261348,"dev-research":0.5325165853,"prompt-eng":0.5009330945,"data-quality":0.0993036294,"ml-security":0.1381632075}}
{"text":"DL compiler's primary function is to translate DNN programs written in high-level DL frameworks such as PyTorch and TensorFlow into portable executables.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1567854036,"dev-research":0.488999972,"prompt-eng":0.4403179642,"data-quality":0.0980878402,"ml-security":0.1704261007}}
{"text":"These executables can then be flexibly executed by the deployed host programs.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.0473179179,"dev-research":0.5055941926,"prompt-eng":0.4466470341,"data-quality":0.1013819693,"ml-security":0.2226331998}}
{"text":"However, existing DL compilers rely on a tracing mechanism, which involves feeding a runtime input to a neural network program and tracing the program execution paths to generate the computational graph necessary for compilation.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.0917418857,"dev-research":0.5420234874,"prompt-eng":0.4449832179,"data-quality":0.1037513548,"ml-security":0.1785828272}}
{"text":"Unfortunately, this mechanism falls short when dealing with modern dynamic neural networks (DyNNs) that possess varying computational graphs depending on the inputs.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.0647150962,"dev-research":0.383364363,"prompt-eng":0.3889395377,"data-quality":0.1326424822,"ml-security":0.236539753}}
{"text":"Consequently, conventional DL compilers struggle to accurately compile DyNNs into executable code.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.0845932523,"dev-research":0.4959537441,"prompt-eng":0.4087520942,"data-quality":0.2106205555,"ml-security":0.1830432786}}
{"text":"To address this limitation, we propose \\tool, a general approach that enables any existing DL compiler to successfully compile DyNNs.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1698255682,"dev-research":0.4884443295,"prompt-eng":0.4219368183,"data-quality":0.1226958555,"ml-security":0.1581650966}}
{"text":"\\tool tackles the dynamic nature of DyNNs by introducing a compilation mechanism that redistributes the control and data flow of the original DNN programs during the compilation process.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.2108513355,"dev-research":0.5043313294,"prompt-eng":0.4659278863,"data-quality":0.1352585404,"ml-security":0.1736347161}}
{"text":"Specifically, \\tool develops program analysis and program transformation techniques to convert a dynamic neural network into multiple sub-neural networks.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1673674314,"dev-research":0.4995200263,"prompt-eng":0.4631494032,"data-quality":0.0856996735,"ml-security":0.1380103947}}
{"text":"Each sub-neural network is devoid of conditional statements and is compiled independently.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.0813094481,"dev-research":0.4069596917,"prompt-eng":0.3808846776,"data-quality":0.1563785956,"ml-security":0.153981743}}
{"text":"Furthermore, \\tool synthesizes a host module that models the control flow of the DyNNs and facilitates the invocation of the sub-neural networks.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1291945422,"dev-research":0.476189729,"prompt-eng":0.4822933567,"data-quality":0.0995988576,"ml-security":0.1571921622}}
{"text":"Our evaluation demonstrates the effectiveness of \\tool, achieving a 100\\% success rate in compiling all dynamic neural networks.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1282881093,"dev-research":0.4431027214,"prompt-eng":0.5012757896,"data-quality":0.1813922757,"ml-security":0.1975907926}}
{"text":"Moreover, the compiled executables generated by \\tool exhibit significantly improved performance, running between $1.12\\times$ and $20.21\\times$ faster than the original DyNNs executed on general-purpose DL frameworks.","meta":{"url":"http://arxiv.org/abs/2307.04963v1"},"cats":{"new-dataset":0.1082980496,"dev-research":0.4972384505,"prompt-eng":0.3913185007,"data-quality":0.0848594377,"ml-security":0.1384794649}}
{"text":"Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.0414865372,"dev-research":0.4378442492,"prompt-eng":0.4233428887,"data-quality":0.0658242086,"ml-security":0.1440658332}}
{"text":"When the environment is naturally represented as a graph, how to guide exploration best remains an open question.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.1601941518,"dev-research":0.4626384004,"prompt-eng":0.4106559353,"data-quality":0.0849486371,"ml-security":0.0919754855}}
{"text":"In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.276876031,"dev-research":0.4228866246,"prompt-eng":0.4036204891,"data-quality":0.1166079546,"ml-security":0.1342880232}}
{"text":"The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by the visited nodes in the environment.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.0471144868,"dev-research":0.4385194144,"prompt-eng":0.3950030292,"data-quality":0.0618307933,"ml-security":0.089165845}}
{"text":"We use these proposed features as rewards for graph neural-network-based reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.1305032988,"dev-research":0.4023147623,"prompt-eng":0.4084805485,"data-quality":0.1181482801,"ml-security":0.1564425259}}
{"text":"On multiple classes of synthetically generated graphs, we find that trained agents generalize to larger environments and to longer exploratory walks than are seen during training.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.2331399045,"dev-research":0.4598964159,"prompt-eng":0.4371168462,"data-quality":0.1330427662,"ml-security":0.2058081516}}
{"text":"Our method computes more efficiently than the greedy evaluation of the relevant topological properties.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.0764367354,"dev-research":0.3954218899,"prompt-eng":0.3582323638,"data-quality":0.0892651727,"ml-security":0.0986325719}}
{"text":"The proposed intrinsic motivations bear particular relevance for recommender systems.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.0380918143,"dev-research":0.4990560913,"prompt-eng":0.4368530059,"data-quality":0.1211557626,"ml-security":0.1742720468}}
{"text":"We demonstrate that curiosity-based recommendations are more predictive of human behavior than PageRank centrality for several real-world graph datasets, including MovieLens, Amazon Books, and Wikispeedia.","meta":{"url":"http://arxiv.org/abs/2307.04962v1"},"cats":{"new-dataset":0.3290144658,"dev-research":0.4517687555,"prompt-eng":0.4778366452,"data-quality":0.1106962559,"ml-security":0.1436583765}}
{"text":"Large reflection and diffraction losses in the Terahertz (THz) band give rise to degraded coverage abilities in non-line-of-sight (NLoS) areas.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.0541926361,"dev-research":0.4003283404,"prompt-eng":0.3984352646,"data-quality":0.0906373835,"ml-security":0.1574462869}}
{"text":"To overcome this, a non-intelligent reflecting surface (NIRS) can be used, which is essentially a rough surface made by metal materials.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.0479786263,"dev-research":0.3842135663,"prompt-eng":0.4031797886,"data-quality":0.087084431,"ml-security":0.0747482004}}
{"text":"NIRS is not only able to enhance received power in large NLoS areas through rich reflections and scattering, but also costless and super-easy to fabricate and implement.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.0461603128,"dev-research":0.3735087999,"prompt-eng":0.408159578,"data-quality":0.0862456383,"ml-security":0.0776038634}}
{"text":"In this article, we first thoroughly compare NIRS with the lively discussed intelligent reflecting surface (IRS) and point out the unique advantages of NIRS over IRS.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.0647354329,"dev-research":0.4204364514,"prompt-eng":0.4087279141,"data-quality":0.0768778234,"ml-security":0.0695501434}}
{"text":"Furthermore, experimental results are elaborated to show the effectiveness of NIRS in improving coverage.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.0875949267,"dev-research":0.3987881969,"prompt-eng":0.4160678454,"data-quality":0.1255349296,"ml-security":0.168585166}}
{"text":"Last but not least, open problems and future directions are highlighted to inspire future research efforts on NIRS.","meta":{"url":"http://arxiv.org/abs/2307.04961v1"},"cats":{"new-dataset":0.1028748149,"dev-research":0.4543547058,"prompt-eng":0.3948528081,"data-quality":0.0979009629,"ml-security":0.1193388808}}
{"text":"Reference immutability is a type based technique for taming mutation that has long been studied in the context of object-oriented languages, like Java.","meta":{"url":"http://arxiv.org/abs/2307.04960v1"},"cats":{"new-dataset":0.1027288895,"dev-research":0.4886893494,"prompt-eng":0.4258676416,"data-quality":0.2116740198,"ml-security":0.2718779972}}
{"text":"Recently, though, languages like Scala have blurred the lines between functional programming languages and object oriented programming languages.","meta":{"url":"http://arxiv.org/abs/2307.04960v1"},"cats":{"new-dataset":0.0952828452,"dev-research":0.4920020807,"prompt-eng":0.3967316962,"data-quality":0.1139366205,"ml-security":0.1475128711}}
{"text":"We explore how reference immutability interacts with features commonly found in these hybrid languages, in particular with higher-order functions -- polymorphism -- and subtyping.","meta":{"url":"http://arxiv.org/abs/2307.04960v1"},"cats":{"new-dataset":0.0797410138,"dev-research":0.4454571056,"prompt-eng":0.4114762629,"data-quality":0.1324591164,"ml-security":0.1304657995}}
{"text":"We construct a calculus System F-sub-M which encodes a reference immutability system as a simple extension of F-sub and prove that it satisfies the standard soundness and immutability safety properties.","meta":{"url":"http://arxiv.org/abs/2307.04960v1"},"cats":{"new-dataset":0.0858163872,"dev-research":0.4197253913,"prompt-eng":0.4015974347,"data-quality":0.1790607694,"ml-security":0.1912008658}}
{"text":"In reinforcement learning, the objective is almost always defined as a \\emph{cumulative} function over the rewards along the process.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0352829599,"dev-research":0.432080929,"prompt-eng":0.4196883214,"data-quality":0.0915343709,"ml-security":0.1738281436}}
{"text":"However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0573013136,"dev-research":0.4156382808,"prompt-eng":0.3972784889,"data-quality":0.1044116829,"ml-security":0.2927858841}}
{"text":"In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0527682986,"dev-research":0.4071685204,"prompt-eng":0.3741771821,"data-quality":0.1281244763,"ml-security":0.1304632197}}
{"text":"Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0873407134,"dev-research":0.4022150783,"prompt-eng":0.4182001746,"data-quality":0.0417328403,"ml-security":0.1946446628}}
{"text":"To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0429584308,"dev-research":0.4158021216,"prompt-eng":0.3744624144,"data-quality":0.0744742619,"ml-security":0.1262938338}}
{"text":"Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision process under which the globally optimal convergence of the generalized Bellman updates can be guaranteed.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0411355087,"dev-research":0.397040236,"prompt-eng":0.3982777308,"data-quality":0.0681098391,"ml-security":0.1877881469}}
{"text":"We demonstrate the idea experimentally with the bottleneck objective, i.e., the objectives determined by the minimum reward along the process, on classical optimal control and reinforcement learning tasks, as well as on two network routing problems on maximizing the flow rates.","meta":{"url":"http://arxiv.org/abs/2307.04957v1"},"cats":{"new-dataset":0.0499113058,"dev-research":0.3879687601,"prompt-eng":0.400650157,"data-quality":0.0756083176,"ml-security":0.1919078013}}
{"text":"Visual anomaly detection is essential and commonly used for many tasks in the field of computer vision.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.0798369421,"dev-research":0.4256498352,"prompt-eng":0.3909096779,"data-quality":0.269909586,"ml-security":0.1795552807}}
{"text":"Recent anomaly detection datasets mainly focus on industrial automated inspection, medical image analysis and video surveillance.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.3458885047,"dev-research":0.4017103675,"prompt-eng":0.4237517363,"data-quality":0.2555465233,"ml-security":0.3014822033}}
{"text":"In order to broaden the application and research of anomaly detection in unmanned supermarkets and smart manufacturing, we introduce the supermarket goods anomaly detection (GoodsAD) dataset.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.4067800952,"dev-research":0.423965655,"prompt-eng":0.4386501867,"data-quality":0.2652011594,"ml-security":0.3418915414}}
{"text":"It contains 6124 high-resolution images of 484 different appearance goods divided into 6 categories.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.584196328,"dev-research":0.4220986467,"prompt-eng":0.4215611355,"data-quality":0.1379443985,"ml-security":0.0455351084}}
{"text":"Each category contains several common different types of anomalies such as deformation, surface damage and opened.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.1585218707,"dev-research":0.4353828809,"prompt-eng":0.4332967096,"data-quality":0.2428391767,"ml-security":0.2146689721}}
{"text":"Anomalies contain both texture changes and structural changes.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.1110863076,"dev-research":0.4260537999,"prompt-eng":0.3949051737,"data-quality":0.2459450384,"ml-security":0.1220035375}}
{"text":"It follows the unsupervised setting and only normal (defect-free) images are used for training.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.2229681686,"dev-research":0.3889194099,"prompt-eng":0.4384361323,"data-quality":0.1564121055,"ml-security":0.1535213828}}
{"text":"Pixel-precise ground truth regions are provided for all anomalies.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.1596535072,"dev-research":0.4092877568,"prompt-eng":0.4341013764,"data-quality":0.2500152061,"ml-security":0.1539458079}}
{"text":"Moreover, we also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.1363289792,"dev-research":0.4055112789,"prompt-eng":0.4454438429,"data-quality":0.2427217717,"ml-security":0.3531444721}}
{"text":"This initial benchmark indicates that some methods which perform well on the industrial anomaly detection dataset (e.g., MVTec AD), show poor performance on our dataset.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.2964506501,"dev-research":0.4249268334,"prompt-eng":0.4178433584,"data-quality":0.3122689639,"ml-security":0.3324581755}}
{"text":"This is a comprehensive, multi-object dataset for supermarket goods anomaly detection that focuses on real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.04956v1"},"cats":{"new-dataset":0.5843374463,"dev-research":0.3903617127,"prompt-eng":0.4398973636,"data-quality":0.239872132,"ml-security":0.2907668112}}
{"text":"Deep learning (DL) methods have outperformed parametric models such as historical average, ARIMA and variants in predicting traffic variables into short and near-short future, that are critical for traffic management.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.1378119639,"dev-research":0.3753997436,"prompt-eng":0.4385740313,"data-quality":0.1283998683,"ml-security":0.3141381138}}
{"text":"Specifically, recurrent neural network (RNN) and its variants (e.g. long short-term memory) are designed to retain long-term temporal correlations and therefore are suitable for modeling sequences.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.1289532558,"dev-research":0.3678723041,"prompt-eng":0.4267838119,"data-quality":0.063663587,"ml-security":0.1628219066}}
{"text":"However, multi-regime models assume the traffic system to evolve through multiple states (say, free-flow, congestion in traffic) with distinct characteristics, and hence, separate models are trained to characterize the traffic dynamics within each regime.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.0721401077,"dev-research":0.3638769966,"prompt-eng":0.4267588455,"data-quality":0.0563895599,"ml-security":0.1545862549}}
{"text":"For instance, Markov-switching models with a hidden Markov model (HMM) for regime identification is capable of capturing complex dynamic patterns and non-stationarity.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.1241461093,"dev-research":0.357591561,"prompt-eng":0.4417175732,"data-quality":0.0724667131,"ml-security":0.1459101124}}
{"text":"Interestingly, both HMM and LSTM can be used for modeling an observation sequence from a set of latent or, hidden state variables.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.2467058696,"dev-research":0.355690308,"prompt-eng":0.530753133,"data-quality":0.1019418395,"ml-security":0.1406433489}}
{"text":"In LSTM, the latent variable is computed in a deterministic manner from the current observation and the previous latent variable, while, in HMM, the set of latent variables is a Markov chain.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.1234446308,"dev-research":0.3792717673,"prompt-eng":0.4991259411,"data-quality":0.1034072056,"ml-security":0.1097432529}}
{"text":"Inspired by research in natural language processing, a hybrid hidden Markov-LSTM model that is capable of learning complementary features in traffic data is proposed for traffic flow prediction.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.2514845127,"dev-research":0.3650782236,"prompt-eng":0.4785334968,"data-quality":0.1278297879,"ml-security":0.253562073}}
{"text":"Results indicate significant performance gains in using hybrid architecture compared to conventional methods such as Markov switching ARIMA and LSTM.","meta":{"url":"http://arxiv.org/abs/2307.04954v1"},"cats":{"new-dataset":0.1051772985,"dev-research":0.342483549,"prompt-eng":0.4549110999,"data-quality":0.0716640531,"ml-security":0.0792927118}}
{"text":"The significance of multi-scale features has been gradually recognized by the edge detection community.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.1098440215,"dev-research":0.3830754481,"prompt-eng":0.382006522,"data-quality":0.1401343024,"ml-security":0.0892285714}}
{"text":"However, the fusion of multi-scale features increases the complexity of the model, which is not friendly to practical application.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.0269287551,"dev-research":0.3794551479,"prompt-eng":0.3285946008,"data-quality":0.0615165644,"ml-security":0.1214033162}}
{"text":"In this work, we propose a Compact Twice Fusion Network (CTFN) to fully integrate multi-scale features while maintaining the compactness of the model.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.0931258179,"dev-research":0.3433081497,"prompt-eng":0.4139445385,"data-quality":0.0898772133,"ml-security":0.1119747685}}
{"text":"CTFN includes two lightweight multi-scale feature fusion modules: a Semantic Enhancement Module (SEM) that can utilize the semantic information contained in coarse-scale features to guide the learning of fine-scale features, and a Pseudo Pixel-level Weighting (PPW) module that aggregate the complementary merits of multi-scale features by assigning weights to all features.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.1126688831,"dev-research":0.4159751228,"prompt-eng":0.4963216876,"data-quality":0.1751633903,"ml-security":0.121147744}}
{"text":"Notwithstanding all this, the interference of texture noise makes the correct classification of some pixels still a challenge.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.0930629821,"dev-research":0.3702483568,"prompt-eng":0.4261289064,"data-quality":0.5146580201,"ml-security":0.1511664464}}
{"text":"For these hard samples, we propose a novel loss function, coined Dynamic Focal Loss, which reshapes the standard cross-entropy loss and dynamically adjusts the weights to correct the distribution of hard samples.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.1282675472,"dev-research":0.3306977778,"prompt-eng":0.4448933,"data-quality":0.1892013099,"ml-security":0.1804492493}}
{"text":"We evaluate our method on three datasets, i.e., BSDS500, NYUDv2, and BIPEDv2.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.4581836393,"dev-research":0.3607021338,"prompt-eng":0.4382483601,"data-quality":0.1175426983,"ml-security":0.0835038454}}
{"text":"Compared with state-of-the-art methods, CTFN achieves competitive accuracy with less parameters and computational cost.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.1634756219,"dev-research":0.366250003,"prompt-eng":0.415507858,"data-quality":0.1514500468,"ml-security":0.1209007104}}
{"text":"Apart from the backbone, CTFN requires only 0.1M additional parameters, which reduces its computation cost to just 60% of other state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.079422295,"dev-research":0.3697384132,"prompt-eng":0.3748220045,"data-quality":0.0649598272,"ml-security":0.1732776037}}
{"text":"The codes are available at https://github.com/Li-yachuan/CTFN-pytorch-master.","meta":{"url":"http://arxiv.org/abs/2307.04952v1"},"cats":{"new-dataset":0.4226909706,"dev-research":0.4433289931,"prompt-eng":0.4630626858,"data-quality":0.1355549447,"ml-security":0.1108290354}}
{"text":"Inverse problems generally require a regularizer or prior for a good solution.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0564702517,"dev-research":0.3856224965,"prompt-eng":0.4480155749,"data-quality":0.209587697,"ml-security":0.1920499861}}
{"text":"A recent trend is to train a convolutional net to denoise images, and use this net as a prior when solving the inverse problem.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.1430695912,"dev-research":0.3789544772,"prompt-eng":0.4371872229,"data-quality":0.2070544399,"ml-security":0.1837607009}}
{"text":"Several proposals depend on a singular value decomposition of the forward operator, and several others backpropagate through the denoising net at runtime.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0629206458,"dev-research":0.3712290215,"prompt-eng":0.4026365115,"data-quality":0.1545713369,"ml-security":0.2687891344}}
{"text":"Here we propose a simpler approach that combines the traditional gradient-based minimization of reconstruction error with denoising.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.1089690941,"dev-research":0.3321374438,"prompt-eng":0.3866871869,"data-quality":0.2442804245,"ml-security":0.1195325784}}
{"text":"Noise is also added at each step, so the iterative dynamics resembles a Langevin or diffusion process.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0465653527,"dev-research":0.4122519876,"prompt-eng":0.4258852187,"data-quality":0.1424912673,"ml-security":0.0905205698}}
{"text":"Both the level of added noise and the size of the denoising step decay exponentially with time.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0609655862,"dev-research":0.3929679244,"prompt-eng":0.3573870647,"data-quality":0.1110199058,"ml-security":0.128210179}}
{"text":"We apply our method to the problem of tomographic reconstruction from electron micrographs acquired at multiple tilt angles.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.1018139685,"dev-research":0.362743715,"prompt-eng":0.3790757099,"data-quality":0.1012843235,"ml-security":0.0641758196}}
{"text":"With empirical studies using simulated tilt views, we find parameter settings for our method that produce good results.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.1422740727,"dev-research":0.3857113866,"prompt-eng":0.4268464508,"data-quality":0.0733937697,"ml-security":0.0657720876}}
{"text":"We show that high accuracy can be achieved with as few as 50 denoising steps.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.1075059788,"dev-research":0.3461998071,"prompt-eng":0.4027688642,"data-quality":0.1911775072,"ml-security":0.100290324}}
{"text":"We also compare with DDRM and DPS, more complex diffusion methods of the kinds mentioned above.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0597586301,"dev-research":0.3828726205,"prompt-eng":0.3908912262,"data-quality":0.0582223513,"ml-security":0.1059191533}}
{"text":"These methods are less accurate (as measured by MSE and SSIM) for our tomography problem, even after the generation hyperparameters are optimized.","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.0399043019,"dev-research":0.3838530338,"prompt-eng":0.4101275278,"data-quality":0.1284291677,"ml-security":0.0702489454}}
{"text":"Finally we extend our method to reconstruction of arbitrary-sized images and show results on 128 $\\times$ 1568 pixel images","meta":{"url":"http://arxiv.org/abs/2307.04946v1"},"cats":{"new-dataset":0.3862636452,"dev-research":0.3624301973,"prompt-eng":0.4055630472,"data-quality":0.1279233599,"ml-security":0.095606043}}
{"text":"We investigate whether Large Language Models (e.g., GPT-4) can synthesize correct router configurations with reduced manual effort.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.0929965383,"dev-research":0.4566260129,"prompt-eng":0.4906459043,"data-quality":0.1011368705,"ml-security":0.1233171076}}
{"text":"We find GPT-4 works very badly by itself, producing promising draft configurations but with egregious errors in topology, syntax, and semantics.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.1092848931,"dev-research":0.4585324074,"prompt-eng":0.4389442961,"data-quality":0.1340666437,"ml-security":0.0873577441}}
{"text":"Our strategy, that we call Verified Prompt Programming, is to combine GPT-4 with verifiers, and use localized feedback from the verifier to automatically correct errors.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.1274795632,"dev-research":0.4863535944,"prompt-eng":0.5890619359,"data-quality":0.388670909,"ml-security":0.12259549}}
{"text":"Verification requires a specification and actionable localized feedback to be effective.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.0799905128,"dev-research":0.4763165238,"prompt-eng":0.5276583283,"data-quality":0.2959413472,"ml-security":0.0909887065}}
{"text":"We show results for two use cases: translating from Cisco to Juniper configurations on a single router, and implementing no-transit policy on multiple routers.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.0633931612,"dev-research":0.413133377,"prompt-eng":0.4182271353,"data-quality":0.1152088423,"ml-security":0.1126713341}}
{"text":"While human input is still required, if we define the leverage as the number of automated prompts to the number of human prompts, our experiments show a leverage of 10X for Juniper translation, and 6X for implementing no-transit policy, ending with verified configurations.","meta":{"url":"http://arxiv.org/abs/2307.04945v1"},"cats":{"new-dataset":0.0719991827,"dev-research":0.4659783077,"prompt-eng":0.5826490527,"data-quality":0.1613171903,"ml-security":0.1583766732}}
{"text":"While prior domain generalization (DG) benchmarks consider train-test dataset heterogeneity, we evaluate Federated DG which introduces federated learning (FL) specific challenges.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.1981641355,"dev-research":0.3772405076,"prompt-eng":0.489200355,"data-quality":0.1764690934,"ml-security":0.2654894405}}
{"text":"Additionally, we explore domain-based heterogeneity in clients' local datasets - a realistic Federated DG scenario.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.2892462939,"dev-research":0.4107629683,"prompt-eng":0.458767442,"data-quality":0.1816488159,"ml-security":0.2144896745}}
{"text":"Prior Federated DG evaluations are limited in terms of the number or heterogeneity of clients and dataset diversity.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.1203770524,"dev-research":0.3875437362,"prompt-eng":0.4311047127,"data-quality":0.0981629195,"ml-security":0.119828036}}
{"text":"To address this gap, we propose an Federated DG benchmark methodology that enables control of the number and heterogeneity of clients and provides metrics for dataset difficulty.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.3075583812,"dev-research":0.4057853062,"prompt-eng":0.4557787575,"data-quality":0.1405136253,"ml-security":0.1421729438}}
{"text":"We then apply our methodology to evaluate 13 Federated DG methods, which include centralized DG methods adapted to the FL context, FL methods that handle client heterogeneity, and methods designed specifically for Federated DG.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.1038911439,"dev-research":0.4390807606,"prompt-eng":0.4472398139,"data-quality":0.0963279962,"ml-security":0.1121149766}}
{"text":"Our results suggest that despite some progress, there remain significant performance gaps in Federated DG particularly when evaluating with a large number of clients, high client heterogeneity, or more realistic datasets.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.1782513958,"dev-research":0.3945994289,"prompt-eng":0.4433316352,"data-quality":0.1094376331,"ml-security":0.1022684325}}
{"text":"Please check our extendable benchmark code here: https://github.com/inouye-lab/FedDG_Benchmark.","meta":{"url":"http://arxiv.org/abs/2307.04942v1"},"cats":{"new-dataset":0.3169431137,"dev-research":0.3720672772,"prompt-eng":0.4281806997,"data-quality":0.1130562951,"ml-security":0.0561705069}}
{"text":"As the core of artificial intelligence applications, the research of convolution has become a hot topic in high performance computing.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.0967353004,"dev-research":0.3714240868,"prompt-eng":0.41894142,"data-quality":0.0869306178,"ml-security":0.1419695123}}
{"text":"With the rapid development of the emerging SW26010 processor in artificial intelligence, there is an urgent need for high-performance convolution algorithms on the processor.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.1613924399,"dev-research":0.3732199022,"prompt-eng":0.4161088848,"data-quality":0.0761436303,"ml-security":0.1149043821}}
{"text":"However, the current support of convolution on SW26010 is still rudimentary.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.0987060622,"dev-research":0.3823424294,"prompt-eng":0.4211963547,"data-quality":0.1716169513,"ml-security":0.1108172868}}
{"text":"The only studies provide sufficient runtime peak performance but lack the adaptability to various convolution scenes.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.073253635,"dev-research":0.3173649768,"prompt-eng":0.3618436172,"data-quality":0.0858502321,"ml-security":0.0749739613}}
{"text":"To perfect convolution algorithms on SW26010, we propose a multi-grained matrix-multiplication-mapping convolution algorithm called MG3MConv, which targets the architectural features of SW26010. MG3MConv supports diversified mapping schemes of convolution tasks based on the concept of the thread block proposed in this paper.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.1206160115,"dev-research":0.3589406425,"prompt-eng":0.4023268434,"data-quality":0.1033314566,"ml-security":0.0848328438}}
{"text":"All the architecture-oriented optimization methods are elaborately designed from four levels to fully exploit the hardware efficiency of SW26010.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.0511014041,"dev-research":0.4323453387,"prompt-eng":0.3981561581,"data-quality":0.0589035778,"ml-security":0.1486069068}}
{"text":"The experiments show that the hardware efficiency of MG3MConv can reach 84.78% in max, which is 1.75 times compared with that of cuDNN based on NVIDIA K80m GPU.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.1522714375,"dev-research":0.3695570244,"prompt-eng":0.3803383987,"data-quality":0.080872124,"ml-security":0.0867135219}}
{"text":"Moreover, MG3MConv can overperform cuDNN in most convolution scenes.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.1583414796,"dev-research":0.3625976834,"prompt-eng":0.4364821798,"data-quality":0.1747030363,"ml-security":0.1234056143}}
{"text":"We also use six representative CNNs as real-world cases, and the hardware efficiency of MG3MConv reaches up to 67.04% on the VGG network model, which is 1.37 times and 1.96 times that of cuDNN and swDNN, respectively.","meta":{"url":"http://arxiv.org/abs/2307.04941v1"},"cats":{"new-dataset":0.1478349304,"dev-research":0.3606133101,"prompt-eng":0.4098215335,"data-quality":0.1024012675,"ml-security":0.1185737972}}
{"text":"We introduce PIGEON, a multi-task end-to-end system for planet-scale image geolocalization that achieves state-of-the-art performance on both external benchmarks and in human evaluation.","meta":{"url":"http://arxiv.org/abs/2307.05845v1"},"cats":{"new-dataset":0.2754060439,"dev-research":0.3787022986,"prompt-eng":0.4343544932,"data-quality":0.1261624383,"ml-security":0.0607684277}}
{"text":"Our work incorporates semantic geocell creation with label smoothing, conducts pretraining of a vision transformer on images with geographic information, and refines location predictions with ProtoNets across a candidate set of geocells.","meta":{"url":"http://arxiv.org/abs/2307.05845v1"},"cats":{"new-dataset":0.310402063,"dev-research":0.4009688729,"prompt-eng":0.4718675898,"data-quality":0.2681939376,"ml-security":0.0595472668}}
{"text":"The contributions of PIGEON are three-fold: first, we design a semantic geocells creation and splitting algorithm based on open-source data which can be adapted to any geospatial dataset.","meta":{"url":"http://arxiv.org/abs/2307.05845v1"},"cats":{"new-dataset":0.4874498202,"dev-research":0.4019289937,"prompt-eng":0.4010442791,"data-quality":0.1645061855,"ml-security":0.114641402}}
{"text":"Second, we show the effectiveness of intra-geocell refinement and the applicability of unsupervised clustering and ProtNets to the task.","meta":{"url":"http://arxiv.org/abs/2307.05845v1"},"cats":{"new-dataset":0.1267911596,"dev-research":0.4057548627,"prompt-eng":0.4315387846,"data-quality":0.2153363907,"ml-security":0.0710678236}}
{"text":"Finally, we make our pre-trained CLIP transformer model, StreetCLIP, publicly available for use in adjacent domains with applications to fighting climate change and urban and rural scene understanding.","meta":{"url":"http://arxiv.org/abs/2307.05845v1"},"cats":{"new-dataset":0.3371617151,"dev-research":0.388188172,"prompt-eng":0.5092737736,"data-quality":0.1117179873,"ml-security":0.1560546973}}
{"text":"The Butterfly Effect, a concept originating from chaos theory, underscores how small changes can have significant and unpredictable impacts on complex systems.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.0703630172,"dev-research":0.4297786426,"prompt-eng":0.3931756835,"data-quality":0.1349082229,"ml-security":0.2407714629}}
{"text":"In the context of AI fairness and bias, the Butterfly Effect can stem from a variety of sources, such as small biases or skewed data inputs during algorithm development, saddle points in training, or distribution shifts in data between training and testing phases.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.0534054006,"dev-research":0.413410635,"prompt-eng":0.4071290734,"data-quality":0.2220456883,"ml-security":0.3532103061}}
{"text":"These seemingly minor alterations can lead to unexpected and substantial unfair outcomes, disproportionately affecting underrepresented individuals or groups and perpetuating pre-existing inequalities.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.0339050726,"dev-research":0.4607084441,"prompt-eng":0.3841274591,"data-quality":0.2322670397,"ml-security":0.2077087878}}
{"text":"Moreover, the Butterfly Effect can amplify inherent biases within data or algorithms, exacerbate feedback loops, and create vulnerabilities for adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.0615320695,"dev-research":0.4283297013,"prompt-eng":0.4236218135,"data-quality":0.2627981311,"ml-security":0.7661129096}}
{"text":"Given the intricate nature of AI systems and their societal implications, it is crucial to thoroughly examine any changes to algorithms or input data for potential unintended consequences.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.1134216479,"dev-research":0.466037993,"prompt-eng":0.4154809051,"data-quality":0.1643232097,"ml-security":0.3989738401}}
{"text":"In this paper, we envision both algorithmic and empirical strategies to detect, quantify, and mitigate the Butterfly Effect in AI systems, emphasizing the importance of addressing these challenges to promote fairness and ensure responsible AI development.","meta":{"url":"http://arxiv.org/abs/2307.05842v1"},"cats":{"new-dataset":0.090484929,"dev-research":0.4546351272,"prompt-eng":0.4480508384,"data-quality":0.2470093312,"ml-security":0.5004411012}}
{"text":"Simplicial complexes have recently been in the limelight of higher-order network analysis, where a minority of simplices play crucial roles in structures and functions due to network heterogeneity.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.0776283643,"dev-research":0.3986139917,"prompt-eng":0.3404515283,"data-quality":0.0914210631,"ml-security":0.1304434088}}
{"text":"We find a significant inconsistency between identifying influential nodes and simplices.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.0891319584,"dev-research":0.4302533357,"prompt-eng":0.390234589,"data-quality":0.2412131267,"ml-security":0.1405568496}}
{"text":"Therefore, it remains elusive how to characterize simplices' influence and identify influential simplices, despite the relative maturity of research on influential nodes (0-simplices) identification.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.1292843685,"dev-research":0.4169611661,"prompt-eng":0.3654911643,"data-quality":0.1398153447,"ml-security":0.1039362714}}
{"text":"Meanwhile, graph neural networks (GNNs) are potent tools that can exploit network topology and node features simultaneously, but they struggle to tackle higher-order tasks.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.0838872103,"dev-research":0.3856059559,"prompt-eng":0.3729413787,"data-quality":0.1444986716,"ml-security":0.2118753651}}
{"text":"In this paper, we propose a higher-order graph learning model, named influential simplices mining neural network (ISMnet), to identify vital h-simplices in simplicial complexes.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.1934053964,"dev-research":0.3870643785,"prompt-eng":0.384886556,"data-quality":0.1319678865,"ml-security":0.1091015416}}
{"text":"It can tackle higher-order tasks by leveraging novel higher-order presentations: hierarchical bipartite graphs and higher-order hierarchical (HoH) Laplacians, where targeted simplices are grouped into a hub set and can interact with other simplices.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.1040210052,"dev-research":0.4079901303,"prompt-eng":0.4005365563,"data-quality":0.0416120105,"ml-security":0.056658902}}
{"text":"Furthermore, ISMnet employs learnable graph convolutional operators in each HoH Laplacian domain to capture interactions among simplices, and it can identify influential simplices of arbitrary order by changing the hub set.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.178988829,"dev-research":0.4010313475,"prompt-eng":0.4384328695,"data-quality":0.113634551,"ml-security":0.1220957768}}
{"text":"Empirical results demonstrate that ISMnet significantly outperforms existing methods in ranking 0-simplices (nodes) and 2-simplices.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.1535478341,"dev-research":0.4091396599,"prompt-eng":0.4368452147,"data-quality":0.1557414911,"ml-security":0.1008564233}}
{"text":"In general, this novel framework excels in identifying influential simplices and promises to serve as a potent tool in higher-order network analysis.","meta":{"url":"http://arxiv.org/abs/2307.05841v1"},"cats":{"new-dataset":0.1006114306,"dev-research":0.4317689797,"prompt-eng":0.3777769552,"data-quality":0.0991446427,"ml-security":0.1973233587}}
{"text":"Recently, DARPA launched the ShELL program, which aims to explore how experience sharing can benefit distributed lifelong learning agents in adapting to new challenges.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.1813405255,"dev-research":0.5085403514,"prompt-eng":0.4697303562,"data-quality":0.0359213197,"ml-security":0.2050119933}}
{"text":"In this paper, we address this issue by conducting both theoretical and empirical research on distributed multi-task reinforcement learning (RL), where a group of $N$ agents collaboratively solves $M$ tasks without prior knowledge of their identities.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.1159340724,"dev-research":0.4129304721,"prompt-eng":0.4597261718,"data-quality":0.090136578,"ml-security":0.2021017416}}
{"text":"We approach the problem by formulating it as linearly parameterized contextual Markov decision processes (MDPs), where each task is represented by a context that specifies the transition dynamics and rewards.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.0685516812,"dev-research":0.4028201069,"prompt-eng":0.4567666847,"data-quality":0.0711626019,"ml-security":0.1218067217}}
{"text":"To tackle this problem, we propose an algorithm called DistMT-LSVI.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.26317896,"dev-research":0.4044323237,"prompt-eng":0.4131833045,"data-quality":0.1275411692,"ml-security":0.1027185379}}
{"text":"First, the agents identify the tasks, and then they exchange information through a central server to derive $\\epsilon$-optimal policies for the tasks.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.0824217212,"dev-research":0.4452606968,"prompt-eng":0.4454883253,"data-quality":0.0839530151,"ml-security":0.2086349368}}
{"text":"Our research demonstrates that to achieve $\\epsilon$-optimal policies for all $M$ tasks, a single agent using DistMT-LSVI needs to run a total number of episodes that is at most $\\tilde{\\mathcal{O}}({d^3H^6(\\epsilon^{-2}+c_{\\rm sep}^{-2})}\\cdot M/N)$, where $c_{\\rm sep}>0$ is a constant representing task separability, $H$ is the horizon of each episode, and $d$ is the feature dimension of the dynamics and rewards.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.0797365575,"dev-research":0.3928254323,"prompt-eng":0.3916631742,"data-quality":0.0546461493,"ml-security":0.1580581922}}
{"text":"Notably, DistMT-LSVI improves the sample complexity of non-distributed settings by a factor of $1/N$, as each agent independently learns $\\epsilon$-optimal policies for all $M$ tasks using $\\tilde{\\mathcal{O}}(d^3H^6M\\epsilon^{-2})$ episodes.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.0812672301,"dev-research":0.3975569817,"prompt-eng":0.410566399,"data-quality":0.0641313172,"ml-security":0.169346257}}
{"text":"Additionally, we provide numerical experiments conducted on OpenAI Gym Atari environments that validate our theoretical findings.","meta":{"url":"http://arxiv.org/abs/2307.05834v1"},"cats":{"new-dataset":0.154599201,"dev-research":0.4180057886,"prompt-eng":0.452354656,"data-quality":0.1030319535,"ml-security":0.195504449}}
{"text":"UAV-based intelligent data acquisition for 3D reconstruction and monitoring of infrastructure has been experiencing an increasing surge of interest due to the recent advancements in image processing and deep learning-based techniques.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.3264389923,"dev-research":0.3640381476,"prompt-eng":0.4089970057,"data-quality":0.0849337727,"ml-security":0.1735030497}}
{"text":"View planning is an essential part of this task that dictates the information capture strategy and heavily impacts the quality of the 3D model generated from the captured data.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.1636491545,"dev-research":0.4126458256,"prompt-eng":0.4152115738,"data-quality":0.0793710855,"ml-security":0.0811476987}}
{"text":"Recent methods have used prior knowledge or partial reconstruction of the target to accomplish view planning for active reconstruction; the former approach poses a challenge for complex or newly identified targets while the latter is computationally expensive.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.096853623,"dev-research":0.3619280848,"prompt-eng":0.4033206845,"data-quality":0.0658847047,"ml-security":0.0717377422}}
{"text":"In this work, we present Bag-of-Views (BoV), a fully appearance-based model used to assign utility to the captured views for both offline dataset refinement and online next-best-view (NBV) planning applications targeting the task of 3D reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.3441697437,"dev-research":0.3889164573,"prompt-eng":0.4072897245,"data-quality":0.0540829469,"ml-security":0.0683570965}}
{"text":"With this contribution, we also developed the View Planning Toolbox (VPT), a lightweight package for training and testing machine learning-based view planning frameworks, custom view dataset generation of arbitrary 3D scenes, and 3D reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.4192559245,"dev-research":0.3774984387,"prompt-eng":0.435006803,"data-quality":0.0609957895,"ml-security":0.1045738699}}
{"text":"Through experiments which pair a BoV-based reinforcement learning model with VPT, we demonstrate the efficacy of our model in reducing the number of required views for high-quality reconstructions in dataset refinement and NBV planning.","meta":{"url":"http://arxiv.org/abs/2307.05832v1"},"cats":{"new-dataset":0.2009275349,"dev-research":0.3857253554,"prompt-eng":0.4624390104,"data-quality":0.0803897583,"ml-security":0.0774163519}}
{"text":"Neural networks are overparametrized and easily overfit the datasets they train on.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.1353918316,"dev-research":0.4030382909,"prompt-eng":0.4374445208,"data-quality":0.2223710586,"ml-security":0.4774959277}}
{"text":"In the extreme case, it is shown that they can memorize a training set with fully randomized labels.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.1955357707,"dev-research":0.4002411275,"prompt-eng":0.5126519231,"data-quality":0.3816270986,"ml-security":0.2471755588}}
{"text":"We propose using the curvature of loss function around the training sample as a measure of its memorization, averaged over all training epochs.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.1508305796,"dev-research":0.3678219672,"prompt-eng":0.4668676916,"data-quality":0.2505303777,"ml-security":0.227832943}}
{"text":"We use this to study the generalization versus memorization properties of different samples in popular image datasets.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.2655655147,"dev-research":0.3729128672,"prompt-eng":0.4746909335,"data-quality":0.2163897381,"ml-security":0.1334311672}}
{"text":"We visualize samples with the highest curvature of loss around them, and show that these visually correspond to long-tailed, mislabeled or conflicting samples.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.2539632478,"dev-research":0.3702963984,"prompt-eng":0.4366591054,"data-quality":0.3576448543,"ml-security":0.1313138309}}
{"text":"This analysis helps us find a, to the best of our knowledge, novel failure model on the CIFAR100 dataset, that of duplicated images with different labels.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.410698008,"dev-research":0.3689349563,"prompt-eng":0.4655194791,"data-quality":0.5319933702,"ml-security":0.1419716011}}
{"text":"We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields high AUROC values for identifying the mislabeled samples.","meta":{"url":"http://arxiv.org/abs/2307.05831v1"},"cats":{"new-dataset":0.3121104409,"dev-research":0.374077113,"prompt-eng":0.5052446728,"data-quality":0.7008092758,"ml-security":0.2616443813}}
{"text":"I present \"SnakeSynth,\" a web-based lightweight audio synthesizer that combines audio generated by a deep generative model and real-time continuous two-dimensional (2D) input to create and control variable-length generative sounds through 2D interaction gestures.","meta":{"url":"http://arxiv.org/abs/2307.05830v1"},"cats":{"new-dataset":0.2254629477,"dev-research":0.4371108143,"prompt-eng":0.4701749458,"data-quality":0.070379382,"ml-security":0.083793479}}
{"text":"Interaction gestures are touch and mobile-compatible with analogies to strummed, bowed, and plucked musical instrument controls.","meta":{"url":"http://arxiv.org/abs/2307.05830v1"},"cats":{"new-dataset":0.124832644,"dev-research":0.4458776906,"prompt-eng":0.4614679504,"data-quality":0.0606634452,"ml-security":0.0659918468}}
{"text":"Point-and-click and drag-and-drop gestures directly control audio playback length and I show that sound length and intensity are modulated by interactions with a programmable 2D coordinate grid.","meta":{"url":"http://arxiv.org/abs/2307.05830v1"},"cats":{"new-dataset":0.1626080789,"dev-research":0.4171913991,"prompt-eng":0.4144413802,"data-quality":0.0622402281,"ml-security":0.0574891117}}
{"text":"Leveraging the speed and ubiquity of browser-based audio and hardware acceleration in Google's TensorFlow.js we generate time-varying high-fidelity sounds with real-time interactivity.","meta":{"url":"http://arxiv.org/abs/2307.05830v1"},"cats":{"new-dataset":0.1203570903,"dev-research":0.3888066073,"prompt-eng":0.4536799782,"data-quality":0.082506203,"ml-security":0.1115566942}}
{"text":"SnakeSynth adaptively reproduces and interpolates between sounds encountered during model training, notably without long training times, and I briefly discuss possible futures for deep generative models as an interactive paradigm for musical expression.","meta":{"url":"http://arxiv.org/abs/2307.05830v1"},"cats":{"new-dataset":0.1340614152,"dev-research":0.3936787488,"prompt-eng":0.4918909039,"data-quality":0.1483180446,"ml-security":0.0978677006}}
{"text":"We study the problem of distance-preserving graph compression for weighted paths and trees.","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.1538601858,"dev-research":0.4072774609,"prompt-eng":0.348507012,"data-quality":0.1690750855,"ml-security":0.1039495872}}
{"text":"The problem entails a weighted graph $G = (V, E)$ with non-negative weights, and a subset of edges $E^{\\prime} \\subset E$ which needs to be removed from G (with their endpoints merged as a supernode).","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.0475791204,"dev-research":0.3813627359,"prompt-eng":0.3379523296,"data-quality":0.138007915,"ml-security":0.1459413735}}
{"text":"The goal is to redistribute the weights of the deleted edges in a way that minimizes the error.","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.0345648567,"dev-research":0.4335496007,"prompt-eng":0.3569761121,"data-quality":0.3319256058,"ml-security":0.1529249507}}
{"text":"The error is defined as the sum of the absolute differences of the shortest path lengths between different pairs of nodes before and after contracting $E^{\\prime}$. Based on this error function, we propose optimal approaches for merging any subset of edges in a path and a single edge in a tree.","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.0526271096,"dev-research":0.4073500167,"prompt-eng":0.3093501275,"data-quality":0.1840233444,"ml-security":0.068436018}}
{"text":"Previous works on graph compression techniques aimed at preserving different graph properties (such as the chromatic number) or solely focused on identifying the optimal set of edges to contract.","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.1615190112,"dev-research":0.4175023898,"prompt-eng":0.3300601057,"data-quality":0.1856734382,"ml-security":0.1286336798}}
{"text":"However, our focus in this paper is on achieving optimal edge contraction (when the contracted edges are provided as input) specifically for weighted trees and paths.","meta":{"url":"http://arxiv.org/abs/2307.05829v1"},"cats":{"new-dataset":0.0481641589,"dev-research":0.4028779139,"prompt-eng":0.3345137089,"data-quality":0.1128311883,"ml-security":0.0721604357}}
{"text":"For a given function of user data, a querier must recover with at least a prescribed probability, the value of the function based on a user-provided query response.","meta":{"url":"http://arxiv.org/abs/2307.05828v1"},"cats":{"new-dataset":0.2324220769,"dev-research":0.3999245656,"prompt-eng":0.4629312295,"data-quality":0.1504921954,"ml-security":0.2741884651}}
{"text":"Subject to this requirement, the user forms the query response so as to minimize the likelihood of the querier guessing a list of prescribed size to which the data value belongs based on the query response.","meta":{"url":"http://arxiv.org/abs/2307.05828v1"},"cats":{"new-dataset":0.1699104984,"dev-research":0.4055285467,"prompt-eng":0.4823949006,"data-quality":0.1095638988,"ml-security":0.2175444504}}
{"text":"We obtain a general converse upper bound for the maximum list privacy which is shown to be tight for the special case of a binary-valued function through an explicit achievability scheme for the query response.","meta":{"url":"http://arxiv.org/abs/2307.05828v1"},"cats":{"new-dataset":0.1941317213,"dev-research":0.4031859367,"prompt-eng":0.3868831423,"data-quality":0.0960686192,"ml-security":0.4681563074}}
{"text":"Relation extraction (RE) is the task of extracting relations between entities in text.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.1842676864,"dev-research":0.4494210493,"prompt-eng":0.4600697801,"data-quality":0.1807229221,"ml-security":0.0659733973}}
{"text":"Most RE methods extract relations from free-form running text and leave out other rich data sources, such as tables.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.2998686672,"dev-research":0.4563624185,"prompt-eng":0.4582383803,"data-quality":0.1467479294,"ml-security":0.1188484304}}
{"text":"We explore RE from the perspective of applying neural methods on tabularly organized data.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.2098370423,"dev-research":0.4073214339,"prompt-eng":0.4123334273,"data-quality":0.1434134531,"ml-security":0.1228099818}}
{"text":"We introduce a new model consisting of Convolutional Neural Network (CNN) and Bidirectional-Long Short Term Memory (BiLSTM) network to encode entities and learn dependencies among them, respectively.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.274076147,"dev-research":0.3831084007,"prompt-eng":0.484432102,"data-quality":0.1059202773,"ml-security":0.1344269739}}
{"text":"We evaluate our model on a large and recent dataset and compare results with previous neural methods.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.3166179511,"dev-research":0.3933528541,"prompt-eng":0.5150637743,"data-quality":0.205251881,"ml-security":0.1458388593}}
{"text":"Experimental results show that our model consistently outperforms the previous model for the task of relation extraction on tabular data.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.2489165735,"dev-research":0.3931890934,"prompt-eng":0.4710325865,"data-quality":0.1847619488,"ml-security":0.0914997693}}
{"text":"We perform comprehensive error analyses and ablation study to show the contribution of various components of our model.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.1055341699,"dev-research":0.375430717,"prompt-eng":0.443505458,"data-quality":0.264266045,"ml-security":0.0433277477}}
{"text":"Finally, we discuss the usefulness and trade-offs of our approach, and provide suggestions for fostering further research.","meta":{"url":"http://arxiv.org/abs/2307.05827v1"},"cats":{"new-dataset":0.1210944107,"dev-research":0.5047424841,"prompt-eng":0.4218368285,"data-quality":0.0970504706,"ml-security":0.0672319029}}
{"text":"In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.1724910015,"dev-research":0.3682851237,"prompt-eng":0.4742000512,"data-quality":0.1675617215,"ml-security":0.0765705612}}
{"text":"Our model offers two key advantages: semantic-awareness and granularity-abundance.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.1529603894,"dev-research":0.437604039,"prompt-eng":0.4618577132,"data-quality":0.1447288059,"ml-security":0.081044966}}
{"text":"To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.381359751,"dev-research":0.4275985629,"prompt-eng":0.5098645338,"data-quality":0.2540543862,"ml-security":0.1092068622}}
{"text":"This allows our model to capture rich semantic information.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.1869252006,"dev-research":0.4915256552,"prompt-eng":0.5407213596,"data-quality":0.2269038159,"ml-security":0.1492905184}}
{"text":"For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.0962804199,"dev-research":0.3770209689,"prompt-eng":0.4748284889,"data-quality":0.1025555715,"ml-security":0.1784674155}}
{"text":"Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.3777474916,"dev-research":0.3818855544,"prompt-eng":0.4805779969,"data-quality":0.205802239,"ml-security":0.1179748938}}
{"text":"Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.2346562754,"dev-research":0.433412839,"prompt-eng":0.5097708277,"data-quality":0.1891930678,"ml-security":0.0878656687}}
{"text":"Furthermore, combining SA-1B training with other segmentation tasks, such as panoptic and part segmentation, leads to performance improvements.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.1051731598,"dev-research":0.3715555628,"prompt-eng":0.4381348539,"data-quality":0.1331611852,"ml-security":0.0719024733}}
{"text":"We will provide code and a demo for further exploration and evaluation.","meta":{"url":"http://arxiv.org/abs/2307.04767v1"},"cats":{"new-dataset":0.4180107232,"dev-research":0.5326354513,"prompt-eng":0.5338174267,"data-quality":0.1116896503,"ml-security":0.1000460024}}
{"text":"We propose a self-supervised method for learning representations based on spatial audio-visual correspondences in egocentric videos.","meta":{"url":"http://arxiv.org/abs/2307.04760v1"},"cats":{"new-dataset":0.2063700137,"dev-research":0.3807508063,"prompt-eng":0.4526394477,"data-quality":0.2329816709,"ml-security":0.0789002539}}
{"text":"In particular, our method leverages a masked auto-encoding framework to synthesize masked binaural audio through the synergy of audio and vision, thereby learning useful spatial relationships between the two modalities.","meta":{"url":"http://arxiv.org/abs/2307.04760v1"},"cats":{"new-dataset":0.1278194855,"dev-research":0.3989385416,"prompt-eng":0.452544496,"data-quality":0.1945004481,"ml-security":0.1508910183}}
{"text":"We use our pretrained features to tackle two downstream video tasks requiring spatial understanding in social scenarios: active speaker detection and spatial audio denoising.","meta":{"url":"http://arxiv.org/abs/2307.04760v1"},"cats":{"new-dataset":0.1582086625,"dev-research":0.3863722881,"prompt-eng":0.5018316965,"data-quality":0.1928912477,"ml-security":0.1050155715}}
{"text":"We show through extensive experiments that our features are generic enough to improve over multiple state-of-the-art baselines on two public challenging egocentric video datasets, EgoCom and EasyCom.","meta":{"url":"http://arxiv.org/abs/2307.04760v1"},"cats":{"new-dataset":0.3918585753,"dev-research":0.4159096244,"prompt-eng":0.4863976517,"data-quality":0.2295270689,"ml-security":0.1141197572}}
{"text":"Project: http://vision.cs.utexas.edu/projects/ego_av_corr.","meta":{"url":"http://arxiv.org/abs/2307.04760v1"},"cats":{"new-dataset":0.2612300466,"dev-research":0.4428941742,"prompt-eng":0.4446029868,"data-quality":0.1021580972,"ml-security":0.0782975089}}
{"text":"One of the fundamental steps toward understanding a complex system is identifying variation at the scale of the system's components that is most relevant to behavior on a macroscopic scale.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.0643623891,"dev-research":0.4162765347,"prompt-eng":0.4167251275,"data-quality":0.079100877,"ml-security":0.0876342433}}
{"text":"Mutual information is a natural means of linking variation across scales of a system due to its independence of the particular functional relationship between variables.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.0739434564,"dev-research":0.4239959839,"prompt-eng":0.4135803105,"data-quality":0.125037102,"ml-security":0.1567394781}}
{"text":"However, estimating mutual information given high-dimensional, continuous-valued data is notoriously difficult, and the desideratum -- to reveal important variation in a comprehensible manner -- is only readily achieved through exhaustive search.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.1453599883,"dev-research":0.3669363114,"prompt-eng":0.3943755952,"data-quality":0.1216480499,"ml-security":0.1485726137}}
{"text":"Here we propose a practical, efficient, and broadly applicable methodology to decompose the information contained in a set of measurements by lossily compressing each measurement with machine learning.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.1738861365,"dev-research":0.3707757989,"prompt-eng":0.4185616806,"data-quality":0.2367228075,"ml-security":0.2862641247}}
{"text":"Guided by the distributed information bottleneck as a learning objective, the information decomposition sorts variation in the measurements of the system state by relevance to specified macroscale behavior, revealing the most important subsets of measurements for different amounts of predictive information.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.1013632265,"dev-research":0.4205566702,"prompt-eng":0.4544966518,"data-quality":0.1284328445,"ml-security":0.2875018968}}
{"text":"Additional granularity is achieved by inspection of the learned compression schemes: the variation transmitted during compression is composed of distinctions among measurement values that are most relevant to the macroscale behavior.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.072344859,"dev-research":0.393746835,"prompt-eng":0.4398944865,"data-quality":0.163142185,"ml-security":0.1369329072}}
{"text":"We focus our analysis on two paradigmatic complex systems: a Boolean circuit and an amorphous material undergoing plastic deformation.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.0612222207,"dev-research":0.4032040659,"prompt-eng":0.4058898184,"data-quality":0.08360164,"ml-security":0.0937538484}}
{"text":"In both examples, specific bits of entropy are identified out of the high entropy of the system state as most related to macroscale behavior for insight about the connection between micro- and macro- in the complex system.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.0568026526,"dev-research":0.4237639544,"prompt-eng":0.4470651398,"data-quality":0.1093131377,"ml-security":0.1136844954}}
{"text":"The identification of meaningful variation in data, with the full generality brought by information theory, is made practical for the study of complex systems.","meta":{"url":"http://arxiv.org/abs/2307.04755v1"},"cats":{"new-dataset":0.150060057,"dev-research":0.4273760599,"prompt-eng":0.399819591,"data-quality":0.1541112451,"ml-security":0.1575855409}}
{"text":"We propose a system for rearranging objects in a scene to achieve a desired object-scene placing relationship, such as a book inserted in an open slot of a bookshelf.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.2812987471,"dev-research":0.4211684223,"prompt-eng":0.4314543267,"data-quality":0.0833380697,"ml-security":0.0628874147}}
{"text":"The pipeline generalizes to novel geometries, poses, and layouts of both scenes and objects, and is trained from demonstrations to operate directly on 3D point clouds.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.2003677242,"dev-research":0.3889163898,"prompt-eng":0.4478631594,"data-quality":0.0520400542,"ml-security":0.0784206715}}
{"text":"Our system overcomes challenges associated with the existence of many geometrically-similar rearrangement solutions for a given scene.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.1047969319,"dev-research":0.4038320519,"prompt-eng":0.3578799365,"data-quality":0.0826047965,"ml-security":0.0873085499}}
{"text":"By leveraging an iterative pose de-noising training procedure, we can fit multi-modal demonstration data and produce multi-modal outputs while remaining precise and accurate.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.1789171395,"dev-research":0.4087250908,"prompt-eng":0.4986896744,"data-quality":0.1326573075,"ml-security":0.1013526868}}
{"text":"We also show the advantages of conditioning on relevant local geometric features while ignoring irrelevant global structure that harms both generalization and precision.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.0568520378,"dev-research":0.4055161236,"prompt-eng":0.408746212,"data-quality":0.2008160715,"ml-security":0.1523708136}}
{"text":"We demonstrate our approach on three distinct rearrangement tasks that require handling multi-modality and generalization over object shape and pose in both simulation and the real world.","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.0798683433,"dev-research":0.3763095425,"prompt-eng":0.4175616209,"data-quality":0.0678278178,"ml-security":0.0846295303}}
{"text":"Project website, code, and videos: https://anthonysimeonov.github.io/rpdiff-multi-modal/","meta":{"url":"http://arxiv.org/abs/2307.04751v1"},"cats":{"new-dataset":0.2370052752,"dev-research":0.446804591,"prompt-eng":0.4544930965,"data-quality":0.1072649288,"ml-security":0.0470407612}}
{"text":"The field of text-conditioned image generation has made unparalleled progress with the recent advent of latent diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1768775507,"dev-research":0.391732067,"prompt-eng":0.5310191699,"data-quality":0.210461597,"ml-security":0.0799530594}}
{"text":"While remarkable, as the complexity of given text input increases, the state-of-the-art diffusion models may still fail in generating images which accurately convey the semantics of the given prompt.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1102547638,"dev-research":0.4411110451,"prompt-eng":0.5866757583,"data-quality":0.2344158145,"ml-security":0.1289061879}}
{"text":"Furthermore, it has been observed that such misalignments are often left undetected by pretrained multi-modal models such as CLIP.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.0377195466,"dev-research":0.3853728224,"prompt-eng":0.4919864395,"data-quality":0.2770069435,"ml-security":0.0746631806}}
{"text":"To address these problems, in this paper we explore a simple yet effective decompositional approach towards both evaluation and improvement of text-to-image alignment.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1477971915,"dev-research":0.4240258025,"prompt-eng":0.4576684425,"data-quality":0.285743176,"ml-security":0.0518665722}}
{"text":"In particular, we first introduce a Decompositional-Alignment-Score which given a complex prompt decomposes it into a set of disjoint assertions.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1362243554,"dev-research":0.457983136,"prompt-eng":0.5446076765,"data-quality":0.2799403313,"ml-security":0.1104985378}}
{"text":"The alignment of each assertion with generated images is then measured using a VQA model.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1345889129,"dev-research":0.4030264888,"prompt-eng":0.4671174968,"data-quality":0.2250759969,"ml-security":0.054777337}}
{"text":"Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.2854877934,"dev-research":0.4347418095,"prompt-eng":0.4891598505,"data-quality":0.3089954311,"ml-security":0.0493911344}}
{"text":"Experimental analysis reveals that the proposed alignment metric shows significantly higher correlation with human ratings as opposed to traditional CLIP, BLIP scores.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1872608396,"dev-research":0.3926694832,"prompt-eng":0.4692599616,"data-quality":0.2050889592,"ml-security":0.0578866993}}
{"text":"Furthermore, we also find that the assertion level alignment scores provide a useful feedback which can then be used in a simple iterative procedure to gradually increase the expression of different assertions in the final image outputs.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.1366731251,"dev-research":0.4262805531,"prompt-eng":0.5077624415,"data-quality":0.2918028259,"ml-security":0.0808997919}}
{"text":"Human user studies indicate that the proposed approach surpasses previous state-of-the-art by 8.7% in overall text-to-image alignment accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.2193304794,"dev-research":0.4125563595,"prompt-eng":0.4913802234,"data-quality":0.3108969062,"ml-security":0.0506730393}}
{"text":"Project page for our paper is available at https://1jsingh.github.io/divide-evaluate-and-refine","meta":{"url":"http://arxiv.org/abs/2307.04749v1"},"cats":{"new-dataset":0.0809500019,"dev-research":0.4254059195,"prompt-eng":0.4243695915,"data-quality":0.1029906032,"ml-security":0.0666822698}}
{"text":"We propose a novel approach to multi-robot collaboration that harnesses the power of pre-trained large language models (LLMs) for both high-level communication and low-level path planning.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.1542711355,"dev-research":0.4064476712,"prompt-eng":0.5642719056,"data-quality":0.0672412554,"ml-security":0.099878375}}
{"text":"Robots are equipped with LLMs to discuss and collectively reason task strategies.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.0946323928,"dev-research":0.497734855,"prompt-eng":0.5579030802,"data-quality":0.0781596896,"ml-security":0.0958746231}}
{"text":"They then generate sub-task plans and task space waypoint paths, which are used by a multi-arm motion planner to accelerate trajectory planning.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.1375213198,"dev-research":0.481236129,"prompt-eng":0.4226804524,"data-quality":0.0351879803,"ml-security":0.0494480225}}
{"text":"We also provide feedback from the environment, such as collision checking, and prompt the LLM agents to improve their plan and waypoints in-context.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.1717634932,"dev-research":0.49797877,"prompt-eng":0.5660940343,"data-quality":0.0948873641,"ml-security":0.1439610071}}
{"text":"For evaluation, we introduce RoCoBench, a 6-task benchmark covering a wide range of multi-robot collaboration scenarios, accompanied by a text-only dataset for agent representation and reasoning.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.4639397963,"dev-research":0.4380026958,"prompt-eng":0.5042980211,"data-quality":0.0783055971,"ml-security":0.0893214671}}
{"text":"We experimentally demonstrate the effectiveness of our approach -- it achieves high success rates across all tasks in RoCoBench and adapts to variations in task semantics.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.0986405271,"dev-research":0.4800544244,"prompt-eng":0.5309241224,"data-quality":0.2179340784,"ml-security":0.0866283008}}
{"text":"Our dialog setup offers high interpretability and flexibility -- in real world experiments, we show RoCo easily incorporates human-in-the-loop, where a user can communicate and collaborate with a robot agent to complete tasks together.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.2303957517,"dev-research":0.4743094692,"prompt-eng":0.5914473081,"data-quality":0.1076620947,"ml-security":0.0898846437}}
{"text":"See project website https://project-roco.github.io for videos and code.","meta":{"url":"http://arxiv.org/abs/2307.04738v1"},"cats":{"new-dataset":0.4877442612,"dev-research":0.4749593088,"prompt-eng":0.4476477725,"data-quality":0.085159509,"ml-security":0.085646132}}
{"text":"To develop a funding model for Open Access journal publication, it is necessary first to understand who benefits.","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.0888691547,"dev-research":0.4577278635,"prompt-eng":0.4088670738,"data-quality":0.0727044348,"ml-security":0.1577680472}}
{"text":"This is a difficult task, because, in Open Access, no credentials are needed to read a journal article, and, thus, those people who access journal articles through Open Access leave no self-identification.","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.1024741657,"dev-research":0.3810244978,"prompt-eng":0.4212204363,"data-quality":0.1260540879,"ml-security":0.2594028248}}
{"text":"We might call these readers \"ghost readers\".","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.1893313004,"dev-research":0.3918425441,"prompt-eng":0.4746998605,"data-quality":0.2188097151,"ml-security":0.1721817163}}
{"text":"In this paper, I propose a method to learn the reading habits of the ghost readers.","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.1506977403,"dev-research":0.3885640781,"prompt-eng":0.4897898183,"data-quality":0.1723856823,"ml-security":0.1163512381}}
{"text":"I explore this method using a database of downloads from the Open Access volumes of the Annual Reviews journals.","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.3414279606,"dev-research":0.4259583689,"prompt-eng":0.4854366235,"data-quality":0.1454679603,"ml-security":0.0599254814}}
{"text":"I find that the habits of the ghost readers are very similar to those of academic readers from known institutions.","meta":{"url":"http://arxiv.org/abs/2307.04731v1"},"cats":{"new-dataset":0.1673430374,"dev-research":0.3950309321,"prompt-eng":0.4586255442,"data-quality":0.1489765316,"ml-security":0.1353598853}}
{"text":"We introduce the problem of deceptive information retrieval (DIR), in which a user wishes to download a required file out of multiple independent files stored in a system of databases while \\emph{deceiving} the databases by making the databases' predictions on the user-required file index incorrect with high probability.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.2314729691,"dev-research":0.4498953664,"prompt-eng":0.463252054,"data-quality":0.30802161,"ml-security":0.5192769422}}
{"text":"Conceptually, DIR is an extension of private information retrieval (PIR).","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.1749053599,"dev-research":0.4468199046,"prompt-eng":0.4397623862,"data-quality":0.1249190984,"ml-security":0.162838138}}
{"text":"In PIR, a user downloads a required file without revealing its index to any of the databases.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.2075553742,"dev-research":0.4384014787,"prompt-eng":0.4113392172,"data-quality":0.108597437,"ml-security":0.2581718311}}
{"text":"The metric of deception is defined as the probability of error of databases' prediction on the user-required file, minus the corresponding probability of error in PIR.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.1744559468,"dev-research":0.4348308253,"prompt-eng":0.4501773089,"data-quality":0.3438264503,"ml-security":0.2554887138}}
{"text":"The problem is defined on time-sensitive data that keeps updating from time to time.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.3346177954,"dev-research":0.4304989602,"prompt-eng":0.4024511399,"data-quality":0.3197777484,"ml-security":0.2421422892}}
{"text":"In the proposed scheme, the user deceives the databases by sending \\emph{real} queries to download the required file at the time of the requirement and \\emph{dummy} queries at multiple distinct future time instances to manipulate the probabilities of sending each query for each file requirement, using which the databases' make the predictions on the user-required file index.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.1990595508,"dev-research":0.4448186482,"prompt-eng":0.4757880307,"data-quality":0.101347682,"ml-security":0.2647473319}}
{"text":"The proposed DIR scheme is based on a capacity achieving probabilistic PIR scheme, and achieves rates lower than the PIR capacity due to the additional downloads made to deceive the databases.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.2319206383,"dev-research":0.3951982209,"prompt-eng":0.4131943784,"data-quality":0.0922725431,"ml-security":0.2012207859}}
{"text":"When the required level of deception is zero, the proposed scheme achieves the PIR capacity.","meta":{"url":"http://arxiv.org/abs/2307.04727v1"},"cats":{"new-dataset":0.0471778216,"dev-research":0.3688474748,"prompt-eng":0.360565343,"data-quality":0.0801864782,"ml-security":0.2233355321}}
{"text":"Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for experience collection.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.0829366277,"dev-research":0.4205405219,"prompt-eng":0.4649919703,"data-quality":0.0812960454,"ml-security":0.1644117902}}
{"text":"In contrast to behavior cloning, which assumes the data is collected from expert demonstrations, offline RL can work with non-expert data and multimodal behavior policies.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.2530886489,"dev-research":0.4354290394,"prompt-eng":0.5109611172,"data-quality":0.0871292358,"ml-security":0.1504723914}}
{"text":"However, offline RL algorithms face challenges in handling distribution shifts and effectively representing policies due to the lack of online interaction during training.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.1132665872,"dev-research":0.3958076017,"prompt-eng":0.4490463455,"data-quality":0.0964569801,"ml-security":0.2401197205}}
{"text":"Prior work on offline RL uses conditional diffusion models to obtain expressive policies to represent multimodal behavior in the dataset.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.1827826446,"dev-research":0.3979538882,"prompt-eng":0.4988671102,"data-quality":0.082845569,"ml-security":0.10202383}}
{"text":"Nevertheless, they are not tailored toward alleviating the out-of-distribution state generalization.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.0302848456,"dev-research":0.37442501,"prompt-eng":0.3682460959,"data-quality":0.189904599,"ml-security":0.2170813206}}
{"text":"We introduce a novel method incorporating state reconstruction feature learning in the recent class of diffusion policies to address the out-of-distribution generalization problem.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.1100500592,"dev-research":0.3565405496,"prompt-eng":0.4739330348,"data-quality":0.1523936151,"ml-security":0.2810793141}}
{"text":"State reconstruction loss promotes more descriptive representation learning of states to alleviate the distribution shift incurred by the out-of-distribution states.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.0824044584,"dev-research":0.3688440848,"prompt-eng":0.4646689913,"data-quality":0.241875839,"ml-security":0.1574293219}}
{"text":"We design a 2D Multimodal Contextual Bandit environment to demonstrate and evaluate our proposed model.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.1659055062,"dev-research":0.4330949028,"prompt-eng":0.5046862225,"data-quality":0.1130696215,"ml-security":0.1447023463}}
{"text":"We assess the performance of our model not only in this new environment but also on several D4RL benchmark tasks, achieving state-of-the-art results.","meta":{"url":"http://arxiv.org/abs/2307.04726v1"},"cats":{"new-dataset":0.15784637,"dev-research":0.395100625,"prompt-eng":0.4928760872,"data-quality":0.0758324777,"ml-security":0.0572761431}}
{"text":"With the advance of text-to-image models (e.g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2161980997,"dev-research":0.3773293226,"prompt-eng":0.4861878678,"data-quality":0.101894099,"ml-security":0.128223999}}
{"text":"Subsequently, there is a great demand for image animation techniques to further combine generated static images with motion dynamics.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.1235418369,"dev-research":0.420585455,"prompt-eng":0.409537186,"data-quality":0.0617501146,"ml-security":0.0422447589}}
{"text":"In this report, we propose a practical framework to animate most of the existing personalized text-to-image models once and for all, saving efforts in model-specific tuning.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2147627648,"dev-research":0.3992802567,"prompt-eng":0.5303577083,"data-quality":0.1119264516,"ml-security":0.0766728257}}
{"text":"At the core of the proposed framework is to insert a newly initialized motion modeling module into the frozen text-to-image model and train it on video clips to distill reasonable motion priors.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2489944853,"dev-research":0.3926934575,"prompt-eng":0.4917234121,"data-quality":0.1400803327,"ml-security":0.0567550107}}
{"text":"Once trained, by simply injecting this motion modeling module, all personalized versions derived from the same base T2I readily become text-driven models that produce diverse and personalized animated images.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2252692732,"dev-research":0.4382495708,"prompt-eng":0.5407683566,"data-quality":0.1243290462,"ml-security":0.0834590968}}
{"text":"We conduct our evaluation on several public representative personalized text-to-image models across anime pictures and realistic photographs, and demonstrate that our proposed framework helps these models generate temporally smooth animation clips while preserving the domain and diversity of their outputs.","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2569020334,"dev-research":0.4022624725,"prompt-eng":0.5109842534,"data-quality":0.2144473126,"ml-security":0.0861215653}}
{"text":"Code and pre-trained weights will be publicly available at https://animatediff.github.io/ .","meta":{"url":"http://arxiv.org/abs/2307.04725v1"},"cats":{"new-dataset":0.2457139371,"dev-research":0.4181312475,"prompt-eng":0.4949306885,"data-quality":0.1017913771,"ml-security":0.146335926}}
{"text":"Meta-learning empowers learning systems with the ability to acquire knowledge from multiple tasks, enabling faster adaptation and generalization to new tasks.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.0820668683,"dev-research":0.416722255,"prompt-eng":0.4711844356,"data-quality":0.1022692574,"ml-security":0.1550139755}}
{"text":"This review provides a comprehensive technical overview of meta-learning, emphasizing its importance in real-world applications where data may be scarce or expensive to obtain.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.2032557646,"dev-research":0.3992253448,"prompt-eng":0.493106561,"data-quality":0.1688710967,"ml-security":0.1708048424}}
{"text":"The paper covers the state-of-the-art meta-learning approaches and explores the relationship between meta-learning and multi-task learning, transfer learning, domain adaptation and generalization, self-supervised learning, personalized federated learning, and continual learning.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.144347531,"dev-research":0.4068082669,"prompt-eng":0.473942159,"data-quality":0.1277755714,"ml-security":0.127201987}}
{"text":"By highlighting the synergies between these topics and the field of meta-learning, the paper demonstrates how advancements in one area can benefit the field as a whole, while avoiding unnecessary duplication of efforts.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.0550348649,"dev-research":0.4457854843,"prompt-eng":0.4394197153,"data-quality":0.1388208889,"ml-security":0.1500676751}}
{"text":"Additionally, the paper delves into advanced meta-learning topics such as learning from complex multi-modal task distributions, unsupervised meta-learning, learning to efficiently adapt to data distribution shifts, and continual meta-learning.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.1129751658,"dev-research":0.3713119229,"prompt-eng":0.463855902,"data-quality":0.0990516342,"ml-security":0.1443796108}}
{"text":"Lastly, the paper highlights open problems and challenges for future research in the field.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.145725353,"dev-research":0.4203396091,"prompt-eng":0.3696971515,"data-quality":0.1023052206,"ml-security":0.1363165737}}
{"text":"By synthesizing the latest research developments, this paper provides a thorough understanding of meta-learning and its potential impact on various machine learning applications.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.1260710375,"dev-research":0.4043612805,"prompt-eng":0.4731877159,"data-quality":0.2108055045,"ml-security":0.247954296}}
{"text":"We believe that this technical overview will contribute to the advancement of meta-learning and its practical implications in addressing real-world problems.","meta":{"url":"http://arxiv.org/abs/2307.04722v1"},"cats":{"new-dataset":0.1103721403,"dev-research":0.4433243354,"prompt-eng":0.4925191326,"data-quality":0.1841510566,"ml-security":0.167843502}}
{"text":"We observe that pre-trained large language models (LLMs) are capable of autoregressively completing complex token sequences -- from arbitrary ones procedurally generated by probabilistic context-free grammars (PCFG), to more rich spatial patterns found in the Abstract Reasoning Corpus (ARC), a general AI benchmark, prompted in the style of ASCII art.","meta":{"url":"http://arxiv.org/abs/2307.04721v1"},"cats":{"new-dataset":0.1456698194,"dev-research":0.4511940871,"prompt-eng":0.5524185546,"data-quality":0.1806117944,"ml-security":0.0918230983}}
{"text":"Surprisingly, pattern completion proficiency can be partially retained even when the sequences are expressed using tokens randomly sampled from the vocabulary.","meta":{"url":"http://arxiv.org/abs/2307.04721v1"},"cats":{"new-dataset":0.076957137,"dev-research":0.3999714696,"prompt-eng":0.5085590579,"data-quality":0.3539122693,"ml-security":0.1180774151}}
{"text":"These results suggest that without any additional training, LLMs can serve as general sequence modelers, driven by in-context learning.","meta":{"url":"http://arxiv.org/abs/2307.04721v1"},"cats":{"new-dataset":0.1091280004,"dev-research":0.4164756266,"prompt-eng":0.55242655,"data-quality":0.1166758199,"ml-security":0.164317379}}
{"text":"In this work, we investigate how these zero-shot capabilities may be applied to problems in robotics -- from extrapolating sequences of numbers that represent states over time to complete simple motions, to least-to-most prompting of reward-conditioned trajectories that can discover and represent closed-loop policies (e.g., a stabilizing controller for CartPole).","meta":{"url":"http://arxiv.org/abs/2307.04721v1"},"cats":{"new-dataset":0.093875099,"dev-research":0.4075958627,"prompt-eng":0.4252084092,"data-quality":0.0802223406,"ml-security":0.1617461785}}
{"text":"While difficult to deploy today for real systems due to latency, context size limitations, and compute costs, the approach of using LLMs to drive low-level control may provide an exciting glimpse into how the patterns among words could be transferred to actions.","meta":{"url":"http://arxiv.org/abs/2307.04721v1"},"cats":{"new-dataset":0.0686047015,"dev-research":0.4664828287,"prompt-eng":0.5838687708,"data-quality":0.1193785808,"ml-security":0.1844010092}}
{"text":"Linearizability is a standard correctness criterion for concurrent algorithms, typically proved by establishing the algorithms' linearization points (LP).","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.0307921608,"dev-research":0.3940973381,"prompt-eng":0.3314207432,"data-quality":0.1316612063,"ml-security":0.1492134478}}
{"text":"However, LPs often hinder abstraction, and for some algorithms such as the timestamped stack, it is unclear how to even identify their LPs.","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.0694622582,"dev-research":0.4382442334,"prompt-eng":0.3839547316,"data-quality":0.2126005727,"ml-security":0.130039451}}
{"text":"In this paper, we show how to develop declarative proofs of linearizability by foregoing LPs and instead employing axiomatization of so-called visibility relations.","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.0505981742,"dev-research":0.4461316191,"prompt-eng":0.3569597676,"data-quality":0.1254147922,"ml-security":0.1729578629}}
{"text":"While visibility relations have been considered before for the timestamped stack, our study is the first to show how to derive the axiomatization systematically and intuitively from the sequential specification of the stack.","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.1104954594,"dev-research":0.4625418908,"prompt-eng":0.4118253587,"data-quality":0.065234003,"ml-security":0.0991420515}}
{"text":"In addition to the visibility relation, a novel separability relation emerges to generalize real-time precedence of procedure invocation.","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.031684067,"dev-research":0.4657708466,"prompt-eng":0.4054332542,"data-quality":0.067769785,"ml-security":0.0876714933}}
{"text":"The visibility and separability relations have natural definitions for the timestamped stack, and enable a novel proof that reduces the algorithm to a simplified form where the timestamps are generated atomically.","meta":{"url":"http://arxiv.org/abs/2307.04720v1"},"cats":{"new-dataset":0.1090625343,"dev-research":0.4413536244,"prompt-eng":0.3595040358,"data-quality":0.1295926623,"ml-security":0.1671481934}}
{"text":"One of the main challenges in modern deep learning is to understand why such over-parameterized models perform so well when trained on finite data.","meta":{"url":"http://arxiv.org/abs/2307.04719v1"},"cats":{"new-dataset":0.1245894713,"dev-research":0.3415978853,"prompt-eng":0.4528122122,"data-quality":0.1113880242,"ml-security":0.4224477498}}
{"text":"A way to analyze this generalization concept is through the properties of the associated loss landscape.","meta":{"url":"http://arxiv.org/abs/2307.04719v1"},"cats":{"new-dataset":0.0420620539,"dev-research":0.4342042872,"prompt-eng":0.4294288544,"data-quality":0.1647496237,"ml-security":0.1735244442}}
{"text":"In this work, we consider the loss landscape as an embedded Riemannian manifold and show that the differential geometric properties of the manifold can be used when analyzing the generalization abilities of a deep net.","meta":{"url":"http://arxiv.org/abs/2307.04719v1"},"cats":{"new-dataset":0.1189777122,"dev-research":0.394169437,"prompt-eng":0.4087682201,"data-quality":0.1161079187,"ml-security":0.1578120597}}
{"text":"In particular, we focus on the scalar curvature, which can be computed analytically for our manifold, and show connections to several settings that potentially imply generalization.","meta":{"url":"http://arxiv.org/abs/2307.04719v1"},"cats":{"new-dataset":0.1051987354,"dev-research":0.3990191222,"prompt-eng":0.4304894592,"data-quality":0.0958560302,"ml-security":0.1313042211}}
{"text":"In this paper, we present a deforestation estimation method based on attention guided UNet architecture using Electro-Optical (EO) and Synthetic Aperture Radar (SAR) satellite imagery.","meta":{"url":"http://arxiv.org/abs/2307.04715v1"},"cats":{"new-dataset":0.1803117156,"dev-research":0.3793380291,"prompt-eng":0.403644246,"data-quality":0.1314683726,"ml-security":0.0799084236}}
{"text":"For optical images, Landsat-8 and for SAR imagery, Sentinel-1 data have been used to train and validate the proposed model.","meta":{"url":"http://arxiv.org/abs/2307.04715v1"},"cats":{"new-dataset":0.327186882,"dev-research":0.3352810821,"prompt-eng":0.448399822,"data-quality":0.1501534827,"ml-security":0.1129754998}}
{"text":"Due to the unavailability of temporally and spatially collocated data, individual model has been trained for each sensor.","meta":{"url":"http://arxiv.org/abs/2307.04715v1"},"cats":{"new-dataset":0.1937402563,"dev-research":0.3346983198,"prompt-eng":0.4601763253,"data-quality":0.1205513277,"ml-security":0.1668284308}}
{"text":"During training time Landsat-8 model achieved training and validation pixel accuracy of 93.45% and Sentinel-2 model achieved 83.87% pixel accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04715v1"},"cats":{"new-dataset":0.1894017804,"dev-research":0.3622141237,"prompt-eng":0.4447704857,"data-quality":0.1802333258,"ml-security":0.0985669322}}
{"text":"During the test set evaluation, the model achieved pixel accuracy of 84.70% with F1-Score of 0.79 and IoU of 0.69.","meta":{"url":"http://arxiv.org/abs/2307.04715v1"},"cats":{"new-dataset":0.199376763,"dev-research":0.3843834758,"prompt-eng":0.4596285571,"data-quality":0.1743872624,"ml-security":0.0550541462}}
{"text":"The standard approach to analyzing the asymptotic complexity of probabilistic programs is based on studying the asymptotic growth of certain expected values (such as the expected termination time) for increasing input size.","meta":{"url":"http://arxiv.org/abs/2307.04707v1"},"cats":{"new-dataset":0.06641125,"dev-research":0.4471235618,"prompt-eng":0.3719769964,"data-quality":0.0823780562,"ml-security":0.2083698578}}
{"text":"We argue that this approach is not sufficiently robust, especially in situations when the expectations are infinite.","meta":{"url":"http://arxiv.org/abs/2307.04707v1"},"cats":{"new-dataset":0.0557937288,"dev-research":0.3754153847,"prompt-eng":0.3852462055,"data-quality":0.1456373677,"ml-security":0.2482396415}}
{"text":"We propose new estimates for the asymptotic analysis of probabilistic programs with non-deterministic choice that overcome this deficiency.","meta":{"url":"http://arxiv.org/abs/2307.04707v1"},"cats":{"new-dataset":0.0941683881,"dev-research":0.4417632863,"prompt-eng":0.4008989954,"data-quality":0.1021552573,"ml-security":0.212058965}}
{"text":"Furthermore, we show how to efficiently compute/analyze these estimates for selected classes of programs represented as Markov decision processes over vector addition systems with states.","meta":{"url":"http://arxiv.org/abs/2307.04707v1"},"cats":{"new-dataset":0.0607011073,"dev-research":0.4511164977,"prompt-eng":0.418628687,"data-quality":0.089082085,"ml-security":0.2208877974}}
{"text":"Articulatory features can provide interpretable and flexible controls for the synthesis of human vocalizations by allowing the user to directly modify parameters like vocal strain or lip position.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.0613593789,"dev-research":0.4347472362,"prompt-eng":0.4920854921,"data-quality":0.1248937776,"ml-security":0.1748814764}}
{"text":"To make this manipulation through resynthesis possible, we need to estimate the features that result in a desired vocalization directly from audio recordings.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.098158596,"dev-research":0.3720897249,"prompt-eng":0.4864190955,"data-quality":0.1679284776,"ml-security":0.1048136047}}
{"text":"In this work, we propose a white-box optimization technique for estimating glottal source parameters and vocal tract shapes from audio recordings of human vowels.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.1393795976,"dev-research":0.3575833376,"prompt-eng":0.4767273309,"data-quality":0.1776175977,"ml-security":0.1128004663}}
{"text":"The approach is based on inverse filtering and optimizing the frequency response of a wave\\-guide model of the vocal tract with gradient descent, propagating error gradients through the mapping of articulatory features to the vocal tract area function.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.0712588732,"dev-research":0.349147761,"prompt-eng":0.4758058919,"data-quality":0.1663396985,"ml-security":0.1126436098}}
{"text":"We apply this method to the task of matching the sound of the Pink Trombone, an interactive articulatory synthesizer, to a given vocalization.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.0989730221,"dev-research":0.3983595145,"prompt-eng":0.4855623674,"data-quality":0.1191688773,"ml-security":0.0930720538}}
{"text":"We find that our method accurately recovers control functions for audio generated by the Pink Trombone itself.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.085165597,"dev-research":0.3969674521,"prompt-eng":0.4642346476,"data-quality":0.1755845186,"ml-security":0.1268187805}}
{"text":"We then compare our technique against evolutionary optimization algorithms and a neural network trained to predict control parameters from audio.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.1165097509,"dev-research":0.4111429863,"prompt-eng":0.4831346609,"data-quality":0.1353141784,"ml-security":0.1795458888}}
{"text":"A subjective evaluation finds that our approach outperforms these black-box optimization baselines on the task of reproducing human vocalizations.","meta":{"url":"http://arxiv.org/abs/2307.04702v1"},"cats":{"new-dataset":0.0900115621,"dev-research":0.4195637525,"prompt-eng":0.5382130748,"data-quality":0.2950447831,"ml-security":0.1683315467}}
{"text":"Planning is a pivotal ability of any intelligent system being developed for real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.111667455,"dev-research":0.4688043585,"prompt-eng":0.436369928,"data-quality":0.0415107669,"ml-security":0.1062144357}}
{"text":"AI planning is concerned with researching and developing planning systems that automatically compute plans that satisfy some user objective.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.1886843155,"dev-research":0.4771322999,"prompt-eng":0.472674846,"data-quality":0.0582695042,"ml-security":0.08561951}}
{"text":"Identifying and understanding the relevant and realistic aspects that characterise real-world application domains are crucial to the development of AI planning systems.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.1717366944,"dev-research":0.4478266755,"prompt-eng":0.4233287535,"data-quality":0.0643249907,"ml-security":0.1302652687}}
{"text":"This provides guidance to knowledge engineers and software engineers in the process of designing, identifying, and categorising resources required for the development process.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.2573703735,"dev-research":0.5849558075,"prompt-eng":0.4836747554,"data-quality":0.1048803962,"ml-security":0.1124757708}}
{"text":"To the best of our knowledge, such support does not exist.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.1472505526,"dev-research":0.400256462,"prompt-eng":0.3718398225,"data-quality":0.1304100517,"ml-security":0.1414819875}}
{"text":"We address this research gap by developing a conceptual framework that identifies and categorises the aspects of real-world planning domains in varying levels of granularity.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.1508487211,"dev-research":0.4493212126,"prompt-eng":0.3902881973,"data-quality":0.0488276977,"ml-security":0.0612364833}}
{"text":"Our framework provides not only a common terminology but also a comprehensive overview of a broad range of planning aspects exemplified using the domain of sustainable buildings as a prominent application domain of AI planning.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.2039164839,"dev-research":0.4476862713,"prompt-eng":0.4384016937,"data-quality":0.0441740279,"ml-security":0.091878525}}
{"text":"The framework has the potential to impact the design, development, and applicability of AI planning systems in real-world application domains.","meta":{"url":"http://arxiv.org/abs/2307.04701v1"},"cats":{"new-dataset":0.1983493336,"dev-research":0.440204702,"prompt-eng":0.4293217429,"data-quality":0.0486140748,"ml-security":0.1417599382}}
{"text":"International institutions may have an important role to play in ensuring advanced AI systems benefit humanity.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.1086047972,"dev-research":0.4447384954,"prompt-eng":0.4381791396,"data-quality":0.0834824159,"ml-security":0.1787199536}}
{"text":"International collaborations can unlock AI's ability to further sustainable development, and coordination of regulatory efforts can reduce obstacles to innovation and the spread of benefits.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.1213944732,"dev-research":0.4719173634,"prompt-eng":0.404244131,"data-quality":0.0976714133,"ml-security":0.1014941595}}
{"text":"Conversely, the potential dangerous capabilities of powerful and general-purpose AI systems create global externalities in their development and deployment, and international efforts to further responsible AI practices could help manage the risks they pose.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.1120252024,"dev-research":0.4663980883,"prompt-eng":0.4295531714,"data-quality":0.1070212249,"ml-security":0.4556726549}}
{"text":"This paper identifies a set of governance functions that could be performed at an international level to address these challenges, ranging from supporting access to frontier AI systems to setting international safety standards.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.2646530901,"dev-research":0.4439343483,"prompt-eng":0.4144498065,"data-quality":0.1485120834,"ml-security":0.2841917573}}
{"text":"It groups these functions into four institutional models that exhibit internal synergies and have precedents in existing organizations: 1) a Commission on Frontier AI that facilitates expert consensus on opportunities and risks from advanced AI, 2) an Advanced AI Governance Organization that sets international standards to manage global threats from advanced models, supports their implementation, and possibly monitors compliance with a future governance regime, 3) a Frontier AI Collaborative that promotes access to cutting-edge AI, and 4) an AI Safety Project that brings together leading researchers and engineers to further AI safety research.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.1882725121,"dev-research":0.4602091958,"prompt-eng":0.411487916,"data-quality":0.1106345505,"ml-security":0.2023214665}}
{"text":"We explore the utility of these models and identify open questions about their viability.","meta":{"url":"http://arxiv.org/abs/2307.04699v1"},"cats":{"new-dataset":0.0610887274,"dev-research":0.4098227954,"prompt-eng":0.4369380511,"data-quality":0.0945846243,"ml-security":0.181974991}}
{"text":"Mining in proof-of-work blockchains has become an expensive affair requiring specialized hardware capable of executing several megahashes per second at huge electricity costs.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0733160503,"dev-research":0.4120408642,"prompt-eng":0.3554903714,"data-quality":0.0749570902,"ml-security":0.1825173078}}
{"text":"Miners earn a reward each time they mine a block within the longest chain, which helps offset their mining costs.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0540466901,"dev-research":0.4662035885,"prompt-eng":0.3677445126,"data-quality":0.1112462674,"ml-security":0.1250488679}}
{"text":"It is therefore of interest to miners to maximize the number of mined blocks in the blockchain and increase revenue.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0551867579,"dev-research":0.4741512554,"prompt-eng":0.3300329195,"data-quality":0.063808523,"ml-security":0.1197038623}}
{"text":"A key factor affecting mining rewards earned is the connectivity between miners in the peer-to-peer network.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0414035444,"dev-research":0.4602256916,"prompt-eng":0.3821404924,"data-quality":0.1118176475,"ml-security":0.1472976975}}
{"text":"To maximize rewards a miner must choose its network connections carefully, ensuring existence of paths to other miners that are on average of a lower latency compared to paths between other miners.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0359084342,"dev-research":0.4337296168,"prompt-eng":0.3715876726,"data-quality":0.0754322091,"ml-security":0.1703691164}}
{"text":"We formulate the problem of deciding whom to connect to for miners as a combinatorial bandit problem.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.1065195357,"dev-research":0.4451628315,"prompt-eng":0.4135337479,"data-quality":0.1226999647,"ml-security":0.2637591914}}
{"text":"Each node picks its neighbors strategically to minimize the latency to reach 90\\% of the hash power of the network relative to the 90-th percentile latency from other nodes.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.0400336965,"dev-research":0.4078333462,"prompt-eng":0.3867748137,"data-quality":0.0856844911,"ml-security":0.1344454859}}
{"text":"A key contribution of our work is the use of a network coordinates based model for learning the network structure within the bandit algorithm.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.1094761572,"dev-research":0.4095582911,"prompt-eng":0.4312269167,"data-quality":0.1360909652,"ml-security":0.2361666866}}
{"text":"Experimentally we show our proposed algorithm outperforming or matching baselines on diverse network settings.","meta":{"url":"http://arxiv.org/abs/2307.04695v1"},"cats":{"new-dataset":0.1560341255,"dev-research":0.3932139682,"prompt-eng":0.4146384912,"data-quality":0.2355852471,"ml-security":0.1525937467}}
{"text":"Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.1174385532,"dev-research":0.540322072,"prompt-eng":0.4963105439,"data-quality":0.2439104871,"ml-security":0.3261171946}}
{"text":"Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.2068971934,"dev-research":0.5463280679,"prompt-eng":0.5525178012,"data-quality":0.1412148053,"ml-security":0.1389113744}}
{"text":"However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.1305958421,"dev-research":0.5368777079,"prompt-eng":0.4254041861,"data-quality":0.3236928819,"ml-security":0.1882544236}}
{"text":"Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.0949024877,"dev-research":0.5626933615,"prompt-eng":0.515510728,"data-quality":0.2266353456,"ml-security":0.2424239168}}
{"text":"Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.2416882646,"dev-research":0.5699542164,"prompt-eng":0.4492067677,"data-quality":0.1439542166,"ml-security":0.1092927271}}
{"text":"To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.2825686555,"dev-research":0.527107574,"prompt-eng":0.4947640991,"data-quality":0.1499507882,"ml-security":0.2036201218}}
{"text":"Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages.","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.1484691301,"dev-research":0.5625584504,"prompt-eng":0.5011240365,"data-quality":0.1631971938,"ml-security":0.0784988304}}
{"text":"We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE.   ","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.2618856558,"dev-research":0.5740759787,"prompt-eng":0.5057469796,"data-quality":0.1946902524,"ml-security":0.1388721731}}
{"text":"Tool: https://pypi.org/project/comex - GitHub: https://github.com/IBM/tree-sitter-codeviews - Demo: https://youtu.be/GER6U87FVbU","meta":{"url":"http://arxiv.org/abs/2307.04693v1"},"cats":{"new-dataset":0.3649990482,"dev-research":0.4777817105,"prompt-eng":0.4604671724,"data-quality":0.103598051,"ml-security":0.0619835706}}
{"text":"We introduce VampNet, a masked acoustic token modeling approach to music synthesis, compression, inpainting, and variation.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.0969686326,"dev-research":0.4139935675,"prompt-eng":0.4406499977,"data-quality":0.2330661044,"ml-security":0.1908003524}}
{"text":"We use a variable masking schedule during training which allows us to sample coherent music from the model by applying a variety of masking approaches (called prompts) during inference.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.1174091849,"dev-research":0.3747500586,"prompt-eng":0.5257710811,"data-quality":0.2227086557,"ml-security":0.2016992989}}
{"text":"VampNet is non-autoregressive, leveraging a bidirectional transformer architecture that attends to all tokens in a forward pass.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.0912556473,"dev-research":0.4228423179,"prompt-eng":0.4353617524,"data-quality":0.1148674473,"ml-security":0.2681171508}}
{"text":"With just 36 sampling passes, VampNet can generate coherent high-fidelity musical waveforms.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.1400486779,"dev-research":0.3777475799,"prompt-eng":0.4104713157,"data-quality":0.1038507683,"ml-security":0.1157826447}}
{"text":"We show that by prompting VampNet in various ways, we can apply it to tasks like music compression, inpainting, outpainting, continuation, and looping with variation (vamping).","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.0965505671,"dev-research":0.4817720082,"prompt-eng":0.4522718142,"data-quality":0.1664999208,"ml-security":0.1353825085}}
{"text":"Appropriately prompted, VampNet is capable of maintaining style, genre, instrumentation, and other high-level aspects of the music.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.150233626,"dev-research":0.4483765345,"prompt-eng":0.4409292964,"data-quality":0.1317574659,"ml-security":0.1400168665}}
{"text":"This flexible prompting capability makes VampNet a powerful music co-creation tool.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.1242258825,"dev-research":0.4734662089,"prompt-eng":0.5293178125,"data-quality":0.1399644141,"ml-security":0.1365360812}}
{"text":"Code and audio samples are available online.","meta":{"url":"http://arxiv.org/abs/2307.04686v1"},"cats":{"new-dataset":0.5464010666,"dev-research":0.4746772112,"prompt-eng":0.5102951131,"data-quality":0.1791307014,"ml-security":0.0914499542}}
{"text":"To serve the intricate and varied demands of image editing, precise and flexible manipulation of image content is indispensable.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.0553610118,"dev-research":0.4196936971,"prompt-eng":0.3741860142,"data-quality":0.0983942626,"ml-security":0.047213748}}
{"text":"Recently, DragGAN has achieved impressive editing results through point-based manipulation.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.0912231255,"dev-research":0.4624036184,"prompt-eng":0.4342488048,"data-quality":0.1111953032,"ml-security":0.0627324545}}
{"text":"However, we have observed that DragGAN struggles with miss tracking, where DragGAN encounters difficulty in effectively tracking the desired handle points, and ambiguous tracking, where the tracked points are situated within other regions that bear resemblance to the handle points.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.1186024277,"dev-research":0.4423460829,"prompt-eng":0.4258615825,"data-quality":0.1995683354,"ml-security":0.0915941821}}
{"text":"To deal with the above issues, we propose FreeDrag, which adopts a feature-oriented approach to free the burden on point tracking within the point-oriented methodology of DragGAN.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.1532458786,"dev-research":0.4454005248,"prompt-eng":0.4180889935,"data-quality":0.1308480455,"ml-security":0.0956722747}}
{"text":"The FreeDrag incorporates adaptive template features, line search, and fuzzy localization techniques to perform stable and efficient point-based image editing.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.0832511723,"dev-research":0.4245912969,"prompt-eng":0.4057150776,"data-quality":0.1386251491,"ml-security":0.0552875483}}
{"text":"Extensive experiments demonstrate that our method is superior to the DragGAN and enables stable point-based editing in challenging scenarios with similar structures, fine details, or under multi-point targets.","meta":{"url":"http://arxiv.org/abs/2307.04684v1"},"cats":{"new-dataset":0.0932524419,"dev-research":0.4320136455,"prompt-eng":0.4222462534,"data-quality":0.1344714929,"ml-security":0.0744961266}}
{"text":"In this paper, we provide a novel framework for the analysis of generalization error of first-order optimization algorithms for statistical learning when the gradient can only be accessed through partial observations given by an oracle.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0493986523,"dev-research":0.3671730851,"prompt-eng":0.4251701559,"data-quality":0.2192883321,"ml-security":0.2567037514}}
{"text":"Our analysis relies on the regularity of the gradient w.r.t.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0870035818,"dev-research":0.3783659647,"prompt-eng":0.42420564,"data-quality":0.1764846755,"ml-security":0.1861227329}}
{"text":"the data samples, and allows to derive near matching upper and lower bounds for the generalization error of multiple learning problems, including supervised learning, transfer learning, robust learning, distributed learning and communication efficient learning using gradient quantization.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.1271751288,"dev-research":0.3441383032,"prompt-eng":0.4141016693,"data-quality":0.25956398,"ml-security":0.2739429427}}
{"text":"These results hold for smooth and strongly-convex optimization problems, as well as smooth non-convex optimization problems verifying a Polyak-Lojasiewicz assumption.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0720777226,"dev-research":0.41144581,"prompt-eng":0.3849100921,"data-quality":0.1755493791,"ml-security":0.2199057833}}
{"text":"In particular, our upper and lower bounds depend on a novel quantity that extends the notion of conditional standard deviation, and is a measure of the extent to which the gradient can be approximated by having access to the oracle.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0548661898,"dev-research":0.3999213832,"prompt-eng":0.3924167246,"data-quality":0.1099315937,"ml-security":0.194644269}}
{"text":"As a consequence, our analysis provides a precise meaning to the intuition that optimization of the statistical learning objective is as hard as the estimation of its gradient.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0542862332,"dev-research":0.4070833982,"prompt-eng":0.4176900948,"data-quality":0.2058999928,"ml-security":0.3119601423}}
{"text":"Finally, we show that, in the case of standard supervised learning, mini-batch gradient descent with increasing batch sizes and a warm start can reach a generalization error that is optimal up to a multiplicative factor, thus motivating the use of this optimization scheme in practical applications.","meta":{"url":"http://arxiv.org/abs/2307.04679v1"},"cats":{"new-dataset":0.0573694756,"dev-research":0.361214806,"prompt-eng":0.4575866429,"data-quality":0.187178297,"ml-security":0.2781508256}}
{"text":"Artificial intelligence (AI) is considered an efficient response to several challenges facing 6G technology.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.0982591464,"dev-research":0.3982416146,"prompt-eng":0.4010299112,"data-quality":0.080761153,"ml-security":0.1032585825}}
{"text":"However, AI still suffers from a huge trust issue due to its ambiguous way of making predictions.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.0793917737,"dev-research":0.4601599893,"prompt-eng":0.4296708455,"data-quality":0.2364222942,"ml-security":0.3568731812}}
{"text":"Therefore, there is a need for a method to evaluate the AI's trustworthiness in practice for future 6G applications.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.0623330842,"dev-research":0.4197618398,"prompt-eng":0.442842533,"data-quality":0.1529748464,"ml-security":0.2686052775}}
{"text":"This paper presents a practical model to analyze the trustworthiness of AI in a dedicated 6G application.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.0824264646,"dev-research":0.3880346565,"prompt-eng":0.4328604849,"data-quality":0.1277510207,"ml-security":0.2387555177}}
{"text":"In particular, we present two customized Deep Neural Networks (DNNs) to solve the Automatic Modulation Recognition (AMR) problem in Terahertz communications-based 6G technology.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.1634699627,"dev-research":0.3849781652,"prompt-eng":0.4357222109,"data-quality":0.1306157763,"ml-security":0.1555153208}}
{"text":"Then, a specific trustworthiness model and its attributes, namely data robustness, parameter sensitivity, and security covering adversarial examples, are introduced.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.1183631563,"dev-research":0.4000720635,"prompt-eng":0.4652444749,"data-quality":0.2797904864,"ml-security":0.7741580062}}
{"text":"The evaluation results indicate that the proposed trustworthiness attributes are crucial to evaluate the trustworthiness of DNN for this 6G application.","meta":{"url":"http://arxiv.org/abs/2307.04677v1"},"cats":{"new-dataset":0.1598202897,"dev-research":0.3735915409,"prompt-eng":0.4582774373,"data-quality":0.2067846755,"ml-security":0.1979732341}}
{"text":"Variational inference is an increasingly popular method in statistics and machine learning for approximating probability distributions.","meta":{"url":"http://arxiv.org/abs/2307.04675v1"},"cats":{"new-dataset":0.0799401784,"dev-research":0.3677186147,"prompt-eng":0.4695301269,"data-quality":0.1288467491,"ml-security":0.1493733134}}
{"text":"We developed LINFA (Library for Inference with Normalizing Flow and Annealing), a Python library for variational inference to accommodate computationally expensive models and difficult-to-sample distributions with dependent parameters.","meta":{"url":"http://arxiv.org/abs/2307.04675v1"},"cats":{"new-dataset":0.124643299,"dev-research":0.3586433916,"prompt-eng":0.4723559772,"data-quality":0.0816755497,"ml-security":0.1257262978}}
{"text":"We discuss the theoretical background, capabilities, and performance of LINFA in various benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.04675v1"},"cats":{"new-dataset":0.0891412602,"dev-research":0.375819023,"prompt-eng":0.3949975101,"data-quality":0.075921464,"ml-security":0.0722630276}}
{"text":"LINFA is publicly available on GitHub at https://github.com/desResLab/LINFA.","meta":{"url":"http://arxiv.org/abs/2307.04675v1"},"cats":{"new-dataset":0.292152289,"dev-research":0.4170487597,"prompt-eng":0.4554985061,"data-quality":0.0976295891,"ml-security":0.0989567766}}
{"text":"This paper presents a solution for the problem of optimal planning for a robot in a collaborative human-robot team, where the human supervisor is intermittently available to assist the robot in completing tasks more quickly.","meta":{"url":"http://arxiv.org/abs/2307.04674v1"},"cats":{"new-dataset":0.080958221,"dev-research":0.4137755886,"prompt-eng":0.4363481667,"data-quality":0.0514997241,"ml-security":0.0547642308}}
{"text":"Specifically, we address the challenge of computing the fastest path between two configurations in an environment with time constraints on how long the robot can wait for assistance.","meta":{"url":"http://arxiv.org/abs/2307.04674v1"},"cats":{"new-dataset":0.155435879,"dev-research":0.4052567826,"prompt-eng":0.4038582169,"data-quality":0.0391597567,"ml-security":0.077052698}}
{"text":"To solve this problem, we propose a novel approach that utilizes the concepts of budget and critical departure times, which enables us to obtain optimal solutions while scaling to larger problem instances than existing methods.","meta":{"url":"http://arxiv.org/abs/2307.04674v1"},"cats":{"new-dataset":0.1148561465,"dev-research":0.4269446471,"prompt-eng":0.3858011912,"data-quality":0.0776167643,"ml-security":0.100428901}}
{"text":"We demonstrate the effectiveness of our approach by comparing it with several baseline algorithms on a city road network and analyzing the quality of the solutions obtained.","meta":{"url":"http://arxiv.org/abs/2307.04674v1"},"cats":{"new-dataset":0.1629982937,"dev-research":0.4083436481,"prompt-eng":0.3598007946,"data-quality":0.1050266416,"ml-security":0.0873577192}}
{"text":"Our work contributes to the field of robot planning by addressing the critical issue of incorporating human assistance and environmental restrictions, which has significant implications for real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.04674v1"},"cats":{"new-dataset":0.0852778799,"dev-research":0.4188760815,"prompt-eng":0.423592534,"data-quality":0.0511120302,"ml-security":0.1078991224}}
{"text":"The rise of social media platforms has facilitated the formation of echo chambers, which are online spaces where users predominantly encounter viewpoints that reinforce their existing beliefs while excluding dissenting perspectives.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.1421356018,"dev-research":0.4341571456,"prompt-eng":0.4534736352,"data-quality":0.1227299274,"ml-security":0.2085508039}}
{"text":"This phenomenon significantly hinders information dissemination across communities and fuels societal polarization.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.0783939684,"dev-research":0.4339605681,"prompt-eng":0.4071992895,"data-quality":0.1727773226,"ml-security":0.2597400588}}
{"text":"Therefore, it is crucial to develop methods for quantifying echo chambers.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.1259901341,"dev-research":0.398682289,"prompt-eng":0.4373712316,"data-quality":0.1636164682,"ml-security":0.1447841644}}
{"text":"In this paper, we present the Echo Chamber Score (ECS), a novel metric that assesses the cohesion and separation of user communities by measuring distances between users in the embedding space.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.1673579879,"dev-research":0.4416093893,"prompt-eng":0.4677967878,"data-quality":0.1694740794,"ml-security":0.1143002535}}
{"text":"In contrast to existing approaches, ECS is able to function without labels for user ideologies and makes no assumptions about the structure of the interaction graph.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.0720966506,"dev-research":0.4197680147,"prompt-eng":0.4006239977,"data-quality":0.1882745035,"ml-security":0.1381056914}}
{"text":"To facilitate measuring distances between users, we propose EchoGAE, a self-supervised graph autoencoder-based user embedding model that leverages users' posts and the interaction graph to embed them in a manner that reflects their ideological similarity.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.2635825356,"dev-research":0.4455453013,"prompt-eng":0.5190834003,"data-quality":0.2120130448,"ml-security":0.1342191094}}
{"text":"To assess the effectiveness of ECS, we use a Twitter dataset consisting of four topics - two polarizing and two non-polarizing.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.2051306715,"dev-research":0.4029660821,"prompt-eng":0.4986023677,"data-quality":0.2023717825,"ml-security":0.1431356105}}
{"text":"Our results showcase ECS's effectiveness as a tool for quantifying echo chambers and shedding light on the dynamics of online discourse.","meta":{"url":"http://arxiv.org/abs/2307.04668v1"},"cats":{"new-dataset":0.1236630253,"dev-research":0.4187454122,"prompt-eng":0.4911956919,"data-quality":0.1775781712,"ml-security":0.1579154325}}
{"text":"In this article we present new results about the expressivity of Graph Neural Networks (GNNs).","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.1897733432,"dev-research":0.3847163629,"prompt-eng":0.3588864684,"data-quality":0.2262759515,"ml-security":0.1685904139}}
{"text":"We prove that for any GNN with piecewise polynomial activations, whose architecture size does not grow with the graph input sizes, there exists a pair of non-isomorphic rooted trees of depth two such that the GNN cannot distinguish their root vertex up to an arbitrary number of iterations.","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0884726154,"dev-research":0.4092548782,"prompt-eng":0.3531926992,"data-quality":0.1272567989,"ml-security":0.2442643559}}
{"text":"The proof relies on tools from the algebra of symmetric polynomials.","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0772298958,"dev-research":0.4655663603,"prompt-eng":0.392015794,"data-quality":0.1139015902,"ml-security":0.2135814392}}
{"text":"In contrast, it was already known that unbounded GNNs (those whose size is allowed to change with the graph sizes) with piecewise polynomial activations can distinguish these vertices in only two iterations.","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0419740245,"dev-research":0.3741179926,"prompt-eng":0.3015434975,"data-quality":0.1226536903,"ml-security":0.1879142232}}
{"text":"Our results imply a strict separation between bounded and unbounded size GNNs, answering an open question formulated by [Grohe, 2021].","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.1458653753,"dev-research":0.385364151,"prompt-eng":0.3811014169,"data-quality":0.1503011623,"ml-security":0.2023577428}}
{"text":"We next prove that if one allows activations that are not piecewise polynomial, then in two iterations a single neuron perceptron can distinguish the root vertices of any pair of nonisomorphic trees of depth two (our results hold for activations like the sigmoid, hyperbolic tan and others).","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0504796362,"dev-research":0.4131441748,"prompt-eng":0.3724887463,"data-quality":0.1424036415,"ml-security":0.1874963482}}
{"text":"This shows how the power of graph neural networks can change drastically if one changes the activation function of the neural networks.","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0483615328,"dev-research":0.4151327342,"prompt-eng":0.3751194129,"data-quality":0.1345001928,"ml-security":0.2768147509}}
{"text":"The proof of this result utilizes the Lindemann-Weierstrauss theorem from transcendental number theory.","meta":{"url":"http://arxiv.org/abs/2307.04661v1"},"cats":{"new-dataset":0.0992728576,"dev-research":0.408437524,"prompt-eng":0.3776638132,"data-quality":0.1462736576,"ml-security":0.1615779916}}
{"text":"In this paper, we introduce the BeaverTails dataset, aimed at fostering research on safety alignment in large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.513235414,"dev-research":0.4253742479,"prompt-eng":0.5456994254,"data-quality":0.2939137935,"ml-security":0.2876026667}}
{"text":"This dataset uniquely separates annotations of helpfulness and harmlessness for question-answering pairs, thus offering distinct perspectives on these crucial attributes.","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.3283786802,"dev-research":0.4741053274,"prompt-eng":0.4919009269,"data-quality":0.3243638459,"ml-security":0.2530208728}}
{"text":"In total, we have compiled safety meta-labels for 30,207 question-answer (QA) pairs and gathered 30,144 pairs of expert comparison data for both the helpfulness and harmlessness metrics.","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.3643569236,"dev-research":0.4527697946,"prompt-eng":0.4962229554,"data-quality":0.4224670359,"ml-security":0.258205968}}
{"text":"We further showcase applications of BeaverTails in content moderation and reinforcement learning with human feedback (RLHF), emphasizing its potential for practical safety measures in LLMs.","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.1443485828,"dev-research":0.4381206235,"prompt-eng":0.5366881847,"data-quality":0.1629747012,"ml-security":0.2123209855}}
{"text":"We believe this dataset provides vital resources for the community, contributing towards the safe development and deployment of LLMs.","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.756931502,"dev-research":0.4485903078,"prompt-eng":0.5383853163,"data-quality":0.1467914535,"ml-security":0.2964383879}}
{"text":"Our project page is available at the following URL: https://sites.google.com/view/pku-beavertails.","meta":{"url":"http://arxiv.org/abs/2307.04657v1"},"cats":{"new-dataset":0.3458367811,"dev-research":0.4381410469,"prompt-eng":0.4404934237,"data-quality":0.0633590408,"ml-security":0.0781361478}}
{"text":"Linearizability is a standard correctness criterion for concurrent algorithms, typically proved by establishing the algorithms' linearization points.","meta":{"url":"http://arxiv.org/abs/2307.04653v1"},"cats":{"new-dataset":0.0309215833,"dev-research":0.3944908994,"prompt-eng":0.3309812947,"data-quality":0.131896546,"ml-security":0.172802163}}
{"text":"However, relying on linearization points leads to proofs that are implementation-dependent, and thus hinder abstraction and reuse.","meta":{"url":"http://arxiv.org/abs/2307.04653v1"},"cats":{"new-dataset":0.0201326857,"dev-research":0.4837242475,"prompt-eng":0.3350314322,"data-quality":0.1261164359,"ml-security":0.271681287}}
{"text":"In this paper we show that one can develop more declarative proofs by foregoing linearization points and instead relying on a technique of axiomatization of visibility relations.","meta":{"url":"http://arxiv.org/abs/2307.04653v1"},"cats":{"new-dataset":0.0544947645,"dev-research":0.4534324638,"prompt-eng":0.3560289386,"data-quality":0.1409076297,"ml-security":0.1886542863}}
{"text":"While visibility relations have been considered before, ours is the first study where the challenge is to formalize the helping nature of the algorithms.","meta":{"url":"http://arxiv.org/abs/2307.04653v1"},"cats":{"new-dataset":0.0819929077,"dev-research":0.4408587483,"prompt-eng":0.3702344952,"data-quality":0.0885179685,"ml-security":0.1481404141}}
{"text":"In particular, we show that by axiomatizing the properties of separation between events that contain bunches of help requests, we can extract what is common for high-level understanding of several descriptor-based helping algorithms of Harris et al. (RDCSS, MCAS, and optimizations), and produce novel proofs of their linearizability that share significant components.","meta":{"url":"http://arxiv.org/abs/2307.04653v1"},"cats":{"new-dataset":0.0725866181,"dev-research":0.491375309,"prompt-eng":0.4727755293,"data-quality":0.1770888413,"ml-security":0.1978699567}}
{"text":"Salient objects attract human attention and usually stand out clearly from their surroundings.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1221149134,"dev-research":0.4202156471,"prompt-eng":0.441189133,"data-quality":0.109270348,"ml-security":0.0778811183}}
{"text":"In contrast, camouflaged objects share similar colors or textures with the environment.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1954802402,"dev-research":0.4225597575,"prompt-eng":0.4151285699,"data-quality":0.1694620899,"ml-security":0.1909221949}}
{"text":"In this case, salient objects are typically non-camouflaged, and camouflaged objects are usually not salient.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1019284602,"dev-research":0.3956665192,"prompt-eng":0.4028873279,"data-quality":0.1963770891,"ml-security":0.1417350688}}
{"text":"Due to this inherent contradictory attribute, we introduce an uncertainty-aware learning pipeline to extensively explore the contradictory information of salient object detection (SOD) and camouflaged object detection (COD) via data-level and task-wise contradiction modeling.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1365888089,"dev-research":0.3947832723,"prompt-eng":0.4754681014,"data-quality":0.4139499763,"ml-security":0.2071168932}}
{"text":"We first exploit the dataset correlation of these two tasks and claim that the easy samples in the COD dataset can serve as hard samples for SOD to improve the robustness of the SOD model.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.2628157394,"dev-research":0.401253898,"prompt-eng":0.4709226919,"data-quality":0.1977069585,"ml-security":0.2272760177}}
{"text":"Based on the assumption that these two models should lead to activation maps highlighting different regions of the same input image, we further introduce a contrastive module with a joint-task contrastive learning framework to explicitly model the contradictory attributes of these two tasks.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1222242172,"dev-research":0.3824517959,"prompt-eng":0.483638694,"data-quality":0.2212016918,"ml-security":0.0952407906}}
{"text":"Different from conventional intra-task contrastive learning for unsupervised representation learning, our contrastive module is designed to model the task-wise correlation, leading to cross-task representation learning.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.2288362423,"dev-research":0.3922924756,"prompt-eng":0.4796866638,"data-quality":0.1120009457,"ml-security":0.0854827266}}
{"text":"To better understand the two tasks from the perspective of uncertainty, we extensively investigate the uncertainty estimation techniques for modeling the main uncertainties of the two tasks, namely task uncertainty (for SOD) and data uncertainty (for COD), and aiming to effectively estimate the challenging regions for each task to achieve difficulty-aware learning.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.1396624091,"dev-research":0.4035055063,"prompt-eng":0.4656514343,"data-quality":0.2526535073,"ml-security":0.146021347}}
{"text":"Experimental results on benchmark datasets demonstrate that our solution leads to both state-of-the-art performance and informative uncertainty estimation.","meta":{"url":"http://arxiv.org/abs/2307.04651v1"},"cats":{"new-dataset":0.4545941008,"dev-research":0.3571503489,"prompt-eng":0.4617076418,"data-quality":0.2916394062,"ml-security":0.1765828838}}
{"text":"Recommender systems are effective tools for mitigating information overload and have seen extensive applications across various domains.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.1283036231,"dev-research":0.4952651175,"prompt-eng":0.4737028181,"data-quality":0.1376084616,"ml-security":0.2753139332}}
{"text":"However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware recommender systems.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.0791990119,"dev-research":0.4380748933,"prompt-eng":0.418829261,"data-quality":0.1773654704,"ml-security":0.2339786049}}
{"text":"While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.13243584,"dev-research":0.4131017285,"prompt-eng":0.3761077311,"data-quality":0.1325277535,"ml-security":0.2974276807}}
{"text":"In this survey, we first discuss each of them individually and then dive into their connections.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.4264624492,"dev-research":0.4412814919,"prompt-eng":0.4919576122,"data-quality":0.0820822947,"ml-security":0.049573976}}
{"text":"Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.1135582912,"dev-research":0.4529914722,"prompt-eng":0.422743314,"data-quality":0.1144280352,"ml-security":0.1679757824}}
{"text":"With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.1435370409,"dev-research":0.4313864454,"prompt-eng":0.4066958248,"data-quality":0.1392861356,"ml-security":0.2649732098}}
{"text":"This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions.","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.0847036915,"dev-research":0.4501504721,"prompt-eng":0.3758872967,"data-quality":0.1150223666,"ml-security":0.2889030268}}
{"text":"Papers discussed in this survey along with public code links are available at https://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems .","meta":{"url":"http://arxiv.org/abs/2307.04644v1"},"cats":{"new-dataset":0.2350770742,"dev-research":0.4494632873,"prompt-eng":0.4454809524,"data-quality":0.1483704448,"ml-security":0.1943051967}}
{"text":"Brain age estimation is clinically important as it can provide valuable information in the context of neurodegenerative diseases such as Alzheimer's.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.1543815274,"dev-research":0.401238603,"prompt-eng":0.4198514587,"data-quality":0.1587268423,"ml-security":0.1157800233}}
{"text":"Population graphs, which include multimodal imaging information of the subjects along with the relationships among the population, have been used in literature along with Graph Convolutional Networks (GCNs) and have proved beneficial for a variety of medical imaging tasks.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.3290503894,"dev-research":0.3658016475,"prompt-eng":0.4141651708,"data-quality":0.0992294004,"ml-security":0.0773357766}}
{"text":"A population graph is usually static and constructed manually using non-imaging information.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.3843636768,"dev-research":0.4096669009,"prompt-eng":0.4208886548,"data-quality":0.1336213902,"ml-security":0.0737842968}}
{"text":"However, graph construction is not a trivial task and might significantly affect the performance of the GCN, which is inherently very sensitive to the graph structure.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.0413215999,"dev-research":0.3913849998,"prompt-eng":0.335284189,"data-quality":0.1256532346,"ml-security":0.1107794282}}
{"text":"In this work, we propose a framework that learns a population graph structure optimized for the downstream task.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.3179189054,"dev-research":0.3900285756,"prompt-eng":0.4358066538,"data-quality":0.1357181717,"ml-security":0.1286836134}}
{"text":"An attention mechanism assigns weights to a set of imaging and non-imaging features (phenotypes), which are then used for edge extraction.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.0568073673,"dev-research":0.4194487425,"prompt-eng":0.4515469467,"data-quality":0.1230552797,"ml-security":0.0885088638}}
{"text":"The resulting graph is used to train the GCN.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.177352708,"dev-research":0.4011031548,"prompt-eng":0.4065818538,"data-quality":0.1156125194,"ml-security":0.0950620988}}
{"text":"The entire pipeline can be trained end-to-end.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.1362991179,"dev-research":0.4217346632,"prompt-eng":0.5169616327,"data-quality":0.1300603846,"ml-security":0.1625893199}}
{"text":"Additionally, by visualizing the attention weights that were the most important for the graph construction, we increase the interpretability of the graph.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.1259714107,"dev-research":0.4634679374,"prompt-eng":0.439199656,"data-quality":0.1622377083,"ml-security":0.0894775435}}
{"text":"We use the UK Biobank, which provides a large variety of neuroimaging and non-imaging phenotypes, to evaluate our method on brain age regression and classification.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.3163062048,"dev-research":0.3782031484,"prompt-eng":0.4397527781,"data-quality":0.1905162351,"ml-security":0.1448174699}}
{"text":"The proposed method outperforms competing static graph approaches and other state-of-the-art adaptive methods.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.0862823905,"dev-research":0.4167896329,"prompt-eng":0.3432427238,"data-quality":0.1904795682,"ml-security":0.0873632976}}
{"text":"We further show that the assigned attention scores indicate that there are both imaging and non-imaging phenotypes that are informative for brain age estimation and are in agreement with the relevant literature.","meta":{"url":"http://arxiv.org/abs/2307.04639v1"},"cats":{"new-dataset":0.1876866178,"dev-research":0.3772162482,"prompt-eng":0.4508468014,"data-quality":0.185724227,"ml-security":0.0967999826}}
{"text":"This paper addresses the challenges of optimally placing a finite number of sensors to detect Poisson-distributed targets in a bounded domain.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.0826359353,"dev-research":0.3527148354,"prompt-eng":0.3849216903,"data-quality":0.1190410411,"ml-security":0.3313883537}}
{"text":"We seek to rigorously account for uncertainty in the target arrival model throughout the problem.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.0519299525,"dev-research":0.3887442391,"prompt-eng":0.4297081826,"data-quality":0.1421567342,"ml-security":0.201713604}}
{"text":"Sensor locations are selected to maximize the probability that no targets are missed.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.0597851275,"dev-research":0.4123864489,"prompt-eng":0.419967874,"data-quality":0.1275415638,"ml-security":0.1712043837}}
{"text":"While this objective function is well-suited to applications where failure to detect targets is highly undesirable, it does not lead to a computationally efficient optimization problem.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.030897232,"dev-research":0.3494215952,"prompt-eng":0.3496933107,"data-quality":0.1691926984,"ml-security":0.3065349478}}
{"text":"We propose an approximation of the objective function that is non-negative, submodular, and monotone and for which greedy selection of sensor locations works well.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.1075241098,"dev-research":0.3647441693,"prompt-eng":0.36966542,"data-quality":0.0942390617,"ml-security":0.1184509661}}
{"text":"We also characterize the gap between the desired objective function and our approximation.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.0468765336,"dev-research":0.4108902917,"prompt-eng":0.3683009174,"data-quality":0.1371557798,"ml-security":0.1196994372}}
{"text":"For numerical illustrations, we consider the case of the detection of ship traffic using sensors mounted on the seafloor.","meta":{"url":"http://arxiv.org/abs/2307.04634v1"},"cats":{"new-dataset":0.1348607095,"dev-research":0.3643054233,"prompt-eng":0.3793431026,"data-quality":0.1382147443,"ml-security":0.1804841886}}
{"text":"Remaining Useful Life (RUL) prediction is a critical task that aims to estimate the amount of time until a system fails, where the latter is formed by three main components, that is, the application, communication network, and RUL logic.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.1970102342,"dev-research":0.4274089008,"prompt-eng":0.3895790494,"data-quality":0.0953024675,"ml-security":0.1353841154}}
{"text":"In this paper, we provide an end-to-end analysis of an entire RUL-based chain.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.0847473825,"dev-research":0.4178604715,"prompt-eng":0.3852930307,"data-quality":0.0903588575,"ml-security":0.0897278222}}
{"text":"Specifically, we consider a factory floor where Automated Guided Vehicles (AGVs) transport dangerous liquids whose fall may cause injuries to workers.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.139900052,"dev-research":0.4279553265,"prompt-eng":0.448259911,"data-quality":0.1439160263,"ml-security":0.2408697075}}
{"text":"Regarding the communication infrastructure, the AGVs are equipped with 5G User Equipments (UEs) that collect real-time data of their movements and send them to an application server.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.1511858869,"dev-research":0.4169839943,"prompt-eng":0.4619050611,"data-quality":0.0594250808,"ml-security":0.1148925224}}
{"text":"The RUL logic consists of a Deep Learning (DL)-based pipeline that assesses if there will be liquid falls by analyzing the collected data, and, eventually, sending commands to the AGVs to avoid such a danger.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.1624505959,"dev-research":0.4142687543,"prompt-eng":0.4676888777,"data-quality":0.093978466,"ml-security":0.1665387668}}
{"text":"According to this scenario, we performed End-to-End 5G NR-compliant network simulations to study the Round-Trip Time (RTT) as a function of the overall system bandwidth, subcarrier spacing, and modulation order.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.120143129,"dev-research":0.3951990975,"prompt-eng":0.392720162,"data-quality":0.0692808794,"ml-security":0.0857419115}}
{"text":"Then, via real-world experiments, we collect data to train, test and compare 7 DL models and 1 baseline threshold-based algorithm in terms of cost and average advance.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.0952499959,"dev-research":0.4042629957,"prompt-eng":0.4742500237,"data-quality":0.0811086342,"ml-security":0.1522999455}}
{"text":"Finally, we assess whether or not the RTT provided by four different 5G NR network architectures is compatible with the average advance provided by the best-performing one-Dimensional Convolutional Neural Network (1D-CNN).","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.1092576621,"dev-research":0.3508735207,"prompt-eng":0.4171801539,"data-quality":0.0908932192,"ml-security":0.1051965159}}
{"text":"Numerical results show under which conditions the DL-based approach for RUL estimation matches with the RTT performance provided by different 5G NR network architectures.","meta":{"url":"http://arxiv.org/abs/2307.04632v1"},"cats":{"new-dataset":0.1089822154,"dev-research":0.3680855468,"prompt-eng":0.394034049,"data-quality":0.090060261,"ml-security":0.0787405325}}
{"text":"This paper describes the NPU-MSXF system for the IWSLT 2023 speech-to-speech translation (S2ST) task which aims to translate from English speech of multi-source to Chinese speech.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.3507499891,"dev-research":0.4040583221,"prompt-eng":0.5460475552,"data-quality":0.1514713777,"ml-security":0.0632870638}}
{"text":"The system is built in a cascaded manner consisting of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS).","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.2231807685,"dev-research":0.4026430366,"prompt-eng":0.5577441639,"data-quality":0.1652593113,"ml-security":0.0846116638}}
{"text":"We make tremendous efforts to handle the challenging multi-source input.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.1563318458,"dev-research":0.4495925581,"prompt-eng":0.4919569422,"data-quality":0.1398863945,"ml-security":0.1324038888}}
{"text":"Specifically, to improve the robustness to multi-source speech input, we adopt various data augmentation strategies and a ROVER-based score fusion on multiple ASR model outputs.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.1807054102,"dev-research":0.3764498184,"prompt-eng":0.533402816,"data-quality":0.2636281549,"ml-security":0.154238226}}
{"text":"To better handle the noisy ASR transcripts, we introduce a three-stage fine-tuning strategy to improve translation accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.2528071595,"dev-research":0.4138997318,"prompt-eng":0.5546788101,"data-quality":0.388555684,"ml-security":0.0614816191}}
{"text":"Finally, we build a TTS model with high naturalness and sound quality, which leverages a two-stage framework, using network bottleneck features as a robust intermediate representation for speaker timbre and linguistic content disentanglement.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.1011201155,"dev-research":0.3980017088,"prompt-eng":0.521508787,"data-quality":0.2657950802,"ml-security":0.1297053477}}
{"text":"Based on the two-stage framework, pre-trained speaker embedding is leveraged as a condition to transfer the speaker timbre in the source English speech to the translated Chinese speech.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.1414957098,"dev-research":0.3935203456,"prompt-eng":0.5640210365,"data-quality":0.1961234527,"ml-security":0.1330109073}}
{"text":"Experimental results show that our system has high translation accuracy, speech naturalness, sound quality, and speaker similarity.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.2211146366,"dev-research":0.3869059352,"prompt-eng":0.5363909104,"data-quality":0.2517115593,"ml-security":0.080366165}}
{"text":"Moreover, it shows good robustness to multi-source data.","meta":{"url":"http://arxiv.org/abs/2307.04630v1"},"cats":{"new-dataset":0.3989499448,"dev-research":0.4230334001,"prompt-eng":0.4199960873,"data-quality":0.2462369816,"ml-security":0.3100299039}}
{"text":"In this work, we study two natural generalizations of clique-width introduced by Martin F\\\"urer.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0958882447,"dev-research":0.4159508819,"prompt-eng":0.3770608043,"data-quality":0.122881151,"ml-security":0.1472017616}}
{"text":"Multi-clique-width (mcw) allows every vertex to hold multiple labels","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0676450684,"dev-research":0.3706979748,"prompt-eng":0.4025793589,"data-quality":0.2551686031,"ml-security":0.0789872456}}
{"text":"[ITCS 2017], while for fusion-width (fw) we have a possibility to merge all vertices of a certain label [LATIN 2014].","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.170231597,"dev-research":0.4082436415,"prompt-eng":0.4178325299,"data-quality":0.2003621982,"ml-security":0.068628428}}
{"text":"F\\\"urer has shown that both parameters are upper-bounded by treewidth thus making them more appealing from an algorithmic perspective than clique-width and asked for applications of these parameters for problem solving.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0669179572,"dev-research":0.4532749511,"prompt-eng":0.3591852403,"data-quality":0.1123394238,"ml-security":0.1362750728}}
{"text":"First, we determine the relation between these two parameters by showing that $\\operatorname{mcw} \\leq \\operatorname{fw} +","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0758363866,"dev-research":0.4299293098,"prompt-eng":0.4190560324,"data-quality":0.0927423139,"ml-security":0.1060718891}}
{"text":"1$.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.2604482341,"dev-research":0.4374760984,"prompt-eng":0.4918193864,"data-quality":0.193670725,"ml-security":0.1119101891}}
{"text":"Then we show that when parameterized by multi-clique-width, many problems (e.g., Connected Dominating Set) admit algorithms with the same running time as for clique-width despite the exponential gap between these two parameters.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0599179248,"dev-research":0.4007626105,"prompt-eng":0.3386671537,"data-quality":0.0930431337,"ml-security":0.1818559816}}
{"text":"For some problems (e.g., Hamiltonian Cycle) we show an analogous result for fusion-width: For this we present an alternative view on fusion-width by introducing so-called glue-expressions which might be interesting on their own.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0497015949,"dev-research":0.4098329911,"prompt-eng":0.3516996644,"data-quality":0.0865779896,"ml-security":0.0979582205}}
{"text":"All algorithms obtained in this work are tight up to (Strong) Exponential Time Hypothesis.","meta":{"url":"http://arxiv.org/abs/2307.04628v1"},"cats":{"new-dataset":0.0791304242,"dev-research":0.3657820719,"prompt-eng":0.3343245124,"data-quality":0.0733461775,"ml-security":0.1752396175}}
{"text":"The impact of text length on the estimation of lexical diversity has captured the attention of the scientific community for more than a century.","meta":{"url":"http://arxiv.org/abs/2307.04626v1"},"cats":{"new-dataset":0.2549715868,"dev-research":0.4325253023,"prompt-eng":0.4475246659,"data-quality":0.2978842171,"ml-security":0.0708017675}}
{"text":"Numerous indices have been proposed, and many studies have been conducted to evaluate them, but the problem remains.","meta":{"url":"http://arxiv.org/abs/2307.04626v1"},"cats":{"new-dataset":0.0709615877,"dev-research":0.3910397531,"prompt-eng":0.3689787066,"data-quality":0.0847654028,"ml-security":0.054448786}}
{"text":"This methodological review provides a critical analysis not only of the most commonly used indices in language learning studies, but also of the length problem itself, as well as of the methodology for evaluating the proposed solutions.","meta":{"url":"http://arxiv.org/abs/2307.04626v1"},"cats":{"new-dataset":0.1129478615,"dev-research":0.4290275714,"prompt-eng":0.4230407093,"data-quality":0.2310958124,"ml-security":0.0816283756}}
{"text":"The analysis of three datasets of English language-learners' texts revealed that indices that reduce all texts to the same length using a probabilistic or an algorithmic approach solve the length dependency problem; however, all these indices failed to address the second problem, which is their sensitivity to the parameter that determines the length to which the texts are reduced.","meta":{"url":"http://arxiv.org/abs/2307.04626v1"},"cats":{"new-dataset":0.1950673706,"dev-research":0.42481242,"prompt-eng":0.4358213424,"data-quality":0.2922819004,"ml-security":0.1268109038}}
{"text":"The paper concludes with recommendations for optimizing lexical diversity analysis.","meta":{"url":"http://arxiv.org/abs/2307.04626v1"},"cats":{"new-dataset":0.2122137977,"dev-research":0.4336883416,"prompt-eng":0.4578404107,"data-quality":0.2312195884,"ml-security":0.0695019278}}
{"text":"This work develops a data-efficient learning from demonstration framework which exploits the use of rich tactile sensing and achieves fine dexterous bimanual manipulation.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.1805816745,"dev-research":0.3893818181,"prompt-eng":0.4558560978,"data-quality":0.0687017563,"ml-security":0.1471173214}}
{"text":"Specifically, we formulated a convolutional autoencoder network that can effectively extract and encode high-dimensional tactile information.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.2224445638,"dev-research":0.3753841665,"prompt-eng":0.4745868452,"data-quality":0.0767442203,"ml-security":0.1376030024}}
{"text":"Further, we developed a behaviour cloning network that can learn human-like sensorimotor skills demonstrated directly on the robot hardware in the task space by fusing both proprioceptive and tactile feedback.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.178379612,"dev-research":0.4154999574,"prompt-eng":0.5183991983,"data-quality":0.0841603371,"ml-security":0.2047429089}}
{"text":"Our comparison study with the baseline method revealed the effectiveness of the contact information, which enabled successful extraction and replication of the demonstrated motor skills.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.0827638145,"dev-research":0.3942791815,"prompt-eng":0.4429424944,"data-quality":0.0945604485,"ml-security":0.0866937564}}
{"text":"Extensive experiments on real dual-arm robots demonstrated the robustness and effectiveness of the fine pinch grasp policy directly learned from one-shot demonstration, including grasping of the same object with different initial poses, generalizing to ten unseen new objects, robust and firm grasping against external pushes, as well as contact-aware and reactive re-grasping in case of dropping objects under very large perturbations.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.1352385692,"dev-research":0.3875675873,"prompt-eng":0.4272921644,"data-quality":0.0902180285,"ml-security":0.1528547453}}
{"text":"Moreover, the saliency map method is employed to describe the weight distribution across various modalities during pinch grasping.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.1023074083,"dev-research":0.3719613653,"prompt-eng":0.3744695423,"data-quality":0.073274442,"ml-security":0.0419885681}}
{"text":"The video is available online at: \\href{https://youtu.be/4Pg29bUBKqs}{https://youtu.be/4Pg29bUBKqs}.","meta":{"url":"http://arxiv.org/abs/2307.04619v1"},"cats":{"new-dataset":0.1754447202,"dev-research":0.4073675231,"prompt-eng":0.410868368,"data-quality":0.0992664403,"ml-security":0.0893439799}}
{"text":"Large medical imaging datasets can be cheaply and quickly annotated with low-confidence, weak labels (e.g., radiological scores).","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.4689500174,"dev-research":0.369107846,"prompt-eng":0.4777917782,"data-quality":0.3356302963,"ml-security":0.2303760605}}
{"text":"Access to high-confidence labels, such as histology-based diagnoses, is rare and costly.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.2703316516,"dev-research":0.3741673162,"prompt-eng":0.4575211364,"data-quality":0.2908946578,"ml-security":0.18590249}}
{"text":"Pretraining strategies, like contrastive learning (CL) methods, can leverage unlabeled or weakly-annotated datasets.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.2365720594,"dev-research":0.3943825424,"prompt-eng":0.4997589115,"data-quality":0.3321083545,"ml-security":0.1922951576}}
{"text":"These methods typically require large batch sizes, which poses a difficulty in the case of large 3D images at full resolution, due to limited GPU memory.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.0773215669,"dev-research":0.380681701,"prompt-eng":0.3525774549,"data-quality":0.0754373103,"ml-security":0.068994512}}
{"text":"Nevertheless, volumetric positional information about the spatial context of each 2D slice can be very important for some medical applications.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.1065500343,"dev-research":0.3630727781,"prompt-eng":0.3555037373,"data-quality":0.0537434181,"ml-security":0.0569393888}}
{"text":"In this work, we propose an efficient weakly-supervised positional (WSP) contrastive learning strategy where we integrate both the spatial context of each 2D slice and a weak label via a generic kernel-based loss function.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.1820735309,"dev-research":0.3407178141,"prompt-eng":0.4306205204,"data-quality":0.2110166555,"ml-security":0.1027392199}}
{"text":"We illustrate our method on cirrhosis prediction using a large volume of weakly-labeled images, namely radiological low-confidence annotations, and small strongly-labeled (i.e., high-confidence) datasets.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.4233688435,"dev-research":0.3869935473,"prompt-eng":0.5147334734,"data-quality":0.3577063428,"ml-security":0.1602794651}}
{"text":"The proposed model improves the classification AUC by 5% with respect to a baseline model on our internal dataset, and by 26% on the public LIHC dataset from the Cancer Genome Atlas.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.3431092891,"dev-research":0.3908162108,"prompt-eng":0.4933806585,"data-quality":0.2097107003,"ml-security":0.1742362619}}
{"text":"The code is available at: https://github.com/Guerbet-AI/wsp-contrastive.","meta":{"url":"http://arxiv.org/abs/2307.04617v1"},"cats":{"new-dataset":0.2341626517,"dev-research":0.3968500814,"prompt-eng":0.479763195,"data-quality":0.1322739532,"ml-security":0.0577582494}}
{"text":"Age and gender recognition in the wild is a highly challenging task: apart from the variability of conditions, pose complexities, and varying image quality, there are cases where the face is partially or completely occluded.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.1486783096,"dev-research":0.3528099135,"prompt-eng":0.4264642419,"data-quality":0.1850734172,"ml-security":0.1868064531}}
{"text":"We present MiVOLO (Multi Input VOLO), a straightforward approach for age and gender estimation using the latest vision transformer.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.2677425024,"dev-research":0.3258762001,"prompt-eng":0.4425454826,"data-quality":0.1340823541,"ml-security":0.107139838}}
{"text":"Our method integrates both tasks into a unified dual input/output model, leveraging not only facial information but also person image data.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.2009695773,"dev-research":0.3911782336,"prompt-eng":0.4850667413,"data-quality":0.1198640385,"ml-security":0.1480569325}}
{"text":"This improves the generalization ability of our model and enables it to deliver satisfactory results even when the face is not visible in the image.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.0455988758,"dev-research":0.4078434826,"prompt-eng":0.4374842876,"data-quality":0.1177265061,"ml-security":0.2040651633}}
{"text":"To evaluate our proposed model, we conduct experiments on four popular benchmarks and achieve state-of-the-art performance, while demonstrating real-time processing capabilities.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.1116405761,"dev-research":0.3632871385,"prompt-eng":0.4288039741,"data-quality":0.0608612518,"ml-security":0.0517474474}}
{"text":"Additionally, we introduce a novel benchmark based on images from the Open Images Dataset.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.5177443191,"dev-research":0.3633958255,"prompt-eng":0.4238095674,"data-quality":0.1490059164,"ml-security":0.1032821845}}
{"text":"The ground truth annotations for this benchmark have been meticulously generated by human annotators, resulting in high accuracy answers due to the smart aggregation of votes.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.3130988015,"dev-research":0.4520799162,"prompt-eng":0.5239878647,"data-quality":0.3475574066,"ml-security":0.1373855913}}
{"text":"Furthermore, we compare our model's age recognition performance with human-level accuracy and demonstrate that it significantly outperforms humans across a majority of age ranges.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.2271623444,"dev-research":0.3595188245,"prompt-eng":0.4784119483,"data-quality":0.2289390836,"ml-security":0.1607637928}}
{"text":"Finally, we grant public access to our models, along with the code for validation and inference.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.286474134,"dev-research":0.4440120914,"prompt-eng":0.5143734337,"data-quality":0.1440986448,"ml-security":0.3315186665}}
{"text":"In addition, we provide extra annotations for used datasets and introduce our new benchmark.","meta":{"url":"http://arxiv.org/abs/2307.04616v1"},"cats":{"new-dataset":0.6493058663,"dev-research":0.4544104352,"prompt-eng":0.5087458764,"data-quality":0.3901784809,"ml-security":0.1673955591}}
{"text":"Hypergraphs have emerged as a powerful modeling framework to represent systems with multiway interactions, that is systems where interactions may involve an arbitrary number of agents.","meta":{"url":"http://arxiv.org/abs/2307.04613v1"},"cats":{"new-dataset":0.0906932695,"dev-research":0.4299991244,"prompt-eng":0.4215161682,"data-quality":0.0692660385,"ml-security":0.1025954547}}
{"text":"Here we explore the properties of real-world hypergraphs, focusing on the encapsulation of their hyperedges, which is the extent that smaller hyperedges are subsets of larger hyperedges.","meta":{"url":"http://arxiv.org/abs/2307.04613v1"},"cats":{"new-dataset":0.1278152959,"dev-research":0.4477588755,"prompt-eng":0.3528497336,"data-quality":0.1562918427,"ml-security":0.1277375042}}
{"text":"Building on the concept of line graphs, our measures quantify the relations existing between hyperedges of different sizes and, as a byproduct, the compatibility of the data with a simplicial complex representation -- whose encapsulation would be maximum.","meta":{"url":"http://arxiv.org/abs/2307.04613v1"},"cats":{"new-dataset":0.1798265298,"dev-research":0.4346093862,"prompt-eng":0.3713736302,"data-quality":0.1108806128,"ml-security":0.0665943615}}
{"text":"We then turn to the impact of the observed structural patterns on diffusive dynamics, focusing on a variant of threshold models, called encapsulation dynamics, and demonstrate that non-random patterns can accelerate the spreading in the system.","meta":{"url":"http://arxiv.org/abs/2307.04613v1"},"cats":{"new-dataset":0.0557956324,"dev-research":0.3890155727,"prompt-eng":0.3997934719,"data-quality":0.0815645198,"ml-security":0.2773725295}}
{"text":"Medical image classification is a challenging task due to the scarcity of labeled samples and class imbalance caused by the high variance in disease prevalence.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.2583447238,"dev-research":0.3452341375,"prompt-eng":0.4230580731,"data-quality":0.3228854231,"ml-security":0.2907229609}}
{"text":"Semi-supervised learning (SSL) methods can mitigate these challenges by leveraging both labeled and unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.1923352357,"dev-research":0.3919701657,"prompt-eng":0.4821343248,"data-quality":0.4825137444,"ml-security":0.3440231291}}
{"text":"However, SSL methods for medical image classification need to address two key challenges: (1) estimating reliable pseudo-labels for the images in the unlabeled dataset and (2) reducing biases caused by class imbalance.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.1422565608,"dev-research":0.343261971,"prompt-eng":0.4061693496,"data-quality":0.4335369548,"ml-security":0.429140017}}
{"text":"In this paper, we propose a novel SSL approach, SPLAL, that effectively addresses these challenges.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.1579362774,"dev-research":0.4228458178,"prompt-eng":0.3819451543,"data-quality":0.121757136,"ml-security":0.3528230261}}
{"text":"SPLAL leverages class prototypes and a weighted combination of classifiers to predict reliable pseudo-labels over a subset of unlabeled images.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.1599263704,"dev-research":0.3753501141,"prompt-eng":0.4881493386,"data-quality":0.6083313978,"ml-security":0.2117332189}}
{"text":"Additionally, we introduce alignment loss to mitigate model biases toward majority classes.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.0739061259,"dev-research":0.4081500633,"prompt-eng":0.4973439686,"data-quality":0.3719599454,"ml-security":0.3748408442}}
{"text":"To evaluate the performance of our proposed approach, we conduct experiments on two publicly available medical image classification benchmark datasets: the skin lesion classification (ISIC 2018) and the blood cell classification dataset (BCCD).","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.4732996616,"dev-research":0.3685674706,"prompt-eng":0.3950156774,"data-quality":0.1752078192,"ml-security":0.1700317682}}
{"text":"The experimental results empirically demonstrate that our approach outperforms several state-of-the-art SSL methods over various evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.0881742539,"dev-research":0.4189215864,"prompt-eng":0.4427832062,"data-quality":0.1497718327,"ml-security":0.2217851372}}
{"text":"Specifically, our proposed approach achieves a significant improvement over the state-of-the-art approach on the ISIC 2018 dataset in both Accuracy and F1 score, with relative margins of 2.24\\% and 11.40\\%, respectively.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.4102796321,"dev-research":0.386091145,"prompt-eng":0.4519035801,"data-quality":0.1847847136,"ml-security":0.0663735248}}
{"text":"Finally, we conduct extensive ablation experiments to examine the contribution of different components of our approach, validating its effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.04610v1"},"cats":{"new-dataset":0.0825986849,"dev-research":0.3850224127,"prompt-eng":0.4188333485,"data-quality":0.15050032,"ml-security":0.0531229808}}
{"text":"Local search algorithms are well-known methods for solving large, hard instances of the satisfiability problem (SAT).","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.1212596778,"dev-research":0.3994827077,"prompt-eng":0.3922415967,"data-quality":0.1310725076,"ml-security":0.1409921361}}
{"text":"The performance of these algorithms crucially depends on heuristics for setting noise parameters and scoring variables.","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.0549326338,"dev-research":0.3594674681,"prompt-eng":0.4021673723,"data-quality":0.1753871502,"ml-security":0.1189453603}}
{"text":"The optimal setting for these heuristics varies for different instance distributions.","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.1083737276,"dev-research":0.3659853876,"prompt-eng":0.4311568246,"data-quality":0.1039061464,"ml-security":0.1121851773}}
{"text":"In this paper, we present an approach for learning effective variable scoring functions and noise parameters by using reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.1193591542,"dev-research":0.3980638804,"prompt-eng":0.5117291558,"data-quality":0.1913915477,"ml-security":0.1670239253}}
{"text":"We consider satisfiability problems from different instance distributions and learn specialized heuristics for each of them.","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.1468555546,"dev-research":0.37615436,"prompt-eng":0.4555658549,"data-quality":0.1270452824,"ml-security":0.1467253812}}
{"text":"Our experimental results show improvements with respect to both a WalkSAT baseline and another local search learned heuristic.","meta":{"url":"http://arxiv.org/abs/2307.04608v1"},"cats":{"new-dataset":0.1170337245,"dev-research":0.4142519182,"prompt-eng":0.4517029947,"data-quality":0.1030132761,"ml-security":0.0656933556}}
{"text":"Over 1.5 billion people worldwide live with hearing impairment.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.3046836824,"dev-research":0.3992519118,"prompt-eng":0.4318111043,"data-quality":0.158247635,"ml-security":0.0815967786}}
{"text":"Despite various technologies that have been created for individuals with such disabilities, most of these technologies are either extremely expensive or inaccessible for everyday use in low-medium income countries.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.1101786538,"dev-research":0.3882357106,"prompt-eng":0.3809595672,"data-quality":0.0620454845,"ml-security":0.1780933133}}
{"text":"In order to combat this issue, we have developed a new assistive device, EchoVest, for blind/deaf people to intuitively become more aware of their environment.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.1481061097,"dev-research":0.4335488377,"prompt-eng":0.4875327201,"data-quality":0.1133269186,"ml-security":0.124299428}}
{"text":"EchoVest transmits vibrations to the user's body by utilizing transcutaneous electric nerve stimulation (TENS) based on the source of the sounds.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.1288191695,"dev-research":0.4058254753,"prompt-eng":0.4579757728,"data-quality":0.0913625489,"ml-security":0.1574510841}}
{"text":"EchoVest also provides various features, including sound localization, sound classification, noise reduction, and depth perception.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.2363178435,"dev-research":0.383015433,"prompt-eng":0.4586646818,"data-quality":0.155417655,"ml-security":0.1149798517}}
{"text":"We aimed to outperform CNN-based machine-learning models, the most commonly used machine learning model for classification tasks, in accuracy and computational costs.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.198178296,"dev-research":0.3525682796,"prompt-eng":0.4584548181,"data-quality":0.1950290924,"ml-security":0.2794901849}}
{"text":"To do so, we developed and employed a novel audio pipeline that adapts the Audio Spectrogram Transformer (AST) model, an attention-based model, for our sound classification purposes, and Fast Fourier Transforms for noise reduction.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.1590906358,"dev-research":0.3674008951,"prompt-eng":0.4925197052,"data-quality":0.2187784688,"ml-security":0.100896328}}
{"text":"The application of Otsu's Method helped us find the optimal thresholds for background noise sound filtering and gave us much greater accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.0823921087,"dev-research":0.3944350799,"prompt-eng":0.4001146252,"data-quality":0.1985212766,"ml-security":0.1077082475}}
{"text":"In order to calculate direction and depth accurately, we applied Complex Time Difference of Arrival algorithms and SOTA localization.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.1040434387,"dev-research":0.3480640005,"prompt-eng":0.3571831747,"data-quality":0.0734195214,"ml-security":0.0581082457}}
{"text":"Our last improvement was to use blind source separation to make our algorithms applicable to multiple microphone inputs.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.0847805009,"dev-research":0.3783955769,"prompt-eng":0.4181561699,"data-quality":0.2878654223,"ml-security":0.1719038506}}
{"text":"The final algorithm achieved state-of-the-art results on numerous checkpoints, including a 95.7\\% accuracy on the ESC-50 dataset for environmental sound classification.","meta":{"url":"http://arxiv.org/abs/2307.04604v1"},"cats":{"new-dataset":0.2402996488,"dev-research":0.3552129644,"prompt-eng":0.4537972546,"data-quality":0.3223183633,"ml-security":0.1660791927}}
{"text":"Recent work has explored Large Language Models (LLMs) to overcome the lack of training data for Information Retrieval (IR) tasks.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.1993697955,"dev-research":0.4080829726,"prompt-eng":0.5792127721,"data-quality":0.2047669269,"ml-security":0.1296190495}}
{"text":"The generalization abilities of these models have enabled the creation of synthetic in-domain data by providing instructions and a few examples on a prompt.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.2256222539,"dev-research":0.444616156,"prompt-eng":0.5400705174,"data-quality":0.1130249243,"ml-security":0.2024909975}}
{"text":"InPars and Promptagator have pioneered this approach and both methods have demonstrated the potential of using LLMs as synthetic data generators for IR tasks.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.1772274357,"dev-research":0.4379056299,"prompt-eng":0.5905268028,"data-quality":0.114596423,"ml-security":0.1599579961}}
{"text":"This makes them an attractive solution for IR tasks that suffer from a lack of annotated data.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.2241458883,"dev-research":0.5025108567,"prompt-eng":0.523979526,"data-quality":0.2904970356,"ml-security":0.1394334377}}
{"text":"However, the reproducibility of these methods was limited, because InPars' training scripts are based on TPUs -- which are not widely accessible -- and because the code for Promptagator was not released and its proprietary LLM is not publicly accessible.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.1162950967,"dev-research":0.4507158596,"prompt-eng":0.5789292957,"data-quality":0.1552764195,"ml-security":0.2046666568}}
{"text":"To fully realize the potential of these methods and make their impact more widespread in the research community, the resources need to be accessible and easy to reproduce by researchers and practitioners.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.190799297,"dev-research":0.4830157641,"prompt-eng":0.4535913269,"data-quality":0.1304338495,"ml-security":0.0937056406}}
{"text":"Our main contribution is a unified toolkit for end-to-end reproducible synthetic data generation research, which includes generation, filtering, training and evaluation.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.5535242242,"dev-research":0.4497919588,"prompt-eng":0.5084545294,"data-quality":0.1862298394,"ml-security":0.1525512801}}
{"text":"Additionally, we provide an interface to IR libraries widely used by the community and support for GPU.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.3274922732,"dev-research":0.4557379604,"prompt-eng":0.4926447275,"data-quality":0.0768161389,"ml-security":0.0955371435}}
{"text":"Our toolkit not only reproduces the InPars method and partially reproduces Promptagator, but also provides a plug-and-play functionality allowing the use of different LLMs, exploring filtering methods and finetuning various reranker models on the generated data.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.1875420585,"dev-research":0.4845141864,"prompt-eng":0.6095978539,"data-quality":0.1907579722,"ml-security":0.1610715649}}
{"text":"We also made available all the synthetic data generated in this work for the 18 different datasets in the BEIR benchmark which took more than 2,000 GPU hours to be generated as well as the reranker models finetuned on the synthetic data.","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.5651782769,"dev-research":0.3777118944,"prompt-eng":0.4263072118,"data-quality":0.0720313365,"ml-security":0.0982403601}}
{"text":"Code and data are available at https://github.com/zetaalphavector/InPars","meta":{"url":"http://arxiv.org/abs/2307.04601v1"},"cats":{"new-dataset":0.4984826714,"dev-research":0.3978422116,"prompt-eng":0.4820171045,"data-quality":0.0921461617,"ml-security":0.0765527709}}
{"text":"Objective: This study aims to investigate the existing body of knowledge in the field of Model-Driven Engineering MDE in support of AI (MDE4AI) to sharpen future research further and define the current state of the art.   ","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0624486846,"dev-research":0.4612104586,"prompt-eng":0.4855234761,"data-quality":0.0802115598,"ml-security":0.1156266187}}
{"text":"Method: We conducted a Systemic Literature Review (SLR), collecting papers from five major databases resulting in 703 candidate studies, eventually retaining 15 primary studies.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.158123276,"dev-research":0.4168431238,"prompt-eng":0.414606062,"data-quality":0.1084429065,"ml-security":0.0786621527}}
{"text":"Each primary study will be evaluated and discussed with respect to the adoption of (1) MDE principles and practices and (2) the phases of AI development support aligned with the stages of the CRISP-DM methodology.   ","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0717912932,"dev-research":0.4822138656,"prompt-eng":0.4702199309,"data-quality":0.1028535268,"ml-security":0.1060813713}}
{"text":"Results:","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.3390451721,"dev-research":0.4429688198,"prompt-eng":0.4419211306,"data-quality":0.2110089253,"ml-security":0.0788170628}}
{"text":"The study's findings show that the pillar concepts of MDE (metamodel, concrete syntax and model transformation), are leveraged to define domain-specific languages (DSL) explicitly addressing AI concerns.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0559521003,"dev-research":0.494902523,"prompt-eng":0.5026856037,"data-quality":0.1256302908,"ml-security":0.1431413453}}
{"text":"Different MDE technologies are used, leveraging different language workbenches.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0723449269,"dev-research":0.501879595,"prompt-eng":0.4899972799,"data-quality":0.1141985596,"ml-security":0.0664422965}}
{"text":"The most prominent AI-related concerns are training and modeling of the AI algorithm, while minor emphasis is given to the time-consuming preparation of the data sets.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.1514588665,"dev-research":0.4542769855,"prompt-eng":0.4338825533,"data-quality":0.1336462664,"ml-security":0.235131659}}
{"text":"Early project phases that support interdisciplinary communication of requirements, such as the CRISP-DM \\textit{Business Understanding} phase, are rarely reflected.   ","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.1294709016,"dev-research":0.4718151667,"prompt-eng":0.4834881843,"data-quality":0.1531495802,"ml-security":0.0735792839}}
{"text":"Conclusion: The study found that the use of MDE for AI is still in its early stages, and there is no single tool or method that is widely used.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0421111681,"dev-research":0.4554808518,"prompt-eng":0.4378675135,"data-quality":0.0891041724,"ml-security":0.1008478308}}
{"text":"Additionally, current approaches tend to focus on specific stages of development rather than providing support for the entire development process.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0470030267,"dev-research":0.5368820765,"prompt-eng":0.3810689857,"data-quality":0.0620116998,"ml-security":0.0886940335}}
{"text":"As a result, the study suggests several research directions to further improve the use of MDE for AI and to guide future research in this area.","meta":{"url":"http://arxiv.org/abs/2307.04599v1"},"cats":{"new-dataset":0.0550075183,"dev-research":0.4721535669,"prompt-eng":0.4718409553,"data-quality":0.0870828719,"ml-security":0.098702431}}
{"text":"There is a strong incentive to develop computational pathology models to i) ease the burden of tissue typology annotation from whole slide histological images; ii) transfer knowledge, e.g., tissue class separability from the withheld source domain to the distributionally shifted unlabeled target domain, and simultaneously iii) detect Open Set samples, i.e., unseen novel categories not present in the training source domain.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.2466854079,"dev-research":0.3908685686,"prompt-eng":0.448115989,"data-quality":0.2347769174,"ml-security":0.1943185941}}
{"text":"This paper proposes a highly practical setting by addressing the abovementioned challenges in one fell swoop, i.e., source-free Open Set domain adaptation (SF-OSDA), which addresses the situation where a model pre-trained on the inaccessible source dataset can be adapted on the unlabeled target dataset containing Open Set samples.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.4817639523,"dev-research":0.4099343242,"prompt-eng":0.4852676119,"data-quality":0.2691650265,"ml-security":0.3528508634}}
{"text":"The central tenet of our proposed method is distilling knowledge from a self-supervised vision transformer trained in the target domain.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.1438884047,"dev-research":0.3943673436,"prompt-eng":0.4716607516,"data-quality":0.2258792506,"ml-security":0.1801287409}}
{"text":"We propose a novel style-based data augmentation used as hard positives for self-training a vision transformer in the target domain, yielding strongly contextualized embedding.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.1254924437,"dev-research":0.404828043,"prompt-eng":0.5049229863,"data-quality":0.3051385097,"ml-security":0.1844394951}}
{"text":"Subsequently, semantically similar target images are clustered while the source model provides their corresponding weak pseudo-labels with unreliable confidence.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.1291467984,"dev-research":0.4042071146,"prompt-eng":0.5139603312,"data-quality":0.614830062,"ml-security":0.1793353455}}
{"text":"Furthermore, we propose cluster relative maximum logit score (CRMLS) to rectify the confidence of the weak pseudo-labels and compute weighted class prototypes in the contextualized embedding space that are utilized for adapting the source model on the target domain.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.1550886287,"dev-research":0.4260969467,"prompt-eng":0.5571632037,"data-quality":0.438726342,"ml-security":0.1807527918}}
{"text":"Our method significantly outperforms the previous methods, including open set detection, test-time adaptation, and SF-OSDA methods, setting the new state-of-the-art on three public histopathological datasets of colorectal cancer (CRC) assessment-","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.5349927238,"dev-research":0.3737057378,"prompt-eng":0.4483134123,"data-quality":0.133027932,"ml-security":0.1198876931}}
{"text":"Kather-16, Kather-19, and CRCTP.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.4276531372,"dev-research":0.3724503677,"prompt-eng":0.4374023847,"data-quality":0.096447025,"ml-security":0.0993525811}}
{"text":"Our code is available at https://github.com/LTS5/Proto-SF-OSDA.","meta":{"url":"http://arxiv.org/abs/2307.04596v1"},"cats":{"new-dataset":0.4071870025,"dev-research":0.4373932866,"prompt-eng":0.4891300029,"data-quality":0.1002936715,"ml-security":0.0964336002}}
{"text":"\\textit{Pursuit-evasion games} have been intensively studied for several decades due to their numerous applications in artificial intelligence, robot motion planning, database theory, distributed computing, and algorithmic theory.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1324141174,"dev-research":0.3990267794,"prompt-eng":0.4093237484,"data-quality":0.0762749669,"ml-security":0.299351695}}
{"text":"\\textsc{Cops and Robber} (\\CR) is one of the most well-known pursuit-evasion games played on graphs, where multiple \\textit{cops} pursue a single \\textit{robber}.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.2706085869,"dev-research":0.427018157,"prompt-eng":0.4176298857,"data-quality":0.2346761957,"ml-security":0.4136757185}}
{"text":"The aim is to compute the \\textit{cop number} of a graph, $k$, which is the minimum number of cops that ensures the \\textit{capture} of the robber.   ","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1957956082,"dev-research":0.4266417434,"prompt-eng":0.3366877715,"data-quality":0.1435924316,"ml-security":0.3402332051}}
{"text":"From the viewpoint of parameterized complexity, \\CR is W[2]-hard parameterized by $k$~[Fomin et al., TCS, 2010].","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.0616304759,"dev-research":0.4077314223,"prompt-eng":0.3780449889,"data-quality":0.1089153113,"ml-security":0.1303676356}}
{"text":"Thus, we study structural parameters of the input graph.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.0737725757,"dev-research":0.4101942442,"prompt-eng":0.4087587493,"data-quality":0.1194749232,"ml-security":0.1184754544}}
{"text":"We begin with the \\textit{vertex cover number} ($\\mathsf{vcn}$).","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1190377563,"dev-research":0.4295585282,"prompt-eng":0.4116463929,"data-quality":0.1083362466,"ml-security":0.1182311151}}
{"text":"First, we establish that $k \\leq \\frac{\\mathsf{vcn}}{3}+1$.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1962619626,"dev-research":0.403974678,"prompt-eng":0.3918803126,"data-quality":0.141714979,"ml-security":0.1641203348}}
{"text":"Second, we prove that \\CR parameterized by $\\mathsf{vcn}$ is \\FPT by designing an exponential kernel.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.077666155,"dev-research":0.4003913997,"prompt-eng":0.4184039192,"data-quality":0.1218060415,"ml-security":0.2123822927}}
{"text":"We complement this result by showing that it is unlikely for \\CR parameterized by $\\mathsf{vcn}$ to admit a polynomial compression.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.0950031782,"dev-research":0.408974372,"prompt-eng":0.3996902961,"data-quality":0.2120763579,"ml-security":0.2217482684}}
{"text":"We extend our exponential kernels to the parameters \\textit{cluster vertex deletion number} and \\textit{deletion to stars number}, and design a linear vertex kernel for \\textit{neighborhood diversity}.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1722303654,"dev-research":0.3977737605,"prompt-eng":0.3947526062,"data-quality":0.1964035735,"ml-security":0.1492049473}}
{"text":"Additionally, we extend all of our results to several well-studied variations of \\CR.","meta":{"url":"http://arxiv.org/abs/2307.04594v1"},"cats":{"new-dataset":0.1197893059,"dev-research":0.429912855,"prompt-eng":0.4460044248,"data-quality":0.2458366692,"ml-security":0.0798754538}}
{"text":"We propose a novel abstraction of the image segmentation task in the form of a combinatorial optimization problem that we call the multi-separator problem.","meta":{"url":"http://arxiv.org/abs/2307.04592v1"},"cats":{"new-dataset":0.1351086296,"dev-research":0.3726940725,"prompt-eng":0.3889836484,"data-quality":0.1608873456,"ml-security":0.0706685689}}
{"text":"Feasible solutions indicate for every pixel whether it belongs to a segment or a segment separator, and indicate for pairs of pixels whether or not the pixels belong to the same segment.","meta":{"url":"http://arxiv.org/abs/2307.04592v1"},"cats":{"new-dataset":0.0773927956,"dev-research":0.4216774574,"prompt-eng":0.3775057778,"data-quality":0.1416612999,"ml-security":0.0862769622}}
{"text":"This is in contrast to the closely related lifted multicut problem where every pixel is associated to a segment and no pixel explicitly represents a separating structure.","meta":{"url":"http://arxiv.org/abs/2307.04592v1"},"cats":{"new-dataset":0.0599360247,"dev-research":0.393009677,"prompt-eng":0.3645105034,"data-quality":0.1281896969,"ml-security":0.0645927077}}
{"text":"While the multi-separator problem is NP-hard, we identify two special cases for which it can be solved efficiently.","meta":{"url":"http://arxiv.org/abs/2307.04592v1"},"cats":{"new-dataset":0.1138351567,"dev-research":0.3988064228,"prompt-eng":0.3607132043,"data-quality":0.144973776,"ml-security":0.1163821606}}
{"text":"Moreover, we define two local search algorithms for the general case and demonstrate their effectiveness in segmenting simulated volume images of foam cells and filaments.","meta":{"url":"http://arxiv.org/abs/2307.04592v1"},"cats":{"new-dataset":0.0822407067,"dev-research":0.3370805729,"prompt-eng":0.3852323071,"data-quality":0.1519888321,"ml-security":0.0726828022}}
{"text":"A graph $G$ is \\emph{locally irregular} if no two of its adjacent vertices have the same degree.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.1149679412,"dev-research":0.4101106464,"prompt-eng":0.4062235765,"data-quality":0.2339117162,"ml-security":0.0842410565}}
{"text":"In [Fioravantes et al. Complexity of finding maximum locally irregular induced subgraph.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.106848752,"dev-research":0.4146236715,"prompt-eng":0.323903486,"data-quality":0.2050240805,"ml-security":0.0982838751}}
{"text":"{\\it SWAT}, 2022], the authors introduced and studied the problem of finding a locally irregular induced subgraph of a given a graph $G$ of maximum order, or, equivalently, computing a subset $S$ of $V(G)$ of minimum order, whose deletion from $G$ results in a locally irregular graph; $S$ is denoted as an \\emph{optimal vertex-irregulator of $G$}.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.071715735,"dev-research":0.4147284595,"prompt-eng":0.3529881226,"data-quality":0.2116445277,"ml-security":0.1017771948}}
{"text":"In this work we provide an in-depth analysis of the parameterised complexity of computing an optimal vertex-irregulator of a given graph $G$.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.0382594927,"dev-research":0.3937799983,"prompt-eng":0.352968635,"data-quality":0.0928737669,"ml-security":0.1388229485}}
{"text":"Moreover, we introduce and study a variation of this problem, where $S$ is a substet of the edges of $G$; in this case, $S$ is denoted as an \\emph{optimal edge-irregulator of $G$}.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.0388735214,"dev-research":0.3838989901,"prompt-eng":0.3701679074,"data-quality":0.0981576334,"ml-security":0.128935459}}
{"text":"In particular, we prove that computing an optimal vertex-irregulator of a graph $G$ is in FPT when parameterised by the vertex integrity, neighborhood diversity or cluster deletion number of $G$, while it is $W[1]$-hard when parameterised by the feedback vertex set number or the treedepth of $G$.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.0358743374,"dev-research":0.393132273,"prompt-eng":0.3962574839,"data-quality":0.1977244873,"ml-security":0.1815918977}}
{"text":"In the case of computing an optimal edge-irregulator of a graph $G$, we prove that this problem is in FPT when parameterised by the vertex integrity of $G$, while it is NP-hard even if $G$ is a planar bipartite graph of maximum degree $4$, and $W[1]$-hard when parameterised by the size of the solution, the feedback vertex set or the treedepth of $G$. Our results paint a comprehensive picture of the tractability of both problems studied here, considering most of the standard graph-structural parameters.","meta":{"url":"http://arxiv.org/abs/2307.04583v1"},"cats":{"new-dataset":0.0354589159,"dev-research":0.3973429575,"prompt-eng":0.365286225,"data-quality":0.1436394206,"ml-security":0.1603715738}}
{"text":"Vision-based teleoperation offers the possibility to endow robots with human-level intelligence to physically interact with the environment, while only requiring low-cost camera sensors.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.1427046456,"dev-research":0.4206308249,"prompt-eng":0.4747095247,"data-quality":0.0484126708,"ml-security":0.0794497702}}
{"text":"However, current vision-based teleoperation systems are designed and engineered towards a particular robot model and deploy environment, which scales poorly as the pool of the robot models expands and the variety of the operating environment increases.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.0844686826,"dev-research":0.4216450242,"prompt-eng":0.4589653269,"data-quality":0.0524913722,"ml-security":0.0836897838}}
{"text":"In this paper, we propose AnyTeleop, a unified and general teleoperation system to support multiple different arms, hands, realities, and camera configurations within a single system.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.1331792624,"dev-research":0.3827755046,"prompt-eng":0.4299832305,"data-quality":0.0396587806,"ml-security":0.0512957651}}
{"text":"Although being designed to provide great flexibility to the choice of simulators and real hardware, our system can still achieve great performance.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.1373776027,"dev-research":0.423546205,"prompt-eng":0.3981942349,"data-quality":0.0559394261,"ml-security":0.1442369977}}
{"text":"For real-world experiments, AnyTeleop can outperform a previous system that was designed for a specific robot hardware with a higher success rate, using the same robot.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.111009371,"dev-research":0.3958815337,"prompt-eng":0.4363498913,"data-quality":0.0835765652,"ml-security":0.094628706}}
{"text":"For teleoperation in simulation, AnyTeleop leads to better imitation learning performance, compared with a previous system that is particularly designed for that simulator.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.1155818079,"dev-research":0.4000198283,"prompt-eng":0.4620934612,"data-quality":0.055959053,"ml-security":0.0833301695}}
{"text":"Project page: http://anyteleop.com/.","meta":{"url":"http://arxiv.org/abs/2307.04577v1"},"cats":{"new-dataset":0.4854834758,"dev-research":0.4490379517,"prompt-eng":0.4459159682,"data-quality":0.0851798541,"ml-security":0.0986793564}}
{"text":"Texture is an essential information in image representation, capturing patterns and structures.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.2029780875,"dev-research":0.4067165146,"prompt-eng":0.3856949367,"data-quality":0.1561611723,"ml-security":0.0755300166}}
{"text":"As a result, texture plays a crucial role in the manufacturing industry and is extensively studied in the fields of computer vision and pattern recognition.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.1397328403,"dev-research":0.4046718589,"prompt-eng":0.3735568548,"data-quality":0.1618683746,"ml-security":0.0713861509}}
{"text":"However, real-world textures are susceptible to defects, which can degrade image quality and cause various issues.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.0751830976,"dev-research":0.4135504292,"prompt-eng":0.3902016746,"data-quality":0.3859232419,"ml-security":0.1526228398}}
{"text":"Therefore, there is a need for accurate and effective methods to detect texture defects.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.0585342901,"dev-research":0.4245715995,"prompt-eng":0.3849392349,"data-quality":0.3591465069,"ml-security":0.1019932607}}
{"text":"In this study, a simple autoencoder and Fourier transform are employed for texture defect detection.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.128571982,"dev-research":0.400020833,"prompt-eng":0.4230593252,"data-quality":0.4046356887,"ml-security":0.1228222635}}
{"text":"The proposed method combines Fourier transform analysis with the reconstructed template obtained from the simple autoencoder.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.1399464207,"dev-research":0.3734877014,"prompt-eng":0.4321555822,"data-quality":0.1437802749,"ml-security":0.096131227}}
{"text":"Fourier transform is a powerful tool for analyzing the frequency domain of images and signals.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.1475984523,"dev-research":0.3710020555,"prompt-eng":0.3778352922,"data-quality":0.1064712512,"ml-security":0.0769986376}}
{"text":"Moreover, since texture defects often exhibit characteristic changes in specific frequency ranges, analyzing the frequency domain enables effective defect detection.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.0850529502,"dev-research":0.4057178981,"prompt-eng":0.4163970627,"data-quality":0.3918154487,"ml-security":0.1024515968}}
{"text":"The proposed method demonstrates effectiveness and accuracy in detecting texture defects.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.0942025008,"dev-research":0.4167614958,"prompt-eng":0.4085635342,"data-quality":0.4845932043,"ml-security":0.0991837672}}
{"text":"Experimental results are presented to evaluate its performance and compare it with existing approaches.","meta":{"url":"http://arxiv.org/abs/2307.04574v1"},"cats":{"new-dataset":0.0644682775,"dev-research":0.4168381138,"prompt-eng":0.4161396721,"data-quality":0.1165431421,"ml-security":0.0517880622}}
{"text":"In today's vast literature landscape, a manual review is very time-consuming.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.1273010521,"dev-research":0.4428124976,"prompt-eng":0.4541721661,"data-quality":0.0990906326,"ml-security":0.0480730603}}
{"text":"To address this challenge, this paper proposes a semi-automated tool for solution method review and selection.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.0945946181,"dev-research":0.531254503,"prompt-eng":0.4794640409,"data-quality":0.1570885912,"ml-security":0.0488952222}}
{"text":"It caters to researchers, practitioners, and decision-makers while serving as a benchmark for future work.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.1072555484,"dev-research":0.4808614614,"prompt-eng":0.3786349439,"data-quality":0.0535354053,"ml-security":0.0870166249}}
{"text":"The tool comprises three modules: (1) paper selection and scoring, using a keyword selection scheme to query Scopus API and compute relevancy; (2) solution method extraction in papers utilizing OpenAI API; (3) sensitivity analysis and post-analyzes.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.1678562489,"dev-research":0.4452459911,"prompt-eng":0.4501246355,"data-quality":0.1268170528,"ml-security":0.0486672974}}
{"text":"It reveals trends, relevant papers, and methods.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.1071068197,"dev-research":0.4580974725,"prompt-eng":0.4075934267,"data-quality":0.0972672891,"ml-security":0.1003662068}}
{"text":"AI in the oncology case study and several use cases are presented with promising results, comparing the tool to manual ground truth.","meta":{"url":"http://arxiv.org/abs/2307.04573v1"},"cats":{"new-dataset":0.1649146217,"dev-research":0.4238019627,"prompt-eng":0.4369865236,"data-quality":0.1283567408,"ml-security":0.1483486326}}
{"text":"Offline reinforcement learning (RL), a technology that offline learns a policy from logged data without the need to interact with online environments, has become a favorable choice in decision-making processes like interactive recommendation.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.1319693271,"dev-research":0.4201910955,"prompt-eng":0.4664977327,"data-quality":0.0741646808,"ml-security":0.1613780381}}
{"text":"Offline RL faces the value overestimation problem.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.1668369592,"dev-research":0.3880047846,"prompt-eng":0.4036385056,"data-quality":0.1796676486,"ml-security":0.2124987463}}
{"text":"To address it, existing methods employ conservatism, e.g., by constraining the learned policy to be close to behavior policies or punishing the rarely visited state-action pairs.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.038509076,"dev-research":0.4294156556,"prompt-eng":0.390628608,"data-quality":0.1143130736,"ml-security":0.2245442304}}
{"text":"However, when applying such offline RL to recommendation, it will cause a severe Matthew effect, i.e., the rich get richer and the poor get poorer, by promoting popular items or categories while suppressing the less popular ones.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.0799704019,"dev-research":0.4232189479,"prompt-eng":0.4435990343,"data-quality":0.1521621638,"ml-security":0.1608488173}}
{"text":"It is a notorious issue that needs to be addressed in practical recommender systems.   ","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.097569643,"dev-research":0.4479291451,"prompt-eng":0.40721911,"data-quality":0.2254141642,"ml-security":0.2470558547}}
{"text":"In this paper, we aim to alleviate the Matthew effect in offline RL-based recommendation.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.15135211,"dev-research":0.4271252106,"prompt-eng":0.4920371272,"data-quality":0.114327867,"ml-security":0.1319287266}}
{"text":"Through theoretical analyses, we find that the conservatism of existing methods fails in pursuing users' long-term satisfaction.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.051996804,"dev-research":0.4382317583,"prompt-eng":0.3518019563,"data-quality":0.0997574551,"ml-security":0.0732243047}}
{"text":"It inspires us to add a penalty term to relax the pessimism on states with high entropy of the logging policy and indirectly penalizes actions leading to less diverse states.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.0310791541,"dev-research":0.4632264824,"prompt-eng":0.4024877078,"data-quality":0.1328383742,"ml-security":0.2290256159}}
{"text":"This leads to the main technical contribution of the work: Debiased model-based Offline RL (DORL) method.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.0906517041,"dev-research":0.4075588828,"prompt-eng":0.4343727848,"data-quality":0.0728195897,"ml-security":0.087501168}}
{"text":"Experiments show that DORL not only captures user interests well but also alleviates the Matthew effect.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.0864449088,"dev-research":0.468391223,"prompt-eng":0.4875700814,"data-quality":0.0840990302,"ml-security":0.14827647}}
{"text":"The implementation is available via https://github.com/chongminggao/DORL-codes.","meta":{"url":"http://arxiv.org/abs/2307.04571v1"},"cats":{"new-dataset":0.2105612193,"dev-research":0.4332503597,"prompt-eng":0.4901960695,"data-quality":0.0881513218,"ml-security":0.0881235391}}
{"text":"Comparing different age estimation methods poses a challenge due to the unreliability of published results, stemming from inconsistencies in the benchmarking process.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.223609369,"dev-research":0.3782601709,"prompt-eng":0.3701120616,"data-quality":0.1932152703,"ml-security":0.1141726383}}
{"text":"Previous studies have reported continuous performance improvements over the past decade using specialized methods; however, our findings challenge these claims.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.0433923282,"dev-research":0.4104314458,"prompt-eng":0.3987019505,"data-quality":0.1028921159,"ml-security":0.0564200429}}
{"text":"We argue that, for age estimation tasks outside of the low-data regime, designing specialized methods is unnecessary, and the standard approach of utilizing cross-entropy loss is sufficient.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.2436728385,"dev-research":0.3610503904,"prompt-eng":0.4153508523,"data-quality":0.1190820728,"ml-security":0.1767675657}}
{"text":"This paper aims to address the benchmark shortcomings by evaluating state-of-the-art age estimation methods in a unified and comparable setting.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.3144852506,"dev-research":0.3746949408,"prompt-eng":0.3704622457,"data-quality":0.1415485502,"ml-security":0.1196337431}}
{"text":"We systematically analyze the impact of various factors, including facial alignment, facial coverage, image resolution, image representation, model architecture, and the amount of data on age estimation results.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.2580312815,"dev-research":0.3900735901,"prompt-eng":0.4150753341,"data-quality":0.1069084711,"ml-security":0.1376003824}}
{"text":"Surprisingly, these factors often exert a more significant influence than the choice of the age estimation method itself.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.0941799783,"dev-research":0.4197317595,"prompt-eng":0.3846095974,"data-quality":0.1046345227,"ml-security":0.1239382425}}
{"text":"We assess the generalization capability of each method by evaluating the cross-dataset performance for publicly available age estimation datasets.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.4744651241,"dev-research":0.3700244714,"prompt-eng":0.4248862598,"data-quality":0.1446705105,"ml-security":0.2110271129}}
{"text":"The results emphasize the importance of using consistent data preprocessing practices and establishing standardized benchmarks to ensure reliable and meaningful comparisons.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.1851506784,"dev-research":0.4390027489,"prompt-eng":0.4485246132,"data-quality":0.2021744384,"ml-security":0.0692128834}}
{"text":"The source code is available at https://github.com/paplhjak/Facial-Age-Estimation-Benchmark.","meta":{"url":"http://arxiv.org/abs/2307.04570v1"},"cats":{"new-dataset":0.4050800629,"dev-research":0.4030492315,"prompt-eng":0.3942505869,"data-quality":0.0936043246,"ml-security":0.0986867983}}
{"text":"Although deep learning has achieved remarkable success in various scientific machine learning applications, its black-box nature poses concerns regarding interpretability and generalization capabilities beyond the training data.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.1287458563,"dev-research":0.379880362,"prompt-eng":0.4073290797,"data-quality":0.2237060022,"ml-security":0.313628141}}
{"text":"Interpretability is crucial and often desired in modeling physical systems.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.0681537217,"dev-research":0.4212326297,"prompt-eng":0.4197946573,"data-quality":0.1330109115,"ml-security":0.1460205497}}
{"text":"Moreover, acquiring extensive datasets that encompass the entire range of input features is challenging in many physics-based learning tasks, leading to increased errors when encountering out-of-distribution (OOD) data.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.3880852397,"dev-research":0.3302136333,"prompt-eng":0.4486818334,"data-quality":0.1716873309,"ml-security":0.2154636835}}
{"text":"In this work, motivated by the field of functional data analysis (FDA), we propose generalized functional linear models as an interpretable surrogate for a trained deep learning model.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.1917435652,"dev-research":0.3594431468,"prompt-eng":0.4241256165,"data-quality":0.1200899659,"ml-security":0.2777101832}}
{"text":"We demonstrate that our model could be trained either based on a trained neural network (post-hoc interpretation) or directly from training data (interpretable operator learning).","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.152881588,"dev-research":0.4024569679,"prompt-eng":0.5463941091,"data-quality":0.1830490185,"ml-security":0.2021433575}}
{"text":"A library of generalized functional linear models with different kernel functions is considered and sparse regression is used to discover an interpretable surrogate model that could be analytically presented.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.1262127386,"dev-research":0.373857445,"prompt-eng":0.4473826168,"data-quality":0.109116791,"ml-security":0.1670985861}}
{"text":"We present test cases in solid mechanics, fluid mechanics, and transport.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.1172465871,"dev-research":0.4059793094,"prompt-eng":0.4153051456,"data-quality":0.1058770555,"ml-security":0.0968382323}}
{"text":"Our results demonstrate that our model can achieve comparable accuracy to deep learning and can improve OOD generalization while providing more transparency and interpretability.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.2443800612,"dev-research":0.3895008598,"prompt-eng":0.4991334009,"data-quality":0.2153820227,"ml-security":0.2212056769}}
{"text":"Our study underscores the significance of interpretability in scientific machine learning and showcases the potential of functional linear models as a tool for interpreting and generalizing deep learning.","meta":{"url":"http://arxiv.org/abs/2307.04569v1"},"cats":{"new-dataset":0.1201726121,"dev-research":0.4086090618,"prompt-eng":0.4295999269,"data-quality":0.2700680972,"ml-security":0.2213455298}}
{"text":"Objective: The NEX project has developed an integrated Internet of Things (IoT) system coupled with data analytics to offer unobtrusive health and wellness monitoring supporting older adults living independently at home.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.4048698825,"dev-research":0.3997800506,"prompt-eng":0.4108730658,"data-quality":0.0725825903,"ml-security":0.0897089003}}
{"text":"Monitoring {currently} involves visualising a set of automatically detected activities of daily living (ADLs) for each participant.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.2656893165,"dev-research":0.4386167026,"prompt-eng":0.4399810819,"data-quality":0.0912840782,"ml-security":0.0755664597}}
{"text":"The detection of ADLs is achieved {} to allow the incorporation of additional participants whose ADLs are detected without re-training the system.   ","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.0276032603,"dev-research":0.444546496,"prompt-eng":0.4679415212,"data-quality":0.1896306004,"ml-security":0.3428553443}}
{"text":"Methods: Following an extensive User Needs and Requirements study involving 426 participants, a pilot trial and a friendly trial of the deployment, an Action Research Cycle (ARC) trial was completed.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.1392793397,"dev-research":0.442160093,"prompt-eng":0.4533001664,"data-quality":0.0469932118,"ml-security":0.0590841331}}
{"text":"This involved 23 participants over a 10-week period each with c.20 IoT sensors in their homes.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.2954994088,"dev-research":0.3980364969,"prompt-eng":0.4454153819,"data-quality":0.0541536681,"ml-security":0.1351678496}}
{"text":"During the ARC trial, participants each took part in two data-informed briefings which presented visualisations of their own in-home activities.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.3592826976,"dev-research":0.4538785967,"prompt-eng":0.4918380877,"data-quality":0.0882998598,"ml-security":0.095702918}}
{"text":"The briefings also gathered training data on the accuracy of detected activities.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.3267686928,"dev-research":0.4064129845,"prompt-eng":0.5075831829,"data-quality":0.2161327012,"ml-security":0.141101654}}
{"text":"Association rule mining was then used on the combination of data from sensors and participant feedback to improve the automatic detection of ADLs.   ","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.1192480276,"dev-research":0.4525631632,"prompt-eng":0.5064561277,"data-quality":0.2827717594,"ml-security":0.2418030816}}
{"text":"Results: Association rule mining was used to detect a range of ADLs for each participant independently of others and was then used to detect ADLs across participants using a single set of rules {for each ADL}.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.1129286714,"dev-research":0.4507904326,"prompt-eng":0.4728261843,"data-quality":0.1821429555,"ml-security":0.1994650208}}
{"text":"This allows additional participants to be added without the necessity of them providing training data.   ","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.1141022502,"dev-research":0.4488020209,"prompt-eng":0.4358663364,"data-quality":0.0929675274,"ml-security":0.2778985914}}
{"text":"Conclusions: Additional participants can be added to the NEX system without the necessity to re-train the system for automatic detection of the set of their activities of daily living.","meta":{"url":"http://arxiv.org/abs/2307.04563v1"},"cats":{"new-dataset":0.1464618315,"dev-research":0.4088480902,"prompt-eng":0.4349067109,"data-quality":0.1075912165,"ml-security":0.0941525179}}
{"text":"This work presents an experimental evaluation of the detection performance of eight different algorithms for anomaly detection on the Controller Area Network (CAN) bus of modern vehicles based on the analysis of the timing or frequency of CAN messages.","meta":{"url":"http://arxiv.org/abs/2307.04561v1"},"cats":{"new-dataset":0.0842230686,"dev-research":0.42362851,"prompt-eng":0.4138535792,"data-quality":0.2492826899,"ml-security":0.2707071724}}
{"text":"This work solves the current limitations of related scientific literature, that is based on private dataset, lacks of open implementations, and detailed description of the detection algorithms.","meta":{"url":"http://arxiv.org/abs/2307.04561v1"},"cats":{"new-dataset":0.5030542274,"dev-research":0.372003669,"prompt-eng":0.3892520528,"data-quality":0.2134521963,"ml-security":0.393384165}}
{"text":"These drawback prevent the reproducibility of published results, and makes it impossible to compare a novel proposal against related work, thus hindering the advancement of science.","meta":{"url":"http://arxiv.org/abs/2307.04561v1"},"cats":{"new-dataset":0.0544419938,"dev-research":0.4488854066,"prompt-eng":0.3507060178,"data-quality":0.1908847555,"ml-security":0.1858952518}}
{"text":"This paper solves these issues by publicly releasing implementations, labeled datasets and by describing an unbiased experimental comparisons.","meta":{"url":"http://arxiv.org/abs/2307.04561v1"},"cats":{"new-dataset":0.5080019933,"dev-research":0.4514586321,"prompt-eng":0.4700517055,"data-quality":0.3488238303,"ml-security":0.3131840655}}
{"text":"Recent advances in deep neural networks have achieved unprecedented success in visual speech recognition.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.1441989244,"dev-research":0.3426508864,"prompt-eng":0.4451765455,"data-quality":0.1735543952,"ml-security":0.176066527}}
{"text":"However, there remains substantial disparity between current methods and their deployment in resource-constrained devices.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.0490942704,"dev-research":0.4486806213,"prompt-eng":0.3976273558,"data-quality":0.094265593,"ml-security":0.108364829}}
{"text":"In this work, we explore different magnitude-based pruning techniques to generate a lightweight model that achieves higher performance than its dense model equivalent, especially under the presence of visual noise.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.067869178,"dev-research":0.4003238737,"prompt-eng":0.4312996253,"data-quality":0.1386945579,"ml-security":0.170761213}}
{"text":"Our sparse models achieve state-of-the-art results at 10% sparsity on the LRS3 dataset and outperform the dense equivalent up to 70% sparsity.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.2175433483,"dev-research":0.3318879991,"prompt-eng":0.4661418237,"data-quality":0.1779694992,"ml-security":0.1346365683}}
{"text":"We evaluate our 50% sparse model on 7 different visual noise types and achieve an overall absolute improvement of more than 2% WER compared to the dense equivalent.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.1188515207,"dev-research":0.3674300994,"prompt-eng":0.4678365583,"data-quality":0.262553357,"ml-security":0.0933105496}}
{"text":"Our results confirm that sparse networks are more resistant to noise than dense networks.","meta":{"url":"http://arxiv.org/abs/2307.04552v1"},"cats":{"new-dataset":0.0799594909,"dev-research":0.3781205523,"prompt-eng":0.3920132798,"data-quality":0.2874378897,"ml-security":0.4091200657}}
{"text":"Research on the convergence of gaming and gambling has been around since the 1990s.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.1138603135,"dev-research":0.3970958318,"prompt-eng":0.3693673459,"data-quality":0.0813502626,"ml-security":0.0859742216}}
{"text":"The emergence of loot boxes in video games in the mid 2010s, a game mechanic with a chance-based outcome that shares structural and psychological similarities to gambling, caused public controversy and lead to the inception of a new field of study, loot box research.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.2466019753,"dev-research":0.4429576943,"prompt-eng":0.4085604127,"data-quality":0.0987994291,"ml-security":0.2199502798}}
{"text":"Since then, various studies have found a relationship between loot box engagement and problem gambling as well as problem gaming.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.146218949,"dev-research":0.438964491,"prompt-eng":0.3723470487,"data-quality":0.109453427,"ml-security":0.1432477037}}
{"text":"Due to the cross-sectional nature of this data, however, inferences about causality are limited.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.2182997967,"dev-research":0.3956864839,"prompt-eng":0.4069561127,"data-quality":0.0690911835,"ml-security":0.1294633363}}
{"text":"While loot box research has extensively investigated the relationship between loot box engagement and problem behaviour, little research has been done to explain the underlying motivations of players that drive them to interact with loot boxes.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.1234147397,"dev-research":0.482857872,"prompt-eng":0.4254629193,"data-quality":0.0873657061,"ml-security":0.1685066271}}
{"text":"The goal of this thesis is to provide possible explanations for the relationship between loot box engagement and problem gamblers or problem gamers.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.2149572414,"dev-research":0.4490570536,"prompt-eng":0.3739173374,"data-quality":0.0972345941,"ml-security":0.199629381}}
{"text":"In doing so, it draws upon two prominent psychological theories.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0381622488,"dev-research":0.4736586217,"prompt-eng":0.4076622775,"data-quality":0.0928348911,"ml-security":0.1384364335}}
{"text":"Self-Determination Theory and the Dualistic Model of Passion.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0742716667,"dev-research":0.4180892141,"prompt-eng":0.3794741792,"data-quality":0.0760829261,"ml-security":0.0587194991}}
{"text":"Self-Determination Theory's concept of psychological needs and their satisfaction or frustration is hereby used to explain the development of harmonious or obsessive passions, which are introduced in the Dualistic Model of Passion.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0512774807,"dev-research":0.4441010946,"prompt-eng":0.4147385585,"data-quality":0.1061571134,"ml-security":0.0622654692}}
{"text":"These obsessive passions have been shown to be possible antecedents of behavioural addictions, such as problem gambling or problem gaming.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0865770603,"dev-research":0.4359278752,"prompt-eng":0.4037691052,"data-quality":0.1295555222,"ml-security":0.1580659137}}
{"text":"Thus, the interplay between needs, passions and loot box opening could elucidate the aforementioned correlations between loot box engagement and problem behaviour.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0883826446,"dev-research":0.4674646166,"prompt-eng":0.4245304798,"data-quality":0.0774996358,"ml-security":0.0992043956}}
{"text":"However, further research, especially utilising longitudinal data, is needed to better understand these processes.","meta":{"url":"http://arxiv.org/abs/2307.04549v1"},"cats":{"new-dataset":0.0792682349,"dev-research":0.4424457523,"prompt-eng":0.4055536247,"data-quality":0.0930064697,"ml-security":0.0609446961}}
{"text":"We consider networks of processes that all execute the same finite-state protocol and communicate via a rendez-vous mechanism.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0635877102,"dev-research":0.3748571315,"prompt-eng":0.4421075806,"data-quality":0.0612250782,"ml-security":0.166981844}}
{"text":"When a process requests a rendez-vous, another process can respond to it and they both change their control states accordingly.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0356185139,"dev-research":0.4195525966,"prompt-eng":0.4855732461,"data-quality":0.076653821,"ml-security":0.1115974604}}
{"text":"We focus here on a specific semantics, called non-blocking, where the process requesting a rendez-vous can change its state even if no process can respond to it.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0357602071,"dev-research":0.433820916,"prompt-eng":0.4357990528,"data-quality":0.1128213296,"ml-security":0.2154429075}}
{"text":"In this context, we study the parameterised coverability problem of a configuration, which consists in determining whether there is an initialnumber of processes and an execution allowing to reach a configuration bigger than a given one.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0880848859,"dev-research":0.4627260645,"prompt-eng":0.4025586421,"data-quality":0.0990646059,"ml-security":0.1872747495}}
{"text":"We show that this problem is EXPSPACE-complete and can be solved in polynomial time if the protocol is partitioned into two sets of states, the states from which a process can request a rendez-vous and the ones from which it can answer one.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0706041962,"dev-research":0.3866014909,"prompt-eng":0.4300281333,"data-quality":0.0712819131,"ml-security":0.1578109972}}
{"text":"We also prove that the problem of the existence of an execution bringing all the processes in a final state is undecidable in our context.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0516652381,"dev-research":0.4535653824,"prompt-eng":0.393389362,"data-quality":0.1405451073,"ml-security":0.2518565039}}
{"text":"These two problems can be solved in polynomial time with the classical rendez-vous semantics.","meta":{"url":"http://arxiv.org/abs/2307.04546v1"},"cats":{"new-dataset":0.0575004908,"dev-research":0.4048178424,"prompt-eng":0.4235314461,"data-quality":0.1397844407,"ml-security":0.1309028571}}
{"text":"Data-free knowledge distillation (DFKD) aims to obtain a lightweight student model without original training data.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.3072784946,"dev-research":0.4024950202,"prompt-eng":0.4733933788,"data-quality":0.0947502291,"ml-security":0.2417371677}}
{"text":"Existing works generally synthesize data from the pre-trained teacher model to replace the original training data for student learning.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.2601426851,"dev-research":0.4598350115,"prompt-eng":0.5089228692,"data-quality":0.1432890767,"ml-security":0.3017349347}}
{"text":"To more effectively train the student model, the synthetic data shall be customized to the current student learning ability.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.3597122,"dev-research":0.4327947719,"prompt-eng":0.4651895228,"data-quality":0.1023182635,"ml-security":0.3058097054}}
{"text":"However, this is ignored in the existing DFKD methods and thus negatively affects the student training.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.0564003489,"dev-research":0.4099068998,"prompt-eng":0.3954341433,"data-quality":0.2006169558,"ml-security":0.2698064388}}
{"text":"To address this issue, we propose Customizing Synthetic Data for Data-Free Student Learning (CSD) in this paper, which achieves adaptive data synthesis using a self-supervised augmented auxiliary task to estimate the student learning ability.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.4124324102,"dev-research":0.4570980476,"prompt-eng":0.5025809447,"data-quality":0.1575639923,"ml-security":0.2549693378}}
{"text":"Specifically, data synthesis is dynamically adjusted to enlarge the cross entropy between the labels and the predictions from the self-supervised augmented task, thus generating hard samples for the student model.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.1425530279,"dev-research":0.4691100924,"prompt-eng":0.5408124683,"data-quality":0.2154591069,"ml-security":0.2047884164}}
{"text":"The experiments on various datasets and teacher-student models show the effectiveness of our proposed method.","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.2871718078,"dev-research":0.4056270729,"prompt-eng":0.487624498,"data-quality":0.1438205685,"ml-security":0.2203949383}}
{"text":"Code is available at: $\\href{https://github.com/luoshiya/CSD}{https://github.com/luoshiya/CSD}$","meta":{"url":"http://arxiv.org/abs/2307.04542v1"},"cats":{"new-dataset":0.1315572413,"dev-research":0.4409701916,"prompt-eng":0.4424593292,"data-quality":0.1415814025,"ml-security":0.117826418}}
{"text":"Fueled by deep learning, computer-aided diagnosis achieves huge advances.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.1107199601,"dev-research":0.4068992869,"prompt-eng":0.4731577439,"data-quality":0.1572685107,"ml-security":0.2792816887}}
{"text":"However, out of controlled lab environments, algorithms could face multiple challenges.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.099746703,"dev-research":0.4427124567,"prompt-eng":0.4047278345,"data-quality":0.1024469173,"ml-security":0.2301417146}}
{"text":"Open set recognition (OSR), as an important one, states that categories unseen in training could appear in testing.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.1666818512,"dev-research":0.422436469,"prompt-eng":0.4448113449,"data-quality":0.2093307933,"ml-security":0.2624721639}}
{"text":"In medical fields, it could derive from incompletely collected training datasets and the constantly emerging new or rare diseases.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.3359458523,"dev-research":0.419903626,"prompt-eng":0.4201433661,"data-quality":0.2442918333,"ml-security":0.3662801509}}
{"text":"OSR requires an algorithm to not only correctly classify known classes, but also recognize unknown classes and forward them to experts for further diagnosis.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.0863045659,"dev-research":0.4336451394,"prompt-eng":0.445928012,"data-quality":0.2626919475,"ml-security":0.2982251958}}
{"text":"To tackle OSR, we assume that known classes could densely occupy small parts of the embedding space and the remaining sparse regions could be recognized as unknowns.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.1215380831,"dev-research":0.3948321926,"prompt-eng":0.4328529394,"data-quality":0.2046009334,"ml-security":0.3025715457}}
{"text":"Following it, we propose Open Margin Cosine Loss (OMCL) unifying two mechanisms.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.0343070023,"dev-research":0.3878344705,"prompt-eng":0.3788835185,"data-quality":0.1317818513,"ml-security":0.1185731716}}
{"text":"The former, called Margin Loss with Adaptive Scale (MLAS), introduces angular margin for reinforcing intra-class compactness and inter-class separability, together with an adaptive scaling factor to strengthen the generalization capacity.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.0428442898,"dev-research":0.3744193552,"prompt-eng":0.4010926849,"data-quality":0.1632105069,"ml-security":0.1151203765}}
{"text":"The latter, called Open-Space Suppression (OSS), opens the classifier by recognizing sparse embedding space as unknowns using proposed feature space descriptors.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.0879058993,"dev-research":0.4044610015,"prompt-eng":0.4089782383,"data-quality":0.2813576224,"ml-security":0.3786729976}}
{"text":"Besides, since medical OSR is still a nascent field, two publicly available benchmark datasets are proposed for comparison.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.4926191963,"dev-research":0.3667695921,"prompt-eng":0.3983990698,"data-quality":0.0724343247,"ml-security":0.1153491888}}
{"text":"Extensive ablation studies and feature visualization demonstrate the effectiveness of each design.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.1248797455,"dev-research":0.3893250279,"prompt-eng":0.4019249965,"data-quality":0.0883777557,"ml-security":0.0466754654}}
{"text":"Compared with state-of-the-art methods, MLAS achieves superior performances, measured by ACC, AUROC, and OSCR.","meta":{"url":"http://arxiv.org/abs/2307.04541v1"},"cats":{"new-dataset":0.0686897624,"dev-research":0.3935706349,"prompt-eng":0.4622237833,"data-quality":0.2090967901,"ml-security":0.0840939907}}
{"text":"In this work, we present an efficient and quantization-aware panoptic driving perception model (Q- YOLOP) for object detection, drivable area segmentation, and lane line segmentation, in the context of autonomous driving.","meta":{"url":"http://arxiv.org/abs/2307.04537v1"},"cats":{"new-dataset":0.1293560044,"dev-research":0.3507742502,"prompt-eng":0.435476486,"data-quality":0.1218751559,"ml-security":0.1290048028}}
{"text":"Our model employs the Efficient Layer Aggregation Network (ELAN) as its backbone and task-specific heads for each task.","meta":{"url":"http://arxiv.org/abs/2307.04537v1"},"cats":{"new-dataset":0.1197302314,"dev-research":0.4072803383,"prompt-eng":0.4213093005,"data-quality":0.0453192619,"ml-security":0.083007347}}
{"text":"We employ a four-stage training process that includes pretraining on the BDD100K dataset, finetuning on both the BDD100K and iVS datasets, and quantization-aware training (QAT) on BDD100K. During the training process, we use powerful data augmentation techniques, such as random perspective and mosaic, and train the model on a combination of the BDD100K and iVS datasets.","meta":{"url":"http://arxiv.org/abs/2307.04537v1"},"cats":{"new-dataset":0.3119853941,"dev-research":0.3622620611,"prompt-eng":0.4921554694,"data-quality":0.1661187388,"ml-security":0.2076396394}}
{"text":"Both strategies enhance the model's generalization capabilities.","meta":{"url":"http://arxiv.org/abs/2307.04537v1"},"cats":{"new-dataset":0.0221865313,"dev-research":0.4335174085,"prompt-eng":0.4392082552,"data-quality":0.0651214328,"ml-security":0.1779713063}}
{"text":"The proposed model achieves state-of-the-art performance with an mAP@0.5 of 0.622 for object detection and an mIoU of 0.612 for segmentation, while maintaining low computational and memory requirements.","meta":{"url":"http://arxiv.org/abs/2307.04537v1"},"cats":{"new-dataset":0.2019097861,"dev-research":0.3272470104,"prompt-eng":0.4147290654,"data-quality":0.1449668565,"ml-security":0.113110494}}
{"text":"In this experience report, we apply deep active learning to the field of design optimization to reduce the number of computationally expensive numerical simulations.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.0971609029,"dev-research":0.3930475973,"prompt-eng":0.4210162562,"data-quality":0.0626060996,"ml-security":0.237436223}}
{"text":"We are interested in optimizing the design of structural components, where the shape is described by a set of parameters.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.0664312234,"dev-research":0.3763641141,"prompt-eng":0.3752731598,"data-quality":0.040762587,"ml-security":0.087014738}}
{"text":"If we can predict the performance based on these parameters and consider only the promising candidates for simulation, there is an enormous potential for saving computing power.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.0810085949,"dev-research":0.3934110549,"prompt-eng":0.4018343006,"data-quality":0.0417203523,"ml-security":0.1662103826}}
{"text":"We present two selection strategies for self-optimization to reduce the computational cost in multi-objective design optimization problems.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.0524749066,"dev-research":0.4016560033,"prompt-eng":0.3869048426,"data-quality":0.0578224796,"ml-security":0.1199202316}}
{"text":"Our proposed methodology provides an intuitive approach that is easy to apply, offers significant improvements over random sampling, and circumvents the need for uncertainty estimation.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.133490918,"dev-research":0.3670114198,"prompt-eng":0.4602336603,"data-quality":0.2793520381,"ml-security":0.1460681165}}
{"text":"We evaluate our strategies on a large dataset from the domain of fluid dynamics and introduce two new evaluation metrics to determine the model's performance.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.284776669,"dev-research":0.3638283714,"prompt-eng":0.4407427907,"data-quality":0.0790785232,"ml-security":0.0903210547}}
{"text":"Findings from our evaluation highlights the effectiveness of our selection strategies in accelerating design optimization.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.0294583286,"dev-research":0.4542612489,"prompt-eng":0.416184865,"data-quality":0.0468540791,"ml-security":0.1231439121}}
{"text":"We believe that the introduced method is easily transferable to other self-optimization problems.","meta":{"url":"http://arxiv.org/abs/2307.04536v1"},"cats":{"new-dataset":0.037409316,"dev-research":0.4395839863,"prompt-eng":0.371153507,"data-quality":0.1018160238,"ml-security":0.1513600129}}
{"text":"Quantizing neural networks is one of the most effective methods for achieving efficient inference on mobile and embedded devices.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0972759332,"dev-research":0.3814297312,"prompt-eng":0.438993278,"data-quality":0.0841336636,"ml-security":0.2203423941}}
{"text":"In particular, mixed precision quantized (MPQ) networks, whose layers can be quantized to different bitwidths, achieve better task performance for the same resource constraint compared to networks with homogeneous bitwidths.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0508940403,"dev-research":0.3764282277,"prompt-eng":0.3294871463,"data-quality":0.0897356505,"ml-security":0.1479258074}}
{"text":"However, finding the optimal bitwidth allocation is a challenging problem as the search space grows exponentially with the number of layers in the network.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0800191297,"dev-research":0.3977026389,"prompt-eng":0.3194462061,"data-quality":0.0660410586,"ml-security":0.1925351236}}
{"text":"In this paper, we propose QBitOpt, a novel algorithm for updating bitwidths during quantization-aware training (QAT).","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.1000422486,"dev-research":0.4159069519,"prompt-eng":0.4022475655,"data-quality":0.1320550801,"ml-security":0.1884702806}}
{"text":"We formulate the bitwidth allocation problem as a constraint optimization problem.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0944243412,"dev-research":0.4247864316,"prompt-eng":0.3413731312,"data-quality":0.091685992,"ml-security":0.1380065109}}
{"text":"By combining fast-to-compute sensitivities with efficient solvers during QAT, QBitOpt can produce mixed-precision networks with high task performance guaranteed to satisfy strict resource constraints.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0596099556,"dev-research":0.4067342457,"prompt-eng":0.4068395515,"data-quality":0.0722505216,"ml-security":0.1433128305}}
{"text":"This contrasts with existing mixed-precision methods that learn bitwidths using gradients and cannot provide such guarantees.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.0613841704,"dev-research":0.3806913411,"prompt-eng":0.3221767233,"data-quality":0.1738115372,"ml-security":0.1181666451}}
{"text":"We evaluate QBitOpt on ImageNet and confirm that we outperform existing fixed and mixed-precision methods under average bitwidth constraints commonly found in the literature.","meta":{"url":"http://arxiv.org/abs/2307.04535v1"},"cats":{"new-dataset":0.1107086389,"dev-research":0.3934449013,"prompt-eng":0.3676332594,"data-quality":0.1256181574,"ml-security":0.1311252642}}
{"text":"The ability to detect learned objects regardless of their appearance is crucial for autonomous systems in real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.0995327307,"dev-research":0.3898798981,"prompt-eng":0.4303879711,"data-quality":0.1712397172,"ml-security":0.2509679114}}
{"text":"Especially for detecting humans, which is often a fundamental task in safety-critical applications, it is vital to prevent errors.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.0756139924,"dev-research":0.4284506623,"prompt-eng":0.4272641548,"data-quality":0.3096147402,"ml-security":0.2868083476}}
{"text":"To address this challenge, we propose a self-monitoring framework that allows for the perception system to perform plausibility checks at runtime.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.1641388421,"dev-research":0.4047184641,"prompt-eng":0.477655792,"data-quality":0.274968791,"ml-security":0.2918134402}}
{"text":"We show that by incorporating an additional component for detecting human body parts, we are able to significantly reduce the number of missed human detections by factors of up to 9 when compared to a baseline setup, which was trained only on holistic person objects.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.1373219943,"dev-research":0.3731248014,"prompt-eng":0.4746152475,"data-quality":0.1814960787,"ml-security":0.1190347204}}
{"text":"Additionally, we found that training a model jointly on humans and their body parts leads to a substantial reduction in false positive detections by up to 50% compared to training on humans alone.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.0677654153,"dev-research":0.3812280061,"prompt-eng":0.4732219047,"data-quality":0.2764359031,"ml-security":0.425597227}}
{"text":"We performed comprehensive experiments on the publicly available datasets DensePose and Pascal VOC in order to demonstrate the effectiveness of our framework.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.3736894949,"dev-research":0.3496112413,"prompt-eng":0.4243784282,"data-quality":0.1743337936,"ml-security":0.1519518442}}
{"text":"Code is available at https://github.com/ FraunhoferIKS/smf-object-detection.","meta":{"url":"http://arxiv.org/abs/2307.04533v1"},"cats":{"new-dataset":0.2931061244,"dev-research":0.3791742119,"prompt-eng":0.4367584338,"data-quality":0.2239776855,"ml-security":0.1019895567}}
{"text":"The fine approach to measure information dependence is based on the total conditional complexity CT(y|x), which is defined as the minimal length of a total program that outputs y on the input x.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0949585218,"dev-research":0.4802122325,"prompt-eng":0.409766249,"data-quality":0.1543079551,"ml-security":0.1964276058}}
{"text":"It is known that the total conditional complexity can be much larger than than the plain conditional complexity.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0357086121,"dev-research":0.4524810669,"prompt-eng":0.3407699173,"data-quality":0.0703539101,"ml-security":0.1455563633}}
{"text":"Such strings x, y are defined by means of a diagonal argument and are not otherwise interesting.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.2097617819,"dev-research":0.4451409258,"prompt-eng":0.4162132896,"data-quality":0.1720913292,"ml-security":0.1570283446}}
{"text":"In this paper we investigate whether this happens also for some natural objects.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0627570707,"dev-research":0.4041007807,"prompt-eng":0.3897827638,"data-quality":0.2281594272,"ml-security":0.1444884046}}
{"text":"More specifically, we consider the following objects: the number of strings of complexity less than n and the lex first string of length n and complexity at least n.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.1191443722,"dev-research":0.4580933126,"prompt-eng":0.378392137,"data-quality":0.1999145514,"ml-security":0.0870722775}}
{"text":"It is known that they have negligible mutual conditional complexities.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0394421441,"dev-research":0.4047232971,"prompt-eng":0.3668436783,"data-quality":0.1251037038,"ml-security":0.1203737634}}
{"text":"In this paper we prove that their mutual total conditional complexities may be large.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0959532623,"dev-research":0.4183149276,"prompt-eng":0.4283531345,"data-quality":0.1099907815,"ml-security":0.121261832}}
{"text":"This is the first example of natural objects whose plain conditional complexity is much less than the total one.","meta":{"url":"http://arxiv.org/abs/2307.04530v1"},"cats":{"new-dataset":0.0726143222,"dev-research":0.4413324303,"prompt-eng":0.3614691965,"data-quality":0.114086705,"ml-security":0.1636183069}}
{"text":"Cloud virtual reality (VR) has emerged as a promising technology, offering users a highly immersive and easily accessible experience.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.1854314663,"dev-research":0.3877828819,"prompt-eng":0.3822611006,"data-quality":0.0540952218,"ml-security":0.1212406001}}
{"text":"However, the current 5G radio access network faces challenges in accommodating the bursty traffic generated by multiple cloudVR flows simultaneously, leading to congestion at the 5G base station and increased delays.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.0881982019,"dev-research":0.3975898601,"prompt-eng":0.3973984597,"data-quality":0.081663115,"ml-security":0.1527601426}}
{"text":"In this research, we present a comprehensive quantitative analysis that highlights the underlying causes for the poor delay performance of cloudVR flows within the existing 5G protocol stack and network.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.0955910213,"dev-research":0.3911987178,"prompt-eng":0.3809683734,"data-quality":0.0718936019,"ml-security":0.1118400425}}
{"text":"To address these issues, we propose a novel cross-layer informationassisted congestion control mechanism deployed in the 5G edge network.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.116972299,"dev-research":0.4114864011,"prompt-eng":0.3924526527,"data-quality":0.1030243333,"ml-security":0.2415496761}}
{"text":"Experiment results show that our mechanism enhances the number of concurrent flows meeting delay standards by 1.5x to 2.5x, while maintaining a smooth network load.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.0474055896,"dev-research":0.414307079,"prompt-eng":0.3707924115,"data-quality":0.0706077116,"ml-security":0.1045073388}}
{"text":"These findings underscore the potential of leveraging 5G edge nodes as a valuable resource to effectively meet the anticipated demands of future services.","meta":{"url":"http://arxiv.org/abs/2307.04529v1"},"cats":{"new-dataset":0.0681861772,"dev-research":0.417993804,"prompt-eng":0.3747999397,"data-quality":0.0708026691,"ml-security":0.1173093413}}
{"text":"The results of training a neural network are heavily dependent on the architecture chosen; and even a modification of only the size of the network, however small, typically involves restarting the training process.","meta":{"url":"http://arxiv.org/abs/2307.04526v1"},"cats":{"new-dataset":0.0280735925,"dev-research":0.4277917406,"prompt-eng":0.4007324255,"data-quality":0.1313869001,"ml-security":0.202601469}}
{"text":"In contrast to this, we begin training with a small architecture, only increase its capacity as necessary for the problem, and avoid interfering with previous optimization while doing so.","meta":{"url":"http://arxiv.org/abs/2307.04526v1"},"cats":{"new-dataset":0.0240957306,"dev-research":0.4090732303,"prompt-eng":0.3758888545,"data-quality":0.0692431638,"ml-security":0.2460814382}}
{"text":"We thereby introduce a natural gradient based approach which intuitively expands both the width and depth of a neural network when this is likely to substantially reduce the hypothetical converged training loss.","meta":{"url":"http://arxiv.org/abs/2307.04526v1"},"cats":{"new-dataset":0.0295462706,"dev-research":0.3952629686,"prompt-eng":0.3790001172,"data-quality":0.1438609536,"ml-security":0.3591890259}}
{"text":"We prove an upper bound on the \"rate\" at which neurons are added, and a computationally cheap lower bound on the expansion score.","meta":{"url":"http://arxiv.org/abs/2307.04526v1"},"cats":{"new-dataset":0.0571992591,"dev-research":0.4321984624,"prompt-eng":0.3699014966,"data-quality":0.1254698359,"ml-security":0.1841273982}}
{"text":"We illustrate the benefits of such Self-Expanding Neural Networks in both classification and regression problems, including those where the appropriate architecture size is substantially uncertain a priori.","meta":{"url":"http://arxiv.org/abs/2307.04526v1"},"cats":{"new-dataset":0.0500696149,"dev-research":0.3870287972,"prompt-eng":0.4080787406,"data-quality":0.2053666329,"ml-security":0.3082385006}}
{"text":"SfM (Structure from Motion) has been extensively used for UAV (Unmanned Aerial Vehicle) image orientation.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.1400818176,"dev-research":0.3917410838,"prompt-eng":0.4249503667,"data-quality":0.0473887831,"ml-security":0.0659414624}}
{"text":"Its efficiency is directly influenced by feature matching.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.0385238949,"dev-research":0.4304649087,"prompt-eng":0.3949039517,"data-quality":0.1171486785,"ml-security":0.0839121684}}
{"text":"Although image retrieval has been extensively used for match pair selection, high computational costs are consumed due to a large number of local features and the large size of the used codebook.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.2538200901,"dev-research":0.4055079622,"prompt-eng":0.4025032389,"data-quality":0.0883681661,"ml-security":0.0973701756}}
{"text":"Thus, this paper proposes an efficient match pair retrieval method and implements an integrated workflow for parallel SfM reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.2926145678,"dev-research":0.3655945132,"prompt-eng":0.4364942508,"data-quality":0.0770114995,"ml-security":0.0598301622}}
{"text":"First, an individual codebook is trained online by considering the redundancy of UAV images and local features, which avoids the ambiguity of training codebooks from other datasets.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.3093746059,"dev-research":0.4672399478,"prompt-eng":0.4357773508,"data-quality":0.1152285229,"ml-security":0.2128090743}}
{"text":"Second, local features of each image are aggregated into a single high-dimension global descriptor through the VLAD (Vector of Locally Aggregated Descriptors) aggregation by using the trained codebook, which remarkably reduces the number of features and the burden of nearest neighbor searching in image indexing.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.2856897198,"dev-research":0.4067311167,"prompt-eng":0.4172095706,"data-quality":0.1381499538,"ml-security":0.0860371692}}
{"text":"Third, the global descriptors are indexed via the HNSW (Hierarchical Navigable Small World) based graph structure for the nearest neighbor searching.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.2493299754,"dev-research":0.4108804007,"prompt-eng":0.393122959,"data-quality":0.1040765685,"ml-security":0.0749312406}}
{"text":"Match pairs are then retrieved by using an adaptive threshold selection strategy and utilized to create a view graph for divide-and-conquer based parallel SfM reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.270681355,"dev-research":0.3441323695,"prompt-eng":0.4398041356,"data-quality":0.0726257344,"ml-security":0.0789961906}}
{"text":"Finally, the performance of the proposed solution has been verified using three large-scale UAV datasets.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.350632756,"dev-research":0.3482101788,"prompt-eng":0.3863343448,"data-quality":0.0608014079,"ml-security":0.1666461502}}
{"text":"The test results demonstrate that the proposed solution accelerates match pair retrieval with a speedup ratio ranging from 36 to 108 and improves the efficiency of SfM reconstruction with competitive accuracy in both relative and absolute orientation.","meta":{"url":"http://arxiv.org/abs/2307.04520v1"},"cats":{"new-dataset":0.2181420111,"dev-research":0.330683075,"prompt-eng":0.4155088236,"data-quality":0.0843097648,"ml-security":0.0582574903}}
{"text":"This document chronicles this author's attempt to explore how words come to mean what they do, with a particular focus on child language acquisition and what that means for models of language understanding.\\footnote{I say \\emph{historical} because I synthesize the ideas based on when I discovered them and how those ideas influenced my later thinking.}","meta":{"url":"http://arxiv.org/abs/2307.04518v1"},"cats":{"new-dataset":0.2285943808,"dev-research":0.4775401206,"prompt-eng":0.4875968641,"data-quality":0.2089060727,"ml-security":0.084689241}}
{"text":"I explain the setting for child language learning, how embodiment -- being able to perceive and enact in the world, including knowledge of concrete and abstract concepts -- is crucial, and how emotion and cognition relate to each other and the language learning process.","meta":{"url":"http://arxiv.org/abs/2307.04518v1"},"cats":{"new-dataset":0.2282031563,"dev-research":0.472396967,"prompt-eng":0.4644919415,"data-quality":0.1240376093,"ml-security":0.0916955675}}
{"text":"I end with what I think are some of the requirements for a language-learning agent that learns language in a setting similar to that of children.","meta":{"url":"http://arxiv.org/abs/2307.04518v1"},"cats":{"new-dataset":0.2518966593,"dev-research":0.4405727399,"prompt-eng":0.5033858852,"data-quality":0.1349962847,"ml-security":0.1131712675}}
{"text":"This paper can act as a potential guide for ongoing and future work in modeling language.","meta":{"url":"http://arxiv.org/abs/2307.04518v1"},"cats":{"new-dataset":0.1516370057,"dev-research":0.4441807481,"prompt-eng":0.5424829507,"data-quality":0.1628619453,"ml-security":0.0763795934}}
{"text":"Wearable sensors such as Inertial Measurement Units (IMUs) are often used to assess the performance of human exercise.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.1625752258,"dev-research":0.3793484789,"prompt-eng":0.4062103108,"data-quality":0.0881776269,"ml-security":0.066354968}}
{"text":"Common approaches use handcrafted features based on domain expertise or automatically extracted features using time series analysis.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.2214249782,"dev-research":0.4484424251,"prompt-eng":0.4442292117,"data-quality":0.0965484572,"ml-security":0.0918494875}}
{"text":"Multiple sensors are required to achieve high classification accuracy, which is not very practical.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.0657612552,"dev-research":0.336728823,"prompt-eng":0.3842401929,"data-quality":0.1640592232,"ml-security":0.1807652854}}
{"text":"These sensors require calibration and synchronization and may lead to discomfort over longer time periods.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.0911895247,"dev-research":0.3834937842,"prompt-eng":0.3864018275,"data-quality":0.1734124415,"ml-security":0.1765020258}}
{"text":"Recent work utilizing computer vision techniques has shown similar performance using video, without the need for manual feature engineering, and avoiding some pitfalls such as sensor calibration and placement on the body.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.0957495981,"dev-research":0.4011220521,"prompt-eng":0.3834933134,"data-quality":0.1127515263,"ml-security":0.0677819956}}
{"text":"In this paper, we compare the performance of IMUs to a video-based approach for human exercise classification on two real-world datasets consisting of Military Press and Rowing exercises.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.3845406808,"dev-research":0.3455618504,"prompt-eng":0.4500093562,"data-quality":0.1449020908,"ml-security":0.1414454625}}
{"text":"We compare the performance using a single camera that captures video in the frontal view versus using 5 IMUs placed on different parts of the body.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.1224100559,"dev-research":0.3656374877,"prompt-eng":0.3807383741,"data-quality":0.0685380912,"ml-security":0.0562012629}}
{"text":"We observe that an approach based on a single camera can outperform a single IMU by 10 percentage points on average.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.0855780903,"dev-research":0.3597895967,"prompt-eng":0.4264335966,"data-quality":0.1319815874,"ml-security":0.0701869256}}
{"text":"Additionally, a minimum of 3 IMUs are required to outperform a single camera.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.0997392906,"dev-research":0.3680071873,"prompt-eng":0.3948095948,"data-quality":0.125726893,"ml-security":0.0615707695}}
{"text":"We observe that working with the raw data using multivariate time series classifiers outperforms traditional approaches based on handcrafted or automatically extracted features.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.2922137378,"dev-research":0.3828433567,"prompt-eng":0.4291323631,"data-quality":0.1691167325,"ml-security":0.1935457375}}
{"text":"Finally, we show that an ensemble model combining the data from a single camera with a single IMU outperforms either data modality.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.2824998232,"dev-research":0.342376299,"prompt-eng":0.4915720067,"data-quality":0.2056568729,"ml-security":0.08459571}}
{"text":"Our work opens up new and more realistic avenues for this application, where a video captured using a readily available smartphone camera, combined with a single sensor, can be used for effective human exercise classification.","meta":{"url":"http://arxiv.org/abs/2307.04516v1"},"cats":{"new-dataset":0.3169378883,"dev-research":0.3646906378,"prompt-eng":0.4190667323,"data-quality":0.1099889437,"ml-security":0.146216492}}
{"text":"The analysis of building models for usable area, building safety, and energy use requires accurate classification data of spaces and space elements.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.159596038,"dev-research":0.4066791392,"prompt-eng":0.4103438617,"data-quality":0.1403853049,"ml-security":0.1654834753}}
{"text":"To reduce input model preparation effort and errors, automated classification of spaces and space elements is desirable.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.0752752078,"dev-research":0.4291498187,"prompt-eng":0.4998631561,"data-quality":0.2445775006,"ml-security":0.1216528557}}
{"text":"A barrier hindering the utilization of Graph Deep Learning (GDL) methods to space function and space element classification is a lack of suitable datasets.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.1660562592,"dev-research":0.3528374467,"prompt-eng":0.3755192144,"data-quality":0.1975063895,"ml-security":0.2238019132}}
{"text":"To bridge this gap, we introduce a dataset, SAGC-A68, which comprises access graphs automatically generated from 68 digital 3D models of space layouts of apartment buildings.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.5786290591,"dev-research":0.4114818875,"prompt-eng":0.4147576804,"data-quality":0.0818046153,"ml-security":0.1271694395}}
{"text":"This graph-based dataset is well-suited for developing GDL models for space function and space element classification.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.2558875327,"dev-research":0.3617020372,"prompt-eng":0.4260168393,"data-quality":0.1299806614,"ml-security":0.0944899337}}
{"text":"To demonstrate the potential of the dataset, we employ it to train and evaluate a graph attention network (GAT) that predicts 22 space function and 6 space element classes.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.2893972684,"dev-research":0.3955573733,"prompt-eng":0.4732270613,"data-quality":0.1504970035,"ml-security":0.1150603263}}
{"text":"The dataset and code used in the experiment are available online.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.7903359402,"dev-research":0.4390507584,"prompt-eng":0.48260271,"data-quality":0.1016485485,"ml-security":0.0974062852}}
{"text":"https://doi.org/10.5281/zenodo.7805872, https://github.com/A2Amir/SAGC-A68.","meta":{"url":"http://arxiv.org/abs/2307.04515v1"},"cats":{"new-dataset":0.220680757,"dev-research":0.3938032061,"prompt-eng":0.4242569009,"data-quality":0.0772437941,"ml-security":0.0637186006}}
{"text":"In graph representation learning, it is important that the complex geometric structure of the input graph, e.g. hidden relations among nodes, is well captured in embedding space.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.114324355,"dev-research":0.4106932786,"prompt-eng":0.4064792848,"data-quality":0.1709331881,"ml-security":0.1780750626}}
{"text":"However, standard Euclidean embedding spaces have a limited capacity in representing graphs of varying structures.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.0877743669,"dev-research":0.3705646931,"prompt-eng":0.3647555311,"data-quality":0.1421836413,"ml-security":0.1453933256}}
{"text":"A promising candidate for the faithful embedding of data with varying structure is product manifolds of component spaces of different geometries (spherical, hyperbolic, or euclidean).","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.1879826043,"dev-research":0.3598921546,"prompt-eng":0.4334200622,"data-quality":0.1427558076,"ml-security":0.1598201538}}
{"text":"In this paper, we take a closer look at the structure of product manifold embedding spaces and argue that each component space in a product contributes differently to expressing structures in the input graph, hence should be weighted accordingly.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.0806190395,"dev-research":0.4217015962,"prompt-eng":0.4292985148,"data-quality":0.1803634534,"ml-security":0.1163856066}}
{"text":"This is different from previous works which consider the roles of different components equally.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.0495832533,"dev-research":0.453925271,"prompt-eng":0.3837558266,"data-quality":0.0709343643,"ml-security":0.056502996}}
{"text":"We then propose WEIGHTED-PM, a data-driven method for learning embedding of heterogeneous graphs in weighted product manifolds.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.1025972316,"dev-research":0.3763409154,"prompt-eng":0.4386148619,"data-quality":0.1732769224,"ml-security":0.0952076825}}
{"text":"Our method utilizes the topological information of the input graph to automatically determine the weight of each component in product spaces.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.104953711,"dev-research":0.4190601514,"prompt-eng":0.4268849938,"data-quality":0.1368367519,"ml-security":0.0804412865}}
{"text":"Extensive experiments on synthetic and real-world graph datasets demonstrate that WEIGHTED-PM is capable of learning better graph representations with lower geometric distortion from input data, and performs better on multiple downstream tasks, such as word similarity learning, top-$k$ recommendation, and knowledge graph embedding.","meta":{"url":"http://arxiv.org/abs/2307.04514v1"},"cats":{"new-dataset":0.2399498847,"dev-research":0.4059763213,"prompt-eng":0.4497544542,"data-quality":0.1800232535,"ml-security":0.1188268471}}
{"text":"Modern abstractive summarization models often generate summaries that contain hallucinated or contradictory information.","meta":{"url":"http://arxiv.org/abs/2307.04507v1"},"cats":{"new-dataset":0.0904563348,"dev-research":0.447045751,"prompt-eng":0.4794866283,"data-quality":0.2582220118,"ml-security":0.096775017}}
{"text":"In this paper, we propose a simple but effective contrastive learning framework that incorporates recent developments in reward learning and factuality metrics.","meta":{"url":"http://arxiv.org/abs/2307.04507v1"},"cats":{"new-dataset":0.1515226191,"dev-research":0.408187684,"prompt-eng":0.455357402,"data-quality":0.1811111297,"ml-security":0.1002260987}}
{"text":"Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations.","meta":{"url":"http://arxiv.org/abs/2307.04507v1"},"cats":{"new-dataset":0.1319529426,"dev-research":0.4313022116,"prompt-eng":0.5159664895,"data-quality":0.1986857804,"ml-security":0.0604147239}}
{"text":"This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries.","meta":{"url":"http://arxiv.org/abs/2307.04507v1"},"cats":{"new-dataset":0.1211611658,"dev-research":0.4896000902,"prompt-eng":0.4622256534,"data-quality":0.1676910597,"ml-security":0.1048466638}}
{"text":"Probabilistic hyperproperties specify quantitative relations between the probabilities of reaching different target sets of states from different initial sets of states.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0409885448,"dev-research":0.399244193,"prompt-eng":0.4571427534,"data-quality":0.1139084299,"ml-security":0.1491979754}}
{"text":"This class of behavioral properties is suitable for capturing important security, privacy, and system-level requirements.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.1325624933,"dev-research":0.4853252585,"prompt-eng":0.4834493629,"data-quality":0.0952825865,"ml-security":0.4205508111}}
{"text":"We propose a new approach to solve the controller synthesis problem for Markov decision processes (MDPs) and probabilistic hyperproperties.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0553131397,"dev-research":0.4120990605,"prompt-eng":0.4422386058,"data-quality":0.0968735889,"ml-security":0.1629979438}}
{"text":"Our specification language builds on top of the logic HyperPCTL and enhances it with structural constraints over the synthesized controllers.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.1147040578,"dev-research":0.5122176358,"prompt-eng":0.4633634589,"data-quality":0.0619212946,"ml-security":0.0975710024}}
{"text":"Our approach starts from a family of controllers represented symbolically and defined over the same copy of an MDP.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0617137064,"dev-research":0.4537192384,"prompt-eng":0.4373154262,"data-quality":0.0766856018,"ml-security":0.130890947}}
{"text":"We then introduce an abstraction refinement strategy that can relate multiple computation trees and that we employ to prune the search space deductively.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0803666235,"dev-research":0.4890586973,"prompt-eng":0.4253768698,"data-quality":0.0871468963,"ml-security":0.1329575592}}
{"text":"The experimental evaluation demonstrates that the proposed approach considerably outperforms HyperProb, a state-of-the-art SMT-based model checking tool for HyperPCTL.","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0702207585,"dev-research":0.4575703838,"prompt-eng":0.4606948519,"data-quality":0.1531892816,"ml-security":0.1500742833}}
{"text":"Moreover, our approach is the first one that is able to effectively combine probabilistic hyperproperties with additional intra-controller constraints (e.g. partial observability) as well as inter-controller constraints (e.g. agreements on a common action).","meta":{"url":"http://arxiv.org/abs/2307.04503v1"},"cats":{"new-dataset":0.0389060442,"dev-research":0.4131749927,"prompt-eng":0.4447963039,"data-quality":0.1014151399,"ml-security":0.1579815336}}
{"text":"This paper proposes a privacy-preserving and accountable billing (PA-Bill) protocol for trading in peer-to-peer energy markets, addressing situations where there may be discrepancies between the volume of energy committed and delivered.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.1671321662,"dev-research":0.4009286026,"prompt-eng":0.4067015713,"data-quality":0.1635837007,"ml-security":0.3036590424}}
{"text":"Such discrepancies can lead to challenges in providing both privacy and accountability while maintaining accurate billing.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.1505972019,"dev-research":0.443763635,"prompt-eng":0.4146244472,"data-quality":0.4335547802,"ml-security":0.264508911}}
{"text":"To overcome these challenges, a universal cost splitting mechanism is proposed that prioritises privacy and accountability.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.1139940956,"dev-research":0.4568391936,"prompt-eng":0.4316427423,"data-quality":0.121941038,"ml-security":0.4524478982}}
{"text":"It leverages a homomorphic encryption cryptosystem to provide privacy and employs blockchain technology to establish accountability.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.1202871449,"dev-research":0.4218976659,"prompt-eng":0.379616312,"data-quality":0.0719733356,"ml-security":0.3532652509}}
{"text":"A dispute resolution mechanism is also introduced to minimise the occurrence of erroneous bill calculations while ensuring accountability and non-repudiation throughout the billing process.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.0697245318,"dev-research":0.4398219761,"prompt-eng":0.4239158725,"data-quality":0.3695009672,"ml-security":0.1413287281}}
{"text":"Our evaluation demonstrates that PA-Bill offers an effective billing mechanism that maintains privacy and accountability in peer-to-peer energy markets utilising a semi-decentralised approach.","meta":{"url":"http://arxiv.org/abs/2307.04501v1"},"cats":{"new-dataset":0.1745422789,"dev-research":0.4105809862,"prompt-eng":0.4203219521,"data-quality":0.1347502496,"ml-security":0.2500266396}}
{"text":"We developed a low-fidelity prototype of a report that contains an algorithmically-generated optimal academic plan.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.1167543081,"dev-research":0.4281532094,"prompt-eng":0.4165376808,"data-quality":0.0754173958,"ml-security":0.0783544666}}
{"text":"Optimal is defined as the minimal set of community college courses that satisfy the transfer requirements for multiple universities a student is preparing to apply to.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.0540220212,"dev-research":0.3954035094,"prompt-eng":0.3901641647,"data-quality":0.0901953497,"ml-security":0.0979139964}}
{"text":"We recruited 24 California community college transfer students to participate in a research session, consisting of an experiment, survey, and interview.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.297644547,"dev-research":0.4273578372,"prompt-eng":0.4831821458,"data-quality":0.0905786972,"ml-security":0.1134810482}}
{"text":"We experimentally compared the prototype to ASSIST, California's official statewide database of articulation agreement reports.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.181698924,"dev-research":0.4592663711,"prompt-eng":0.5061242808,"data-quality":0.191954214,"ml-security":0.0427572834}}
{"text":"Compared to students who used the prototype, students assigned to use ASSIST reports to manually create an optimal academic plan underperformed in optimality mistakes, time required, and usability scores.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.0848048228,"dev-research":0.4907040461,"prompt-eng":0.4837395865,"data-quality":0.1013048127,"ml-security":0.066684852}}
{"text":"Moving to our non-experimental results, a sizable minority of students had a negative assessment of counselors' ability and willingness to manually create optimal academic plans using ASSIST.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.0435114455,"dev-research":0.4726227977,"prompt-eng":0.4688460836,"data-quality":0.1200268278,"ml-security":0.1104564806}}
{"text":"Our last results revolved around students' recommendations for supplemental software features to improve the optimization prototype.","meta":{"url":"http://arxiv.org/abs/2307.04500v1"},"cats":{"new-dataset":0.1069900584,"dev-research":0.5268377007,"prompt-eng":0.4649510979,"data-quality":0.0962232016,"ml-security":0.1547625509}}
{"text":"We carry on the study of the synthesis problem on data words for fragments of first order logic, and delineate precisely the border between decidability and undecidability.","meta":{"url":"http://arxiv.org/abs/2307.04499v1"},"cats":{"new-dataset":0.1763729944,"dev-research":0.4481910483,"prompt-eng":0.4254730346,"data-quality":0.1431367849,"ml-security":0.1911204775}}
{"text":"This paper presents a quasi-deterministic ray tracing (QD-RT) method for analyzing the propagation of electromagnetic waves in street canyons.","meta":{"url":"http://arxiv.org/abs/2307.04498v1"},"cats":{"new-dataset":0.1189761567,"dev-research":0.3905896111,"prompt-eng":0.386536366,"data-quality":0.0672627109,"ml-security":0.1125297613}}
{"text":"The method uses a statistical bistatic distribution to model the Radar Cross Section (RCS) of various irregular objects such as cars and pedestrians, instead of relying on exact values as in a deterministic propagation model.","meta":{"url":"http://arxiv.org/abs/2307.04498v1"},"cats":{"new-dataset":0.1709778966,"dev-research":0.3630328404,"prompt-eng":0.4091041239,"data-quality":0.0981455087,"ml-security":0.1428044989}}
{"text":"The performance of the QD-RT method is evaluated by comparing its generated path loss distributions to those of the deterministic ray tracing (D-RT) model using the Two-sample Cramer-von Mises test.","meta":{"url":"http://arxiv.org/abs/2307.04498v1"},"cats":{"new-dataset":0.0607483008,"dev-research":0.3926602641,"prompt-eng":0.4326178109,"data-quality":0.0935777141,"ml-security":0.0793578705}}
{"text":"The results indicate that the QD-RT method generates the same path loss distributions as the D-RT model while offering lower complexity.","meta":{"url":"http://arxiv.org/abs/2307.04498v1"},"cats":{"new-dataset":0.0566386044,"dev-research":0.3968332814,"prompt-eng":0.4266622487,"data-quality":0.0880341465,"ml-security":0.1083397587}}
{"text":"This study suggests that the QD-RT method has the potential to be used for analyzing complicated scenarios such as street canyon scenarios in mmWave wireless communication systems.","meta":{"url":"http://arxiv.org/abs/2307.04498v1"},"cats":{"new-dataset":0.0827744097,"dev-research":0.4159204198,"prompt-eng":0.4219695021,"data-quality":0.0686779215,"ml-security":0.131031322}}
{"text":"The exploration of the lunar poles and the collection of samples from the martian surface are characterized by shorter time windows demanding increased autonomy and speeds.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0922631946,"dev-research":0.3926031578,"prompt-eng":0.3977166081,"data-quality":0.0456634971,"ml-security":0.0601549046}}
{"text":"Autonomous mobile robots must intrinsically cope with a wider range of disturbances.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0741007092,"dev-research":0.3980190875,"prompt-eng":0.4072737602,"data-quality":0.0806247568,"ml-security":0.1458380454}}
{"text":"Faster off-road navigation has been explored for terrestrial applications but the combined effects of increased speeds and reduced gravity fields are yet to be fully studied.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0625021128,"dev-research":0.3632676095,"prompt-eng":0.3758596857,"data-quality":0.049028982,"ml-security":0.0588421508}}
{"text":"In this paper, we design and demonstrate a novel fully passive suspension design for wheeled planetary robots, which couples a high-range passive rocker with elastic in-wheel coil-over shock absorbers.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.1202746511,"dev-research":0.388748566,"prompt-eng":0.4320460908,"data-quality":0.0901397636,"ml-security":0.1053988485}}
{"text":"The design was initially conceived and verified in a reduced-gravity (1.625 m/s$^2$) simulated environment, where three different passive suspension configurations were evaluated against a set of challenges--climbing steep slopes and surmounting unexpected obstacles like rocks and outcrops--and later prototyped and validated in a series of field tests.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0828024136,"dev-research":0.3838540097,"prompt-eng":0.397739898,"data-quality":0.0770327831,"ml-security":0.0855557397}}
{"text":"The proposed mechanically-hybrid suspension proves to mitigate more effectively the negative effects (high-frequency/high-amplitude vibrations and impact loads) of faster locomotion (>1 m/s) over unstructured terrains under varied gravity fields.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0777302248,"dev-research":0.3844380643,"prompt-eng":0.4015645555,"data-quality":0.0826299839,"ml-security":0.0855210804}}
{"text":"This lowers the demand on navigation and control systems, impacting the efficiency of exploration missions in the years to come.","meta":{"url":"http://arxiv.org/abs/2307.04494v1"},"cats":{"new-dataset":0.0562565854,"dev-research":0.4358885675,"prompt-eng":0.4154548402,"data-quality":0.0376765138,"ml-security":0.089774205}}
{"text":"Methods: This work introduces a method supporting the collaborative definition of machine learning tasks by leveraging model-based engineering in the formalization of the systems modeling language SysML.","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.0843323407,"dev-research":0.4892092308,"prompt-eng":0.5532789721,"data-quality":0.1568073178,"ml-security":0.213548528}}
{"text":"The method supports the identification and integration of various data sources, the required definition of semantic connections between data attributes, and the definition of data processing steps within the machine learning support.   ","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.148417362,"dev-research":0.4612982425,"prompt-eng":0.4625030501,"data-quality":0.2612534813,"ml-security":0.1535544384}}
{"text":"Results:","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.3390451721,"dev-research":0.4429688198,"prompt-eng":0.4419211306,"data-quality":0.2110089253,"ml-security":0.0788170628}}
{"text":"By consolidating the knowledge of domain and machine learning experts, a powerful tool to describe machine learning tasks by formalizing knowledge using the systems modeling language SysML is introduced.","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.1318720531,"dev-research":0.4906718032,"prompt-eng":0.5412727902,"data-quality":0.1601925887,"ml-security":0.1974542876}}
{"text":"The method is evaluated based on two use cases, i.e., a smart weather system that allows to predict weather forecasts based on sensor data, and a waste prevention case for 3D printer filament that cancels the printing if the intended result cannot be achieved (image processing).","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.1134390457,"dev-research":0.4480919369,"prompt-eng":0.4273678119,"data-quality":0.1223913884,"ml-security":0.151263353}}
{"text":"Further, a user study is conducted to gather insights of potential users regarding perceived workload and usability of the elaborated method.   ","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.060304116,"dev-research":0.4797285756,"prompt-eng":0.3771164397,"data-quality":0.0433830439,"ml-security":0.0568643925}}
{"text":"Conclusion: Integrating machine learning-specific properties in systems engineering techniques allows non-data scientists to understand formalized knowledge and define specific aspects of a machine learning problem, document knowledge on the data, and to further support data scientists to use the formalized knowledge as input for an implementation using (semi-) automatic code generation.","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.121410182,"dev-research":0.5129342866,"prompt-eng":0.4711781027,"data-quality":0.1731368566,"ml-security":0.3161965986}}
{"text":"In this respect, this work contributes by consolidating knowledge from various domains and therefore, fosters the integration of machine learning in industry by involving several stakeholders.","meta":{"url":"http://arxiv.org/abs/2307.04495v1"},"cats":{"new-dataset":0.1443170383,"dev-research":0.4693910859,"prompt-eng":0.4613011992,"data-quality":0.1636776656,"ml-security":0.2355979873}}
{"text":"Understanding the macroscopic characteristics of biological complexes demands precision and specificity in statistical ensemble modeling.","meta":{"url":"http://arxiv.org/abs/2307.04493v1"},"cats":{"new-dataset":0.1024364695,"dev-research":0.3765315866,"prompt-eng":0.4228569446,"data-quality":0.1126986092,"ml-security":0.1107793923}}
{"text":"One of the primary challenges in this domain lies in sampling from particular subsets of the state-space, driven either by existing structural knowledge or specific areas of interest within the state-space.","meta":{"url":"http://arxiv.org/abs/2307.04493v1"},"cats":{"new-dataset":0.1289475463,"dev-research":0.3646428975,"prompt-eng":0.4433425695,"data-quality":0.1254116895,"ml-security":0.1386108903}}
{"text":"We propose a method that enables sampling from distributions that rigorously adhere to arbitrary sets of geometric constraints in Euclidean spaces.","meta":{"url":"http://arxiv.org/abs/2307.04493v1"},"cats":{"new-dataset":0.1308052129,"dev-research":0.3744881131,"prompt-eng":0.3940202624,"data-quality":0.1386602479,"ml-security":0.159590367}}
{"text":"This is achieved by integrating a constraint projection operator within the well-regarded architecture of Denoising Diffusion Probabilistic Models, a framework founded in generative modeling and probabilistic inference.","meta":{"url":"http://arxiv.org/abs/2307.04493v1"},"cats":{"new-dataset":0.0827555355,"dev-research":0.3867117449,"prompt-eng":0.4832020017,"data-quality":0.1256472306,"ml-security":0.1283763274}}
{"text":"The significance of this work becomes apparent, for instance, in the context of deep learning-based drug design, where it is imperative to maintain specific molecular profile interactions to realize the desired therapeutic outcomes and guarantee safety.","meta":{"url":"http://arxiv.org/abs/2307.04493v1"},"cats":{"new-dataset":0.0937048689,"dev-research":0.4393624584,"prompt-eng":0.4016775602,"data-quality":0.1151551654,"ml-security":0.2920755773}}
{"text":"The ease of using a Large Language Model (LLM) to answer a wide variety of queries and their high availability has resulted in LLMs getting integrated into various applications.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.1605810444,"dev-research":0.4508690236,"prompt-eng":0.5952139424,"data-quality":0.1154531313,"ml-security":0.1112278047}}
{"text":"LLM-based recommenders are now routinely used by students as well as professional software programmers for code generation and testing.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.1883643906,"dev-research":0.5611366653,"prompt-eng":0.5487466332,"data-quality":0.1138194463,"ml-security":0.1387258917}}
{"text":"Though LLM-based technology has proven useful, its unethical and unattributed use by students and professionals is a growing cause of concern.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.0932960657,"dev-research":0.48183131,"prompt-eng":0.4662344162,"data-quality":0.1401823081,"ml-security":0.3998568109}}
{"text":"As such, there is a need for tools and technologies which may assist teachers and other evaluators in identifying whether any portion of a source code is LLM generated.   ","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.1537124193,"dev-research":0.5691311085,"prompt-eng":0.5496775666,"data-quality":0.1862086717,"ml-security":0.1803890453}}
{"text":"In this paper, we propose a neural network-based tool that instructors can use to determine the original effort (and LLM's contribution) put by students in writing source codes.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.2034371625,"dev-research":0.5475200122,"prompt-eng":0.5000392841,"data-quality":0.1941685184,"ml-security":0.1731204259}}
{"text":"Our tool is motivated by minimum description length measures like Kolmogorov complexity.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.1176741373,"dev-research":0.4658807935,"prompt-eng":0.4076608903,"data-quality":0.1542925236,"ml-security":0.0934898959}}
{"text":"Our initial experiments with moderate sized (up to 500 lines of code) have shown promising results that we report in this paper.","meta":{"url":"http://arxiv.org/abs/2307.04492v1"},"cats":{"new-dataset":0.1299347355,"dev-research":0.5052474366,"prompt-eng":0.4514686373,"data-quality":0.2054574448,"ml-security":0.1775956743}}
{"text":"The BDD package Adiar manipulates Binary Decision Diagrams (BDDs) in external memory.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.1017728289,"dev-research":0.4752654614,"prompt-eng":0.4461517015,"data-quality":0.0843133588,"ml-security":0.1850549579}}
{"text":"This enables handling big BDDs, but the performance suffers when dealing with moderate-sized BDDs.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.0408403288,"dev-research":0.4145836339,"prompt-eng":0.3986273588,"data-quality":0.1026444373,"ml-security":0.1639201699}}
{"text":"This is mostly due to initializing expensive external memory data structures, even if their contents can fit entirely inside internal memory.   ","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.1533738537,"dev-research":0.4518962594,"prompt-eng":0.3922886811,"data-quality":0.1398718705,"ml-security":0.1737498662}}
{"text":"The contents of these auxiliary data structures always correspond to a graph cut in an input or output BDD.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.2047070955,"dev-research":0.4581492279,"prompt-eng":0.4229174383,"data-quality":0.1815365686,"ml-security":0.1554465891}}
{"text":"Specifically, these cuts respect the levels of the BDD.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.076750773,"dev-research":0.4037362749,"prompt-eng":0.4064368504,"data-quality":0.1637629965,"ml-security":0.1551806553}}
{"text":"We formalise the shape of these cuts and prove sound upper bounds on their maximum size for each BDD operation.   ","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.1237425723,"dev-research":0.4189940163,"prompt-eng":0.3779723466,"data-quality":0.1268139253,"ml-security":0.1412335356}}
{"text":"We have implemented these upper bounds within Adiar.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.1039209376,"dev-research":0.4010024499,"prompt-eng":0.3744298682,"data-quality":0.0938499534,"ml-security":0.1112189357}}
{"text":"With these bounds, it can predict whether a faster internal memory variant of the auxiliary data structures can be used.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.1235313226,"dev-research":0.4489071497,"prompt-eng":0.427397703,"data-quality":0.0837331607,"ml-security":0.1745719316}}
{"text":"In practice, this improves Adiar's running time across the board.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.0479230258,"dev-research":0.4338008483,"prompt-eng":0.3472193115,"data-quality":0.0680052669,"ml-security":0.0985670795}}
{"text":"Specifically for the moderate-sized BDDs, this results in an average reduction of the computation time by 86.1% (median of 89.7%).","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.0778915543,"dev-research":0.4171520692,"prompt-eng":0.3952189513,"data-quality":0.0812434966,"ml-security":0.1442702695}}
{"text":"In some cases, the difference is even 99.9\\%.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.0666774594,"dev-research":0.4268535214,"prompt-eng":0.4143849838,"data-quality":0.2112845117,"ml-security":0.1125296213}}
{"text":"When checking equivalence of hardware circuits from the EPFL Benchmark Suite, for one of the instances the time was decreased by 52 hours.","meta":{"url":"http://arxiv.org/abs/2307.04488v1"},"cats":{"new-dataset":0.113184683,"dev-research":0.4053943455,"prompt-eng":0.406642843,"data-quality":0.1158805397,"ml-security":0.07640705}}
{"text":"X-ray interaction with matter is an energy-dependent process that is contingent on the atomic structure of the constituent material elements.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.0384550718,"dev-research":0.4371819671,"prompt-eng":0.4126121643,"data-quality":0.0741054428,"ml-security":0.071586685}}
{"text":"The most advanced models to capture this relationship currently rely on Monte Carlo (MC) simulations.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.166523729,"dev-research":0.3618356892,"prompt-eng":0.4673612631,"data-quality":0.0766294674,"ml-security":0.1143137088}}
{"text":"Whilst these very accurate models, in many problems in spectral X-ray imaging, such as data compression, noise removal, spectral estimation, and the quantitative measurement of material compositions, these models are of limited use, as these applications typically require the efficient inversion of the model, that is, they require the estimation of the best model parameters for a given spectral measurement.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.0645979559,"dev-research":0.3345135769,"prompt-eng":0.39286185,"data-quality":0.1732303841,"ml-security":0.0972315598}}
{"text":"Current models that can be easily inverted however typically only work when modelling spectra in regions away from their K-edges, so they have limited utility when modelling a wider range of materials.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.0323063368,"dev-research":0.3338702304,"prompt-eng":0.3986626172,"data-quality":0.0926247604,"ml-security":0.1450194336}}
{"text":"In this paper, we thus propose a novel, non-linear model that combines a deep neural network autoencoder with an optimal linear model based on the Singular Value Decomposition (SVD).","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.1467442506,"dev-research":0.3698731005,"prompt-eng":0.4393670625,"data-quality":0.274621349,"ml-security":0.2053756913}}
{"text":"We compare our new method to other alternative linear and non-linear approaches, a sparse model and an alternative deep learning model.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.1470696658,"dev-research":0.3548436229,"prompt-eng":0.4229320193,"data-quality":0.2044395755,"ml-security":0.1670524939}}
{"text":"We demonstrate the advantages of our method over traditional models, especially when modelling X-ray absorption spectra that contain K-edges in the energy range of interest.","meta":{"url":"http://arxiv.org/abs/2307.04484v1"},"cats":{"new-dataset":0.0913567579,"dev-research":0.3479141605,"prompt-eng":0.4013515415,"data-quality":0.0717380765,"ml-security":0.1317113376}}
{"text":"Manufacturing tools like 3D printers have become accessible to the wider society, making the promise of digital fabrication for everyone seemingly reachable.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.1203709855,"dev-research":0.4583982535,"prompt-eng":0.3999488132,"data-quality":0.0607341543,"ml-security":0.1222519741}}
{"text":"While the actual manufacturing process is largely automated today, users still require knowledge of complex design applications to produce ready-designed objects and adapt them to their needs or design new objects from scratch.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.1136009294,"dev-research":0.5260175281,"prompt-eng":0.4648064563,"data-quality":0.0649377249,"ml-security":0.06516699}}
{"text":"To lower the barrier to the design and customization of personalized 3D models, we explored novice mental models in voice-based 3D modeling by conducting a high-fidelity Wizard of Oz study with 22 participants.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.1749527855,"dev-research":0.420187469,"prompt-eng":0.4880015513,"data-quality":0.0776416284,"ml-security":0.0971099715}}
{"text":"We performed a thematic analysis of the collected data to understand how the mental model of novices translates into voice-based 3D modeling.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.2163574077,"dev-research":0.4595897489,"prompt-eng":0.4924628184,"data-quality":0.1153924008,"ml-security":0.0806497875}}
{"text":"We conclude with design implications for voice assistants.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.0656572204,"dev-research":0.4352693767,"prompt-eng":0.5008935896,"data-quality":0.1654780717,"ml-security":0.1840586793}}
{"text":"For example, they have to: deal with vague, incomplete and wrong commands; provide a set of straightforward commands to shape simple and composite objects; and offer different strategies to select 3D objects.","meta":{"url":"http://arxiv.org/abs/2307.04481v1"},"cats":{"new-dataset":0.0500434863,"dev-research":0.4951906169,"prompt-eng":0.4349193938,"data-quality":0.0593796408,"ml-security":0.0646680361}}
{"text":"Sequence Alignment is the process of aligning biological sequences in order to identify similarities between multiple sequences.","meta":{"url":"http://arxiv.org/abs/2307.04479v1"},"cats":{"new-dataset":0.2022128795,"dev-research":0.444435538,"prompt-eng":0.4261946256,"data-quality":0.1904308282,"ml-security":0.0623662378}}
{"text":"In this paper, a Quantum Algorithm for finding the optimal alignment between DNA sequences has been demonstrated which works by mapping the sequence alignment problem into a path-searching problem through a 2D graph.","meta":{"url":"http://arxiv.org/abs/2307.04479v1"},"cats":{"new-dataset":0.1530221921,"dev-research":0.3825696253,"prompt-eng":0.3508801205,"data-quality":0.0957276152,"ml-security":0.0596979768}}
{"text":"The transition, which converges to a fixed path on the graph, is based on a proposed oracle for profit calculation.","meta":{"url":"http://arxiv.org/abs/2307.04479v1"},"cats":{"new-dataset":0.0595467782,"dev-research":0.4465515131,"prompt-eng":0.35122245,"data-quality":0.051305539,"ml-security":0.052326648}}
{"text":"By implementing Grover's search algorithm, our proposed approach is able to align a pair of sequences and figure out the optimal alignment within linear time, which hasn't been attained by any classical deterministic algorithm.","meta":{"url":"http://arxiv.org/abs/2307.04479v1"},"cats":{"new-dataset":0.0897451288,"dev-research":0.3887385938,"prompt-eng":0.3572195614,"data-quality":0.1280092219,"ml-security":0.1390988222}}
{"text":"In addition to that, the proposed algorithm is capable of quadratic speeding up to any unstructured search problem by finding out the optimal paths accurately in a deterministic manner, in contrast to existing randomized algorithms that frequently sort out the sub-optimal alignments, therefore, don't always guarantee of finding out the optimal solutions.","meta":{"url":"http://arxiv.org/abs/2307.04479v1"},"cats":{"new-dataset":0.0667546705,"dev-research":0.3838950048,"prompt-eng":0.3489096107,"data-quality":0.0974996472,"ml-security":0.0949091895}}
{"text":"The spectral decomposition of a symmetric, second-order tensor is widely adopted in many fields of Computational Mechanics.","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0500673747,"dev-research":0.3891661762,"prompt-eng":0.3505271561,"data-quality":0.0863664697,"ml-security":0.1230918862}}
{"text":"As an example, in elasto-plasticity under large strain and rotations, given the Cauchy deformation tensor, it is a fundamental step to compute the logarithmic strain tensor.   ","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0831524031,"dev-research":0.3820333128,"prompt-eng":0.4123439699,"data-quality":0.1083484914,"ml-security":0.0838136265}}
{"text":"Recently, this approach has been also adopted in small-strain isotropic plasticity to reconstruct the stress tensor as a function of its eigenvalues, allowing the formulation of predictor-corrector return algorithms in the invariants space.","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0537492471,"dev-research":0.3679897799,"prompt-eng":0.4291251856,"data-quality":0.1897227952,"ml-security":0.1330543715}}
{"text":"These algorithms not only reduce the number of unknowns at the constitutive level, but also allow the correct handling of stress states in which the plastic normals are undefined, thus ensuring a better convergence with respect to the standard approach.   ","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0299783188,"dev-research":0.3792127582,"prompt-eng":0.3255373962,"data-quality":0.1379710859,"ml-security":0.142381696}}
{"text":"While the eigenvalues of a symmetric, second-order tensor can be simply computed as a function of the tensor invariants, the computation of its eigenbasis can be more difficult, especially when two or more eigenvalues are coincident.","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0317930928,"dev-research":0.3923697519,"prompt-eng":0.3710252802,"data-quality":0.1009294087,"ml-security":0.1125465167}}
{"text":"Moreover, when a Newton-Rhapson algorithm is adopted to solve nonlinear problems in Computational Mechanics, also the tensorial derivatives of the eigenbasis, whose computation is still more complicate, are required to assemble the tangent matrix.   ","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0948383617,"dev-research":0.3937343879,"prompt-eng":0.3477533346,"data-quality":0.0658148414,"ml-security":0.1199277741}}
{"text":"A simple and comprehensive method is presented, which can be adopted to compute a closed form representation of a second-order tensor, as well as their derivatives with respect to the tensor itself, allowing a simpler implementation of spectral decomposition of a tensor in Computational Mechanics applications.","meta":{"url":"http://arxiv.org/abs/2307.04478v1"},"cats":{"new-dataset":0.0619278465,"dev-research":0.3832528402,"prompt-eng":0.3758999087,"data-quality":0.0975332081,"ml-security":0.1173967063}}
{"text":"Coronary artery segmentation on coronary-computed tomography angiography (CCTA) images is crucial for clinical use.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1047423928,"dev-research":0.3497226666,"prompt-eng":0.3710134696,"data-quality":0.1558425158,"ml-security":0.0725190104}}
{"text":"Due to the expertise-required and labor-intensive annotation process, there is a growing demand for the relevant label-efficient learning algorithms.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1672468257,"dev-research":0.4498498704,"prompt-eng":0.4795115198,"data-quality":0.5447031518,"ml-security":0.1615449288}}
{"text":"To this end, we propose partial vessels annotation (PVA) based on the challenges of coronary artery segmentation and clinical diagnostic characteristics.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1327218804,"dev-research":0.3704044932,"prompt-eng":0.426838726,"data-quality":0.3269055726,"ml-security":0.100775767}}
{"text":"Further, we propose a progressive weakly supervised learning framework to achieve accurate segmentation under PVA.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1322362452,"dev-research":0.3428188145,"prompt-eng":0.452948168,"data-quality":0.2932781884,"ml-security":0.0616476608}}
{"text":"First, our proposed framework learns the local features of vessels to propagate the knowledge to unlabeled regions.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1747341687,"dev-research":0.3910115139,"prompt-eng":0.4323148194,"data-quality":0.1859331444,"ml-security":0.1009354031}}
{"text":"Subsequently, it learns the global structure by utilizing the propagated knowledge, and corrects the errors introduced in the propagation process.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.1104161179,"dev-research":0.4468031981,"prompt-eng":0.4866398049,"data-quality":0.2136241442,"ml-security":0.1219618764}}
{"text":"Finally, it leverages the similarity between feature embeddings and the feature prototype to enhance testing outputs.","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.0792708467,"dev-research":0.5050058332,"prompt-eng":0.5161552459,"data-quality":0.1718644783,"ml-security":0.1416437725}}
{"text":"Experiments on clinical data reveals that our proposed framework outperforms the competing methods under PVA (24.29% vessels), and achieves comparable performance in trunk continuity with the baseline model using full annotation (100% vessels).","meta":{"url":"http://arxiv.org/abs/2307.04472v1"},"cats":{"new-dataset":0.0740055504,"dev-research":0.3660818199,"prompt-eng":0.4066979554,"data-quality":0.1585250211,"ml-security":0.0556917506}}
{"text":"The ability to scene understanding in adverse visual conditions, e.g., nighttime, has sparked active research for RGB-Thermal (RGB-T) semantic segmentation.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.2764345291,"dev-research":0.3818094102,"prompt-eng":0.4696079962,"data-quality":0.2542368757,"ml-security":0.087067349}}
{"text":"However, it is essentially hampered by two critical problems: 1) the day-night gap of RGB images is larger than that of thermal images, and 2) the class-wise performance of RGB images at night is not consistently higher or lower than that of thermal images.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.0831006184,"dev-research":0.3442012731,"prompt-eng":0.3479420213,"data-quality":0.1564754064,"ml-security":0.0894880537}}
{"text":"we propose the first test-time adaptation (TTA) framework, dubbed Night-TTA, to address the problems for nighttime RGBT semantic segmentation without access to the source (daytime) data during adaptation.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.2370421932,"dev-research":0.3745983203,"prompt-eng":0.4530135667,"data-quality":0.1886945841,"ml-security":0.0758813889}}
{"text":"Our method enjoys three key technical parts.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.0666156404,"dev-research":0.5032893271,"prompt-eng":0.4286533675,"data-quality":0.0826229424,"ml-security":0.0676550344}}
{"text":"Firstly, as one modality (e.g., RGB) suffers from a larger domain gap than that of the other (e.g., thermal), Imaging Heterogeneity Refinement (IHR) employs an interaction branch on the basis of RGB and thermal branches to prevent cross-modal discrepancy and performance degradation.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.0398919562,"dev-research":0.3755720982,"prompt-eng":0.3994166258,"data-quality":0.077388545,"ml-security":0.0291897554}}
{"text":"Then, Class Aware Refinement (CAR) is introduced to obtain reliable ensemble logits based on pixel-level distribution aggregation of the three branches.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.1494035373,"dev-research":0.4066070516,"prompt-eng":0.4838845057,"data-quality":0.2263081186,"ml-security":0.1312202857}}
{"text":"In addition, we also design a specific learning scheme for our TTA framework, which enables the ensemble logits and three student logits to collaboratively learn to improve the quality of predictions during the testing phase of our Night TTA.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.1905318293,"dev-research":0.4354595152,"prompt-eng":0.5571477833,"data-quality":0.0969525673,"ml-security":0.2555943107}}
{"text":"Extensive experiments show that our method achieves state-of-the-art (SoTA) performance with a 13.07% boost in mIoU.","meta":{"url":"http://arxiv.org/abs/2307.04470v1"},"cats":{"new-dataset":0.0999342407,"dev-research":0.3371477869,"prompt-eng":0.4531933566,"data-quality":0.0965062594,"ml-security":0.0934718438}}
{"text":"Generating context specific data quality deficits is necessary to experimentally assess data quality of data-driven (artificial intelligence (AI) or machine learning (ML)) applications.","meta":{"url":"http://arxiv.org/abs/2307.04468v1"},"cats":{"new-dataset":0.2251367895,"dev-research":0.4379572055,"prompt-eng":0.466935358,"data-quality":0.3755145098,"ml-security":0.239801497}}
{"text":"In this paper we present badgers, an extensible open-source Python library to generate data quality deficits (outliers, imbalanced data, drift, etc.) for different modalities (tabular data, time-series, text, etc.).","meta":{"url":"http://arxiv.org/abs/2307.04468v1"},"cats":{"new-dataset":0.4598317961,"dev-research":0.4382115988,"prompt-eng":0.4491303536,"data-quality":0.3185529672,"ml-security":0.1879262649}}
{"text":"The documentation is accessible at https://fraunhofer-iese.github.io/badgers/ and the source code at https://github.com/Fraunhofer-IESE/badgers","meta":{"url":"http://arxiv.org/abs/2307.04468v1"},"cats":{"new-dataset":0.2593767781,"dev-research":0.4656776137,"prompt-eng":0.4934465422,"data-quality":0.1119876314,"ml-security":0.1323928132}}
{"text":"This paper presents an overview of robot failure detection work from HRI and adjacent fields using failures as an opportunity to examine robot explanation behaviours.","meta":{"url":"http://arxiv.org/abs/2307.04462v1"},"cats":{"new-dataset":0.0919211569,"dev-research":0.4342719662,"prompt-eng":0.5041701438,"data-quality":0.3657471342,"ml-security":0.1143082731}}
{"text":"As humanoid robots remain experimental tools in the early 2020s, interactions with robots are situated overwhelmingly in controlled environments, typically studying various interactional phenomena.","meta":{"url":"http://arxiv.org/abs/2307.04462v1"},"cats":{"new-dataset":0.1161776907,"dev-research":0.4196510719,"prompt-eng":0.4977261336,"data-quality":0.0512257321,"ml-security":0.1286729634}}
{"text":"Such interactions suffer from real-world and large-scale experimentation and tend to ignore the 'imperfectness' of the everyday user.","meta":{"url":"http://arxiv.org/abs/2307.04462v1"},"cats":{"new-dataset":0.0639603956,"dev-research":0.4632845738,"prompt-eng":0.4278807682,"data-quality":0.1434356545,"ml-security":0.1985988974}}
{"text":"Robot explanations can be used to approach and mitigate failures, by expressing robot legibility and incapability, and within the perspective of common-ground.","meta":{"url":"http://arxiv.org/abs/2307.04462v1"},"cats":{"new-dataset":0.0783396481,"dev-research":0.4825783271,"prompt-eng":0.4807342198,"data-quality":0.2399820664,"ml-security":0.2027726527}}
{"text":"In this paper, I discuss how failures present opportunities for explanations in interactive conversational robots and what the potentials are for the intersection of HRI and explainability research.","meta":{"url":"http://arxiv.org/abs/2307.04462v1"},"cats":{"new-dataset":0.0680890009,"dev-research":0.4767322534,"prompt-eng":0.5245758804,"data-quality":0.2383833087,"ml-security":0.1072578547}}
{"text":"Clinicians are increasingly looking towards machine learning to gain insights about patient evolutions.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.181174885,"dev-research":0.4055871957,"prompt-eng":0.439870685,"data-quality":0.1334390834,"ml-security":0.2665515318}}
{"text":"We propose a novel approach named Multi-Modal UMLS Graph Learning (MMUGL) for learning meaningful representations of medical concepts using graph neural networks over knowledge graphs based on the unified medical language system.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.1677062006,"dev-research":0.4039318998,"prompt-eng":0.456023573,"data-quality":0.1548666558,"ml-security":0.111057829}}
{"text":"These representations are aggregated to represent entire patient visits and then fed into a sequence model to perform predictions at the granularity of multiple hospital visits of a patient.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.1637357388,"dev-research":0.3879339162,"prompt-eng":0.4473825421,"data-quality":0.0636939606,"ml-security":0.1108180454}}
{"text":"We improve performance by incorporating prior medical knowledge and considering multiple modalities.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.0806667623,"dev-research":0.4244574874,"prompt-eng":0.4435350356,"data-quality":0.0884257997,"ml-security":0.0723185361}}
{"text":"We compare our method to existing architectures proposed to learn representations at different granularities on the MIMIC-III dataset and show that our approach outperforms these methods.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.4325322952,"dev-research":0.385390754,"prompt-eng":0.5072972513,"data-quality":0.1877226648,"ml-security":0.216592242}}
{"text":"The results demonstrate the significance of multi-modal medical concept representations based on prior medical knowledge.","meta":{"url":"http://arxiv.org/abs/2307.04461v1"},"cats":{"new-dataset":0.1103212368,"dev-research":0.430152594,"prompt-eng":0.464440983,"data-quality":0.1337797874,"ml-security":0.1022601116}}
{"text":"An Operating System (OS) combines multiple interdependent software packages, which usually have their own independently developed architectures.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.1015349023,"dev-research":0.5178474734,"prompt-eng":0.4336390933,"data-quality":0.063642612,"ml-security":0.1610340068}}
{"text":"When a multitude of independent packages are placed together in an OS, an implicit inter-package architecture is formed.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.0914797424,"dev-research":0.5122674785,"prompt-eng":0.4360030743,"data-quality":0.1058819695,"ml-security":0.1271235968}}
{"text":"For an evolutionary effort, designers/developers of OS can greatly benefit from fully understanding the system-wide dependency focused on individual files, specifically executable files, and dynamically loadable libraries.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.1276997032,"dev-research":0.5237289826,"prompt-eng":0.4436347774,"data-quality":0.0831494078,"ml-security":0.1908490299}}
{"text":"We propose a framework, DepEx, aimed at discovering the detailed package relations at the level of individual binary files and their associated evolutionary changes.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.4754895469,"dev-research":0.518433247,"prompt-eng":0.4741063206,"data-quality":0.1862607811,"ml-security":0.1157979382}}
{"text":"We demonstrate the utility of DepEx by systematically investigating the evolution of a large-scale Open Source OS, Ubuntu.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.2647908645,"dev-research":0.4934942076,"prompt-eng":0.4670541314,"data-quality":0.0669799017,"ml-security":0.1526547005}}
{"text":"DepEx enabled us to systematically acquire and analyze the dependencies in different versions of Ubuntu released between 2005 (5.04) to 2023 (23.04).","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.24067089,"dev-research":0.4910576658,"prompt-eng":0.4857677151,"data-quality":0.1025355986,"ml-security":0.0713490181}}
{"text":"Our analysis revealed various evolutionary trends in package management and their implications based on the analysis of the 84 consecutive versions available for download (these include beta versions).","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.3275767452,"dev-research":0.5065613528,"prompt-eng":0.4621105697,"data-quality":0.1306912305,"ml-security":0.1301565492}}
{"text":"This study has enabled us to assert that DepEx can provide researchers and practitioners with a better understanding of the implicit software dependencies in order to improve the stability, performance, and functionality of their software as well as to reduce the risk of issues arising during maintenance, updating, or migration.","meta":{"url":"http://arxiv.org/abs/2307.04458v1"},"cats":{"new-dataset":0.1348662693,"dev-research":0.5644310854,"prompt-eng":0.4591131682,"data-quality":0.112712394,"ml-security":0.1563569418}}
{"text":"Image Quality Assessment (IQA) is a challenging task that requires training on massive datasets to achieve accurate predictions.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.3735693552,"dev-research":0.3714662803,"prompt-eng":0.4310227762,"data-quality":0.2232289202,"ml-security":0.0857660271}}
{"text":"However, due to the lack of IQA data, deep learning-based IQA methods typically rely on pre-trained networks trained on massive datasets as feature extractors to enhance their generalization ability, such as the ResNet network trained on ImageNet.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.2346087519,"dev-research":0.384214051,"prompt-eng":0.4408346763,"data-quality":0.1322428804,"ml-security":0.1830939889}}
{"text":"In this paper, we utilize the encoder of Segment Anything, a recently proposed segmentation model trained on a massive dataset, for high-level semantic feature extraction.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.2838375118,"dev-research":0.3743541969,"prompt-eng":0.4518496825,"data-quality":0.205382144,"ml-security":0.1174299297}}
{"text":"Most IQA methods are limited to extracting spatial-domain features, while frequency-domain features have been shown to better represent noise and blur.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.1715089258,"dev-research":0.3778120819,"prompt-eng":0.3882645449,"data-quality":0.1468690212,"ml-security":0.0798284905}}
{"text":"Therefore, we leverage both spatial-domain and frequency-domain features by applying Fourier and standard convolutions on the extracted features, respectively.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.1543944115,"dev-research":0.3501864507,"prompt-eng":0.4169667709,"data-quality":0.1646767432,"ml-security":0.1134957236}}
{"text":"Extensive experiments are conducted to demonstrate the effectiveness of all the proposed components, and results show that our approach outperforms the state-of-the-art (SOTA) in four representative datasets, both qualitatively and quantitatively.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.4348079335,"dev-research":0.3853700145,"prompt-eng":0.4574375549,"data-quality":0.1471655101,"ml-security":0.1323628451}}
{"text":"Our experiments confirm the powerful feature extraction capabilities of Segment Anything and highlight the value of combining spatial-domain and frequency-domain features in IQA tasks.","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.1446426777,"dev-research":0.3771433782,"prompt-eng":0.4459011953,"data-quality":0.1551058825,"ml-security":0.0593858918}}
{"text":"Code: https://github.com/Hedlen/SAM-IQA","meta":{"url":"http://arxiv.org/abs/2307.04455v1"},"cats":{"new-dataset":0.4356293013,"dev-research":0.4885347334,"prompt-eng":0.4609002376,"data-quality":0.0930286597,"ml-security":0.0900849909}}
{"text":"Last-mile delivery of goods has gained a lot of attraction during the COVID-19 pandemic.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.2422976614,"dev-research":0.4167601104,"prompt-eng":0.4351922249,"data-quality":0.0741669084,"ml-security":0.1466693607}}
{"text":"However, current package delivery processes often lead to parking in the second lane, which in turn has negative effects on the urban environment in which the deliveries take place, i.e., traffic congestion and safety issues for other road users.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1030624287,"dev-research":0.4556756622,"prompt-eng":0.3981227476,"data-quality":0.1857988618,"ml-security":0.1885281632}}
{"text":"To tackle these challenges, an effective autonomous delivery system is required that guarantees efficient, flexible and safe delivery of goods.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1480484966,"dev-research":0.4130857187,"prompt-eng":0.4207715016,"data-quality":0.1018891582,"ml-security":0.1656676963}}
{"text":"The project LogiSmile, co-funded by EIT Urban Mobility, pilots an autonomous delivery vehicle dubbed the Autonomous Hub Vehicle (AHV) that works in cooperation with a small autonomous robot called the Autonomous Delivery Device (ADD).","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1478781585,"dev-research":0.4709735695,"prompt-eng":0.439232477,"data-quality":0.093240462,"ml-security":0.0851341352}}
{"text":"With the two cooperating robots, the project LogiSmile aims to find a possible solution to the challenges of urban goods distribution in congested areas and to demonstrate the future of urban mobility.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1482638719,"dev-research":0.4247982564,"prompt-eng":0.4321153921,"data-quality":0.0661133085,"ml-security":0.1275003509}}
{"text":"As a member of Nieders\\\"achsische Forschungszentrum f\\\"ur Fahrzeugtechnik (NFF), the Institute for Software and Systems Engineering (ISSE) developed an integrated software safety architecture for runtime monitoring of the AHV, with (1) a dependability cage (DC) used for the on-board monitoring of the AHV, and (2) a remote command control center (CCC) which enables the remote off-board supervision of a fleet of AHVs.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1643050798,"dev-research":0.4788641583,"prompt-eng":0.443106499,"data-quality":0.1414927035,"ml-security":0.1159175564}}
{"text":"The DC supervises the vehicle continuously and in case of any safety violation, it switches the nominal driving mode to degraded driving mode or fail-safe mode.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.0546284259,"dev-research":0.4101755461,"prompt-eng":0.4435836973,"data-quality":0.1598608355,"ml-security":0.1253318518}}
{"text":"Additionally, the CCC also manages the communication of the AHV with the ADD and provides fail-operational solutions for the AHV when it cannot handle complex situations autonomously.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.0553090486,"dev-research":0.4746329738,"prompt-eng":0.4346040668,"data-quality":0.1257836534,"ml-security":0.0918070261}}
{"text":"The runtime monitoring concept developed for the AHV has been demonstrated in 2022 in Hamburg.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.1704816658,"dev-research":0.4471691513,"prompt-eng":0.4390724398,"data-quality":0.0862603189,"ml-security":0.1425013347}}
{"text":"We report on the obtained results and on the lessons learned.","meta":{"url":"http://arxiv.org/abs/2307.04454v1"},"cats":{"new-dataset":0.3941967448,"dev-research":0.4443185674,"prompt-eng":0.4884606399,"data-quality":0.2657324967,"ml-security":0.0816677839}}
{"text":"Continuously-worn wearable sensors enable researchers to collect copious amounts of rich bio-behavioral time series recordings of real-life activities of daily living, offering unprecedented opportunities to infer novel human behavior patterns during daily routines.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.317917739,"dev-research":0.3827591973,"prompt-eng":0.4229101077,"data-quality":0.0676482022,"ml-security":0.1535544775}}
{"text":"Existing approaches to routine discovery through bio-behavioral data rely either on pre-defined notions of activities or use additional non-behavioral measurements as contexts, such as GPS location or localization within the home, presenting risks to user privacy.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.2899695962,"dev-research":0.4294989113,"prompt-eng":0.4480494974,"data-quality":0.1160087646,"ml-security":0.3186593191}}
{"text":"In this work, we propose a novel wearable time-series mining framework, Hawkes point process On Time series clusters for ROutine Discovery (HOT-ROD), for uncovering behavioral routines from completely unlabeled wearable recordings.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.2235038447,"dev-research":0.3807336783,"prompt-eng":0.421313985,"data-quality":0.0935995015,"ml-security":0.1701731431}}
{"text":"We utilize a covariance-based method to generate time-series clusters and discover routines via the Hawkes point process learning algorithm.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.1382384355,"dev-research":0.3866056005,"prompt-eng":0.430387903,"data-quality":0.0921158669,"ml-security":0.1247897252}}
{"text":"We empirically validate our approach for extracting routine behaviors using a completely unlabeled time-series collected continuously from over 100 individuals both in and outside of the workplace during a period of ten weeks.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.2168810723,"dev-research":0.3916693283,"prompt-eng":0.4416285826,"data-quality":0.1319655984,"ml-security":0.1737050941}}
{"text":"Furthermore, we demonstrate this approach intuitively captures daily transitional relationships between physical activity states without using prior knowledge.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.1477198648,"dev-research":0.4222269333,"prompt-eng":0.4119871986,"data-quality":0.0577544615,"ml-security":0.0889251188}}
{"text":"We also show that the learned behavioral patterns can assist in illuminating an individual's personality and affect.","meta":{"url":"http://arxiv.org/abs/2307.04445v1"},"cats":{"new-dataset":0.1163474017,"dev-research":0.4952399592,"prompt-eng":0.4830339214,"data-quality":0.1371383557,"ml-security":0.1572035841}}
{"text":"Edge computing aims to enable edge devices, such as IoT devices, to process data locally instead of relying on the cloud.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.1019915377,"dev-research":0.4539421857,"prompt-eng":0.3587456725,"data-quality":0.0565817175,"ml-security":0.1794182927}}
{"text":"However, deep learning techniques like computer vision and natural language processing can be computationally expensive and memory-intensive.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.114032521,"dev-research":0.3889867643,"prompt-eng":0.3889656699,"data-quality":0.1140207079,"ml-security":0.2360072883}}
{"text":"Creating manual architectures specialized for each device is infeasible due to their varying memory and computational constraints.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.0761639582,"dev-research":0.4386929404,"prompt-eng":0.455239285,"data-quality":0.0478333355,"ml-security":0.0933598142}}
{"text":"To address these concerns, we automate the construction of task-specific deep learning architectures optimized for device constraints through Neural Architecture Search (NAS).","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.143843453,"dev-research":0.3934650291,"prompt-eng":0.47932316,"data-quality":0.1012132963,"ml-security":0.2063779373}}
{"text":"We present DCA-NAS, a principled method of fast neural network architecture search that incorporates edge-device constraints such as model size and floating-point operations.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.0570220717,"dev-research":0.363062426,"prompt-eng":0.3724886627,"data-quality":0.0804602575,"ml-security":0.1425340696}}
{"text":"It incorporates weight sharing and channel bottleneck techniques to speed up the search time.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.0714530367,"dev-research":0.3930594671,"prompt-eng":0.4089293438,"data-quality":0.0514870444,"ml-security":0.1113304538}}
{"text":"Based on our experiments, we see that DCA-NAS outperforms manual architectures for similar sized models and is comparable to popular mobile architectures on various image classification datasets like CIFAR-10, CIFAR-100, and Imagenet-1k.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.2277483761,"dev-research":0.3625572112,"prompt-eng":0.4651921867,"data-quality":0.1394709481,"ml-security":0.124495056}}
{"text":"Experiments with search spaces -- DARTS and NAS-Bench-201 show the generalization capabilities of DCA-NAS.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.0494357236,"dev-research":0.3856678789,"prompt-eng":0.4032568357,"data-quality":0.0903973369,"ml-security":0.1209014194}}
{"text":"On further evaluating our approach on Hardware-NAS-Bench, device-specific architectures with low inference latency and state-of-the-art performance were discovered.","meta":{"url":"http://arxiv.org/abs/2307.04443v1"},"cats":{"new-dataset":0.0993548769,"dev-research":0.3736308289,"prompt-eng":0.4366478684,"data-quality":0.0854883056,"ml-security":0.0778549335}}
{"text":"Knee osteoarthritis (KOA) is a widespread condition that can cause chronic pain and stiffness in the knee joint.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.1569089911,"dev-research":0.4077995194,"prompt-eng":0.35147604,"data-quality":0.1101835341,"ml-security":0.097057091}}
{"text":"Early detection and diagnosis are crucial for successful clinical intervention and management to prevent severe complications, such as loss of mobility.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.0727496952,"dev-research":0.3884591468,"prompt-eng":0.4375163877,"data-quality":0.139537563,"ml-security":0.1509487885}}
{"text":"In this paper, we propose an automated approach that employs the Swin Transformer to predict the severity of KOA.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.1162301991,"dev-research":0.3850569979,"prompt-eng":0.4653061201,"data-quality":0.1524383529,"ml-security":0.1526772831}}
{"text":"Our model uses publicly available radiographic datasets with Kellgren and Lawrence scores to enable early detection and severity assessment.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.3996596919,"dev-research":0.3666465234,"prompt-eng":0.4697710214,"data-quality":0.166708094,"ml-security":0.1528189658}}
{"text":"To improve the accuracy of our model, we employ a multi-prediction head architecture that utilizes multi-layer perceptron classifiers.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.1326902176,"dev-research":0.3694751118,"prompt-eng":0.4750560127,"data-quality":0.1807887033,"ml-security":0.1783315985}}
{"text":"Additionally, we introduce a novel training approach that reduces the data drift between multiple datasets to ensure the generalization ability of the model.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.2476090775,"dev-research":0.3756844405,"prompt-eng":0.4552597802,"data-quality":0.2681939686,"ml-security":0.3095858409}}
{"text":"The results of our experiments demonstrate the effectiveness and feasibility of our approach in predicting KOA severity accurately.","meta":{"url":"http://arxiv.org/abs/2307.04442v1"},"cats":{"new-dataset":0.1452318661,"dev-research":0.3964129163,"prompt-eng":0.4680630417,"data-quality":0.2237984757,"ml-security":0.1503286892}}
{"text":"We prove a characterization of the structural conditions on matrices of sign-rank 3 and unit disk graphs (UDGs) which permit constant-cost public-coin randomized communication protocols.","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.1305492913,"dev-research":0.4035725017,"prompt-eng":0.3876312621,"data-quality":0.112265574,"ml-security":0.2137019186}}
{"text":"Therefore, under these conditions, these graphs also admit implicit representations.   ","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.1059358652,"dev-research":0.4646724393,"prompt-eng":0.3817706351,"data-quality":0.2280648018,"ml-security":0.1890465232}}
{"text":"The sign-rank of a matrix $M \\in \\{\\pm 1\\}^{N \\times N}$ is the smallest rank of a matrix $R$ such that $M_{i,j} = \\mathrm{sign}(R_{i,j})$ for all $i,j \\in","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.1361434889,"dev-research":0.3993466557,"prompt-eng":0.4174525896,"data-quality":0.0992274818,"ml-security":0.1110715667}}
{"text":"[N]$; equivalently, it is the smallest dimension $d$ in which $M$ can be represented as a point-halfspace incidence matrix with halfspaces through the origin, and it is essentially equivalent to the unbounded-error communication complexity.","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.0868475762,"dev-research":0.416218453,"prompt-eng":0.3619973506,"data-quality":0.1055845801,"ml-security":0.1345468027}}
{"text":"Matrices of sign-rank 3 can achieve the maximum possible bounded-error randomized communication complexity $\\Theta(\\log N)$, and meanwhile the existence of implicit representations for graphs of bounded sign-rank (including UDGs, which have sign-rank 4) has been open since at least 2003.","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.1095179691,"dev-research":0.4092083968,"prompt-eng":0.3864961729,"data-quality":0.1106289037,"ml-security":0.2323683475}}
{"text":"We prove that matrices of sign-rank 3, and UDGs, have constant randomized communication complexity if and only if they do not encode arbitrarily large instances of the Greater-Than communication problem, or, equivalently, if they do not contain arbitrarily large half-graphs as semi-induced subgraphs.","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.1067733882,"dev-research":0.4139184911,"prompt-eng":0.3761220424,"data-quality":0.1396448377,"ml-security":0.226225951}}
{"text":"This also establishes the existence of implicit representations for these graphs under the same conditions.","meta":{"url":"http://arxiv.org/abs/2307.04441v1"},"cats":{"new-dataset":0.0897555392,"dev-research":0.4553777669,"prompt-eng":0.3763948541,"data-quality":0.1931525638,"ml-security":0.1679630953}}
{"text":"Terahertz (THz) integrated sensing and communication (ISAC) enables simultaneous data transmission with Terabit-per-second (Tbps) rate and millimeter-level accurate sensing.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0947100054,"dev-research":0.3840468846,"prompt-eng":0.422408749,"data-quality":0.0700538538,"ml-security":0.1190764771}}
{"text":"To realize such a blueprint, ultra-massive antenna arrays with directional beamforming are used to compensate for severe path loss in the THz band.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0431923437,"dev-research":0.3786340093,"prompt-eng":0.3831714308,"data-quality":0.0865530488,"ml-security":0.122560948}}
{"text":"In this paper, the time-frequency-space transmit design is investigated for THz ISAC to generate time-varying scanning sensing beams and stable communication beams.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0821402132,"dev-research":0.3874168346,"prompt-eng":0.4246291559,"data-quality":0.0624325533,"ml-security":0.1159442659}}
{"text":"Specifically, with the dynamic array-of-subarray (DAoSA) hybrid beamforming architecture and multi-carrier modulation, two ISAC hybrid precoding algorithms are proposed, namely, a vectorization (VEC) based algorithm that outperforms existing ISAC hybrid precoding methods and a low-complexity sensing codebook assisted (SCA) approach.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0777251813,"dev-research":0.3765510062,"prompt-eng":0.3983058778,"data-quality":0.0886891131,"ml-security":0.1370172758}}
{"text":"Meanwhile, coupled with the transmit design, parameter estimation algorithms are proposed to realize high-accuracy sensing, including a wideband DAoSA MUSIC (W-DAoSA-MUSIC) method for angle estimation and a sum-DFT-GSS (S-DFT-GSS) approach for range and velocity estimation.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.1429574808,"dev-research":0.3448754466,"prompt-eng":0.3800286522,"data-quality":0.1003278399,"ml-security":0.1193655815}}
{"text":"Numerical results indicate that the proposed algorithms can realize centi-degree-level angle estimation accuracy and millimeter-level range estimation accuracy, which are one or two orders of magnitudes better than the methods in the millimeter-wave band.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0860337115,"dev-research":0.373307522,"prompt-eng":0.3917017347,"data-quality":0.1256484047,"ml-security":0.0897312616}}
{"text":"In addition, to overcome the cyclic prefix limitation and Doppler effects in the THz band, an inter-symbol interference- and inter-carrier interference-tackled sensing algorithm is developed to refine sensing capabilities for THz ISAC.","meta":{"url":"http://arxiv.org/abs/2307.04440v1"},"cats":{"new-dataset":0.0380587625,"dev-research":0.398052007,"prompt-eng":0.4115472171,"data-quality":0.1077713021,"ml-security":0.1474495642}}
{"text":"The Global Precedence Effect (GPE) suggests that the processing of global properties of a visual stimulus precedes the processing of local properties.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0439173477,"dev-research":0.4324058145,"prompt-eng":0.4543016081,"data-quality":0.1208201648,"ml-security":0.0705267981}}
{"text":"The generality of this theory was argued for four decades during different known Perceptual Field Variables.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0478525011,"dev-research":0.3827892908,"prompt-eng":0.3820184133,"data-quality":0.0864363985,"ml-security":0.0727190003}}
{"text":"The effect size of various PFVs, regarding the findings during these four decades, were pooled in our recent meta-analysis study.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.1006225342,"dev-research":0.3901736878,"prompt-eng":0.3954977989,"data-quality":0.1122169005,"ml-security":0.0814895861}}
{"text":"Pursuing the study, in the present paper, we explore the effects of Congruency, Size, and Sparsity and their interaction on global advantage in two different experiments with different task paradigms; Matching judgment and Similarity judgment.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0387123657,"dev-research":0.4326161378,"prompt-eng":0.3977367952,"data-quality":0.059979243,"ml-security":0.0829024846}}
{"text":"Upon results of these experiments, Congruency and Size have significant effects and Sparsity has small effects.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0421839583,"dev-research":0.3863360792,"prompt-eng":0.4144257364,"data-quality":0.1339681128,"ml-security":0.0792437211}}
{"text":"Also, the task paradigm and its interaction with other PFVs are shown significant effects in this study, which shows the prominence of the role of task paradigms in evaluating PFVs' effects on GPE.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0479355021,"dev-research":0.4531412566,"prompt-eng":0.4301371686,"data-quality":0.0715409254,"ml-security":0.0799045516}}
{"text":"Also, we found that the effects of these parameters were not specific to the special condition that individuals were instructed to retinal stabilize.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0456120747,"dev-research":0.3978941039,"prompt-eng":0.3835463918,"data-quality":0.1030750157,"ml-security":0.080596177}}
{"text":"So, the experiments were more extendible to daily human behavior.","meta":{"url":"http://arxiv.org/abs/2307.04435v1"},"cats":{"new-dataset":0.0944051336,"dev-research":0.4446516828,"prompt-eng":0.387821012,"data-quality":0.0855263781,"ml-security":0.1328643353}}
{"text":"The automatic inspection of surface defects is an important task for quality control in the computers, communications, and consumer electronics (3C) industry.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0674601757,"dev-research":0.4580186219,"prompt-eng":0.451703679,"data-quality":0.3244437336,"ml-security":0.0869147337}}
{"text":"Conventional devices for defect inspection (viz.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0562052136,"dev-research":0.427196897,"prompt-eng":0.4334988097,"data-quality":0.2373590378,"ml-security":0.0912227589}}
{"text":"line-scan sensors) have a limited field of view, thus, a robot-aided defect inspection system needs to scan the object from multiple viewpoints.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0710899761,"dev-research":0.4014127535,"prompt-eng":0.3881277352,"data-quality":0.1260317964,"ml-security":0.0777139453}}
{"text":"Optimally selecting the robot's viewpoints and planning a path is regarded as coverage path planning (CPP), a problem that enables inspecting the object's complete surface while reducing the scanning time and avoiding misdetection of defects.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0555352769,"dev-research":0.4304113927,"prompt-eng":0.4134641647,"data-quality":0.0629251163,"ml-security":0.108348273}}
{"text":"However, the development of CPP strategies for robotic line scanners has not been sufficiently studied by researchers.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0425415146,"dev-research":0.3849292499,"prompt-eng":0.4018957,"data-quality":0.089361527,"ml-security":0.074671693}}
{"text":"To fill this gap in the literature, in this paper, we present a new approach for robotic line scanners to detect surface defects of 3C free-form objects automatically.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0771841586,"dev-research":0.3994300426,"prompt-eng":0.417297549,"data-quality":0.2243509705,"ml-security":0.0812993917}}
{"text":"Our proposed solution consists of generating a local path by a new hybrid region segmentation method and an adaptive planning algorithm to ensure the coverage of the complete object surface.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0840333689,"dev-research":0.3924212595,"prompt-eng":0.3972674424,"data-quality":0.0830166813,"ml-security":0.0517277895}}
{"text":"An optimization method for the global path sequence is developed to maximize the scanning efficiency.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0590792912,"dev-research":0.3867953781,"prompt-eng":0.3898814885,"data-quality":0.0696652006,"ml-security":0.0643939648}}
{"text":"To verify our proposed methodology, we conduct detailed simulation-based and experimental studies on various free-form workpieces, and compare its performance with a state-of-the-art solution.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0450648052,"dev-research":0.3964484684,"prompt-eng":0.3751763663,"data-quality":0.0652959848,"ml-security":0.0529558898}}
{"text":"The reported results demonstrate the feasibility and effectiveness of our approach.","meta":{"url":"http://arxiv.org/abs/2307.04431v1"},"cats":{"new-dataset":0.0667306095,"dev-research":0.4337377247,"prompt-eng":0.4429578828,"data-quality":0.1014138965,"ml-security":0.0882925217}}
{"text":"Cognitive diagnosis plays a vital role in modern intelligent education platforms to reveal students' proficiency in knowledge concepts for subsequent adaptive tasks.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.1376089522,"dev-research":0.4652719374,"prompt-eng":0.491731716,"data-quality":0.1933472361,"ml-security":0.144395109}}
{"text":"However, due to the requirement of high model interpretability, existing manually designed cognitive diagnosis models hold too simple architectures to meet the demand of current intelligent education systems, where the bias of human design also limits the emergence of effective cognitive diagnosis models.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.0712118644,"dev-research":0.4495083653,"prompt-eng":0.5157147991,"data-quality":0.1807576919,"ml-security":0.2182234445}}
{"text":"In this paper, we propose to automatically design novel cognitive diagnosis models by evolutionary multi-objective neural architecture search (NAS).","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.0924281776,"dev-research":0.4133654342,"prompt-eng":0.4852785234,"data-quality":0.1301169909,"ml-security":0.1346026916}}
{"text":"Specifically, we observe existing models can be represented by a general model handling three given types of inputs and thus first design an expressive search space for the NAS task in cognitive diagnosis.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.0851297732,"dev-research":0.4503717501,"prompt-eng":0.5367634601,"data-quality":0.1445828997,"ml-security":0.1437994915}}
{"text":"Then, we propose multi-objective genetic programming (MOGP) to explore the NAS task's search space by maximizing model performance and interpretability.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.1216841895,"dev-research":0.4247092961,"prompt-eng":0.4322971885,"data-quality":0.0732456124,"ml-security":0.1171774348}}
{"text":"In the MOGP design, each architecture is transformed into a tree architecture and encoded by a tree for easy optimization, and a tailored genetic operation based on four sub-genetic operations is devised to generate offspring effectively.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.0795374399,"dev-research":0.4161469119,"prompt-eng":0.3991805025,"data-quality":0.054884284,"ml-security":0.0819125005}}
{"text":"Besides, an initialization strategy is also suggested to accelerate the convergence by evolving half of the population from existing models' variants.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.0466413887,"dev-research":0.3913253671,"prompt-eng":0.418015703,"data-quality":0.0627962446,"ml-security":0.1425585044}}
{"text":"Experiments on two real-world datasets demonstrate that the cognitive diagnosis models searched by the proposed approach exhibit significantly better performance than existing models and also hold as good interpretability as human-designed models.","meta":{"url":"http://arxiv.org/abs/2307.04429v1"},"cats":{"new-dataset":0.1989711068,"dev-research":0.4225029782,"prompt-eng":0.4978233103,"data-quality":0.2335050006,"ml-security":0.1757711069}}
{"text":"The ability of robots to navigate through doors is crucial for their effective operation in indoor environments.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0541440251,"dev-research":0.4205786667,"prompt-eng":0.4528684462,"data-quality":0.0738474651,"ml-security":0.1176860136}}
{"text":"Consequently, extensive research has been conducted to develop robots capable of opening specific doors.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0810407404,"dev-research":0.4251166065,"prompt-eng":0.4481468107,"data-quality":0.05673363,"ml-security":0.090037365}}
{"text":"However, the diverse combinations of door handles and opening directions necessitate a more versatile door opening system for robots to successfully operate in real-world environments.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0728489267,"dev-research":0.4361206254,"prompt-eng":0.4484277529,"data-quality":0.0536389389,"ml-security":0.0965429146}}
{"text":"In this paper, we propose a mobile manipulator system that can autonomously open various doors without prior knowledge.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.1174120506,"dev-research":0.4166031177,"prompt-eng":0.4463988898,"data-quality":0.0793076305,"ml-security":0.1428467198}}
{"text":"By using convolutional neural networks, point cloud extraction techniques, and external force measurements during exploratory motion, we obtained information regarding handle types, poses, and door characteristics.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.2611950299,"dev-research":0.3627023312,"prompt-eng":0.4294373703,"data-quality":0.0660463826,"ml-security":0.098133765}}
{"text":"Through two different approaches, adaptive position-force control and deep reinforcement learning, we successfully opened doors without precise trajectory or excessive external force.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.1145958311,"dev-research":0.3796926912,"prompt-eng":0.4170778917,"data-quality":0.0801487596,"ml-security":0.2141668692}}
{"text":"The adaptive position-force control method involves moving the end-effector in the direction of the door opening while responding compliantly to external forces, ensuring safety and manipulator workspace.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0552585309,"dev-research":0.4515794083,"prompt-eng":0.4185315993,"data-quality":0.0873632469,"ml-security":0.128590908}}
{"text":"Meanwhile, the deep reinforcement learning policy minimizes applied forces and eliminates unnecessary movements, enabling stable operation across doors with different poses and widths.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0857683961,"dev-research":0.3693795562,"prompt-eng":0.4062221188,"data-quality":0.0619252429,"ml-security":0.1933548861}}
{"text":"The RL-based approach outperforms the adaptive position-force control method in terms of compensating for external forces, ensuring smooth motion, and achieving efficient speed.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0598923163,"dev-research":0.4028162987,"prompt-eng":0.3574418658,"data-quality":0.0584499775,"ml-security":0.0783262546}}
{"text":"It reduces the maximum force required by 3.27 times and improves motion smoothness by 1.82 times.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.057137856,"dev-research":0.4084356339,"prompt-eng":0.3426195278,"data-quality":0.0524092848,"ml-security":0.0491295775}}
{"text":"However, the non-learning-based adaptive position-force control method demonstrates more versatility in opening a wider range of doors, encompassing revolute doors with four distinct opening directions and varying widths.","meta":{"url":"http://arxiv.org/abs/2307.04422v1"},"cats":{"new-dataset":0.0500202906,"dev-research":0.4100513545,"prompt-eng":0.4103830842,"data-quality":0.0700260132,"ml-security":0.1555336729}}
{"text":"With the rapid proliferation of Internet of Things (IoT) devices and the growing concern for data privacy among the public, Federated Learning (FL) has gained significant attention as a privacy-preserving machine learning paradigm.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.2320880724,"dev-research":0.3724877124,"prompt-eng":0.4350351241,"data-quality":0.1246279442,"ml-security":0.5751868296}}
{"text":"FL enables the training of a global model among clients without exposing local data.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.2013549537,"dev-research":0.4320376482,"prompt-eng":0.4457194974,"data-quality":0.1170419642,"ml-security":0.3763809392}}
{"text":"However, when a federated learning system runs on wireless communication networks, limited wireless resources, heterogeneity of clients, and network transmission failures affect its performance and accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.0567064719,"dev-research":0.3942275168,"prompt-eng":0.4148194373,"data-quality":0.1890360356,"ml-security":0.3595711685}}
{"text":"In this study, we propose a novel dynamic cross-tier FL scheme, named FedDCT to increase training accuracy and performance in wireless communication networks.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.085087566,"dev-research":0.3764493194,"prompt-eng":0.4185562491,"data-quality":0.1132985271,"ml-security":0.2532917336}}
{"text":"We utilize a tiering algorithm that dynamically divides clients into different tiers according to specific indicators and assigns specific timeout thresholds to each tier to reduce the training time required.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.063018358,"dev-research":0.4032416983,"prompt-eng":0.4081828529,"data-quality":0.104374844,"ml-security":0.2598724921}}
{"text":"To improve the accuracy of the model without increasing the training time, we introduce a cross-tier client selection algorithm that can effectively select the tiers and participants.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.0767142363,"dev-research":0.3953229724,"prompt-eng":0.4629885938,"data-quality":0.0816797219,"ml-security":0.1886167659}}
{"text":"Simulation experiments show that our scheme can make the model converge faster and achieve a higher accuracy in wireless communication networks.","meta":{"url":"http://arxiv.org/abs/2307.04420v1"},"cats":{"new-dataset":0.0473184167,"dev-research":0.384779286,"prompt-eng":0.3940906069,"data-quality":0.1041489747,"ml-security":0.1935802129}}
{"text":"Federated learning (FL) has garnered considerable attention due to its privacy-preserving feature.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.218297588,"dev-research":0.4069964976,"prompt-eng":0.446404502,"data-quality":0.1238293858,"ml-security":0.4613870404}}
{"text":"Nonetheless, the lack of freedom in managing user data can lead to group fairness issues, where models might be biased towards sensitive factors such as race or gender, even if they are trained using a legally compliant process.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.1339462934,"dev-research":0.4212559172,"prompt-eng":0.4052666601,"data-quality":0.1515113387,"ml-security":0.5222623625}}
{"text":"To redress this concern, this paper proposes a novel FL algorithm designed explicitly to address group fairness issues.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.103389661,"dev-research":0.3872511617,"prompt-eng":0.3757922213,"data-quality":0.1353462466,"ml-security":0.3355939663}}
{"text":"We show empirically on CelebA and ImSitu datasets that the proposed method can improve fairness both quantitatively and qualitatively with minimal loss in accuracy in the presence of statistical heterogeneity and with different numbers of clients.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.2291532381,"dev-research":0.4003764719,"prompt-eng":0.4231625639,"data-quality":0.2410174844,"ml-security":0.4015145891}}
{"text":"Besides improving fairness, the proposed FL algorithm is compatible with local differential privacy (LDP), has negligible communication costs, and results in minimal overhead when migrating existing FL systems from the common FL protocol such as FederatedAveraging (FedAvg).","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.2046414929,"dev-research":0.3910208515,"prompt-eng":0.3976150721,"data-quality":0.1014102242,"ml-security":0.396939442}}
{"text":"We also provide the theoretical convergence rate guarantee for the proposed algorithm and the required noise level of the Gaussian mechanism to achieve desired LDP.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.0433130274,"dev-research":0.3180127842,"prompt-eng":0.3729119011,"data-quality":0.1324584821,"ml-security":0.1120886878}}
{"text":"This innovative approach holds significant potential to enhance the fairness and effectiveness of FL systems, particularly in sensitive applications such as healthcare or criminal justice.","meta":{"url":"http://arxiv.org/abs/2307.04417v1"},"cats":{"new-dataset":0.0858030226,"dev-research":0.4308332159,"prompt-eng":0.4051664752,"data-quality":0.0996673939,"ml-security":0.4024797026}}
{"text":"Cyber ranges mimic real-world cyber environments and are in high demand.","meta":{"url":"http://arxiv.org/abs/2307.04416v1"},"cats":{"new-dataset":0.1832809285,"dev-research":0.4083972684,"prompt-eng":0.4263586733,"data-quality":0.0648633728,"ml-security":0.1996277011}}
{"text":"Before building their own cyber ranges, organizations need to deeply understand what construction supplies are available to them.","meta":{"url":"http://arxiv.org/abs/2307.04416v1"},"cats":{"new-dataset":0.2073184646,"dev-research":0.4810674533,"prompt-eng":0.4525598564,"data-quality":0.0992310044,"ml-security":0.1911074181}}
{"text":"A fundamental supply is the cyber range architecture, which prompts an important research question: Which cyber range architecture is most appropriate for an organization's requirements?","meta":{"url":"http://arxiv.org/abs/2307.04416v1"},"cats":{"new-dataset":0.1365594651,"dev-research":0.4050775369,"prompt-eng":0.3725644873,"data-quality":0.0435558973,"ml-security":0.1236948276}}
{"text":"To answer this question, we propose an innovative framework to specify cyber range requirements, characterize cyber range architectures (based on our analysis of 45 cyber range architectures), and match cyber range architectures to cyber range requirements.","meta":{"url":"http://arxiv.org/abs/2307.04416v1"},"cats":{"new-dataset":0.111265174,"dev-research":0.4267117709,"prompt-eng":0.4251631174,"data-quality":0.0582150192,"ml-security":0.1812832908}}
{"text":"Biomedical summarization requires large datasets to train for text generation.","meta":{"url":"http://arxiv.org/abs/2307.04412v1"},"cats":{"new-dataset":0.4104896715,"dev-research":0.4335383172,"prompt-eng":0.483466553,"data-quality":0.1509917015,"ml-security":0.0930134895}}
{"text":"We show that while transfer learning offers a viable option for addressing this challenge, an in-domain pre-training does not always offer advantages in a BioASQ summarization task.","meta":{"url":"http://arxiv.org/abs/2307.04412v1"},"cats":{"new-dataset":0.2789885856,"dev-research":0.4161503476,"prompt-eng":0.5187736239,"data-quality":0.1525410034,"ml-security":0.0885035429}}
{"text":"We identify a suitable model architecture and use it to show a benefit of a general-domain pre-training followed by a task-specific fine-tuning in the context of a BioASQ summarization task, leading to a novel three-step fine-tuning approach that works with only a thousand in-domain examples.","meta":{"url":"http://arxiv.org/abs/2307.04412v1"},"cats":{"new-dataset":0.1648625096,"dev-research":0.4314872238,"prompt-eng":0.5468721877,"data-quality":0.1713578436,"ml-security":0.0592847841}}
{"text":"Our results indicate that a Large Language Model without domain-specific pre-training can have a significant edge in some domain-specific biomedical text generation tasks.","meta":{"url":"http://arxiv.org/abs/2307.04412v1"},"cats":{"new-dataset":0.1867847172,"dev-research":0.449580702,"prompt-eng":0.5729912436,"data-quality":0.2454367725,"ml-security":0.1079146713}}
{"text":"We consider the problem of fair allocation of $m$ indivisible items to a group of $n$ agents with subsidy (money).","meta":{"url":"http://arxiv.org/abs/2307.04411v1"},"cats":{"new-dataset":0.1996360313,"dev-research":0.4076499217,"prompt-eng":0.4164450787,"data-quality":0.1180383595,"ml-security":0.2136256191}}
{"text":"Our work mainly focuses on the allocation of chores but most of our results extend to the allocation of goods as well.","meta":{"url":"http://arxiv.org/abs/2307.04411v1"},"cats":{"new-dataset":0.1767048488,"dev-research":0.4748223534,"prompt-eng":0.4302243674,"data-quality":0.0916500797,"ml-security":0.0566551402}}
{"text":"We consider the case when agents have (general) additive cost functions.","meta":{"url":"http://arxiv.org/abs/2307.04411v1"},"cats":{"new-dataset":0.0548853108,"dev-research":0.4470715386,"prompt-eng":0.3709069633,"data-quality":0.0784335709,"ml-security":0.2094828768}}
{"text":"Assuming that the maximum cost of an item to an agent can be compensated by one dollar, we show that a total of $n/4$ dollars of subsidy suffices to ensure a proportional allocation.","meta":{"url":"http://arxiv.org/abs/2307.04411v1"},"cats":{"new-dataset":0.1206022088,"dev-research":0.4288946301,"prompt-eng":0.4092413585,"data-quality":0.0929803304,"ml-security":0.170639861}}
{"text":"Moreover, we show that $n/4$ is tight in the sense that there exists an instance with $n$ agents for which every proportional allocation requires a total subsidy of at least $n/4$. We also consider the weighted case and show that a total subsidy of $(n-1)/2$ suffices to ensure a weighted proportional allocation.","meta":{"url":"http://arxiv.org/abs/2307.04411v1"},"cats":{"new-dataset":0.0744477084,"dev-research":0.4101616672,"prompt-eng":0.3669376115,"data-quality":0.1110577122,"ml-security":0.2066007105}}
{"text":"Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.1227484633,"dev-research":0.4717687429,"prompt-eng":0.5999254802,"data-quality":0.1263297708,"ml-security":0.12769161}}
{"text":"However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.0817518968,"dev-research":0.442279881,"prompt-eng":0.4799997227,"data-quality":0.1762087365,"ml-security":0.1155565245}}
{"text":"One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.036804706,"dev-research":0.4814832212,"prompt-eng":0.460072348,"data-quality":0.1953606242,"ml-security":0.080217736}}
{"text":"Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.0523820701,"dev-research":0.3729496675,"prompt-eng":0.4937665883,"data-quality":0.1616148336,"ml-security":0.158809939}}
{"text":"To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.2919788701,"dev-research":0.460975254,"prompt-eng":0.5789907005,"data-quality":0.1969364768,"ml-security":0.1169487879}}
{"text":"Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.1585839932,"dev-research":0.4353473327,"prompt-eng":0.5700621585,"data-quality":0.4342114088,"ml-security":0.1328405203}}
{"text":"We evaluate our method on WMT2022 test sets and show that it outperforms existing methods.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.1558551188,"dev-research":0.4491411383,"prompt-eng":0.4766629669,"data-quality":0.1985942911,"ml-security":0.0938340671}}
{"text":"Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a promising solution for generating high-quality translations.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.1734626234,"dev-research":0.4424304564,"prompt-eng":0.5979417243,"data-quality":0.2679839884,"ml-security":0.05784233}}
{"text":"Please refer to Github for more details: https://github.com/lemon0830/TIM.","meta":{"url":"http://arxiv.org/abs/2307.04408v1"},"cats":{"new-dataset":0.1874322285,"dev-research":0.4653265971,"prompt-eng":0.4390397088,"data-quality":0.1051138572,"ml-security":0.0849494512}}
{"text":"Large pre-trained language models achieve impressive results across many tasks.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.1809537768,"dev-research":0.4276363859,"prompt-eng":0.5855091074,"data-quality":0.1998797574,"ml-security":0.1247376168}}
{"text":"However, recent works point out that pre-trained language models may memorize a considerable fraction of their training data, leading to the privacy risk of information leakage.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.2032059828,"dev-research":0.4385019248,"prompt-eng":0.5361940083,"data-quality":0.3568030586,"ml-security":0.6637723565}}
{"text":"In this paper, we propose a method named Ethicist for targeted training data extraction through loss smoothed soft prompting and calibrated confidence estimation, investigating how to recover the suffix in the training data when given a prefix.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.2144706538,"dev-research":0.4006443724,"prompt-eng":0.5569680527,"data-quality":0.4804178048,"ml-security":0.2589091592}}
{"text":"To elicit memorization in the attacked model, we tune soft prompt embeddings while keeping the model fixed.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.0642589508,"dev-research":0.4751761167,"prompt-eng":0.6294690541,"data-quality":0.2366966393,"ml-security":0.6042362982}}
{"text":"We further propose a smoothing loss that smooths the loss distribution of the suffix tokens to make it easier to sample the correct suffix.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.0932646314,"dev-research":0.4136162575,"prompt-eng":0.4763815854,"data-quality":0.4263395326,"ml-security":0.1552323629}}
{"text":"In order to select the most probable suffix from a collection of sampled suffixes and estimate the prediction confidence, we propose a calibrated confidence estimation method, which normalizes the confidence of the generated suffixes with a local estimation.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.194503646,"dev-research":0.4049979461,"prompt-eng":0.5343587192,"data-quality":0.4360974915,"ml-security":0.1624857235}}
{"text":"We show that Ethicist significantly improves the extraction performance on a recently proposed public benchmark.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.1893611824,"dev-research":0.3780754531,"prompt-eng":0.4338383161,"data-quality":0.1954343442,"ml-security":0.1040824668}}
{"text":"We also investigate several factors influencing the data extraction performance, including decoding strategy, model scale, prefix length, and suffix length.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.1901976576,"dev-research":0.4002818998,"prompt-eng":0.4435779035,"data-quality":0.2438900965,"ml-security":0.1231024617}}
{"text":"Our code is available at https://github.com/thu-coai/Targeted-Data-Extraction.","meta":{"url":"http://arxiv.org/abs/2307.04401v1"},"cats":{"new-dataset":0.4586728725,"dev-research":0.4103175978,"prompt-eng":0.4706169035,"data-quality":0.1523645739,"ml-security":0.0922319342}}
{"text":"Segmentation of objects in a video is challenging due to the nuances such as motion blurring, parallax, occlusions, changes in illumination, etc.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.1438321841,"dev-research":0.3509803946,"prompt-eng":0.385356639,"data-quality":0.1567724546,"ml-security":0.0578047978}}
{"text":"Instead of addressing these nuances separately, we focus on building a generalizable solution that avoids overfitting to the individual intricacies.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.0758818879,"dev-research":0.5204030161,"prompt-eng":0.4158702008,"data-quality":0.1286865219,"ml-security":0.1945409907}}
{"text":"Such a solution would also help us save enormous resources involved in human annotation of video corpora.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.3232411676,"dev-research":0.4768199226,"prompt-eng":0.4895973669,"data-quality":0.3192050372,"ml-security":0.0814050574}}
{"text":"To solve Video Object Segmentation (VOS) in an unsupervised setting, we propose a new pipeline (FODVid) based on the idea of guiding segmentation outputs using flow-guided graph-cut and temporal consistency.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.216967228,"dev-research":0.3804428748,"prompt-eng":0.4336323457,"data-quality":0.1736118768,"ml-security":0.0634402474}}
{"text":"Basically, we design a segmentation model incorporating intra-frame appearance and flow similarities, and inter-frame temporal continuation of the objects under consideration.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.1966934696,"dev-research":0.3706054501,"prompt-eng":0.4440381303,"data-quality":0.1405956246,"ml-security":0.0424628478}}
{"text":"We perform an extensive experimental analysis of our straightforward methodology on the standard DAVIS16 video benchmark.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.2722477909,"dev-research":0.3852572351,"prompt-eng":0.429084356,"data-quality":0.1358859788,"ml-security":0.0601071635}}
{"text":"Though simple, our approach produces results comparable (within a range of ~2 mIoU) to the existing top approaches in unsupervised VOS.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.1230361609,"dev-research":0.3825456139,"prompt-eng":0.4425018363,"data-quality":0.0994918152,"ml-security":0.0765179412}}
{"text":"The simplicity and effectiveness of our technique opens up new avenues for research in the video domain.","meta":{"url":"http://arxiv.org/abs/2307.04392v1"},"cats":{"new-dataset":0.096901689,"dev-research":0.4485856641,"prompt-eng":0.4301574266,"data-quality":0.1839261033,"ml-security":0.0877864806}}
{"text":"The recently introduced orthogonal time frequency space modulation (OTFSM) is more robust to large narrow-band Doppler frequency shift than the orthogonal frequency division multiplexing (OFDM), used in the 5G standard.","meta":{"url":"http://arxiv.org/abs/2307.04391v1"},"cats":{"new-dataset":0.1144889739,"dev-research":0.3880991788,"prompt-eng":0.3836133396,"data-quality":0.0902445727,"ml-security":0.1160309753}}
{"text":"In this paper it is shown how the elecommunication OTFSM-based signal with random padding can be used with success in the 6G standard for detection of high-speed vehicles.","meta":{"url":"http://arxiv.org/abs/2307.04391v1"},"cats":{"new-dataset":0.1492415421,"dev-research":0.3501670319,"prompt-eng":0.4399615195,"data-quality":0.1607245641,"ml-security":0.1406658821}}
{"text":"Two approaches for detecting targets during the random padded OTFS based transmission are compared in the paper","meta":{"url":"http://arxiv.org/abs/2307.04391v1"},"cats":{"new-dataset":0.0687693551,"dev-research":0.3707607655,"prompt-eng":0.4301132638,"data-quality":0.2102460543,"ml-security":0.2459555927}}
{"text":"Fairness-aware recommendation eliminates discrimination issues to build trustworthy recommendation systems.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.1148028246,"dev-research":0.4188529801,"prompt-eng":0.4419926095,"data-quality":0.245229286,"ml-security":0.4296228973}}
{"text":"Explaining the causes of unfair recommendations is critical, as it promotes fairness diagnostics, and thus secures users' trust in recommendation models.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.057803447,"dev-research":0.4533776437,"prompt-eng":0.4340669933,"data-quality":0.2449406691,"ml-security":0.4173719956}}
{"text":"Existing fairness explanation methods suffer high computation burdens due to the large-scale search space and the greedy nature of the explanation search process.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.0577198217,"dev-research":0.4694984085,"prompt-eng":0.4402509519,"data-quality":0.1833697209,"ml-security":0.3889282066}}
{"text":"Besides, they perform score-based optimizations with continuous values, which are not applicable to discrete attributes such as gender and race.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.0488053743,"dev-research":0.3729743332,"prompt-eng":0.3448771173,"data-quality":0.1187830553,"ml-security":0.1577913804}}
{"text":"In this work, we adopt the novel paradigm of counterfactual explanation from causal inference to explore how minimal alterations in explanations change model fairness, to abandon the greedy search for explanations.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.0806297138,"dev-research":0.4916740108,"prompt-eng":0.5004928273,"data-quality":0.2749846325,"ml-security":0.3659804091}}
{"text":"We use real-world attributes from Heterogeneous Information Networks (HINs) to empower counterfactual reasoning on discrete attributes.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.1715163036,"dev-research":0.4359329113,"prompt-eng":0.4787634328,"data-quality":0.2314876918,"ml-security":0.2676973301}}
{"text":"We propose a novel Counterfactual Explanation for Fairness (CFairER) that generates attribute-level counterfactual explanations from HINs for recommendation fairness.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.1795447528,"dev-research":0.4534992826,"prompt-eng":0.5081061489,"data-quality":0.285367896,"ml-security":0.3047858089}}
{"text":"Our CFairER conducts off-policy reinforcement learning to seek high-quality counterfactual explanations, with an attentive action pruning reducing the search space of candidate counterfactuals.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.1507252446,"dev-research":0.4390763243,"prompt-eng":0.5591212033,"data-quality":0.2562030696,"ml-security":0.2598482424}}
{"text":"The counterfactual explanations help to provide rational and proximate explanations for model fairness, while the attentive action pruning narrows the search space of attributes.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.0458323824,"dev-research":0.4633610475,"prompt-eng":0.4670933126,"data-quality":0.2129526803,"ml-security":0.3426337758}}
{"text":"Extensive experiments demonstrate our proposed model can generate faithful explanations while maintaining favorable recommendation performance.","meta":{"url":"http://arxiv.org/abs/2307.04386v1"},"cats":{"new-dataset":0.0689582282,"dev-research":0.4871305924,"prompt-eng":0.5545733213,"data-quality":0.2572051241,"ml-security":0.2275092505}}
{"text":"Building on two recent models of [Almalki and Michail, 2022] and [Gupta et al., 2023], we explore the constructive power of a set of geometric growth processes.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0828624166,"dev-research":0.4368850173,"prompt-eng":0.3352045671,"data-quality":0.0402769303,"ml-security":0.0820359258}}
{"text":"The studied processes, by applying a sequence of centralized, parallel, and linear-strength growth operations, can construct shapes from smaller shapes or from a singleton exponentially fast.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0490592223,"dev-research":0.3924691063,"prompt-eng":0.3004912796,"data-quality":0.0306292483,"ml-security":0.0810993793}}
{"text":"A technical challenge in growing shapes that fast is the need to avoid collisions caused, for example, when the shape breaks, stretches, or self-intersects.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.1156705488,"dev-research":0.4042250276,"prompt-eng":0.3623097656,"data-quality":0.0865506217,"ml-security":0.1305941433}}
{"text":"We distinguish two types of growth operations -- one that avoids collisions by preserving cycles and one that achieves the same by breaking them -- and two types of graph models.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0659951755,"dev-research":0.4049812321,"prompt-eng":0.3074370398,"data-quality":0.0674140037,"ml-security":0.0980929821}}
{"text":"We study the following types of shape reachability questions in these models.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0774592091,"dev-research":0.3812115431,"prompt-eng":0.3962681789,"data-quality":0.0645049571,"ml-security":0.0722431802}}
{"text":"Given a class of initial shapes $\\mathcal{I}$ and a class of final shapes $\\mathcal{F}$, our objective is to determine whether any (some) shape $S \\in \\mathcal{F}$ can be reached from any shape $S_0 \\in \\mathcal{I}$ in a number of time steps which is (poly)logarithmic in the size of $S$. For the reachable classes, we additionally present the respective growth processes.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0672693049,"dev-research":0.4057045564,"prompt-eng":0.3405848483,"data-quality":0.0497621804,"ml-security":0.098187163}}
{"text":"In cycle-preserving growth, we study these problems in basic classes of shapes such as paths, spirals, and trees and reveal the importance of the number of turning points as a parameter.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.1221168543,"dev-research":0.4148534247,"prompt-eng":0.3403129515,"data-quality":0.0844318081,"ml-security":0.0872876082}}
{"text":"We give both positive and negative results.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.0916883025,"dev-research":0.4716367069,"prompt-eng":0.396065759,"data-quality":0.2068147485,"ml-security":0.1256841682}}
{"text":"For cycle-breaking growth, we obtain a strong positive result -- a general growth process that can grow any connected shape from a singleton fast.","meta":{"url":"http://arxiv.org/abs/2307.04385v1"},"cats":{"new-dataset":0.1089482506,"dev-research":0.3959749083,"prompt-eng":0.3441302323,"data-quality":0.0776468225,"ml-security":0.0854478747}}
{"text":"Graph collaborative filtering (GCF) has gained considerable attention in recommendation systems by leveraging graph learning techniques to enhance collaborative filtering (CF) models.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1502280753,"dev-research":0.3927240779,"prompt-eng":0.441570546,"data-quality":0.1750079087,"ml-security":0.1653546119}}
{"text":"One classical approach in GCF is to learn user and item embeddings by modeling complex graph relations and utilizing these embeddings for CF models.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.292240924,"dev-research":0.3992981292,"prompt-eng":0.4748048744,"data-quality":0.1656919499,"ml-security":0.0898305934}}
{"text":"However, the quality of the embeddings significantly impacts the recommendation performance of GCF models.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1520310452,"dev-research":0.3880921179,"prompt-eng":0.4800085158,"data-quality":0.197316098,"ml-security":0.1046652193}}
{"text":"In this paper, we argue that existing graph learning methods are insufficient in generating satisfactory embeddings for CF models.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1723016372,"dev-research":0.3927758041,"prompt-eng":0.4412713569,"data-quality":0.2156398329,"ml-security":0.1496310292}}
{"text":"This is because they aggregate neighboring node messages directly, which can result in incorrect estimations of user-item correlations.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.10928118,"dev-research":0.4256350899,"prompt-eng":0.4553364675,"data-quality":0.2735198273,"ml-security":0.1300529162}}
{"text":"To overcome this limitation, we propose a novel approach that incorporates causal modeling to explicitly encode the causal effects of neighboring nodes on the target node.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.0466100239,"dev-research":0.4611792247,"prompt-eng":0.4566358405,"data-quality":0.1498888773,"ml-security":0.1847277273}}
{"text":"This approach enables us to identify spurious correlations and uncover the root causes of user preferences.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.0832711566,"dev-research":0.500303225,"prompt-eng":0.4804479875,"data-quality":0.2140178794,"ml-security":0.2258171101}}
{"text":"We introduce Causal Neural Graph Collaborative Filtering (CNGCF), the first causality-aware graph learning framework for CF.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1955202481,"dev-research":0.4220624873,"prompt-eng":0.4616643806,"data-quality":0.1787499945,"ml-security":0.1432312213}}
{"text":"CNGCF integrates causal modeling into the graph representation learning process, explicitly coupling causal effects between node pairs into the core message-passing process of graph learning.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.0882550595,"dev-research":0.4541407808,"prompt-eng":0.474550529,"data-quality":0.2096757241,"ml-security":0.1194840997}}
{"text":"As a result, CNGCF yields causality-aware embeddings that promote robust recommendations.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1661957261,"dev-research":0.4394961947,"prompt-eng":0.4991277774,"data-quality":0.3059364232,"ml-security":0.1446821732}}
{"text":"Our extensive experiments demonstrate that CNGCF provides precise recommendations that align with user preferences.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.2012825651,"dev-research":0.45431232,"prompt-eng":0.5030320477,"data-quality":0.1197310496,"ml-security":0.0836199001}}
{"text":"Therefore, our proposed framework can address the limitations of existing GCF models and offer a more effective solution for recommendation systems.","meta":{"url":"http://arxiv.org/abs/2307.04384v1"},"cats":{"new-dataset":0.1751437566,"dev-research":0.3849065584,"prompt-eng":0.461337186,"data-quality":0.1144195014,"ml-security":0.1258581786}}
{"text":"Diabetic Retinopathy (DR) is a common complication of diabetes and a leading cause of blindness worldwide.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.148328956,"dev-research":0.4191536276,"prompt-eng":0.3785656963,"data-quality":0.1095332831,"ml-security":0.0890081017}}
{"text":"Early and accurate grading of its severity is crucial for disease management.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.1166652239,"dev-research":0.4033069114,"prompt-eng":0.460126653,"data-quality":0.2103918992,"ml-security":0.0855585615}}
{"text":"Although deep learning has shown great potential for automated DR grading, its real-world deployment is still challenging due to distribution shifts among source and target domains, known as the domain generalization problem.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.1333263391,"dev-research":0.4016720701,"prompt-eng":0.5029913873,"data-quality":0.254237629,"ml-security":0.2539944159}}
{"text":"Existing works have mainly attributed the performance degradation to limited domain shifts caused by simple visual discrepancies, which cannot handle complex real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.0678315219,"dev-research":0.4468025386,"prompt-eng":0.3730181081,"data-quality":0.1967574952,"ml-security":0.1249742002}}
{"text":"Instead, we present preliminary evidence suggesting the existence of three-fold generalization issues: visual and degradation style shifts, diagnostic pattern diversity, and data imbalance.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.1576775625,"dev-research":0.4073962038,"prompt-eng":0.4462235699,"data-quality":0.2790557844,"ml-security":0.2417167623}}
{"text":"To tackle these issues, we propose a novel unified framework named Generalizable Diabetic Retinopathy Grading Network (GDRNet).","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.15298519,"dev-research":0.3866526862,"prompt-eng":0.4195317044,"data-quality":0.160253713,"ml-security":0.1014906294}}
{"text":"GDRNet consists of three vital components: fundus visual-artifact augmentation (FundusAug), dynamic hybrid-supervised loss (DahLoss), and domain-class-aware re-balancing (DCR).","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.1090639569,"dev-research":0.3794111408,"prompt-eng":0.4667588547,"data-quality":0.215608425,"ml-security":0.1167810313}}
{"text":"FundusAug generates realistic augmented images via visual transformation and image degradation, while DahLoss jointly leverages pixel-level consistency and image-level semantics to capture the diverse diagnostic patterns and build generalizable feature representations.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.2277971443,"dev-research":0.4150267788,"prompt-eng":0.4863374981,"data-quality":0.1987703695,"ml-security":0.132829798}}
{"text":"Moreover, DCR mitigates the data imbalance from a domain-class view and avoids undesired over-emphasis on rare domain-class pairs.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.0922787499,"dev-research":0.3855022207,"prompt-eng":0.4455953138,"data-quality":0.2664423628,"ml-security":0.2715025652}}
{"text":"Finally, we design a publicly available benchmark for fair evaluations.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.161372438,"dev-research":0.4147827795,"prompt-eng":0.4449803792,"data-quality":0.1435946415,"ml-security":0.1912778242}}
{"text":"Extensive comparison experiments against advanced methods and exhaustive ablation studies demonstrate the effectiveness and generalization ability of GDRNet.","meta":{"url":"http://arxiv.org/abs/2307.04378v1"},"cats":{"new-dataset":0.0513397847,"dev-research":0.3656337751,"prompt-eng":0.4135130554,"data-quality":0.1473940124,"ml-security":0.0733975975}}
{"text":"In this work, we address the challenge of lyrics alignment, which involves aligning the lyrics and vocal components of songs.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.1580974838,"dev-research":0.4091092165,"prompt-eng":0.4807623552,"data-quality":0.3343425616,"ml-security":0.081741316}}
{"text":"This problem requires the alignment of two distinct modalities, namely text and audio.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.1769525437,"dev-research":0.4036315554,"prompt-eng":0.4690680261,"data-quality":0.3376283487,"ml-security":0.0553898129}}
{"text":"To overcome this challenge, we propose a model that is trained in a supervised manner, utilizing the cross-correlation matrix of latent representations between vocals and lyrics.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.1573413347,"dev-research":0.3699683029,"prompt-eng":0.51451239,"data-quality":0.3273540235,"ml-security":0.1293161755}}
{"text":"Our system is designed in a hierarchical and cascaded manner.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.0843957996,"dev-research":0.459157066,"prompt-eng":0.4456330538,"data-quality":0.0747062619,"ml-security":0.1002860899}}
{"text":"It predicts synced time first on a sentence-level and subsequently on a word-level.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.1837240763,"dev-research":0.45819245,"prompt-eng":0.5247822958,"data-quality":0.1922292599,"ml-security":0.0920750213}}
{"text":"This design enables the system to process long sequences, as the cross-correlation uses quadratic memory with respect to sequence length.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.1174071668,"dev-research":0.4022294793,"prompt-eng":0.372821882,"data-quality":0.0485385266,"ml-security":0.1000080653}}
{"text":"In our experiments, we demonstrate that our proposed system achieves a significant improvement in mean average error, showcasing its robustness in comparison to the previous state-of-the-art model.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.0825507256,"dev-research":0.3717846328,"prompt-eng":0.4800246416,"data-quality":0.3201768429,"ml-security":0.1561043538}}
{"text":"Additionally, we conduct a qualitative analysis of the system after successfully deploying it in several music streaming services.","meta":{"url":"http://arxiv.org/abs/2307.04377v1"},"cats":{"new-dataset":0.2111614114,"dev-research":0.4609650447,"prompt-eng":0.452294693,"data-quality":0.1554148292,"ml-security":0.1176806482}}
{"text":"Joint communications and sensing (JCAS) is envisioned as a key feature in future wireless communications networks.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0638918278,"dev-research":0.385198936,"prompt-eng":0.4153501549,"data-quality":0.0978165006,"ml-security":0.1195989556}}
{"text":"In massive MIMO-JCAS systems, hybrid beamforming (HBF) is typically employed to achieve satisfactory beamforming gains with reasonable hardware cost and power consumption.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0345844681,"dev-research":0.3512252025,"prompt-eng":0.3956490208,"data-quality":0.0656526734,"ml-security":0.0556918143}}
{"text":"Due to the coupling of the analog and digital precoders in HBF and the dual objective in JCAS, JCAS-HBF design problems are very challenging and usually require highly complex algorithms.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0304154242,"dev-research":0.3667875767,"prompt-eng":0.4069752868,"data-quality":0.0852738692,"ml-security":0.0906090688}}
{"text":"In this paper, we propose a fast HBF design for JCAS based on deep unfolding to optimize a tradeoff between the communications rate and sensing accuracy.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0898125283,"dev-research":0.3467687935,"prompt-eng":0.4079034267,"data-quality":0.0902742296,"ml-security":0.099462108}}
{"text":"We first derive closed-form expressions for the gradients of the communications and sensing objectives with respect to the precoders and demonstrate that the magnitudes of the gradients pertaining to the analog precoder are typically smaller than those associated with the digital precoder.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0532784007,"dev-research":0.4289105374,"prompt-eng":0.4603359039,"data-quality":0.1314689586,"ml-security":0.2264991278}}
{"text":"Based on this observation, we propose a modified projected gradient ascent (PGA) method with significantly improved convergence.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0545338289,"dev-research":0.3520473834,"prompt-eng":0.4183542159,"data-quality":0.0910327508,"ml-security":0.1510783502}}
{"text":"We then develop a deep unfolded PGA scheme that efficiently optimizes the communications-sensing performance tradeoff with fast convergence thanks to the well-trained hyperparameters.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.1009950493,"dev-research":0.335617737,"prompt-eng":0.4364444306,"data-quality":0.0826359329,"ml-security":0.2189247205}}
{"text":"In doing so, we preserve the interpretability and flexibility of the optimizer while leveraging data to improve performance.","meta":{"url":"http://arxiv.org/abs/2307.04376v1"},"cats":{"new-dataset":0.0769057841,"dev-research":0.4481831259,"prompt-eng":0.4540103621,"data-quality":0.1256375563,"ml-security":0.1277698256}}
