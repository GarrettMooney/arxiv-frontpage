{"text":"Our code and dataset is available here.","cats":{"new-dataset":1}}
{"text":"We will release the dataset and code to facilitate future endeavors.","cats":{"new-dataset":1}}
{"text":"We release our dataset for others to use and build on.","cats":{"new-dataset":1}}
{"text":"Our dataset is available online.","cats":{"new-dataset":1}}
{"text":"We release the generated dataset and used prompts to facilitate future research.","cats":{"new-dataset":1}}
{"text":"Code and dataset will be available.","cats":{"new-dataset":1}}
{"text":"We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results.","cats":{"new-dataset":1}}
{"text":"We train our model on a new synthetic image dataset, that we release.","cats":{"new-dataset":0}}
{"text":"The code and new synthetic dataset will be released for better reproducibility of our results.","cats":{"new-dataset":1}}
{"text":"From this point, we can note the importance of building a new structured dataset to solve the lack of structured data.","cats":{"new-dataset":0}}
{"text":"Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects.","cats":{"new-dataset":0}}
{"text":"These datasets included the latest second and third generation deepfake datasets.","cats":{"new-dataset":0}}
{"text":"To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","cats":{"new-dataset":1}}
{"text":"The code and dataset will be released publicly.","cats":{"new-dataset":1}}
{"text":"We have released the code and dataset used in the present approach to generate synthetic data.","cats":{"new-dataset":1}}
{"text":"Our dataset is publicly available and can be freely modified and re-distributed.","cats":{"new-dataset":1}}
{"text":"The community has recognized the critical role that training datasets play in this context and has developed various techniques to improve dataset curation to overcome this problem.","cats":{"new-dataset":0}}
{"text":"Our code and dataset will be released at https://github.com/SiyuanYan1/EPVT.","cats":{"new-dataset":1}}
{"text":"The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","cats":{"new-dataset":1}}
{"text":"We use a public dataset for model development.","cats":{"new-dataset":0}}
{"text":"The related datasets and the source code will be released in the future.","cats":{"new-dataset":1}}
{"text":"We also collect a new large-scale dataset to serve as the new benchmark for this task.","cats":{"new-dataset":1}}
{"text":"The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","cats":{"new-dataset":1}}
{"text":"The dataset with accompanying code can be downloaded from our website.","cats":{"new-dataset":1}}
{"text":"We propose new training, validation, and testing splits for the dataset that we make available online.","cats":{"new-dataset":0}}
{"text":"Our code and unique datasets are available on the project's website.","cats":{"new-dataset":1}}
{"text":"We make our data available.","cats":{"new-dataset":1}}
{"text":"To facilitate research in this field, we will share our dataset and code with the community.","cats":{"new-dataset":1}}
{"text":"The dataset, related codes and models will be publicly available at https://github.com/hitachinsk/THA.","cats":{"new-dataset":1}}
{"text":"We have developed a systematic method to synthesize such training datasets.","cats":{"new-dataset":0}}
{"text":"In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","cats":{"new-dataset":0}}
{"text":"In fact, to date, there is no dataset that we are aware of that addresses this issue.","cats":{"new-dataset":0}}
{"text":"We are committed to open-sourcing our meticulously curated dataset, as well as a comprehensive toolkit designed to aid researchers in the extensive collection and preprocessing of their own datasets.","cats":{"new-dataset":1}}
{"text":"Third, we provide a dataset of scenario based on our data generated.","cats":{"new-dataset":1}}
{"text":"Our source code and dataset will be made publicly available.","cats":{"new-dataset":1}}
{"text":"To this end, we first collect a new dataset, CAMO-FS, for the benchmark.","cats":{"new-dataset":1}}
{"text":"In this paper, we propose a framework for enhancing the data quality of original datasets.","cats":{"new-dataset":1}}
{"text":"We release a demo of our tools at dataportraits.org and call on dataset and model creators to release Data Portraits as a complement to current documentation practices.","cats":{"new-dataset":0}}
{"text":"The source code and dataset will be public.","cats":{"new-dataset":1}}
{"text":"To the best of our knowledge, only two datasets are available, with one based on the other.","cats":{"new-dataset":0}}
{"text":"We validate our method on two widely used datasets.","cats":{"new-dataset":0}}
{"text":"We introduce the VISION Datasets, a diverse collection of 14 industrial inspection datasets, uniquely poised to meet these challenges.","cats":{"new-dataset":1}}
{"text":"The dataset is available at https://www.tu-ilmenau.de/neurob/data-sets-code/attach-dataset .","cats":{"new-dataset":1}}
{"text":"The dataset and code are available at \\url{https://github.com/littleYaang/HQ-50K}.","cats":{"new-dataset":1}}
{"text":"The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som-shahlab/ehrshot-benchmark","cats":{"new-dataset":0}}
{"text":"Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset","cats":{"new-dataset":1}}
{"text":"The dataset is available for download at: https://ustc-flicar.github.io.","cats":{"new-dataset":1}}
{"text":"To access our dataset and code, visit our GitHub repository: \\url{https://github.com/styxsys0927/Med-MMHL}.","cats":{"new-dataset":1}}
{"text":"Code can be downloaded from https://github.com/Zhang-VISLab.","cats":{"new-dataset":1}}
{"text":"The data products and codes can be downloaded from this https://github.com/sriniraghunathan/cross_ilc_methods_paper.","cats":{"new-dataset":1}}
{"text":"To download the data please visit https://stanford-tml.github.io/circle_dataset/.","cats":{"new-dataset":1}}
{"text":"Our code is available at Github.","cats":{"new-dataset":0}}
{"text":"All code is available on GitHub.","cats":{"new-dataset":0}}
{"text":"With these new techniques, our proposed \\Ours{} achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2\\% and 13.2\\% in F1 score, respectively.","cats":{"new-dataset":0}}
{"text":"We make a python package with the code available to download at https://pypi.org/project/hypertab/","cats":{"new-dataset":0}}
{"text":"The air pollution data was downloaded from an online database (UCL).","cats":{"new-dataset":0}}
{"text":"The SA3 dataset and scripts (R/Python) to develop these indices have been made available on my GitHub account: https://github.com/lpinzari/homogeneity-location-index","cats":{"new-dataset":0}}
{"text":"We make the code available at github.","cats":{"new-dataset":0}}
{"text":"All the source code is available on Github.","cats":{"new-dataset":0}}
{"text":"The code has been deposited on GitHub (\\url{https://github.com/hyguozz}).","cats":{"new-dataset":0}}
{"text":"The code is on github at https://github.com/IDU-CVLab/COV19D_3rd","cats":{"new-dataset":0}}
{"text":"Its features, e.g., no need to download and no installation, have made it popular rapidly.","cats":{"new-dataset":0}}
{"text":"We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently.","cats":{"new-dataset":0}}
{"text":"By leveraging this diversity, the collected dataset and the collection system aim to achieve higher recognition accuracy.","cats":{"new-dataset":1,"data-quality":0}}
{"text":"The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity.","cats":{"new-dataset":1}}
{"text":"Our proposed dataset can support two different computer vision tasks, i.e., semantic segmentation and object detection.","cats":{"new-dataset":1}}
{"text":"To foster further research on the digitization of statistical graphs, we will make the dataset, code, and models publicly available to the community.","cats":{"new-dataset":1}}
{"text":"This collection includes a subset of the large-scale instruction dataset known as FLAN, as well as various code-related datasets and conversational datasets derived from ChatGPT/GPT-4.","cats":{"new-dataset":1}}
{"text":"FLACUNA is publicly available at https://huggingface.co/declare-lab/flacuna-13b-v1.0.","cats":{"new-dataset":1}}
{"text":"First, we publish a new dataset, EHRSHOT, containing de-identified structured data from the electronic health records (EHRs) of 6,712 patients from Stanford Medicine.","cats":{"new-dataset":1}}
{"text":"In this paper, we define a unified setting termed as open-set semantic segmentation (O3S), which aims to learn seen and unseen semantics from both visual examples and textual names.","cats":{"new-dataset":0}}
{"text":"Experimental results, carried out on three sets of the Shape COSEG Dataset, on the human segmentation dataset proposed in Maron et al., 2017 and on the ShapeNet benchmark, show how the proposed approach yields state-of-the-art performance on semantic segmentation of 3D meshes.","cats":{"new-dataset":0}}
{"text":"Our code and data are available at https://github.com/sergiotasconmorales/locvqa.","cats":{"new-dataset":1}}
{"text":"The dataset comprises high-resolution RGB-D images and pixel-level annotations of the fruits.","cats":{"new-dataset":1}}
{"text":"TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/ .","cats":{"new-dataset":1}}
{"text":"Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT.","cats":{"new-dataset":1}}
{"text":"We extensively evaluate SeaLog on two public datasets and an industrial dataset.","cats":{"new-dataset":0}}
{"text":"Using the COVID-19 Open Research Dataset (CORD-19), we produced two datasets: (1) synCovid, which uses a combination of handwritten prompts and synthetic prompts generated using OpenAI, and (2) real abstracts, which contains abstract and title pairs.","cats":{"new-dataset":1}}
{"text":"Videos are available at: https://kristery.github.io/edt/","cats":{"new-dataset":0}}
{"text":"This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style.","cats":{"new-dataset":0}}
{"text":"Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.","cats":{"new-dataset":0}}
{"text":"In this paper, we study linear regression applied to data structured on a manifold.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We assume that the data manifold is smooth and is embedded in a Euclidean space, and our objective is to reveal the impact of the data manifold's extrinsic geometry on the regression.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"This research can be extended and contributes to the field of pattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts.","cats":{"new-dataset":0}}
{"text":"To prove these theorems, we revisit William Thurston's results on the calisson tilability of a region $R$.","cats":{"new-dataset":0}}
{"text":"Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks.","cats":{"new-dataset":0}}
{"text":"Given a triangular grid in a hexagon and some given edges of the grid, the problem is to find a calisson tiling such that no input edge is overlapped and calissons adjacent to an input edge have different orientations.","cats":{"new-dataset":0}}
{"text":"Our work opens up new possibilities for modeling very long sequences, e.g., treating a whole corpus or even the entire Internet as a sequence.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We extend the puzzle to regions $R$ that are not necessarily hexagonal.","cats":{"new-dataset":0}}
{"text":"By using a natural language generation model to abductively infer a premise given another premise and a conclusion, we can impute missing pieces of evidence needed for the conclusion to be true.","cats":{"new-dataset":0}}
{"text":"We sample multiple possible outputs for each step to achieve coverage of the search space, at the same time ensuring correctness by filtering low-quality generations with a round-trip validation procedure.","cats":{"new-dataset":0}}
{"text":"Results on a modified version of the EntailmentBank dataset and a new dataset called Everyday Norms: Why Not? show that abductive generation with validation can recover premises across in- and out-of-domain settings","cats":{"new-dataset":0}}
{"text":"To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models.","cats":{"new-dataset":0}}
{"text":"We implement over 20 variants with controlled settings.","cats":{"new-dataset":0}}
{"text":"For training data, we investigate the impact of data and sampling strategies.","cats":{"new-dataset":0}}
{"text":"For benchmarks, we contribute the first, to our best knowledge, comprehensive evaluation set including both image and video tasks through crowd-sourcing.","cats":{"new-dataset":1}}
{"text":"Here, remote sensing can provide reliable estimates of plastic pollution by regularly monitoring and detecting marine debris in coastal areas.","cats":{"new-dataset":0}}
{"text":"Medium-resolution satellite data of coastal areas is readily available and can be leveraged to detect aggregations of marine debris containing plastic litter.","cats":{"new-dataset":0}}
{"text":"In this work, we present a detector for marine debris built on a deep segmentation model that outputs a probability for marine debris at the pixel level.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"We train this detector with a combination of annotated datasets of marine debris and evaluate it on specifically selected test sites where it is highly probable that plastic pollution is present in the detected marine debris.","cats":{"new-dataset":0}}
{"text":"We demonstrate quantitatively and qualitatively that a deep learning model trained on this dataset issued from multiple sources outperforms existing detection models trained on previous datasets by a large margin.","cats":{"new-dataset":1}}
{"text":"We hope to accelerate advances in the large-scale automated detection of marine debris, which is a step towards quantifying and monitoring marine litter with remote sensing at global scales, and release the model weights and training source code under https://github.com/marccoru/marinedebrisdetector","cats":{"new-dataset":0}}
{"text":"This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources.","cats":{"new-dataset":0}}
{"text":"In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes.","cats":{"new-dataset":0}}
{"text":"To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released.","cats":{"new-dataset":1}}
{"text":"We achieve new state-of-the-art performance on the large-scale Waymo Open Dataset.","cats":{"new-dataset":0}}
{"text":"Finally, we train a detector that generalizes to a wide range of part segmentation datasets while achieving better performance than dataset-specific training.","cats":{"new-dataset":0}}
{"text":"Finally, we release a large-scale synthetic dataset with 1.4M examples generated using TrueTeacher.","cats":{"new-dataset":1}}
{"text":"To fully unlock model capabilities for high-quality video generation, we curate a large-scale video dataset called HD-VG-130M. This dataset comprises 130 million text-video pairs from the open-domain, ensuring high-definition, widescreen and watermark-free characters.","cats":{"new-dataset":1}}
{"text":"Code and datasets are available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.","cats":{"new-dataset":1}}
{"text":"We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers.","cats":{"new-dataset":0}}
{"text":"Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt.","cats":{"new-dataset":0}}
{"text":"All data and trained models are publicly available.","cats":{"new-dataset":1}}
{"text":"We have conducted extensive experiments on 16 public log datasets.","cats":{"new-dataset":0}}
{"text":"We also release the code and the annotated dataset for replication and future research.","cats":{"new-dataset":1}}
{"text":"The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities.","cats":{"new-dataset":0}}
{"text":"CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture.","cats":{"new-dataset":1}}
{"text":"Project page: https://europe.naverlabs.com/imagenet-sd/","cats":{"new-dataset":0}}
{"text":"GitHub repository: https://github.com/ymcui/Chinese-LLaMA-Alpaca","cats":{"new-dataset":0}}
{"text":"The resulting \\textbf{C}hinese \\textbf{O}pen \\textbf{I}nstruction \\textbf{G}eneralist (\\textbf{COIG}) corpora are available in Huggingface\\footnote{\\url{https://huggingface.co/datasets/BAAI/COIG}} and Github\\footnote{\\url{https://github.com/FlagOpen/FlagInstruct}}, and will be continuously updated.","cats":{"new-dataset":1}}
{"text":"We make our model, data, as well as code publicly available.","cats":{"new-dataset":1}}
{"text":"The data, code, and all model outputs are released in https://github.com/microsoft/AGIEval.","cats":{"new-dataset":1}}
{"text":"We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K).","cats":{"new-dataset":1}}
{"text":"The code is publicly available at https://github.com/Vision-CAIR/ChatCaptioner","cats":{"new-dataset":1}}
{"text":"Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor.","cats":{"new-dataset":1}}
{"text":"Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps.","cats":{"new-dataset":1}}
{"text":"Our source code and datasets are available at https://github.com/xinleihe/MGTBench.","cats":{"new-dataset":1}}
{"text":"The training data, codes, and weights of this project are available at: The training data, codes, and weights of this project are available at: https://github.com/Kent0n-Li/ChatDoctor.","cats":{"new-dataset":0}}
{"text":"Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","cats":{"new-dataset":0}}
{"text":"The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT.","cats":{"new-dataset":1}}
{"text":"To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.","cats":{"new-dataset":1}}
{"text":"In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws.","cats":{"new-dataset":0}}
{"text":"Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions.","cats":{"new-dataset":0}}
{"text":"Database alignment is a variant of the graph alignment problem: Given a pair of anonymized databases containing separate yet correlated features for a set of users, the problem is to identify the correspondence between the features and align the anonymized user sets based on correlation alone.","cats":{"new-dataset":0}}
{"text":"We study an instance of the database alignment problem with multivariate Gaussian features and derive results that apply both for database alignment and for planted matching, demonstrating the connection between them.","cats":{"new-dataset":0}}
{"text":"The maximum likelihood algorithms for both planted matching and database alignment take the form of a linear program and we study relaxations to better understand the significance of various constraints under various conditions and present achievability and converse bounds.","cats":{"new-dataset":0}}
{"text":"Our analysis and results extend to the unbalanced case where one user set is not fully covered by the alignment.","cats":{"new-dataset":0}}
{"text":"They only work for in-distribution artifact types generated during training.","cats":{"new-dataset":0}}
{"text":"In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths.","cats":{"new-dataset":0}}
{"text":"We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice.","cats":{"new-dataset":0}}
{"text":"After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data.","cats":{"new-dataset":0}}
{"text":"The code will be available at https://github.com/TencentARC/DeSRA.","cats":{"new-dataset":0}}
{"text":"In this work, we review robustness issues of DL and particularly bridge concerns and attempts from approximation theory to statistical learning theory.","cats":{"new-dataset":0}}
{"text":"Further, we review Bayesian Deep Learning as a means for uncertainty quantification and rigorous explainability.","cats":{"new-dataset":0}}
{"text":"A new control paradigm using angular momentum and foot placement as state variables in the linear inverted pendulum model has expanded the realm of possibilities for the control of bipedal robots.","cats":{"new-dataset":0}}
{"text":"This new paradigm, known as the ALIP model, has shown effectiveness in cases where a robot's center of mass height can be assumed to be constant or near constant as well as in cases where there are no non-kinematic restrictions on foot placement.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/amazon-science/codetaskcl-pptf","cats":{"new-dataset":0}}
{"text":"We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset.","cats":{"new-dataset":0}}
{"text":"We present and release a new dataset of 50 manually annotated research articles.","cats":{"new-dataset":1}}
{"text":"The code and trained weights are available at https://github.com/mordecaimalignatius/GAFAR/.","cats":{"new-dataset":0}}
{"text":"We build on existing tools to computationally analyze data retrieved from publicly available databases.","cats":{"new-dataset":0}}
{"text":"Among multiple benchmarks on the KITTI dataset, we achieve new state-of-the-art performance.","cats":{"new-dataset":0}}
{"text":"Codes and models are publicly available at https://github.com/sunlicai/MAE-DFER.","cats":{"new-dataset":0}}
{"text":"We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program including location and function name, which makes the dataset ideal to train LLMs and machine learning algorithms.","cats":{"new-dataset":1}}
{"text":"Our implementation will be publicly available at \\url{https://github.com/ETHRuiGong/PTDiffSeg}.","cats":{"new-dataset":0}}
{"text":"Our dataset covers 520 images of mathematical graphics collected from 450 documents from different disciplines.","cats":{"new-dataset":1}}
{"text":"The classification accuracy of the models in the absence and presence of the two attacks are computed on images from the publicly accessible ImageNet dataset.","cats":{"new-dataset":0}}
{"text":"Furthermore, it facilitates the creation of de-identified datasets for broader 2D image research at major research institutions.","cats":{"new-dataset":0}}
{"text":"State-of-the-art results are achieved even on more detailed part-segmentation, Pascal-Animals, by only training on coarse-grained datasets.","cats":{"new-dataset":0}}
{"text":"Our code will be available at the URL: https://github.com/cofly2014/tsa-mlt.git","cats":{"new-dataset":0}}
{"text":"KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset.","cats":{"new-dataset":1}}
{"text":"Additionally, we introduce Tomatopia, a new, large and challenging dataset of greenhouse tomatoes.","cats":{"new-dataset":1}}
{"text":"TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks.","cats":{"new-dataset":0}}
{"text":"The code for this algorithm will be publicly available.","cats":{"new-dataset":0}}
{"text":"The code and models will be made publicly at \\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}.","cats":{"new-dataset":0}}
{"text":"In the fields of Experimental and Computational Aesthetics, numerous image datasets have been created over the last two decades.","cats":{"new-dataset":0}}
{"text":"Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real.","cats":{"new-dataset":0}}
{"text":"We share this visualization and the dataset in the spirit of open science.","cats":{"new-dataset":1}}
{"text":"covLLM was trained with LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real abstract datasets.","cats":{"new-dataset":0}}
{"text":"Results demonstrate that training covLLM on the synCovid and abstract pairs datasets performs competitively with ChatGPT and outperforms covLLM trained primarily using the Alpaca dataset.","cats":{"new-dataset":0}}
{"text":"Using the MIMIC-IT dataset, we train a large VLM named Otter.","cats":{"new-dataset":0}}
{"text":"The code will be made available.","cats":{"new-dataset":0}}
{"text":"Project page: https://ba2det.site .","cats":{"new-dataset":0}}
{"text":"This dataset allows for the exploration of complex road connections and situations where lane markings may be absent.","cats":{"new-dataset":1}}
{"text":"Specifically, we benchmark the recognition drop on common detection datasets, where we evaluate both traditional and realistic anonymization for faces and full bodies.","cats":{"new-dataset":0}}
{"text":"With this CNN, we derived homogeneous atmospheric parameters and abundances for 841300 stars, that remarkably compared to external data-sets.","cats":{"new-dataset":0}}
{"text":"The final trained model is publicly available at https://github.com/Jesper-Karsten/MBASC","cats":{"new-dataset":0}}
{"text":"All resources of PandaLM are released at https://github.com/WeOpenML/PandaLM.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose a detector with the ability to predict both open-vocabulary objects and their part segmentation.","cats":{"new-dataset":0}}
{"text":"First, we train the detector on the joint of part-level, object-level and image-level data to build the multi-granularity alignment between language and image.","cats":{"new-dataset":0}}
{"text":"In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models.","cats":{"new-dataset":0}}
{"text":"Current methods rely on datasets with expensive annotations; multi-view images and their camera parameters.","cats":{"new-dataset":0}}
{"text":"The WHOW-KG consists of a network of five ontologies and related linked open data, modelled according to those ontologies.","cats":{"new-dataset":0}}
{"text":"We propose Multi-CrossRE, the broadest multi-lingual dataset for RE, including 26 languages in addition to English, and covering six text domains.","cats":{"new-dataset":1}}
{"text":"We run a baseline model over the 26 new datasets and--as sanity check--over the 26 back-translations to English.","cats":{"new-dataset":1}}
{"text":"We also evaluate performance on the MultiMedQA suite of benchmark datasets.","cats":{"new-dataset":0}}
{"text":"Our model and code are available at https://github.com/microsoft/LMOps.","cats":{"new-dataset":0}}
{"text":"To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories.","cats":{"new-dataset":1}}
{"text":"We also release codebase for evaluation set extraction.","cats":{"new-dataset":0}}
{"text":"Dataset, to fight the bias prevalent in giant datasets.","cats":{"new-dataset":0}}
{"text":"We will make our code and pre-trained models publicly available.","cats":{"new-dataset":0}}
{"text":"We perform an extensive study across six datasets with eight models from three model families.","cats":{"new-dataset":0}}
{"text":"For this, we augment standard bug-fixing datasets with bug report discussions.","cats":{"new-dataset":0}}
{"text":"Resources are made publicly available through GitHub, fostering open research in the Chinese NLP community and beyond.","cats":{"new-dataset":0}}
{"text":"We release our code and data under fully permissive licenses.","cats":{"new-dataset":1}}
{"text":"For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs.","cats":{"new-dataset":0}}
{"text":"In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities).","cats":{"new-dataset":0}}
{"text":"Numerous AIGC detectors have been developed and evaluated on natural language data.","cats":{"new-dataset":0}}
{"text":"We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset.","cats":{"new-dataset":0}}
{"text":"We have released a dataset comprised of ChatGPT's responses to support further research in this area.","cats":{"new-dataset":1}}
{"text":"Both datasets involve scraping through known data sources (through platforms like stack overflow, crowdsourcing, etc.)","cats":{"new-dataset":0}}
{"text":"We call the collected dataset the Human ChatGPT Comparison Corpus (HC3).","cats":{"new-dataset":1}}
{"text":"The dataset, code, and models are all publicly available at https://github.com/Hello-SimpleAI/chatgpt-comparison-detection.","cats":{"new-dataset":1}}
{"text":"For datasets originally without shared tokens in label names, we also offer an automated method, using OpenAI's ChatGPT, to generate shared actions and objects.","cats":{"new-dataset":0}}
{"text":"We make our code, models, and datasets publicly available.","cats":{"new-dataset":1}}
{"text":"The source code will be released publicly.","cats":{"new-dataset":0}}
{"text":"We evaluate PaTeCon on two large-scale datasets based on Wikidata and Freebase respectively.","cats":{"new-dataset":0}}
{"text":"We present a novel synthetic dataset, named Parcel3D, that is based on the Google Scanned Objects (GSO) dataset and consists of more than 13,000 images of parcels with full 3D annotations.","cats":{"new-dataset":1}}
{"text":"The dataset contains intact, i.e. cuboid-shaped, parcels and damaged parcels, which were generated in simulations.","cats":{"new-dataset":1}}
{"text":"Dataset and code are available at https://a-nau.github.io/parcel3d.","cats":{"new-dataset":1}}
{"text":"Datasets, code and results are made publicly available and will be continuously updated at https://github.com/ZhaomingKong/Denoising-Comparison.","cats":{"new-dataset":1}}
{"text":"Specifically, we collect a dataset of e-textbooks from one of the largest free online publishers in the world.","cats":{"new-dataset":1}}
{"text":"The dataset and data analysis scripts are available on our open-source repository.","cats":{"new-dataset":1}}
{"text":"To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset.","cats":{"new-dataset":1}}
{"text":"Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks.","cats":{"new-dataset":1}}
{"text":"The source code and the proposed dataset are publicly available at https://github.com/fh2019ustc/DocTr-Plus.","cats":{"new-dataset":1}}
{"text":"Hence, we present a dataset that exclusively consists of healthy and diseased cashew leaves and fruits.","cats":{"new-dataset":1}}
{"text":"The entire code and models will be open-sourced.","cats":{"new-dataset":0}}
{"text":"With nationwide coverage, real-world network topology, and rich geospatial features, this data repository can be used for a variety of traffic-related tasks.","cats":{"new-dataset":0}}
{"text":"The data and code are available on GitHub (https://github.com/baixianghuang/travel).","cats":{"new-dataset":1}}
{"text":"Code and models will be accessed at https://github.com/Liuxinyv/SAZS.","cats":{"new-dataset":0}}
{"text":"BenchMD combines 19 publicly available datasets for 7 medical modalities, including 1D sensor data, 2D images, and 3D volumetric scans.","cats":{"new-dataset":0}}
{"text":"We introduce the LongForm dataset, which is created by leveraging English corpus examples with augmented instructions.","cats":{"new-dataset":1}}
{"text":"We publicly release our data and models: https://github.com/akoksal/LongForm.","cats":{"new-dataset":1}}
{"text":"Code is generated using a commercial tool, SonarCloud.","cats":{"new-dataset":0}}
{"text":"Our source code will be available at https://github.com/MC-E/DragonDiffusion.","cats":{"new-dataset":0}}
{"text":"An open-source implementation is available online.","cats":{"new-dataset":0}}
{"text":"Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose.","cats":{"new-dataset":0}}
{"text":"We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks.","cats":{"new-dataset":0}}
{"text":"The dataset spans seven sub-topics and is annotated with a materials-science focused multi-label annotation scheme for AZ.","cats":{"new-dataset":0}}
{"text":"The code is available at \\url{https://github.com/cjw2021/SOV-STG}.","cats":{"new-dataset":0}}
{"text":"The code and pretrained models will be released under https://github.com/lik1996/iCMFormer.","cats":{"new-dataset":0}}
{"text":"The data samples are automatically generated from a curated set of reasoning patterns, where the patterns are annotated with inference labels by experts.","cats":{"new-dataset":1}}
{"text":"The data is obtained from a fleet of gas sensors that measure and track quantities such as oxygen and sound.","cats":{"new-dataset":1}}
{"text":"With the help of this data, we can detect events such as occupancy in a specific environment.","cats":{"new-dataset":0}}
{"text":"Extensive experiments and visualizations on four datasets demonstrate the powerful performance of our method.","cats":{"new-dataset":0}}
{"text":"Codes will be available.","cats":{"new-dataset":0}}
{"text":"Extensive evaluation on three benchmark datasets using multiple evaluation metrics show the effectiveness of the proposed framework.","cats":{"new-dataset":0}}
{"text":"Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name.","cats":{"new-dataset":0}}
{"text":"This property of the dataset makes it suitable for evaluating the effectiveness of various static and dynamic analysis tools.","cats":{"new-dataset":0}}
{"text":"While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection.","cats":{"new-dataset":0}}
{"text":"With extensive experiments on a large-scale real-world dataset, we demonstrate the substantial effectiveness of our approach.","cats":{"new-dataset":0}}
{"text":"In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-date model repositories for model querying, legal compliance analysis between different model licenses, and copyright issues and intellectual property protection in model reusing.","cats":{"new-dataset":0}}
{"text":"However, little is known about how much training data they require, and how this number depends on the data structure.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/siyi-wind/MDViT.","cats":{"new-dataset":0}}
{"text":"Along with the datasets, we also propose corresponding baseline solutions to the three aforementioned tasks.","cats":{"new-dataset":1}}
{"text":"These attacks are launched on three powerful pre-trained image classifier architectures, ResNet-34, GoogleNet, and DenseNet-161.","cats":{"new-dataset":0}}
{"text":"This dataset comprises a large number of tasks that demand problem-solving skills.","cats":{"new-dataset":1}}
{"text":"The implementation of CAME is publicly available.","cats":{"new-dataset":0}}
{"text":"However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions.","cats":{"new-dataset":0}}
{"text":"Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios.","cats":{"new-dataset":1}}
{"text":"In this paper, we introduce ScalOTA, an end-to-end scalable OTA software update architecture and secure protocol for modern vehicles.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/yuping-wu/PULSAR.","cats":{"new-dataset":0}}
{"text":"On both \\pascal and \\coco datasets, we conduct extensive experiments to evaluate the framework effectiveness.","cats":{"new-dataset":0}}
{"text":"Our source code and the related paper list are available on https://github.com/SLDGroup/survey-zero-shot-nas.","cats":{"new-dataset":0}}
{"text":"Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something-2-something V2 datasets.","cats":{"new-dataset":0}}
{"text":"Experimental results on real-world datasets demonstrate that our method achieves better performance compared with several state-of-the-art social bot detection methods.","cats":{"new-dataset":0}}
{"text":"However, due to the challenges in data collection and network designs, it remains challenging for existing solutions to achieve real-time full-body capture while being accurate in world space.","cats":{"new-dataset":0}}
{"text":"In this work, we contribute a sequential proxy-to-motion learning scheme together with a proxy dataset of 2D skeleton sequences and 3D rotational motions in world space.","cats":{"new-dataset":0}}
{"text":"More video results can be found at our project page: https://liuyebin.com/proxycap.","cats":{"new-dataset":0}}
{"text":"In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world.","cats":{"new-dataset":1}}
{"text":"We address this issue by introducing a new dataset: GHOSTS.","cats":{"new-dataset":1}}
{"text":"This paper also contributes a new surveillance dataset called NightSuR.","cats":{"new-dataset":1}}
{"text":"We present in this work a new Universal Morphology dataset for Korean.","cats":{"new-dataset":1}}
{"text":"The PIKS technique is scalable and can readily ingest new datasets.","cats":{"new-dataset":0}}
{"text":"Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences.","cats":{"new-dataset":0}}
{"text":"The MIND dataset is at the moment of writing the most extensive dataset available for the research and development of news recommender systems.","cats":{"new-dataset":1}}
{"text":"We also introduce a new dataset generated by our classifier that tracks the dynamics of fake news in the Chinese language during the early pandemic.","cats":{"new-dataset":1}}
{"text":"Our code and data will be released shortly.","cats":{"new-dataset":0}}
{"text":"We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets.","cats":{"new-dataset":1}}
{"text":"This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.","cats":{"new-dataset":0}}
{"text":"This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C.  ","cats":{"new-dataset":0}}
{"text":"The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU.","cats":{"new-dataset":0}}
{"text":"Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4.","cats":{"new-dataset":0}}
{"text":"We present working notes on transfer learning with semi-supervised dataset annotation for the BirdCLEF 2023 competition, focused on identifying African bird species in recorded soundscapes","cats":{"new-dataset":1}}
{"text":"We explore the embedding space learned by BirdNET and propose a process to derive an annotated dataset for supervised learning","cats":{"new-dataset":1}}
{"text":"Our approach utilizes existing off-the-shelf models, BirdNET and MixIT, to address representation and labeling challenges in the competition.","cats":{"new-dataset":0}}
{"text":"We explore the embedding space learned by BirdNET and propose a process to derive an annotated dataset for supervised learning.","cats":{"new-dataset":0}}
{"text":"Our experiments involve various models and feature engineerih in classifying bird species and highlight the potential of transfer learning and semi-supervised dataset annotation in similar tasks.","cats":{"new-dataset":0}}
{"text":"Our data generator is capable of generating large-scale datasets of human activities","cats":{"new-dataset":1}}
{"text":"We release M3Act3D, an 87.6-hour 3D motion dataset of human activities with larger group sizes and higher complexity of inter-person interactions than previous multi-person datasets","cats":{"new-dataset":1}}
{"text":"The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision.","cats":{"new-dataset":0}}
{"text":"However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets.","cats":{"new-dataset":0}}
{"text":"To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator.","cats":{"new-dataset":0}}
{"text":"Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process.  ","cats":{"new-dataset":0}}
{"text":"with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories).","cats":{"new-dataset":0}}
{"text":"Using M3Act, we perform synthetic data pre-training for 2D skeleton-based group activity recognition and RGB-based multi-person pose tracking.","cats":{"new-dataset":0}}
{"text":"The results indicate that learning from our synthetic datasets largely improves the model performances on real-world datasets, with the highest gain of 5.59% and 7.32% respectively in group and person recognition accuracy on CAD2, as well as an improvement of 6.63 in MOTP on HiEve.","cats":{"new-dataset":0}}
{"text":"Pre-training with our synthetic data also leads to faster model convergence on downstream tasks (up to 6.8% faster).","cats":{"new-dataset":0}}
{"text":"Moreover, M3Act opens new research problems for 3D group activity generation.","cats":{"new-dataset":0}}
{"text":"We release M3Act3D, an 87.6-hour 3D motion dataset of human activities with larger g","cats":{"new-dataset":0}}
{"text":"Large language models typically undergo two training stages, pretraining and finetuning.","cats":{"new-dataset":0}}
{"text":"Despite that large-scale pretraining endows the model with strong capabilities to generate natural language responses, these pretrained models can still fail to understand human instructions at times.","cats":{"new-dataset":0}}
{"text":"To enhance language models' ability of interpreting and responding to instructions, instruction finetuning has emerged as a critical method in this area.","cats":{"new-dataset":0}}
{"text":"Recent studies found that large language models can be finetuned to perform well even with a small amount of high-quality instruction-following data.","cats":{"new-dataset":0}}
{"text":"However, the selection of high-quality datasets for finetuning language models still lacks clear guidelines to follow.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose InstructMining, a linear rule for evaluating instruction-following data quality.","cats":{"new-dataset":0}}
{"text":"We formulate InstructMining using specific natural language indicators.","cats":{"new-dataset":0}}
{"text":"To investigate the relationship between data quality and these indicators, we further conduct extensive finetuning experiments.","cats":{"new-dataset":0}}
{"text":"The experiment results are then applied to estimating parameters in InstructMining.","cats":{"new-dataset":0}}
{"text":"To further investigate its performance, we use InstructMining to select high-quality data from unseen datasets.","cats":{"new-dataset":0}}
{"text":"Results demonstrate that InstructMining can help select relatively high-quality samples from various instruction-following datasets.","cats":{"new-dataset":0}}
{"text":"Compared to models finetuned on unfiltered datasets, models finetuned on InstructMining selected datasets perform better on 42.5% cases.","cats":{"new-dataset":0}}
{"text":"Therefore, we introduce the Infrastructural Multi-Person Trajectory and Context Dataset (IMPTC).","cats":{"new-dataset":1}}
{"text":"The resulting dataset consists of eight hours of measurement data","cats":{"new-dataset":1}}
{"text":"In addition, to enable the entire stack of research capabilities, the dataset includes all data, starting from the sensor-, calibration- and detection data until trajectory and context data.","cats":{"new-dataset":1}}
{"text":"The dataset is continuously expanded and is available online for non-commercial research at https://github.com/kav-institute/imptc-dataset.","cats":{"new-dataset":1}}
{"text":"Inner-city intersections are among the most critical traffic areas for injury and fatal accidents.","cats":{"new-dataset":0}}
{"text":"Automated vehicles struggle with the complex and hectic everyday life within those areas.","cats":{"new-dataset":0}}
{"text":"Sensor-equipped smart infrastructures, which can cooperate with vehicles, can benefit automated traffic by extending the perception capabilities of drivers and vehicle perception systems.","cats":{"new-dataset":0}}
{"text":"Additionally, they offer the opportunity to gather reproducible and precise data of a holistic scene understanding, including context information as a basis for training algorithms for various applications in automated traffic.  ","cats":{"new-dataset":0}}
{"text":"We use an intelligent public inner-city intersection in Germany with visual sensor technology.","cats":{"new-dataset":0}}
{"text":"A multi-view camera and LiDAR system perceives traffic situations and road users' behavior.","cats":{"new-dataset":0}}
{"text":"Additional sensors monitor contextual information like weather, lighting, and traffic light signal status.","cats":{"new-dataset":0}}
{"text":"The data acquisition system focuses on Vulnerable Road Users (VRUs) and multi-agent interaction.","cats":{"new-dataset":0}}
{"text":"The resulting dataset consists of eight hours of measurement data.","cats":{"new-dataset":0}}
{"text":"It contains over 2,500 VRU trrollers, and wheelchair users, and over 20,000 vehicle trajectories at different day times, weather conditions, and seasons.","cats":{"new-dataset":0}}
{"text":"In addition, to enable the entire stack of research capabilities, the dataset includes all data, starting from the sensor-, calibration- and detection data until","cats":{"new-dataset":0}}
{"text":"Noisy label problems are inevitably in existence within medical image segmentation causing severe performance degradation.","cats":{"new-dataset":0}}
{"text":"Previous segmentation methods for noisy label problems only utilize a single image while the potential of leveraging the correlation between images has been overlooked.","cats":{"new-dataset":0,"data-quality":1}}
{"text":"Especially for video segmentation, adjacent frames contain rich contextual information beneficial in cognizing noisy labels.","cats":{"new-dataset":0}}
{"text":"Based on two insights, we propose a Multi-Scale Temporal Feature Affinity Learning (MS-TFAL) framework to resolve noisy-labeled medical video segmentation issues.","cats":{"new-dataset":0}}
{"text":"First, we argue the sequential prior of videos is an effective reference, i.e., pixel-level features from adjacent frames are close in distance for the same class and far in distance otherwise.","cats":{"new-dataset":0}}
{"text":"Therefore, Temporal Feature Affinity Learning (TFAL) is devised to indicate possible noisy labels by evaluating the affinity between pixels in two adjacent frames.","cats":{"new-dataset":0}}
{"text":"We also notice that the noise distribution exhibits considerable variations across video, image, and pixel levels.","cats":{"new-dataset":0}}
{"text":"In this way, we introduce Multi-Scale Supervision (MSS) to supervise the network from three different perspectives by re-weighting and refining the samples.","cats":{"new-dataset":0}}
{"text":"This design enables the network to concentrate on clean samples in a coarse-to-fine manner.","cats":{"new-dataset":0}}
{"text":"Experiments with both synthetic and real-world label noise demonstrate that our method outperforms recent state-of-the-art robust segmentation approaches.","cats":{"new-dataset":0,"data-quality":1}}
{"text":"Code is available at https://github.com/BeileiCui/MS-TFAL.","cats":{"new-dataset":0}}
{"text":"This paper proposes a data-efficient detection method for deep neural networks against backdoor attacks under a black-box scenario.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"The proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining the backdoored network output than any other benign features.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"To quantitatively measure the effects of triggers and benign features on determining the backdoored network output, we introduce five metrics.","cats":{"new-dataset":0}}
{"text":"To calculate the five-metric values for a given input, we first generate several synthetic samples by injecting the input's partial contents into clean validation samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Then, the five metrics are computed by using the output labels of the corresponding synthetic samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"One contribution of this work is the use of a tiny clean validation dataset.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Having the computed five metrics, five novelty detectors are trained from the validation dataset.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"A meta novelty detector fuses the output of the five trained novelty detectors to generate a meta confidence score.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"During online testing, our method determines if online samples are poisoned or not via assessing their meta confidence scores output by the meta novelty detector.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"We show the efficacy of our methodology through a broad range of backdoor attacks, including ablation studies and comparison to existing approaches.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Our methodology is promising since the proposed five metrics quantify the inherent differences between clean and poisoned samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Additionally, our detection method can be incrementally improved by appending more metrics that may be proposed to address future advanced attacks.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"To address this limitation, we have developed a synthetic dataset for short-term trajectory prediction tasks using the CARLA simulator.","cats":{"new-dataset":1}}
{"text":"This dataset is extensive and incorporates what is considered complex scenarios - pedestrians crossing the road, vehicles overtaking - and comprises 6000 perspective view images with corresponding IMU and odometry information for each frame.","cats":{"new-dataset":1}}
{"text":"In an effort to accelerate this research and assist others, we are releasing our dataset and model to the research community.","cats":{"new-dataset":0}}
{"text":"Our datasets are publicly available on https://github.com/navigatinguncertainty.","cats":{"new-dataset":0}}
{"text":"Autonomous vehicles require accurate and reliable short-term trajectory predictions for safe and efficient driving.","cats":{"new-dataset":0}}
{"text":"While most commercial automated vehicles currently use state machine-based algorithms for trajectory forecasting, recent efforts have focused on end-to-end data-driven systems.","cats":{"new-dataset":0}}
{"text":"Often, the design of these models is limited by the availability of datasets, which are typically restricted to generic scenarios.  ","cats":{"new-dataset":0}}
{"text":"This dataset is extensive and incorporates what is considered complex scenarios - pedestrians crossing the road, vehicles overtaking -  (LSTM) networks has also been developed.","cats":{"new-dataset":0}}
{"text":"This model can handle corner cases, such as slowing down near zebra crossings and stopping when pedestrians cross the road, without the need for explicit encoding of the surrounding environment.","cats":{"new-dataset":0}}
{"text":"Prompt-tuning has become an increasingly popular parameter-efficient method for adapting large pretrained language models to downstream tasks.","cats":{"new-dataset":0}}
{"text":"However, both discrete prompting and continuous prompting assume fixed prompts for all data samples within a task, neglecting the fact that inputs vary greatly in some tasks such as open-domain dialogue generation.","cats":{"new-dataset":0}}
{"text":"In this paper, we present a novel, instance-specific prompt-tuning algorithm for dialogue generation.","cats":{"new-dataset":0}}
{"text":"Specifically, we generate prompts based on instance-level control code, rather than the conversation history, to explore their impact on controlled dialogue generation.","cats":{"new-dataset":0}}
{"text":"Experiments on popular open-domain dialogue datasets, evaluated on both automated metrics and human evaluation, demonstrate that our method is superior to prompting baselines and comparable to fine-tuning with only 5%-6% of total parameters.","cats":{"new-dataset":0}}
{"text":"Code and datasets are available on GitHub https://github.com/neurospin-projects/2023_rlouiset_sepvae.","cats":{"new-dataset":1}}
{"text":"Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset.","cats":{"new-dataset":0}}
{"text":"To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets).","cats":{"new-dataset":0}}
{"text":"Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation.","cats":{"new-dataset":0}}
{"text":"To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space.","cats":{"new-dataset":0}}
{"text":"We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA).","cats":{"new-dataset":0}}
{"text":"The code and dataset are open source at https://github.com/junjun-yan/ATL-PINN.","cats":{"new-dataset":1}}
{"text":"Physics-informed neural networks (PINNs) have emerged as promising surrogate modes for solving partial differential equations (PDEs).","cats":{"new-dataset":0}}
{"text":"Their effectiveness lies in the ability to capture solution-related features through neural networks.","cats":{"new-dataset":0}}
{"text":"However, original PINNs often suffer from bottlenecks, such as low accuracy and non-convergence, limiting their applicability in complex physical contexts.","cats":{"new-dataset":0}}
{"text":"To alleviate these issues, we proposed auxiliary-task learning-based physics-informed neural networks (ATL-PINNs), which provide four different auxiliary-task learning modes and investigate their performance compared with original PINNs.","cats":{"new-dataset":0}}
{"text":"We also employ the gradient cosine similarity algorithm to integrate auxiliary problem loss with the primary problem loss in ATL-PINNs, which aims to enhance the effectiveness of the auxiliary-task learning modes.","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, this is the first study to introduce auxiliary-task learning modes in the context of physics-informed learning.","cats":{"new-dataset":0}}
{"text":"We conduct experiments on three PDE problems across different fields and scenarios.","cats":{"new-dataset":0}}
{"text":"Our findings demonstrate that the proposed auxiliary-task learning modes can significantly improve solution accuracy, achieving a maximum performance boost of 96.62% (averaging 28.23%) compared to the original single-task PINNs.","cats":{"new-dataset":0}}
{"text":"To facilitate the investigation, we introduce WikiTiLo, a well-curated image dataset compromising images with rich socio-cultural cues","cats":{"new-dataset":1}}
{"text":"We will release our dataset and codes to facilitate future studies.","cats":{"new-dataset":0}}
{"text":"Vision-Language Models (VLMs) are expected to be capable of reasoning with commonsense knowledge as human beings.","cats":{"new-dataset":0}}
{"text":"One example is that humans can reason where and when an image is taken based on their knowledge.","cats":{"new-dataset":0}}
{"text":"This makes us wonder if, based on visual cues, Vision-Language Models that are pre-trained with large-scale image-text resources can achieve and even outperform human's capability in reasoning times and location.","cats":{"new-dataset":0}}
{"text":"To address this question, we propose a two-stage \\recognition\\space and \\reasoning\\space probing task, applied to discriminative and generative VLMs to uncover whether VLMs can recognize times and location-relevant features and further reason about it. .","cats":{"new-dataset":0}}
{"text":"In the extensive experimental studies, we find that although VLMs can effectively retain relevant features in visual encoders, they still fail to make perfect reasoning.","cats":{"new-dataset":0}}
{"text":"Our model was evaluated on two benchmark tree counting datasets, Jiangsu, and Yosemite, as well as a new dataset, KCL-London, created by ourselves","cats":{"new-dataset":1}}
{"text":"The codes and datasets are available at https://github.com/HAAClassic/TreeFormer.","cats":{"new-dataset":0}}
{"text":"Automatic tree density estimation and counting using single aerial and satellite images is a challenging task in photogrammetry and remote sensing, yet has an important role in forest management.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose the first semisupervised transformer-based framework for tree counting which reduces the expensive tree annotations for remote sensing images.","cats":{"new-dataset":0}}
{"text":"Our method, termed as TreeFormer, first develops a pyramid tree representation module based on transformer blocks to extract multi-scale features during the encoding stage.","cats":{"new-dataset":0}}
{"text":"Contextual attention-based feature fusion and tree density regressor modules are further designed to utilize the robust features from the encoder to estimate tree density maps in the decoder.","cats":{"new-dataset":0}}
{"text":"Moreover, we propose a pyramid learning strategy that includes local tree density consistency and local tree count ranking losses to utilize unlabeled images into the training process.","cats":{"new-dataset":0}}
{"text":"Finally, the tree counter token is introduced to regulate the network by computing the global tree counts for both labeled and unlabeled images. .","cats":{"new-dataset":0}}
{"text":"Our TreeFormer outperforms the state of the art semi-supervised methods under the same setting and exceeds the fully-supervised methods using the same number of labeled images.","cats":{"new-dataset":0}}
{"text":"Despite recent advancements in speech emotion recognition (SER) models, state-of-the-art deep learning (DL) approaches face the challenge of the limited availability of annotated data.","cats":{"new-dataset":0}}
{"text":"Large language models (LLMs) have revolutionised our understanding of natural language, introducing emergent properties that broaden comprehension in language, speech, and vision.","cats":{"new-dataset":0}}
{"text":"This paper examines the potential of LLMs to annotate abundant speech data, aiming to enhance the state-of-the-art in SER.","cats":{"new-dataset":0}}
{"text":"We evaluate this capability across various settings using publicly available speech emotion classification datasets.","cats":{"new-dataset":0}}
{"text":"Leveraging ChatGPT, we experimentally demonstrate the promising role of LLMs in speech emotion data annotation.","cats":{"new-dataset":0}}
{"text":"Our evaluation encompasses single-shot and few-shots scenarios, revealing performance variability in SER.","cats":{"new-dataset":0}}
{"text":"Notably, we achieve improved results through data augmentation, incorporating ChatGPT-annotated samples into existing datasets.","cats":{"new-dataset":0}}
{"text":"Our work uncovers new frontiers in speech emotion classification, highlighting the increasing significance of LLMs in this field moving forward.","cats":{"new-dataset":0}}
{"text":"We have taken millions of images in the sorghum fields, manually selected 5,447 images that contain aphids, and annotated each aphid cluster in the image.","cats":{"new-dataset":1}}
{"text":"To use these images for machine learning models, we crop the images into patches and created a labeled dataset with over 151,000 image patches.","cats":{"new-dataset":0}}
{"text":"Aphids are one of the main threats to crops, rural families, and global food security.","cats":{"new-dataset":0}}
{"text":"Chemical pest control is a necessary component of crop production for maximizing yields, however, it is unnecessary to apply the chemical approaches to the entire fields in consideration of the environmental pollution and the cost.","cats":{"new-dataset":0}}
{"text":"Thus, accurately localizing the aphid and estimating the infestation level is crucial to the precise local application of pesticides.","cats":{"new-dataset":0}}
{"text":"Aphid detection is very challenging as each individual aphid is really small and all aphids are crowded together as clusters.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose to estimate the infection level by detecting aphid clusters.  ","cats":{"new-dataset":0}}
{"text":"Then, we i","cats":{"new-dataset":0}}
{"text":"Given a set of calibrated images of a scene, we present an approach that produces a simple, compact, and actionable 3D world representation by means of 3D primitives.","cats":{"new-dataset":0}}
{"text":"While many approaches focus on recovering high-fidelity 3D scenes, we focus on parsing a scene into mid-level 3D representations made of a small set of textured primitives.","cats":{"new-dataset":0}}
{"text":"Such representations are interpretable, easy to manipulate and suited for physics-based simulations.","cats":{"new-dataset":0}}
{"text":"Moreover, unlike existing primitive decomposition methods that rely on 3D input data, our approach operates directly on images through differentiable rendering.","cats":{"new-dataset":0}}
{"text":"Specifically, we model primitives as textured superquadric meshes and optimize their parameters from scratch with an image rendering loss.","cats":{"new-dataset":0}}
{"text":"We highlight the importance of modeling transparency for each primitive, which is critical for optimization and also enables handling varying numbers of primitives.","cats":{"new-dataset":0}}
{"text":"We show that the resulting textured primitives faithfully reconstruct the input images and accurately model the visible 3D points, while providing amodal shape completions of unseen object regions.","cats":{"new-dataset":0}}
{"text":"We compare our approach to the state of the art on diverse scenes from DTU, and demonstrate its robustness on real-life captures from BlendedMVS and Nerfstudio.","cats":{"new-dataset":0}}
{"text":"We also showcase how our results can be used to effortlessly edit a scene or perform physical simulations.","cats":{"new-dataset":0}}
{"text":"Code and video results are available at https://www.tmonnier.com/DBW .","cats":{"new-dataset":0}}
{"text":"This resource paper introduces ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs","cats":{"new-dataset":1}}
{"text":"To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language","cats":{"new-dataset":1}}
{"text":"To validate the performance of existing end-to-end Sign language to spoken language translation systems, we benchmark the created dataset with a transformer-based model for ISL translation","cats":{"new-dataset":1}}
{"text":"Sign languages are the primary means of communication for many hard-of-hearing people worldwide.","cats":{"new-dataset":0}}
{"text":"Recently, to bridge the communication gap between the hard-of-hearing community and the rest of the population, several sign language translation datasets have been proposed to enable the development of statistical sign language translation systems.","cats":{"new-dataset":0}}
{"text":"However, there is a dearth of sign language resources for the Indian sign language. .","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language.","cats":{"new-dataset":0}}
{"text":"We provide a detailed analysis of the dataset.","cats":{"new-dataset":0}}
{"text":"To validchmark the created dataset with a transformer-based model for ISL translation.","cats":{"new-dataset":0}}
{"text":"This paper introduces the Life Scapes Reasoning Benchmark (LSR-Benchmark), a novel dataset targeting real-life scenario reasoning","cats":{"new-dataset":1}}
{"text":"The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its quality.","cats":{"new-dataset":1}}
{"text":", aiming to close the gap in artificial neural networks' ability to reason in everyday contexts.","cats":{"new-dataset":0}}
{"text":"In contrast to domain knowledge reasoning datasets, LSR-Benchmark comprises free-text formatted questions with rich information on real-life scenarios, human behaviors, and character roles.","cats":{"new-dataset":0}}
{"text":"The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its qualitto test the performance in LSR-Benchmark.","cats":{"new-dataset":0}}
{"text":"The results reveal that humans outperform these models significantly, indicating a persisting challenge for machine learning models in comprehending daily human life.","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset contains audio signals of cough (4,676), regular breathing (4,665), deep breathing (4,695) and voice (4,291) as recorded by means of mobile devices following a crowd-sourcing approach","cats":{"new-dataset":1}}
{"text":"Other self reported information is also included (e.g. COVID-19 virus tests), thus providing a comprehensive dataset for the development of COVID-19 risk detection models.","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset is released in the form of a web-ontology language (OWL) knowledge base enabling data consolidation from other relevant datasets, complex queries and reasoning","cats":{"new-dataset":1}}
{"text":"Harnessing the power of Artificial Intelligence (AI) and m-health towards detecting new bio-markers indicative of the onset and progress of respiratory abnormalities/conditions has greatly attracted the scientific and research interest especially during COVID-19 pandemic. .","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset is releasedtowards the development of models able to: (i) extract clinically informative respiratory indicators from regular breathing records, and (ii) identify cough, breath and voirisk detection models is proposed and validated.","cats":{"new-dataset":0}}
{"text":"This dataset collects nighttime images with different properties of nighttime environments, such as flare and extreme darkness","cats":{"new-dataset":1}}
{"text":"The dataset and source code will be released on GitHub soon.","cats":{"new-dataset":0}}
{"text":"Nighttime surveillance suffers from degradation due to poor illumination and arduous human annotations.","cats":{"new-dataset":0}}
{"text":"It is challengable and remains a security risk at night.","cats":{"new-dataset":0}}
{"text":"Existing methods rely on multi-spectral images to perceive objects in the dark, which are troubled by low resolution and color absence.","cats":{"new-dataset":0}}
{"text":"We argue that the ultimate solution for nighttime surveillance is night-to-day translation, or Night2Day, which aims to translate a surveillance scene from nighttime to the daytime while maintaining semantic consistency.","cats":{"new-dataset":0}}
{"text":"To achieve this, this paper presents a Disentangled Contrastive (DiCo) learning method.","cats":{"new-dataset":0}}
{"text":"Specifically, to address the poor and complex illumination in the nighttime scenes, we propose a learnable physical prior, i.e., the color invariant, which provides a stable perception of a highly dynamic night environment and can be incorporated into the learning pipeline of neural networks.","cats":{"new-dataset":0}}
{"text":"Targeting the surveillance scenes, we develop a disentangled representation, which is an auxiliary pretext task that separates surveillance scenes into the foreground and background with contrastive learning.","cats":{"new-dataset":0}}
{"text":"Such a strategy can extract the semantics without supervision and boost our model to achieve instance-aware translation.","cats":{"new-dataset":0}}
{"text":"Finally, we incorporate all the modules above into generative adversarial networks and achieve high-fidelity translation.  ","cats":{"new-dataset":0}}
{"text":"It includes six scenes to support the study on nighttime surveillance.","cats":{"new-dataset":0}}
{"text":"This dataset collects nighttime images with different properties of nigg works significantly.","cats":{"new-dataset":0}}
{"text":"In this paper, we present TRansPose, the first large-scale multispectral dataset that combines stereo RGB-D, thermal infrared (TIR) images, and object poses to promote transparent object research","cats":{"new-dataset":1}}
{"text":"The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects","cats":{"new-dataset":1}}
{"text":"It comprises a vast collection of 333,819 images and 4,000,056 annotations, providing instance-level segmentation masks, ground-truth poses, and completed depth information","cats":{"new-dataset":1}}
{"text":"The data was acquired using a FLIR A65 thermal infrared (TIR) camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator","cats":{"new-dataset":1}}
{"text":"TRansPose dataset can be accessed from the following link: https://sites.google.com/view/transpose-dataset","cats":{"new-dataset":0}}
{"text":"Transparent objects are encountered frequently in our daily lives, yet recognizing them poses challenges for conventional vision sensors due to their unique material properties, not being well perceived from RGB or depth cameras.","cats":{"new-dataset":0}}
{"text":"Overcoming this limitation, thermal infrared cameras have emerged as a solution, offering improved visibility and shape information for transparent objects. .","cats":{"new-dataset":0}}
{"text":"The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects.","cats":{"new-dataset":0}}
{"text":"It comprises a vast colleced using a FLIR A65 thermal infrared (TIR) camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator.","cats":{"new-dataset":0}}
{"text":"Spanning 87 sequences, TRansPose cbjects in plastic bags, and multi-stacked objects.","cats":{"new-dataset":0}}
{"text":"this paper, we introduce the BeaverTails dataset, aimed at fostering research on safety alignment in large language models (LLMs).","cats":{"new-dataset":1}}
{"text":"In total, we have compiled safety meta-labels for 30,207 question-answer (QA) pairs and gathered 30,144 pairs of expert comparison data for both the helpfulness and harmlessness metrics","cats":{"new-dataset":1}}
{"text":"We believe this dataset provides vital resources for the community, contributing towards the safe development and deployment of LLMs.","cats":{"new-dataset":0}}
{"text":"In  This dataset uniquely separates annotations of helpfulness and harmlessness for question-answering pairs, thus offering distinct perspectives on these crucial attributes.","cats":{"new-dataset":0}}
{"text":"In total, we have compiled safety meta-labels for 30,207 question-answer (QA) pairs and gathered 30,144 pairs of expert comparisonhasizing its potential for practical safety measures in LLMs.","cats":{"new-dataset":0}}
{"text":"Our project page is available at the following URL: https://sites.google.com/view/pku-beavertails.","cats":{"new-dataset":0}}
{"text":"We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM).","cats":{"new-dataset":0}}
{"text":"The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes.","cats":{"new-dataset":0}}
{"text":"We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context.","cats":{"new-dataset":0}}
{"text":"Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses.","cats":{"new-dataset":0}}
{"text":"Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts.","cats":{"new-dataset":0}}
{"text":"The promising results demonstrate significant implications of the ICAE for its novel approach to the long context problem and its potential to reduce computation and memory overheads for LLM inference in practice, suggesting further research effort in context management for an LLM.","cats":{"new-dataset":0}}
{"text":"This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation.","cats":{"new-dataset":1}}
{"text":"The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words.","cats":{"new-dataset":1}}
{"text":" The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words.","cats":{"new-dataset":0}}
{"text":"Our core contribution is to developnguage representation at scale.","cats":{"new-dataset":0}}
{"text":"Specifically, we utilize a multi-scale approach to generate video-related descriptions.","cats":{"new-dataset":0}}
{"text":"Furthermore, we introduce ViCLIP, a video-text representation learning model based on ViT-L. Learned on InternVid via contrastive learning, this model demonstrates leading zero-shot action recognition and competitive video retrieval performance.","cats":{"new-dataset":0}}
{"text":"Beyond basic video understanding tasks like recognition and retrieval, our dataset and model have broad applications.","cats":{"new-dataset":0}}
{"text":"They are particularly beneficial for generating interleaved video-text data for learning a video-centric dialogue system, advancing video-to-text and text-to-video generation research.","cats":{"new-dataset":0}}
{"text":"These proposed resources provide a tool for researchers and practitioners interested in multimodal video understanding and generation.","cats":{"new-dataset":0}}
{"text":"We make our data and code publicly available in https://github.com/AI21Labs/factor.","cats":{"new-dataset":1}}
{"text":"Before deploying a language model (LM) within a given domain, it is important to measure its tendency to generate factually incorrect information in that domain.","cats":{"new-dataset":0}}
{"text":"Existing factual generation evaluation methods focus on facts sampled from the LM itself, and thus do not control the set of evaluated facts and might under-represent rare and unlikely facts.","cats":{"new-dataset":0}}
{"text":"We propose FACTOR:","cats":{"new-dataset":0}}
{"text":"Factual Assessment via Corpus TransfORmation, a scalable approach for evaluating LM factuality.","cats":{"new-dataset":0}}
{"text":"FACTOR automatically transforms a factual corpus of interest into a benchmark evaluating an LM's propensity to generate true facts from the corpus vs. similar but incorrect statements.","cats":{"new-dataset":0}}
{"text":"We use our framework to create two benchmarks: Wiki-FACTOR and News-FACTOR.","cats":{"new-dataset":0}}
{"text":"We show that: (i) our benchmark scores increase with model size and improve when the LM is augmented with retrieval; (ii) benchmark score correlates with perplexity, but the two metrics do not always agree on model ranking; and (iii) when perplexity and benchmark score disagree, the latter better reflects factuality in open-ended generation, as measured by human annotators.","cats":{"new-dataset":0}}
{"text":"LCC provided an anonymised dataset comprising 14360 records of young people under the age of 18.","cats":{"new-dataset":1}}
{"text":"Local authorities in England, such as Leicestershire County Council (LCC), provide Early Help services that can be offered at any point in a young person's life when they experience difficulties that cannot be supported by universal services alone, such as schools.","cats":{"new-dataset":0}}
{"text":"This paper investigates the utilisation of machine learning (ML) to assist experts in identifying families that may need to be referred for Early Help assessment and support.  ","cats":{"new-dataset":0}}
{"text":"The dataset was pre-processed, machine learning models were build, and experiments were conducted to validate and test the performance of the models.","cats":{"new-dataset":0}}
{"text":"Bias mitigation techniques were applied to improve the fairness of these models.","cats":{"new-dataset":0}}
{"text":"During testing, while the models demonstrated the capability to identify young people requiring intervention or early help, they also produced a significant number of false positives, especially when constructed with imbalanced data, incorrectly identifying individuals who most likely did not need an Early Help referral.","cats":{"new-dataset":0}}
{"text":"This paper empirically explores the suitability of data-driven ML models for identifying young people who may require Early Help services and discusses their appropriateness and limitations for this task.","cats":{"new-dataset":0}}
{"text":"Experiments on a new dataset of real images show that adding RePoGen data to the COCO surpasses previous attempts to top-view pose estimation and significantly improves performance on the bottom-view dataset","cats":{"new-dataset":1}}
{"text":"The code and the datasets are available on the project website.","cats":{"new-dataset":0}}
{"text":"Human Pose Estimation is a thoroughly researched problem; however, most datasets focus on the side and front-view scenarios.","cats":{"new-dataset":0}}
{"text":"We address the limitation by proposing a novel approach that tackles the challenges posed by extreme viewpoints and poses.","cats":{"new-dataset":0}}
{"text":"We introduce a new method for synthetic data generation - RePoGen, RarE POses GENerator - with comprehensive control over pose and view to augment the COCO dataset. .","cats":{"new-dataset":0}}
{"text":"Through an extensive ablation study on both the top and bottom view data, we elucidate the contributions of methodological choices and demonstrate improved performance.","cats":{"new-dataset":0}}
{"text":"We propose IntelliGraphs, a set of five new Knowledge Graph datasets.","cats":{"new-dataset":1}}
{"text":"We also present the dataset generator that produced the synthetic datasets.","cats":{"new-dataset":1}}
{"text":"Knowledge Graph Embedding (KGE) models are used to learn continuous representations of entities and relations.","cats":{"new-dataset":0}}
{"text":"A key task in the literature is predicting missing links between entities.","cats":{"new-dataset":0}}
{"text":"However, Knowledge Graphs are not just sets of links but also have semantics underlying their structure.","cats":{"new-dataset":0}}
{"text":"Semantics is crucial in several downstream tasks, such as query answering or reasoning.","cats":{"new-dataset":0}}
{"text":"We introduce the subgraph inference task, where a model has to generate likely and semantically valid subgraphs.  ","cats":{"new-dataset":0}}
{"text":"The IntelliGraphs datasets contain subgraphs with semantics expressed in logical rules for evaluating subgraph inference.","cats":{"new-dataset":0}}
{"text":"We also present the dataset generator that produced the synthetic datased on traditional KGEs.","cats":{"new-dataset":0}}
{"text":"We evaluate their expressiveness and show that these models cannot capture the semantics.","cats":{"new-dataset":0}}
{"text":"We believe this benchmark will encourage the development of machine learning models that emphasize semantic understanding.","cats":{"new-dataset":0}}
{"text":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization.","cats":{"prompt-eng":1}}
{"text":"The specific assignment prompted students to define and explain their career goals as engineers.","cats":{"prompt-eng":0}}
{"text":"Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks.","cats":{"prompt-eng":1}}
{"text":"It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering.","cats":{"prompt-eng":1}}
{"text":"Specifically, we add a set of ``task prompts'', each corresponding to a different task, and let each prompt predict task-related annotations.","cats":{"prompt-eng":1}}
{"text":"To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output.","cats":{"prompt-eng":1}}
{"text":"The context of our task leverages a generative model as an IR engine to evaluate the prompts' performance on image retrieval tasks.","cats":{"prompt-eng":1}}
{"text":"Specifically, we first perform supervised fine-tuning with a pretrained language model on a small collection of manually engineered prompts.","cats":{"prompt-eng":1}}
{"text":"We first devise a learnable universal prompt to describe the correlations among all tasks and then convert this prompt and image features into a task-specific prompt, which is fed to the decoder as a part of its input.","cats":{"prompt-eng":1}}
{"text":"Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering.","cats":{"prompt-eng":1}}
{"text":"Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction.","cats":{"prompt-eng":0}}
{"text":"We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts.","cats":{"prompt-eng":1}}
{"text":"We adopt a specific prompting approach to solving the ranking task by LLMs: we carefully design the prompting template by including the sequential interaction history, the candidate items, and the ranking instruction.","cats":{"prompt-eng":1}}
{"text":"To be specific, we design a set of prompts to fine-tune the pre-trained image captioner.","cats":{"prompt-eng":1}}
{"text":"However, these approaches are task-specific; designing algorithms for new tasks is a cumbersome process.","cats":{"prompt-eng":0}}
{"text":"Therefore, no further task-specific reward design is needed.","cats":{"prompt-eng":0}}
{"text":"In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP).","cats":{"prompt-eng":1}}
{"text":"However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted.","cats":{"prompt-eng":0,"data-quality":0}}
{"text":"LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between tokens; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization.","cats":{"prompt-eng":0}}
{"text":"In the case where the region is the entire infinite triangular grid, we prove that the existence of a solution can be solved with an algorithm of complexity $O(|X|^3)$ where $X$ is the set of input edges.","cats":{"prompt-eng":0}}
{"text":"However, even manually labeled datasets contain errors, not to mention automatically labeled ones.","cats":{"data-quality":1}}
{"text":"Label error is a ubiquitous problem in annotated data.","cats":{"data-quality":1}}
{"text":"After demonstrating that our methodology empirically outperforms other algorithms for label error detection, we apply our approach to discover many label errors in the CelebA image tagging dataset.","cats":{"data-quality":1}}
{"text":"These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings.","cats":{"data-quality":0}}
{"text":"In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines.","cats":{"data-quality":1}}
{"text":"Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings.","cats":{"data-quality":1}}
{"text":"We also propose an improved self-labeling loss; it is robust to pseudo-labeling errors and enforces stronger fairness.","cats":{"data-quality":1}}
{"text":"Inferencing unlabeled data from labeled data is an error-prone process.","cats":{"data-quality":1}}
{"text":"However, creating such large keypoint labels is time-consuming and costly, and is often error-prone due to inconsistent labeling.","cats":{"data-quality":0}}
{"text":"The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter.","cats":{"data-quality":1}}
{"text":"PseudoAugments outperforms pseudo labeling by mitigating pseudo labeling errors and generating diverse fused training scenes.","cats":{"data-quality":1}}
{"text":"Our model is also able to maintain high classification accuracy with very few labels, with only 7.79% error when only using 145 labels.","cats":{"data-quality":0}}
{"text":"Detecting errors in KGs is challenging since the patterns of errors are unknown and diverse, while ground-truth labels are rare or even unavailable.","cats":{"data-quality":1}}
{"text":"We analyze the factors affecting this approximation error and design a pseudo-label clustering generation method to reduce the approximation error.","cats":{"data-quality":1}}
{"text":"To ameliorate the impact of label errors, we equipped our method with a novel negative label sampling strategy to strengthen the model robustness.","cats":{"data-quality":1}}
{"text":"We propose an extension of the Confident Learning framework to this setting, as well as a label quality score that ranks examples with label errors much higher than those which are correctly labeled.","cats":{"data-quality":1}}
{"text":"The later case can generate dense flow labels but the interpolated events are prone to errors.","cats":{"data-quality":0}}
{"text":"Improper fingerprint localization and finger labeling errors lead to poor matching performance.","cats":{"data-quality":0}}
{"text":"Our experiments show that our method is robust to linguistic labels with poor orthography and alignment errors.","cats":{"data-quality":1}}
{"text":"We derive an upper bound for the generalization error that is linear in the clients' label noise level.","cats":{"data-quality":1}}
{"text":"For example, for the IMDB text data with known labeling errors, a 14% boost is shown.","cats":{"data-quality":1}}
{"text":"Large amounts of label error substantially degrades the quality of deep learning models.","cats":{"data-quality":1}}
{"text":"We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets.","cats":{"data-quality":1}}
{"text":"We prove that semi-supervised labels improve the downstream error bound whereas noisy labels have limited effects under such a paradigm.","cats":{"data-quality":1}}
{"text":"This paper provides an exact characterization of the expected generalization error (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via the Gibbs algorithm.","cats":{"data-quality":0}}
{"text":"However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","cats":{"data-quality":1}}
{"text":"Most existing methods utilize the off-the-shelf pose or parsing networks as pseudo labels, which are prone to error.","cats":{"data-quality":0}}
{"text":"The result is an SSL classification framework explicitly designed to overcome inevitable pseudo-label errors.","cats":{"data-quality":1}}
{"text":"Here we consider the task of finding sentences that contain label errors in token classification datasets.","cats":{"data-quality":1}}
{"text":"Scaling sequence length has become a critical demand in the era of large language models.","cats":{"data-quality":0}}
{"text":"In this work, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences.","cats":{"data-quality":0}}
{"text":"Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows.","cats":{"data-quality":0}}
{"text":"Experiments results demonstrate that LongNet yields strong performance on both long-sequence modeling and general language tasks.","cats":{"data-quality":0}}
{"text":"Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains.","cats":{"data-quality":0}}
{"text":"However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents.","cats":{"data-quality":0}}
{"text":"In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments.","cats":{"data-quality":0}}
{"text":"Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently.","cats":{"data-quality":0}}
{"text":"We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting.","cats":{"data-quality":0}}
{"text":"We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans.","cats":{"data-quality":0}}
{"text":"For QE in particular, high-quality labeled data is often lacking due to the high-cost and effort associated with labeling such data.","cats":{"data-quality":0}}
{"text":"With many possible classes to consider, data annotators are likely to make errors when labeling such data in practice.","cats":{"data-quality":1}}
{"text":"However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels.","cats":{"data-quality":0}}
{"text":"For such bone structure analyses, deep learning technologies are promising but require high-quality labeled data for the learning, while the data labeling is costly.","cats":{"data-quality":0}}
{"text":"However, agreement between annotators is often low, leading to inconsistent labels that hinder the reliability of models.","cats":{"data-quality":1}}
{"text":"Our experiments show that this approach consistently improves inter-annotator agreement and annotation accuracy.","cats":{"data-quality":1}}
{"text":"We advocate for the use of IAA in predicting the labeling quality of individual annotators, leading to cost and time efficiency in data production.","cats":{"data-quality":1}}
{"text":"This paper presents a novel approach of leveraging Inter-Annotator Agreement (IAA), traditionally used for assessing labeling consistency, to optimize Data Management Operations (DMOps).","cats":{"data-quality":1}}
{"text":"Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively.","cats":{"data-quality":1}}
{"text":"However, such annotations may fail in practice because of the change in annotation requirements, application scenarios, and modeling goals, where label validation and relabeling by domain experts are required.","cats":{"data-quality":1}}
{"text":"However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the results.","cats":{"data-quality":1}}
{"text":"However, these annotations are inherently subjective and some of the instances are hard to classify, resulting in noisy annotations due to error or lack of agreement.","cats":{"data-quality":1}}
{"text":"We propose and evaluate an additional application of our method leading to the detection of annotation errors.","cats":{"data-quality":1}}
{"text":"However, arbitrating the final annotation is not always effective because new biases might be produced during the process, especially when there are significant variations among annotations.","cats":{"data-quality":1}}
{"text":"A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus.","cats":{"data-quality":0}}
{"text":"We observe a striking correlation between the model's and humans' annotation: Categories with consistent human annotations (>$0.9$ inter-rater reliability, IRR) also display higher human-model agreement (>$0.7$), while categories with less consistent human annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower human-model agreement ($0.3$-$0.5$).","cats":{"data-quality":1}}
{"text":"We propose two metrics to audit the noise of annotations.","cats":{"data-quality":1}}
{"text":"We will release our annotation scheme, the corpus, and codes to the research community to alleviate the scarcity of labeled data in this domain.","cats":{"data-quality":1}}
{"text":"Whereas such annotation is costly and hard to scale, significantly holding back the development of the research.","cats":{"data-quality":0}}
{"text":"A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label.","cats":{"data-quality":1}}
{"text":"We hypothesize two failure modes of safety training: competing objectives and mismatched generalization.","cats":{"data-quality":0}}
{"text":"Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist.","cats":{"data-quality":0}}
{"text":"We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models.","cats":{"data-quality":0}}
{"text":"Specifically, we analyze the impact of the manifold's curvatures (or higher order nonlinearity in the parameterization when the curvatures are locally zero) on the uniqueness of the regression solution.","cats":{"data-quality":0}}
{"text":"Our findings suggest that the corresponding linear regression does not have a unique solution when the embedded submanifold is flat in some dimensions.","cats":{"data-quality":0}}
{"text":"Our findings thus reveal the role of data manifold geometry in ensuring the stability of regression models for out-of-distribution inferences.","cats":{"data-quality":0}}
{"text":"To disentangle these effects, we propose an evaluation framework based on \"counterfactual\" task variants that deviate from the default assumptions underlying standard tasks.","cats":{"data-quality":0}}
{"text":"Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions.","cats":{"data-quality":0}}
{"text":"We detail corpus statistics and demonstrate high inter-annotator agreement.","cats":{"data-quality":0}}
{"text":"We also propose an accurate pseudo label generation method through prototype learning.","cats":{"data-quality":0}}
{"text":"Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities, representing distributions over classes in a classification setting, subject to a hyper-parameter encoding annotator reliability.","cats":{"data-quality":1}}
{"text":"Based on this model, we propose a metric for measuring annotation uncertainty and provide uncertainty-adjusted metrics for performance evaluation.","cats":{"data-quality":0}}
{"text":"Identifying the samples with corrupted labels and preventing the model from learning them is a promising approach to address this challenge.","cats":{"data-quality":1}}
{"text":"Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset.","cats":{"data-quality":1}}
{"text":"Large-scale datasets in the real world inevitably involve label noise.","cats":{"data-quality":0}}
{"text":"This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone.","cats":{"data-quality":0}}
{"text":"We develop an efficient algorithm for detecting label errors and outlier data points based on the relational graph structure of the dataset.","cats":{"data-quality":1}}
{"text":"By focusing on finding incorrect labels in the original training datasets, we can eliminate erroneous examples in their root.","cats":{"data-quality":1}}
{"text":"Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project.","cats":{"data-quality":0}}
{"text":"Here we consider algorithms for finding mislabeled examples in multi-label classification datasets.","cats":{"data-quality":1}}
{"text":"Negative labels are those that a corresponding data item does not belong.","cats":{"data-quality":0}}
{"text":"This issue is due to biased labeling preferences at multiple clients and is a typical setting of data heterogeneity.","cats":{"data-quality":0}}
{"text":"However, noisy samples (i.e., with wrong labels) in the training set induce confusion and cause the network to learn the incorrect representation.","cats":{"data-quality":1}}
{"text":"Mislabeled examples are a common issue in real-world data, particularly for tasks like token classification where many labels must be chosen on a fine-grained basis.","cats":{"data-quality":1}}
{"text":"We also introduced robust loss to reduce the noise effects of inaccurate labels generated in semi-supervised learning.","cats":{"data-quality":1}}
{"text":"The main anomaly was found by the autoencoder and automatically created labels and was also recorded in the log files.","cats":{"data-quality":1}}
{"text":"About 0.2% of the images could not be assigned a label, while for 5.1% the reviewers were uncertain, or they assigned an invalid label.","cats":{"data-quality":1}}
{"text":"We find that the above issues are caused by the training dataset's pose imbalance.   ","cats":{"data-quality":0}}
{"text":"However, we identify issues with the dataset quality and evaluation metric.","cats":{"data-quality":1}}
{"text":"The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly.","cats":{"data-quality":1}}
{"text":"We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled.","cats":{"data-quality":1}}
{"text":"Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized.","cats":{"data-quality":1}}
{"text":"Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset.","cats":{"data-quality":1}}
{"text":"Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error.","cats":{"data-quality":1}}
{"text":"In recent years, research on learning with noisy labels has focused on devising novel algorithms that can achieve robustness to noisy training labels while generalizing to clean data.","cats":{"data-quality":1}}
{"text":"While some of these regularization strategies have been utilized in previous noisy label learning research, their full potential has not been thoroughly explored.","cats":{"data-quality":1}}
{"text":"We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields high AUROC values for identifying the mislabeled samples.","cats":{"data-quality":1}}
{"text":"Motivated by the optimal strategy, we introduce double-score OOD methods that leverage uncertainty scores from two chosen OOD detectors: one focused on OOD/ID discrimination and the other on misclassification detection.","cats":{"data-quality":1}}
{"text":"The optimal prediction strategy for out-of-distribution (OOD) setups is a fundamental question in machine learning.","cats":{"data-quality":0}}
{"text":"In this paper, we address this question and present several contributions.","cats":{"data-quality":0}}
{"text":"We propose three reject option models for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the Bounded Precision-Recall model.","cats":{"data-quality":0}}
{"text":"These models extend the standard reject option models used in non-OOD setups and define the notion of an optimal OOD selective classifier.","cats":{"data-quality":0}}
{"text":"We establish that all the proposed models, despite their different formulations, share a common class of optimal strategies.  ","cats":{"data-quality":0}}
{"text":"The experimental results consistently demonstrate the superior performance of this simple strategy compared to state-of-the-art methods.","cats":{"data-quality":0}}
{"text":"Additionally, we propose novel evaluation metrics derived from the definition of the optimal strategy under the proposed OOD rejection models.","cats":{"data-quality":0}}
{"text":"These new metrics provide a comprehensive and reliable assessment of OOD methods without the deficiencies observed in existing evaluation approaches.","cats":{"data-quality":0}}
{"text":"This analysis helps us find a, to the best of our knowledge, novel failure model on the CIFAR100 dataset, that of duplicated images with different labels","cats":{"data-quality":1}}
{"text":"Neural networks are overparametrized and easily overfit the datasets they train on.","cats":{"data-quality":0}}
{"text":"In the extreme case, it is shown that they can memorize a training set with fully randomized labels.","cats":{"data-quality":0}}
{"text":"We propose using the curvature of loss function around the training sample as a measure of its memorization, averaged over all training epochs.","cats":{"data-quality":0}}
{"text":"We use this to study the generalization versus memorization properties of different samples in popular image datasets.","cats":{"data-quality":0}}
{"text":"We visualize samples with the highest curvature of loss around them, and show that these visually correspond to long-tailed, mislabeled or conflicting samples. .","cats":{"data-quality":0}}
{"text":"We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields","cats":{"data-quality":0}}
{"text":"Medical image classification is a challenging task due to the scarcity of labeled samples and class imbalance caused by the high variance in disease prevalence.","cats":{"data-quality":0}}
{"text":"Semi-supervised learning (SSL) methods can mitigate these challenges by leveraging both labeled and unlabeled data.","cats":{"data-quality":0}}
{"text":"However, SSL methods for medical image classification need to address two key challenges: (1) estimating reliable pseudo-labels for the images in the unlabeled dataset and (2) reducing biases caused by class imbalance.","cats":{"data-quality":0}}
{"text":"In this paper, we propose a novel SSL approach, SPLAL, that effectively addresses these challenges.","cats":{"data-quality":0}}
{"text":"SPLAL leverages class prototypes and a weighted combination of classifiers to predict reliable pseudo-labels over a subset of unlabeled images.","cats":{"data-quality":0}}
{"text":"Additionally, we introduce alignment loss to mitigate model biases toward majority classes.","cats":{"data-quality":0}}
{"text":"To evaluate the performance of our proposed approach, we conduct experiments on two publicly available medical image classification benchmark datasets: the skin lesion classification (ISIC 2018) and the blood cell classification dataset (BCCD).","cats":{"data-quality":0}}
{"text":"The experimental results empirically demonstrate that our approach outperforms several state-of-the-art SSL methods over various evaluation metrics.","cats":{"data-quality":0}}
{"text":"Specifically, our proposed approach achieves a significant improvement over the state-of-the-art approach on the ISIC 2018 dataset in both Accuracy and F1 score, with relative margins of 2.24\\% and 11.40\\%, respectively.","cats":{"data-quality":0}}
{"text":"Finally, we conduct extensive ablation experiments to examine the contribution of different components of our approach, validating its effectiveness.","cats":{"data-quality":0}}
{"text":"Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks","cats":{"data-quality":1}}
{"text":"Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training.","cats":{"data-quality":1}}
{"text":"However, all these methods still suffer from the token distribution shift induced by typos","cats":{"data-quality":1}}
{"text":"We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing.","cats":{"data-quality":0}}
{"text":"Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them.","cats":{"data-quality":0}}
{"text":"Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing wixtual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences.","cats":{"data-quality":0}}
{"text":"By using raw text similarities, our ae that the attention bias introduced by LEA helps cross-encoders to tackle complex scenarios with textual noise, specially in domains with short-text descriptions and limited context.","cats":{"data-quality":0}}
{"text":"Experiments using three popular Transformer encoders in five e-commerce datasets for product matching show that LEA consistently boosts performance under the presence of noise, while remaining competitive on the original (clean) splits.","cats":{"data-quality":0}}
{"text":"We also evaluate our approach in two datasets for textual entailment and paraphrasing showing that LEA is robust to typos in domains with longer sentences and more natural context.","cats":{"data-quality":0}}
{"text":"Additionally, we thoroughly analyze several design choices in our approach, providing insights about the impact of the decisions made and fostering future research in cross-encoders dealing with typos.","cats":{"data-quality":0}}
{"text":"For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain.","cats":{"data-quality":0}}
{"text":"However, this is actually not the case and the ground truth may be uncertain.","cats":{"data-quality":0}}
{"text":"Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance.","cats":{"data-quality":0}}
{"text":"To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information.","cats":{"data-quality":0}}
{"text":"This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging.","cats":{"data-quality":0}}
{"text":"In contrast, we propose a framework where aggregation is done using a statistical model.  ","cats":{"data-quality":0}}
{"text":"We present a case study applying our framework to skin condition classification fromtion (IRN) from previous work ignores ground truth uncertainty in evaluation.","cats":{"data-quality":0}}
{"text":"Instead, we present two alternative statistical models: a probabilistic version of IRN and a Plackett-Luce-based model.","cats":{"data-quality":0}}
{"text":"We find that a large portion of the dataset exhibits significant ground truth uncertainty and standard IRN-based evaluation severely over-estimates performance without providing uncertainty estimates.","cats":{"data-quality":0}}
{"text":"To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment","cats":{"data-quality":1}}
{"text":"The two components are respectively designed to eliminate Type I and Type II pseudo-labeling errors identified through our analyse.","cats":{"data-quality":0}}
{"text":"The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated.","cats":{"data-quality":1}}
{"text":"Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. .","cats":{"data-quality":0}}
{"text":"UPL-EA consists of two complementary components: (1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to enable more accurate determination of entity correspondences across two KGs and to mitigate the adverse impact of erroneous matches.","cats":{"data-quality":0}}
{"text":"A simple but highly effective criterion is further devised to derive pseudo-labeled entity pairs that satisfy one-to-one correspondences at each iteration.","cats":{"data-quality":0}}
{"text":"(2) The cross-iteration pseudo-label calibration operates across multiple consecutive iterations to further improve the pseudo-labeling precision rate by reducing the local pseudo-label selection variability with a theoretical guarantee.","cats":{"data-quality":0}}
{"text":"The calibrated pseudo-labels are thereafter used to augment prior alignment seeds to reinforce subsequent model training fomentally validated.","cats":{"data-quality":0}}
{"text":"The experimental results show that our approach achieves competitive performance with limited prior alignment seeds.","cats":{"data-quality":0}}
{"text":"A novel annotation method was used to collect three separate annotations for each region of interest, and these annotations were performed in a fully transparent setting using a web-based annotation tool.","cats":{"data-quality":1}}
{"text":"This paper presents the challenge report for the 2021 Kidney and Kidney Tumor Segmentation Challenge (KiTS21) held in conjunction with the 2021 international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI).","cats":{"data-quality":0}}
{"text":"KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset.  ","cats":{"data-quality":0}}
{"text":"Further, the KiTS21 test set was collected from an outside institution, challenging participants to develop methods that generalize well to new populations.","cats":{"data-quality":0}}
{"text":"Nonetheless, the top-performing teams achieved a significant improvement over the state of the art set in 2019, and this performance is shown to inch ever closer to human-level performance.","cats":{"data-quality":0}}
{"text":"An in-depth meta-analysis is presented describing which methods were used and how they faired on the leaderboard, as well as the characteristics of which cases generally saw good performance, and which did not.","cats":{"data-quality":0}}
{"text":"Overall KiTS21 facilitated a significant advancement in the state of the art in kidney tumor segmentation, and provides useful insights that are applicable to the field of semantic segmentation as a whole.","cats":{"data-quality":0}}
{"text":"Additionally, label noise is inevitable in large-scale annotations and hinders the applications of learning-based models.","cats":{"data-quality":1}}
{"text":"To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of multi-label classification and long-tailed learning under noisy cases","cats":{"data-quality":1}}
{"text":"In detail, we propose a Stitch-Up augmentation to synthesize a cleaner sample, which directly reduces multi-label noise by stitching up multiple noisy training samples","cats":{"data-quality":1}}
{"text":"In real-world scenarios, collected and annotated data often exhibit the characteristics of multiple classes and long-tailed distribution.  ","cats":{"data-quality":0}}
{"text":"Although many deep learning based methods have been proposed for handling long-tailed multi-label recognition or label noise respectively, learning with noisy labels in long-tailed multi-label visual data has not been well-studied because of the complexity of long-tailed distribution entangled with multi-label correlation.","cats":{"data-quality":0}}
{"text":"To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of m by stitching up multiple noisy training samples.","cats":{"data-quality":0}}
{"text":"Equipped with Stitch-Up, a Heterogeneous Co-Learning framework is further designed to leverage the inconsistency between long-tailed and balamarks, named VOC-MLT-Noise and COCO-MLT-Noise, respectively.","cats":{"data-quality":0}}
{"text":"Extensive experiments are conducted to demonstrate the effectiveness of our proposed method.","cats":{"data-quality":0}}
{"text":"Compared to a variety of baselines, our method achieves superior results.","cats":{"data-quality":0}}
{"text":"Most of the existing methods adopt a coarse-grained fixed label assignment strategy and suffer from the inconsistency between the classification score and localization accuracy.","cats":{"data-quality":1}}
{"text":"Second, to further address the inconsistency between classification and localization, we propose a critical feature sampling (CFS) module, which performs localization refinement on the sampling location for classification task to extract critical features accurately","cats":{"data-quality":1}}
{"text":"Arbitrary-oriented object detection is a relatively emerging but challenging task.","cats":{"data-quality":0}}
{"text":"Although remarkable progress has been made, there still remain many unsolved issues due to the large diversity of patterns in orientation, scale, aspect ratio, and visual appearance of objects in aerial images.  ","cats":{"data-quality":0}}
{"text":"First, to align the metric inconsistency between sample selection and regression loss calculation caused by fixed IoU strategy, we introduce affine transformation to evaluate the quality of samples and propose a distance-based label assignment strategy.","cats":{"data-quality":0}}
{"text":"The proposed metric-aligned selection (MAS) strategy can dynamically select samples according to the shape and rotation characteristic of objects.","cats":{"data-quality":0}}
{"text":"Second, to further address the inconsistency between classification and localization, we propose a critical feature sampling (CFS) module, which performs localization refinementtics of proposals during training.","cats":{"data-quality":0}}
{"text":"Extensive experiments are conducted on four challenging rotated object detection datasets DOTA, FAIR1M-1.0, HRSC2016, and UCAS-AOD.","cats":{"data-quality":0}}
{"text":"The results show the state-of-the-art accuracy of the proposed detector.","cats":{"data-quality":0}}
{"text":"However, results from even highly accurate methods require manual verification and correction","cats":{"data-quality":1}}
{"text":"The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of cases.","cats":{"data-quality":1}}
{"text":"We learned that our automatic transcription is biased towards the most frequent codes, with a higher degree of misclassification for the lowest frequency codes","cats":{"data-quality":1}}
{"text":"Machine learning methods have proven useful in transcribing historical data. .","cats":{"data-quality":0}}
{"text":"Such manual review can be time-consuming and expensive, therefore the objective of this paper was to make it more efficient.","cats":{"data-quality":0}}
{"text":"Previously, we used machine learning to transcribe 2.3 million handwritten occupation codes from the Norwegian 1950 census with high accuracy (97%).","cats":{"data-quality":0}}
{"text":"We manually reviewed the 90,000 (3%) codes with the lowest model confidence.","cats":{"data-quality":0}}
{"text":"We allocated those 90,000 codes to human reviewers, who used our annotation tool to review the codes.","cats":{"data-quality":0}}
{"text":"To assess reviewer agreement, some codes were assigned to multiple reviewers.","cats":{"data-quality":0}}
{"text":"We then analyzed the review results to understand the relationship between accuracy improvements and effort.","cats":{"data-quality":0}}
{"text":"Additionally, we interviewed the reviewers to improve the workflow.","cats":{"data-quality":0}}
{"text":"The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of casescertain, or they assigned an invalid label.","cats":{"data-quality":0}}
{"text":"9,000 images were independently reviewed by multiplds the most frequent codes, with a higher degree of misclassification for the lowest frequency codes.","cats":{"data-quality":0}}
{"text":"Our interview findings show that the reviewers did internal quality control and found our custom tool well-suited.","cats":{"data-quality":0}}
{"text":"So, only one reviewer is needed, but they shou","cats":{"data-quality":0}}
{"text":" We advocate for the use of IAA in predicting the labeling quality of individual annotators, leading to cost and time efficiency in data production.","cats":{"data-quality":0}}
{"text":"Additionally, our work highlights the  IAA's broader application potential in data-driven research optimization and holds significant implications for large-scale data projects prioritizing efficiency, cost reduction, and high-quality data.","cats":{"data-quality":0}}
{"text":"We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information.","cats":{"data-quality":0}}
{"text":"Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process.","cats":{"data-quality":0}}
{"text":"The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training.","cats":{"data-quality":0}}
{"text":"Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts.","cats":{"data-quality":0}}
{"text":"The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data.","cats":{"data-quality":0}}
{"text":"Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling.","cats":{"data-quality":0}}
{"text":"The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task.","cats":{"data-quality":0}}
{"text":"Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data.","cats":{"data-quality":0}}
{"text":"Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations.","cats":{"data-quality":1}}
{"text":"Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data.","cats":{"data-quality":0}}
{"text":"The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations.","cats":{"data-quality":0}}
{"text":"These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL).  ","cats":{"data-quality":0}}
{"text":"Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels.","cats":{"data-quality":0}}
{"text":"In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner.","cats":{"data-quality":0}}
{"text":"Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75.","cats":{"data-quality":0}}
{"text":"Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications.","cats":{"data-quality":0}}
{"text":"This paper presents a large publicly available multi-center lumbar spine magnetic resonance imaging (MRI) dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal.","cats":{"data-quality":0}}
{"text":"The dataset includes 447 sagittal T1 and T2 MRI series from 218 patients with a history of low back pain.","cats":{"data-quality":0}}
{"text":"It was collected from four different hospitals and was divided into a training (179 patients) and validation (39 patients) set.","cats":{"data-quality":0}}
{"text":"An iterative data annotation approach was used by training a segmentation algorithm on a small part of the dataset, enabling semi-automatic segmentation of the remaining images.","cats":{"data-quality":0}}
{"text":"The algorithm provided an initial segmentation, which was subsequently reviewed, manually corrected, and added to the training data.","cats":{"data-quality":0}}
{"text":"We provide reference performance values for this baseline algorithm and nnU-Net, which performed comparably.","cats":{"data-quality":0}}
{"text":"We set up a continuous segmentation challenge to allow for a fair comparison of different segmentation algorithms.","cats":{"data-quality":0}}
{"text":"This study may encourage wider collaboration in the field of spine segmentation, and improve the diagnostic value of lumbar spine MRI.","cats":{"data-quality":0}}
{"text":"But meanwhile, the distributed and isolated nature of data isolation may be complicated by data quality, making it more vulnerable to noisy labels","cats":{"data-quality":1}}
{"text":"Many efforts exist to defend against the negative impacts of noisy labels in centralized or federated settings","cats":{"data-quality":1}}
{"text":"Also, we conduct comprehensive experiments to explore the characteristics of these data settings and unravel challenging scenarios on the federated noisy label learning, which may guide method development in the future.","cats":{"data-quality":0}}
{"text":"We highlight the 20 basic settings for more than 5 datasets proposed in our benchmark and standardized simulation pipeline for federated noisy label learning.","cats":{"data-quality":1}}
{"text":"Federated learning has gained popularity for distributed learning without aggregating sensitive data from clients. .","cats":{"data-quality":0}}
{"text":"Many efforts exist to defend against the negative impacts of noisy labels in centralized or federated settings.","cats":{"data-quality":0}}
{"text":"However, there is a lack of a benchis work, we serve the first standardized benchmark that can help researchers fully explore potential federated noisy settings.","cats":{"data-quality":0}}
{"text":"We highlight the 20 basic settings f \\texttt{FedNoisy} is available at \\codeword{https://github.com/SMILELab-FL/FedNoisy}.","cats":{"data-quality":0}}
{"text":"In this paper, we explore different ways of training a model for handwritten text recognition when multiple imperfect or noisy transcriptions are available","cats":{"data-quality":1}}
{"text":"We consider various training configurations, such as selecting a single transcription, retaining all transcriptions, or computing an aggregated transcription from all available annotations.","cats":{"data-quality":0}}
{"text":"In addition, we evaluate the impact of quality-based data selection, where samples with low agreement are removed from the training set.","cats":{"data-quality":0}}
{"text":"Our experiments are carried out on municipal registers of the city of Belfort (France) written between 1790 and 1946.","cats":{"data-quality":0}}
{"text":"% results The results show that computing a consensus transcription or training on multiple transcriptions are good alternatives.","cats":{"data-quality":0}}
{"text":"However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the res","cats":{"data-quality":0}}
{"text":"The aim of the experiment is to judge the final annotation quality when pre-annotation is used.","cats":{"data-quality":1}}
{"text":"In addition, it evaluates the effect of automatic linguistically-based (rule-formulated) checks and another annotation on the same data available to the annotators, and their influence on annotation quality and efficiency.","cats":{"data-quality":1}}
{"text":"This paper presents an analysis of annotation using an automatic pre-annotation for a mid-level annotation complexity task -- dependency syntax annotation.","cats":{"data-quality":0}}
{"text":"It compares the annotation efforts made by annotators using a pre-annotated version (with a high-accuracy parser) and those made by fully manual annotation.  ","cats":{"data-quality":0}}
{"text":"In addition, it evaluates the effect of automatic linguistically-based (rule-formulated) checkstic annotation which increases the consistency of the resulting annotation without reducing its quality.","cats":{"data-quality":0}}
{"text":"SLPerf can facilitate SL algorithm development and fair performance comparisons.","cats":{"dev-research":0}}
{"text":"Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.","cats":{"dev-research":1}}
{"text":"In addition, we develop a feature-strengthened modularized unit to further boost the reconstruction performance.","cats":{"dev-research":0}}
{"text":"So far, several studies have been performed to develop robust hate speech detection systems.","cats":{"dev-research":0}}
{"text":"The key challenges in developing GDBs are achieving high performance, scalability, programmability, and portability.","cats":{"dev-research":0}}
{"text":"Extensive simulation studies are conducted to assess the finite sample performance of our developed methods.","cats":{"dev-research":0}}
{"text":"Motivated by the performance of each RNNs, a meta-model is developed to improve the overall recognition performance by combining the predictions of the individual RNNs.","cats":{"dev-research":0,"ml-security":0}}
{"text":"However, so far, the focus of developing drift detectors is on detection quality, e.g.~accuracy, but not on computational performance, such as running time.","cats":{"dev-research":0}}
{"text":"We developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures.","cats":{"dev-research":0}}
{"text":"Therefore, improving the development process indirectly improves the software product, too.","cats":{"dev-research":1}}
{"text":"Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.","cats":{"dev-research":1}}
{"text":"By aligning the reasoning of automated debugging more closely with that of human developers, we aim to produce intelligible explanations of how a specific patch has been generated, with the hope that the explanation will lead to more efficient and accurate developer decisions.","cats":{"dev-research":1}}
{"text":"This often makes it difficult to achieve good results in practice.","cats":{"dev-research":0}}
{"text":"We start with the intuition that developers tend to consciously and unconsciously have a collection of semantics facts in mind when working on coding tasks.","cats":{"dev-research":1}}
{"text":"Fourth, as programmable networks and machine learning (ML) techniques are increasingly becoming adopted by the community, their current applications in network security are discussed.","cats":{"ml-security":0}}
{"text":"Especially when both the ML model and the input data's confidentiality must be protected.","cats":{"ml-security":1}}
{"text":"We can expect such systems to be vulnerable to some adversarial-ML attacks.","cats":{"ml-security":1}}
{"text":"Traditional adversarial training is a popular methodology for robustifying ML models against attacks.","cats":{"ml-security":0}}
{"text":"The remarkable success of the use of machine learning-based solutions for network security problems has been impeded by the developed ML models' inability to maintain efficacy when used in different network environments exhibiting different network behaviors.","cats":{"ml-security":1}}
{"text":"Machine learning (ML) models can leak information about users, and differential privacy (DP) provides a rigorous way to bound that leakage under a given budget.","cats":{"ml-security":1}}
{"text":"However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model.","cats":{"ml-security":1}}
{"text":"However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements.","cats":{"ml-security":0}}
{"text":"We analyze the root causes of potentially-increased attack surface in learned systems and develop a framework for identifying vulnerabilities that stem from the use of ML.","cats":{"ml-security":1}}
{"text":"Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences.","cats":{"ml-security":1}}
{"text":"Backdoor attacks have been demonstrated as a security threat for machine learning models.","cats":{"ml-security":1}}
{"text":"However, if the privacy of machine learning applications' customers cannot be guaranteed, it will cause security threats and losses to users' personal privacy information and service providers.","cats":{"ml-security":1}}
{"text":"In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.","cats":{"ml-security":0}}
{"text":"Our model offers two key advantages: semantic-awareness and granularity-abundance.","cats":{"ml-security":0}}
{"text":"To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts.","cats":{"ml-security":0}}
{"text":"This allows our model to capture rich semantic information.","cats":{"ml-security":0}}
{"text":"For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks.","cats":{"ml-security":0}}
{"text":"Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets.","cats":{"ml-security":0}}
{"text":"Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance.","cats":{"ml-security":0}}
{"text":"Furthermore, combining SA-1B training with other segmentation tasks, such as panoptic and part segmentation, leads to performance improvements.","cats":{"ml-security":0}}
{"text":"We will provide code and a demo for further exploration and evaluation.","cats":{"ml-security":0}}
{"text":"We propose a self-supervised method for learning representations based on spatial audio-visual correspondences in egocentric videos.","cats":{"ml-security":0}}
{"text":"In particular, our method leverages a masked auto-encoding framework to synthesize masked binaural audio through the synergy of audio and vision, thereby learning useful spatial relationships between the two modalities.","cats":{"ml-security":0}}
{"text":"We use our pretrained features to tackle two downstream video tasks requiring spatial understanding in social scenarios: active speaker detection and spatial audio denoising.","cats":{"ml-security":0}}
{"text":"We show through extensive experiments that our features are generic enough to improve over multiple state-of-the-art baselines on two public challenging egocentric video datasets, EgoCom and EasyCom.","cats":{"ml-security":0}}
{"text":"Project: http://vision.cs.utexas.edu/projects/ego_av_corr.","cats":{"ml-security":0}}
{"text":"One of the fundamental steps toward understanding a complex system is identifying variation at the scale of the system's components that is most relevant to behavior on a macroscopic scale.","cats":{"ml-security":0}}
{"text":"Mutual information is a natural means of linking variation across scales of a system due to its independence of the particular functional relationship between variables.","cats":{"ml-security":0}}
{"text":"However, estimating mutual information given high-dimensional, continuous-valued data is notoriously difficult, and the desideratum -- to reveal important variation in a comprehensible manner -- is only readily achieved through exhaustive search.","cats":{"ml-security":0}}
{"text":"Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score.","cats":{"ml-security":0}}
{"text":"Code and pre-trained weights will be publicly available at https://animatediff.github.io/ .","cats":{"ml-security":0}}
{"text":"While difficult to deploy today for real systems due to latency, context size limitations, and compute costs, the approach of using LLMs to drive low-level control may provide an exciting glimpse into how the patterns among words could be transferred to actions.","cats":{"ml-security":0}}
{"text":"In particular, we focus on the scalar curvature, which can be computed analytically for our manifold, and show connections to several settings that potentially imply generalization.","cats":{"ml-security":0}}
{"text":"To the best of our knowledge, such support does not exist.","cats":{"ml-security":0}}
{"text":"To serve the intricate and varied demands of image editing, precise and flexible manipulation of image content is indispensable.","cats":{"ml-security":0}}
{"text":"In this paper, we provide a novel framework for the analysis of generalization error of first-order optimization algorithms for statistical learning when the gradient can only be accessed through partial observations given by an oracle.","cats":{"ml-security":0}}
{"text":"Then, a specific trustworthiness model and its attributes, namely data robustness, parameter sensitivity, and security covering adversarial examples, are introduced.","cats":{"ml-security":1}}
{"text":"Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level.","cats":{"ml-security":0}}
{"text":"In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process.","cats":{"ml-security":0}}
{"text":"This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations.","cats":{"ml-security":0}}
{"text":"We use Meta's Ad Library to collect 602,546 ads that have been issued by US Congress members since mid-2018.","cats":{"ml-security":0}}
{"text":"We release the BigTrans model and hope it can advance the research progress.","cats":{"ml-security":0}}
{"text":"When the measurement delay exceeds the permissible number, the packet dropout happens.","cats":{"ml-security":0}}
{"text":"To testify the effectiveness and superiority of the proposed approach, we conduct extensive experiments on benchmark datasets.","cats":{"ml-security":0}}
{"text":"Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security).","cats":{"ml-security":0}}
{"text":"The LaSSIM metric does not require clean reference images and has been shown to be superior to SSIM in capturing image structural changes under image degradations, such as strong blurring on different datasets.","cats":{"ml-security":0}}
{"text":"It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically.","cats":{"ml-security":0}}
{"text":"Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values.","cats":{"ml-security":0}}
{"text":"The proposed method inserts pilot sequences in the zero bins of the ZP-OTFS system, resulting in low overhead and PAPR.","cats":{"ml-security":0}}
{"text":"Our work is a step towards understanding how simple geometrically-local error-correction strategies can protect information encoded into complex noisy systems, such as topological quantum error-correcting codes.","cats":{"ml-security":0}}
{"text":"In the case of two multivariate normal classes with a common covariance matrix, they showed that the error rate of the estimated Bayes' rule formed by this SSL approach can actually have lower error rate than the one that could be formed from a completely classified sample.","cats":{"ml-security":0}}
{"text":"However, previous studies seldom take advantage of such brain anatomy prior.","cats":{"ml-security":0}}
{"text":"Moreover, they require hundreds of gigabytes of training data.","cats":{"ml-security":0}}
{"text":"Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system.","cats":{"ml-security":0}}
{"text":"Self-training is a simple yet effective method within semi-supervised learning.","cats":{"ml-security":0}}
{"text":"For the information leakage caused by the attack during the information transmission process, privacy-preservation is introduced for system states.","cats":{"ml-security":1}}
{"text":"Most existing systems that conceal leakage either (1) incur substantial overheads, (2) focus on specific subsets of leakage patterns, or (3) apply the same security notion across various workloads, thereby impeding the attainment of fine-tuned privacy-efficiency trade-offs.","cats":{"ml-security":1}}
{"text":"Numerous studies have underscored the significant privacy risks associated with various leakage patterns in encrypted data stores.","cats":{"ml-security":1}}
{"text":"In our daily life, mobile phone applications and identity documents that we use may bring the risk of privacy leakage, which had increasingly aroused public concern.","cats":{"ml-security":1}}
{"text":"Overall, our approach to privacy unifies, formalizes, and explains many existing ideas, e.g., why the informed adversary assumption may lead to underestimating the information leaking about each entry in the database.","cats":{"ml-security":0}}
{"text":"Our findings can provide valuable insights into the evolving field of non-standard and covert channels, and help spur new countermeasures against such privacy leakage and security issues.","cats":{"ml-security":0}}
{"text":"Classifiers based on deep neural networks have been recently challenged by Adversarial Attack, where the widely existing vulnerability has invoked the research in defending them from potential threats.","cats":{"ml-security":1}}
{"text":"Adversarial attacks are a serious threat to the reliable deployment of machine learning models in safety-critical applications.","cats":{"ml-security":1}}
{"text":"The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications.","cats":{"ml-security":1}}
{"text":"Machine-learning architectures, such as Convolutional Neural Networks (CNNs) are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label.","cats":{"ml-security":1}}
{"text":"Many research works developed certain techniques to generate adversarial samples to help the machine learning models obtain the ability to recognize those perturbations.","cats":{"ml-security":1}}
{"text":"Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input.","cats":{"ml-security":1}}
{"text":"Given a vulnerable classifier, existing defense methods are mostly white-box and often require re-training the victim under modified loss functions/training regimes.","cats":{"ml-security":1}}
{"text":"Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners.","cats":{"ml-security":1}}
{"text":"With the wide-spread application of machine learning models, it has become critical to study the potential data leakage of models trained on sensitive data.","cats":{"ml-security":1}}
{"text":"The results show that the centralized machine learning model shows more serious member information leakage in all aspects, and the accuracy of the attacker in the central parameter server is significantly higher than the local Inference attacks as participants.","cats":{"ml-security":1}}
{"text":"Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applications.","cats":{"ml-security":1}}
{"text":"Recently, however, there has been a trend towards evaluating the robustness of these models against adversarial attacks.","cats":{"ml-security":1}}
{"text":"As in-the-wild data are increasingly involved in the training stage, machine learning applications become more susceptible to data poisoning attacks.","cats":{"ml-security":1}}
{"text":"In this paper, we investigate the third type of exploitation of data poisoning - increasing the risks of privacy leakage of benign training samples.","cats":{"ml-security":1}}
{"text":"To this end, we demonstrate a set of data poisoning attacks to amplify the membership exposure of the targeted class.","cats":{"ml-security":1}}
{"text":"Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage.","cats":{"ml-security":1}}
{"text":"These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks.","cats":{"ml-security":1}}
{"text":"We then propose an optimization-based clean-label attack in the transfer learning scenario, whereby the poisoning samples are correctly labeled and look \"natural\" to evade human moderation.","cats":{"ml-security":1}}
{"text":"To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge.","cats":{"ml-security":1}}
{"text":"Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products.","cats":{"ml-security":1}}
{"text":"We introduce ShortcutGen, a new data poisoning attack that generates sample-dependent, error-minimizing perturbations by learning a generator.","cats":{"ml-security":1}}
{"text":"Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small.","cats":{"ml-security":1}}
{"text":"We thus formulate such a privacy defense as an adversarial learning problem, where RecUP-FL generates slight perturbations that can be added to the gradients before sharing to fool adversary models.","cats":{"ml-security":1}}
{"text":"We test the performance of the considered attack strategies on an experimental dataset.","cats":{"ml-security":1}}
{"text":"A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks.","cats":{"ml-security":1}}
{"text":"We then propose the first learning-based prompt stealing attack, PromptStealer, and demonstrate its superiority over two baseline methods quantitatively and qualitatively.","cats":{"ml-security":1}}
{"text":"Adversarial attacks have the potential to mislead deep neural network classifiers by introducing slight perturbations.","cats":{"ml-security":1}}
{"text":"Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models.","cats":{"ml-security":1}}
{"text":"After the evaluation, we found that transfer learning is a good technique that allows better performance when working with a small data set.","cats":{"ml-security":0}}
{"text":"Moreover, the fairest classifier was found to be accomplished using transfer learning, threshold change, re-weighting and image augmentation as bias mitigation methods.","cats":{"ml-security":0}}
{"text":"It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.   ","cats":{"ml-security":0}}
{"text":"Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods.","cats":{"ml-security":0}}
{"text":"These results demonstrate that our trained model can successfully reproduce the classification labels derived from detailed SED analysis.","cats":{"ml-security":0}}
{"text":"In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks.","cats":{"ml-security":0}}
{"text":"Decoupling these two tasks enables training of the \"speaking\" module using abundant audio-only data, and unlocks the highly efficient combination of pretraining and backtranslation to reduce the need for parallel data when training the \"reading\" component.","cats":{"ml-security":0}}
{"text":"Interestingly, we observe that clinical text information annotated by radiologists provides us with discriminative knowledge to identify challenging samples.","cats":{"ml-security":0}}
{"text":"Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\".","cats":{"ml-security":0}}
{"text":"Our code is available at \\url{https://github.com/nkdinsdale/SFHarmony}.","cats":{"ml-security":0}}
{"text":"In online advertising systems, although there are millions to billions of ads, users tend to click only a small set of them and to convert on an even smaller set.","cats":{"ml-security":0}}
{"text":"Membership inference (MI) attacks threaten user privacy through determining if a given data example has been used to train a target model.","cats":{"ml-security":1}}
{"text":"In this paper, we seek to develop a comprehensive benchmark for comparing different MI attacks, called MIBench, which consists not only the evaluation metrics, but also the evaluation scenarios","cats":{"ml-security":1}}
{"text":" However, it has been increasingly recognized that the \"comparing different MI attacks\" methodology used in the existing works has serious limitations.","cats":{"ml-security":0}}
{"text":"Due to these limitations, we found (through the experiments in this work) that some comparison results reported in the literature are quite misleading.","cats":{"ml-security":0}}
{"text":"In this paper, we seek to develop a comprehensive benchmark for comparing different MI attacks, called MIBench, which consists not only thance between data samples of the target dataset, the differential distance between two datasets (i.e., the target dataset and a generated dataset with only nonmembers), and the ratio of the samples that are made no inferences by an MI attack.","cats":{"ml-security":0}}
{"text":"The evaluation metrics consist of ten typical evaluation metrics.","cats":{"ml-security":0}}
{"text":"We have identified three principles for the proposed \"comparing different MI attacks\" methodology, and we have designed and implemented the MIBench benchmark with 84 evaluation scenarios for each dataset.","cats":{"ml-security":0}}
{"text":"In total, we have used our benchmark to fairly and systematically compare 15 state-of-the-art MI attack algorithms across 588 evaluation scenarios, and these evaluation scenarios cover 7 widely used datasets and 7 representative types of models.","cats":{"ml-security":0}}
{"text":"All codes and evaluations of MIBench are publicly available at https://github.com/MIBench/MIBench.github.io/blob/main/README.md.","cats":{"ml-security":0}}
{"text":" The proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining ive metrics.","cats":{"ml-security":0}}
{"text":"Additionally, our detection method can be i","cats":{"ml-security":0}}
{"text":"We study how to mitigate the effects of energy attacks in the batteryless Internet of Things (IoT).","cats":{"ml-security":1}}
{"text":"We design, implement, and evaluate a mitigation system for energy attacks.","cats":{"ml-security":0}}
{"text":" Battery-less IoT devices live and die with ambient energy, as they use energy harvesting to power their operation.","cats":{"ml-security":0}}
{"text":"They are employed in a multitude of applications, including safety-critical ones such as biomedical implants.","cats":{"ml-security":0}}
{"text":"Due to scarce energy intakes and limited energy buffers, their executions become intermittent, alternating periods of active operation with periods of recharging their energy buffers.","cats":{"ml-security":0}}
{"text":"Experimental evidence exists that shows how controlling ambient energy allows an attacker to steer a device execution in unintended ways: energy provisioning effectively becomes an attack vector.","cats":{"ml-security":0}}
{"text":"By taking into account t module, we tune task execution rates and optimize energy management.","cats":{"ml-security":0}}
{"text":"This ensures continued application execution in the event of an energy attack.","cats":{"ml-security":0}}
{"text":"When a device is under attack, our solution ensures the execution of 23.3% additional application cycles compared to the baselines we consider and increases task schedulability by at least 21%, while enabling a 34% higher peripheral availability.","cats":{"ml-security":0}}
{"text":"The architecture can naturally be exploited in privacy-sensitive situations such as surveillance and health, where personally identifiable information cannot be released.","cats":{"ml-security":1}}
{"text":"Predicting where a person is looking is a complex task, requiring to understand not only the person's gaze and scene content, but also the 3D scene structure and the person's situation (are they manipulating?","cats":{"ml-security":0}}
{"text":"interacting or observing others?","cats":{"ml-security":0}}
{"text":"attentive?) to detect obstructions in the line of sight or apply attention priors that humans typically have when observing others.","cats":{"ml-security":0}}
{"text":"In this paper, we hypothesize that identifying and leveraging such priors can be better achieved through the exploitation of explicitly derived multimodal cues such as depth and pose.","cats":{"ml-security":0}}
{"text":"We thus propose a modular multimodal architecture allowing to combine these cues using an attention mechanism.  ","cats":{"ml-security":0}}
{"text":"We perform extensive experiments on the GazeFollow and VideoAttentionTarget public datasets, obtaining state-of-the-art performance and demonstrating very competitive results in the privacy setting case.","cats":{"ml-security":0}}
{"text":"This paper extends and advances our recently introduced two-factor Honeytoken authentication method by incorporating blockchain technology.","cats":{"ml-security":0}}
{"text":"This novel approach strengthens the authentication method to prevent many attacks including tampering attacks.","cats":{"ml-security":0}}
{"text":"Evaluation results show that integrating blockchain into the Honeytoken method could improve performance and operational efficiency.","cats":{"ml-security":0}}
{"text":"Moreover, the Butterfly Effect can amplify inherent biases within data or algorithms, exacerbate feedback loops, and create vulnerabilities for adversarial attacks.","cats":{"ml-security":1}}
{"text":"In this paper, we envision both algorithmic and empirical strategies to detect, quantify, and mitigate the Butterfly Effect in AI systems, emphasizing the importance of addressing these challenges to promote fairness and ensure responsible AI development","cats":{"ml-security":1}}
{"text":"The Butterfly Effect, a concept originating from chaos theory, underscores how small changes can have significant and unpredictable impacts on complex systems.","cats":{"ml-security":0}}
{"text":"In the context of AI fairness and bias, the Butterfly Effect can stem from a variety of sources, such as small biases or skewed data inputs during algorithm development, saddle points in training, or distribution shifts in data between training and testing phases.","cats":{"ml-security":0}}
{"text":"These seemingly minor alterations can lead to unexpected and substantial unfair outcomes, disproportionately affecting underrepresented individuals or groups and perpetuating pre-existing inequalities.  ","cats":{"ml-security":0}}
{"text":"Given the intricate nature of AI systems and their societal implications, it is crucial to thoroughly examine any changes to algorithms or input data for potential unintended consequences.","cats":{"ml-security":0}}
{"text":"In this paper, we envision both algorithmic and empirical strategies to detect, quantify, and mitigate the Butterfly Effect in AI systems, emphasizing the importanc","cats":{"ml-security":0}}
{"text":"Artificial intelligence (AI) is considered an efficient response to several challenges facing 6G technology.","cats":{"ml-security":0}}
{"text":"However, AI still suffers from a huge trust issue due to its ambiguous way of making predictions.","cats":{"ml-security":0}}
{"text":"Therefore, there is a need for a method to evaluate the AI's trustworthiness in practice for future 6G applications.","cats":{"ml-security":0}}
{"text":"This paper presents a practical model to analyze the trustworthiness of AI in a dedicated 6G application.","cats":{"ml-security":0}}
{"text":"In particular, we present two customized Deep Neural Networks (DNNs) to solve the Automatic Modulation Recognition (AMR) problem in Terahertz communications-based 6G technology.  ","cats":{"ml-security":0}}
{"text":"The evaluation results indicate that the proposed trustworthiness attributes are crucial to evaluate the trustworthiness of DNN for this 6G application.","cats":{"ml-security":0}}
{"text":"Automatic metrics play a crucial role in machine translation.","cats":{"ml-security":0}}
{"text":"Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics.","cats":{"ml-security":0}}
{"text":"However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect.","cats":{"ml-security":0}}
{"text":"In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems.","cats":{"ml-security":0}}
{"text":"Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore.","cats":{"ml-security":0}}
{"text":"In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm.","cats":{"ml-security":0}}
{"text":"By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems.","cats":{"ml-security":0}}
{"text":"Codes are available at \\url{https://github.com/powerpuffpomelo/fairseq_mrt}.","cats":{"ml-security":0}}
{"text":"However, concerns have arisen regarding the unauthorized usage of data during the training process.","cats":{"ml-security":1}}
{"text":"In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset.","cats":{"ml-security":1}}
{"text":"By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data.","cats":{"ml-security":0}}
{"text":"Recent text-to-image diffusion models have shown surprising performance in generating high-quality images.  ","cats":{"ml-security":0}}
{"text":"One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist.","cats":{"ml-security":0}}
{"text":"To address this issue, it becomes crucial to detect unauthorized data usage.","cats":{"ml-security":0}}
{"text":"In this paper, we propose a method for detecting such unauthorized data usage by planting injected s stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models.","cats":{"ml-security":0}}
{"text":"Our experiments conducted on Stable Diffusion an","cats":{"ml-security":0}}
{"text":"We then show that such probabilistic descriptions can be used to construct defences against adversarial attacks.","cats":{"ml-security":1}}
{"text":"This paper begins with a description of methods for estimating probability density functions for images that reflects the observation that such data is usually constrained to lie in restricted regions of the high-dimensional image space - not every pattern of pixels is an image.","cats":{"ml-security":0}}
{"text":"It is common to say that images lie on a lower-dimensional manifold in the high-dimensional space.","cats":{"ml-security":0}}
{"text":"However, although images may lie on such lower-dimensional manifolds, it is not the case that all points on the manifold have an equal probability of being images.","cats":{"ml-security":0}}
{"text":"Images are unevenly distributed on the manifold, and our task is to devise ways to model this distribution as a probability distribution.","cats":{"ml-security":0}}
{"text":"In pursuing this goal, we consider generative models that are popular in AI and computer vision community.","cats":{"ml-security":0}}
{"text":"For our purposes, generative/probabilistic models should have the properties of 1) sample generation: it should be possible to sample from this distribution according to the modelled density function, and 2) probability computation: given a previously unseen sample from the dataset of interest, one should be able to compute the probability of the sample, at least up to a normalising constant.","cats":{"ml-security":0}}
{"text":"To this end, we investigate the use of methods such as normalising flow and diffusion models.  ","cats":{"ml-security":0}}
{"text":"In addition to describing the manifold in terms of density, we also consider how semantic interpretations can be used to describe points on the manifold.","cats":{"ml-security":0}}
{"text":"To this end, we consider an emergent language framework which makes use of variational encoders to produce a disentangled representation of points that reside on a given manifold.","cats":{"ml-security":0}}
{"text":"Trajectories between points on a manifold can then be described in terms of evolving semantic descriptions.","cats":{"ml-security":0}}
{"text":"Face presentation attacks, also known as spoofing attacks, pose a significant threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems.","cats":{"ml-security":1}}
{"text":"In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism","cats":{"ml-security":1}}
{"text":" To prevent spoofing, several video-based methods have been presented in the literature that analyze facial motion in successive video frames.","cats":{"ml-security":0}}
{"text":"However, estimating the motion between adjacent frames is a challenging task and requires high computational cost.","cats":{"ml-security":0}}
{"text":"In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism.","cats":{"ml-security":0}}
{"text":"The proposed frame skipping is based on a uniform sampling apprasily be perceived during the training of three different recurrent neural networks (RNNs).","cats":{"ml-security":0}}
{"text":"Extensive experiments were conducted on four datasets, and state-of-the-art performance is reported for MSU-MFSD (3.12\\%), Replay-Attack (11.19\\%), and OULU-NPU (12.23\\%) using half total error rate (HTER) in the most challenging cross-dataset test scenario.","cats":{"ml-security":0}}
{"text":"Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow.","cats":{"ml-security":0}}
{"text":"Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more.","cats":{"ml-security":0}}
{"text":"Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge.","cats":{"ml-security":0}}
{"text":"We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI.","cats":{"ml-security":0}}
{"text":"This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency.","cats":{"ml-security":0}}
{"text":"By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models.","cats":{"ml-security":0}}
{"text":"Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence.","cats":{"ml-security":0}}
{"text":"Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI.","cats":{"ml-security":0}}
{"text":"The introduction of vulnerability detection enables reducing the number of false alerts to focus the limited testing efforts on potentially vulnerable files.","cats":{"ml-security":1}}
{"text":"In Software Development Life Cycle (SDLC), security vulnerabilities are one of the points introduced during the construction stage.","cats":{"ml-security":0}}
{"text":"Failure to detect software defects earlier after releasing the product to the market causes higher repair costs for the company.","cats":{"ml-security":0}}
{"text":"So, it decreases the company's reputation, violates user privacy, and causes an unrepairable issue for the application.  ","cats":{"ml-security":0}}
{"text":"UMKM Masa Kini (UMI) is a Point of Sales application to sell any Micro, Small, and Medium Enterprises Product (UMKM).","cats":{"ml-security":0}}
{"text":"Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applica","cats":{"ml-security":0}}
{"text":"Background: Despite the widespread use of automated security defect detection tools, software projects still contain many security defects that could result in serious damage.","cats":{"ml-security":1}}
{"text":"Such tools are largely context-insensitive and may not cover all possible scenarios in testing potential issues, which makes them susceptible to missing complex security defects.","cats":{"ml-security":0}}
{"text":"Hence, thorough detection entails a synergistic cooperation between these tools and human-intensive detection techniques, including code review.","cats":{"ml-security":0}}
{"text":"Code review is widely recognized as a crucial and effective practice for identifying security defects.","cats":{"ml-security":0}}
{"text":"Aim: This work aims to empirically investigate security defect detection through code review.","cats":{"ml-security":0}}
{"text":"Method: To this end, we conducted an empirical study by analyzing code review comments derived from four projects in the OpenStack and Qt communities.","cats":{"ml-security":0}}
{"text":"Through manually checking 20,995 review comments obtained by keyword-based search, we identified 614 comments as security-related.","cats":{"ml-security":0}}
{"text":"Results:","cats":{"ml-security":0}}
{"text":"Our results show that (1) security defects are not prevalently discussed in code review, (2) more than half of the reviewers provided explicit fixing strategies/solutions to help developers fix security defects, (3) developers tend to follow reviewers' suggestions and action the changes, (4) Not worth fixing the defect now and Disagreement between the developer and the reviewer are the main causes for not resolving security defects.","cats":{"ml-security":0}}
{"text":"Conclusions: Our research results demonstrate that (1) software security practices should combine manual code review with automated detection tools, achieving a more comprehensive coverage to identifying and addressing security defects, and (2) promoting appropriate standardization of practitioners' behaviors during code review remains necessary for enhancing software security.","cats":{"ml-security":0}}
{"text":"This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing","cats":{"ml-security":1}}
{"text":"Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space.   ","cats":{"ml-security":0}}
{"text":"The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation, and signal communication.   ","cats":{"ml-security":0}}
{"text":"However, little concern has been devoted to their robustness during practical deployment.   ","cats":{"ml-security":0}}
{"text":"Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent.   .   ","cats":{"ml-security":0}}
{"text":"In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space.   ","cats":{"ml-security":0}}
{"text":"We also evaluate the difference between variational autoencoders anoff between the adversarial robustness and the degree of the disentanglement of the latent codes.   ","cats":{"ml-security":0}}
{"text":"Additionally, we also verify the feasibility of improvement for the latent robustness of VAEs through adversarial training.   ","cats":{"ml-security":0}}
{"text":"In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges.","cats":{"ml-security":0}}
{"text":"A major security threat to an integrated circuit (IC) design is the Hardware Trojan attack which is a malicious modification of the design.","cats":{"ml-security":0}}
{"text":"Previously several papers have investigated into side-channel analysis to detect the presence of Hardware Trojans.","cats":{"ml-security":0}}
{"text":"The side channel analysis were prescribed in these papers as an alternative to the conventional logic testing for detecting malicious modification in the design.","cats":{"ml-security":0}}
{"text":"It has been found that these conventional logic testing are ineffective when it comes to detecting small Trojans due to decrease in the sensitivity due to process variations encountered in the manufacturing techniques.","cats":{"ml-security":0}}
{"text":"The main paper under consideration in this survey report focuses on proposing a new technique to detect Trojans by using multiple-parameter side-channel analysis.","cats":{"ml-security":0}}
{"text":"The novel idea will be explained thoroughly in this survey report.","cats":{"ml-security":0}}
{"text":"We also look into several other papers, which talk about single parameter analysis and how they are implemented.","cats":{"ml-security":0}}
{"text":"We analyzed the short comings of those single parameter analysis techniques and we then show how this multi-parameter analysis technique is better.","cats":{"ml-security":0}}
{"text":"Finally we will talk about the combined side-channel analysis and logic testing approach in which there is higher detection coverage for hardware Trojan circuits of different types and sizes.","cats":{"ml-security":0}}
