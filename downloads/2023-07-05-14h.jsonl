{"created":"2023-07-03 17:59:45","title":"Real-time Monocular Full-body Capture in World Space via Sequential Proxy-to-Motion Learning","abstract":"Learning-based approaches to monocular motion capture have recently shown promising results by learning to regress in a data-driven manner. However, due to the challenges in data collection and network designs, it remains challenging for existing solutions to achieve real-time full-body capture while being accurate in world space. In this work, we contribute a sequential proxy-to-motion learning scheme together with a proxy dataset of 2D skeleton sequences and 3D rotational motions in world space. Such proxy data enables us to build a learning-based network with accurate full-body supervision while also mitigating the generalization issues. For more accurate and physically plausible predictions, a contact-aware neural motion descent module is proposed in our network so that it can be aware of foot-ground contact and motion misalignment with the proxy observations. Additionally, we share the body-hand context information in our network for more compatible wrist poses recovery with the full-body model. With the proposed learning-based solution, we demonstrate the first real-time monocular full-body capture system with plausible foot-ground contact in world space. More video results can be found at our project page: https://liuyebin.com/proxycap.","sentences":["Learning-based approaches to monocular motion capture have recently shown promising results by learning to regress in a data-driven manner.","However, due to the challenges in data collection and network designs, it remains challenging for existing solutions to achieve real-time full-body capture while being accurate in world space.","In this work, we contribute a sequential proxy-to-motion learning scheme together with a proxy dataset of 2D skeleton sequences and 3D rotational motions in world space.","Such proxy data enables us to build a learning-based network with accurate full-body supervision while also mitigating the generalization issues.","For more accurate and physically plausible predictions, a contact-aware neural motion descent module is proposed in our network so that it can be aware of foot-ground contact and motion misalignment with the proxy observations.","Additionally, we share the body-hand context information in our network for more compatible wrist poses recovery with the full-body model.","With the proposed learning-based solution, we demonstrate the first real-time monocular full-body capture system with plausible foot-ground contact in world space.","More video results can be found at our project page: https://liuyebin.com/proxycap."],"url":"http://arxiv.org/abs/2307.01200v1"}
{"created":"2023-07-03 17:59:20","title":"NeuBTF: Neural fields for BTF encoding and transfer","abstract":"Neural material representations are becoming a popular way to represent materials for rendering. They are more expressive than analytic models and occupy less memory than tabulated BTFs. However, existing neural materials are immutable, meaning that their output for a certain query of UVs, camera, and light vector is fixed once they are trained. While this is practical when there is no need to edit the material, it can become very limiting when the fragment of the material used for training is too small or not tileable, which frequently happens when the material has been captured with a gonioreflectometer. In this paper, we propose a novel neural material representation which jointly tackles the problems of BTF compression, tiling, and extrapolation. At test time, our method uses a guidance image as input to condition the neural BTF to the structural features of this input image. Then, the neural BTF can be queried as a regular BTF using UVs, camera, and light vectors. Every component in our framework is purposefully designed to maximize BTF encoding quality at minimal parameter count and computational complexity, achieving competitive compression rates compared with previous work. We demonstrate the results of our method on a variety of synthetic and captured materials, showing its generality and capacity to learn to represent many optical properties.","sentences":["Neural material representations are becoming a popular way to represent materials for rendering.","They are more expressive than analytic models and occupy less memory than tabulated BTFs.","However, existing neural materials are immutable, meaning that their output for a certain query of UVs, camera, and light vector is fixed once they are trained.","While this is practical when there is no need to edit the material, it can become very limiting when the fragment of the material used for training is too small or not tileable, which frequently happens when the material has been captured with a gonioreflectometer.","In this paper, we propose a novel neural material representation which jointly tackles the problems of BTF compression, tiling, and extrapolation.","At test time, our method uses a guidance image as input to condition the neural BTF to the structural features of this input image.","Then, the neural BTF can be queried as a regular BTF using UVs, camera, and light vectors.","Every component in our framework is purposefully designed to maximize BTF encoding quality at minimal parameter count and computational complexity, achieving competitive compression rates compared with previous work.","We demonstrate the results of our method on a variety of synthetic and captured materials, showing its generality and capacity to learn to represent many optical properties."],"url":"http://arxiv.org/abs/2307.01199v1"}
{"created":"2023-07-03 17:58:26","title":"Improved sampling via learned diffusions","abstract":"Recently, a series of papers proposed deep learning-based approaches to sample from unnormalized target densities using controlled diffusion processes. In this work, we identify these approaches as special cases of the Schr\\\"odinger bridge problem, seeking the most likely stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches.","sentences":["Recently, a series of papers proposed deep learning-based approaches to sample from unnormalized target densities using controlled diffusion processes.","In this work, we identify these approaches as special cases of the Schr\\\"odinger bridge problem, seeking the most likely stochastic evolution between a given prior distribution and the specified target.","We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes.","This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases.","At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse.","In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches."],"url":"http://arxiv.org/abs/2307.01198v1"}
{"created":"2023-07-03 17:58:01","title":"Segment Anything Meets Point Tracking","abstract":"The Segment Anything Model (SAM) has established itself as a powerful zero-shot image segmentation model, employing interactive prompts such as points to generate masks. This paper presents SAM-PT, a method extending SAM's capability to tracking and segmenting anything in dynamic videos. SAM-PT leverages robust and sparse point selection and propagation techniques for mask generation, demonstrating that a SAM-based segmentation tracker can yield strong zero-shot performance across popular video object segmentation benchmarks, including DAVIS, YouTube-VOS, and MOSE. Compared to traditional object-centric mask propagation strategies, we uniquely use point propagation to exploit local structure information that is agnostic to object semantics. We highlight the merits of point-based tracking through direct evaluation on the zero-shot open-world Unidentified Video Objects (UVO) benchmark. To further enhance our approach, we utilize K-Medoids clustering for point initialization and track both positive and negative points to clearly distinguish the target object. We also employ multiple mask decoding passes for mask refinement and devise a point re-initialization strategy to improve tracking accuracy. Our code integrates different point trackers and video segmentation benchmarks and will be released at https://github.com/SysCV/sam-pt.","sentences":["The Segment Anything Model (SAM) has established itself as a powerful zero-shot image segmentation model, employing interactive prompts such as points to generate masks.","This paper presents SAM-PT, a method extending SAM's capability to tracking and segmenting anything in dynamic videos.","SAM-PT leverages robust and sparse point selection and propagation techniques for mask generation, demonstrating that a SAM-based segmentation tracker can yield strong zero-shot performance across popular video object segmentation benchmarks, including DAVIS, YouTube-VOS, and MOSE.","Compared to traditional object-centric mask propagation strategies, we uniquely use point propagation to exploit local structure information that is agnostic to object semantics.","We highlight the merits of point-based tracking through direct evaluation on the zero-shot open-world Unidentified Video Objects (UVO) benchmark.","To further enhance our approach, we utilize K-Medoids clustering for point initialization and track both positive and negative points to clearly distinguish the target object.","We also employ multiple mask decoding passes for mask refinement and devise a point re-initialization strategy to improve tracking accuracy.","Our code integrates different point trackers and video segmentation benchmarks and will be released at https://github.com/SysCV/sam-pt."],"url":"http://arxiv.org/abs/2307.01197v1"}
{"created":"2023-07-03 17:54:40","title":"Squeezing Large-Scale Diffusion Models for Mobile","abstract":"The emergence of diffusion models has greatly broadened the scope of high-fidelity image synthesis, resulting in notable advancements in both practical implementation and academic research. With the active adoption of the model in various real-world applications, the need for on-device deployment has grown considerably. However, deploying large diffusion models such as Stable Diffusion with more than one billion parameters to mobile devices poses distinctive challenges due to the limited computational and memory resources, which may vary according to the device. In this paper, we present the challenges and solutions for deploying Stable Diffusion on mobile devices with TensorFlow Lite framework, which supports both iOS and Android devices. The resulting Mobile Stable Diffusion achieves the inference latency of smaller than 7 seconds for a 512x512 image generation on Android devices with mobile GPUs.","sentences":["The emergence of diffusion models has greatly broadened the scope of high-fidelity image synthesis, resulting in notable advancements in both practical implementation and academic research.","With the active adoption of the model in various real-world applications, the need for on-device deployment has grown considerably.","However, deploying large diffusion models such as Stable Diffusion with more than one billion parameters to mobile devices poses distinctive challenges due to the limited computational and memory resources, which may vary according to the device.","In this paper, we present the challenges and solutions for deploying Stable Diffusion on mobile devices with TensorFlow Lite framework, which supports both iOS and Android devices.","The resulting Mobile Stable Diffusion achieves the inference latency of smaller than 7 seconds for a 512x512 image generation on Android devices with mobile GPUs."],"url":"http://arxiv.org/abs/2307.01193v1"}
{"created":"2023-07-03 17:53:39","title":"Trainable Transformer in Transformer","abstract":"Recent works attribute the capability of in-context learning (ICL) in large pre-trained language models to implicitly simulating and fine-tuning an internal model (e.g., linear or 2-layer MLP) during inference. However, such constructions require large memory overhead, which makes simulation of more sophisticated internal models intractable. In this work, we propose an efficient construction, Transformer in Transformer (in short, TinT), that allows a transformer to simulate and fine-tune complex models internally during inference (e.g., pre-trained language models). In particular, we introduce innovative approximation techniques that allow a TinT model with less than 2 billion parameters to simulate and fine-tune a 125 million parameter transformer model within a single forward pass. TinT accommodates many common transformer variants and its design ideas also improve the efficiency of past instantiations of simple models inside transformers. We conduct end-to-end experiments to validate the internal fine-tuning procedure of TinT on various language modeling and downstream tasks. For example, even with a limited one-step budget, we observe TinT for a OPT-125M model improves performance by 4-16% absolute on average compared to OPT-125M. These findings suggest that large pre-trained language models are capable of performing intricate subroutines. To facilitate further work, a modular and extensible codebase for TinT is included.","sentences":["Recent works attribute the capability of in-context learning (ICL) in large pre-trained language models to implicitly simulating and fine-tuning an internal model (e.g., linear or 2-layer MLP) during inference.","However, such constructions require large memory overhead, which makes simulation of more sophisticated internal models intractable.","In this work, we propose an efficient construction, Transformer in Transformer (in short, TinT), that allows a transformer to simulate and fine-tune complex models internally during inference (e.g., pre-trained language models).","In particular, we introduce innovative approximation techniques that allow a TinT model with less than 2 billion parameters to simulate and fine-tune a 125 million parameter transformer model within a single forward pass.","TinT accommodates many common transformer variants and its design ideas also improve the efficiency of past instantiations of simple models inside transformers.","We conduct end-to-end experiments to validate the internal fine-tuning procedure of TinT on various language modeling and downstream tasks.","For example, even with a limited one-step budget, we observe TinT for a OPT-125M model improves performance by 4-16% absolute on average compared to OPT-125M. These findings suggest that large pre-trained language models are capable of performing intricate subroutines.","To facilitate further work, a modular and extensible codebase for TinT is included."],"url":"http://arxiv.org/abs/2307.01189v1"}
{"created":"2023-07-03 17:52:44","title":"SAMAug: Point Prompt Augmentation for Segment Anything Model","abstract":"This paper introduces SAMAug, a novel visual point augmentation method for the Segment Anything Model (SAM) that enhances interactive image segmentation performance. SAMAug generates augmented point prompts to provide more information to SAM. From the initial point prompt, SAM produces the initial mask, which is then fed into our proposed SAMAug to generate augmented point prompts. By incorporating these extra points, SAM can generate augmented segmentation masks based on the augmented point prompts and the initial prompt, resulting in improved segmentation performance. We evaluate four point augmentation techniques: random selection, maximum difference entropy, maximum distance, and a saliency model. Experiments on the COCO, Fundus, and Chest X-ray datasets demonstrate that SAMAug can boost SAM's segmentation results, especially using the maximum distance and saliency model methods. SAMAug underscores the potential of visual prompt engineering to advance interactive computer vision models.","sentences":["This paper introduces SAMAug, a novel visual point augmentation method for the Segment Anything Model (SAM) that enhances interactive image segmentation performance.","SAMAug generates augmented point prompts to provide more information to SAM.","From the initial point prompt, SAM produces the initial mask, which is then fed into our proposed SAMAug to generate augmented point prompts.","By incorporating these extra points, SAM can generate augmented segmentation masks based on the augmented point prompts and the initial prompt, resulting in improved segmentation performance.","We evaluate four point augmentation techniques: random selection, maximum difference entropy, maximum distance, and a saliency model.","Experiments on the COCO, Fundus, and Chest X-ray datasets demonstrate that SAMAug can boost SAM's segmentation results, especially using the maximum distance and saliency model methods.","SAMAug underscores the potential of visual prompt engineering to advance interactive computer vision models."],"url":"http://arxiv.org/abs/2307.01187v1"}
{"created":"2023-07-03 17:45:01","title":"PlanE: Representation Learning over Planar Graphs","abstract":"Graph neural networks are prominent models for representation learning over graphs, where the idea is to iteratively compute representations of nodes of an input graph through a series of transformations in such a way that the learned graph function is isomorphism invariant on graphs, which makes the learned representations graph invariants. On the other hand, it is well-known that graph invariants learned by these class of models are incomplete: there are pairs of non-isomorphic graphs which cannot be distinguished by standard graph neural networks. This is unsurprising given the computational difficulty of graph isomorphism testing on general graphs, but the situation begs to differ for special graph classes, for which efficient graph isomorphism testing algorithms are known, such as planar graphs. The goal of this work is to design architectures for efficiently learning complete invariants of planar graphs. Inspired by the classical planar graph isomorphism algorithm of Hopcroft and Tarjan, we propose PlanE as a framework for planar representation learning. PlanE includes architectures which can learn complete invariants over planar graphs while remaining practically scalable. We empirically validate the strong performance of the resulting model architectures on well-known planar graph benchmarks, achieving multiple state-of-the-art results.","sentences":["Graph neural networks are prominent models for representation learning over graphs, where the idea is to iteratively compute representations of nodes of an input graph through a series of transformations in such a way that the learned graph function is isomorphism invariant on graphs, which makes the learned representations graph invariants.","On the other hand, it is well-known that graph invariants learned by these class of models are incomplete: there are pairs of non-isomorphic graphs which cannot be distinguished by standard graph neural networks.","This is unsurprising given the computational difficulty of graph isomorphism testing on general graphs, but the situation begs to differ for special graph classes, for which efficient graph isomorphism testing algorithms are known, such as planar graphs.","The goal of this work is to design architectures for efficiently learning complete invariants of planar graphs.","Inspired by the classical planar graph isomorphism algorithm of Hopcroft and Tarjan, we propose PlanE as a framework for planar representation learning.","PlanE includes architectures which can learn complete invariants over planar graphs while remaining practically scalable.","We empirically validate the strong performance of the resulting model architectures on well-known planar graph benchmarks, achieving multiple state-of-the-art results."],"url":"http://arxiv.org/abs/2307.01180v1"}
{"created":"2023-07-03 17:44:22","title":"Learning Mixtures of Gaussians Using the DDPM Objective","abstract":"Recent works have shown that diffusion models can learn essentially any distribution provided one can perform score estimation. Yet it remains poorly understood under what settings score estimation is possible, let alone when practical gradient-based algorithms for this task can provably succeed.   In this work, we give the first provably efficient results along these lines for one of the most fundamental distribution families, Gaussian mixture models. We prove that gradient descent on the denoising diffusion probabilistic model (DDPM) objective can efficiently recover the ground truth parameters of the mixture model in the following two settings: 1) We show gradient descent with random initialization learns mixtures of two spherical Gaussians in $d$ dimensions with $1/\\text{poly}(d)$-separated centers. 2) We show gradient descent with a warm start learns mixtures of $K$ spherical Gaussians with $\\Omega(\\sqrt{\\log(\\min(K,d))})$-separated centers. A key ingredient in our proofs is a new connection between score-based methods and two other approaches to distribution learning, the EM algorithm and spectral methods.","sentences":["Recent works have shown that diffusion models can learn essentially any distribution provided one can perform score estimation.","Yet it remains poorly understood under what settings score estimation is possible, let alone when practical gradient-based algorithms for this task can provably succeed.   ","In this work, we give the first provably efficient results along these lines for one of the most fundamental distribution families, Gaussian mixture models.","We prove that gradient descent on the denoising diffusion probabilistic model (DDPM) objective can efficiently recover the ground truth parameters of the mixture model in the following two settings: 1) We show gradient descent with random initialization learns mixtures of two spherical Gaussians in $d$ dimensions with $1/\\text{poly}(d)$-separated centers.","2) We show gradient descent with a warm start learns mixtures of $K$ spherical Gaussians with $\\Omega(\\sqrt{\\log(\\min(K,d))})$-separated centers.","A key ingredient in our proofs is a new connection between score-based methods and two other approaches to distribution learning, the EM algorithm and spectral methods."],"url":"http://arxiv.org/abs/2307.01178v1"}
{"created":"2023-07-03 17:40:58","title":"Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space","abstract":"The characterization of the functions spaces explored by neural networks (NNs) is an important aspect of deep learning theory. In this work, we view a multi-layer NN with arbitrary width as defining a particular hierarchy of reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL). This allows us to define a function space and a complexity measure that generalize prior results for shallow NNs, and we then examine their theoretical properties and implications in several aspects. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with the complexity measure controlled. Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized as the dynamics of multiple random fields. Fourth, we show examples of depth separation in NHLs under ReLU and quadratic activation functions. Finally, we complement the theory with numerical results to illustrate the learning of RKHS in NN training.","sentences":["The characterization of the functions spaces explored by neural networks (NNs) is an important aspect of deep learning theory.","In this work, we view a multi-layer NN with arbitrary width as defining a particular hierarchy of reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL).","This allows us to define a function space and a complexity measure that generalize prior results for shallow NNs, and we then examine their theoretical properties and implications in several aspects.","First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs.","Second, we prove generalization guarantees for learning an NHL with the complexity measure controlled.","Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized as the dynamics of multiple random fields.","Fourth, we show examples of depth separation in NHLs under ReLU and quadratic activation functions.","Finally, we complement the theory with numerical results to illustrate the learning of RKHS in NN training."],"url":"http://arxiv.org/abs/2307.01177v1"}
{"created":"2023-07-03 17:39:02","title":"Patient-centric health data sovereignty: an approach using Proxy re-encryption","abstract":"The exponential growth in the digitisation of services implies the handling and storage of large volumes of data. Businesses and services see data sharing and crossing as an opportunity to improve and produce new business opportunities. The health sector is one area where this proves to be true, enabling better and more innovative treatments. Notwithstanding, this raises concerns regarding personal data being treated and processed. In this paper, we present a patient-centric platform for the secure sharing of health records by shifting the control over the data to the patient, therefore, providing a step further towards data sovereignty. Data sharing is performed only with the consent of the patient, allowing it to revoke access at any given time. Furthermore, we also provide a break-glass approach, resorting to Proxy Re-encryption (PRE) and the concept of a centralised trusted entity that possesses instant access to patients' medical records. Lastly, an analysis is made to assess the performance of the platform's key operations, and the impact that a PRE scheme has on those operations.","sentences":["The exponential growth in the digitisation of services implies the handling and storage of large volumes of data.","Businesses and services see data sharing and crossing as an opportunity to improve and produce new business opportunities.","The health sector is one area where this proves to be true, enabling better and more innovative treatments.","Notwithstanding, this raises concerns regarding personal data being treated and processed.","In this paper, we present a patient-centric platform for the secure sharing of health records by shifting the control over the data to the patient, therefore, providing a step further towards data sovereignty.","Data sharing is performed only with the consent of the patient, allowing it to revoke access at any given time.","Furthermore, we also provide a break-glass approach, resorting to Proxy Re-encryption (PRE) and the concept of a centralised trusted entity that possesses instant access to patients' medical records.","Lastly, an analysis is made to assess the performance of the platform's key operations, and the impact that a PRE scheme has on those operations."],"url":"http://arxiv.org/abs/2307.01175v1"}
{"created":"2023-07-03 17:38:38","title":"Anonymous and Copy-Robust Delegations for Liquid Democracy","abstract":"Liquid democracy with ranked delegations is a novel voting scheme that unites the practicability of representative democracy with the idealistic appeal of direct democracy: Every voter decides between casting their vote on a question at hand or delegating their voting weight to some other, trusted agent. Delegations are transitive, and since voters may end up in a delegation cycle, they are encouraged to indicate not only a single delegate, but a set of potential delegates and a ranking among them. Based on the delegation preferences of all voters, a delegation rule selects one representative per voter. Previous work has revealed a trade-off between two properties of delegation rules called anonymity and copy-robustness.   To overcome this issue we study two fractional delegation rules: Mixed Borda branching, which generalizes a rule satisfying copy-robustness, and the random walk rule, which satisfies anonymity. Using the Markov chain tree theorem, we show that the two rules are in fact equivalent, and simultaneously satisfy generalized versions of the two properties. Combining the same theorem with Fulkerson's algorithm, we develop a polynomial-time algorithm for computing the outcome of the studied delegation rule. This algorithm is of independent interest, having applications in semi-supervised learning and graph theory.","sentences":["Liquid democracy with ranked delegations is a novel voting scheme that unites the practicability of representative democracy with the idealistic appeal of direct democracy: Every voter decides between casting their vote on a question at hand or delegating their voting weight to some other, trusted agent.","Delegations are transitive, and since voters may end up in a delegation cycle, they are encouraged to indicate not only a single delegate, but a set of potential delegates and a ranking among them.","Based on the delegation preferences of all voters, a delegation rule selects one representative per voter.","Previous work has revealed a trade-off between two properties of delegation rules called anonymity and copy-robustness.   ","To overcome this issue we study two fractional delegation rules: Mixed Borda branching, which generalizes a rule satisfying copy-robustness, and the random walk rule, which satisfies anonymity.","Using the Markov chain tree theorem, we show that the two rules are in fact equivalent, and simultaneously satisfy generalized versions of the two properties.","Combining the same theorem with Fulkerson's algorithm, we develop a polynomial-time algorithm for computing the outcome of the studied delegation rule.","This algorithm is of independent interest, having applications in semi-supervised learning and graph theory."],"url":"http://arxiv.org/abs/2307.01174v1"}
{"created":"2023-07-03 17:29:58","title":"Online nearest neighbor classification","abstract":"We study an instance of online non-parametric classification in the realizable setting. In particular, we consider the classical 1-nearest neighbor algorithm, and show that it achieves sublinear regret - that is, a vanishing mistake rate - against dominated or smoothed adversaries in the realizable setting.","sentences":["We study an instance of online non-parametric classification in the realizable setting.","In particular, we consider the classical 1-nearest neighbor algorithm, and show that it achieves sublinear regret - that is, a vanishing mistake rate - against dominated or smoothed adversaries in the realizable setting."],"url":"http://arxiv.org/abs/2307.01170v1"}
{"created":"2023-07-03 17:23:34","title":"Don't freeze: Finetune encoders for better Self-Supervised HAR","abstract":"Recently self-supervised learning has been proposed in the field of human activity recognition as a solution to the labelled data availability problem. The idea being that by using pretext tasks such as reconstruction or contrastive predictive coding, useful representations can be learned that then can be used for classification. Those approaches follow the pretrain, freeze and fine-tune procedure. In this paper we will show how a simple change - not freezing the representation - leads to substantial performance gains across pretext tasks. The improvement was found in all four investigated datasets and across all four pretext tasks and is inversely proportional to amount of labelled data. Moreover the effect is present whether the pretext task is carried on the Capture24 dataset or directly in unlabelled data of the target dataset.","sentences":["Recently self-supervised learning has been proposed in the field of human activity recognition as a solution to the labelled data availability problem.","The idea being that by using pretext tasks such as reconstruction or contrastive predictive coding, useful representations can be learned that then can be used for classification.","Those approaches follow the pretrain, freeze and fine-tune procedure.","In this paper we will show how a simple change - not freezing the representation - leads to substantial performance gains across pretext tasks.","The improvement was found in all four investigated datasets and across all four pretext tasks and is inversely proportional to amount of labelled data.","Moreover the effect is present whether the pretext task is carried on the Capture24 dataset or directly in unlabelled data of the target dataset."],"url":"http://arxiv.org/abs/2307.01168v1"}
{"created":"2023-07-03 17:18:50","title":"Coupled Gradient Flows for Strategic Non-Local Distribution Shift","abstract":"We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed. Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure. In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift. We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users. For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters. To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems. Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture.","sentences":["We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed.","Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure.","In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift.","We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users.","For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters.","To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems.","Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture."],"url":"http://arxiv.org/abs/2307.01166v1"}
{"created":"2023-07-03 17:12:44","title":"Improving Language Plasticity via Pretraining with Active Forgetting","abstract":"Pretrained language models (PLMs) are today the primary model for natural language processing. Despite their impressive downstream performance, it can be difficult to apply PLMs to new languages, a barrier to making their capabilities universally accessible. While prior work has shown it possible to address this issue by learning a new embedding layer for the new language, doing so is both data and compute inefficient. We propose to use an active forgetting mechanism during pretraining, as a simple way of creating PLMs that can quickly adapt to new languages. Concretely, by resetting the embedding layer every K updates during pretraining, we encourage the PLM to improve its ability of learning new embeddings within a limited number of updates, similar to a meta-learning effect. Experiments with RoBERTa show that models pretrained with our forgetting mechanism not only demonstrate faster convergence during language adaptation but also outperform standard ones in a low-data regime, particularly for languages that are distant from English.","sentences":["Pretrained language models (PLMs) are today the primary model for natural language processing.","Despite their impressive downstream performance, it can be difficult to apply PLMs to new languages, a barrier to making their capabilities universally accessible.","While prior work has shown it possible to address this issue by learning a new embedding layer for the new language, doing so is both data and compute inefficient.","We propose to use an active forgetting mechanism during pretraining, as a simple way of creating PLMs that can quickly adapt to new languages.","Concretely, by resetting the embedding layer every K updates during pretraining, we encourage the PLM to improve its ability of learning new embeddings within a limited number of updates, similar to a meta-learning effect.","Experiments with RoBERTa show that models pretrained with our forgetting mechanism not only demonstrate faster convergence during language adaptation but also outperform standard ones in a low-data regime, particularly for languages that are distant from English."],"url":"http://arxiv.org/abs/2307.01163v1"}
{"created":"2023-07-03 17:10:19","title":"Soft Gripping: Specifying for Trustworthiness","abstract":"Soft robotics is an emerging technology in which engineers create flexible devices for use in a variety of applications. In order to advance the wide adoption of soft robots, ensuring their trustworthiness is essential; if soft robots are not trusted, they will not be used to their full potential. In order to demonstrate trustworthiness, a specification needs to be formulated to define what is trustworthy. However, even for soft robotic grippers, which is one of the most mature areas in soft robotics, the soft robotics community has so far given very little attention to formulating specifications. In this work, we discuss the importance of developing specifications during development of soft robotic systems, and present an extensive example specification for a soft gripper for pick-and-place tasks for grocery items. The proposed specification covers both functional and non-functional requirements, such as reliability, safety, adaptability, predictability, ethics, and regulations. We also highlight the need to promote verifiability as a first-class objective in the design of a soft gripper.","sentences":["Soft robotics is an emerging technology in which engineers create flexible devices for use in a variety of applications.","In order to advance the wide adoption of soft robots, ensuring their trustworthiness is essential; if soft robots are not trusted, they will not be used to their full potential.","In order to demonstrate trustworthiness, a specification needs to be formulated to define what is trustworthy.","However, even for soft robotic grippers, which is one of the most mature areas in soft robotics, the soft robotics community has so far given very little attention to formulating specifications.","In this work, we discuss the importance of developing specifications during development of soft robotic systems, and present an extensive example specification for a soft gripper for pick-and-place tasks for grocery items.","The proposed specification covers both functional and non-functional requirements, such as reliability, safety, adaptability, predictability, ethics, and regulations.","We also highlight the need to promote verifiability as a first-class objective in the design of a soft gripper."],"url":"http://arxiv.org/abs/2307.01159v1"}
{"created":"2023-07-03 17:07:18","title":"Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning","abstract":"The ability to model the mental states of others is crucial to human social intelligence, and can offer similar benefits to artificial agents with respect to the social dynamics induced in multi-agent settings. We present a method of grounding semantically meaningful, human-interpretable beliefs within policies modeled by deep networks. We then consider the task of 2nd-order belief prediction. We propose that ability of each agent to predict the beliefs of the other agents can be used as an intrinsic reward signal for multi-agent reinforcement learning. Finally, we present preliminary empirical results in a mixed cooperative-competitive environment.","sentences":["The ability to model the mental states of others is crucial to human social intelligence, and can offer similar benefits to artificial agents with respect to the social dynamics induced in multi-agent settings.","We present a method of grounding semantically meaningful, human-interpretable beliefs within policies modeled by deep networks.","We then consider the task of 2nd-order belief prediction.","We propose that ability of each agent to predict the beliefs of the other agents can be used as an intrinsic reward signal for multi-agent reinforcement learning.","Finally, we present preliminary empirical results in a mixed cooperative-competitive environment."],"url":"http://arxiv.org/abs/2307.01158v1"}
{"created":"2023-07-03 17:05:29","title":"A novel approach for predicting epidemiological forecasting parameters based on real-time signals and Data Assimilation","abstract":"This paper proposes a novel approach to predict epidemiological parameters by integrating new real-time signals from various sources of information, such as novel social media-based population density maps and Air Quality data. We implement an ensemble of Convolutional Neural Networks (CNN) models using various data sources and fusion methodology to build robust predictions and simulate several dynamic parameters that could improve the decision-making process for policymakers. Additionally, we used data assimilation to estimate the state of our system from fused CNN predictions. The combination of meteorological signals and social media-based population density maps improved the performance and flexibility of our prediction of the COVID-19 outbreak in London. While the proposed approach outperforms standard models, such as compartmental models traditionally used in disease forecasting (SEIR), generating robust and consistent predictions allows us to increase the stability of our model while increasing its accuracy.","sentences":["This paper proposes a novel approach to predict epidemiological parameters by integrating new real-time signals from various sources of information, such as novel social media-based population density maps and Air Quality data.","We implement an ensemble of Convolutional Neural Networks (CNN) models using various data sources and fusion methodology to build robust predictions and simulate several dynamic parameters that could improve the decision-making process for policymakers.","Additionally, we used data assimilation to estimate the state of our system from fused CNN predictions.","The combination of meteorological signals and social media-based population density maps improved the performance and flexibility of our prediction of the COVID-19 outbreak in London.","While the proposed approach outperforms standard models, such as compartmental models traditionally used in disease forecasting (SEIR), generating robust and consistent predictions allows us to increase the stability of our model while increasing its accuracy."],"url":"http://arxiv.org/abs/2307.01157v1"}
{"created":"2023-07-03 16:39:28","title":"Investigating Data Memorization in 3D Latent Diffusion Models for Medical Image Synthesis","abstract":"Generative latent diffusion models have been established as state-of-the-art in data generation. One promising application is generation of realistic synthetic medical imaging data for open data sharing without compromising patient privacy. Despite the promise, the capacity of such models to memorize sensitive patient training data and synthesize samples showing high resemblance to training data samples is relatively unexplored. Here, we assess the memorization capacity of 3D latent diffusion models on photon-counting coronary computed tomography angiography and knee magnetic resonance imaging datasets. To detect potential memorization of training samples, we utilize self-supervised models based on contrastive learning. Our results suggest that such latent diffusion models indeed memorize training data, and there is a dire need for devising strategies to mitigate memorization.","sentences":["Generative latent diffusion models have been established as state-of-the-art in data generation.","One promising application is generation of realistic synthetic medical imaging data for open data sharing without compromising patient privacy.","Despite the promise, the capacity of such models to memorize sensitive patient training data and synthesize samples showing high resemblance to training data samples is relatively unexplored.","Here, we assess the memorization capacity of 3D latent diffusion models on photon-counting coronary computed tomography angiography and knee magnetic resonance imaging datasets.","To detect potential memorization of training samples, we utilize self-supervised models based on contrastive learning.","Our results suggest that such latent diffusion models indeed memorize training data, and there is a dire need for devising strategies to mitigate memorization."],"url":"http://arxiv.org/abs/2307.01148v1"}
{"created":"2023-07-03 16:37:10","title":"AVSegFormer: Audio-Visual Segmentation with Transformer","abstract":"The combination of audio and vision has long been a topic of interest in the multi-modal community. Recently, a new audio-visual segmentation (AVS) task has been introduced, aiming to locate and segment the sounding objects in a given video. This task demands audio-driven pixel-level scene understanding for the first time, posing significant challenges. In this paper, we propose AVSegFormer, a novel framework for AVS tasks that leverages the transformer architecture. Specifically, we introduce audio queries and learnable queries into the transformer decoder, enabling the network to selectively attend to interested visual features. Besides, we present an audio-visual mixer, which can dynamically adjust visual features by amplifying relevant and suppressing irrelevant spatial channels. Additionally, we devise an intermediate mask loss to enhance the supervision of the decoder, encouraging the network to produce more accurate intermediate predictions. Extensive experiments demonstrate that AVSegFormer achieves state-of-the-art results on the AVS benchmark. The code is available at https://github.com/vvvb-github/AVSegFormer.","sentences":["The combination of audio and vision has long been a topic of interest in the multi-modal community.","Recently, a new audio-visual segmentation (AVS) task has been introduced, aiming to locate and segment the sounding objects in a given video.","This task demands audio-driven pixel-level scene understanding for the first time, posing significant challenges.","In this paper, we propose AVSegFormer, a novel framework for AVS tasks that leverages the transformer architecture.","Specifically, we introduce audio queries and learnable queries into the transformer decoder, enabling the network to selectively attend to interested visual features.","Besides, we present an audio-visual mixer, which can dynamically adjust visual features by amplifying relevant and suppressing irrelevant spatial channels.","Additionally, we devise an intermediate mask loss to enhance the supervision of the decoder, encouraging the network to produce more accurate intermediate predictions.","Extensive experiments demonstrate that AVSegFormer achieves state-of-the-art results on the AVS benchmark.","The code is available at https://github.com/vvvb-github/AVSegFormer."],"url":"http://arxiv.org/abs/2307.01146v1"}
{"created":"2023-07-03 16:32:46","title":"Prompt Middleware: Mapping Prompts for Large Language Models to UI Affordances","abstract":"To help users do complex work, researchers have developed techniques to integrate AI and human intelligence into user interfaces (UIs). With the recent introduction of large language models (LLMs), which can generate text in response to a natural language prompt, there are new opportunities to consider how to integrate LLMs into UIs. We present Prompt Middleware, a framework for generating prompts for LLMs based on UI affordances. These include prompts that are predefined by experts (static prompts), generated from templates with fill-in options in the UI (template-based prompts), or created from scratch (free-form prompts). We demonstrate this framework with FeedbackBuffet, a writing assistant that automatically generates feedback based on a user's text input. Inspired by prior research showing how templates can help non-experts perform more like experts, FeedbackBuffet leverages template-based prompt middleware to enable feedback seekers to specify the types of feedback they want to receive as options in a UI. These options are composed using a template to form a feedback request prompt to GPT-3. We conclude with a discussion about how Prompt Middleware can help developers integrate LLMs into UIs.","sentences":["To help users do complex work, researchers have developed techniques to integrate AI and human intelligence into user interfaces (UIs).","With the recent introduction of large language models (LLMs), which can generate text in response to a natural language prompt, there are new opportunities to consider how to integrate LLMs into UIs.","We present Prompt Middleware, a framework for generating prompts for LLMs based on UI affordances.","These include prompts that are predefined by experts (static prompts), generated from templates with fill-in options in the UI (template-based prompts), or created from scratch (free-form prompts).","We demonstrate this framework with FeedbackBuffet, a writing assistant that automatically generates feedback based on a user's text input.","Inspired by prior research showing how templates can help non-experts perform more like experts, FeedbackBuffet leverages template-based prompt middleware to enable feedback seekers to specify the types of feedback they want to receive as options in a UI.","These options are composed using a template to form a feedback request prompt to GPT-3.","We conclude with a discussion about how Prompt Middleware can help developers integrate LLMs into UIs."],"url":"http://arxiv.org/abs/2307.01142v1"}
{"created":"2023-07-03 16:25:49","title":"SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions","abstract":"Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity, this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines, concepts and goals. In this work, we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions. To test our methodology, we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding. In comparison to the models that are finetuned with machine generated data only, LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark.","sentences":["Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent.","Despite its popularity, this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines, concepts and goals.","In this work, we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions.","To test our methodology, we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding.","In comparison to the models that are finetuned with machine generated data only, LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark."],"url":"http://arxiv.org/abs/2307.01139v1"}
{"created":"2023-07-03 16:19:50","title":"Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking","abstract":"The biomedical field relies heavily on concept linking in various areas such as literature mining, graph alignment, information retrieval, question-answering, data, and knowledge integration. Although large language models (LLMs) have made significant strides in many natural language processing tasks, their effectiveness in biomedical concept mapping is yet to be fully explored. This research investigates a method that exploits the in-context learning (ICL) capabilities of large models for biomedical concept linking. The proposed approach adopts a two-stage retrieve-and-rank framework. Initially, biomedical concepts are embedded using language models, and then embedding similarity is utilized to retrieve the top candidates. These candidates' contextual information is subsequently incorporated into the prompt and processed by a large language model to re-rank the concepts. This approach achieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7% in chemical entity normalization, exhibiting a competitive performance relative to supervised learning methods. Further, it showed a significant improvement, with an over 20-point absolute increase in F1 score on an oncology matching dataset. Extensive qualitative assessments were conducted, and the benefits and potential shortcomings of using large language models within the biomedical domain were discussed. were discussed.","sentences":["The biomedical field relies heavily on concept linking in various areas such as literature mining, graph alignment, information retrieval, question-answering, data, and knowledge integration.","Although large language models (LLMs) have made significant strides in many natural language processing tasks, their effectiveness in biomedical concept mapping is yet to be fully explored.","This research investigates a method that exploits the in-context learning (ICL) capabilities of large models for biomedical concept linking.","The proposed approach adopts a two-stage retrieve-and-rank framework.","Initially, biomedical concepts are embedded using language models, and then embedding similarity is utilized to retrieve the top candidates.","These candidates' contextual information is subsequently incorporated into the prompt and processed by a large language model to re-rank the concepts.","This approach achieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7% in chemical entity normalization, exhibiting a competitive performance relative to supervised learning methods.","Further, it showed a significant improvement, with an over 20-point absolute increase in F1 score on an oncology matching dataset.","Extensive qualitative assessments were conducted, and the benefits and potential shortcomings of using large language models within the biomedical domain were discussed.","were discussed."],"url":"http://arxiv.org/abs/2307.01137v1"}
{"created":"2023-07-03 16:15:34","title":"ChatGPT vs. Google: A Comparative Study of Search Performance and User Experience","abstract":"The advent of ChatGPT, a large language model-powered chatbot, has prompted questions about its potential implications for traditional search engines. In this study, we investigate the differences in user behavior when employing search engines and chatbot tools for information-seeking tasks. We carry out a randomized online experiment, dividing participants into two groups: one using a ChatGPT-like tool and the other using a Google Search-like tool. Our findings reveal that the ChatGPT group consistently spends less time on all tasks, with no significant difference in overall task performance between the groups. Notably, ChatGPT levels user search performance across different education levels and excels in answering straightforward questions and providing general solutions but falls short in fact-checking tasks. Users perceive ChatGPT's responses as having higher information quality compared to Google Search, despite displaying a similar level of trust in both tools. Furthermore, participants using ChatGPT report significantly better user experiences in terms of usefulness, enjoyment, and satisfaction, while perceived ease of use remains comparable between the two tools. However, ChatGPT may also lead to overreliance and generate or replicate misinformation, yielding inconsistent results. Our study offers valuable insights for search engine management and highlights opportunities for integrating chatbot technologies into search engine designs.","sentences":["The advent of ChatGPT, a large language model-powered chatbot, has prompted questions about its potential implications for traditional search engines.","In this study, we investigate the differences in user behavior when employing search engines and chatbot tools for information-seeking tasks.","We carry out a randomized online experiment, dividing participants into two groups: one using a ChatGPT-like tool and the other using a Google Search-like tool.","Our findings reveal that the ChatGPT group consistently spends less time on all tasks, with no significant difference in overall task performance between the groups.","Notably, ChatGPT levels user search performance across different education levels and excels in answering straightforward questions and providing general solutions but falls short in fact-checking tasks.","Users perceive ChatGPT's responses as having higher information quality compared to Google Search, despite displaying a similar level of trust in both tools.","Furthermore, participants using ChatGPT report significantly better user experiences in terms of usefulness, enjoyment, and satisfaction, while perceived ease of use remains comparable between the two tools.","However, ChatGPT may also lead to overreliance and generate or replicate misinformation, yielding inconsistent results.","Our study offers valuable insights for search engine management and highlights opportunities for integrating chatbot technologies into search engine designs."],"url":"http://arxiv.org/abs/2307.01135v1"}
{"created":"2023-07-03 16:10:42","title":"Passive Query-Recovery Attack Against Secure Conjunctive Keyword Search Schemes","abstract":"While storing documents on the cloud can be attractive, the question remains whether cloud providers can be trusted with storing private documents. Even if trusted, data breaches are ubiquitous. To prevent information leakage one can store documents encrypted. If encrypted under traditional schemes, one loses the ability to perform simple operations over the documents, such as searching through them. Searchable encryption schemes were proposed allowing some search functionality while documents remain encrypted. Orthogonally, research is done to find attacks that exploit search and access pattern leakage that most efficient schemes have. One type of such an attack is the ability to recover plaintext queries. Passive query-recovery attacks on single-keyword search schemes have been proposed in literature, however, conjunctive keyword search has not been considered, although keyword searches with two or three keywords appear more frequently in online searches.   We introduce a generic extension strategy for existing passive query-recovery attacks against single-keyword search schemes and explore its applicability for the attack presented by Damie et al. (USENIX Security '21). While the original attack achieves up to a recovery rate of 85% against single-keyword search schemes for an attacker without exact background knowledge, our experiments show that the generic extension to conjunctive queries comes with a significant performance decrease achieving recovery rates of at most 32%. Assuming a stronger attacker with partial knowledge of the indexed document set boosts the recovery rate to 85% for conjunctive keyword queries with two keywords and achieves similar recovery rates as previous attacks by Cash et al. (CCS '15) and Islam et al. (NDSS '12) in the same setting for single-keyword search schemes.","sentences":["While storing documents on the cloud can be attractive, the question remains whether cloud providers can be trusted with storing private documents.","Even if trusted, data breaches are ubiquitous.","To prevent information leakage one can store documents encrypted.","If encrypted under traditional schemes, one loses the ability to perform simple operations over the documents, such as searching through them.","Searchable encryption schemes were proposed allowing some search functionality while documents remain encrypted.","Orthogonally, research is done to find attacks that exploit search and access pattern leakage that most efficient schemes have.","One type of such an attack is the ability to recover plaintext queries.","Passive query-recovery attacks on single-keyword search schemes have been proposed in literature, however, conjunctive keyword search has not been considered, although keyword searches with two or three keywords appear more frequently in online searches.   ","We introduce a generic extension strategy for existing passive query-recovery attacks against single-keyword search schemes and explore its applicability for the attack presented by Damie et al.","(USENIX Security '21).","While the original attack achieves up to a recovery rate of 85% against single-keyword search schemes for an attacker without exact background knowledge, our experiments show that the generic extension to conjunctive queries comes with a significant performance decrease achieving recovery rates of at most 32%.","Assuming a stronger attacker with partial knowledge of the indexed document set boosts the recovery rate to 85% for conjunctive keyword queries with two keywords and achieves similar recovery rates as previous attacks by Cash et al.","(CCS '15) and Islam et al.","(NDSS '12) in the same setting for single-keyword search schemes."],"url":"http://arxiv.org/abs/2307.01131v1"}
{"created":"2023-07-03 16:01:45","title":"Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction","abstract":"In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios. In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure. However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields. This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building. The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process. Our unique manifold approach may encompass significant benefits to the scientific community. In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for \"guiding\" the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise. To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain. We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts.","sentences":["In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios.","In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure.","However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields.","This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building.","The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process.","Our unique manifold approach may encompass significant benefits to the scientific community.","In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for \"guiding\" the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise.","To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain.","We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts."],"url":"http://arxiv.org/abs/2307.01128v1"}
{"created":"2023-07-03 15:51:39","title":"Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and 3D Localization","abstract":"Geometric navigation is nowadays a well-established field of robotics and the research focus is shifting towards higher-level scene understanding, such as Semantic Mapping. When a robot needs to interact with its environment, it must be able to comprehend the contextual information of its surroundings. This work focuses on classifying and localising objects within a map, which is under construction (SLAM) or already built. To further explore this direction, we propose a framework that can autonomously detect and localize predefined objects in a known environment using a multi-modal sensor fusion approach (combining RGB and depth data from an RGB-D camera and a lidar). The framework consists of three key elements: understanding the environment through RGB data, estimating depth through multi-modal sensor fusion, and managing artifacts (i.e., filtering and stabilizing measurements). The experiments show that the proposed framework can accurately detect 98% of the objects in the real sample environment, without post-processing, while 85% and 80% of the objects were mapped using the single RGBD camera or RGB + lidar setup respectively. The comparison with single-sensor (camera or lidar) experiments is performed to show that sensor fusion allows the robot to accurately detect near and far obstacles, which would have been noisy or imprecise in a purely visual or laser-based approach.","sentences":["Geometric navigation is nowadays a well-established field of robotics and the research focus is shifting towards higher-level scene understanding, such as Semantic Mapping.","When a robot needs to interact with its environment, it must be able to comprehend the contextual information of its surroundings.","This work focuses on classifying and localising objects within a map, which is under construction (SLAM) or already built.","To further explore this direction, we propose a framework that can autonomously detect and localize predefined objects in a known environment using a multi-modal sensor fusion approach (combining RGB and depth data from an RGB-D camera and a lidar).","The framework consists of three key elements: understanding the environment through RGB data, estimating depth through multi-modal sensor fusion, and managing artifacts (i.e., filtering and stabilizing measurements).","The experiments show that the proposed framework can accurately detect 98% of the objects in the real sample environment, without post-processing, while 85% and 80% of the objects were mapped using the single RGBD camera or RGB + lidar setup respectively.","The comparison with single-sensor (camera or lidar) experiments is performed to show that sensor fusion allows the robot to accurately detect near and far obstacles, which would have been noisy or imprecise in a purely visual or laser-based approach."],"url":"http://arxiv.org/abs/2307.01121v1"}
{"created":"2023-07-03 15:49:15","title":"musif: a Python package for symbolic music feature extraction","abstract":"In this work, we introduce musif, a Python package that facilitates the automatic extraction of features from symbolic music scores. The package includes the implementation of a large number of features, which have been developed by a team of experts in musicology, music theory, statistics, and computer science. Additionally, the package allows for the easy creation of custom features using commonly available Python libraries. musif is primarily geared towards processing high-quality musicological data encoded in MusicXML format, but also supports other formats commonly used in music information retrieval tasks, including MIDI, MEI, Kern, and others. We provide comprehensive documentation and tutorials to aid in the extension of the framework and to facilitate the introduction of new and inexperienced users to its usage.","sentences":["In this work, we introduce musif, a Python package that facilitates the automatic extraction of features from symbolic music scores.","The package includes the implementation of a large number of features, which have been developed by a team of experts in musicology, music theory, statistics, and computer science.","Additionally, the package allows for the easy creation of custom features using commonly available Python libraries.","musif is primarily geared towards processing high-quality musicological data encoded in MusicXML format, but also supports other formats commonly used in music information retrieval tasks, including MIDI, MEI, Kern, and others.","We provide comprehensive documentation and tutorials to aid in the extension of the framework and to facilitate the introduction of new and inexperienced users to its usage."],"url":"http://arxiv.org/abs/2307.01120v1"}
{"created":"2023-07-03 15:45:14","title":"MeT: A Graph Transformer for Semantic Segmentation of 3D Meshes","abstract":"Polygonal meshes have become the standard for discretely approximating 3D shapes, thanks to their efficiency and high flexibility in capturing non-uniform shapes. This non-uniformity, however, leads to irregularity in the mesh structure, making tasks like segmentation of 3D meshes particularly challenging. Semantic segmentation of 3D mesh has been typically addressed through CNN-based approaches, leading to good accuracy. Recently, transformers have gained enough momentum both in NLP and computer vision fields, achieving performance at least on par with CNN models, supporting the long-sought architecture universalism. Following this trend, we propose a transformer-based method for semantic segmentation of 3D mesh motivated by a better modeling of the graph structure of meshes, by means of global attention mechanisms. In order to address the limitations of standard transformer architectures in modeling relative positions of non-sequential data, as in the case of 3D meshes, as well as in capturing the local context, we perform positional encoding by means the Laplacian eigenvectors of the adjacency matrix, replacing the traditional sinusoidal positional encodings, and by introducing clustering-based features into the self-attention and cross-attention operators. Experimental results, carried out on three sets of the Shape COSEG Dataset, on the human segmentation dataset proposed in Maron et al., 2017 and on the ShapeNet benchmark, show how the proposed approach yields state-of-the-art performance on semantic segmentation of 3D meshes.","sentences":["Polygonal meshes have become the standard for discretely approximating 3D shapes, thanks to their efficiency and high flexibility in capturing non-uniform shapes.","This non-uniformity, however, leads to irregularity in the mesh structure, making tasks like segmentation of 3D meshes particularly challenging.","Semantic segmentation of 3D mesh has been typically addressed through CNN-based approaches, leading to good accuracy.","Recently, transformers have gained enough momentum both in NLP and computer vision fields, achieving performance at least on par with CNN models, supporting the long-sought architecture universalism.","Following this trend, we propose a transformer-based method for semantic segmentation of 3D mesh motivated by a better modeling of the graph structure of meshes, by means of global attention mechanisms.","In order to address the limitations of standard transformer architectures in modeling relative positions of non-sequential data, as in the case of 3D meshes, as well as in capturing the local context, we perform positional encoding by means the Laplacian eigenvectors of the adjacency matrix, replacing the traditional sinusoidal positional encodings, and by introducing clustering-based features into the self-attention and cross-attention operators.","Experimental results, carried out on three sets of the Shape COSEG Dataset, on the human segmentation dataset proposed in Maron et al., 2017 and on the ShapeNet benchmark, show how the proposed approach yields state-of-the-art performance on semantic segmentation of 3D meshes."],"url":"http://arxiv.org/abs/2307.01115v1"}
{"created":"2023-07-03 15:35:42","title":"Complexity Dichotomies for the Maximum Weighted Digraph Partition Problem","abstract":"We introduce and study a new optimization problem on digraphs, termed Maximum Weighted Digraph Partition (MWDP) problem. We prove three complexity dichotomies for MWDP: on arbitrary digraphs, on oriented digraphs, and on symmetric digraphs. We demonstrate applications of the dichotomies for binary-action polymatrix games and several graph theory problems.","sentences":["We introduce and study a new optimization problem on digraphs, termed Maximum Weighted Digraph Partition (MWDP) problem.","We prove three complexity dichotomies for MWDP: on arbitrary digraphs, on oriented digraphs, and on symmetric digraphs.","We demonstrate applications of the dichotomies for binary-action polymatrix games and several graph theory problems."],"url":"http://arxiv.org/abs/2307.01109v1"}
{"created":"2023-07-03 15:32:55","title":"A phase field-based framework for electro-chemo-mechanical fracture: crack-contained electrolytes, chemical reactions and stabilisation","abstract":"We present a new theoretical and computational framework for modelling electro-chemo-mechanical fracture. The model combines a phase field description of fracture with a fully coupled characterisation of electrolyte behaviour, surface chemical reactions and stress-assisted diffusion. Importantly, a new physics-based formulation is presented to describe electrolyte-containing phase field cracks, appropriately capturing the sensitivity of electrochemical transport and reaction kinetics to the crack opening height. Unlike other existing methods, this approach is shown to accurately capture the results obtained with discrete fracture simulations. The potential of the electro-chemo-mechanical model presented is demonstrated by particularising it to the analysis of hydrogen embrittlement in metallic samples exposed to aqueous electrolytes. The finite element implementation takes as nodal degrees-of-freedom the electrolyte potential, the concentrations of relevant ionic species, the surface coverage, the concentration of diluted species, the displacement field and the phase field order parameter. Particular attention is devoted to improve stability and efficiency, resulting in the development of strategies for avoiding ill-constrained degrees of freedom and lumped integration schemes that eliminate numerical oscillations. The numerical experiments conducted showcase the ability of the model to deliver assumptions-free predictions for systems involving both free-flowing and crack-contained electrolytes. The results obtained highlight the role of electrolyte behaviour in driving the cracking process, evidencing the limitations of existing models.","sentences":["We present a new theoretical and computational framework for modelling electro-chemo-mechanical fracture.","The model combines a phase field description of fracture with a fully coupled characterisation of electrolyte behaviour, surface chemical reactions and stress-assisted diffusion.","Importantly, a new physics-based formulation is presented to describe electrolyte-containing phase field cracks, appropriately capturing the sensitivity of electrochemical transport and reaction kinetics to the crack opening height.","Unlike other existing methods, this approach is shown to accurately capture the results obtained with discrete fracture simulations.","The potential of the electro-chemo-mechanical model presented is demonstrated by particularising it to the analysis of hydrogen embrittlement in metallic samples exposed to aqueous electrolytes.","The finite element implementation takes as nodal degrees-of-freedom the electrolyte potential, the concentrations of relevant ionic species, the surface coverage, the concentration of diluted species, the displacement field and the phase field order parameter.","Particular attention is devoted to improve stability and efficiency, resulting in the development of strategies for avoiding ill-constrained degrees of freedom and lumped integration schemes that eliminate numerical oscillations.","The numerical experiments conducted showcase the ability of the model to deliver assumptions-free predictions for systems involving both free-flowing and crack-contained electrolytes.","The results obtained highlight the role of electrolyte behaviour in driving the cracking process, evidencing the limitations of existing models."],"url":"http://arxiv.org/abs/2307.01105v1"}
{"created":"2023-07-03 15:26:08","title":"Assessment of the Utilization of Quadruped Robots in Pharmaceutical Research and Development Laboratories","abstract":"Drug development is becoming more and more complex and resource-intensive. To reduce the costs and the time-to-market, the pharmaceutical industry employs cutting-edge automation solutions. Supportive robotics technologies, such as stationary and mobile manipulators, exist in various laboratory settings. However, they still lack the mobility and dexterity to navigate and operate in human-centered environments. We evaluate the feasibility of quadruped robots for the specific use case of remote inspection, utilizing the out-of-the-box capabilities of Boston Dynamics' Spot platform. We also provide an outlook on the newest technological advancements and the future applications these are anticipated to enable.","sentences":["Drug development is becoming more and more complex and resource-intensive.","To reduce the costs and the time-to-market, the pharmaceutical industry employs cutting-edge automation solutions.","Supportive robotics technologies, such as stationary and mobile manipulators, exist in various laboratory settings.","However, they still lack the mobility and dexterity to navigate and operate in human-centered environments.","We evaluate the feasibility of quadruped robots for the specific use case of remote inspection, utilizing the out-of-the-box capabilities of Boston Dynamics' Spot platform.","We also provide an outlook on the newest technological advancements and the future applications these are anticipated to enable."],"url":"http://arxiv.org/abs/2307.01101v1"}
{"created":"2023-07-03 15:19:17","title":"MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion","abstract":"This paper introduces MVDiffusion, a simple yet effective multi-view image generation method for scenarios where pixel-to-pixel correspondences are available, such as perspective crops from panorama or multi-view images given geometry (depth maps and poses). Unlike prior models that rely on iterative image warping and inpainting, MVDiffusion concurrently generates all images with a global awareness, encompassing high resolution and rich content, effectively addressing the error accumulation prevalent in preceding models. MVDiffusion specifically incorporates a correspondence-aware attention mechanism, enabling effective cross-view interaction. This mechanism underpins three pivotal modules: 1) a generation module that produces low-resolution images while maintaining global correspondence, 2) an interpolation module that densifies spatial coverage between images, and 3) a super-resolution module that upscales into high-resolution outputs. In terms of panoramic imagery, MVDiffusion can generate high-resolution photorealistic images up to 1024$\\times$1024 pixels. For geometry-conditioned multi-view image generation, MVDiffusion demonstrates the first method capable of generating a textured map of a scene mesh. The project page is at https://mvdiffusion.github.io.","sentences":["This paper introduces MVDiffusion, a simple yet effective multi-view image generation method for scenarios where pixel-to-pixel correspondences are available, such as perspective crops from panorama or multi-view images given geometry (depth maps and poses).","Unlike prior models that rely on iterative image warping and inpainting, MVDiffusion concurrently generates all images with a global awareness, encompassing high resolution and rich content, effectively addressing the error accumulation prevalent in preceding models.","MVDiffusion specifically incorporates a correspondence-aware attention mechanism, enabling effective cross-view interaction.","This mechanism underpins three pivotal modules: 1) a generation module that produces low-resolution images while maintaining global correspondence, 2) an interpolation module that densifies spatial coverage between images, and 3) a super-resolution module that upscales into high-resolution outputs.","In terms of panoramic imagery, MVDiffusion can generate high-resolution photorealistic images up to 1024$\\times$1024 pixels.","For geometry-conditioned multi-view image generation, MVDiffusion demonstrates the first method capable of generating a textured map of a scene mesh.","The project page is at https://mvdiffusion.github.io."],"url":"http://arxiv.org/abs/2307.01097v1"}
{"created":"2023-07-03 15:16:42","title":"Coded Orthogonal Modulation for the Multi-Antenna Multiple-Access Channel","abstract":"This study focuses on (traditional and unsourced) multiple-access communication over a single transmit and multiple ($M$) receive antennas. We assume full or partial channel state information (CSI) at the receiver. It is known that to fully achieve the fundamental limits (even asymptotically) the decoder needs to jointly estimate all user codewords, doing which directly is computationally infeasible. We propose a low-complexity solution, termed coded orthogonal modulation multiple-access (COMMA), in which users first encode their messages via a long (multi-user interference aware) outer code operating over a $q$-ary alphabet. These symbols are modulated onto $q$ orthogonal waveforms. At the decoder a multiple-measurement vector approximate message passing (MMV-AMP) algorithm estimates several candidates (out of $q$) for each user, with the remaining uncertainty resolved by the single-user outer decoders. Numerically, we show that COMMA outperforms a standard solution based on linear multiuser detection (MUD) with Gaussian signaling. Theoretically, we derive bounds and scaling laws for $M$, the number of users $K_a$, SNR, and $q$, allowing to quantify the trade-off between receive antennas and spectral efficiency. The orthogonal signaling scheme is applicable to unsourced random access and, with chirp sequences as basis, allows for low-complexity fast Fourier transform (FFT) based receivers that are resilient to frequency and timing offsets.","sentences":["This study focuses on (traditional and unsourced) multiple-access communication over a single transmit and multiple ($M$) receive antennas.","We assume full or partial channel state information (CSI) at the receiver.","It is known that to fully achieve the fundamental limits (even asymptotically) the decoder needs to jointly estimate all user codewords, doing which directly is computationally infeasible.","We propose a low-complexity solution, termed coded orthogonal modulation multiple-access (COMMA), in which users first encode their messages via a long (multi-user interference aware) outer code operating over a $q$-ary alphabet.","These symbols are modulated onto $q$ orthogonal waveforms.","At the decoder a multiple-measurement vector approximate message passing (MMV-AMP) algorithm estimates several candidates (out of $q$) for each user, with the remaining uncertainty resolved by the single-user outer decoders.","Numerically, we show that COMMA outperforms a standard solution based on linear multiuser detection (MUD) with Gaussian signaling.","Theoretically, we derive bounds and scaling laws for $M$, the number of users $K_a$, SNR, and $q$, allowing to quantify the trade-off between receive antennas and spectral efficiency.","The orthogonal signaling scheme is applicable to unsourced random access and, with chirp sequences as basis, allows for low-complexity fast Fourier transform (FFT) based receivers that are resilient to frequency and timing offsets."],"url":"http://arxiv.org/abs/2307.01095v1"}
{"created":"2023-07-03 15:09:37","title":"The Lawn Mowing Problem: From Algebra to Algorithms","abstract":"For a given polygonal region $P$, the Lawn Mowing Problem (LMP) asks for a shortest tour $T$ that gets within Euclidean distance 1/2 of every point in $P$; this is equivalent to computing a shortest tour for a unit-diameter cutter $C$ that covers all of $P$. As a generalization of the Traveling Salesman Problem, the LMP is NP-hard; unlike the discrete TSP, however, the LMP has defied efforts to achieve exact solutions, due to its combination of combinatorial complexity with continuous geometry.   We provide a number of new contributions that provide insights into the involved difficulties, as well as positive results that enable both theoretical and practical progress. (1) We show that the LMP is algebraically hard: it is not solvable by radicals over the field of rationals, even for the simple case in which $P$ is a $2\\times 2$ square. This implies that it is impossible to compute exact optimal solutions under models of computation that rely on elementary arithmetic operations and the extraction of $k$th roots, and explains the perceived practical difficulty. (2) We exploit this algebraic analysis for the natural class of polygons with axis-parallel edges and integer vertices (i.e., polyominoes), highlighting the relevance of turn-cost minimization for Lawn Mowing tours, and leading to a general construction method for feasible tours. (3) We show that this construction method achieves theoretical worst-case guarantees that improve previous approximation factors for polyominoes. (4) We demonstrate the practical usefulness \\emph{beyond polyominoes} by performing an extensive practical study on a spectrum of more general benchmark polygons: We obtain solutions that are better than the previous best values by Fekete et al., for instance sizes up to $20$ times larger.","sentences":["For a given polygonal region $P$, the Lawn Mowing Problem (LMP) asks for a shortest tour $T$ that gets within Euclidean distance 1/2 of every point in $P$; this is equivalent to computing a shortest tour for a unit-diameter cutter $C$ that covers all of $P$. As a generalization of the Traveling Salesman Problem, the LMP is NP-hard; unlike the discrete TSP, however, the LMP has defied efforts to achieve exact solutions, due to its combination of combinatorial complexity with continuous geometry.   ","We provide a number of new contributions that provide insights into the involved difficulties, as well as positive results that enable both theoretical and practical progress.","(1) We show that the LMP is algebraically hard: it is not solvable by radicals over the field of rationals, even for the simple case in which $P$ is a $2\\times 2$ square.","This implies that it is impossible to compute exact optimal solutions under models of computation that rely on elementary arithmetic operations and the extraction of $k$th roots, and explains the perceived practical difficulty.","(2) We exploit this algebraic analysis for the natural class of polygons with axis-parallel edges and integer vertices (i.e., polyominoes), highlighting the relevance of turn-cost minimization for Lawn Mowing tours, and leading to a general construction method for feasible tours.","(3) We show that this construction method achieves theoretical worst-case guarantees that improve previous approximation factors for polyominoes.","(4) We demonstrate the practical usefulness \\emph{beyond polyominoes} by performing an extensive practical study on a spectrum of more general benchmark polygons: We obtain solutions that are better than the previous best values by Fekete et al., for instance sizes up to $20$ times larger."],"url":"http://arxiv.org/abs/2307.01092v1"}
{"created":"2023-07-03 15:09:32","title":"UW-ProCCaps: UnderWater Progressive Colourisation with Capsules","abstract":"Underwater images are fundamental for studying and understanding the status of marine life. We focus on reducing the memory space required for image storage while the memory space consumption in the collecting phase limits the time lasting of this phase leading to the need for more image collection campaigns. We present a novel machine-learning model that reconstructs the colours of underwater images from their luminescence channel, thus saving 2/3 of the available storage space. Our model specialises in underwater colour reconstruction and consists of an encoder-decoder architecture. The encoder is composed of a convolutional encoder and a parallel specialised classifier trained with webly-supervised data. The encoder and the decoder use layers of capsules to capture the features of the entities in the image. The colour reconstruction process recalls the progressive and the generative adversarial training procedures. The progressive training gives the ground for a generative adversarial routine focused on the refining of colours giving the image bright and saturated colours which bring the image back to life. We validate the model both qualitatively and quantitatively on four benchmark datasets. This is the first attempt at colour reconstruction in greyscale underwater images. Extensive results on four benchmark datasets demonstrate that our solution outperforms state-of-the-art (SOTA) solutions. We also demonstrate that the generated colourisation enhances the quality of images compared to enhancement models at the SOTA.","sentences":["Underwater images are fundamental for studying and understanding the status of marine life.","We focus on reducing the memory space required for image storage while the memory space consumption in the collecting phase limits the time lasting of this phase leading to the need for more image collection campaigns.","We present a novel machine-learning model that reconstructs the colours of underwater images from their luminescence channel, thus saving 2/3 of the available storage space.","Our model specialises in underwater colour reconstruction and consists of an encoder-decoder architecture.","The encoder is composed of a convolutional encoder and a parallel specialised classifier trained with webly-supervised data.","The encoder and the decoder use layers of capsules to capture the features of the entities in the image.","The colour reconstruction process recalls the progressive and the generative adversarial training procedures.","The progressive training gives the ground for a generative adversarial routine focused on the refining of colours giving the image bright and saturated colours which bring the image back to life.","We validate the model both qualitatively and quantitatively on four benchmark datasets.","This is the first attempt at colour reconstruction in greyscale underwater images.","Extensive results on four benchmark datasets demonstrate that our solution outperforms state-of-the-art (SOTA) solutions.","We also demonstrate that the generated colourisation enhances the quality of images compared to enhancement models at the SOTA."],"url":"http://arxiv.org/abs/2307.01091v1"}
{"created":"2023-07-03 15:08:28","title":"Empirically Validating Conformal Prediction on Modern Vision Architectures Under Distribution Shift and Long-tailed Data","abstract":"Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees. Yet, its performance is known to degrade under distribution shift and long-tailed class distributions, which are often present in real world applications. Here, we characterize the performance of several post-hoc and training-based conformal prediction methods under these settings, providing the first empirical evaluation on large-scale datasets and models. We show that across numerous conformal methods and neural network families, performance greatly degrades under distribution shifts violating safety guarantees. Similarly, we show that in long-tailed settings the guarantees are frequently violated on many classes. Understanding the limitations of these methods is necessary for deployment in real world and safety-critical applications.","sentences":["Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees.","Yet, its performance is known to degrade under distribution shift and long-tailed class distributions, which are often present in real world applications.","Here, we characterize the performance of several post-hoc and training-based conformal prediction methods under these settings, providing the first empirical evaluation on large-scale datasets and models.","We show that across numerous conformal methods and neural network families, performance greatly degrades under distribution shifts violating safety guarantees.","Similarly, we show that in long-tailed settings the guarantees are frequently violated on many classes.","Understanding the limitations of these methods is necessary for deployment in real world and safety-critical applications."],"url":"http://arxiv.org/abs/2307.01088v1"}
{"created":"2023-07-03 15:07:10","title":"Some challenges of calibrating differentiable agent-based models","abstract":"Agent-based models (ABMs) are a promising approach to modelling and reasoning about complex systems, yet their application in practice is impeded by their complexity, discrete nature, and the difficulty of performing parameter inference and optimisation tasks. This in turn has sparked interest in the construction of differentiable ABMs as a strategy for combatting these difficulties, yet a number of challenges remain. In this paper, we discuss and present experiments that highlight some of these challenges, along with potential solutions.","sentences":["Agent-based models (ABMs) are a promising approach to modelling and reasoning about complex systems, yet their application in practice is impeded by their complexity, discrete nature, and the difficulty of performing parameter inference and optimisation tasks.","This in turn has sparked interest in the construction of differentiable ABMs as a strategy for combatting these difficulties, yet a number of challenges remain.","In this paper, we discuss and present experiments that highlight some of these challenges, along with potential solutions."],"url":"http://arxiv.org/abs/2307.01085v1"}
{"created":"2023-07-03 14:58:28","title":"Meaning and identity of proofs in a bilateralist setting: A two-sorted typed lambda-calculus for proofs and refutations","abstract":"In this paper I will develop a lambda-term calculus, lambda-2Int, for a bi-intuitionistic logic and discuss its implications for the notions of sense and denotation of derivations in a bilateralist setting. Thus, I will use the Curry-Howard correspondence, which has been well-established between the simply typed lambda-calculus and natural deduction systems for intuitionistic logic, and apply it to a bilateralist proof system displaying two derivability relations, one for proving and one for refuting. The basis will be the natural deduction system of Wansing's bi-intuitionistic logic 2Int (2016a; 2017), which I will turn into a term-annotated form. Therefore, we need a type theory that extends to a two-sorted typed lambda-calculus. I will present such a term-annotated proof system for 2Int and prove some properties and results for it, most importantly for this paper a Dualization Theorem relating proofs and refutations in this system. On the basis of these formal results I will argue that this gives us interesting insights into questions about sense and denotation as well as synonymy and identity of proofs from a bilateralist point of view.","sentences":["In this paper I will develop a lambda-term calculus, lambda-2Int, for a bi-intuitionistic logic and discuss its implications for the notions of sense and denotation of derivations in a bilateralist setting.","Thus, I will use the Curry-Howard correspondence, which has been well-established between the simply typed lambda-calculus and natural deduction systems for intuitionistic logic, and apply it to a bilateralist proof system displaying two derivability relations, one for proving and one for refuting.","The basis will be the natural deduction system of Wansing's bi-intuitionistic logic 2Int (2016a; 2017), which I will turn into a term-annotated form.","Therefore, we need a type theory that extends to a two-sorted typed lambda-calculus.","I will present such a term-annotated proof system for 2Int and prove some properties and results for it, most importantly for this paper a Dualization Theorem relating proofs and refutations in this system.","On the basis of these formal results I will argue that this gives us interesting insights into questions about sense and denotation as well as synonymy and identity of proofs from a bilateralist point of view."],"url":"http://arxiv.org/abs/2307.01079v1"}
{"created":"2023-07-03 14:55:02","title":"Analyzing Multiple-Choice Reading and Listening Comprehension Tests","abstract":"Multiple-choice reading and listening comprehension tests are an important part of language assessment. Content creators for standard educational tests need to carefully curate questions that assess the comprehension abilities of candidates taking the tests. However, recent work has shown that a large number of questions in general multiple-choice reading comprehension datasets can be answered without comprehension, by leveraging world knowledge instead. This work investigates how much of a contextual passage needs to be read in multiple-choice reading based on conversation transcriptions and listening comprehension tests to be able to work out the correct answer. We find that automated reading comprehension systems can perform significantly better than random with partial or even no access to the context passage. These findings offer an approach for content creators to automatically capture the trade-off between comprehension and world knowledge required for their proposed questions.","sentences":["Multiple-choice reading and listening comprehension tests are an important part of language assessment.","Content creators for standard educational tests need to carefully curate questions that assess the comprehension abilities of candidates taking the tests.","However, recent work has shown that a large number of questions in general multiple-choice reading comprehension datasets can be answered without comprehension, by leveraging world knowledge instead.","This work investigates how much of a contextual passage needs to be read in multiple-choice reading based on conversation transcriptions and listening comprehension tests to be able to work out the correct answer.","We find that automated reading comprehension systems can perform significantly better than random with partial or even no access to the context passage.","These findings offer an approach for content creators to automatically capture the trade-off between comprehension and world knowledge required for their proposed questions."],"url":"http://arxiv.org/abs/2307.01076v1"}
{"created":"2023-07-03 14:54:13","title":"When Can Linear Learners be Robust to Indiscriminate Poisoning Attacks?","abstract":"We study indiscriminate poisoning for linear learners where an adversary injects a few crafted examples into the training data with the goal of forcing the induced model to incur higher test error. Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners. For theoretical Gaussian distributions, we rigorously characterize the behavior of an optimal poisoning attack, defined as the poisoning strategy that attains the maximum risk of the induced model at a given poisoning budget. Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small. These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks.","sentences":["We study indiscriminate poisoning for linear learners where an adversary injects a few crafted examples into the training data with the goal of forcing the induced model to incur higher test error.","Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners.","For theoretical Gaussian distributions, we rigorously characterize the behavior of an optimal poisoning attack, defined as the poisoning strategy that attains the maximum risk of the induced model at a given poisoning budget.","Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small.","These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks."],"url":"http://arxiv.org/abs/2307.01073v1"}
{"created":"2023-07-03 14:53:41","title":"Scenario-Based Motion Planning with Bounded Probability of Collision","abstract":"Robots will increasingly operate near humans that introduce uncertainties in the motion planning problem due to their complex nature. Typically, chance constraints are introduced in the planner to optimize performance while guaranteeing probabilistic safety. However, existing methods do not consider the actual probability of collision for the planned trajectory, but rather its marginalization, that is, the independent collision probabilities for each planning step and/or dynamic obstacle, resulting in conservative trajectories. To address this issue, we introduce a novel real-time capable method termed Safe Horizon MPC, that explicitly constrains the joint probability of collision with all obstacles over the duration of the motion plan. This is achieved by reformulating the chance-constrained planning problem using scenario optimization and predictive control. Our method is less conservative than state-of-the-art approaches, applicable to arbitrary probability distributions of the obstacles' trajectories, computationally tractable and scalable. We demonstrate our proposed approach using a mobile robot and an autonomous vehicle in an environment shared with humans.","sentences":["Robots will increasingly operate near humans that introduce uncertainties in the motion planning problem due to their complex nature.","Typically, chance constraints are introduced in the planner to optimize performance while guaranteeing probabilistic safety.","However, existing methods do not consider the actual probability of collision for the planned trajectory, but rather its marginalization, that is, the independent collision probabilities for each planning step and/or dynamic obstacle, resulting in conservative trajectories.","To address this issue, we introduce a novel real-time capable method termed Safe Horizon MPC, that explicitly constrains the joint probability of collision with all obstacles over the duration of the motion plan.","This is achieved by reformulating the chance-constrained planning problem using scenario optimization and predictive control.","Our method is less conservative than state-of-the-art approaches, applicable to arbitrary probability distributions of the obstacles' trajectories, computationally tractable and scalable.","We demonstrate our proposed approach using a mobile robot and an autonomous vehicle in an environment shared with humans."],"url":"http://arxiv.org/abs/2307.01070v1"}
{"created":"2023-07-03 14:50:14","title":"Shi-NeSS: Detecting Good and Stable Keypoints with a Neural Stability Score","abstract":"Learning a feature point detector presents a challenge both due to the ambiguity of the definition of a keypoint and correspondingly the need for a specially prepared ground truth labels for such points. In our work, we address both of these issues by utilizing a combination of a hand-crafted Shi detector and a neural network. We build on the principled and localized keypoints provided by the Shi detector and perform their selection using the keypoint stability score regressed by the neural network - Neural Stability Score (NeSS). Therefore, our method is named Shi-NeSS since it combines the Shi detector and the properties of the keypoint stability score, and it only requires for training sets of images without dataset pre-labeling or the need for reconstructed correspondence labels. We evaluate Shi-NeSS on HPatches, ScanNet, MegaDepth and IMC-PT, demonstrating state-of-the-art performance and good generalization on downstream tasks.","sentences":["Learning a feature point detector presents a challenge both due to the ambiguity of the definition of a keypoint and correspondingly the need for a specially prepared ground truth labels for such points.","In our work, we address both of these issues by utilizing a combination of a hand-crafted Shi detector and a neural network.","We build on the principled and localized keypoints provided by the Shi detector and perform their selection using the keypoint stability score regressed by the neural network - Neural Stability Score (NeSS).","Therefore, our method is named Shi-NeSS since it combines the Shi detector and the properties of the keypoint stability score, and it only requires for training sets of images without dataset pre-labeling or the need for reconstructed correspondence labels.","We evaluate Shi-NeSS on HPatches, ScanNet, MegaDepth and IMC-PT, demonstrating state-of-the-art performance and good generalization on downstream tasks."],"url":"http://arxiv.org/abs/2307.01069v1"}
{"created":"2023-07-03 14:47:18","title":"Localized Questions in Medical Visual Question Answering","abstract":"Visual Question Answering (VQA) models aim to answer natural language questions about given images. Due to its ability to ask questions that differ from those used when training the model, medical VQA has received substantial attention in recent years. However, existing medical VQA models typically focus on answering questions that refer to an entire image rather than where the relevant content may be located in the image. Consequently, VQA models are limited in their interpretability power and the possibility to probe the model about specific image regions. This paper proposes a novel approach for medical VQA that addresses this limitation by developing a model that can answer questions about image regions while considering the context necessary to answer the questions. Our experimental results demonstrate the effectiveness of our proposed model, outperforming existing methods on three datasets. Our code and data are available at https://github.com/sergiotasconmorales/locvqa.","sentences":["Visual Question Answering (VQA) models aim to answer natural language questions about given images.","Due to its ability to ask questions that differ from those used when training the model, medical VQA has received substantial attention in recent years.","However, existing medical VQA models typically focus on answering questions that refer to an entire image rather than where the relevant content may be located in the image.","Consequently, VQA models are limited in their interpretability power and the possibility to probe the model about specific image regions.","This paper proposes a novel approach for medical VQA that addresses this limitation by developing a model that can answer questions about image regions while considering the context necessary to answer the questions.","Our experimental results demonstrate the effectiveness of our proposed model, outperforming existing methods on three datasets.","Our code and data are available at https://github.com/sergiotasconmorales/locvqa."],"url":"http://arxiv.org/abs/2307.01067v1"}
{"created":"2023-07-03 14:43:40","title":"TomatoDIFF: On-plant Tomato Segmentation with Denoising Diffusion Models","abstract":"Artificial intelligence applications enable farmers to optimize crop growth and production while reducing costs and environmental impact. Computer vision-based algorithms in particular, are commonly used for fruit segmentation, enabling in-depth analysis of the harvest quality and accurate yield estimation. In this paper, we propose TomatoDIFF, a novel diffusion-based model for semantic segmentation of on-plant tomatoes. When evaluated against other competitive methods, our model demonstrates state-of-the-art (SOTA) performance, even in challenging environments with highly occluded fruits. Additionally, we introduce Tomatopia, a new, large and challenging dataset of greenhouse tomatoes. The dataset comprises high-resolution RGB-D images and pixel-level annotations of the fruits.","sentences":["Artificial intelligence applications enable farmers to optimize crop growth and production while reducing costs and environmental impact.","Computer vision-based algorithms in particular, are commonly used for fruit segmentation, enabling in-depth analysis of the harvest quality and accurate yield estimation.","In this paper, we propose TomatoDIFF, a novel diffusion-based model for semantic segmentation of on-plant tomatoes.","When evaluated against other competitive methods, our model demonstrates state-of-the-art (SOTA) performance, even in challenging environments with highly occluded fruits.","Additionally, we introduce Tomatopia, a new, large and challenging dataset of greenhouse tomatoes.","The dataset comprises high-resolution RGB-D images and pixel-level annotations of the fruits."],"url":"http://arxiv.org/abs/2307.01064v1"}
{"created":"2023-07-03 14:41:04","title":"Synthesising Full-Information Protocols","abstract":"We lay out a model of games with imperfect information that features explicit communication actions, by which the entire observation history of a player is revealed to another player. Such full-information protocols are common in asynchronous distributed systems; here, we consider a synchronous setting with a single active player who may communicate with multiple passive observers in an indeterminate environment. We present a procedure for solving the basic strategy-synthesis problem under regular winning conditions.   We present our solution in an abstract framework of games with imperfect information and we split the proof in two conceptual parts: (i) a generic reduction schema from imperfect-information to perfect-information games, and (ii) a specific construction for full-information protocols that satisfies the requirement of the reduction schema.","sentences":["We lay out a model of games with imperfect information that features explicit communication actions, by which the entire observation history of a player is revealed to another player.","Such full-information protocols are common in asynchronous distributed systems; here, we consider a synchronous setting with a single active player who may communicate with multiple passive observers in an indeterminate environment.","We present a procedure for solving the basic strategy-synthesis problem under regular winning conditions.   ","We present our solution in an abstract framework of games with imperfect information and we split the proof in two conceptual parts: (i) a generic reduction schema from imperfect-information to perfect-information games, and (ii) a specific construction for full-information protocols that satisfies the requirement of the reduction schema."],"url":"http://arxiv.org/abs/2307.01063v1"}
{"created":"2023-07-03 14:41:02","title":"A Data-Driven Approach to Geometric Modeling of Systems with Low-Bandwidth Actuator Dynamics","abstract":"It is challenging to perform identification on soft robots due to their underactuated, high dimensional dynamics. In this work, we present a data-driven modeling framework, based on geometric mechanics (also known as gauge theory), that can be applied to systems with low-bandwidth actuation of the shape space. By exploiting temporal asymmetries in actuator dynamics, our approach enables the design of robots that can be driven by a single control input. We present a method for constructing a series connected model comprising actuator and locomotor dynamics based on data points from stochastically perturbed, repeated behaviors around the observed limit cycle. We demonstrate our methods on a real-world example of a soft crawler made by stimuli-responsive hydrogels that locomotes on merely one cycling control signal by utilizing its geometric and temporal asymmetry. For systems with first-order, low-pass actuator dynamics, such as swelling-driven actuators used in hydrogel crawlers, we show that first order Taylor approximations can well capture the dynamics of the system shape as well as its movements. Finally, we propose an approach of numerically optimizing control signals by iteratively refining models and optimizing the input waveform.","sentences":["It is challenging to perform identification on soft robots due to their underactuated, high dimensional dynamics.","In this work, we present a data-driven modeling framework, based on geometric mechanics (also known as gauge theory), that can be applied to systems with low-bandwidth actuation of the shape space.","By exploiting temporal asymmetries in actuator dynamics, our approach enables the design of robots that can be driven by a single control input.","We present a method for constructing a series connected model comprising actuator and locomotor dynamics based on data points from stochastically perturbed, repeated behaviors around the observed limit cycle.","We demonstrate our methods on a real-world example of a soft crawler made by stimuli-responsive hydrogels that locomotes on merely one cycling control signal by utilizing its geometric and temporal asymmetry.","For systems with first-order, low-pass actuator dynamics, such as swelling-driven actuators used in hydrogel crawlers, we show that first order Taylor approximations can well capture the dynamics of the system shape as well as its movements.","Finally, we propose an approach of numerically optimizing control signals by iteratively refining models and optimizing the input waveform."],"url":"http://arxiv.org/abs/2307.01062v1"}
{"created":"2023-07-03 14:35:24","title":"A 3 TOPS/W RISC-V Parallel Cluster for Inference of Fine-Grain Mixed-Precision Quantized Neural Networks","abstract":"The emerging trend of deploying complex algorithms, such as Deep Neural Networks (DNNs), increasingly poses strict memory and energy efficiency requirements on Internet-of-Things (IoT) end-nodes. Mixed-precision quantization has been proposed as a technique to minimize a DNN's memory footprint and maximize its execution efficiency, with negligible end-to-end precision degradation. In this work, we present a novel hardware and software stack for energy-efficient inference of mixed-precision Quantized Neural Networks (QNNs). We introduce Flex-V, a processor based on the RISC-V Instruction Set Architecture (ISA) that features fused Mac&Load mixed-precision dot product instructions; to avoid the exponential growth of the encoding space due to mixed-precision variants, we encode formats into the Control-Status Registers (CSRs). Flex-V core is integrated into a tightly-coupled cluster of eight processors; in addition, we provide a full framework for the end-to-end deployment of DNNs including a compiler, optimized libraries, and a memory-aware deployment flow. Our results show up to 91.5 MAC/cycle and 3.26 TOPS/W on the cluster, implemented in a commercial 22nm FDX technology, with up to 8.5x speed-up, and an area overhead of only 5.6% with respect to the baseline. To demonstrate the capabilities of the architecture, we benchmark it with end-to-end real-life QNNs, improving performance by 2x - 2.5x with respect to existing solutions using fully flexible programmable processors.","sentences":["The emerging trend of deploying complex algorithms, such as Deep Neural Networks (DNNs), increasingly poses strict memory and energy efficiency requirements on Internet-of-Things (IoT) end-nodes.","Mixed-precision quantization has been proposed as a technique to minimize a DNN's memory footprint and maximize its execution efficiency, with negligible end-to-end precision degradation.","In this work, we present a novel hardware and software stack for energy-efficient inference of mixed-precision Quantized Neural Networks (QNNs).","We introduce Flex-V, a processor based on the RISC-V Instruction Set Architecture (ISA) that features fused Mac&Load mixed-precision dot product instructions; to avoid the exponential growth of the encoding space due to mixed-precision variants, we encode formats into the Control-Status Registers (CSRs).","Flex-V core is integrated into a tightly-coupled cluster of eight processors; in addition, we provide a full framework for the end-to-end deployment of DNNs including a compiler, optimized libraries, and a memory-aware deployment flow.","Our results show up to 91.5 MAC/cycle and 3.26 TOPS/W on the cluster, implemented in a commercial 22nm FDX technology, with up to 8.5x speed-up, and an area overhead of only 5.6% with respect to the baseline.","To demonstrate the capabilities of the architecture, we benchmark it with end-to-end real-life QNNs, improving performance by 2x - 2.5x with respect to existing solutions using fully flexible programmable processors."],"url":"http://arxiv.org/abs/2307.01056v1"}
{"created":"2023-07-03 14:33:14","title":"ENGAGE: Explanation Guided Data Augmentation for Graph Representation Learning","abstract":"The recent contrastive learning methods, due to their effectiveness in representation learning, have been widely applied to modeling graph data. Random perturbation is widely used to build contrastive views for graph data, which however, could accidentally break graph structures and lead to suboptimal performance. In addition, graph data is usually highly abstract, so it is hard to extract intuitive meanings and design more informed augmentation schemes. Effective representations should preserve key characteristics in data and abandon superfluous information. In this paper, we propose ENGAGE (ExplaNation Guided data AuGmEntation), where explanation guides the contrastive augmentation process to preserve the key parts in graphs and explore removing superfluous information. Specifically, we design an efficient unsupervised explanation method called smoothed activation map as the indicator of node importance in representation learning. Then, we design two data augmentation schemes on graphs for perturbing structural and feature information, respectively. We also provide justification for the proposed method in the framework of information theories. Experiments of both graph-level and node-level tasks, on various model architectures and on different real-world graphs, are conducted to demonstrate the effectiveness and flexibility of ENGAGE. The code of ENGAGE can be found: https://github.com/sycny/ENGAGE.","sentences":["The recent contrastive learning methods, due to their effectiveness in representation learning, have been widely applied to modeling graph data.","Random perturbation is widely used to build contrastive views for graph data, which however, could accidentally break graph structures and lead to suboptimal performance.","In addition, graph data is usually highly abstract, so it is hard to extract intuitive meanings and design more informed augmentation schemes.","Effective representations should preserve key characteristics in data and abandon superfluous information.","In this paper, we propose ENGAGE (ExplaNation Guided data AuGmEntation), where explanation guides the contrastive augmentation process to preserve the key parts in graphs and explore removing superfluous information.","Specifically, we design an efficient unsupervised explanation method called smoothed activation map as the indicator of node importance in representation learning.","Then, we design two data augmentation schemes on graphs for perturbing structural and feature information, respectively.","We also provide justification for the proposed method in the framework of information theories.","Experiments of both graph-level and node-level tasks, on various model architectures and on different real-world graphs, are conducted to demonstrate the effectiveness and flexibility of ENGAGE.","The code of ENGAGE can be found: https://github.com/sycny/ENGAGE."],"url":"http://arxiv.org/abs/2307.01053v1"}
{"created":"2023-07-03 14:24:04","title":"Cross-modal Place Recognition in Image Databases using Event-based Sensors","abstract":"Visual place recognition is an important problem towards global localization in many robotics tasks. One of the biggest challenges is that it may suffer from illumination or appearance changes in surrounding environments. Event cameras are interesting alternatives to frame-based sensors as their high dynamic range enables robust perception in difficult illumination conditions. However, current event-based place recognition methods only rely on event information, which restricts downstream applications of VPR. In this paper, we present the first cross-modal visual place recognition framework that is capable of retrieving regular images from a database given an event query. Our method demonstrates promising results with respect to the state-of-the-art frame-based and event-based methods on the Brisbane-Event-VPR dataset under different scenarios. We also verify the effectiveness of the combination of retrieval and classification, which can boost performance by a large margin.","sentences":["Visual place recognition is an important problem towards global localization in many robotics tasks.","One of the biggest challenges is that it may suffer from illumination or appearance changes in surrounding environments.","Event cameras are interesting alternatives to frame-based sensors as their high dynamic range enables robust perception in difficult illumination conditions.","However, current event-based place recognition methods only rely on event information, which restricts downstream applications of VPR.","In this paper, we present the first cross-modal visual place recognition framework that is capable of retrieving regular images from a database given an event query.","Our method demonstrates promising results with respect to the state-of-the-art frame-based and event-based methods on the Brisbane-Event-VPR dataset under different scenarios.","We also verify the effectiveness of the combination of retrieval and classification, which can boost performance by a large margin."],"url":"http://arxiv.org/abs/2307.01047v1"}
{"created":"2023-07-03 14:23:47","title":"A Fine-Grained Classification of the Complexity of Evaluating the Tutte Polynomial on Integer Points Parameterized by Treewidth and Cutwidth","abstract":"We give a fine-grained classification of evaluating the Tutte polynomial $T(G;x,y)$ on all integer points on graphs with small treewidth and cutwidth. Specifically, we show for any point $(x,y) \\in \\mathbb{Z}^2$ that either   - can be computed in polynomial time,   - can be computed in $2^{O(tw)}n^{O(1)}$ time, but not in $2^{o(ctw)}n^{O(1)}$ time assuming the Exponential Time Hypothesis (ETH),   - can be computed in $2^{O(tw \\log tw)}n^{O(1)}$ time, but not in $2^{o(ctw \\log ctw)}n^{O(1)}$ time assuming the ETH,   where we assume tree decompositions of treewidth $tw$ and cutwidth decompositions of cutwidth $ctw$ are given as input along with the input graph on $n$ vertices and point $(x,y)$.   To obtain these results, we refine the existing reductions that were instrumental for the seminal dichotomy by Jaeger, Welsh and Vertigan~[Math. Proc. Cambridge Philos. Soc'90].   One of our technical contributions is a new rank bound of a matrix that indicates whether the union of two forests is a forest itself, which we use to show that the number of forests of a graph can be counted in $2^{O(tw)}n^{O(1)}$ time.","sentences":["We give a fine-grained classification of evaluating the Tutte polynomial $T(G;x,y)$ on all integer points on graphs with small treewidth and cutwidth.","Specifically, we show for any point $(x,y) \\in \\mathbb{Z}^2$ that either   - can be computed in polynomial time,   - can be computed in $2^{O(tw)}n^{O(1)}$ time, but not in $2^{o(ctw)}n^{O(1)}$ time assuming the Exponential Time Hypothesis (ETH),   - can be computed in $2^{O(tw \\log tw)}n^{O(1)}$ time, but not in $2^{o(ctw \\log ctw)}n^{O(1)}$ time assuming the ETH,   where we assume tree decompositions of treewidth $tw$ and cutwidth decompositions of cutwidth $ctw$ are given as input along with the input graph on $n$ vertices and point $(x,y)$.   To obtain these results, we refine the existing reductions that were instrumental for the seminal dichotomy by Jaeger, Welsh and Vertigan~[Math.","Proc.","Cambridge Philos.","Soc'90].   ","One of our technical contributions is a new rank bound of a matrix that indicates whether the union of two forests is a forest itself, which we use to show that the number of forests of a graph can be counted in $2^{O(tw)}n^{O(1)}$ time."],"url":"http://arxiv.org/abs/2307.01046v1"}
{"created":"2023-07-03 14:22:05","title":"Cloud Native Software Engineering","abstract":"Cloud compute adoption has been growing since its inception in the early 2000's with estimates that the size of this market in terms of worldwide spend will increase from \\$700 billion in 2021 to \\$1.3 trillion in 2025. While there is a significant research activity in many areas of cloud computing technologies, we see little attention being paid to advancing software engineering practices needed to support the current and next generation of cloud native applications. By cloud native, we mean software that is designed and built specifically for deployment to a modern cloud platform. This paper frames the landscape of Cloud Native Software Engineering from a practitioners standpoint, and identifies several software engineering research opportunities that should be investigated. We cover specific engineering challenges associated with software architectures commonly used in cloud applications along with incremental challenges that are expected with emerging IoT/Edge computing use cases.","sentences":["Cloud compute adoption has been growing since its inception in the early 2000's with estimates that the size of this market in terms of worldwide spend will increase from \\$700 billion in 2021 to \\$1.3 trillion in 2025.","While there is a significant research activity in many areas of cloud computing technologies, we see little attention being paid to advancing software engineering practices needed to support the current and next generation of cloud native applications.","By cloud native, we mean software that is designed and built specifically for deployment to a modern cloud platform.","This paper frames the landscape of Cloud Native Software Engineering from a practitioners standpoint, and identifies several software engineering research opportunities that should be investigated.","We cover specific engineering challenges associated with software architectures commonly used in cloud applications along with incremental challenges that are expected with emerging IoT/Edge computing use cases."],"url":"http://arxiv.org/abs/2307.01045v1"}
{"created":"2023-07-03 14:20:15","title":"Practical Non-Invasive Probing Attacks Against Novel Carbon-Nanotube-Based Physical Unclonable Functions","abstract":"As the number of devices being interconnected increases, so does also the demand for (lightweight) security. To this end, Physical Unclonable Functions (PUFs) have been proposed as hardware primitives that can act as roots of trust and security. Recently, a new type of PUF based on Carbon NanoTubes (CNTs) has been proposed. At the same time, attacks and testing based on direct electrical probing appear to be moving towards non-invasive techniques. In this context, this work attempts to examine the potential for practical non-invasive probing attacks against the CNT-PUF, a novel PUF based on CNTs. Our results indicate that direct probing might potentially compromise the security of this PUF. Nevertheless, we note that this holds true only in the case that the attacker can directly probe the wire corresponding to the secret value of each CNT-PUF cell. Thus, we can conclude that the examined CNT-PUFs are rather resilient to direct probing attacks, that non-invasive probing methods appear to be promising for testing such PUFs, and that, in order for the attacker to gain the full-length value of the secret, all the relevant channels would need to be probed. Nevertheless, as our work proves, practical non-invasive attacks against the CNT-PUF are feasible and adequate countermeasures need to be employed in order to address this issue.","sentences":["As the number of devices being interconnected increases, so does also the demand for (lightweight) security.","To this end, Physical Unclonable Functions (PUFs) have been proposed as hardware primitives that can act as roots of trust and security.","Recently, a new type of PUF based on Carbon NanoTubes (CNTs) has been proposed.","At the same time, attacks and testing based on direct electrical probing appear to be moving towards non-invasive techniques.","In this context, this work attempts to examine the potential for practical non-invasive probing attacks against the CNT-PUF, a novel PUF based on CNTs.","Our results indicate that direct probing might potentially compromise the security of this PUF.","Nevertheless, we note that this holds true only in the case that the attacker can directly probe the wire corresponding to the secret value of each CNT-PUF cell.","Thus, we can conclude that the examined CNT-PUFs are rather resilient to direct probing attacks, that non-invasive probing methods appear to be promising for testing such PUFs, and that, in order for the attacker to gain the full-length value of the secret, all the relevant channels would need to be probed.","Nevertheless, as our work proves, practical non-invasive attacks against the CNT-PUF are feasible and adequate countermeasures need to be employed in order to address this issue."],"url":"http://arxiv.org/abs/2307.01041v1"}
{"created":"2023-07-03 14:01:24","title":"Advancing O-RAN to Facilitate Intelligence in V2X","abstract":"Vehicular communications at high frequencies are envisioned to be a breakthrough application for the 6G cellular systems. Traditional Radio Access Networks (RANs) lack the flexibility to enable sophisticated control mechanisms that are demanded by the strict performance requirements of the dynamic vehicular environment. In contrast, the features of Open RAN (O-RAN) can be exploited to support advanced use cases. Indeed, the emerging paradigm of O-RAN represents an ideal framework for the orchestration of vehicular communication. Although the high potential stemming from their integration can be easily seen and recognized, the effective combination of the two ecosystems is an open issue. This article pioneers the integration of the two strategies for seamlessly incorporating vehicle-to-everything (V2X) control within O-RAN's ecosystem. We propose and discuss an enabling architecture that tightly integrates V2X and O-RAN. In the proposed solution, an O-RAN-based control plane operates at low frequencies to achieve reliable and efficient connectivity among autonomous vehicles at higher frequencies. The technological feasibility of this integrated architecture is investigated. A detailed case study is presented and analyzed to demonstrate the design of an xApp to showcase a practical example of O-RAN solution for a specific V2X scenario.","sentences":["Vehicular communications at high frequencies are envisioned to be a breakthrough application for the 6G cellular systems.","Traditional Radio Access Networks (RANs) lack the flexibility to enable sophisticated control mechanisms that are demanded by the strict performance requirements of the dynamic vehicular environment.","In contrast, the features of Open RAN (O-RAN) can be exploited to support advanced use cases.","Indeed, the emerging paradigm of O-RAN represents an ideal framework for the orchestration of vehicular communication.","Although the high potential stemming from their integration can be easily seen and recognized, the effective combination of the two ecosystems is an open issue.","This article pioneers the integration of the two strategies for seamlessly incorporating vehicle-to-everything (V2X) control within O-RAN's ecosystem.","We propose and discuss an enabling architecture that tightly integrates V2X and O-RAN.","In the proposed solution, an O-RAN-based control plane operates at low frequencies to achieve reliable and efficient connectivity among autonomous vehicles at higher frequencies.","The technological feasibility of this integrated architecture is investigated.","A detailed case study is presented and analyzed to demonstrate the design of an xApp to showcase a practical example of O-RAN solution for a specific V2X scenario."],"url":"http://arxiv.org/abs/2307.01029v1"}
{"created":"2023-07-03 13:58:20","title":"Temporal Graph Benchmark for Machine Learning on Temporal Graphs","abstract":"We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on temporal graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, experiment setup and performance evaluation. TGB will be maintained and updated on a regular basis and welcomes community feedback. TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/ .","sentences":["We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs.","TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks.","For both tasks, we design evaluation protocols based on realistic use-cases.","We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets.","In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models.","We believe that these findings open up opportunities for future research on temporal graphs.","Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, experiment setup and performance evaluation.","TGB will be maintained and updated on a regular basis and welcomes community feedback.","TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/ ."],"url":"http://arxiv.org/abs/2307.01026v1"}
{"created":"2023-07-03 13:55:44","title":"SAM-DA: UAV Tracks Anything at Night with SAM-Powered Domain Adaptation","abstract":"Domain adaptation (DA) has demonstrated significant promise for real-time nighttime unmanned aerial vehicle (UAV) tracking. However, the state-of-the-art (SOTA) DA still lacks the potential object with accurate pixel-level location and boundary to generate the high-quality target domain training sample. This key issue constrains the transfer learning of the real-time daytime SOTA trackers for challenging nighttime UAV tracking. Recently, the notable Segment Anything Model (SAM) has achieved remarkable zero-shot generalization ability to discover abundant potential objects due to its huge data-driven training approach. To solve the aforementioned issue, this work proposes a novel SAM-powered DA framework for real-time nighttime UAV tracking, i.e., SAM-DA. Specifically, an innovative SAM-powered target domain training sample swelling is designed to determine enormous high-quality target domain training samples from every single raw nighttime image. This novel one-to-many method significantly expands the high-quality target domain training sample for DA. Comprehensive experiments on extensive nighttime UAV videos prove the robustness and domain adaptability of SAM-DA for nighttime UAV tracking. Especially, compared to the SOTA DA, SAM-DA can achieve better performance with fewer raw nighttime images, i.e., the fewer-better training. This economized training approach facilitates the quick validation and deployment of algorithms for UAVs. The code is available at https://github.com/vision4robotics/SAM-DA.","sentences":["Domain adaptation (DA) has demonstrated significant promise for real-time nighttime unmanned aerial vehicle (UAV) tracking.","However, the state-of-the-art (SOTA) DA still lacks the potential object with accurate pixel-level location and boundary to generate the high-quality target domain training sample.","This key issue constrains the transfer learning of the real-time daytime SOTA trackers for challenging nighttime UAV tracking.","Recently, the notable Segment Anything Model (SAM) has achieved remarkable zero-shot generalization ability to discover abundant potential objects due to its huge data-driven training approach.","To solve the aforementioned issue, this work proposes a novel SAM-powered DA framework for real-time nighttime UAV tracking, i.e., SAM-DA.","Specifically, an innovative SAM-powered target domain training sample swelling is designed to determine enormous high-quality target domain training samples from every single raw nighttime image.","This novel one-to-many method significantly expands the high-quality target domain training sample for DA.","Comprehensive experiments on extensive nighttime UAV videos prove the robustness and domain adaptability of SAM-DA for nighttime UAV tracking.","Especially, compared to the SOTA DA, SAM-DA can achieve better performance with fewer raw nighttime images, i.e., the fewer-better training.","This economized training approach facilitates the quick validation and deployment of algorithms for UAVs.","The code is available at https://github.com/vision4robotics/SAM-DA."],"url":"http://arxiv.org/abs/2307.01024v1"}
{"created":"2023-07-03 13:54:50","title":"Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future and Past Trends in Time Series Data","abstract":"This work introduces Neural Chronos Ordinary Differential Equations (Neural CODE), a deep neural network architecture that fits a continuous-time ODE dynamics for predicting the chronology of a system both forward and backward in time. To train the model, we solve the ODE as an initial value problem and a final value problem, similar to Neural ODEs. We also explore two approaches to combining Neural CODE with Recurrent Neural Networks by replacing Neural ODE with Neural CODE (CODE-RNN), and incorporating a bidirectional RNN for full information flow in both time directions (CODE-BiRNN), and variants with other update cells namely GRU and LSTM: CODE-GRU, CODE-BiGRU, CODE-LSTM, CODE-BiLSTM.   Experimental results demonstrate that Neural CODE outperforms Neural ODE in learning the dynamics of a spiral forward and backward in time, even with sparser data. We also compare the performance of CODE-RNN/-GRU/-LSTM and CODE-BiRNN/-BiGRU/-BiLSTM against ODE-RNN/-GRU/-LSTM on three real-life time series data tasks: imputation of missing data for lower and higher dimensional data, and forward and backward extrapolation with shorter and longer time horizons. Our findings show that the proposed architectures converge faster, with CODE-BiRNN/-BiGRU/-BiLSTM consistently outperforming the other architectures on all tasks.","sentences":["This work introduces Neural Chronos Ordinary Differential Equations (Neural CODE), a deep neural network architecture that fits a continuous-time ODE dynamics for predicting the chronology of a system both forward and backward in time.","To train the model, we solve the ODE as an initial value problem and a final value problem, similar to Neural ODEs.","We also explore two approaches to combining Neural CODE with Recurrent Neural Networks by replacing Neural ODE with Neural CODE (CODE-RNN), and incorporating a bidirectional RNN for full information flow in both time directions (CODE-BiRNN), and variants with other update cells namely GRU and LSTM: CODE-GRU, CODE-BiGRU, CODE-LSTM, CODE-BiLSTM.   ","Experimental results demonstrate that Neural CODE outperforms Neural ODE in learning the dynamics of a spiral forward and backward in time, even with sparser data.","We also compare the performance of CODE-RNN/-GRU/-LSTM and CODE-BiRNN/-BiGRU/-BiLSTM against ODE-RNN/-GRU/-LSTM on three real-life time series data tasks: imputation of missing data for lower and higher dimensional data, and forward and backward extrapolation with shorter and longer time horizons.","Our findings show that the proposed architectures converge faster, with CODE-BiRNN/-BiGRU/-BiLSTM consistently outperforming the other architectures on all tasks."],"url":"http://arxiv.org/abs/2307.01023v1"}
{"created":"2023-07-03 13:49:14","title":"Estimating Post-OCR Denoising Complexity on Numerical Texts","abstract":"Post-OCR processing has significantly improved over the past few years. However, these have been primarily beneficial for texts consisting of natural, alphabetical words, as opposed to documents of numerical nature such as invoices, payslips, medical certificates, etc. To evaluate the OCR post-processing difficulty of these datasets, we propose a method to estimate the denoising complexity of a text and evaluate it on several datasets of varying nature, and show that texts of numerical nature have a significant disadvantage. We evaluate the estimated complexity ranking with respect to the error rates of modern-day denoising approaches to show the validity of our estimator.","sentences":["Post-OCR processing has significantly improved over the past few years.","However, these have been primarily beneficial for texts consisting of natural, alphabetical words, as opposed to documents of numerical nature such as invoices, payslips, medical certificates, etc.","To evaluate the OCR post-processing difficulty of these datasets, we propose a method to estimate the denoising complexity of a text and evaluate it on several datasets of varying nature, and show that texts of numerical nature have a significant disadvantage.","We evaluate the estimated complexity ranking with respect to the error rates of modern-day denoising approaches to show the validity of our estimator."],"url":"http://arxiv.org/abs/2307.01020v1"}
{"created":"2023-07-03 13:45:24","title":"CGAM: Click-Guided Attention Module for Interactive Pathology Image Segmentation via Backpropagating Refinement","abstract":"Tumor region segmentation is an essential task for the quantitative analysis of digital pathology. Recently presented deep neural networks have shown state-of-the-art performance in various image-segmentation tasks. However, because of the unclear boundary between the cancerous and normal regions in pathology images, despite using modern methods, it is difficult to produce satisfactory segmentation results in terms of the reliability and accuracy required for medical data. In this study, we propose an interactive segmentation method that allows users to refine the output of deep neural networks through click-type user interactions. The primary method is to formulate interactive segmentation as an optimization problem that leverages both user-provided click constraints and semantic information in a feature map using a click-guided attention module (CGAM). Unlike other existing methods, CGAM avoids excessive changes in segmentation results, which can lead to the overfitting of user clicks. Another advantage of CGAM is that the model size is independent of input image size. Experimental results on pathology image datasets indicated that our method performs better than existing state-of-the-art methods.","sentences":["Tumor region segmentation is an essential task for the quantitative analysis of digital pathology.","Recently presented deep neural networks have shown state-of-the-art performance in various image-segmentation tasks.","However, because of the unclear boundary between the cancerous and normal regions in pathology images, despite using modern methods, it is difficult to produce satisfactory segmentation results in terms of the reliability and accuracy required for medical data.","In this study, we propose an interactive segmentation method that allows users to refine the output of deep neural networks through click-type user interactions.","The primary method is to formulate interactive segmentation as an optimization problem that leverages both user-provided click constraints and semantic information in a feature map using a click-guided attention module (CGAM).","Unlike other existing methods, CGAM avoids excessive changes in segmentation results, which can lead to the overfitting of user clicks.","Another advantage of CGAM is that the model size is independent of input image size.","Experimental results on pathology image datasets indicated that our method performs better than existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.01015v1"}
{"created":"2023-07-03 13:44:36","title":"SynthCal: A Synthetic Benchmarking Pipeline to Compare Camera Calibration Algorithms","abstract":"Accurate camera calibration is crucial for various computer vision applications. However, measuring camera parameters in the real world is challenging and arduous, and there needs to be a dataset with ground truth to evaluate calibration algorithms' accuracy. In this paper, we present SynthCal, a synthetic camera calibration benchmarking pipeline that generates images of calibration patterns to measure and enable accurate quantification of calibration algorithm performance in camera parameter estimation. We present a SynthCal-generated calibration dataset with four common patterns, two camera types, and two environments with varying view, distortion, lighting, and noise levels. The dataset evaluates single-view calibration algorithms by measuring reprojection and root-mean-square errors for identical patterns and camera settings. Additionally, we analyze the significance of different patterns using Zhang's method, which estimates intrinsic and extrinsic camera parameters with known correspondences between 3D points and their 2D projections in different configurations and environments. The experimental results demonstrate the effectiveness of SynthCal in evaluating various calibration algorithms and patterns.","sentences":["Accurate camera calibration is crucial for various computer vision applications.","However, measuring camera parameters in the real world is challenging and arduous, and there needs to be a dataset with ground truth to evaluate calibration algorithms' accuracy.","In this paper, we present SynthCal, a synthetic camera calibration benchmarking pipeline that generates images of calibration patterns to measure and enable accurate quantification of calibration algorithm performance in camera parameter estimation.","We present a SynthCal-generated calibration dataset with four common patterns, two camera types, and two environments with varying view, distortion, lighting, and noise levels.","The dataset evaluates single-view calibration algorithms by measuring reprojection and root-mean-square errors for identical patterns and camera settings.","Additionally, we analyze the significance of different patterns using Zhang's method, which estimates intrinsic and extrinsic camera parameters with known correspondences between 3D points and their 2D projections in different configurations and environments.","The experimental results demonstrate the effectiveness of SynthCal in evaluating various calibration algorithms and patterns."],"url":"http://arxiv.org/abs/2307.01013v1"}
{"created":"2023-07-03 13:41:13","title":"APEIRON: composing smart TDAQ systems for high energy physics experiments","abstract":"APEIRON is a framework encompassing the general architecture of a distributed heterogeneous processing platform and the corresponding software stack, from the low level device drivers up to the high level programming model. The framework is designed to be efficiently used for studying, prototyping and deploying smart trigger and data acquisition (TDAQ) systems for high energy physics experiments.","sentences":["APEIRON is a framework encompassing the general architecture of a distributed heterogeneous processing platform and the corresponding software stack, from the low level device drivers up to the high level programming model.","The framework is designed to be efficiently used for studying, prototyping and deploying smart trigger and data acquisition (TDAQ) systems for high energy physics experiments."],"url":"http://arxiv.org/abs/2307.01009v1"}
{"created":"2023-07-03 13:40:20","title":"Joint Coordinate Regression and Association For Multi-Person Pose Estimation, A Pure Neural Network Approach","abstract":"We introduce a novel one-stage end-to-end multi-person 2D pose estimation algorithm, known as Joint Coordinate Regression and Association (JCRA), that produces human pose joints and associations without requiring any post-processing. The proposed algorithm is fast, accurate, effective, and simple. The one-stage end-to-end network architecture significantly improves the inference speed of JCRA. Meanwhile, we devised a symmetric network structure for both the encoder and decoder, which ensures high accuracy in identifying keypoints. It follows an architecture that directly outputs part positions via a transformer network, resulting in a significant improvement in performance. Extensive experiments on the MS COCO and CrowdPose benchmarks demonstrate that JCRA outperforms state-of-the-art approaches in both accuracy and efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\\% faster at inference acceleration than previous state-of-the-art bottom-up algorithms. The code for this algorithm will be publicly available.","sentences":["We introduce a novel one-stage end-to-end multi-person 2D pose estimation algorithm, known as Joint Coordinate Regression and Association (JCRA), that produces human pose joints and associations without requiring any post-processing.","The proposed algorithm is fast, accurate, effective, and simple.","The one-stage end-to-end network architecture significantly improves the inference speed of JCRA.","Meanwhile, we devised a symmetric network structure for both the encoder and decoder, which ensures high accuracy in identifying keypoints.","It follows an architecture that directly outputs part positions via a transformer network, resulting in a significant improvement in performance.","Extensive experiments on the MS COCO and CrowdPose benchmarks demonstrate that JCRA outperforms state-of-the-art approaches in both accuracy and efficiency.","Moreover, JCRA demonstrates 69.2 mAP and is 78\\% faster at inference acceleration than previous state-of-the-art bottom-up algorithms.","The code for this algorithm will be publicly available."],"url":"http://arxiv.org/abs/2307.01004v1"}
{"created":"2023-07-03 13:37:00","title":"Visual Instruction Tuning with Polite Flamingo","abstract":"Recent research has demonstrated that the multi-task fine-tuning of multi-modal Large Language Models (LLMs) using an assortment of annotated downstream vision-language datasets significantly enhances their performance. Yet, during this process, a side effect, which we termed as the \"multi-modal alignment tax\", surfaces. This side effect negatively impacts the model's ability to format responses appropriately -- for instance, its \"politeness\" -- due to the overly succinct and unformatted nature of raw annotations, resulting in reduced human preference. In this paper, we introduce Polite Flamingo, a multi-modal response rewriter that transforms raw annotations into a more appealing, \"polite\" format. Polite Flamingo is trained to reconstruct high-quality responses from their automatically distorted counterparts and is subsequently applied to a vast array of vision-language datasets for response rewriting. After rigorous filtering, we generate the PF-1M dataset and further validate its value by fine-tuning a multi-modal LLM with it. Combined with novel methodologies including U-shaped multi-stage tuning and multi-turn augmentation, the resulting model, Clever Flamingo, demonstrates its advantages in both multi-modal understanding and response politeness according to automated and human evaluations.","sentences":["Recent research has demonstrated that the multi-task fine-tuning of multi-modal Large Language Models (LLMs) using an assortment of annotated downstream vision-language datasets significantly enhances their performance.","Yet, during this process, a side effect, which we termed as the \"multi-modal alignment tax\", surfaces.","This side effect negatively impacts the model's ability to format responses appropriately -- for instance, its \"politeness\" -- due to the overly succinct and unformatted nature of raw annotations, resulting in reduced human preference.","In this paper, we introduce Polite Flamingo, a multi-modal response rewriter that transforms raw annotations into a more appealing, \"polite\" format.","Polite Flamingo is trained to reconstruct high-quality responses from their automatically distorted counterparts and is subsequently applied to a vast array of vision-language datasets for response rewriting.","After rigorous filtering, we generate the PF-1M dataset and further validate its value by fine-tuning a multi-modal LLM with it.","Combined with novel methodologies including U-shaped multi-stage tuning and multi-turn augmentation, the resulting model, Clever Flamingo, demonstrates its advantages in both multi-modal understanding and response politeness according to automated and human evaluations."],"url":"http://arxiv.org/abs/2307.01003v1"}
{"created":"2023-07-03 13:21:58","title":"RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation","abstract":"The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation. However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and limited understanding of different modalities, such as language and vision. This paper presents the RefSAM model, which for the first time explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps. Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts. Subsequently, a parameter-efficient tuning strategy is employed to effectively align and fuse the language and vision features. Through comprehensive ablation studies, we demonstrate the practical and effective design choices of our strategy. Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasets validate the superiority and effectiveness of our RefSAM model over existing methods. The code and models will be made publicly at \\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}.","sentences":["The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation.","However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and limited understanding of different modalities, such as language and vision.","This paper presents the RefSAM model, which for the first time explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps.","Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts.","Subsequently, a parameter-efficient tuning strategy is employed to effectively align and fuse the language and vision features.","Through comprehensive ablation studies, we demonstrate the practical and effective design choices of our strategy.","Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasets validate the superiority and effectiveness of our RefSAM model over existing methods.","The code and models will be made publicly at \\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}."],"url":"http://arxiv.org/abs/2307.00997v1"}
{"created":"2023-07-03 13:20:28","title":"Kernelizing Problems on Planar Graphs in Sublinear Space and Polynomial Time","abstract":"In this paper, we devise a scheme for kernelizing, in sublinear space and polynomial time, various problems on planar graphs. The scheme exploits planarity to ensure that the resulting algorithms run in polynomial time and use O((sqrt(n) + k) log n) bits of space, where n is the number of vertices in the input instance and k is the intended solution size. As examples, we apply the scheme to Dominating Set and Vertex Cover. For Dominating Set, we also show that a well-known kernelization algorithm due to Alber et al. (JACM 2004) can be carried out in polynomial time and space O(k log n). Along the way, we devise restricted-memory procedures for computing region decompositions and approximating the aforementioned problems, which might be of independent interest.","sentences":["In this paper, we devise a scheme for kernelizing, in sublinear space and polynomial time, various problems on planar graphs.","The scheme exploits planarity to ensure that the resulting algorithms run in polynomial time and use O((sqrt(n)","+","k) log n) bits of space, where n is the number of vertices in the input instance and k is the intended solution size.","As examples, we apply the scheme to Dominating Set and Vertex Cover.","For Dominating Set, we also show that a well-known kernelization algorithm due to Alber et al. (JACM 2004) can be carried out in polynomial time and space O(k log n).","Along the way, we devise restricted-memory procedures for computing region decompositions and approximating the aforementioned problems, which might be of independent interest."],"url":"http://arxiv.org/abs/2307.00996v1"}
{"created":"2023-07-03 13:18:55","title":"Towards Suicide Prevention from Bipolar Disorder with Temporal Symptom-Aware Multitask Learning","abstract":"Bipolar disorder (BD) is closely associated with an increased risk of suicide. However, while the prior work has revealed valuable insight into understanding the behavior of BD patients on social media, little attention has been paid to developing a model that can predict the future suicidality of a BD patient. Therefore, this study proposes a multi-task learning model for predicting the future suicidality of BD patients by jointly learning current symptoms. We build a novel BD dataset clinically validated by psychiatrists, including 14 years of posts on bipolar-related subreddits written by 818 BD patients, along with the annotations of future suicidality and BD symptoms. We also suggest a temporal symptom-aware attention mechanism to determine which symptoms are the most influential for predicting future suicidality over time through a sequence of BD posts. Our experiments demonstrate that the proposed model outperforms the state-of-the-art models in both BD symptom identification and future suicidality prediction tasks. In addition, the proposed temporal symptom-aware attention provides interpretable attention weights, helping clinicians to apprehend BD patients more comprehensively and to provide timely intervention by tracking mental state progression.","sentences":["Bipolar disorder (BD) is closely associated with an increased risk of suicide.","However, while the prior work has revealed valuable insight into understanding the behavior of BD patients on social media, little attention has been paid to developing a model that can predict the future suicidality of a BD patient.","Therefore, this study proposes a multi-task learning model for predicting the future suicidality of BD patients by jointly learning current symptoms.","We build a novel BD dataset clinically validated by psychiatrists, including 14 years of posts on bipolar-related subreddits written by 818 BD patients, along with the annotations of future suicidality and BD symptoms.","We also suggest a temporal symptom-aware attention mechanism to determine which symptoms are the most influential for predicting future suicidality over time through a sequence of BD posts.","Our experiments demonstrate that the proposed model outperforms the state-of-the-art models in both BD symptom identification and future suicidality prediction tasks.","In addition, the proposed temporal symptom-aware attention provides interpretable attention weights, helping clinicians to apprehend BD patients more comprehensively and to provide timely intervention by tracking mental state progression."],"url":"http://arxiv.org/abs/2307.00995v1"}
{"created":"2023-07-03 13:16:08","title":"NOMA-Assisted Grant-Free Transmission: How to Design Pre-Configured SNR Levels?","abstract":"An effective way to realize non-orthogonal multiple access (NOMA) assisted grant-free transmission is to first create multiple receive signal-to-noise ratio (SNR) levels and then serve multiple grant-free users by employing these SNR levels as bandwidth resources. These SNR levels need to be pre-configured prior to the grant-free transmission and have great impact on the performance of grant-free networks. The aim of this letter is to illustrate different designs for configuring the SNR levels and investigate their impact on the performance of grant-free transmission, where age-of-information is used as the performance metric. The presented analytical and simulation results demonstrate the performance gain achieved by NOMA over orthogonal multiple access, and also reveal the relative merits of the considered designs for pre-configured SNR levels.","sentences":["An effective way to realize non-orthogonal multiple access (NOMA) assisted grant-free transmission is to first create multiple receive signal-to-noise ratio (SNR) levels and then serve multiple grant-free users by employing these SNR levels as bandwidth resources.","These SNR levels need to be pre-configured prior to the grant-free transmission and have great impact on the performance of grant-free networks.","The aim of this letter is to illustrate different designs for configuring the SNR levels and investigate their impact on the performance of grant-free transmission, where age-of-information is used as the performance metric.","The presented analytical and simulation results demonstrate the performance gain achieved by NOMA over orthogonal multiple access, and also reveal the relative merits of the considered designs for pre-configured SNR levels."],"url":"http://arxiv.org/abs/2307.00990v1"}
{"created":"2023-07-03 13:05:46","title":"Effect of the cross-section architecture on the impact resistance of bio-inspired low-porosity structures using neural networks","abstract":"Biological structural designs in nature, like hoof walls, horns, and antlers, can be used as inspiration for generating structures with excellent mechanical properties. A common theme in these designs is the small percent porosity in the structure ranging from 1 - 5\\%. In this work, the sheep horn was used as an inspiration due to its higher toughness when loaded in the radial direction compared to the longitudinal direction. Under dynamic transverse compression, we investigated the structure-property relations in low porosity structures characterized by their two-dimensional (2D) cross-sections. A diverse design space was created by combining polygonal tubules with different numbers of sides placed on a grid with different numbers of rows and columns. The volume fraction and the orientation angle of the tubules were also varied. The finite element (FE) method was used with a rate-dependent elastoplastic material model to generate the stress-strain curves in plane strain conditions. A gated recurrent unit (GRU) model was trained to predict the structures' stress-strain response and energy absorption under different strain rates and applied strains. The parameter-based model uses eight discrete parameters to characterize the design space and as inputs to the model. The trained GRU model can efficiently predict the response of a new design in as little as 0.16 ms and allows rapid performance evaluation of 128000 designs in the design space. The GRU predictions identified high-performance structures and four design trends that affect the specific energy absorption were extracted and discussed.","sentences":["Biological structural designs in nature, like hoof walls, horns, and antlers, can be used as inspiration for generating structures with excellent mechanical properties.","A common theme in these designs is the small percent porosity in the structure ranging from 1 - 5\\%.","In this work, the sheep horn was used as an inspiration due to its higher toughness when loaded in the radial direction compared to the longitudinal direction.","Under dynamic transverse compression, we investigated the structure-property relations in low porosity structures characterized by their two-dimensional (2D) cross-sections.","A diverse design space was created by combining polygonal tubules with different numbers of sides placed on a grid with different numbers of rows and columns.","The volume fraction and the orientation angle of the tubules were also varied.","The finite element (FE) method was used with a rate-dependent elastoplastic material model to generate the stress-strain curves in plane strain conditions.","A gated recurrent unit (GRU) model was trained to predict the structures' stress-strain response and energy absorption under different strain rates and applied strains.","The parameter-based model uses eight discrete parameters to characterize the design space and as inputs to the model.","The trained GRU model can efficiently predict the response of a new design in as little as 0.16 ms and allows rapid performance evaluation of 128000 designs in the design space.","The GRU predictions identified high-performance structures and four design trends that affect the specific energy absorption were extracted and discussed."],"url":"http://arxiv.org/abs/2307.00986v1"}
{"created":"2023-07-03 13:05:15","title":"An embarrassingly parallel optimal-space cardinality estimation algorithm","abstract":"In 2020 Blasiok (ACM Trans. Algorithms 16(2) 3:1-3:28) constructed an optimal space streaming algorithm for the cardinality estimation problem with the space complexity of $\\mathcal O(\\varepsilon^{-2} \\ln(\\delta^{-1}) + \\ln n)$ where $\\varepsilon$, $\\delta$ and $n$ denote the relative accuracy, failure probability and universe size, respectively. However, his solution requires the stream to be processed sequentially. On the other hand, there are algorithms that admit a merge operation; they can be used in a distributed setting, allowing parallel processing of sections of the stream, and are highly relevant for large-scale distributed applications. The best-known such algorithm, unfortunately, has a space complexity exceeding $\\Omega(\\ln(\\delta^{-1}) (\\varepsilon^{-2} \\ln \\ln n + \\ln n))$. This work presents a new algorithm that improves on the solution by Blasiok, preserving its space complexity, but with the benefit that it admits such a merge operation, thus providing an optimal solution for the problem for both sequential and parallel applications. Orthogonally, the new algorithm also improves algorithmically on Blasiok's solution (even in the sequential setting) by reducing its implementation complexity and requiring fewer distinct pseudo-random objects.","sentences":["In 2020 Blasiok (ACM Trans.","Algorithms 16(2) 3:1-3:28) constructed an optimal space streaming algorithm for the cardinality estimation problem with the space complexity of $\\mathcal O(\\varepsilon^{-2} \\ln(\\delta^{-1})","+ \\ln n)$ where $\\varepsilon$, $\\delta$ and $n$ denote the relative accuracy, failure probability and universe size, respectively.","However, his solution requires the stream to be processed sequentially.","On the other hand, there are algorithms that admit a merge operation; they can be used in a distributed setting, allowing parallel processing of sections of the stream, and are highly relevant for large-scale distributed applications.","The best-known such algorithm, unfortunately, has a space complexity exceeding $\\Omega(\\ln(\\delta^{-1}) (\\varepsilon^{-2} \\ln \\ln n + \\ln n))$.","This work presents a new algorithm that improves on the solution by Blasiok, preserving its space complexity, but with the benefit that it admits such a merge operation, thus providing an optimal solution for the problem for both sequential and parallel applications.","Orthogonally, the new algorithm also improves algorithmically on Blasiok's solution (even in the sequential setting) by reducing its implementation complexity and requiring fewer distinct pseudo-random objects."],"url":"http://arxiv.org/abs/2307.00985v1"}
{"created":"2023-07-03 13:03:17","title":"Predicting beauty, liking, and aesthetic quality: A comparative analysis of image databases for visual aesthetics research","abstract":"In the fields of Experimental and Computational Aesthetics, numerous image datasets have been created over the last two decades. In the present work, we provide a comparative overview of twelve image datasets that include aesthetic ratings (beauty, liking or aesthetic quality) and investigate the reproducibility of results across different datasets. Specifically, we examine how consistently the ratings can be predicted by using either (A) a set of 20 previously studied statistical image properties, or (B) the layers of a convolutional neural network developed for object recognition. Our findings reveal substantial variation in the predictability of aesthetic ratings across the different datasets. However, consistent similarities were found for datasets containing either photographs or paintings, suggesting different relevant features in the aesthetic evaluation of these two image genres. To our surprise, statistical image properties and the convolutional neural network predict aesthetic ratings with similar accuracy, highlighting a significant overlap in the image information captured by the two methods. Nevertheless, the discrepancies between the datasets call into question the generalizability of previous research findings on single datasets. Our study underscores the importance of considering multiple datasets to improve the validity and generalizability of research results in the fields of experimental and computational aesthetics.","sentences":["In the fields of Experimental and Computational Aesthetics, numerous image datasets have been created over the last two decades.","In the present work, we provide a comparative overview of twelve image datasets that include aesthetic ratings (beauty, liking or aesthetic quality) and investigate the reproducibility of results across different datasets.","Specifically, we examine how consistently the ratings can be predicted by using either (A) a set of 20 previously studied statistical image properties, or (B) the layers of a convolutional neural network developed for object recognition.","Our findings reveal substantial variation in the predictability of aesthetic ratings across the different datasets.","However, consistent similarities were found for datasets containing either photographs or paintings, suggesting different relevant features in the aesthetic evaluation of these two image genres.","To our surprise, statistical image properties and the convolutional neural network predict aesthetic ratings with similar accuracy, highlighting a significant overlap in the image information captured by the two methods.","Nevertheless, the discrepancies between the datasets call into question the generalizability of previous research findings on single datasets.","Our study underscores the importance of considering multiple datasets to improve the validity and generalizability of research results in the fields of experimental and computational aesthetics."],"url":"http://arxiv.org/abs/2307.00984v1"}
{"created":"2023-07-03 12:46:19","title":"Autism Spectrum Disorder Classification in Children based on Structural MRI Features Extracted using Contrastive Variational Autoencoder","abstract":"Autism spectrum disorder (ASD) is a highly disabling mental disease that brings significant impairments of social interaction ability to the patients, making early screening and intervention of ASD critical. With the development of the machine learning and neuroimaging technology, extensive research has been conducted on machine classification of ASD based on structural MRI (s-MRI). However, most studies involve with datasets where participants' age are above 5. Few studies conduct machine classification of ASD for participants below 5-year-old, but, with mediocre predictive accuracy. In this paper, we push the boundary of predictive accuracy (above 0.97) of machine classification of ASD in children (age range: 0.92-4.83 years), based on s-MRI features extracted using contrastive variational autoencoder (CVAE). 78 s-MRI, collected from Shenzhen Children's Hospital, are used for training CVAE, which consists of both ASD-specific feature channel and common shared feature channel. The ASD participants represented by ASD-specific features can be easily discriminated from TC participants represented by the common shared features, leading to high classification accuracy. In case of degraded predictive accuracy when data size is extremely small, a transfer learning strategy is proposed here as a potential solution. Finally, we conduct neuroanatomical interpretation based on the correlation between s-MRI features extracted from CVAE and surface area of different cortical regions, which discloses potential biomarkers that could help target treatments of ASD in the future.","sentences":["Autism spectrum disorder (ASD) is a highly disabling mental disease that brings significant impairments of social interaction ability to the patients, making early screening and intervention of ASD critical.","With the development of the machine learning and neuroimaging technology, extensive research has been conducted on machine classification of ASD based on structural MRI (s-MRI).","However, most studies involve with datasets where participants' age are above 5.","Few studies conduct machine classification of ASD for participants below 5-year-old, but, with mediocre predictive accuracy.","In this paper, we push the boundary of predictive accuracy (above 0.97) of machine classification of ASD in children (age range: 0.92-4.83 years), based on s-MRI features extracted using contrastive variational autoencoder (CVAE).","78 s-MRI, collected from Shenzhen Children's Hospital, are used for training CVAE, which consists of both ASD-specific feature channel and common shared feature channel.","The ASD participants represented by ASD-specific features can be easily discriminated from TC participants represented by the common shared features, leading to high classification accuracy.","In case of degraded predictive accuracy when data size is extremely small, a transfer learning strategy is proposed here as a potential solution.","Finally, we conduct neuroanatomical interpretation based on the correlation between s-MRI features extracted from CVAE and surface area of different cortical regions, which discloses potential biomarkers that could help target treatments of ASD in the future."],"url":"http://arxiv.org/abs/2307.00976v1"}
{"created":"2023-07-03 12:44:19","title":"Digital Twin-Empowered Communications: A New Frontier of Wireless Networks","abstract":"The future of wireless network generations is revolving toward unlocking the opportunities offered by virtualization and digitization services, with the aim to realize improved quality-of-experience (QoE) and bring several advantages to network users. According to the rapid development in the field of network virtualization, we envision that future wireless networks will run over ubiquitous deployment of virtualized components that are controlled by artificial intelligence (AI), i.e., the conceptualization of the Digital Twin (DT) paradigm. The key principle of the DT relies on creating a holistic representation of wireless network elements, in addition to decoupling the information pertaining to physical objects and dynamics, into a cyber twin. The cyber twin will then leverage this information for AI models training, and then reasoning and decision-making operations, which will be then reflected to the physical environment, for improved sustainability. Motivated by this, in this article, we dig deep into the intertwined role of wireless technologies as being enablers and enabled by the DT. Furthermore, we put a forward-looking vision of the integral role that future 6G networks are anticipated to play in order to realize an efficient DT. Finally, we sketch the roadmap toward identifying the limitations of the DT in 6G-enabled wireless networks, and open new horizons for further developments in different design aspects.","sentences":["The future of wireless network generations is revolving toward unlocking the opportunities offered by virtualization and digitization services, with the aim to realize improved quality-of-experience (QoE) and bring several advantages to network users.","According to the rapid development in the field of network virtualization, we envision that future wireless networks will run over ubiquitous deployment of virtualized components that are controlled by artificial intelligence (AI), i.e., the conceptualization of the Digital Twin (DT) paradigm.","The key principle of the DT relies on creating a holistic representation of wireless network elements, in addition to decoupling the information pertaining to physical objects and dynamics, into a cyber twin.","The cyber twin will then leverage this information for AI models training, and then reasoning and decision-making operations, which will be then reflected to the physical environment, for improved sustainability.","Motivated by this, in this article, we dig deep into the intertwined role of wireless technologies as being enablers and enabled by the DT.","Furthermore, we put a forward-looking vision of the integral role that future 6G networks are anticipated to play in order to realize an efficient DT.","Finally, we sketch the roadmap toward identifying the limitations of the DT in 6G-enabled wireless networks, and open new horizons for further developments in different design aspects."],"url":"http://arxiv.org/abs/2307.00973v1"}
{"created":"2023-07-03 12:44:07","title":"MoVie: Visual Model-Based Policy Adaptation for View Generalization","abstract":"Visual Reinforcement Learning (RL) agents trained on limited views face significant challenges in generalizing their learned abilities to unseen views. This inherent difficulty is known as the problem of $\\textit{view generalization}$. In this work, we systematically categorize this fundamental problem into four distinct and highly challenging scenarios that closely resemble real-world situations. Subsequently, we propose a straightforward yet effective approach to enable successful adaptation of visual $\\textbf{Mo}$del-based policies for $\\textbf{Vie}$w generalization ($\\textbf{MoVie}$) during test time, without any need for explicit reward signals and any modification during training time. Our method demonstrates substantial advancements across all four scenarios encompassing a total of $\\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative improvement of $\\mathbf{33}$%, $\\mathbf{86}$%, and $\\mathbf{152}$% respectively. The superior results highlight the immense potential of our approach for real-world robotics applications. Videos are available at https://yangsizhe.github.io/MoVie/ .","sentences":["Visual Reinforcement Learning (RL) agents trained on limited views face significant challenges in generalizing their learned abilities to unseen views.","This inherent difficulty is known as the problem of $\\textit{view generalization}$.","In this work, we systematically categorize this fundamental problem into four distinct and highly challenging scenarios that closely resemble real-world situations.","Subsequently, we propose a straightforward yet effective approach to enable successful adaptation of visual $\\textbf{Mo}$del-based policies for $\\textbf{Vie}$w generalization ($\\textbf{MoVie}$) during test time, without any need for explicit reward signals and any modification during training time.","Our method demonstrates substantial advancements across all four scenarios encompassing a total of $\\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative improvement of $\\mathbf{33}$%, $\\mathbf{86}$%, and $\\mathbf{152}$% respectively.","The superior results highlight the immense potential of our approach for real-world robotics applications.","Videos are available at https://yangsizhe.github.io/MoVie/ ."],"url":"http://arxiv.org/abs/2307.00972v1"}
{"created":"2023-07-03 12:44:00","title":"Fishing For Better Constants: The Prophet Secretary Via Poissonization","abstract":"Given n random variables $X_1, \\ldots , X_n$ taken from known distributions, a gambler observes their realizations in this order, and needs to select one of them, immediately after it is being observed, so that its value is as high as possible. The classical prophet inequality shows a strategy that guarantees a value at least half (in expectation) of that an omniscience prophet that picks the maximum, and this ratio is tight.   Esfandiari, Hajiaghayi, Liaghat, and Monemizadeh introduced a variant of the prophet inequality, the prophet secretary problem in [1]. The difference being that that the realizations arrive at a random permutation order, and not an adversarial order. Esfandiari et al. gave a simple $1-1/e \\approx 0.632$ competitive algorithm for the problem. This was later improved in a surprising result by Azar, Chiplunkar and Kaplan [2] into a $1-1/e + 1/400 \\approx 0.634$ competitive algorithm. In a subsequent result, Correa, Saona, and Ziliotto [3] took a systematic approach, introducing blind strategies, and gave an improved $0.669$ competitive algorithm. Since then, there has been no improvements on the lower bounds. Meanwhile, current upper bounds show that no algorithm can achieve a competitive ratio better than $0.7235$ [4].   In this paper, we give a $0.6724$-competitive algorithm for the prophet secretary problem. The algorithm follows blind strategies introduced by [3] but has a technical difference. We do this by re-interpretting the blind strategies, framing them as Poissonization strategies. We break the non-iid random variables into iid shards and argue about the competitive ratio in terms of events on shards. This gives significantly simpler and direct proofs, in addition to a tighter analysis on the competitive ratio. The analysis might be of independent interest for similar problems such as the prophet inequality with order-selection","sentences":["Given n random variables $X_1, \\ldots , X_n$ taken from known distributions, a gambler observes their realizations in this order, and needs to select one of them, immediately after it is being observed, so that its value is as high as possible.","The classical prophet inequality shows a strategy that guarantees a value at least half (in expectation) of that an omniscience prophet that picks the maximum, and this ratio is tight.   ","Esfandiari, Hajiaghayi, Liaghat, and Monemizadeh introduced a variant of the prophet inequality, the prophet secretary problem in [1].","The difference being that that the realizations arrive at a random permutation order, and not an adversarial order.","Esfandiari et al. gave a simple $1-1/e \\approx 0.632$ competitive algorithm for the problem.","This was later improved in a surprising result by Azar, Chiplunkar and Kaplan","[2] into a $1-1/e + 1/400 \\approx 0.634$ competitive algorithm.","In a subsequent result, Correa, Saona, and Ziliotto","[3] took a systematic approach, introducing blind strategies, and gave an improved $0.669$ competitive algorithm.","Since then, there has been no improvements on the lower bounds.","Meanwhile, current upper bounds show that no algorithm can achieve a competitive ratio better than $0.7235$ [4].   ","In this paper, we give a $0.6724$-competitive algorithm for the prophet secretary problem.","The algorithm follows blind strategies introduced by [3] but has a technical difference.","We do this by re-interpretting the blind strategies, framing them as Poissonization strategies.","We break the non-iid random variables into iid shards and argue about the competitive ratio in terms of events on shards.","This gives significantly simpler and direct proofs, in addition to a tighter analysis on the competitive ratio.","The analysis might be of independent interest for similar problems such as the prophet inequality with order-selection"],"url":"http://arxiv.org/abs/2307.00971v1"}
{"created":"2023-07-03 12:40:11","title":"High Altitude Platform Stations: the New Network Energy Efficiency Enabler in the 6G Era","abstract":"The rapidly evolving communication landscape, with the advent of 6G technology, brings new challenges to the design and operation of wireless networks. One of the key concerns is the energy efficiency of the Radio Access Network (RAN), as the exponential growth in wireless traffic demands increasingly higher energy consumption. In this paper, we assess the potential of integrating a High Altitude Platform Station (HAPS) to improve the energy efficiency of a RAN, and quantify the potential energy conservation through meticulously designed simulations. We propose a quantitative framework based on real traffic patterns to estimate the energy consumption of the HAPS integrated RAN and compare it with the conventional terrestrial RAN. Our simulation results elucidate that HAPS can significantly reduce energy consumption by up to almost 30\\% by exploiting the unique advantages of HAPS, such as its self-sustainability, high altitude, and wide coverage. We further analyze the impact of different system parameters on performance, and provide insights for the design and optimization of future 6G networks. Our work sheds light on the potential of HAPS integrated RAN to mitigate the energy challenges in the 6G era, and contributes to the sustainable development of wireless communications.","sentences":["The rapidly evolving communication landscape, with the advent of 6G technology, brings new challenges to the design and operation of wireless networks.","One of the key concerns is the energy efficiency of the Radio Access Network (RAN), as the exponential growth in wireless traffic demands increasingly higher energy consumption.","In this paper, we assess the potential of integrating a High Altitude Platform Station (HAPS) to improve the energy efficiency of a RAN, and quantify the potential energy conservation through meticulously designed simulations.","We propose a quantitative framework based on real traffic patterns to estimate the energy consumption of the HAPS integrated RAN and compare it with the conventional terrestrial RAN.","Our simulation results elucidate that HAPS can significantly reduce energy consumption by up to almost 30\\% by exploiting the unique advantages of HAPS, such as its self-sustainability, high altitude, and wide coverage.","We further analyze the impact of different system parameters on performance, and provide insights for the design and optimization of future 6G networks.","Our work sheds light on the potential of HAPS integrated RAN to mitigate the energy challenges in the 6G era, and contributes to the sustainable development of wireless communications."],"url":"http://arxiv.org/abs/2307.00969v1"}
{"created":"2023-07-03 12:39:26","title":"REAL: A Representative Error-Driven Approach for Active Learning","abstract":"Given a limited labeling budget, active learning (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training. To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity. However, it does not consider erroneous instances with their neighborhood error density, which have great potential to improve the model performance. To address this limitation, we propose $REAL$, a novel approach to select data instances with $\\underline{R}$epresentative $\\underline{E}$rrors for $\\underline{A}$ctive $\\underline{L}$earning. It identifies minority predictions as \\emph{pseudo errors} within a cluster and allocates an adaptive sampling budget for the cluster based on estimated error density. Extensive experiments on five text classification datasets demonstrate that $REAL$ consistently outperforms all best-performing baselines regarding accuracy and F1-macro scores across a wide range of hyperparameter settings. Our analysis also shows that $REAL$ selects the most representative pseudo errors that match the distribution of ground-truth errors along the decision boundary. Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real.","sentences":["Given a limited labeling budget, active learning (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training.","To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity.","However, it does not consider erroneous instances with their neighborhood error density, which have great potential to improve the model performance.","To address this limitation, we propose $REAL$, a novel approach to select data instances with $\\underline{R}$epresentative $\\underline{E}$rrors for $\\underline{A}$ctive $\\underline{L}$earning.","It identifies minority predictions as \\emph{pseudo errors} within a cluster and allocates an adaptive sampling budget for the cluster based on estimated error density.","Extensive experiments on five text classification datasets demonstrate that $REAL$ consistently outperforms all best-performing baselines regarding accuracy and F1-macro scores across a wide range of hyperparameter settings.","Our analysis also shows that $REAL$ selects the most representative pseudo errors that match the distribution of ground-truth errors along the decision boundary.","Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real."],"url":"http://arxiv.org/abs/2307.00968v1"}
{"created":"2023-07-03 12:35:03","title":"OpenClinicalAI: An Open and Dynamic Model for Alzheimer's Disease Diagnosis","abstract":"Although Alzheimer's disease (AD) cannot be reversed or cured, timely diagnosis can significantly reduce the burden of treatment and care. Current research on AD diagnosis models usually regards the diagnosis task as a typical classification task with two primary assumptions: 1) All target categories are known a priori; 2) The diagnostic strategy for each patient is consistent, that is, the number and type of model input data for each patient are the same. However, real-world clinical settings are open, with complexity and uncertainty in terms of both subjects and the resources of the medical institutions. This means that diagnostic models may encounter unseen disease categories and need to dynamically develop diagnostic strategies based on the subject's specific circumstances and available medical resources. Thus, the AD diagnosis task is tangled and coupled with the diagnosis strategy formulation. To promote the application of diagnostic systems in real-world clinical settings, we propose OpenClinicalAI for direct AD diagnosis in complex and uncertain clinical settings. This is the first powerful end-to-end model to dynamically formulate diagnostic strategies and provide diagnostic results based on the subject's conditions and available medical resources. OpenClinicalAI combines reciprocally coupled deep multiaction reinforcement learning (DMARL) for diagnostic strategy formulation and multicenter meta-learning (MCML) for open-set recognition. The experimental results show that OpenClinicalAI achieves better performance and fewer clinical examinations than the state-of-the-art model. Our method provides an opportunity to embed the AD diagnostic system into the current health care system to cooperate with clinicians to improve current health care.","sentences":["Although Alzheimer's disease (AD) cannot be reversed or cured, timely diagnosis can significantly reduce the burden of treatment and care.","Current research on AD diagnosis models usually regards the diagnosis task as a typical classification task with two primary assumptions: 1) All target categories are known a priori; 2) The diagnostic strategy for each patient is consistent, that is, the number and type of model input data for each patient are the same.","However, real-world clinical settings are open, with complexity and uncertainty in terms of both subjects and the resources of the medical institutions.","This means that diagnostic models may encounter unseen disease categories and need to dynamically develop diagnostic strategies based on the subject's specific circumstances and available medical resources.","Thus, the AD diagnosis task is tangled and coupled with the diagnosis strategy formulation.","To promote the application of diagnostic systems in real-world clinical settings, we propose OpenClinicalAI for direct AD diagnosis in complex and uncertain clinical settings.","This is the first powerful end-to-end model to dynamically formulate diagnostic strategies and provide diagnostic results based on the subject's conditions and available medical resources.","OpenClinicalAI combines reciprocally coupled deep multiaction reinforcement learning (DMARL) for diagnostic strategy formulation and multicenter meta-learning (MCML) for open-set recognition.","The experimental results show that OpenClinicalAI achieves better performance and fewer clinical examinations than the state-of-the-art model.","Our method provides an opportunity to embed the AD diagnostic system into the current health care system to cooperate with clinicians to improve current health care."],"url":"http://arxiv.org/abs/2307.00965v1"}
{"created":"2023-07-03 12:26:44","title":"Challenges in Domain-Specific Abstractive Summarization and How to Overcome them","abstract":"Large Language Models work quite well with general-purpose data and many tasks in Natural Language Processing. However, they show several limitations when used for a task such as domain-specific abstractive text summarization. This paper identifies three of those limitations as research problems in the context of abstractive text summarization: 1) Quadratic complexity of transformer-based models with respect to the input text length; 2) Model Hallucination, which is a model's ability to generate factually incorrect text; and 3) Domain Shift, which happens when the distribution of the model's training and test corpus is not the same. Along with a discussion of the open research questions, this paper also provides an assessment of existing state-of-the-art techniques relevant to domain-specific text summarization to address the research gaps.","sentences":["Large Language Models work quite well with general-purpose data and many tasks in Natural Language Processing.","However, they show several limitations when used for a task such as domain-specific abstractive text summarization.","This paper identifies three of those limitations as research problems in the context of abstractive text summarization: 1) Quadratic complexity of transformer-based models with respect to the input text length; 2) Model Hallucination, which is a model's ability to generate factually incorrect text; and 3) Domain Shift, which happens when the distribution of the model's training and test corpus is not the same.","Along with a discussion of the open research questions, this paper also provides an assessment of existing state-of-the-art techniques relevant to domain-specific text summarization to address the research gaps."],"url":"http://arxiv.org/abs/2307.00963v1"}
{"created":"2023-07-03 12:25:09","title":"Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in Multi-Objective Neural Architecture Search","abstract":"Deep learning is increasingly impacting various aspects of contemporary society. Artificial neural networks have emerged as the dominant models for solving an expanding range of tasks. The introduction of Neural Architecture Search (NAS) techniques, which enable the automatic design of task-optimal networks, has led to remarkable advances. However, the NAS process is typically associated with long execution times and significant computational resource requirements. Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2), have been developed to mitigate these challenges. While maintaining exceptional performance and eliminating the need for retraining, they aim to build a single super-network model capable of directly extracting sub-networks satisfying different constraints. Neural Architecture Transfer (NAT) was developed to maximise the effectiveness of extracting sub-networks from a super-network. In this paper, we present NATv2, an extension of NAT that improves multi-objective search algorithms applied to dynamic super-network architectures. NATv2 achieves qualitative improvements in the extractable sub-networks by exploiting the improved super-networks generated by OFAv2 and incorporating new policies for initialisation, pre-processing and updating its networks archive. In addition, a post-processing pipeline based on fine-tuning is introduced. Experimental results show that NATv2 successfully improves NAT and is highly recommended for investigating high-performance architectures with a minimal number of parameters.","sentences":["Deep learning is increasingly impacting various aspects of contemporary society.","Artificial neural networks have emerged as the dominant models for solving an expanding range of tasks.","The introduction of Neural Architecture Search (NAS) techniques, which enable the automatic design of task-optimal networks, has led to remarkable advances.","However, the NAS process is typically associated with long execution times and significant computational resource requirements.","Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2), have been developed to mitigate these challenges.","While maintaining exceptional performance and eliminating the need for retraining, they aim to build a single super-network model capable of directly extracting sub-networks satisfying different constraints.","Neural Architecture Transfer (NAT) was developed to maximise the effectiveness of extracting sub-networks from a super-network.","In this paper, we present NATv2, an extension of NAT that improves multi-objective search algorithms applied to dynamic super-network architectures.","NATv2 achieves qualitative improvements in the extractable sub-networks by exploiting the improved super-networks generated by OFAv2 and incorporating new policies for initialisation, pre-processing and updating its networks archive.","In addition, a post-processing pipeline based on fine-tuning is introduced.","Experimental results show that NATv2 successfully improves NAT and is highly recommended for investigating high-performance architectures with a minimal number of parameters."],"url":"http://arxiv.org/abs/2307.00960v1"}
{"created":"2023-07-03 12:23:56","title":"5G Wings: Investigating 5G-Connected Drones Performance in Non-Urban Areas","abstract":"Unmanned aerial vehicles (UAVs) have become extremely popular for both military and civilian applications due to their ease of deployment, cost-effectiveness, high maneuverability, and availability. Both applications, however, need reliable communication for command and control (C2) and/or data transmission. Utilizing commercial cellular networks for drone communication can enable beyond visual line of sight (BVLOS) operation, high data rate transmission, and secure communication. However, deployment of cellular-connected drones over commercial LTE/5G networks still presents various challenges such as sparse coverage outside urban areas, and interference caused to the network as the UAV is visible to many towers. Commercial 5G networks can offer various features for aerial user equipment (UE) far beyond what LTE could provide by taking advantage of mmWave, flexible numerology, slicing, and the capability of applying AI-based solutions. Limited experimental data is available to investigate the operation of aerial UEs over current, without any modification, commercial 5G networks, particularly in suburban and NON-URBAN areas. In this paper, we perform a comprehensive study of drone communications over the existing low-band and mid-band 5G networks in a suburban area for different velocities and elevations, comparing the performance against that of LTE. It is important to acknowledge that the network examined in this research is primarily designed and optimized to meet the requirements of terrestrial users, and may not adequately address the needs of aerial users. This paper not only reports the Key Performance Indicators (KPIs) compared among all combinations of the test cases but also provides recommendations for aerial users to enhance their communication quality by controlling their trajectory.","sentences":["Unmanned aerial vehicles (UAVs) have become extremely popular for both military and civilian applications due to their ease of deployment, cost-effectiveness, high maneuverability, and availability.","Both applications, however, need reliable communication for command and control (C2) and/or data transmission.","Utilizing commercial cellular networks for drone communication can enable beyond visual line of sight (BVLOS) operation, high data rate transmission, and secure communication.","However, deployment of cellular-connected drones over commercial LTE/5G networks still presents various challenges such as sparse coverage outside urban areas, and interference caused to the network as the UAV is visible to many towers.","Commercial 5G networks can offer various features for aerial user equipment (UE) far beyond what LTE could provide by taking advantage of mmWave, flexible numerology, slicing, and the capability of applying AI-based solutions.","Limited experimental data is available to investigate the operation of aerial UEs over current, without any modification, commercial 5G networks, particularly in suburban and NON-URBAN areas.","In this paper, we perform a comprehensive study of drone communications over the existing low-band and mid-band 5G networks in a suburban area for different velocities and elevations, comparing the performance against that of LTE.","It is important to acknowledge that the network examined in this research is primarily designed and optimized to meet the requirements of terrestrial users, and may not adequately address the needs of aerial users.","This paper not only reports the Key Performance Indicators (KPIs) compared among all combinations of the test cases but also provides recommendations for aerial users to enhance their communication quality by controlling their trajectory."],"url":"http://arxiv.org/abs/2307.00959v1"}
{"created":"2023-07-03 11:56:21","title":"HODINet: High-Order Discrepant Interaction Network for RGB-D Salient Object Detection","abstract":"RGB-D salient object detection (SOD) aims to detect the prominent regions by jointly modeling RGB and depth information. Most RGB-D SOD methods apply the same type of backbones and fusion modules to identically learn the multimodality and multistage features. However, these features contribute differently to the final saliency results, which raises two issues: 1) how to model discrepant characteristics of RGB images and depth maps; 2) how to fuse these cross-modality features in different stages. In this paper, we propose a high-order discrepant interaction network (HODINet) for RGB-D SOD. Concretely, we first employ transformer-based and CNN-based architectures as backbones to encode RGB and depth features, respectively. Then, the high-order representations are delicately extracted and embedded into spatial and channel attentions for cross-modality feature fusion in different stages. Specifically, we design a high-order spatial fusion (HOSF) module and a high-order channel fusion (HOCF) module to fuse features of the first two and the last two stages, respectively. Besides, a cascaded pyramid reconstruction network is adopted to progressively decode the fused features in a top-down pathway. Extensive experiments are conducted on seven widely used datasets to demonstrate the effectiveness of the proposed approach. We achieve competitive performance against 24 state-of-the-art methods under four evaluation metrics.","sentences":["RGB-D salient object detection (SOD) aims to detect the prominent regions by jointly modeling RGB and depth information.","Most RGB-D SOD methods apply the same type of backbones and fusion modules to identically learn the multimodality and multistage features.","However, these features contribute differently to the final saliency results, which raises two issues: 1) how to model discrepant characteristics of RGB images and depth maps; 2) how to fuse these cross-modality features in different stages.","In this paper, we propose a high-order discrepant interaction network (HODINet) for RGB-D SOD.","Concretely, we first employ transformer-based and CNN-based architectures as backbones to encode RGB and depth features, respectively.","Then, the high-order representations are delicately extracted and embedded into spatial and channel attentions for cross-modality feature fusion in different stages.","Specifically, we design a high-order spatial fusion (HOSF) module and a high-order channel fusion (HOCF) module to fuse features of the first two and the last two stages, respectively.","Besides, a cascaded pyramid reconstruction network is adopted to progressively decode the fused features in a top-down pathway.","Extensive experiments are conducted on seven widely used datasets to demonstrate the effectiveness of the proposed approach.","We achieve competitive performance against 24 state-of-the-art methods under four evaluation metrics."],"url":"http://arxiv.org/abs/2307.00954v1"}
{"created":"2023-07-03 11:51:00","title":"Towards Explainable AI for Channel Estimation in Wireless Communications","abstract":"Research into 6G networks has been initiated to support a variety of critical artificial intelligence (AI) assisted applications such as autonomous driving. In such applications, AI-based decisions should be performed in a real-time manner. These decisions include resource allocation, localization, channel estimation, etc. Considering the black-box nature of existing AI-based models, it is highly challenging to understand and trust the decision-making behavior of such models. Therefore, explaining the logic behind those models through explainable AI (XAI) techniques is essential for their employment in critical applications. This manuscript proposes a novel XAI-based channel estimation (XAI-CHEST) scheme that provides detailed reasonable interpretability of the deep learning (DL) models that are employed in doubly-selective channel estimation. The aim of the proposed XAI-CHEST scheme is to identify the relevant model inputs by inducing high noise on the irrelevant ones. As a result, the behavior of the studied DL-based channel estimators can be further analyzed and evaluated based on the generated interpretations. Simulation results show that the proposed XAI-CHEST scheme provides valid interpretations of the DL-based channel estimators for different scenarios.","sentences":["Research into 6G networks has been initiated to support a variety of critical artificial intelligence (AI) assisted applications such as autonomous driving.","In such applications, AI-based decisions should be performed in a real-time manner.","These decisions include resource allocation, localization, channel estimation, etc.","Considering the black-box nature of existing AI-based models, it is highly challenging to understand and trust the decision-making behavior of such models.","Therefore, explaining the logic behind those models through explainable AI (XAI) techniques is essential for their employment in critical applications.","This manuscript proposes a novel XAI-based channel estimation (XAI-CHEST) scheme that provides detailed reasonable interpretability of the deep learning (DL) models that are employed in doubly-selective channel estimation.","The aim of the proposed XAI-CHEST scheme is to identify the relevant model inputs by inducing high noise on the irrelevant ones.","As a result, the behavior of the studied DL-based channel estimators can be further analyzed and evaluated based on the generated interpretations.","Simulation results show that the proposed XAI-CHEST scheme provides valid interpretations of the DL-based channel estimators for different scenarios."],"url":"http://arxiv.org/abs/2307.00952v1"}
{"created":"2023-07-03 11:49:53","title":"A Cross-Chain Query Language for Application-Level Interoperability Between Open and Permissionless Blockchains","abstract":"Open and permissionless blockchains are distributed systems with thousands to tens of thousands of nodes, establishing novel platforms for decentralized applications. When realizing such an application, data might be stored and retrieved from one or more blockchains by distributed network nodes without relying on centralized coordination and trusted third parties. Data access could be provided through a query language such as SQL at the application level, establishing a unified view on application-level data that is verifiably stored. However, when accessing multiple blockchains through their node software and APIs, interoperability cannot be assumed today, resulting in challenges of inhomogeneous data access. In addition, different feature sets and trade-offs exist, e.g., regarding smart contract functionality, availability, distribution, scalability, and security. For increasing interoperability, the paper at hand suggests pursuing the development of a cross-chain query language at the application level. The language abstracts from implementation by providing a standardized syntax, an integrated data model, and a processing architecture for data queries. This research is an extended and updated paper demonstrating the language syntax, data model, and architecture with an evaluation of compatibility against the largest open and permissionless blockchains today.","sentences":["Open and permissionless blockchains are distributed systems with thousands to tens of thousands of nodes, establishing novel platforms for decentralized applications.","When realizing such an application, data might be stored and retrieved from one or more blockchains by distributed network nodes without relying on centralized coordination and trusted third parties.","Data access could be provided through a query language such as SQL at the application level, establishing a unified view on application-level data that is verifiably stored.","However, when accessing multiple blockchains through their node software and APIs, interoperability cannot be assumed today, resulting in challenges of inhomogeneous data access.","In addition, different feature sets and trade-offs exist, e.g., regarding smart contract functionality, availability, distribution, scalability, and security.","For increasing interoperability, the paper at hand suggests pursuing the development of a cross-chain query language at the application level.","The language abstracts from implementation by providing a standardized syntax, an integrated data model, and a processing architecture for data queries.","This research is an extended and updated paper demonstrating the language syntax, data model, and architecture with an evaluation of compatibility against the largest open and permissionless blockchains today."],"url":"http://arxiv.org/abs/2307.00951v1"}
{"created":"2023-07-03 11:49:08","title":"Energy-aware Time- and Event-triggered KVM Nodes","abstract":"Industries are considering the adoption of cloud and edge computing for real-time applications due to current improvements in network latencies and the advent of Fog and Edge computing. Current cloud paradigms are not designed for real-time applications, as they neither provide low latencies/jitter nor the guarantees and determinism required by real-time applications. Experts estimate that data centers use 1% of global electricity for powering the equipment, and in turn, for dealing with the produced heat. Hence, energy consumption is a crucial metric in cloud technologies. Applying energy conservation techniques is not straightforward due to the increased scheduling overheads and application execution times. Inspired by slot shifting, we propose an algorithm to support energy-aware time-triggered execution of periodic real-time VMs while still providing the ability to execute aperiodic real-time and best-effort VMs in the slack of the time-triggered ones. The algorithm considers energy reduction techniques based on dynamic power management and dynamic voltage and frequency scaling. We implement our algorithm as an extension to the Linux kernel scheduler (for use with the KVM hypervisor) and evaluate it on a server-grade Intel Xeon node.","sentences":["Industries are considering the adoption of cloud and edge computing for real-time applications due to current improvements in network latencies and the advent of Fog and Edge computing.","Current cloud paradigms are not designed for real-time applications, as they neither provide low latencies/jitter nor the guarantees and determinism required by real-time applications.","Experts estimate that data centers use 1% of global electricity for powering the equipment, and in turn, for dealing with the produced heat.","Hence, energy consumption is a crucial metric in cloud technologies.","Applying energy conservation techniques is not straightforward due to the increased scheduling overheads and application execution times.","Inspired by slot shifting, we propose an algorithm to support energy-aware time-triggered execution of periodic real-time VMs while still providing the ability to execute aperiodic real-time and best-effort VMs in the slack of the time-triggered ones.","The algorithm considers energy reduction techniques based on dynamic power management and dynamic voltage and frequency scaling.","We implement our algorithm as an extension to the Linux kernel scheduler (for use with the KVM hypervisor) and evaluate it on a server-grade Intel Xeon node."],"url":"http://arxiv.org/abs/2307.00950v1"}
{"created":"2023-07-03 11:45:29","title":"Greedy Minimum-Energy Scheduling","abstract":"We consider the problem of energy-efficient scheduling across multiple processors with a power-down mechanism. In this setting a set of $n$ jobs with individual release times, deadlines, and processing volumes must be scheduled across $m$ parallel processors while minimizing the consumed energy. Idle processors can be turned off to save energy, while turning them on requires a fixed amount of energy. For the special case of a single processor, the greedy Left-to-Right algorithm guarantees an approximation factor of $2$. We generalize this simple greedy policy to the case of $m \\geq 1$ processors running in parallel and show that the energy costs are still bounded by $2 \\text{OPT} + P$, where $\\text{OPT}$ is the energy consumed by an optimal solution and $P < \\text{OPT}$ is the total processing volume. Our algorithm has a running time of $\\mathcal{O}(n f \\log d)$, where $d$ is the difference between the latest deadline and the earliest release time, and $f$ is the running time of a maximum flow calculation in a network of $\\mathcal{O}(n)$ nodes.","sentences":["We consider the problem of energy-efficient scheduling across multiple processors with a power-down mechanism.","In this setting a set of $n$ jobs with individual release times, deadlines, and processing volumes must be scheduled across $m$ parallel processors while minimizing the consumed energy.","Idle processors can be turned off to save energy, while turning them on requires a fixed amount of energy.","For the special case of a single processor, the greedy Left-to-Right algorithm guarantees an approximation factor of $2$. We generalize this simple greedy policy to the case of $m \\geq 1$ processors running in parallel and show that the energy costs are still bounded by $2 \\text{OPT} + P$, where $\\text{OPT}$ is the energy consumed by an optimal solution and $P <","\\text{OPT}$ is the total processing volume.","Our algorithm has a running time of $\\mathcal{O}(n f \\log d)$, where $d$ is the difference between the latest deadline and the earliest release time, and $f$ is the running time of a maximum flow calculation in a network of $\\mathcal{O}(n)$ nodes."],"url":"http://arxiv.org/abs/2307.00949v1"}
{"created":"2023-07-03 11:24:25","title":"Interpolation of Point Distributions for Digital Stippling","abstract":"We present a new way to merge any two point distribution approaches using distance fields. Our new process allows us to produce digital stippling that fills areas with stipple dots without visual artifacts as well as includes clear linear features without fussiness. Our merging thus benefits from past work that can optimize for either goal individually, yet typically by sacrificing the other. The new possibility of combining any two distributions using different distance field functions and their parameters also allows us to produce a vast range of stippling styles, which we demonstrate as well.","sentences":["We present a new way to merge any two point distribution approaches using distance fields.","Our new process allows us to produce digital stippling that fills areas with stipple dots without visual artifacts as well as includes clear linear features without fussiness.","Our merging thus benefits from past work that can optimize for either goal individually, yet typically by sacrificing the other.","The new possibility of combining any two distributions using different distance field functions and their parameters also allows us to produce a vast range of stippling styles, which we demonstrate as well."],"url":"http://arxiv.org/abs/2307.00938v1"}
{"created":"2023-07-03 11:24:11","title":"A Biomimetic Fingerprint for Robotic Tactile Sensing","abstract":"Tactile sensors have been developed since the early '70s and have greatly improved, but there are still no widely adopted solutions. Various technologies, such as capacitive, piezoelectric, piezoresistive, optical, and magnetic, are used in haptic sensing. However, most sensors are not mechanically robust for many applications and cannot cope well with curved or sizeable surfaces. Aiming to address this problem, we present a 3D printed fingerprint pattern to enhance the body-borne vibration signal for dynamic tactile feedback. The 3D printed fingerprint patterns were designed and tested for an RH8D Adult size Robot Hand. The patterns significantly increased the signal's power to over 11 times the baseline. A public haptic dataset including 52 objects of several materials was created using the best fingerprint pattern and material.","sentences":["Tactile sensors have been developed since the early '70s and have greatly improved, but there are still no widely adopted solutions.","Various technologies, such as capacitive, piezoelectric, piezoresistive, optical, and magnetic, are used in haptic sensing.","However, most sensors are not mechanically robust for many applications and cannot cope well with curved or sizeable surfaces.","Aiming to address this problem, we present a 3D printed fingerprint pattern to enhance the body-borne vibration signal for dynamic tactile feedback.","The 3D printed fingerprint patterns were designed and tested for an RH8D Adult size Robot Hand.","The patterns significantly increased the signal's power to over 11 times the baseline.","A public haptic dataset including 52 objects of several materials was created using the best fingerprint pattern and material."],"url":"http://arxiv.org/abs/2307.00937v1"}
{"created":"2023-07-03 11:21:09","title":"OpenAPMax: Abnormal Patterns-based Model for Real-World Alzheimer's Disease Diagnosis","abstract":"Alzheimer's disease (AD) cannot be reversed, but early diagnosis will significantly benefit patients' medical treatment and care. In recent works, AD diagnosis has the primary assumption that all categories are known a prior -- a closed-set classification problem, which contrasts with the open-set recognition problem. This assumption hinders the application of the model in natural clinical settings. Although many open-set recognition technologies have been proposed in other fields, they are challenging to use for AD diagnosis directly since 1) AD is a degenerative disease of the nervous system with similar symptoms at each stage, and it is difficult to distinguish from its pre-state, and 2) diversified strategies for AD diagnosis are challenging to model uniformly. In this work, inspired by the concerns of clinicians during diagnosis, we propose an open-set recognition model, OpenAPMax, based on the anomaly pattern to address AD diagnosis in real-world settings. OpenAPMax first obtains the abnormal pattern of each patient relative to each known category through statistics or a literature search, clusters the patients' abnormal pattern, and finally, uses extreme value theory (EVT) to model the distance between each patient's abnormal pattern and the center of their category and modify the classification probability. We evaluate the performance of the proposed method with recent open-set recognition, where we obtain state-of-the-art results.","sentences":["Alzheimer's disease (AD) cannot be reversed, but early diagnosis will significantly benefit patients' medical treatment and care.","In recent works, AD diagnosis has the primary assumption that all categories are known a prior -- a closed-set classification problem, which contrasts with the open-set recognition problem.","This assumption hinders the application of the model in natural clinical settings.","Although many open-set recognition technologies have been proposed in other fields, they are challenging to use for AD diagnosis directly since 1) AD is a degenerative disease of the nervous system with similar symptoms at each stage, and it is difficult to distinguish from its pre-state, and 2) diversified strategies for AD diagnosis are challenging to model uniformly.","In this work, inspired by the concerns of clinicians during diagnosis, we propose an open-set recognition model, OpenAPMax, based on the anomaly pattern to address AD diagnosis in real-world settings.","OpenAPMax first obtains the abnormal pattern of each patient relative to each known category through statistics or a literature search, clusters the patients' abnormal pattern, and finally, uses extreme value theory (EVT) to model the distance between each patient's abnormal pattern and the center of their category and modify the classification probability.","We evaluate the performance of the proposed method with recent open-set recognition, where we obtain state-of-the-art results."],"url":"http://arxiv.org/abs/2307.00936v1"}
{"created":"2023-07-03 11:16:39","title":"Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration","abstract":"The current approach for testing the robustness of object detectors suffers from serious deficiencies such as improper methods of performing out-of-distribution detection and using calibration metrics which do not consider both localisation and classification quality. In this work, we address these issues, and introduce the Self-Aware Object Detection (SAOD) task, a unified testing framework which respects and adheres to the challenges that object detectors face in safety-critical environments such as autonomous driving. Specifically, the SAOD task requires an object detector to be: robust to domain shift; obtain reliable uncertainty estimates for the entire scene; and provide calibrated confidence scores for the detections. We extensively use our framework, which introduces novel metrics and large scale test datasets, to test numerous object detectors in two different use-cases, allowing us to highlight critical insights into their robustness performance. Finally, we introduce a simple baseline for the SAOD task, enabling researchers to benchmark future proposed methods and move towards robust object detectors which are fit for purpose. Code is available at https://github.com/fiveai/saod","sentences":["The current approach for testing the robustness of object detectors suffers from serious deficiencies such as improper methods of performing out-of-distribution detection and using calibration metrics which do not consider both localisation and classification quality.","In this work, we address these issues, and introduce the Self-Aware Object Detection (SAOD) task, a unified testing framework which respects and adheres to the challenges that object detectors face in safety-critical environments such as autonomous driving.","Specifically, the SAOD task requires an object detector to be: robust to domain shift; obtain reliable uncertainty estimates for the entire scene; and provide calibrated confidence scores for the detections.","We extensively use our framework, which introduces novel metrics and large scale test datasets, to test numerous object detectors in two different use-cases, allowing us to highlight critical insights into their robustness performance.","Finally, we introduce a simple baseline for the SAOD task, enabling researchers to benchmark future proposed methods and move towards robust object detectors which are fit for purpose.","Code is available at https://github.com/fiveai/saod"],"url":"http://arxiv.org/abs/2307.00934v1"}
{"created":"2023-07-03 11:15:42","title":"Data-Driven Information Extraction and Enrichment of Molecular Profiling Data for Cancer Cell Lines","abstract":"With the proliferation of research means and computational methodologies, published biomedical literature is growing exponentially in numbers and volume. As a consequence, in the fields of biological, medical and clinical research, domain experts have to sift through massive amounts of scientific text to find relevant information. However, this process is extremely tedious and slow to be performed by humans. Hence, novel computational information extraction and correlation mechanisms are required to boost meaningful knowledge extraction. In this work, we present the design, implementation and application of a novel data extraction and exploration system. This system extracts deep semantic relations between textual entities from scientific literature to enrich existing structured clinical data in the domain of cancer cell lines. We introduce a new public data exploration portal, which enables automatic linking of genomic copy number variants plots with ranked, related entities such as affected genes. Each relation is accompanied by literature-derived evidences, allowing for deep, yet rapid, literature search, using existing structured data as a springboard. Our system is publicly available on the web at https://cancercelllines.org","sentences":["With the proliferation of research means and computational methodologies, published biomedical literature is growing exponentially in numbers and volume.","As a consequence, in the fields of biological, medical and clinical research, domain experts have to sift through massive amounts of scientific text to find relevant information.","However, this process is extremely tedious and slow to be performed by humans.","Hence, novel computational information extraction and correlation mechanisms are required to boost meaningful knowledge extraction.","In this work, we present the design, implementation and application of a novel data extraction and exploration system.","This system extracts deep semantic relations between textual entities from scientific literature to enrich existing structured clinical data in the domain of cancer cell lines.","We introduce a new public data exploration portal, which enables automatic linking of genomic copy number variants plots with ranked, related entities such as affected genes.","Each relation is accompanied by literature-derived evidences, allowing for deep, yet rapid, literature search, using existing structured data as a springboard.","Our system is publicly available on the web at https://cancercelllines.org"],"url":"http://arxiv.org/abs/2307.00933v1"}
{"created":"2023-07-03 11:02:40","title":"Learning Differentiable Logic Programs for Abstract Visual Reasoning","abstract":"Visual reasoning is essential for building intelligent agents that understand the world and perform problem-solving beyond perception. Differentiable forward reasoning has been developed to integrate reasoning with gradient-based machine learning paradigms. However, due to the memory intensity, most existing approaches do not bring the best of the expressivity of first-order logic, excluding a crucial ability to solve abstract visual reasoning, where agents need to perform reasoning by using analogies on abstract concepts in different scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner, passing messages in a memory-efficient manner and handling structured programs with functors. Moreover, we propose a computationally-efficient structure learning algorithm to perform explanatory program induction on complex visual scenes. To evaluate, in addition to conventional visual reasoning tasks, we propose a new task, visual reasoning behind-the-scenes, where agents need to learn abstract programs and then answer queries by imagining scenes that are not observed. We empirically demonstrate that NEUMANN solves visual reasoning tasks efficiently, outperforming neural, symbolic, and neuro-symbolic baselines.","sentences":["Visual reasoning is essential for building intelligent agents that understand the world and perform problem-solving beyond perception.","Differentiable forward reasoning has been developed to integrate reasoning with gradient-based machine learning paradigms.","However, due to the memory intensity, most existing approaches do not bring the best of the expressivity of first-order logic, excluding a crucial ability to solve abstract visual reasoning, where agents need to perform reasoning by using analogies on abstract concepts in different scenarios.","To overcome this problem, we propose NEUro-symbolic Message-pAssiNg reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner, passing messages in a memory-efficient manner and handling structured programs with functors.","Moreover, we propose a computationally-efficient structure learning algorithm to perform explanatory program induction on complex visual scenes.","To evaluate, in addition to conventional visual reasoning tasks, we propose a new task, visual reasoning behind-the-scenes, where agents need to learn abstract programs and then answer queries by imagining scenes that are not observed.","We empirically demonstrate that NEUMANN solves visual reasoning tasks efficiently, outperforming neural, symbolic, and neuro-symbolic baselines."],"url":"http://arxiv.org/abs/2307.00928v1"}
{"created":"2023-07-03 10:54:59","title":"Reduced-Complexity Cross-Domain Iterative Detection for OTFS Modulation via Delay-Doppler Decoupling","abstract":"In this paper, a reduced-complexity cross-domain iterative detection for orthogonal time frequency space (OTFS) modulation is proposed, which exploits channel properties in both time and delay-Doppler domains. Specifically, we first show that in the time domain effective channel, the path delay only introduces interference among samples in adjacent time slots, while the Doppler becomes a phase term that does not affect the channel sparsity. This ``band-limited'' matrix structure motivates us to apply a reduced-size linear minimum mean square error (LMMSE) filter to eliminate the effect of delay in the time domain, while exploiting the cross-domain iteration for minimizing the effect of Doppler by noticing that the time and Doppler are a pair of Fourier dual. The state (MSE) evolution was derived and compared with bounds to verify the effectiveness of the proposed scheme. Simulation results demonstrate that the proposed scheme achieves almost the same error performance as the optimal detection, but only requires a reduced complexity.","sentences":["In this paper, a reduced-complexity cross-domain iterative detection for orthogonal time frequency space (OTFS) modulation is proposed, which exploits channel properties in both time and delay-Doppler domains.","Specifically, we first show that in the time domain effective channel, the path delay only introduces interference among samples in adjacent time slots, while the Doppler becomes a phase term that does not affect the channel sparsity.","This ``band-limited'' matrix structure motivates us to apply a reduced-size linear minimum mean square error (LMMSE) filter to eliminate the effect of delay in the time domain, while exploiting the cross-domain iteration for minimizing the effect of Doppler by noticing that the time and Doppler are a pair of Fourier dual.","The state (MSE) evolution was derived and compared with bounds to verify the effectiveness of the proposed scheme.","Simulation results demonstrate that the proposed scheme achieves almost the same error performance as the optimal detection, but only requires a reduced complexity."],"url":"http://arxiv.org/abs/2307.00926v1"}
{"created":"2023-07-03 10:53:05","title":"Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution","abstract":"Semantic similarity measures are widely used in natural language processing to catalyze various computer-related tasks. However, no single semantic similarity measure is the most appropriate for all tasks, and researchers often use ensemble strategies to ensure performance. This research work proposes a method for automatically designing semantic similarity ensembles. In fact, our proposed method uses grammatical evolution, for the first time, to automatically select and aggregate measures from a pool of candidates to create an ensemble that maximizes correlation to human judgment. The method is evaluated on several benchmark datasets and compared to state-of-the-art ensembles, showing that it can significantly improve similarity assessment accuracy and outperform existing methods in some cases. As a result, our research demonstrates the potential of using grammatical evolution to automatically compare text and prove the benefits of using ensembles for semantic similarity tasks.","sentences":["Semantic similarity measures are widely used in natural language processing to catalyze various computer-related tasks.","However, no single semantic similarity measure is the most appropriate for all tasks, and researchers often use ensemble strategies to ensure performance.","This research work proposes a method for automatically designing semantic similarity ensembles.","In fact, our proposed method uses grammatical evolution, for the first time, to automatically select and aggregate measures from a pool of candidates to create an ensemble that maximizes correlation to human judgment.","The method is evaluated on several benchmark datasets and compared to state-of-the-art ensembles, showing that it can significantly improve similarity assessment accuracy and outperform existing methods in some cases.","As a result, our research demonstrates the potential of using grammatical evolution to automatically compare text and prove the benefits of using ensembles for semantic similarity tasks."],"url":"http://arxiv.org/abs/2307.00925v1"}
{"created":"2023-07-03 10:50:44","title":"Semi-supervised multi-view concept decomposition","abstract":"Concept Factorization (CF), as a novel paradigm of representation learning, has demonstrated superior performance in multi-view clustering tasks. It overcomes limitations such as the non-negativity constraint imposed by traditional matrix factorization methods and leverages kernel methods to learn latent representations that capture the underlying structure of the data, thereby improving data representation. However, existing multi-view concept factorization methods fail to consider the limited labeled information inherent in real-world multi-view data. This often leads to significant performance loss. To overcome these limitations, we propose a novel semi-supervised multi-view concept factorization model, named SMVCF. In the SMVCF model, we first extend the conventional single-view CF to a multi-view version, enabling more effective exploration of complementary information across multiple views. We then integrate multi-view CF, label propagation, and manifold learning into a unified framework to leverage and incorporate valuable information present in the data. Additionally, an adaptive weight vector is introduced to balance the importance of different views in the clustering process. We further develop targeted optimization methods specifically tailored for the SMVCF model. Finally, we conduct extensive experiments on four diverse datasets with varying label ratios to evaluate the performance of SMVCF. The experimental results demonstrate the effectiveness and superiority of our proposed approach in multi-view clustering tasks.","sentences":["Concept Factorization (CF), as a novel paradigm of representation learning, has demonstrated superior performance in multi-view clustering tasks.","It overcomes limitations such as the non-negativity constraint imposed by traditional matrix factorization methods and leverages kernel methods to learn latent representations that capture the underlying structure of the data, thereby improving data representation.","However, existing multi-view concept factorization methods fail to consider the limited labeled information inherent in real-world multi-view data.","This often leads to significant performance loss.","To overcome these limitations, we propose a novel semi-supervised multi-view concept factorization model, named SMVCF.","In the SMVCF model, we first extend the conventional single-view CF to a multi-view version, enabling more effective exploration of complementary information across multiple views.","We then integrate multi-view CF, label propagation, and manifold learning into a unified framework to leverage and incorporate valuable information present in the data.","Additionally, an adaptive weight vector is introduced to balance the importance of different views in the clustering process.","We further develop targeted optimization methods specifically tailored for the SMVCF model.","Finally, we conduct extensive experiments on four diverse datasets with varying label ratios to evaluate the performance of SMVCF.","The experimental results demonstrate the effectiveness and superiority of our proposed approach in multi-view clustering tasks."],"url":"http://arxiv.org/abs/2307.00924v1"}
{"created":"2023-07-03 10:49:31","title":"Achieving Stable Training of Reinforcement Learning Agents in Bimodal Environments through Batch Learning","abstract":"Bimodal, stochastic environments present a challenge to typical Reinforcement Learning problems. This problem is one that is surprisingly common in real world applications, being particularly applicable to pricing problems. In this paper we present a novel learning approach to the tabular Q-learning algorithm, tailored to tackling these specific challenges by using batch updates. A simulation of pricing problem is used as a testbed to compare a typically updated agent with a batch learning agent. The batch learning agents are shown to be both more effective than the typically-trained agents, and to be more resilient to the fluctuations in a large stochastic environment. This work has a significant potential to enable practical, industrial deployment of Reinforcement Learning in the context of pricing and others.","sentences":["Bimodal, stochastic environments present a challenge to typical Reinforcement Learning problems.","This problem is one that is surprisingly common in real world applications, being particularly applicable to pricing problems.","In this paper we present a novel learning approach to the tabular Q-learning algorithm, tailored to tackling these specific challenges by using batch updates.","A simulation of pricing problem is used as a testbed to compare a typically updated agent with a batch learning agent.","The batch learning agents are shown to be both more effective than the typically-trained agents, and to be more resilient to the fluctuations in a large stochastic environment.","This work has a significant potential to enable practical, industrial deployment of Reinforcement Learning in the context of pricing and others."],"url":"http://arxiv.org/abs/2307.00923v1"}
{"created":"2023-07-03 10:44:07","title":"Node-weighted Graph Convolutional Network for Depression Detection in Transcribed Clinical Interviews","abstract":"We propose a simple approach for weighting self-connecting edges in a Graph Convolutional Network (GCN) and show its impact on depression detection from transcribed clinical interviews. To this end, we use a GCN for modeling non-consecutive and long-distance semantics to classify the transcriptions into depressed or control subjects. The proposed method aims to mitigate the limiting assumptions of locality and the equal importance of self-connections vs. edges to neighboring nodes in GCNs, while preserving attractive features such as low computational cost, data agnostic, and interpretability capabilities. We perform an exhaustive evaluation in two benchmark datasets. Results show that our approach consistently outperforms the vanilla GCN model as well as previously reported results, achieving an F1=0.84% on both datasets. Finally, a qualitative analysis illustrates the interpretability capabilities of the proposed approach and its alignment with previous findings in psychology.","sentences":["We propose a simple approach for weighting self-connecting edges in a Graph Convolutional Network (GCN) and show its impact on depression detection from transcribed clinical interviews.","To this end, we use a GCN for modeling non-consecutive and long-distance semantics to classify the transcriptions into depressed or control subjects.","The proposed method aims to mitigate the limiting assumptions of locality and the equal importance of self-connections vs. edges to neighboring nodes in GCNs, while preserving attractive features such as low computational cost, data agnostic, and interpretability capabilities.","We perform an exhaustive evaluation in two benchmark datasets.","Results show that our approach consistently outperforms the vanilla GCN model as well as previously reported results, achieving an F1=0.84% on both datasets.","Finally, a qualitative analysis illustrates the interpretability capabilities of the proposed approach and its alignment with previous findings in psychology."],"url":"http://arxiv.org/abs/2307.00920v1"}
{"created":"2023-07-03 10:41:34","title":"Why do CNNs excel at feature extraction? A mathematical explanation","abstract":"Over the past decade deep learning has revolutionized the field of computer vision, with convolutional neural network models proving to be very effective for image classification benchmarks. However, a fundamental theoretical questions remain answered: why can they solve discrete image classification tasks that involve feature extraction? We address this question in this paper by introducing a novel mathematical model for image classification, based on feature extraction, that can be used to generate images resembling real-world datasets. We show that convolutional neural network classifiers can solve these image classification tasks with zero error. In our proof, we construct piecewise linear functions that detect the presence of features, and show that they can be realized by a convolutional network.","sentences":["Over the past decade deep learning has revolutionized the field of computer vision, with convolutional neural network models proving to be very effective for image classification benchmarks.","However, a fundamental theoretical questions remain answered: why can they solve discrete image classification tasks that involve feature extraction?","We address this question in this paper by introducing a novel mathematical model for image classification, based on feature extraction, that can be used to generate images resembling real-world datasets.","We show that convolutional neural network classifiers can solve these image classification tasks with zero error.","In our proof, we construct piecewise linear functions that detect the presence of features, and show that they can be realized by a convolutional network."],"url":"http://arxiv.org/abs/2307.00919v1"}
{"created":"2023-07-03 10:14:33","title":"Contextual Prompt Learning for Vision-Language Understanding","abstract":"Recent advances in multimodal learning has resulted in powerful vision-language models, whose representations are generalizable across a variety of downstream tasks. Recently, their generalizability has been further extended by incorporating trainable prompts, borrowed from the natural language processing literature. While such prompt learning techniques have shown impressive results, we identify that these prompts are trained based on global image features which limits itself in two aspects: First, by using global features, these prompts could be focusing less on the discriminative foreground image, resulting in poor generalization to various out-of-distribution test cases. Second, existing work weights all prompts equally whereas our intuition is that these prompts are more specific to the type of the image. We address these issues with as part of our proposed Contextual Prompt Learning (CoPL) framework, capable of aligning the prompts to the localized features of the image. Our key innovations over earlier works include using local image features as part of the prompt learning process, and more crucially, learning to weight these prompts based on local features that are appropriate for the task at hand. This gives us dynamic prompts that are both aligned to local image features as well as aware of local contextual relationships. Our extensive set of experiments on a variety of standard and few-shot datasets show that our method produces substantially improved performance when compared to the current state of the art methods. We also demonstrate both few-shot and out-of-distribution performance to establish the utility of learning dynamic prompts that are aligned to local image features.","sentences":["Recent advances in multimodal learning has resulted in powerful vision-language models, whose representations are generalizable across a variety of downstream tasks.","Recently, their generalizability has been further extended by incorporating trainable prompts, borrowed from the natural language processing literature.","While such prompt learning techniques have shown impressive results, we identify that these prompts are trained based on global image features which limits itself in two aspects: First, by using global features, these prompts could be focusing less on the discriminative foreground image, resulting in poor generalization to various out-of-distribution test cases.","Second, existing work weights all prompts equally whereas our intuition is that these prompts are more specific to the type of the image.","We address these issues with as part of our proposed Contextual Prompt Learning (CoPL) framework, capable of aligning the prompts to the localized features of the image.","Our key innovations over earlier works include using local image features as part of the prompt learning process, and more crucially, learning to weight these prompts based on local features that are appropriate for the task at hand.","This gives us dynamic prompts that are both aligned to local image features as well as aware of local contextual relationships.","Our extensive set of experiments on a variety of standard and few-shot datasets show that our method produces substantially improved performance when compared to the current state of the art methods.","We also demonstrate both few-shot and out-of-distribution performance to establish the utility of learning dynamic prompts that are aligned to local image features."],"url":"http://arxiv.org/abs/2307.00910v1"}
{"created":"2023-07-03 10:10:34","title":"Enhancing the Robustness of QMIX against State-adversarial Attacks","abstract":"Deep reinforcement learning (DRL) performance is generally impacted by state-adversarial attacks, a perturbation applied to an agent's observation. Most recent research has concentrated on robust single-agent reinforcement learning (SARL) algorithms against state-adversarial attacks. Still, there has yet to be much work on robust multi-agent reinforcement learning. Using QMIX, one of the popular cooperative multi-agent reinforcement algorithms, as an example, we discuss four techniques to improve the robustness of SARL algorithms and extend them to multi-agent scenarios. To increase the robustness of multi-agent reinforcement learning (MARL) algorithms, we train models using a variety of attacks in this research. We then test the models taught using the other attacks by subjecting them to the corresponding attacks throughout the training phase. In this way, we organize and summarize techniques for enhancing robustness when used with MARL.","sentences":["Deep reinforcement learning (DRL) performance is generally impacted by state-adversarial attacks, a perturbation applied to an agent's observation.","Most recent research has concentrated on robust single-agent reinforcement learning (SARL) algorithms against state-adversarial attacks.","Still, there has yet to be much work on robust multi-agent reinforcement learning.","Using QMIX, one of the popular cooperative multi-agent reinforcement algorithms, as an example, we discuss four techniques to improve the robustness of SARL algorithms and extend them to multi-agent scenarios.","To increase the robustness of multi-agent reinforcement learning (MARL) algorithms, we train models using a variety of attacks in this research.","We then test the models taught using the other attacks by subjecting them to the corresponding attacks throughout the training phase.","In this way, we organize and summarize techniques for enhancing robustness when used with MARL."],"url":"http://arxiv.org/abs/2307.00907v1"}
{"created":"2023-07-03 09:52:54","title":"Many tasks make light work: Learning to localise medical anomalies from multiple synthetic tasks","abstract":"There is a growing interest in single-class modelling and out-of-distribution detection as fully supervised machine learning models cannot reliably identify classes not included in their training. The long tail of infinitely many out-of-distribution classes in real-world scenarios, e.g., for screening, triage, and quality control, means that it is often necessary to train single-class models that represent an expected feature distribution, e.g., from only strictly healthy volunteer data. Conventional supervised machine learning would require the collection of datasets that contain enough samples of all possible diseases in every imaging modality, which is not realistic. Self-supervised learning methods with synthetic anomalies are currently amongst the most promising approaches, alongside generative auto-encoders that analyse the residual reconstruction error. However, all methods suffer from a lack of structured validation, which makes calibration for deployment difficult and dataset-dependant. Our method alleviates this by making use of multiple visually-distinct synthetic anomaly learning tasks for both training and validation. This enables more robust training and generalisation. With our approach we can readily outperform state-of-the-art methods, which we demonstrate on exemplars in brain MRI and chest X-rays. Code is available at https://github.com/matt-baugh/many-tasks-make-light-work .","sentences":["There is a growing interest in single-class modelling and out-of-distribution detection as fully supervised machine learning models cannot reliably identify classes not included in their training.","The long tail of infinitely many out-of-distribution classes in real-world scenarios, e.g., for screening, triage, and quality control, means that it is often necessary to train single-class models that represent an expected feature distribution, e.g., from only strictly healthy volunteer data.","Conventional supervised machine learning would require the collection of datasets that contain enough samples of all possible diseases in every imaging modality, which is not realistic.","Self-supervised learning methods with synthetic anomalies are currently amongst the most promising approaches, alongside generative auto-encoders that analyse the residual reconstruction error.","However, all methods suffer from a lack of structured validation, which makes calibration for deployment difficult and dataset-dependant.","Our method alleviates this by making use of multiple visually-distinct synthetic anomaly learning tasks for both training and validation.","This enables more robust training and generalisation.","With our approach we can readily outperform state-of-the-art methods, which we demonstrate on exemplars in brain MRI and chest X-rays.","Code is available at https://github.com/matt-baugh/many-tasks-make-light-work ."],"url":"http://arxiv.org/abs/2307.00899v1"}
{"created":"2023-07-03 09:50:08","title":"Fixing confirmation bias in feature attribution methods via semantic match","abstract":"Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the \"semantic match\" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spanning tabular and image data, and show how the assessment of semantic match can give insight into both desirable (e.g., focusing on an object relevant for prediction) and undesirable model behaviors (e.g., focusing on a spurious correlation). We couple our experimental results with an analysis on the metrics to measure semantic match, and argue that this approach constitutes the first step towards resolving the issue of confirmation bias in XAI.","sentences":["Feature attribution methods have become a staple method to disentangle the complex behavior of black box models.","Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts.","Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior.","We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions.","This is what we call the \"semantic match\" between human concepts and (sub-symbolic) explanations.","Building on the conceptual framework put forward in Cin\\`a et al.","[2023], we propose a structured approach to evaluate semantic match in practice.","We showcase the procedure in a suite of experiments spanning tabular and image data, and show how the assessment of semantic match can give insight into both desirable (e.g., focusing on an object relevant for prediction) and undesirable model behaviors (e.g., focusing on a spurious correlation).","We couple our experimental results with an analysis on the metrics to measure semantic match, and argue that this approach constitutes the first step towards resolving the issue of confirmation bias in XAI."],"url":"http://arxiv.org/abs/2307.00897v1"}
{"created":"2023-07-03 09:44:39","title":"Mega-cities dominate China's urban greening","abstract":"Trees play a crucial role in urban environments, offering various ecosystem services that contribute to public health and human well-being. China has initiated a range of urban greening policies over the past decades, however, monitoring their impact on urban tree dynamics at a national scale has proven challenging. In this study, we deployed nano-satellites to quantify urban tree coverage in all major Chinese cities larger than 50 km2 in 2010 and 2019. Our findings indicate that approximately 6000 km2 (11%) of urban areas were covered by trees in 2019, and 76% of these cities experienced an increase in tree cover compared to 2010. Notably, the increase in tree cover in mega-cities such as Beijing, and Shanghai was approximately twice as large as in most other cities (7.69% vs 3.94%). The study employs a data-driven approach towards assessing urban tree cover changes in relation to greening policies, showing clear signs of tree cover increases but also suggesting an uneven implementation primarily benefiting a few mega-cities.","sentences":["Trees play a crucial role in urban environments, offering various ecosystem services that contribute to public health and human well-being.","China has initiated a range of urban greening policies over the past decades, however, monitoring their impact on urban tree dynamics at a national scale has proven challenging.","In this study, we deployed nano-satellites to quantify urban tree coverage in all major Chinese cities larger than 50 km2 in 2010 and 2019.","Our findings indicate that approximately 6000 km2 (11%) of urban areas were covered by trees in 2019, and 76% of these cities experienced an increase in tree cover compared to 2010.","Notably, the increase in tree cover in mega-cities such as Beijing, and Shanghai was approximately twice as large as in most other cities (7.69% vs 3.94%).","The study employs a data-driven approach towards assessing urban tree cover changes in relation to greening policies, showing clear signs of tree cover increases but also suggesting an uneven implementation primarily benefiting a few mega-cities."],"url":"http://arxiv.org/abs/2307.00894v1"}
{"created":"2023-07-03 09:44:13","title":"Generating Reliable Pixel-Level Labels for Source Free Domain Adaptation","abstract":"This work addresses the challenging domain adaptation setting in which knowledge from the labelled source domain dataset is available only from the pretrained black-box segmentation model. The pretrained model's predictions for the target domain images are noisy because of the distributional differences between the source domain data and the target domain data. Since the model's predictions serve as pseudo labels during self-training, the noise in the predictions impose an upper bound on model performance. Therefore, we propose a simple yet novel image translation workflow, ReGEN, to address this problem. ReGEN comprises an image-to-image translation network and a segmentation network. Our workflow generates target-like images using the noisy predictions from the original target domain images. These target-like images are semantically consistent with the noisy model predictions and therefore can be used to train the segmentation network. In addition to being semantically consistent with the predictions from the original target domain images, the generated target-like images are also stylistically similar to the target domain images. This allows us to leverage the stylistic differences between the target-like images and the target domain image as an additional source of supervision while training the segmentation model. We evaluate our model with two benchmark domain adaptation settings and demonstrate that our approach performs favourably relative to recent state-of-the-art work. The source code will be made available.","sentences":["This work addresses the challenging domain adaptation setting in which knowledge from the labelled source domain dataset is available only from the pretrained black-box segmentation model.","The pretrained model's predictions for the target domain images are noisy because of the distributional differences between the source domain data and the target domain data.","Since the model's predictions serve as pseudo labels during self-training, the noise in the predictions impose an upper bound on model performance.","Therefore, we propose a simple yet novel image translation workflow, ReGEN, to address this problem.","ReGEN comprises an image-to-image translation network and a segmentation network.","Our workflow generates target-like images using the noisy predictions from the original target domain images.","These target-like images are semantically consistent with the noisy model predictions and therefore can be used to train the segmentation network.","In addition to being semantically consistent with the predictions from the original target domain images, the generated target-like images are also stylistically similar to the target domain images.","This allows us to leverage the stylistic differences between the target-like images and the target domain image as an additional source of supervision while training the segmentation model.","We evaluate our model with two benchmark domain adaptation settings and demonstrate that our approach performs favourably relative to recent state-of-the-art work.","The source code will be made available."],"url":"http://arxiv.org/abs/2307.00893v1"}
{"created":"2023-07-03 09:44:10","title":"Tales from the Git: Automating the detection of secrets on code and assessing developers' passwords choices","abstract":"Typical users are known to use and reuse weak passwords. Yet, as cybersecurity concerns continue to rise, understanding the password practices of software developers becomes increasingly important. In this work, we examine developers' passwords on public repositories. Our dedicated crawler collected millions of passwords from public GitHub repositories; however, our focus is on their unique characteristics. To this end, this is the first study investigating the developer traits in password selection across different programming languages and contexts, e.g. email and database. Despite the fact that developers may have carelessly leaked their code on public repositories, our findings indicate that they tend to use significantly more secure passwords, regardless of the underlying programming language and context. Nevertheless, when the context allows, they often resort to similar password selection criteria as typical users. The public availability of such information in a cleartext format indicates that there is still much room for improvement and that further targeted awareness campaigns are necessary.","sentences":["Typical users are known to use and reuse weak passwords.","Yet, as cybersecurity concerns continue to rise, understanding the password practices of software developers becomes increasingly important.","In this work, we examine developers' passwords on public repositories.","Our dedicated crawler collected millions of passwords from public GitHub repositories; however, our focus is on their unique characteristics.","To this end, this is the first study investigating the developer traits in password selection across different programming languages and contexts, e.g. email and database.","Despite the fact that developers may have carelessly leaked their code on public repositories, our findings indicate that they tend to use significantly more secure passwords, regardless of the underlying programming language and context.","Nevertheless, when the context allows, they often resort to similar password selection criteria as typical users.","The public availability of such information in a cleartext format indicates that there is still much room for improvement and that further targeted awareness campaigns are necessary."],"url":"http://arxiv.org/abs/2307.00892v1"}
{"created":"2023-07-03 09:40:50","title":"Efficient Interpolation-Based Decoding of Reed-Solomon Codes","abstract":"We propose a new interpolation-based error decoding algorithm for $(n,k)$ Reed-Solomon (RS) codes over a finite field of size $q$, where $n=q-1$ is the length and $k$ is the dimension. In particular, we employ the fast Fourier transform (FFT) together with properties of a circulant matrix associated with the error interpolation polynomial and some known results from elimination theory in the decoding process. The asymptotic computational complexity of the proposed algorithm for correcting any $t \\leq \\lfloor \\frac{n-k}{2} \\rfloor$ errors in an $(n,k)$ RS code is of order $\\mathcal{O}(t\\log^2 t)$ and $\\mathcal{O}(n\\log^2 n \\log\\log n)$ over FFT-friendly and arbitrary finite fields, respectively, achieving the best currently known asymptotic decoding complexity, proposed for the same set of parameters.","sentences":["We propose a new interpolation-based error decoding algorithm for $(n,k)$ Reed-Solomon (RS) codes over a finite field of size $q$, where $n=q-1$ is the length and $k$ is the dimension.","In particular, we employ the fast Fourier transform (FFT) together with properties of a circulant matrix associated with the error interpolation polynomial and some known results from elimination theory in the decoding process.","The asymptotic computational complexity of the proposed algorithm for correcting any $t \\leq \\lfloor \\frac{n-k}{2} \\rfloor$ errors in an $(n,k)$ RS code is of order $\\mathcal{O}(t\\log^2 t)$ and $\\mathcal{O}(n\\log^2 n \\log\\log n)$ over FFT-friendly and arbitrary finite fields, respectively, achieving the best currently known asymptotic decoding complexity, proposed for the same set of parameters."],"url":"http://arxiv.org/abs/2307.00891v1"}
{"created":"2023-07-03 09:29:27","title":"Augmenting Deep Learning Adaptation for Wearable Sensor Data through Combined Temporal-Frequency Image Encoding","abstract":"Deep learning advancements have revolutionized scalable classification in many domains including computer vision. However, when it comes to wearable-based classification and domain adaptation, existing computer vision-based deep learning architectures and pretrained models trained on thousands of labeled images for months fall short. This is primarily because wearable sensor data necessitates sensor-specific preprocessing, architectural modification, and extensive data collection. To overcome these challenges, researchers have proposed encoding of wearable temporal sensor data in images using recurrent plots. In this paper, we present a novel modified-recurrent plot-based image representation that seamlessly integrates both temporal and frequency domain information. Our approach incorporates an efficient Fourier transform-based frequency domain angular difference estimation scheme in conjunction with the existing temporal recurrent plot image. Furthermore, we employ mixup image augmentation to enhance the representation. We evaluate the proposed method using accelerometer-based activity recognition data and a pretrained ResNet model, and demonstrate its superior performance compared to existing approaches.","sentences":["Deep learning advancements have revolutionized scalable classification in many domains including computer vision.","However, when it comes to wearable-based classification and domain adaptation, existing computer vision-based deep learning architectures and pretrained models trained on thousands of labeled images for months fall short.","This is primarily because wearable sensor data necessitates sensor-specific preprocessing, architectural modification, and extensive data collection.","To overcome these challenges, researchers have proposed encoding of wearable temporal sensor data in images using recurrent plots.","In this paper, we present a novel modified-recurrent plot-based image representation that seamlessly integrates both temporal and frequency domain information.","Our approach incorporates an efficient Fourier transform-based frequency domain angular difference estimation scheme in conjunction with the existing temporal recurrent plot image.","Furthermore, we employ mixup image augmentation to enhance the representation.","We evaluate the proposed method using accelerometer-based activity recognition data and a pretrained ResNet model, and demonstrate its superior performance compared to existing approaches."],"url":"http://arxiv.org/abs/2307.00883v1"}
{"created":"2023-07-03 09:20:28","title":"Co-Learning Meets Stitch-Up for Noisy Multi-label Visual Recognition","abstract":"In real-world scenarios, collected and annotated data often exhibit the characteristics of multiple classes and long-tailed distribution. Additionally, label noise is inevitable in large-scale annotations and hinders the applications of learning-based models. Although many deep learning based methods have been proposed for handling long-tailed multi-label recognition or label noise respectively, learning with noisy labels in long-tailed multi-label visual data has not been well-studied because of the complexity of long-tailed distribution entangled with multi-label correlation. To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of multi-label classification and long-tailed learning under noisy cases. In detail, we propose a Stitch-Up augmentation to synthesize a cleaner sample, which directly reduces multi-label noise by stitching up multiple noisy training samples. Equipped with Stitch-Up, a Heterogeneous Co-Learning framework is further designed to leverage the inconsistency between long-tailed and balanced distributions, yielding cleaner labels for more robust representation learning with noisy long-tailed data. To validate our method, we build two challenging benchmarks, named VOC-MLT-Noise and COCO-MLT-Noise, respectively. Extensive experiments are conducted to demonstrate the effectiveness of our proposed method. Compared to a variety of baselines, our method achieves superior results.","sentences":["In real-world scenarios, collected and annotated data often exhibit the characteristics of multiple classes and long-tailed distribution.","Additionally, label noise is inevitable in large-scale annotations and hinders the applications of learning-based models.","Although many deep learning based methods have been proposed for handling long-tailed multi-label recognition or label noise respectively, learning with noisy labels in long-tailed multi-label visual data has not been well-studied because of the complexity of long-tailed distribution entangled with multi-label correlation.","To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of multi-label classification and long-tailed learning under noisy cases.","In detail, we propose a Stitch-Up augmentation to synthesize a cleaner sample, which directly reduces multi-label noise by stitching up multiple noisy training samples.","Equipped with Stitch-Up, a Heterogeneous Co-Learning framework is further designed to leverage the inconsistency between long-tailed and balanced distributions, yielding cleaner labels for more robust representation learning with noisy long-tailed data.","To validate our method, we build two challenging benchmarks, named VOC-MLT-Noise and COCO-MLT-Noise, respectively.","Extensive experiments are conducted to demonstrate the effectiveness of our proposed method.","Compared to a variety of baselines, our method achieves superior results."],"url":"http://arxiv.org/abs/2307.00880v1"}
{"created":"2023-07-03 09:10:21","title":"Cryptography and Key Management Schemes for Wireless Sensor Networks","abstract":"Wireless sensor networks (WSNs) are made up of a large number of tiny sensors, which can sense, analyze, and communicate information about the outside world. These networks play a significant role in a broad range of fields, from crucial military surveillance applications to monitoring building security. Key management in WSNs is a critical task. While the security and integrity of messages communicated through these networks and the authenticity of the nodes are dependent on the robustness of the key management schemes, designing an efficient key generation, distribution, and revocation scheme is quite challenging. While resource-constrained sensor nodes should not be exposed to computationally demanding asymmetric key algorithms, the use of symmetric key-based systems leaves the entire network vulnerable to several attacks. This chapter provides a comprehensive survey of several well-known cryptographic mechanisms and key management schemes for WSNs.","sentences":["Wireless sensor networks (WSNs) are made up of a large number of tiny sensors, which can sense, analyze, and communicate information about the outside world.","These networks play a significant role in a broad range of fields, from crucial military surveillance applications to monitoring building security.","Key management in WSNs is a critical task.","While the security and integrity of messages communicated through these networks and the authenticity of the nodes are dependent on the robustness of the key management schemes, designing an efficient key generation, distribution, and revocation scheme is quite challenging.","While resource-constrained sensor nodes should not be exposed to computationally demanding asymmetric key algorithms, the use of symmetric key-based systems leaves the entire network vulnerable to several attacks.","This chapter provides a comprehensive survey of several well-known cryptographic mechanisms and key management schemes for WSNs."],"url":"http://arxiv.org/abs/2307.00872v1"}
{"created":"2023-07-03 09:08:06","title":"Mining Clues from Incomplete Utterance: A Query-enhanced Network for Incomplete Utterance Rewriting","abstract":"Incomplete utterance rewriting has recently raised wide attention. However, previous works do not consider the semantic structural information between incomplete utterance and rewritten utterance or model the semantic structure implicitly and insufficiently. To address this problem, we propose a QUEry-Enhanced Network (QUEEN). Firstly, our proposed query template explicitly brings guided semantic structural knowledge between the incomplete utterance and the rewritten utterance making model perceive where to refer back to or recover omitted tokens. Then, we adopt a fast and effective edit operation scoring network to model the relation between two tokens. Benefiting from proposed query template and the well-designed edit operation scoring network, QUEEN achieves state-of-the-art performance on several public datasets.","sentences":["Incomplete utterance rewriting has recently raised wide attention.","However, previous works do not consider the semantic structural information between incomplete utterance and rewritten utterance or model the semantic structure implicitly and insufficiently.","To address this problem, we propose a QUEry-Enhanced Network (QUEEN).","Firstly, our proposed query template explicitly brings guided semantic structural knowledge between the incomplete utterance and the rewritten utterance making model perceive where to refer back to or recover omitted tokens.","Then, we adopt a fast and effective edit operation scoring network to model the relation between two tokens.","Benefiting from proposed query template and the well-designed edit operation scoring network, QUEEN achieves state-of-the-art performance on several public datasets."],"url":"http://arxiv.org/abs/2307.00866v1"}
{"created":"2023-07-03 09:08:01","title":"A Survey on Graph Classification and Link Prediction based on GNN","abstract":"Traditional convolutional neural networks are limited to handling Euclidean space data, overlooking the vast realm of real-life scenarios represented as graph data, including transportation networks, social networks, and reference networks. The pivotal step in transferring convolutional neural networks to graph data analysis and processing lies in the construction of graph convolutional operators and graph pooling operators. This comprehensive review article delves into the world of graph convolutional neural networks. Firstly, it elaborates on the fundamentals of graph convolutional neural networks. Subsequently, it elucidates the graph neural network models based on attention mechanisms and autoencoders, summarizing their application in node classification, graph classification, and link prediction along with the associated datasets.","sentences":["Traditional convolutional neural networks are limited to handling Euclidean space data, overlooking the vast realm of real-life scenarios represented as graph data, including transportation networks, social networks, and reference networks.","The pivotal step in transferring convolutional neural networks to graph data analysis and processing lies in the construction of graph convolutional operators and graph pooling operators.","This comprehensive review article delves into the world of graph convolutional neural networks.","Firstly, it elaborates on the fundamentals of graph convolutional neural networks.","Subsequently, it elucidates the graph neural network models based on attention mechanisms and autoencoders, summarizing their application in node classification, graph classification, and link prediction along with the associated datasets."],"url":"http://arxiv.org/abs/2307.00865v1"}
{"created":"2023-07-03 09:04:41","title":"Thompson Sampling under Bernoulli Rewards with Local Differential Privacy","abstract":"This paper investigates the problem of regret minimization for multi-armed bandit (MAB) problems with local differential privacy (LDP) guarantee. Given a fixed privacy budget $\\epsilon$, we consider three privatizing mechanisms under Bernoulli scenario: linear, quadratic and exponential mechanisms. Under each mechanism, we derive stochastic regret bound for Thompson Sampling algorithm. Finally, we simulate to illustrate the convergence of different mechanisms under different privacy budgets.","sentences":["This paper investigates the problem of regret minimization for multi-armed bandit (MAB) problems with local differential privacy (LDP) guarantee.","Given a fixed privacy budget $\\epsilon$, we consider three privatizing mechanisms under Bernoulli scenario: linear, quadratic and exponential mechanisms.","Under each mechanism, we derive stochastic regret bound for Thompson Sampling algorithm.","Finally, we simulate to illustrate the convergence of different mechanisms under different privacy budgets."],"url":"http://arxiv.org/abs/2307.00863v1"}
{"created":"2023-07-03 09:03:12","title":"UniFine: A Unified and Fine-grained Approach for Zero-shot Vision-Language Understanding","abstract":"Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because they require the model's reasoning ability to understand the semantics of the visual world and natural language. Supervised methods working for vision-language tasks have been well-studied. However, solving these tasks in a zero-shot setting is less explored. Since Contrastive Language-Image Pre-training (CLIP) has shown remarkable zero-shot performance on image-text matching, previous works utilized its strong zero-shot ability by converting vision-language tasks into an image-text matching problem, and they mainly consider global-level matching (e.g., the whole image or sentence). However, we find visual and textual fine-grained information, e.g., keywords in the sentence and objects in the image, can be fairly informative for semantics understanding. Inspired by this, we propose a unified framework to take advantage of the fine-grained information for zero-shot vision-language learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our experiments show that our framework outperforms former zero-shot methods on VQA and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our ablation studies confirm the effectiveness and generalizability of our proposed method. Code will be available at https://github.com/ThreeSR/UniFine","sentences":["Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because they require the model's reasoning ability to understand the semantics of the visual world and natural language.","Supervised methods working for vision-language tasks have been well-studied.","However, solving these tasks in a zero-shot setting is less explored.","Since Contrastive Language-Image Pre-training (CLIP) has shown remarkable zero-shot performance on image-text matching, previous works utilized its strong zero-shot ability by converting vision-language tasks into an image-text matching problem, and they mainly consider global-level matching (e.g., the whole image or sentence).","However, we find visual and textual fine-grained information, e.g., keywords in the sentence and objects in the image, can be fairly informative for semantics understanding.","Inspired by this, we propose a unified framework to take advantage of the fine-grained information for zero-shot vision-language learning, covering multiple tasks such as VQA, SNLI-VE, and VCR.","Our experiments show that our framework outperforms former zero-shot methods on VQA and achieves substantial improvement on SNLI-VE and VCR.","Furthermore, our ablation studies confirm the effectiveness and generalizability of our proposed method.","Code will be available at https://github.com/ThreeSR/UniFine"],"url":"http://arxiv.org/abs/2307.00862v1"}
{"created":"2023-07-03 09:02:36","title":"Perch a quadrotor on planes by the ceiling effect","abstract":"Perching is a promising solution for a small unmanned aerial vehicle (UAV) to save energy and extend operation time. This paper proposes a quadrotor that can perch on planar structures using the ceiling effect. Compared with the existing work, this perching method does not require any claws, hooks, or adhesive pads, leading to a simpler system design. This method does not limit the perching by surface angle or material either. The design of the quadrotor that only uses its propeller guards for surface contact is presented in this paper. We also discussed the automatic perching strategy including trajectory generation and power management. Experiments are conducted to verify that the approach is practical and the UAV can perch on planes with different angles. Energy consumption in the perching state is assessed, showing that more than 30% of power can be saved. Meanwhile, the quadrotor exhibits improved stability while perching compared to when it is hovering.","sentences":["Perching is a promising solution for a small unmanned aerial vehicle (UAV) to save energy and extend operation time.","This paper proposes a quadrotor that can perch on planar structures using the ceiling effect.","Compared with the existing work, this perching method does not require any claws, hooks, or adhesive pads, leading to a simpler system design.","This method does not limit the perching by surface angle or material either.","The design of the quadrotor that only uses its propeller guards for surface contact is presented in this paper.","We also discussed the automatic perching strategy including trajectory generation and power management.","Experiments are conducted to verify that the approach is practical and the UAV can perch on planes with different angles.","Energy consumption in the perching state is assessed, showing that more than 30% of power can be saved.","Meanwhile, the quadrotor exhibits improved stability while perching compared to when it is hovering."],"url":"http://arxiv.org/abs/2307.00861v1"}
{"created":"2023-07-03 08:58:32","title":"CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery","abstract":"In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential applications in drug discovery and drug interactions are vast, from identifying new drug targets to predicting drug-to-drug interactions and enabling novel drug discovery. This innovative approach provides an AI-enhanced methodology in drug development, utilizing SSL combined with GNNs to overcome existing limitations and pave the way for a richer exploration of the vast combinatorial chemical space in drug discovery.","sentences":["In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge.","While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles.","This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery.","CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time.","It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures.","CardiGraphormer's potential applications in drug discovery and drug interactions are vast, from identifying new drug targets to predicting drug-to-drug interactions and enabling novel drug discovery.","This innovative approach provides an AI-enhanced methodology in drug development, utilizing SSL combined with GNNs to overcome existing limitations and pave the way for a richer exploration of the vast combinatorial chemical space in drug discovery."],"url":"http://arxiv.org/abs/2307.00859v1"}
{"created":"2023-07-03 08:54:32","title":"OpenSiteRec: An Open Dataset for Site Recommendation","abstract":"As a representative information retrieval task, site recommendation, which aims at predicting the optimal sites for a brand or an institution to open new branches in an automatic data-driven way, is beneficial and crucial for brand development in modern business. However, there is no publicly available dataset so far and most existing approaches are limited to an extremely small scope of brands, which seriously hinders the research on site recommendation. Therefore, we collect, construct and release an open comprehensive dataset, namely OpenSiteRec, to facilitate and promote the research on site recommendation. Specifically, OpenSiteRec leverages a heterogeneous graph schema to represent various types of real-world entities and relations in four international metropolises. To evaluate the performance of the existing general methods on the site recommendation task, we conduct benchmarking experiments of several representative recommendation models on OpenSiteRec. Furthermore, we also highlight the potential application directions to demonstrate the wide applicability of OpenSiteRec. We believe that our OpenSiteRec dataset is significant and anticipated to encourage the development of advanced methods for site recommendation. OpenSiteRec is available online at https://OpenSiteRec.github.io/.","sentences":["As a representative information retrieval task, site recommendation, which aims at predicting the optimal sites for a brand or an institution to open new branches in an automatic data-driven way, is beneficial and crucial for brand development in modern business.","However, there is no publicly available dataset so far and most existing approaches are limited to an extremely small scope of brands, which seriously hinders the research on site recommendation.","Therefore, we collect, construct and release an open comprehensive dataset, namely OpenSiteRec, to facilitate and promote the research on site recommendation.","Specifically, OpenSiteRec leverages a heterogeneous graph schema to represent various types of real-world entities and relations in four international metropolises.","To evaluate the performance of the existing general methods on the site recommendation task, we conduct benchmarking experiments of several representative recommendation models on OpenSiteRec.","Furthermore, we also highlight the potential application directions to demonstrate the wide applicability of OpenSiteRec.","We believe that our OpenSiteRec dataset is significant and anticipated to encourage the development of advanced methods for site recommendation.","OpenSiteRec is available online at https://OpenSiteRec.github.io/."],"url":"http://arxiv.org/abs/2307.00856v1"}
{"created":"2023-07-03 08:48:49","title":"Review of Large Vision Models and Visual Prompt Engineering","abstract":"Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities. As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident. Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction. This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering. We present influential large models in the visual domain and a range of prompt engineering methods employed on these models. It is our hope that this review provides a comprehensive and systematic description of prompt engineering methods based on large visual models, offering valuable insights for future researchers in their exploration of this field.","sentences":["Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities.","As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident.","Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction.","This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering.","We present influential large models in the visual domain and a range of prompt engineering methods employed on these models.","It is our hope that this review provides a comprehensive and systematic description of prompt engineering methods based on large visual models, offering valuable insights for future researchers in their exploration of this field."],"url":"http://arxiv.org/abs/2307.00855v1"}
{"created":"2023-07-03 08:47:40","title":"On the Definition of the Eta-long Normal Form in Type Systems of the Cube","abstract":"The smallest transitive relation < on well-typed normal terms such that if t is a strict subterm of u then t < u and if T is the normal form of the type of t and the term t is not a sort then T < t is well-founded in the type systems of the cube. Thus every term admits a eta-long normal form.","sentences":["The smallest transitive relation < on well-typed normal terms such that if t is a strict subterm of u then t < u","and if T is the normal form of the type of t and the term t is not a sort then T < t is well-founded in the type systems of the cube.","Thus every term admits a eta-long normal form."],"url":"http://arxiv.org/abs/2307.00854v1"}
{"created":"2023-07-03 08:47:12","title":"Short Flip Sequences to Untangle Segments in the Plane","abstract":"A (multi)set of segments in the plane may form a TSP tour, a matching, a tree, or any multigraph. If two segments cross, then we can reduce the total length with the following flip operation. We remove a pair of crossing segments, and insert a pair of non-crossing segments, while keeping the same vertex degrees. The goal of this paper is to devise efficient strategies to flip the segments in order to obtain crossing-free segments after a small number of flips. Linear and near-linear bounds on the number of flips were only known for segments with endpoints in convex position. We generalize these results, proving linear and near-linear bounds for cases with endpoints that are not in convex position. Our results are proved in a general setting that applies to multiple problems, using multigraphs and the distinction between removal and insertion choices when performing a flip.","sentences":["A (multi)set of segments in the plane may form a TSP tour, a matching, a tree, or any multigraph.","If two segments cross, then we can reduce the total length with the following flip operation.","We remove a pair of crossing segments, and insert a pair of non-crossing segments, while keeping the same vertex degrees.","The goal of this paper is to devise efficient strategies to flip the segments in order to obtain crossing-free segments after a small number of flips.","Linear and near-linear bounds on the number of flips were only known for segments with endpoints in convex position.","We generalize these results, proving linear and near-linear bounds for cases with endpoints that are not in convex position.","Our results are proved in a general setting that applies to multiple problems, using multigraphs and the distinction between removal and insertion choices when performing a flip."],"url":"http://arxiv.org/abs/2307.00853v1"}
{"created":"2023-07-03 08:45:42","title":"VOLTA: Diverse and Controllable Question-Answer Pair Generation with Variational Mutual Information Maximizing Autoencoder","abstract":"Previous question-answer pair generation methods aimed to produce fluent and meaningful question-answer pairs but tend to have poor diversity. Recent attempts addressing this issue suffer from either low model capacity or overcomplicated architecture. Furthermore, they overlooked the problem where the controllability of their models is highly dependent on the input. In this paper, we propose a model named VOLTA that enhances generative diversity by leveraging the Variational Autoencoder framework with a shared backbone network as its encoder and decoder. In addition, we propose adding InfoGAN-style latent codes to enable input-independent controllability over the generation process. We perform comprehensive experiments and the results show that our approach can significantly improve diversity and controllability over state-of-the-art models.","sentences":["Previous question-answer pair generation methods aimed to produce fluent and meaningful question-answer pairs but tend to have poor diversity.","Recent attempts addressing this issue suffer from either low model capacity or overcomplicated architecture.","Furthermore, they overlooked the problem where the controllability of their models is highly dependent on the input.","In this paper, we propose a model named VOLTA that enhances generative diversity by leveraging the Variational Autoencoder framework with a shared backbone network as its encoder and decoder.","In addition, we propose adding InfoGAN-style latent codes to enable input-independent controllability over the generation process.","We perform comprehensive experiments and the results show that our approach can significantly improve diversity and controllability over state-of-the-art models."],"url":"http://arxiv.org/abs/2307.00852v1"}
{"created":"2023-07-03 08:45:30","title":"Fairness Scheduling in User-Centric Cell-Free Massive MIMO Wireless Networks","abstract":"We consider a user-centric cell-free massive MIMO wireless network with $L$ remote radio units, each with $M$ antennas, serving $K_{\\rm tot}$ user equipments (UEs). Most of the literature considers the regime $LM \\gg K_{\\rm tot}$, where the $K$ UEs are active on each time-frequency slot, and evaluates the system performance in terms of ergodic rates. In this paper, we take a quite different viewpoint. We observe that the regime of $LM \\gg K_{\\rm tot}$ corresponds to a lightly loaded system with low sum spectral efficiency (SE). In contrast, in most relevant scenarios, the number of UEs is much larger than the total number of antennas, but users are not all active at the same time. To achieve high sum SE and handle $K_{\\rm tot} \\gg ML$, users must be scheduled over the time-frequency resource. The number of active users $K_{\\rm act} \\leq K_{\\rm tot}$ must be chosen such that: 1) the network operates close to its maximum SE; 2) the active user set must be chosen dynamically over time in order to enforce fairness in terms of per-user time-averaged throughput rates. The fairness scheduling problem is formulated as the maximization of a concave componentwise non-decreasing network utility function of the per-user rates. Intermittent user activity imposes slot-by-slot coding/decoding which prevents the achievability of ergodic rates. Hence, we model the per-slot service rates using information outage probability. To obtain a tractable problem, we make a decoupling assumption on the CDF of the instantaneous mutual information seen at each UE $k$ receiver. We approximately enforce this condition with a conflict graph that prevents the simultaneous scheduling of users with large pilot contamination and propose an adaptive scheme for instantaneous service rate scheduling. Overall, the proposed dynamic scheduling is robust to system model uncertainties and can be easily implemented in practice.","sentences":["We consider a user-centric cell-free massive MIMO wireless network with $L$ remote radio units, each with $M$ antennas, serving $K_{\\rm tot}$ user equipments (UEs).","Most of the literature considers the regime $LM \\gg K_{\\rm tot}$, where the $K$ UEs are active on each time-frequency slot, and evaluates the system performance in terms of ergodic rates.","In this paper, we take a quite different viewpoint.","We observe that the regime of $LM \\gg K_{\\rm tot}$ corresponds to a lightly loaded system with low sum spectral efficiency (SE).","In contrast, in most relevant scenarios, the number of UEs is much larger than the total number of antennas, but users are not all active at the same time.","To achieve high sum SE and handle $K_{\\rm tot} \\gg ML$, users must be scheduled over the time-frequency resource.","The number of active users $K_{\\rm act} \\leq K_{\\rm tot}$ must be chosen such that: 1) the network operates close to its maximum SE; 2) the active user set must be chosen dynamically over time in order to enforce fairness in terms of per-user time-averaged throughput rates.","The fairness scheduling problem is formulated as the maximization of a concave componentwise non-decreasing network utility function of the per-user rates.","Intermittent user activity imposes slot-by-slot coding/decoding which prevents the achievability of ergodic rates.","Hence, we model the per-slot service rates using information outage probability.","To obtain a tractable problem, we make a decoupling assumption on the CDF of the instantaneous mutual information seen at each UE $k$ receiver.","We approximately enforce this condition with a conflict graph that prevents the simultaneous scheduling of users with large pilot contamination and propose an adaptive scheme for instantaneous service rate scheduling.","Overall, the proposed dynamic scheduling is robust to system model uncertainties and can be easily implemented in practice."],"url":"http://arxiv.org/abs/2307.00850v1"}
{"created":"2023-07-03 08:35:53","title":"VINECS: Video-based Neural Character Skinning","abstract":"Rigging and skinning clothed human avatars is a challenging task and traditionally requires a lot of manual work and expertise. Recent methods addressing it either generalize across different characters or focus on capturing the dynamics of a single character observed under different pose configurations. However, the former methods typically predict solely static skinning weights, which perform poorly for highly articulated poses, and the latter ones either require dense 3D character scans in different poses or cannot generate an explicit mesh with vertex correspondence over time. To address these challenges, we propose a fully automated approach for creating a fully rigged character with pose-dependent skinning weights, which can be solely learned from multi-view video. Therefore, we first acquire a rigged template, which is then statically skinned. Next, a coordinate-based MLP learns a skinning weights field parameterized over the position in a canonical pose space and the respective pose. Moreover, we introduce our pose- and view-dependent appearance field allowing us to differentiably render and supervise the posed mesh using multi-view imagery. We show that our approach outperforms state-of-the-art while not relying on dense 4D scans.","sentences":["Rigging and skinning clothed human avatars is a challenging task and traditionally requires a lot of manual work and expertise.","Recent methods addressing it either generalize across different characters or focus on capturing the dynamics of a single character observed under different pose configurations.","However, the former methods typically predict solely static skinning weights, which perform poorly for highly articulated poses, and the latter ones either require dense 3D character scans in different poses or cannot generate an explicit mesh with vertex correspondence over time.","To address these challenges, we propose a fully automated approach for creating a fully rigged character with pose-dependent skinning weights, which can be solely learned from multi-view video.","Therefore, we first acquire a rigged template, which is then statically skinned.","Next, a coordinate-based MLP learns a skinning weights field parameterized over the position in a canonical pose space and the respective pose.","Moreover, we introduce our pose- and view-dependent appearance field allowing us to differentiably render and supervise the posed mesh using multi-view imagery.","We show that our approach outperforms state-of-the-art while not relying on dense 4D scans."],"url":"http://arxiv.org/abs/2307.00842v1"}
{"created":"2023-07-03 08:27:05","title":"Advantages of Multimodal versus Verbal-Only Robot-to-Human Communication with an Anthropomorphic Robotic Mock Driver","abstract":"Robots are increasingly used in shared environments with humans, making effective communication a necessity for successful human-robot interaction. In our work, we study a crucial component: active communication of robot intent. Here, we present an anthropomorphic solution where a humanoid robot communicates the intent of its host robot acting as an \"Anthropomorphic Robotic Mock Driver\" (ARMoD). We evaluate this approach in two experiments in which participants work alongside a mobile robot on various tasks, while the ARMoD communicates a need for human attention, when required, or gives instructions to collaborate on a joint task. The experiments feature two interaction styles of the ARMoD: a verbal-only mode using only speech and a multimodal mode, additionally including robotic gaze and pointing gestures to support communication and register intent in space. Our results show that the multimodal interaction style, including head movements and eye gaze as well as pointing gestures, leads to more natural fixation behavior. Participants naturally identified and fixated longer on the areas relevant for intent communication, and reacted faster to instructions in collaborative tasks. Our research further indicates that the ARMoD intent communication improves engagement and social interaction with mobile robots in workplace settings.","sentences":["Robots are increasingly used in shared environments with humans, making effective communication a necessity for successful human-robot interaction.","In our work, we study a crucial component: active communication of robot intent.","Here, we present an anthropomorphic solution where a humanoid robot communicates the intent of its host robot acting as an \"Anthropomorphic Robotic Mock Driver\" (ARMoD).","We evaluate this approach in two experiments in which participants work alongside a mobile robot on various tasks, while the ARMoD communicates a need for human attention, when required, or gives instructions to collaborate on a joint task.","The experiments feature two interaction styles of the ARMoD: a verbal-only mode using only speech and a multimodal mode, additionally including robotic gaze and pointing gestures to support communication and register intent in space.","Our results show that the multimodal interaction style, including head movements and eye gaze as well as pointing gestures, leads to more natural fixation behavior.","Participants naturally identified and fixated longer on the areas relevant for intent communication, and reacted faster to instructions in collaborative tasks.","Our research further indicates that the ARMoD intent communication improves engagement and social interaction with mobile robots in workplace settings."],"url":"http://arxiv.org/abs/2307.00841v1"}
{"created":"2023-07-03 08:20:19","title":"Surgical fine-tuning for Grape Bunch Segmentation under Visual Domain Shifts","abstract":"Mobile robots will play a crucial role in the transition towards sustainable agriculture. To autonomously and effectively monitor the state of plants, robots ought to be equipped with visual perception capabilities that are robust to the rapid changes that characterise agricultural settings. In this paper, we focus on the challenging task of segmenting grape bunches from images collected by mobile robots in vineyards. In this context, we present the first study that applies surgical fine-tuning to instance segmentation tasks. We show how selectively tuning only specific model layers can support the adaptation of pre-trained Deep Learning models to newly-collected grape images that introduce visual domain shifts, while also substantially reducing the number of tuned parameters.","sentences":["Mobile robots will play a crucial role in the transition towards sustainable agriculture.","To autonomously and effectively monitor the state of plants, robots ought to be equipped with visual perception capabilities that are robust to the rapid changes that characterise agricultural settings.","In this paper, we focus on the challenging task of segmenting grape bunches from images collected by mobile robots in vineyards.","In this context, we present the first study that applies surgical fine-tuning to instance segmentation tasks.","We show how selectively tuning only specific model layers can support the adaptation of pre-trained Deep Learning models to newly-collected grape images that introduce visual domain shifts, while also substantially reducing the number of tuned parameters."],"url":"http://arxiv.org/abs/2307.00837v1"}
{"created":"2023-07-03 08:18:59","title":"Injectivity of Multi-window Gabor Phase Retrieval","abstract":"In many signal processing problems arising in practical applications, we wish to reconstruct an unknown signal from its phaseless measurements with respect to a frame. This inverse problem is known as the phase retrieval problem. For each particular application, the set of relevant measurement frames is determined by the problem at hand, which motivates the study of phase retrieval for structured, application-relevant frames. In this paper, we focus on one class of such frames that appear naturally in diffraction imaging, ptychography, and audio processing, namely, multi-window Gabor frames. We study the question of injectivity of the phase retrieval problem with these measurement frames in the finite-dimensional setup and propose an explicit construction of an infinite family of phase retrievable multi-window Gabor frames. We show that phase retrievability for the constructed frames can be achieved with a much smaller number of phaseless measurements compared to the previous results for this type of measurement frames. Additionally, we show that the sufficient for reconstruction number of phaseless measurements depends on the dimension of the signal space, and not on the ambient dimension of the problem.","sentences":["In many signal processing problems arising in practical applications, we wish to reconstruct an unknown signal from its phaseless measurements with respect to a frame.","This inverse problem is known as the phase retrieval problem.","For each particular application, the set of relevant measurement frames is determined by the problem at hand, which motivates the study of phase retrieval for structured, application-relevant frames.","In this paper, we focus on one class of such frames that appear naturally in diffraction imaging, ptychography, and audio processing, namely, multi-window Gabor frames.","We study the question of injectivity of the phase retrieval problem with these measurement frames in the finite-dimensional setup and propose an explicit construction of an infinite family of phase retrievable multi-window Gabor frames.","We show that phase retrievability for the constructed frames can be achieved with a much smaller number of phaseless measurements compared to the previous results for this type of measurement frames.","Additionally, we show that the sufficient for reconstruction number of phaseless measurements depends on the dimension of the signal space, and not on the ambient dimension of the problem."],"url":"http://arxiv.org/abs/2307.00834v1"}
{"created":"2023-07-03 08:17:06","title":"On the Satisfiability of Local First-Order Logics with Data","abstract":"We study first-order logic over unordered structures whose elements carry a finite number of data values from an infinite domain. Data values can be compared wrt.\\ equality. As the satisfiability problem for this logic is undecidable in general, we introduce a family of local fragments. They restrict quantification to the neighbourhood of a given reference point that is bounded by some radius. Our first main result establishes decidability of the satisfiability problem for the local radius-1 fragment in presence of one ``diagonal relation''. On the other hand, extending the radius leads to undecidability. In a second part, we provide the precise decidability and complexity landscape of the satisfiability problem for the existential fragments of local logic, which are parameterized by the number of data values carried by each element and the radius of the considered neighbourhoods. Altogether, we draw a landscape of formalisms that are suitable for the specification of systems with data and open up new avenues for future research.","sentences":["We study first-order logic over unordered structures whose elements carry a finite number of data values from an infinite domain.","Data values can be compared wrt.\\ equality.","As the satisfiability problem for this logic is undecidable in general, we introduce a family of local fragments.","They restrict quantification to the neighbourhood of a given reference point that is bounded by some radius.","Our first main result establishes decidability of the satisfiability problem for the local radius-1 fragment in presence of one ``diagonal relation''.","On the other hand, extending the radius leads to undecidability.","In a second part, we provide the precise decidability and complexity landscape of the satisfiability problem for the existential fragments of local logic, which are parameterized by the number of data values carried by each element and the radius of the considered neighbourhoods.","Altogether, we draw a landscape of formalisms that are suitable for the specification of systems with data and open up new avenues for future research."],"url":"http://arxiv.org/abs/2307.00831v1"}
{"created":"2023-07-03 08:16:41","title":"Ontology-based Mediation with Quality Criteria","abstract":"This paper presents a semantic system named OntMed for an ontology-based data integration of heterogeneous data sources to achieve interoperability between heterogeneous data sources. Our system is based on the quality criteria (consistency, completeness and conciseness) for building the reliable analysis contexts to provide an accurate unified view of data to the end user. The generation of an error-free global analysis context with the semantic validation of initial mappings generates accuracy, and provides the means to access and exchange information in semantically sound manner. In addition, data integration in this way becomes more practical for dynamic situations and helps decision maker to work within more consistent and reliable virtual data warehouse. We also discuss our successful participation in the Ontology Alignment for Query Answering (OA4QA) track at OAEI 2015 campaign, where our system (DKP-AOM) has performed fair enough and became one of only matchers whose alignments allowed answering all the queries of the evaluation.","sentences":["This paper presents a semantic system named OntMed for an ontology-based data integration of heterogeneous data sources to achieve interoperability between heterogeneous data sources.","Our system is based on the quality criteria (consistency, completeness and conciseness) for building the reliable analysis contexts to provide an accurate unified view of data to the end user.","The generation of an error-free global analysis context with the semantic validation of initial mappings generates accuracy, and provides the means to access and exchange information in semantically sound manner.","In addition, data integration in this way becomes more practical for dynamic situations and helps decision maker to work within more consistent and reliable virtual data warehouse.","We also discuss our successful participation in the Ontology Alignment for Query Answering (OA4QA) track at OAEI 2015 campaign, where our system (DKP-AOM) has performed fair enough and became one of only matchers whose alignments allowed answering all the queries of the evaluation."],"url":"http://arxiv.org/abs/2307.00830v1"}
{"created":"2023-07-03 08:13:48","title":"Toward a Mapping of Capability and Skill Models using Asset Administration Shells and Ontologies","abstract":"In order to react efficiently to changes in production, resources and their functions must be integrated into plants in accordance with the plug and produce principle. In this context, research on so-called capabilities and skills has shown promise. However, there are currently two incompatible approaches to modeling capabilities and skills. On the one hand, formal descriptions using ontologies have been developed. On the other hand, there are efforts to standardize submodels of the Asset Administration Shell (AAS) for this purpose. In this paper, we present ongoing research to connect these two incompatible modeling approaches. Both models are analyzed to identify comparable as well as dissimilar model elements. Subsequently, we present a concept for a bidirectional mapping between AAS submodels and a capability and skill ontology. For this purpose, two unidirectional, declarative mappings are applied that implement transformations from one modeling approach to the other - and vice versa.","sentences":["In order to react efficiently to changes in production, resources and their functions must be integrated into plants in accordance with the plug and produce principle.","In this context, research on so-called capabilities and skills has shown promise.","However, there are currently two incompatible approaches to modeling capabilities and skills.","On the one hand, formal descriptions using ontologies have been developed.","On the other hand, there are efforts to standardize submodels of the Asset Administration Shell (AAS) for this purpose.","In this paper, we present ongoing research to connect these two incompatible modeling approaches.","Both models are analyzed to identify comparable as well as dissimilar model elements.","Subsequently, we present a concept for a bidirectional mapping between AAS submodels and a capability and skill ontology.","For this purpose, two unidirectional, declarative mappings are applied that implement transformations from one modeling approach to the other - and vice versa."],"url":"http://arxiv.org/abs/2307.00827v1"}
{"created":"2023-07-03 08:06:22","title":"Analysis of Task Transferability in Large Pre-trained Classifiers","abstract":"Transfer learning transfers the knowledge acquired by a model from a source task to multiple downstream target tasks with minimal fine-tuning. The success of transfer learning at improving performance, especially with the use of large pre-trained models has made transfer learning an essential tool in the machine learning toolbox. However, the conditions under which the performance is transferable to downstream tasks are not understood very well. In this work, we analyze the transfer of performance for classification tasks, when only the last linear layer of the source model is fine-tuned on the target task. We propose a novel Task Transfer Analysis approach that transforms the source distribution (and classifier) by changing the class prior distribution, label, and feature spaces to produce a new source distribution (and classifier) and allows us to relate the loss of the downstream task (i.e., transferability) to that of the source task. Concretely, our bound explains transferability in terms of the Wasserstein distance between the transformed source and downstream task's distribution, conditional entropy between the label distributions of the two tasks, and weighted loss of the source classifier on the source task. Moreover, we propose an optimization problem for learning the transforms of the source task to minimize the upper bound on transferability. We perform a large-scale empirical study by using state-of-the-art pre-trained models and demonstrate the effectiveness of our bound and optimization at predicting transferability. The results of our experiments demonstrate how factors such as task relatedness, pretraining method, and model architecture affect transferability.","sentences":["Transfer learning transfers the knowledge acquired by a model from a source task to multiple downstream target tasks with minimal fine-tuning.","The success of transfer learning at improving performance, especially with the use of large pre-trained models has made transfer learning an essential tool in the machine learning toolbox.","However, the conditions under which the performance is transferable to downstream tasks are not understood very well.","In this work, we analyze the transfer of performance for classification tasks, when only the last linear layer of the source model is fine-tuned on the target task.","We propose a novel Task Transfer Analysis approach that transforms the source distribution (and classifier) by changing the class prior distribution, label, and feature spaces to produce a new source distribution (and classifier) and allows us to relate the loss of the downstream task (i.e., transferability) to that of the source task.","Concretely, our bound explains transferability in terms of the Wasserstein distance between the transformed source and downstream task's distribution, conditional entropy between the label distributions of the two tasks, and weighted loss of the source classifier on the source task.","Moreover, we propose an optimization problem for learning the transforms of the source task to minimize the upper bound on transferability.","We perform a large-scale empirical study by using state-of-the-art pre-trained models and demonstrate the effectiveness of our bound and optimization at predicting transferability.","The results of our experiments demonstrate how factors such as task relatedness, pretraining method, and model architecture affect transferability."],"url":"http://arxiv.org/abs/2307.00823v1"}
{"created":"2023-07-03 08:01:43","title":"Unveiling the Potential of Spike Streams for Foreground Occlusion Removal from Densely Continuous Views","abstract":"The extraction of a clean background image by removing foreground occlusion holds immense practical significance, but it also presents several challenges. Presently, the majority of de-occlusion research focuses on addressing this issue through the extraction and synthesis of discrete images from calibrated camera arrays. Nonetheless, the restoration quality tends to suffer when faced with dense occlusions or high-speed motions due to limited perspectives and motion blur. To successfully remove dense foreground occlusion, an effective multi-view visual information integration approach is required. Introducing the spike camera as a novel type of neuromorphic sensor offers promising capabilities with its ultra-high temporal resolution and high dynamic range. In this paper, we propose an innovative solution for tackling the de-occlusion problem through continuous multi-view imaging using only one spike camera without any prior knowledge of camera intrinsic parameters and camera poses. By rapidly moving the spike camera, we continually capture the dense stream of spikes from the occluded scene. To process the spikes, we build a novel model \\textbf{SpkOccNet}, in which we integrate information of spikes from continuous viewpoints within multi-windows, and propose a novel cross-view mutual attention mechanism for effective fusion and refinement. In addition, we contribute the first real-world spike-based dataset \\textbf{S-OCC} for occlusion removal. The experimental results demonstrate that our proposed model efficiently removes dense occlusions in diverse scenes while exhibiting strong generalization.","sentences":["The extraction of a clean background image by removing foreground occlusion holds immense practical significance, but it also presents several challenges.","Presently, the majority of de-occlusion research focuses on addressing this issue through the extraction and synthesis of discrete images from calibrated camera arrays.","Nonetheless, the restoration quality tends to suffer when faced with dense occlusions or high-speed motions due to limited perspectives and motion blur.","To successfully remove dense foreground occlusion, an effective multi-view visual information integration approach is required.","Introducing the spike camera as a novel type of neuromorphic sensor offers promising capabilities with its ultra-high temporal resolution and high dynamic range.","In this paper, we propose an innovative solution for tackling the de-occlusion problem through continuous multi-view imaging using only one spike camera without any prior knowledge of camera intrinsic parameters and camera poses.","By rapidly moving the spike camera, we continually capture the dense stream of spikes from the occluded scene.","To process the spikes, we build a novel model \\textbf{SpkOccNet}, in which we integrate information of spikes from continuous viewpoints within multi-windows, and propose a novel cross-view mutual attention mechanism for effective fusion and refinement.","In addition, we contribute the first real-world spike-based dataset \\textbf{S-OCC} for occlusion removal.","The experimental results demonstrate that our proposed model efficiently removes dense occlusions in diverse scenes while exhibiting strong generalization."],"url":"http://arxiv.org/abs/2307.00821v1"}
{"created":"2023-07-03 07:57:29","title":"Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset","abstract":"In this paper, we present Motion-X, a large-scale 3D expressive whole-body motion dataset. Existing motion datasets predominantly contain body-only poses, lacking facial expressions, hand gestures, and fine-grained pose descriptions. Moreover, they are primarily collected from limited laboratory scenes with textual descriptions manually labeled, which greatly limits their scalability. To overcome these limitations, we develop a whole-body motion and text annotation pipeline, which can automatically annotate motion from either single- or multi-view videos and provide comprehensive semantic labels for each video and fine-grained whole-body pose descriptions for each frame. This pipeline is of high precision, cost-effective, and scalable for further research. Based on it, we construct Motion-X, which comprises 13.7M precise 3D whole-body pose annotations (i.e., SMPL-X) covering 96K motion sequences from massive scenes. Besides, Motion-X provides 13.7M frame-level whole-body pose descriptions and 96K sequence-level semantic labels. Comprehensive experiments demonstrate the accuracy of the annotation pipeline and the significant benefit of Motion-X in enhancing expressive, diverse, and natural motion generation, as well as 3D whole-body human mesh recovery.","sentences":["In this paper, we present Motion-X, a large-scale 3D expressive whole-body motion dataset.","Existing motion datasets predominantly contain body-only poses, lacking facial expressions, hand gestures, and fine-grained pose descriptions.","Moreover, they are primarily collected from limited laboratory scenes with textual descriptions manually labeled, which greatly limits their scalability.","To overcome these limitations, we develop a whole-body motion and text annotation pipeline, which can automatically annotate motion from either single- or multi-view videos and provide comprehensive semantic labels for each video and fine-grained whole-body pose descriptions for each frame.","This pipeline is of high precision, cost-effective, and scalable for further research.","Based on it, we construct Motion-X, which comprises 13.7M precise 3D whole-body pose annotations (i.e., SMPL-X) covering 96K motion sequences from massive scenes.","Besides, Motion-X provides 13.7M frame-level whole-body pose descriptions and 96K sequence-level semantic labels.","Comprehensive experiments demonstrate the accuracy of the annotation pipeline and the significant benefit of Motion-X in enhancing expressive, diverse, and natural motion generation, as well as 3D whole-body human mesh recovery."],"url":"http://arxiv.org/abs/2307.00818v1"}
{"created":"2023-07-03 07:51:08","title":"Review helps learn better: Temporal Supervised Knowledge Distillation","abstract":"Reviewing plays an important role when learning knowledge. The knowledge acquisition at a certain time point may be strongly inspired with the help of previous experience. Thus the knowledge growing procedure should show strong relationship along the temporal dimension. In our research, we find that during the network training, the evolution of feature map follows temporal sequence property. A proper temporal supervision may further improve the network training performance. Inspired by this observation, we design a novel knowledge distillation method. Specifically, we extract the spatiotemporal features in the different training phases of student by convolutional Long Short-term memory network (Conv-LSTM). Then, we train the student net through a dynamic target, rather than static teacher network features. This process realizes the refinement of old knowledge in student network, and utilizes them to assist current learning. Extensive experiments verify the effectiveness and advantages of our method over existing knowledge distillation methods, including various network architectures, different tasks (image classification and object detection) .","sentences":["Reviewing plays an important role when learning knowledge.","The knowledge acquisition at a certain time point may be strongly inspired with the help of previous experience.","Thus the knowledge growing procedure should show strong relationship along the temporal dimension.","In our research, we find that during the network training, the evolution of feature map follows temporal sequence property.","A proper temporal supervision may further improve the network training performance.","Inspired by this observation, we design a novel knowledge distillation method.","Specifically, we extract the spatiotemporal features in the different training phases of student by convolutional Long Short-term memory network (Conv-LSTM).","Then, we train the student net through a dynamic target, rather than static teacher network features.","This process realizes the refinement of old knowledge in student network, and utilizes them to assist current learning.","Extensive experiments verify the effectiveness and advantages of our method over existing knowledge distillation methods, including various network architectures, different tasks (image classification and object detection) ."],"url":"http://arxiv.org/abs/2307.00811v1"}
{"created":"2023-07-03 07:41:07","title":"SketchMetaFace: A Learning-based Sketching Interface for High-fidelity 3D Character Face Modeling","abstract":"Modeling 3D avatars benefits various application scenarios such as AR/VR, gaming, and filming. Character faces contribute significant diversity and vividity as a vital component of avatars. However, building 3D character face models usually requires a heavy workload with commercial tools, even for experienced artists. Various existing sketch-based tools fail to support amateurs in modeling diverse facial shapes and rich geometric details. In this paper, we present SketchMetaFace - a sketching system targeting amateur users to model high-fidelity 3D faces in minutes. We carefully design both the user interface and the underlying algorithm. First, curvature-aware strokes are adopted to better support the controllability of carving facial details. Second, considering the key problem of mapping a 2D sketch map to a 3D model, we develop a novel learning-based method termed \"Implicit and Depth Guided Mesh Modeling\" (IDGMM). It fuses the advantages of mesh, implicit, and depth representations to achieve high-quality results with high efficiency. In addition, to further support usability, we present a coarse-to-fine 2D sketching interface design and a data-driven stroke suggestion tool. User studies demonstrate the superiority of our system over existing modeling tools in terms of the ease to use and visual quality of results. Experimental analyses also show that IDGMM reaches a better trade-off between accuracy and efficiency. SketchMetaFace are available at https://zhongjinluo.github.io/SketchMetaFace/.","sentences":["Modeling 3D avatars benefits various application scenarios such as AR/VR, gaming, and filming.","Character faces contribute significant diversity and vividity as a vital component of avatars.","However, building 3D character face models usually requires a heavy workload with commercial tools, even for experienced artists.","Various existing sketch-based tools fail to support amateurs in modeling diverse facial shapes and rich geometric details.","In this paper, we present SketchMetaFace - a sketching system targeting amateur users to model high-fidelity 3D faces in minutes.","We carefully design both the user interface and the underlying algorithm.","First, curvature-aware strokes are adopted to better support the controllability of carving facial details.","Second, considering the key problem of mapping a 2D sketch map to a 3D model, we develop a novel learning-based method termed \"Implicit and Depth Guided Mesh Modeling\" (IDGMM).","It fuses the advantages of mesh, implicit, and depth representations to achieve high-quality results with high efficiency.","In addition, to further support usability, we present a coarse-to-fine 2D sketching interface design and a data-driven stroke suggestion tool.","User studies demonstrate the superiority of our system over existing modeling tools in terms of the ease to use and visual quality of results.","Experimental analyses also show that IDGMM reaches a better trade-off between accuracy and efficiency.","SketchMetaFace are available at https://zhongjinluo.github.io/SketchMetaFace/."],"url":"http://arxiv.org/abs/2307.00804v1"}
{"created":"2023-07-03 07:33:35","title":"Does Interdisciplinary Creative Coding Boost Creativity? A Mixed Methods Approach","abstract":"This study explores the influence of an interdisciplinary intervention on creative problem-solving skills. Literature deems such skills as vital for software engineering (SE) students in higher education. 39 SE students and graphic design (GD) students were randomly paired to work on an open-ended creative coding assignment in p5.js, an online JS-based Processing editor that makes it easy for novices to quickly and easily code visual webpages. Three categories were formed: the test group SE+GD (18 students), and control groups SE+SE (10) and GD+GD (11). A mixed methods approach was taken to gather and interpret results: Amabile's Consensual Assessment Technique provided a global creativity score for the finished product, the Creative Programming Problem Solving Test assessed three dimensions of the creative process (Ability, Mindset, Interaction), and 9 semi-structured follow-up interviews provided context and revealed underlying themes. The results indicate that, while the creativity of the end product initially takes a hit, the SE+GD groups' socio-interactive creativity levels increased. We also observed fixed mindsets towards creativity (\"design students are more creative than we\") that call for future work.","sentences":["This study explores the influence of an interdisciplinary intervention on creative problem-solving skills.","Literature deems such skills as vital for software engineering (SE) students in higher education.","39 SE students and graphic design (GD) students were randomly paired to work on an open-ended creative coding assignment in p5.js, an online JS-based Processing editor that makes it easy for novices to quickly and easily code visual webpages.","Three categories were formed: the test group SE+GD (18 students), and control groups SE+SE (10) and GD+GD (11).","A mixed methods approach was taken to gather and interpret results: Amabile's Consensual Assessment Technique provided a global creativity score for the finished product, the Creative Programming Problem Solving Test assessed three dimensions of the creative process (Ability, Mindset, Interaction), and 9 semi-structured follow-up interviews provided context and revealed underlying themes.","The results indicate that, while the creativity of the end product initially takes a hit, the SE+GD groups' socio-interactive creativity levels increased.","We also observed fixed mindsets towards creativity (\"design students are more creative than we\") that call for future work."],"url":"http://arxiv.org/abs/2307.00800v1"}
{"created":"2023-07-03 07:30:58","title":"First Steps towards a Runtime Analysis of Neuroevolution","abstract":"We consider a simple setting in neuroevolution where an evolutionary algorithm optimizes the weights and activation functions of a simple artificial neural network. We then define simple example functions to be learned by the network and conduct rigorous runtime analyses for networks with a single neuron and for a more advanced structure with several neurons and two layers. Our results show that the proposed algorithm is generally efficient on two example problems designed for one neuron and efficient with at least constant probability on the example problem for a two-layer network. In particular, the so-called harmonic mutation operator choosing steps of size $j$ with probability proportional to $1/j$ turns out as a good choice for the underlying search space. However, for the case of one neuron, we also identify situations with hard-to-overcome local optima. Experimental investigations of our neuroevolutionary algorithm and a state-of-the-art CMA-ES support the theoretical findings.","sentences":["We consider a simple setting in neuroevolution where an evolutionary algorithm optimizes the weights and activation functions of a simple artificial neural network.","We then define simple example functions to be learned by the network and conduct rigorous runtime analyses for networks with a single neuron and for a more advanced structure with several neurons and two layers.","Our results show that the proposed algorithm is generally efficient on two example problems designed for one neuron and efficient with at least constant probability on the example problem for a two-layer network.","In particular, the so-called harmonic mutation operator choosing steps of size $j$ with probability proportional to $1/j$ turns out as a good choice for the underlying search space.","However, for the case of one neuron, we also identify situations with hard-to-overcome local optima.","Experimental investigations of our neuroevolutionary algorithm and a state-of-the-art CMA-ES support the theoretical findings."],"url":"http://arxiv.org/abs/2307.00799v1"}
{"created":"2023-07-03 07:22:19","title":"Editors handle their collaborators' submissions despite explicit policies","abstract":"Editors are crucial to the integrity of the scientific publishing process, yet they themselves could face conflicts of interest (COIs), whereby their personal interests interfere with their editorial duties. One such COI stems from the fact that, apart from a few exceptions, the vast majority of editors are research-active scientists with many collaborators. Each such editor could potentially handle submissions from their recent collaborators, allowing the editor to use their power, consciously or otherwise, to treat such submissions favourably, thereby jeopardizing the integrity of the editorial decision. Naturally, a number of policies have been put in place to govern such COI, but their effectiveness remains unknown. We fill this gap by analyzing half a million papers handled by 60,000 different editors and published in 500 journals by six publishers, namely Frontiers, Hindawi, IEEE, MDPI, PLOS, and PNAS. We find numerous papers handled by editors who collaborated recently with the authors; this happens despite policies explicitly prohibiting such behavior. Overall, nearly 3% of journals have a COI rate $\\geq$ 10%, and nearly half of them have a COI rate $\\geq$ 2%. Moreover, leveraging three quasi-experiments, we find that COI policies have a limited, if any, effect on regulating this phenomenon. Finally, we find that editors are faster to accept submissions from their collaborators, raising the possibility of favoritism. These findings highlight the need for policy reform to assure the scientific community that all submissions are treated equally.","sentences":["Editors are crucial to the integrity of the scientific publishing process, yet they themselves could face conflicts of interest (COIs), whereby their personal interests interfere with their editorial duties.","One such COI stems from the fact that, apart from a few exceptions, the vast majority of editors are research-active scientists with many collaborators.","Each such editor could potentially handle submissions from their recent collaborators, allowing the editor to use their power, consciously or otherwise, to treat such submissions favourably, thereby jeopardizing the integrity of the editorial decision.","Naturally, a number of policies have been put in place to govern such COI, but their effectiveness remains unknown.","We fill this gap by analyzing half a million papers handled by 60,000 different editors and published in 500 journals by six publishers, namely Frontiers, Hindawi, IEEE, MDPI, PLOS, and PNAS.","We find numerous papers handled by editors who collaborated recently with the authors; this happens despite policies explicitly prohibiting such behavior.","Overall, nearly 3% of journals have a COI rate $\\geq$ 10%, and nearly half of them have a COI rate $\\geq$ 2%.","Moreover, leveraging three quasi-experiments, we find that COI policies have a limited, if any, effect on regulating this phenomenon.","Finally, we find that editors are faster to accept submissions from their collaborators, raising the possibility of favoritism.","These findings highlight the need for policy reform to assure the scientific community that all submissions are treated equally."],"url":"http://arxiv.org/abs/2307.00794v1"}
{"created":"2023-07-03 07:11:18","title":"Utilizing wearable technology to characterize and facilitate occupant collaborations in flexible workspaces","abstract":"Hybrid working strategies have become, and will continue to be, the norm for many offices. This raises two considerations: newly unoccupied spaces needlessly consume energy, and the occupied spaces need to be effectively used to facilitate meaningful interactions and create a positive, sustainable work culture. This work aims to determine when spontaneous, collaborative interactions occur within the building and the environmental factors that facilitate such interactions. This study uses smartwatch-based micro-surveys using the Cozie platform to identify the occurrence of and spatially place interactions while categorizing them as a collaboration or distraction. This method uniquely circumvents pitfalls associated with surveying and qualitative data collection: occupant behaviors are identified in real-time in a non-intrusive manner, and survey data is corroborated with quantitative sensor data. A proof-of-concept study was deployed with nine hybrid-working participants providing 100 micro-survey cluster responses over approximately two weeks. The results show the spontaneous interactions occurring in hybrid mode are split evenly among the categories of collaboration, wanted socialization, and distraction and primarily occur with coworkers at one's desk. From these data, we can establish various correlations between the occurrence of positive spontaneous interactions and different factors, such as the time of day and the locations in the building. This framework and first deployment provide the foundation for future large-scale data collection experiments and human interaction modeling.","sentences":["Hybrid working strategies have become, and will continue to be, the norm for many offices.","This raises two considerations: newly unoccupied spaces needlessly consume energy, and the occupied spaces need to be effectively used to facilitate meaningful interactions and create a positive, sustainable work culture.","This work aims to determine when spontaneous, collaborative interactions occur within the building and the environmental factors that facilitate such interactions.","This study uses smartwatch-based micro-surveys using the Cozie platform to identify the occurrence of and spatially place interactions while categorizing them as a collaboration or distraction.","This method uniquely circumvents pitfalls associated with surveying and qualitative data collection: occupant behaviors are identified in real-time in a non-intrusive manner, and survey data is corroborated with quantitative sensor data.","A proof-of-concept study was deployed with nine hybrid-working participants providing 100 micro-survey cluster responses over approximately two weeks.","The results show the spontaneous interactions occurring in hybrid mode are split evenly among the categories of collaboration, wanted socialization, and distraction and primarily occur with coworkers at one's desk.","From these data, we can establish various correlations between the occurrence of positive spontaneous interactions and different factors, such as the time of day and the locations in the building.","This framework and first deployment provide the foundation for future large-scale data collection experiments and human interaction modeling."],"url":"http://arxiv.org/abs/2307.00789v1"}
{"created":"2023-07-03 07:05:59","title":"Evaluating Shutdown Avoidance of Language Models in Textual Scenarios","abstract":"Recently, there has been an increase in interest in evaluating large language models for emergent and dangerous capabilities. Importantly, agents could reason that in some scenarios their goal is better achieved if they are not turned off, which can lead to undesirable behaviors. In this paper, we investigate the potential of using toy textual scenarios to evaluate instrumental reasoning and shutdown avoidance in language models such as GPT-4 and Claude. Furthermore, we explore whether shutdown avoidance is merely a result of simple pattern matching between the dataset and the prompt or if it is a consistent behaviour across different environments and variations.   We evaluated behaviours manually and also experimented with using language models for automatic evaluations, and these evaluations demonstrate that simple pattern matching is likely not the sole contributing factor for shutdown avoidance. This study provides insights into the behaviour of language models in shutdown avoidance scenarios and inspires further research on the use of textual scenarios for evaluations.","sentences":["Recently, there has been an increase in interest in evaluating large language models for emergent and dangerous capabilities.","Importantly, agents could reason that in some scenarios their goal is better achieved if they are not turned off, which can lead to undesirable behaviors.","In this paper, we investigate the potential of using toy textual scenarios to evaluate instrumental reasoning and shutdown avoidance in language models such as GPT-4 and Claude.","Furthermore, we explore whether shutdown avoidance is merely a result of simple pattern matching between the dataset and the prompt or if it is a consistent behaviour across different environments and variations.   ","We evaluated behaviours manually and also experimented with using language models for automatic evaluations, and these evaluations demonstrate that simple pattern matching is likely not the sole contributing factor for shutdown avoidance.","This study provides insights into the behaviour of language models in shutdown avoidance scenarios and inspires further research on the use of textual scenarios for evaluations."],"url":"http://arxiv.org/abs/2307.00787v1"}
{"created":"2023-07-03 07:05:25","title":"An FTP Algorithm for Temporal Graph Untangling","abstract":"Several classical combinatorial problems have been considered and analysed on temporal graphs. Recently, a variant of Vertex Cover on temporal graphs, called MinTimelineCover, has been introduced to summarize timeline activities in social networks. The problem asks to cover every temporal edge while minimizing the total span of the vertices (where the span of a vertex is the length of the timestamp interval it must remain active in, minus one). While the problem has been shown to be NP-hard even in very restricted cases, its parameterized complexity has not been fully understood. The problem is known to be in FPT under the span parameter only for graphs with two timestamps, but the parameterized complexity for the general case is open. We settle this open problem by giving an FPT algorithm that is based on a combination of iterative compression and a reduction to the Digraph Pair Cut problem, a powerful problem that has received significant attention recently.","sentences":["Several classical combinatorial problems have been considered and analysed on temporal graphs.","Recently, a variant of Vertex Cover on temporal graphs, called MinTimelineCover, has been introduced to summarize timeline activities in social networks.","The problem asks to cover every temporal edge while minimizing the total span of the vertices (where the span of a vertex is the length of the timestamp interval it must remain active in, minus one).","While the problem has been shown to be NP-hard even in very restricted cases, its parameterized complexity has not been fully understood.","The problem is known to be in FPT under the span parameter only for graphs with two timestamps, but the parameterized complexity for the general case is open.","We settle this open problem by giving an FPT algorithm that is based on a combination of iterative compression and a reduction to the Digraph Pair Cut problem, a powerful problem that has received significant attention recently."],"url":"http://arxiv.org/abs/2307.00786v1"}
{"created":"2023-07-03 06:55:03","title":"ContextSpeech: Expressive and Efficient Text-to-Speech for Paragraph Reading","abstract":"While state-of-the-art Text-to-Speech systems can generate natural speech of very high quality at sentence level, they still meet great challenges in speech generation for paragraph / long-form reading. Such deficiencies are due to i) ignorance of cross-sentence contextual information, and ii) high computation and memory cost for long-form synthesis. To address these issues, this work develops a lightweight yet effective TTS system, ContextSpeech. Specifically, we first design a memory-cached recurrence mechanism to incorporate global text and speech context into sentence encoding. Then we construct hierarchically-structured textual semantics to broaden the scope for global context enhancement. Additionally, we integrate linearized self-attention to improve model efficiency. Experiments show that ContextSpeech significantly improves the voice quality and prosody expressiveness in paragraph reading with competitive model efficiency. Audio samples are available at: https://contextspeech.github.io/demo/","sentences":["While state-of-the-art Text-to-Speech systems can generate natural speech of very high quality at sentence level, they still meet great challenges in speech generation for paragraph / long-form reading.","Such deficiencies are due to i) ignorance of cross-sentence contextual information, and ii) high computation and memory cost for long-form synthesis.","To address these issues, this work develops a lightweight yet effective TTS system, ContextSpeech.","Specifically, we first design a memory-cached recurrence mechanism to incorporate global text and speech context into sentence encoding.","Then we construct hierarchically-structured textual semantics to broaden the scope for global context enhancement.","Additionally, we integrate linearized self-attention to improve model efficiency.","Experiments show that ContextSpeech significantly improves the voice quality and prosody expressiveness in paragraph reading with competitive model efficiency.","Audio samples are available at: https://contextspeech.github.io/demo/"],"url":"http://arxiv.org/abs/2307.00782v1"}
{"created":"2023-07-03 06:49:04","title":"ACDMSR: Accelerated Conditional Diffusion Models for Single Image Super-Resolution","abstract":"Diffusion models have gained significant popularity in the field of image-to-image translation. Previous efforts applying diffusion models to image super-resolution (SR) have demonstrated that iteratively refining pure Gaussian noise using a U-Net architecture trained on denoising at various noise levels can yield satisfactory high-resolution images from low-resolution inputs. However, this iterative refinement process comes with the drawback of low inference speed, which strongly limits its applications. To speed up inference and further enhance the performance, our research revisits diffusion models in image super-resolution and proposes a straightforward yet significant diffusion model-based super-resolution method called ACDMSR (accelerated conditional diffusion model for image super-resolution). Specifically, our method adapts the standard diffusion model to perform super-resolution through a deterministic iterative denoising process. Our study also highlights the effectiveness of using a pre-trained SR model to provide the conditional image of the given low-resolution (LR) image to achieve superior high-resolution results. We demonstrate that our method surpasses previous attempts in qualitative and quantitative results through extensive experiments conducted on benchmark datasets such as Set5, Set14, Urban100, BSD100, and Manga109. Moreover, our approach generates more visually realistic counterparts for low-resolution images, emphasizing its effectiveness in practical scenarios.","sentences":["Diffusion models have gained significant popularity in the field of image-to-image translation.","Previous efforts applying diffusion models to image super-resolution (SR) have demonstrated that iteratively refining pure Gaussian noise using a U-Net architecture trained on denoising at various noise levels can yield satisfactory high-resolution images from low-resolution inputs.","However, this iterative refinement process comes with the drawback of low inference speed, which strongly limits its applications.","To speed up inference and further enhance the performance, our research revisits diffusion models in image super-resolution and proposes a straightforward yet significant diffusion model-based super-resolution method called ACDMSR (accelerated conditional diffusion model for image super-resolution).","Specifically, our method adapts the standard diffusion model to perform super-resolution through a deterministic iterative denoising process.","Our study also highlights the effectiveness of using a pre-trained SR model to provide the conditional image of the given low-resolution (LR) image to achieve superior high-resolution results.","We demonstrate that our method surpasses previous attempts in qualitative and quantitative results through extensive experiments conducted on benchmark datasets such as Set5, Set14, Urban100, BSD100, and Manga109.","Moreover, our approach generates more visually realistic counterparts for low-resolution images, emphasizing its effectiveness in practical scenarios."],"url":"http://arxiv.org/abs/2307.00781v1"}
{"created":"2023-07-03 06:41:15","title":"GA-DRL: Graph Neural Network-Augmented Deep Reinforcement Learning for DAG Task Scheduling over Dynamic Vehicular Clouds","abstract":"Vehicular clouds (VCs) are modern platforms for processing of computation-intensive tasks over vehicles. Such tasks are often represented as directed acyclic graphs (DAGs) consisting of interdependent vertices/subtasks and directed edges. In this paper, we propose a graph neural network-augmented deep reinforcement learning scheme (GA-DRL) for scheduling DAG tasks over dynamic VCs. In doing so, we first model the VC-assisted DAG task scheduling as a Markov decision process. We then adopt a multi-head graph attention network (GAT) to extract the features of DAG subtasks. Our developed GAT enables a two-way aggregation of the topological information in a DAG task by simultaneously considering predecessors and successors of each subtask. We further introduce non-uniform DAG neighborhood sampling through codifying the scheduling priority of different subtasks, which makes our developed GAT generalizable to completely unseen DAG task topologies. Finally, we augment GAT into a double deep Q-network learning module to conduct subtask-to-vehicle assignment according to the extracted features of subtasks, while considering the dynamics and heterogeneity of the vehicles in VCs. Through simulating various DAG tasks under real-world movement traces of vehicles, we demonstrate that GA-DRL outperforms existing benchmarks in terms of DAG task completion time.","sentences":["Vehicular clouds (VCs) are modern platforms for processing of computation-intensive tasks over vehicles.","Such tasks are often represented as directed acyclic graphs (DAGs) consisting of interdependent vertices/subtasks and directed edges.","In this paper, we propose a graph neural network-augmented deep reinforcement learning scheme (GA-DRL) for scheduling DAG tasks over dynamic VCs.","In doing so, we first model the VC-assisted DAG task scheduling as a Markov decision process.","We then adopt a multi-head graph attention network (GAT) to extract the features of DAG subtasks.","Our developed GAT enables a two-way aggregation of the topological information in a DAG task by simultaneously considering predecessors and successors of each subtask.","We further introduce non-uniform DAG neighborhood sampling through codifying the scheduling priority of different subtasks, which makes our developed GAT generalizable to completely unseen DAG task topologies.","Finally, we augment GAT into a double deep Q-network learning module to conduct subtask-to-vehicle assignment according to the extracted features of subtasks, while considering the dynamics and heterogeneity of the vehicles in VCs.","Through simulating various DAG tasks under real-world movement traces of vehicles, we demonstrate that GA-DRL outperforms existing benchmarks in terms of DAG task completion time."],"url":"http://arxiv.org/abs/2307.00777v1"}
{"created":"2023-07-03 06:33:49","title":"DifFSS: Diffusion Model for Few-Shot Semantic Segmentation","abstract":"Diffusion models have demonstrated excellent performance in image generation. Although various few-shot semantic segmentation (FSS) models with different network structures have been proposed, performance improvement has reached a bottleneck. This paper presents the first work to leverage the diffusion model for FSS task, called DifFSS. DifFSS, a novel FSS paradigm, can further improve the performance of the state-of-the-art FSS models by a large margin without modifying their network structure. Specifically, we utilize the powerful generation ability of diffusion models to generate diverse auxiliary support images by using the semantic mask, scribble or soft HED boundary of the support image as control conditions. This generation process simulates the variety within the class of the query image, such as color, texture variation, lighting, $etc$. As a result, FSS models can refer to more diverse support images, yielding more robust representations, thereby achieving a consistent improvement in segmentation performance. Extensive experiments on three publicly available datasets based on existing advanced FSS models demonstrate the effectiveness of the diffusion model for FSS task. Furthermore, we explore in detail the impact of different input settings of the diffusion model on segmentation performance. Hopefully, this completely new paradigm will bring inspiration to the study of FSS task integrated with AI-generated content.","sentences":["Diffusion models have demonstrated excellent performance in image generation.","Although various few-shot semantic segmentation (FSS) models with different network structures have been proposed, performance improvement has reached a bottleneck.","This paper presents the first work to leverage the diffusion model for FSS task, called DifFSS.","DifFSS, a novel FSS paradigm, can further improve the performance of the state-of-the-art FSS models by a large margin without modifying their network structure.","Specifically, we utilize the powerful generation ability of diffusion models to generate diverse auxiliary support images by using the semantic mask, scribble or soft HED boundary of the support image as control conditions.","This generation process simulates the variety within the class of the query image, such as color, texture variation, lighting, $etc$. As a result, FSS models can refer to more diverse support images, yielding more robust representations, thereby achieving a consistent improvement in segmentation performance.","Extensive experiments on three publicly available datasets based on existing advanced FSS models demonstrate the effectiveness of the diffusion model for FSS task.","Furthermore, we explore in detail the impact of different input settings of the diffusion model on segmentation performance.","Hopefully, this completely new paradigm will bring inspiration to the study of FSS task integrated with AI-generated content."],"url":"http://arxiv.org/abs/2307.00773v1"}
{"created":"2023-07-03 06:21:05","title":"Resistive memory-based zero-shot liquid state machine for multimodal event data learning","abstract":"The human brain is a complex spiking neural network (SNN) that learns multimodal signals in a zero-shot manner by generalizing existing knowledge. Remarkably, the brain achieves this with minimal power consumption, using event-based signals that propagate within its structure. However, mimicking the human brain in neuromorphic hardware presents both hardware and software challenges. Hardware limitations, such as the slowdown of Moore's law and the von Neumann bottleneck, hinder the efficiency of digital computers. On the software side, SNNs are known for their difficult training, especially when learning multimodal signals. To overcome these challenges, we propose a hardware-software co-design that combines a fixed and random liquid state machine (LSM) SNN encoder with trainable artificial neural network (ANN) projections. The LSM is physically implemented using analogue resistive memory, leveraging the inherent stochasticity of resistive switching to generate random weights. This highly efficient and nanoscale in-memory computing approach effectively addresses the von Neumann bottleneck and the slowdown of Moore's law. The ANN projections are implemented digitally, allowing for easy optimization using contrastive loss, which helps to overcome the difficulties associated with SNN training. We experimentally implement this co-design on a 40nm 256Kb in-memory computing macro. We first demonstrate LSM-based event encoding through supervised classification and linear probing on the N-MNIST and N-TIDIGITS datasets.","sentences":["The human brain is a complex spiking neural network (SNN) that learns multimodal signals in a zero-shot manner by generalizing existing knowledge.","Remarkably, the brain achieves this with minimal power consumption, using event-based signals that propagate within its structure.","However, mimicking the human brain in neuromorphic hardware presents both hardware and software challenges.","Hardware limitations, such as the slowdown of Moore's law and the von Neumann bottleneck, hinder the efficiency of digital computers.","On the software side, SNNs are known for their difficult training, especially when learning multimodal signals.","To overcome these challenges, we propose a hardware-software co-design that combines a fixed and random liquid state machine (LSM) SNN encoder with trainable artificial neural network (ANN) projections.","The LSM is physically implemented using analogue resistive memory, leveraging the inherent stochasticity of resistive switching to generate random weights.","This highly efficient and nanoscale in-memory computing approach effectively addresses the von Neumann bottleneck and the slowdown of Moore's law.","The ANN projections are implemented digitally, allowing for easy optimization using contrastive loss, which helps to overcome the difficulties associated with SNN training.","We experimentally implement this co-design on a 40nm 256Kb in-memory computing macro.","We first demonstrate LSM-based event encoding through supervised classification and linear probing on the N-MNIST and N-TIDIGITS datasets."],"url":"http://arxiv.org/abs/2307.00771v1"}
{"created":"2023-07-03 06:18:13","title":"CollabKG: A Learnable Human-Machine-Cooperative Information Extraction Toolkit for (Event) Knowledge Graph Construction","abstract":"In order to construct or extend entity-centric and event-centric knowledge graphs (KG and EKG), the information extraction (IE) annotation toolkit is essential. However, existing IE toolkits have several non-trivial problems, such as not supporting multi-tasks, not supporting automatic updates. In this work, we present CollabKG, a learnable human-machine-cooperative IE toolkit for KG and EKG construction. Specifically, for the multi-task issue, CollabKG unifies different IE subtasks, including named entity recognition (NER), entity-relation triple extraction (RE), and event extraction (EE), and supports both KG and EKG. Then, combining advanced prompting-based IE technology, the human-machine-cooperation mechanism with LLMs as the assistant machine is presented which can provide a lower cost as well as a higher performance. Lastly, owing to the two-way interaction between the human and machine, CollabKG with learning ability allows self-renewal. Besides, CollabKG has several appealing features (e.g., customization, training-free, propagation, etc.) that make the system powerful, easy-to-use, and high-productivity. We holistically compare our toolkit with other existing tools on these features. Human evaluation quantitatively illustrates that CollabKG significantly improves annotation quality, efficiency, and stability simultaneously.","sentences":["In order to construct or extend entity-centric and event-centric knowledge graphs (KG and EKG), the information extraction (IE) annotation toolkit is essential.","However, existing IE toolkits have several non-trivial problems, such as not supporting multi-tasks, not supporting automatic updates.","In this work, we present CollabKG, a learnable human-machine-cooperative IE toolkit for KG and EKG construction.","Specifically, for the multi-task issue, CollabKG unifies different IE subtasks, including named entity recognition (NER), entity-relation triple extraction (RE), and event extraction (EE), and supports both KG and EKG.","Then, combining advanced prompting-based IE technology, the human-machine-cooperation mechanism with LLMs as the assistant machine is presented which can provide a lower cost as well as a higher performance.","Lastly, owing to the two-way interaction between the human and machine, CollabKG with learning ability allows self-renewal.","Besides, CollabKG has several appealing features (e.g., customization, training-free, propagation, etc.) that make the system powerful, easy-to-use, and high-productivity.","We holistically compare our toolkit with other existing tools on these features.","Human evaluation quantitatively illustrates that CollabKG significantly improves annotation quality, efficiency, and stability simultaneously."],"url":"http://arxiv.org/abs/2307.00769v1"}
{"created":"2023-07-03 06:02:15","title":"Hierarchical Open-vocabulary Universal Image Segmentation","abstract":"Open-vocabulary image segmentation aims to partition an image into semantic regions according to arbitrary text descriptions. However, complex visual scenes can be naturally decomposed into simpler parts and abstracted at multiple levels of granularity, introducing inherent segmentation ambiguity. Unlike existing methods that typically sidestep this ambiguity and treat it as an external factor, our approach actively incorporates a hierarchical representation encompassing different semantic-levels into the learning process. We propose a decoupled text-image fusion mechanism and representation learning modules for both \"things\" and \"stuff\".1 Additionally, we systematically examine the differences that exist in the textual and visual features between these types of categories. Our resulting model, named HIPIE, tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within a unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO, Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the state-of-the-art results at various levels of image comprehension, including semantic-level (e.g., semantic segmentation), instance-level (e.g., panoptic/referring segmentation and object detection), as well as part-level (e.g., part/subpart segmentation) tasks. Our code is released at https://github.com/berkeley-hipie/HIPIE.","sentences":["Open-vocabulary image segmentation aims to partition an image into semantic regions according to arbitrary text descriptions.","However, complex visual scenes can be naturally decomposed into simpler parts and abstracted at multiple levels of granularity, introducing inherent segmentation ambiguity.","Unlike existing methods that typically sidestep this ambiguity and treat it as an external factor, our approach actively incorporates a hierarchical representation encompassing different semantic-levels into the learning process.","We propose a decoupled text-image fusion mechanism and representation learning modules for both \"things\" and \"stuff\".1 Additionally, we systematically examine the differences that exist in the textual and visual features between these types of categories.","Our resulting model, named HIPIE, tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within a unified framework.","Benchmarked on over 40 datasets, e.g., ADE20K, COCO, Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the state-of-the-art results at various levels of image comprehension, including semantic-level (e.g., semantic segmentation), instance-level (e.g., panoptic/referring segmentation and object detection), as well as part-level (e.g., part/subpart segmentation) tasks.","Our code is released at https://github.com/berkeley-hipie/HIPIE."],"url":"http://arxiv.org/abs/2307.00764v1"}
{"created":"2023-07-03 05:38:28","title":"Learning Noise-Resistant Image Representation by Aligning Clean and Noisy Domains","abstract":"Recent supervised and unsupervised image representation learning algorithms have achieved quantum leaps. However, these techniques do not account for representation resilience against noise in their design paradigms. Consequently, these effective methods suffer failure when confronted with noise outside the training distribution, such as complicated real-world noise that is usually opaque to model training. To address this issue, dual domains are optimized to separately model a canonical space for noisy representations, namely the Noise-Robust (NR) domain, and a twinned canonical clean space, namely the Noise-Free (NF) domain, by maximizing the interaction information between the representations. Given the dual canonical domains, we design a target-guided implicit neural mapping function to accurately translate the NR representations to the NF domain, yielding noise-resistant representations by eliminating noise regencies. The proposed method is a scalable module that can be readily integrated into existing learning systems to improve their robustness against noise. Comprehensive trials of various tasks using both synthetic and real-world noisy data demonstrate that the proposed Target-Guided Dual-Domain Translation (TDDT) method is able to achieve remarkable performance and robustness in the face of complex noisy images.","sentences":["Recent supervised and unsupervised image representation learning algorithms have achieved quantum leaps.","However, these techniques do not account for representation resilience against noise in their design paradigms.","Consequently, these effective methods suffer failure when confronted with noise outside the training distribution, such as complicated real-world noise that is usually opaque to model training.","To address this issue, dual domains are optimized to separately model a canonical space for noisy representations, namely the Noise-Robust (NR) domain, and a twinned canonical clean space, namely the Noise-Free (NF) domain, by maximizing the interaction information between the representations.","Given the dual canonical domains, we design a target-guided implicit neural mapping function to accurately translate the NR representations to the NF domain, yielding noise-resistant representations by eliminating noise regencies.","The proposed method is a scalable module that can be readily integrated into existing learning systems to improve their robustness against noise.","Comprehensive trials of various tasks using both synthetic and real-world noisy data demonstrate that the proposed Target-Guided Dual-Domain Translation (TDDT) method is able to achieve remarkable performance and robustness in the face of complex noisy images."],"url":"http://arxiv.org/abs/2307.00761v1"}
{"created":"2023-07-03 05:29:38","title":"Multilingual Contextual Adapters To Improve Custom Word Recognition In Low-resource Languages","abstract":"Connectionist Temporal Classification (CTC) models are popular for their balance between speed and performance for Automatic Speech Recognition (ASR). However, these CTC models still struggle in other areas, such as personalization towards custom words. A recent approach explores Contextual Adapters, wherein an attention-based biasing model for CTC is used to improve the recognition of custom entities. While this approach works well with enough data, we showcase that it isn't an effective strategy for low-resource languages. In this work, we propose a supervision loss for smoother training of the Contextual Adapters. Further, we explore a multilingual strategy to improve performance with limited training data. Our method achieves 48% F1 improvement in retrieving unseen custom entities for a low-resource language. Interestingly, as a by-product of training the Contextual Adapters, we see a 5-11% Word Error Rate (WER) reduction in the performance of the base CTC model as well.","sentences":["Connectionist Temporal Classification (CTC) models are popular for their balance between speed and performance for Automatic Speech Recognition (ASR).","However, these CTC models still struggle in other areas, such as personalization towards custom words.","A recent approach explores Contextual Adapters, wherein an attention-based biasing model for CTC is used to improve the recognition of custom entities.","While this approach works well with enough data, we showcase that it isn't an effective strategy for low-resource languages.","In this work, we propose a supervision loss for smoother training of the Contextual Adapters.","Further, we explore a multilingual strategy to improve performance with limited training data.","Our method achieves 48% F1 improvement in retrieving unseen custom entities for a low-resource language.","Interestingly, as a by-product of training the Contextual Adapters, we see a 5-11% Word Error Rate (WER) reduction in the performance of the base CTC model as well."],"url":"http://arxiv.org/abs/2307.00759v1"}
{"created":"2023-07-03 05:26:05","title":"Structured Network Pruning by Measuring Filter-wise Interactions","abstract":"Structured network pruning is a practical approach to reduce computation cost directly while retaining the CNNs' generalization performance in real applications. However, identifying redundant filters is a core problem in structured network pruning, and current redundancy criteria only focus on individual filters' attributes. When pruning sparsity increases, these redundancy criteria are not effective or efficient enough. Since the filter-wise interaction also contributes to the CNN's prediction accuracy, we integrate the filter-wise interaction into the redundancy criterion. In our criterion, we introduce the filter importance and filter utilization strength to reflect the decision ability of individual and multiple filters. Utilizing this new redundancy criterion, we propose a structured network pruning approach SNPFI (Structured Network Pruning by measuring Filter-wise Interaction). During the pruning, the SNPFI can automatically assign the proper sparsity based on the filter utilization strength and eliminate the useless filters by filter importance. After the pruning, the SNPFI can recover pruned model's performance effectively without iterative training by minimizing the interaction difference. We empirically demonstrate the effectiveness of the SNPFI with several commonly used CNN models, including AlexNet, MobileNetv1, and ResNet-50, on various image classification datasets, including MNIST, CIFAR-10, and ImageNet. For all experimental CNN models, nearly 60% of computation is reduced in a network compression while the classification accuracy remains.","sentences":["Structured network pruning is a practical approach to reduce computation cost directly while retaining the CNNs' generalization performance in real applications.","However, identifying redundant filters is a core problem in structured network pruning, and current redundancy criteria only focus on individual filters' attributes.","When pruning sparsity increases, these redundancy criteria are not effective or efficient enough.","Since the filter-wise interaction also contributes to the CNN's prediction accuracy, we integrate the filter-wise interaction into the redundancy criterion.","In our criterion, we introduce the filter importance and filter utilization strength to reflect the decision ability of individual and multiple filters.","Utilizing this new redundancy criterion, we propose a structured network pruning approach SNPFI (Structured Network Pruning by measuring Filter-wise Interaction).","During the pruning, the SNPFI can automatically assign the proper sparsity based on the filter utilization strength and eliminate the useless filters by filter importance.","After the pruning, the SNPFI can recover pruned model's performance effectively without iterative training by minimizing the interaction difference.","We empirically demonstrate the effectiveness of the SNPFI with several commonly used CNN models, including AlexNet, MobileNetv1, and ResNet-50, on various image classification datasets, including MNIST, CIFAR-10, and ImageNet.","For all experimental CNN models, nearly 60% of computation is reduced in a network compression while the classification accuracy remains."],"url":"http://arxiv.org/abs/2307.00758v1"}
{"created":"2023-07-03 05:04:34","title":"Towards Real Smart Apps: Investigating Human-AI Interactions in Smartphone On-Device AI Apps","abstract":"With the emergence of deep learning techniques, smartphone apps are now embedded on-device AI features for enabling advanced tasks like speech translation, to attract users and increase market competitiveness. A good interaction design is important to make an AI feature usable and understandable. However, AI features have their unique challenges like sensitiveness to the input, dynamic behaviours and output uncertainty. Existing guidelines and tools either do not cover AI features or consider mobile apps which are confirmed by our informal interview with professional designers. To address these issues, we conducted the first empirical study to explore user-AI-interaction in mobile apps. We aim to understand the status of on-device AI usage by investigating 176 AI apps from 62,822 apps. We identified 255 AI features and summarised 759 implementations into three primary interaction pattern types. We further implemented our findings into a multi-faceted search-enabled gallery. The results of the user study demonstrate the usefulness of our findings.","sentences":["With the emergence of deep learning techniques, smartphone apps are now embedded on-device AI features for enabling advanced tasks like speech translation, to attract users and increase market competitiveness.","A good interaction design is important to make an AI feature usable and understandable.","However, AI features have their unique challenges like sensitiveness to the input, dynamic behaviours and output uncertainty.","Existing guidelines and tools either do not cover AI features or consider mobile apps which are confirmed by our informal interview with professional designers.","To address these issues, we conducted the first empirical study to explore user-AI-interaction in mobile apps.","We aim to understand the status of on-device AI usage by investigating 176 AI apps from 62,822 apps.","We identified 255 AI features and summarised 759 implementations into three primary interaction pattern types.","We further implemented our findings into a multi-faceted search-enabled gallery.","The results of the user study demonstrate the usefulness of our findings."],"url":"http://arxiv.org/abs/2307.00756v1"}
{"created":"2023-07-03 04:57:53","title":"Graph-level Anomaly Detection via Hierarchical Memory Networks","abstract":"Graph-level anomaly detection aims to identify abnormal graphs that exhibit deviant structures and node attributes compared to the majority in a graph set. One primary challenge is to learn normal patterns manifested in both fine-grained and holistic views of graphs for identifying graphs that are abnormal in part or in whole. To tackle this challenge, we propose a novel approach called Hierarchical Memory Networks (HimNet), which learns hierarchical memory modules -- node and graph memory modules -- via a graph autoencoder network architecture. The node-level memory module is trained to model fine-grained, internal graph interactions among nodes for detecting locally abnormal graphs, while the graph-level memory module is dedicated to the learning of holistic normal patterns for detecting globally abnormal graphs. The two modules are jointly optimized to detect both locally- and globally-anomalous graphs. Extensive empirical results on 16 real-world graph datasets from various domains show that i) HimNet significantly outperforms the state-of-art methods and ii) it is robust to anomaly contamination. Codes are available at: https://github.com/Niuchx/HimNet.","sentences":["Graph-level anomaly detection aims to identify abnormal graphs that exhibit deviant structures and node attributes compared to the majority in a graph set.","One primary challenge is to learn normal patterns manifested in both fine-grained and holistic views of graphs for identifying graphs that are abnormal in part or in whole.","To tackle this challenge, we propose a novel approach called Hierarchical Memory Networks (HimNet), which learns hierarchical memory modules -- node and graph memory modules -- via a graph autoencoder network architecture.","The node-level memory module is trained to model fine-grained, internal graph interactions among nodes for detecting locally abnormal graphs, while the graph-level memory module is dedicated to the learning of holistic normal patterns for detecting globally abnormal graphs.","The two modules are jointly optimized to detect both locally- and globally-anomalous graphs.","Extensive empirical results on 16 real-world graph datasets from various domains show that i) HimNet significantly outperforms the state-of-art methods and ii) it is robust to anomaly contamination.","Codes are available at: https://github.com/Niuchx/HimNet."],"url":"http://arxiv.org/abs/2307.00755v1"}
{"created":"2023-07-03 04:57:40","title":"ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection","abstract":"Anomaly detection in multivariate time series data is of paramount importance for ensuring the efficient operation of large-scale systems across diverse domains. However, accurately detecting anomalies in such data poses significant challenges. Existing approaches, including forecasting and reconstruction-based methods, struggle to address these challenges effectively. To overcome these limitations, we propose a novel anomaly detection framework named ImDiffusion, which combines time series imputation and diffusion models to achieve accurate and robust anomaly detection. The imputation-based approach employed by ImDiffusion leverages the information from neighboring values in the time series, enabling precise modeling of temporal and inter-correlated dependencies, reducing uncertainty in the data, thereby enhancing the robustness of the anomaly detection process. ImDiffusion further leverages diffusion models as time series imputers to accurately capturing complex dependencies. We leverage the step-by-step denoised outputs generated during the inference process to serve as valuable signals for anomaly prediction, resulting in improved accuracy and robustness of the detection process.   We evaluate the performance of ImDiffusion via extensive experiments on benchmark datasets. The results demonstrate that our proposed framework significantly outperforms state-of-the-art approaches in terms of detection accuracy and timeliness. ImDiffusion is further integrated into the real production system in Microsoft and observe a remarkable 11.4% increase in detection F1 score compared to the legacy approach. To the best of our knowledge, ImDiffusion represents a pioneering approach that combines imputation-based techniques with time series anomaly detection, while introducing the novel use of diffusion models to the field.","sentences":["Anomaly detection in multivariate time series data is of paramount importance for ensuring the efficient operation of large-scale systems across diverse domains.","However, accurately detecting anomalies in such data poses significant challenges.","Existing approaches, including forecasting and reconstruction-based methods, struggle to address these challenges effectively.","To overcome these limitations, we propose a novel anomaly detection framework named ImDiffusion, which combines time series imputation and diffusion models to achieve accurate and robust anomaly detection.","The imputation-based approach employed by ImDiffusion leverages the information from neighboring values in the time series, enabling precise modeling of temporal and inter-correlated dependencies, reducing uncertainty in the data, thereby enhancing the robustness of the anomaly detection process.","ImDiffusion further leverages diffusion models as time series imputers to accurately capturing complex dependencies.","We leverage the step-by-step denoised outputs generated during the inference process to serve as valuable signals for anomaly prediction, resulting in improved accuracy and robustness of the detection process.   ","We evaluate the performance of ImDiffusion via extensive experiments on benchmark datasets.","The results demonstrate that our proposed framework significantly outperforms state-of-the-art approaches in terms of detection accuracy and timeliness.","ImDiffusion is further integrated into the real production system in Microsoft and observe a remarkable 11.4% increase in detection F1 score compared to the legacy approach.","To the best of our knowledge, ImDiffusion represents a pioneering approach that combines imputation-based techniques with time series anomaly detection, while introducing the novel use of diffusion models to the field."],"url":"http://arxiv.org/abs/2307.00754v1"}
{"created":"2023-07-03 04:56:55","title":"Population Age Group Sensitivity for COVID-19 Infections with Deep Learning","abstract":"The COVID-19 pandemic has created unprecedented challenges for governments and healthcare systems worldwide, highlighting the critical importance of understanding the factors that contribute to virus transmission. This study aimed to identify the most influential age groups in COVID-19 infection rates at the US county level using the Modified Morris Method and deep learning for time series. Our approach involved training the state-of-the-art time-series model Temporal Fusion Transformer on different age groups as a static feature and the population vaccination status as the dynamic feature. We analyzed the impact of those age groups on COVID-19 infection rates by perturbing individual input features and ranked them based on their Morris sensitivity scores, which quantify their contribution to COVID-19 transmission rates. The findings are verified using ground truth data from the CDC and US Census, which provide the true infection rates for each age group. The results suggest that young adults were the most influential age group in COVID-19 transmission at the county level between March 1, 2020, and November 27, 2021. Using these results can inform public health policies and interventions, such as targeted vaccination strategies, to better control the spread of the virus. Our approach demonstrates the utility of feature sensitivity analysis in identifying critical factors contributing to COVID-19 transmission and can be applied in other public health domains.","sentences":["The COVID-19 pandemic has created unprecedented challenges for governments and healthcare systems worldwide, highlighting the critical importance of understanding the factors that contribute to virus transmission.","This study aimed to identify the most influential age groups in COVID-19 infection rates at the US county level using the Modified Morris Method and deep learning for time series.","Our approach involved training the state-of-the-art time-series model Temporal Fusion Transformer on different age groups as a static feature and the population vaccination status as the dynamic feature.","We analyzed the impact of those age groups on COVID-19 infection rates by perturbing individual input features and ranked them based on their Morris sensitivity scores, which quantify their contribution to COVID-19 transmission rates.","The findings are verified using ground truth data from the CDC and US Census, which provide the true infection rates for each age group.","The results suggest that young adults were the most influential age group in COVID-19 transmission at the county level between March 1, 2020, and November 27, 2021.","Using these results can inform public health policies and interventions, such as targeted vaccination strategies, to better control the spread of the virus.","Our approach demonstrates the utility of feature sensitivity analysis in identifying critical factors contributing to COVID-19 transmission and can be applied in other public health domains."],"url":"http://arxiv.org/abs/2307.00751v1"}
{"created":"2023-07-03 04:56:17","title":"Feasibility of Universal Anomaly Detection without Knowing the Abnormality in Medical Images","abstract":"Many anomaly detection approaches, especially deep learning methods, have been recently developed to identify abnormal image morphology by only employing normal images during training. Unfortunately, many prior anomaly detection methods were optimized for a specific \"known\" abnormality (e.g., brain tumor, bone fraction, cell types). Moreover, even though only the normal images were used in the training process, the abnormal images were oftenly employed during the validation process (e.g., epoch selection, hyper-parameter tuning), which might leak the supposed ``unknown\" abnormality unintentionally. In this study, we investigated these two essential aspects regarding universal anomaly detection in medical images by (1) comparing various anomaly detection methods across four medical datasets, (2) investigating the inevitable but often neglected issues on how to unbiasedly select the optimal anomaly detection model during the validation phase using only normal images, and (3) proposing a simple decision-level ensemble method to leverage the advantage of different kinds of anomaly detection without knowing the abnormality. The results of our experiments indicate that none of the evaluated methods consistently achieved the best performance across all datasets. Our proposed method enhanced the robustness of performance in general (average AUC 0.956).","sentences":["Many anomaly detection approaches, especially deep learning methods, have been recently developed to identify abnormal image morphology by only employing normal images during training.","Unfortunately, many prior anomaly detection methods were optimized for a specific \"known\" abnormality (e.g., brain tumor, bone fraction, cell types).","Moreover, even though only the normal images were used in the training process, the abnormal images were oftenly employed during the validation process (e.g., epoch selection, hyper-parameter tuning), which might leak the supposed ``unknown\" abnormality unintentionally.","In this study, we investigated these two essential aspects regarding universal anomaly detection in medical images by (1) comparing various anomaly detection methods across four medical datasets, (2) investigating the inevitable but often neglected issues on how to unbiasedly select the optimal anomaly detection model during the validation phase using only normal images, and (3) proposing a simple decision-level ensemble method to leverage the advantage of different kinds of anomaly detection without knowing the abnormality.","The results of our experiments indicate that none of the evaluated methods consistently achieved the best performance across all datasets.","Our proposed method enhanced the robustness of performance in general (average AUC 0.956)."],"url":"http://arxiv.org/abs/2307.00750v1"}
{"created":"2023-07-03 04:16:20","title":"Joint Power Allocation and Beamforming for Active IRS-aided Directional Modulation Network","abstract":"To boost the secrecy rate (SR) of the conventional directional modulation (DM) network and overcome the double fading effect of the cascaded channels of passive intelligent reflecting surface (IRS), a novel active IRS-assisted DM system is investigated in this paper. Aiming to maximize the SR, two power allocation (PA) strategies, called maximizing SR based on fractional programming (FP) (Max-SR-FP) and maximizing SR based on derivative operation (DO) (Max-SR-DO), are proposed by jointly designing the PA factors, beamforming vector, and phase shift matrix of IRS, subject to the power constraint at IRS. The former with higher performance employs the FP and successive convex approximation (SCA) algorithms to design the confidential message PA factor and the total PA factor at the base station, and the SCA algorithm is also utilized to design the beamforming vector and the phase shift matrix of the IRS. The latter with lower complexity adopts the DO, and equal amplitude reflecting (EAR) and general power iterative (GPI) methods to solve them, respectively. The simulation results show that compared with the benchmark PA schemes, both the proposed PA schemes achieve a significant SR performance improvement. Moreover, the SR gap between two proposed schemes decreases gradually with the increases of the number of IRS phase shift element.","sentences":["To boost the secrecy rate (SR) of the conventional directional modulation (DM) network and overcome the double fading effect of the cascaded channels of passive intelligent reflecting surface (IRS), a novel active IRS-assisted DM system is investigated in this paper.","Aiming to maximize the SR, two power allocation (PA) strategies, called maximizing SR based on fractional programming (FP) (Max-SR-FP) and maximizing SR based on derivative operation (DO) (Max-SR-DO), are proposed by jointly designing the PA factors, beamforming vector, and phase shift matrix of IRS, subject to the power constraint at IRS.","The former with higher performance employs the FP and successive convex approximation (SCA) algorithms to design the confidential message PA factor and the total PA factor at the base station, and the SCA algorithm is also utilized to design the beamforming vector and the phase shift matrix of the IRS.","The latter with lower complexity adopts the DO, and equal amplitude reflecting (EAR) and general power iterative (GPI) methods to solve them, respectively.","The simulation results show that compared with the benchmark PA schemes, both the proposed PA schemes achieve a significant SR performance improvement.","Moreover, the SR gap between two proposed schemes decreases gradually with the increases of the number of IRS phase shift element."],"url":"http://arxiv.org/abs/2307.00743v1"}
{"created":"2023-07-03 04:10:55","title":"UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input","abstract":"Localization is a fundamental task in robotics for autonomous navigation. Existing localization methods rely on a single input data modality or train several computational models to process different modalities. This leads to stringent computational requirements and sub-optimal results that fail to capitalize on the complementary information in other data streams. This paper proposes UnLoc, a novel unified neural modeling approach for localization with multi-sensor input in all weather conditions. Our multi-stream network can handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can work with one or more input sensors, making it robust to sensor failure. UnLoc uses 3D sparse convolutions and cylindrical partitioning of the space to process LiDAR frames and implements ResNet blocks with a slot attention-based feature filtering module for the Radar and image modalities. We introduce a unique learnable modality encoding scheme to distinguish between the input sensor data. Our method is extensively evaluated on Oxford Radar RobotCar, ApolloSouthBay and Perth-WA datasets. The results ascertain the efficacy of our technique.","sentences":["Localization is a fundamental task in robotics for autonomous navigation.","Existing localization methods rely on a single input data modality or train several computational models to process different modalities.","This leads to stringent computational requirements and sub-optimal results that fail to capitalize on the complementary information in other data streams.","This paper proposes UnLoc, a novel unified neural modeling approach for localization with multi-sensor input in all weather conditions.","Our multi-stream network can handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can work with one or more input sensors, making it robust to sensor failure.","UnLoc uses 3D sparse convolutions and cylindrical partitioning of the space to process LiDAR frames and implements ResNet blocks with a slot attention-based feature filtering module for the Radar and image modalities.","We introduce a unique learnable modality encoding scheme to distinguish between the input sensor data.","Our method is extensively evaluated on Oxford Radar RobotCar, ApolloSouthBay and Perth-WA datasets.","The results ascertain the efficacy of our technique."],"url":"http://arxiv.org/abs/2307.00741v1"}
{"created":"2023-07-03 03:44:12","title":"Novelty and Lifted Helpful Actions in Generalized Planning","abstract":"It has been shown recently that successful techniques in classical planning, such as goal-oriented heuristics and landmarks, can improve the ability to compute planning programs for generalized planning (GP) problems. In this work, we introduce the notion of action novelty rank, which computes novelty with respect to a planning program, and propose novelty-based generalized planning solvers, which prune a newly generated planning program if its most frequent action repetition is greater than a given bound $v$, implemented by novelty-based best-first search BFS($v$) and its progressive variant PGP($v$). Besides, we introduce lifted helpful actions in GP derived from action schemes, and propose new evaluation functions and structural program restrictions to scale up the search. Our experiments show that the new algorithms BFS($v$) and PGP($v$) outperform the state-of-the-art in GP over the standard generalized planning benchmarks. Practical findings on the above-mentioned methods in generalized planning are briefly discussed.","sentences":["It has been shown recently that successful techniques in classical planning, such as goal-oriented heuristics and landmarks, can improve the ability to compute planning programs for generalized planning (GP) problems.","In this work, we introduce the notion of action novelty rank, which computes novelty with respect to a planning program, and propose novelty-based generalized planning solvers, which prune a newly generated planning program if its most frequent action repetition is greater than a given bound $v$, implemented by novelty-based best-first search BFS($v$) and its progressive variant PGP($v$).","Besides, we introduce lifted helpful actions in GP derived from action schemes, and propose new evaluation functions and structural program restrictions to scale up the search.","Our experiments show that the new algorithms BFS($v$) and PGP($v$) outperform the state-of-the-art in GP over the standard generalized planning benchmarks.","Practical findings on the above-mentioned methods in generalized planning are briefly discussed."],"url":"http://arxiv.org/abs/2307.00735v1"}
{"created":"2023-07-03 03:21:23","title":"An End-to-End Multi-Module Audio Deepfake Generation System for ADD Challenge 2023","abstract":"The task of synthetic speech generation is to generate language content from a given text, then simulating fake human voice.The key factors that determine the effect of synthetic speech generation mainly include speed of generation, accuracy of word segmentation, naturalness of synthesized speech, etc. This paper builds an end-to-end multi-module synthetic speech generation model, including speaker encoder, synthesizer based on Tacotron2, and vocoder based on WaveRNN. In addition, we perform a lot of comparative experiments on different datasets and various model structures. Finally, we won the first place in the ADD 2023 challenge Track 1.1 with the weighted deception success rate (WDSR) of 44.97%.","sentences":["The task of synthetic speech generation is to generate language content from a given text, then simulating fake human voice.","The key factors that determine the effect of synthetic speech generation mainly include speed of generation, accuracy of word segmentation, naturalness of synthesized speech, etc.","This paper builds an end-to-end multi-module synthetic speech generation model, including speaker encoder, synthesizer based on Tacotron2, and vocoder based on WaveRNN.","In addition, we perform a lot of comparative experiments on different datasets and various model structures.","Finally, we won the first place in the ADD 2023 challenge Track 1.1 with the weighted deception success rate (WDSR) of 44.97%."],"url":"http://arxiv.org/abs/2307.00729v1"}
{"created":"2023-07-03 03:09:44","title":"LXL: LiDAR Exclusive Lean 3D Object Detection with 4D Imaging Radar and Camera Fusion","abstract":"As an emerging technology and a relatively affordable device, the 4D imaging radar has already been confirmed effective in performing 3D object detection in autonomous driving. Nevertheless, the sparsity and noisiness of 4D radar point clouds hinder further performance improvement, and in-depth studies about its fusion with other modalities are lacking. On the other hand, most of the camera-based perception methods transform the extracted image perspective view features into the bird's-eye view geometrically via \"depth-based splatting\" proposed in Lift-Splat-Shoot (LSS), and some researchers exploit other modals such as LiDARs or ordinary automotive radars for enhancement. Recently, a few works have applied the \"sampling\" strategy for image view transformation, showing that it outperforms \"splatting\" even without image depth prediction. However, the potential of \"sampling\" is not fully unleashed. In this paper, we investigate the \"sampling\" view transformation strategy on the camera and 4D imaging radar fusion-based 3D object detection. In the proposed model, LXL, predicted image depth distribution maps and radar 3D occupancy grids are utilized to aid image view transformation, called \"radar occupancy-assisted depth-based sampling\". Experiments on VoD and TJ4DRadSet datasets show that the proposed method outperforms existing 3D object detection methods by a significant margin without bells and whistles. Ablation studies demonstrate that our method performs the best among different enhancement settings.","sentences":["As an emerging technology and a relatively affordable device, the 4D imaging radar has already been confirmed effective in performing 3D object detection in autonomous driving.","Nevertheless, the sparsity and noisiness of 4D radar point clouds hinder further performance improvement, and in-depth studies about its fusion with other modalities are lacking.","On the other hand, most of the camera-based perception methods transform the extracted image perspective view features into the bird's-eye view geometrically via \"depth-based splatting\" proposed in Lift-Splat-Shoot (LSS), and some researchers exploit other modals such as LiDARs or ordinary automotive radars for enhancement.","Recently, a few works have applied the \"sampling\" strategy for image view transformation, showing that it outperforms \"splatting\" even without image depth prediction.","However, the potential of \"sampling\" is not fully unleashed.","In this paper, we investigate the \"sampling\" view transformation strategy on the camera and 4D imaging radar fusion-based 3D object detection.","In the proposed model, LXL, predicted image depth distribution maps and radar 3D occupancy grids are utilized to aid image view transformation, called \"radar occupancy-assisted depth-based sampling\".","Experiments on VoD and TJ4DRadSet datasets show that the proposed method outperforms existing 3D object detection methods by a significant margin without bells and whistles.","Ablation studies demonstrate that our method performs the best among different enhancement settings."],"url":"http://arxiv.org/abs/2307.00724v1"}
{"created":"2023-07-03 03:00:22","title":"Neural Polytopes","abstract":"We find that simple neural networks with ReLU activation generate polytopes as an approximation of a unit sphere in various dimensions. The species of polytopes are regulated by the network architecture, such as the number of units and layers. For a variety of activation functions, generalization of polytopes is obtained, which we call neural polytopes. They are a smooth analogue of polytopes, exhibiting geometric duality. This finding initiates research of discrete geometry via machine learning and also a visualization of trained networks.","sentences":["We find that simple neural networks with ReLU activation generate polytopes as an approximation of a unit sphere in various dimensions.","The species of polytopes are regulated by the network architecture, such as the number of units and layers.","For a variety of activation functions, generalization of polytopes is obtained, which we call neural polytopes.","They are a smooth analogue of polytopes, exhibiting geometric duality.","This finding initiates research of discrete geometry via machine learning and also a visualization of trained networks."],"url":"http://arxiv.org/abs/2307.00721v1"}
{"created":"2023-07-03 02:59:44","title":"Evaluation and Control Model Design of Human Factors for Autonomous Driving Systems","abstract":"With the fast development of driving automation technologies, user psychological acceptance of driving automation has become one of the major obstacles to the adoption of the driving automation technology. The most basic function of a passenger car is to transport passengers or drivers to their destinations safely and comfortably. Thus, the design of the driving automation should not just guarantee the safety of vehicle operation but also ensure occupant subjective level of comfort. Hence this paper proposes a local path planning algorithm for obstacle avoidance with occupant subjective feelings considered. Firstly, turning and obstacle avoidance conditions are designed, and four classifiers in machine learning are used to respectively establish subjective and objective evaluation models that link the objective vehicle dynamics parameters and occupant subjective confidence. Then, two potential fields are established based on the artificial potential field, reflecting the psychological feeling of drivers on obstacles and road boundaries. Accordingly, a path planning algorithm and a path tracking algorithm are designed respectively based on model predictive control, and the psychological safety boundary and the optimal classifier are used as part of cost functions. Finally, co-simulations of MATLAB/Simulink and CarSim are carried out. The results confirm the effectiveness of the proposed control algorithm, which can avoid obstacles satisfactorily and improve the psychological feeling of occupants effectively.","sentences":["With the fast development of driving automation technologies, user psychological acceptance of driving automation has become one of the major obstacles to the adoption of the driving automation technology.","The most basic function of a passenger car is to transport passengers or drivers to their destinations safely and comfortably.","Thus, the design of the driving automation should not just guarantee the safety of vehicle operation but also ensure occupant subjective level of comfort.","Hence this paper proposes a local path planning algorithm for obstacle avoidance with occupant subjective feelings considered.","Firstly, turning and obstacle avoidance conditions are designed, and four classifiers in machine learning are used to respectively establish subjective and objective evaluation models that link the objective vehicle dynamics parameters and occupant subjective confidence.","Then, two potential fields are established based on the artificial potential field, reflecting the psychological feeling of drivers on obstacles and road boundaries.","Accordingly, a path planning algorithm and a path tracking algorithm are designed respectively based on model predictive control, and the psychological safety boundary and the optimal classifier are used as part of cost functions.","Finally, co-simulations of MATLAB/Simulink and CarSim are carried out.","The results confirm the effectiveness of the proposed control algorithm, which can avoid obstacles satisfactorily and improve the psychological feeling of occupants effectively."],"url":"http://arxiv.org/abs/2307.00720v1"}
{"created":"2023-07-03 02:42:14","title":"SSC3OD: Sparsely Supervised Collaborative 3D Object Detection from LiDAR Point Clouds","abstract":"Collaborative 3D object detection, with its improved interaction advantage among multiple agents, has been widely explored in autonomous driving. However, existing collaborative 3D object detectors in a fully supervised paradigm heavily rely on large-scale annotated 3D bounding boxes, which is labor-intensive and time-consuming. To tackle this issue, we propose a sparsely supervised collaborative 3D object detection framework SSC3OD, which only requires each agent to randomly label one object in the scene. Specifically, this model consists of two novel components, i.e., the pillar-based masked autoencoder (Pillar-MAE) and the instance mining module. The Pillar-MAE module aims to reason over high-level semantics in a self-supervised manner, and the instance mining module generates high-quality pseudo labels for collaborative detectors online. By introducing these simple yet effective mechanisms, the proposed SSC3OD can alleviate the adverse impacts of incomplete annotations. We generate sparse labels based on collaborative perception datasets to evaluate our method. Extensive experiments on three large-scale datasets reveal that our proposed SSC3OD can effectively improve the performance of sparsely supervised collaborative 3D object detectors.","sentences":["Collaborative 3D object detection, with its improved interaction advantage among multiple agents, has been widely explored in autonomous driving.","However, existing collaborative 3D object detectors in a fully supervised paradigm heavily rely on large-scale annotated 3D bounding boxes, which is labor-intensive and time-consuming.","To tackle this issue, we propose a sparsely supervised collaborative 3D object detection framework SSC3OD, which only requires each agent to randomly label one object in the scene.","Specifically, this model consists of two novel components, i.e., the pillar-based masked autoencoder (Pillar-MAE) and the instance mining module.","The Pillar-MAE module aims to reason over high-level semantics in a self-supervised manner, and the instance mining module generates high-quality pseudo labels for collaborative detectors online.","By introducing these simple yet effective mechanisms, the proposed SSC3OD can alleviate the adverse impacts of incomplete annotations.","We generate sparse labels based on collaborative perception datasets to evaluate our method.","Extensive experiments on three large-scale datasets reveal that our proposed SSC3OD can effectively improve the performance of sparsely supervised collaborative 3D object detectors."],"url":"http://arxiv.org/abs/2307.00717v1"}
{"created":"2023-07-03 02:39:08","title":"JourneyDB: A Benchmark for Generative Image Understanding","abstract":"While recent advancements in vision-language models have revolutionized multi-modal understanding, it remains unclear whether they possess the capabilities of comprehending the generated images. Compared to real data, synthetic images exhibit a higher degree of diversity in both content and style, for which there are significant difficulties for the models to fully apprehend. To this end, we present a large-scale dataset, JourneyDB, for multi-modal visual understanding in generative images. Our curated dataset covers 4 million diverse and high-quality generated images paired with the text prompts used to produce them. We further design 4 benchmarks to quantify the performance of generated image understanding in terms of both content and style interpretation. These benchmarks include prompt inversion, style retrieval, image captioning and visual question answering. Lastly, we assess the performance of current state-of-the-art multi-modal models when applied to JourneyDB, and provide an in-depth analysis of their strengths and limitations in generated content understanding. We hope the proposed dataset and benchmarks will facilitate the research in the field of generative content understanding. The dataset will be available on https://journeydb.github.io.","sentences":["While recent advancements in vision-language models have revolutionized multi-modal understanding, it remains unclear whether they possess the capabilities of comprehending the generated images.","Compared to real data, synthetic images exhibit a higher degree of diversity in both content and style, for which there are significant difficulties for the models to fully apprehend.","To this end, we present a large-scale dataset, JourneyDB, for multi-modal visual understanding in generative images.","Our curated dataset covers 4 million diverse and high-quality generated images paired with the text prompts used to produce them.","We further design 4 benchmarks to quantify the performance of generated image understanding in terms of both content and style interpretation.","These benchmarks include prompt inversion, style retrieval, image captioning and visual question answering.","Lastly, we assess the performance of current state-of-the-art multi-modal models when applied to JourneyDB, and provide an in-depth analysis of their strengths and limitations in generated content understanding.","We hope the proposed dataset and benchmarks will facilitate the research in the field of generative content understanding.","The dataset will be available on https://journeydb.github.io."],"url":"http://arxiv.org/abs/2307.00716v1"}
{"created":"2023-07-03 02:32:09","title":"A Comparative Study of Software Secrets Reporting by Secret Detection Tools","abstract":"Background: According to GitGuardian's monitoring of public GitHub repositories, secrets sprawl continued accelerating in 2022 by 67% compared to 2021, exposing over 10 million secrets (API keys and other credentials). Though many open-source and proprietary secret detection tools are available, these tools output many false positives, making it difficult for developers to take action and teams to choose one tool out of many. To our knowledge, the secret detection tools are not yet compared and evaluated. Aims: The goal of our study is to aid developers in choosing a secret detection tool to reduce the exposure of secrets through an empirical investigation of existing secret detection tools. Method: We present an evaluation of five open-source and four proprietary tools against a benchmark dataset. Results: The top three tools based on precision are: GitHub Secret Scanner (75%), Gitleaks (46%), and Commercial X (25%), and based on recall are: Gitleaks (88%), SpectralOps (67%) and TruffleHog (52%). Our manual analysis of reported secrets reveals that false positives are due to employing generic regular expressions and ineffective entropy calculation. In contrast, false negatives are due to faulty regular expressions, skipping specific file types, and insufficient rulesets. Conclusions: We recommend developers choose tools based on secret types present in their projects to prevent missing secrets. In addition, we recommend tool vendors update detection rules periodically and correctly employ secret verification mechanisms by collaborating with API vendors to improve accuracy.","sentences":["Background:","According to GitGuardian's monitoring of public GitHub repositories, secrets sprawl continued accelerating in 2022 by 67% compared to 2021, exposing over 10 million secrets (API keys and other credentials).","Though many open-source and proprietary secret detection tools are available, these tools output many false positives, making it difficult for developers to take action and teams to choose one tool out of many.","To our knowledge, the secret detection tools are not yet compared and evaluated.","Aims:","The goal of our study is to aid developers in choosing a secret detection tool to reduce the exposure of secrets through an empirical investigation of existing secret detection tools.","Method: We present an evaluation of five open-source and four proprietary tools against a benchmark dataset.","Results:","The top three tools based on precision are: GitHub Secret Scanner (75%), Gitleaks (46%), and Commercial X (25%), and based on recall are: Gitleaks (88%), SpectralOps (67%) and TruffleHog (52%).","Our manual analysis of reported secrets reveals that false positives are due to employing generic regular expressions and ineffective entropy calculation.","In contrast, false negatives are due to faulty regular expressions, skipping specific file types, and insufficient rulesets.","Conclusions: We recommend developers choose tools based on secret types present in their projects to prevent missing secrets.","In addition, we recommend tool vendors update detection rules periodically and correctly employ secret verification mechanisms by collaborating with API vendors to improve accuracy."],"url":"http://arxiv.org/abs/2307.00714v1"}
{"created":"2023-07-03 02:31:29","title":"Designing a Magnetic Micro-Robot for Transporting Filamentous Microcargo","abstract":"In recent years, the medical industry has witnessed a growing interest in minimally invasive procedures, with magnetic microrobots emerging as a promising approach. These micro-robots possess the ability to navigate through various media, including viscoelastic and non-Newtonian fluids, enabling targeted drug delivery and medical interventions. Many current designs, inspired by micro-swimmers in biological systems like bacteria and sperm, employ a contact-based method for transporting a payload. Adhesion between the cargo and the carrier can make release at the target site problematic. In this project, our primary objective was to explore the potential of a helical micro-robot for non-contact drug or cargo delivery. We conducted a comprehensive study on the shape and geometrical parameters of the helical microrobot, specifically focusing on its capability to transport passive filaments. Based on our analysis, we propose a novel design consisting of three sections with alternating handedness, including two pulling and one pushing microhelices, to enhance the capture and transport of passive filaments in Newtonian fluids using a non-contact approach. We then simulated the process of capturing and transporting the passive filament, and tested the functionality of the newly designed micro-robot. Our findings offer valuable insights into the physics of helical micro-robots and their potential for medical procedures and drug delivery. Furthermore, the proposed non-contact method for delivering filamentous cargo could lead to the development of more efficient and effective microrobots for medical applications.","sentences":["In recent years, the medical industry has witnessed a growing interest in minimally invasive procedures, with magnetic microrobots emerging as a promising approach.","These micro-robots possess the ability to navigate through various media, including viscoelastic and non-Newtonian fluids, enabling targeted drug delivery and medical interventions.","Many current designs, inspired by micro-swimmers in biological systems like bacteria and sperm, employ a contact-based method for transporting a payload.","Adhesion between the cargo and the carrier can make release at the target site problematic.","In this project, our primary objective was to explore the potential of a helical micro-robot for non-contact drug or cargo delivery.","We conducted a comprehensive study on the shape and geometrical parameters of the helical microrobot, specifically focusing on its capability to transport passive filaments.","Based on our analysis, we propose a novel design consisting of three sections with alternating handedness, including two pulling and one pushing microhelices, to enhance the capture and transport of passive filaments in Newtonian fluids using a non-contact approach.","We then simulated the process of capturing and transporting the passive filament, and tested the functionality of the newly designed micro-robot.","Our findings offer valuable insights into the physics of helical micro-robots and their potential for medical procedures and drug delivery.","Furthermore, the proposed non-contact method for delivering filamentous cargo could lead to the development of more efficient and effective microrobots for medical applications."],"url":"http://arxiv.org/abs/2307.00713v1"}
{"created":"2023-07-03 02:25:19","title":"Worth of knowledge in deep learning","abstract":"Knowledge constitutes the accumulated understanding and experience that humans use to gain insight into the world. In deep learning, prior knowledge is essential for mitigating shortcomings of data-driven models, such as data dependence, generalization ability, and compliance with constraints. To enable efficient evaluation of the worth of knowledge, we present a framework inspired by interpretable machine learning. Through quantitative experiments, we assess the influence of data volume and estimation range on the worth of knowledge. Our findings elucidate the complex relationship between data and knowledge, including dependence, synergistic, and substitution effects. Our model-agnostic framework can be applied to a variety of common network architectures, providing a comprehensive understanding of the role of prior knowledge in deep learning models. It can also be used to improve the performance of informed machine learning, as well as distinguish improper prior knowledge.","sentences":["Knowledge constitutes the accumulated understanding and experience that humans use to gain insight into the world.","In deep learning, prior knowledge is essential for mitigating shortcomings of data-driven models, such as data dependence, generalization ability, and compliance with constraints.","To enable efficient evaluation of the worth of knowledge, we present a framework inspired by interpretable machine learning.","Through quantitative experiments, we assess the influence of data volume and estimation range on the worth of knowledge.","Our findings elucidate the complex relationship between data and knowledge, including dependence, synergistic, and substitution effects.","Our model-agnostic framework can be applied to a variety of common network architectures, providing a comprehensive understanding of the role of prior knowledge in deep learning models.","It can also be used to improve the performance of informed machine learning, as well as distinguish improper prior knowledge."],"url":"http://arxiv.org/abs/2307.00712v1"}
{"created":"2023-07-03 02:19:48","title":"Guided Patch-Grouping Wavelet Transformer with Spatial Congruence for Ultra-High Resolution Segmentation","abstract":"Most existing ultra-high resolution (UHR) segmentation methods always struggle in the dilemma of balancing memory cost and local characterization accuracy, which are both taken into account in our proposed Guided Patch-Grouping Wavelet Transformer (GPWFormer) that achieves impressive performances. In this work, GPWFormer is a Transformer ($\\mathcal{T}$)-CNN ($\\mathcal{C}$) mutual leaning framework, where $\\mathcal{T}$ takes the whole UHR image as input and harvests both local details and fine-grained long-range contextual dependencies, while $\\mathcal{C}$ takes downsampled image as input for learning the category-wise deep context. For the sake of high inference speed and low computation complexity, $\\mathcal{T}$ partitions the original UHR image into patches and groups them dynamically, then learns the low-level local details with the lightweight multi-head Wavelet Transformer (WFormer) network. Meanwhile, the fine-grained long-range contextual dependencies are also captured during this process, since patches that are far away in the spatial domain can also be assigned to the same group. In addition, masks produced by $\\mathcal{C}$ are utilized to guide the patch grouping process, providing a heuristics decision. Moreover, the congruence constraints between the two branches are also exploited to maintain the spatial consistency among the patches. Overall, we stack the multi-stage process in a pyramid way. Experiments show that GPWFormer outperforms the existing methods with significant improvements on five benchmark datasets.","sentences":["Most existing ultra-high resolution (UHR) segmentation methods always struggle in the dilemma of balancing memory cost and local characterization accuracy, which are both taken into account in our proposed Guided Patch-Grouping Wavelet Transformer (GPWFormer) that achieves impressive performances.","In this work, GPWFormer is a Transformer ($\\mathcal{T}$)-CNN ($\\mathcal{C}$) mutual leaning framework, where $\\mathcal{T}$ takes the whole UHR image as input and harvests both local details and fine-grained long-range contextual dependencies, while $\\mathcal{C}$ takes downsampled image as input for learning the category-wise deep context.","For the sake of high inference speed and low computation complexity, $\\mathcal{T}$ partitions the original UHR image into patches and groups them dynamically, then learns the low-level local details with the lightweight multi-head Wavelet Transformer (WFormer) network.","Meanwhile, the fine-grained long-range contextual dependencies are also captured during this process, since patches that are far away in the spatial domain can also be assigned to the same group.","In addition, masks produced by $\\mathcal{C}$ are utilized to guide the patch grouping process, providing a heuristics decision.","Moreover, the congruence constraints between the two branches are also exploited to maintain the spatial consistency among the patches.","Overall, we stack the multi-stage process in a pyramid way.","Experiments show that GPWFormer outperforms the existing methods with significant improvements on five benchmark datasets."],"url":"http://arxiv.org/abs/2307.00711v1"}
