{"created":"2023-07-18 17:59:25","title":"Forecasting the steam mass flow in a powerplant using the parallel hybrid network","abstract":"Efficient and sustainable power generation is a crucial concern in the energy sector. In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction. In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future. Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error (MSE) loss on the test set after training compared to pure classical and pure quantum networks, respectively. Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model. These findings contribute to the broader scientific understanding of how integrating quantum and classical machine learning techniques can be applied to real-world challenges faced by the energy sector, ultimately leading to optimized power plant operations.","sentences":["Efficient and sustainable power generation is a crucial concern in the energy sector.","In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction.","In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future.","Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error (MSE) loss on the test set after training compared to pure classical and pure quantum networks, respectively.","Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model.","These findings contribute to the broader scientific understanding of how integrating quantum and classical machine learning techniques can be applied to real-world challenges faced by the energy sector, ultimately leading to optimized power plant operations."],"url":"http://arxiv.org/abs/2307.09483v1"}
{"created":"2023-07-18 17:59:02","title":"AnyDoor: Zero-shot Object-level Image Customization","abstract":"This work presents AnyDoor, a diffusion-based image generator with the power to teleport target objects to new scenes at user-specified locations in a harmonious way. Instead of tuning parameters for each object, our model is trained only once and effortlessly generalizes to diverse object-scene combinations at the inference stage. Such a challenging zero-shot setting requires an adequate characterization of a certain object. To this end, we complement the commonly used identity feature with detail features, which are carefully designed to maintain texture details yet allow versatile local variations (e.g., lighting, orientation, posture, etc.), supporting the object in favorably blending with different surroundings. We further propose to borrow knowledge from video datasets, where we can observe various forms (i.e., along the time axis) of a single object, leading to stronger model generalizability and robustness. Extensive experiments demonstrate the superiority of our approach over existing alternatives as well as its great potential in real-world applications, such as virtual try-on and object moving. Project page is https://damo-vilab.github.io/AnyDoor-Page/.","sentences":["This work presents AnyDoor, a diffusion-based image generator with the power to teleport target objects to new scenes at user-specified locations in a harmonious way.","Instead of tuning parameters for each object, our model is trained only once and effortlessly generalizes to diverse object-scene combinations at the inference stage.","Such a challenging zero-shot setting requires an adequate characterization of a certain object.","To this end, we complement the commonly used identity feature with detail features, which are carefully designed to maintain texture details yet allow versatile local variations (e.g., lighting, orientation, posture, etc.), supporting the object in favorably blending with different surroundings.","We further propose to borrow knowledge from video datasets, where we can observe various forms (i.e., along the time axis) of a single object, leading to stronger model generalizability and robustness.","Extensive experiments demonstrate the superiority of our approach over existing alternatives as well as its great potential in real-world applications, such as virtual try-on and object moving.","Project page is https://damo-vilab.github.io/AnyDoor-Page/."],"url":"http://arxiv.org/abs/2307.09481v1"}
{"created":"2023-07-18 17:58:22","title":"FACTS: Facial Animation Creation using the Transfer of Styles","abstract":"The ability to accurately capture and express emotions is a critical aspect of creating believable characters in video games and other forms of entertainment. Traditionally, this animation has been achieved with artistic effort or performance capture, both requiring costs in time and labor. More recently, audio-driven models have seen success, however, these often lack expressiveness in areas not correlated to the audio signal. In this paper, we present a novel approach to facial animation by taking existing animations and allowing for the modification of style characteristics. Specifically, we explore the use of a StarGAN to enable the conversion of 3D facial animations into different emotions and person-specific styles. We are able to maintain the lip-sync of the animations with this method thanks to the use of a novel viseme-preserving loss.","sentences":["The ability to accurately capture and express emotions is a critical aspect of creating believable characters in video games and other forms of entertainment.","Traditionally, this animation has been achieved with artistic effort or performance capture, both requiring costs in time and labor.","More recently, audio-driven models have seen success, however, these often lack expressiveness in areas not correlated to the audio signal.","In this paper, we present a novel approach to facial animation by taking existing animations and allowing for the modification of style characteristics.","Specifically, we explore the use of a StarGAN to enable the conversion of 3D facial animations into different emotions and person-specific styles.","We are able to maintain the lip-sync of the animations with this method thanks to the use of a novel viseme-preserving loss."],"url":"http://arxiv.org/abs/2307.09480v1"}
{"created":"2023-07-18 17:56:50","title":"Overthinking the Truth: Understanding how Language Models Process False Demonstrations","abstract":"Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \"critical layer\", after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking. Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors.","sentences":["Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning.","However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context.","We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: overthinking and false induction heads.","The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations.","At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \"critical layer\", after which the accuracy given incorrect demonstrations progressively decreases.","The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking.","Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors."],"url":"http://arxiv.org/abs/2307.09476v1"}
{"created":"2023-07-18 17:56:06","title":"ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning","abstract":"Human-AI interactivity is a critical aspect that reflects the usability of multimodal large language models (MLLMs). However, existing end-to-end MLLMs only allow users to interact with them through language instructions, leading to the limitation of the interactive accuracy and efficiency. In this study, we present precise referring instructions that utilize diverse reference representations such as points and boxes as referring prompts to refer to the special region. This enables MLLMs to focus on the region of interest and achieve finer-grained interaction. Based on precise referring instruction, we propose ChatSpot, a unified end-to-end multimodal large language model that supports diverse forms of interactivity including mouse clicks, drag-and-drop, and drawing boxes, which provides a more flexible and seamless interactive experience. We also construct a multi-grained vision-language instruction-following dataset based on existing datasets and GPT-4 generating. Furthermore, we design a series of evaluation tasks to assess the effectiveness of region recognition and interaction. Experimental results showcase ChatSpot's promising performance.","sentences":["Human-AI interactivity is a critical aspect that reflects the usability of multimodal large language models (MLLMs).","However, existing end-to-end MLLMs only allow users to interact with them through language instructions, leading to the limitation of the interactive accuracy and efficiency.","In this study, we present precise referring instructions that utilize diverse reference representations such as points and boxes as referring prompts to refer to the special region.","This enables MLLMs to focus on the region of interest and achieve finer-grained interaction.","Based on precise referring instruction, we propose ChatSpot, a unified end-to-end multimodal large language model that supports diverse forms of interactivity including mouse clicks, drag-and-drop, and drawing boxes, which provides a more flexible and seamless interactive experience.","We also construct a multi-grained vision-language instruction-following dataset based on existing datasets and GPT-4 generating.","Furthermore, we design a series of evaluation tasks to assess the effectiveness of region recognition and interaction.","Experimental results showcase ChatSpot's promising performance."],"url":"http://arxiv.org/abs/2307.09474v1"}
{"created":"2023-07-18 17:55:29","title":"GroupLane: End-to-End 3D Lane Detection with Channel-wise Grouping","abstract":"Efficiency is quite important for 3D lane detection due to practical deployment demand. In this work, we propose a simple, fast, and end-to-end detector that still maintains high detection precision. Specifically, we devise a set of fully convolutional heads based on row-wise classification. In contrast to previous counterparts, ours supports recognizing both vertical and horizontal lanes. Besides, our method is the first one to perform row-wise classification in bird-eye-view. In the heads, we split feature into multiple groups and every group of feature corresponds to a lane instance. During training, the predictions are associated with lane labels using the proposed single-win one-to-one matching to compute loss, and no post-processing operation is demanded for inference. In this way, our proposed fully convolutional detector, GroupLane, realizes end-to-end detection like DETR. Evaluated on 3 real world 3D lane benchmarks, OpenLane, Once-3DLanes, and OpenLane-Huawei, GroupLane adopting ConvNext-Base as the backbone outperforms the published state-of-the-art PersFormer by 13.6% F1 score in the OpenLane validation set. Besides, GroupLane with ResNet18 still surpasses PersFormer by 4.9% F1 score, while the inference speed is nearly 7x faster and the FLOPs is only 13.3% of it.","sentences":["Efficiency is quite important for 3D lane detection due to practical deployment demand.","In this work, we propose a simple, fast, and end-to-end detector that still maintains high detection precision.","Specifically, we devise a set of fully convolutional heads based on row-wise classification.","In contrast to previous counterparts, ours supports recognizing both vertical and horizontal lanes.","Besides, our method is the first one to perform row-wise classification in bird-eye-view.","In the heads, we split feature into multiple groups and every group of feature corresponds to a lane instance.","During training, the predictions are associated with lane labels using the proposed single-win one-to-one matching to compute loss, and no post-processing operation is demanded for inference.","In this way, our proposed fully convolutional detector, GroupLane, realizes end-to-end detection like DETR.","Evaluated on 3 real world 3D lane benchmarks, OpenLane, Once-3DLanes, and OpenLane-Huawei, GroupLane adopting ConvNext-Base as the backbone outperforms the published state-of-the-art PersFormer by 13.6% F1 score in the OpenLane validation set.","Besides, GroupLane with ResNet18 still surpasses PersFormer by 4.9% F1 score, while the inference speed is nearly 7x faster and the FLOPs is only 13.3% of it."],"url":"http://arxiv.org/abs/2307.09472v1"}
{"created":"2023-07-18 17:47:47","title":"Optimal Vehicle Trajectory Planning for Static Obstacle Avoidance using Nonlinear Optimization","abstract":"Vehicle trajectory planning is a key component for an autonomous driving system. A practical system not only requires the component to compute a feasible trajectory, but also a comfortable one given certain comfort metrics. Nevertheless, computation efficiency is critical for the system to be deployed as a commercial product. In this paper, we present a novel trajectory planning algorithm based on nonlinear optimization. The algorithm computes a kinematically feasible and comfort-optimal trajectory that achieves collision avoidance with static obstacles. Furthermore, the algorithm is time efficient. It generates an 6-second trajectory within 10 milliseconds on an Intel i7 machine or 20 milliseconds on an Nvidia Drive Orin platform.","sentences":["Vehicle trajectory planning is a key component for an autonomous driving system.","A practical system not only requires the component to compute a feasible trajectory, but also a comfortable one given certain comfort metrics.","Nevertheless, computation efficiency is critical for the system to be deployed as a commercial product.","In this paper, we present a novel trajectory planning algorithm based on nonlinear optimization.","The algorithm computes a kinematically feasible and comfort-optimal trajectory that achieves collision avoidance with static obstacles.","Furthermore, the algorithm is time efficient.","It generates an 6-second trajectory within 10 milliseconds on an Intel i7 machine or 20 milliseconds on an Nvidia Drive Orin platform."],"url":"http://arxiv.org/abs/2307.09466v1"}
{"created":"2023-07-18 17:47:24","title":"Occlusion Aware Student Emotion Recognition based on Facial Action Unit Detection","abstract":"Given that approximately half of science, technology, engineering, and mathematics (STEM) undergraduate students in U.S. colleges and universities leave by the end of the first year [15], it is crucial to improve the quality of classroom environments. This study focuses on monitoring students' emotions in the classroom as an indicator of their engagement and proposes an approach to address this issue. The impact of different facial parts on the performance of an emotional recognition model is evaluated through experimentation. To test the proposed model under partial occlusion, an artificially occluded dataset is introduced. The novelty of this work lies in the proposal of an occlusion-aware architecture for facial action units (AUs) extraction, which employs attention mechanism and adaptive feature learning. The AUs can be used later to classify facial expressions in classroom settings.   This research paper's findings provide valuable insights into handling occlusion in analyzing facial images for emotional engagement analysis. The proposed experiments demonstrate the significance of considering occlusion and enhancing the reliability of facial analysis models in classroom environments. These findings can also be extended to other settings where occlusions are prevalent.","sentences":["Given that approximately half of science, technology, engineering, and mathematics (STEM) undergraduate students in U.S. colleges and universities leave by the end of the first year","[15], it is crucial to improve the quality of classroom environments.","This study focuses on monitoring students' emotions in the classroom as an indicator of their engagement and proposes an approach to address this issue.","The impact of different facial parts on the performance of an emotional recognition model is evaluated through experimentation.","To test the proposed model under partial occlusion, an artificially occluded dataset is introduced.","The novelty of this work lies in the proposal of an occlusion-aware architecture for facial action units (AUs) extraction, which employs attention mechanism and adaptive feature learning.","The AUs can be used later to classify facial expressions in classroom settings.   ","This research paper's findings provide valuable insights into handling occlusion in analyzing facial images for emotional engagement analysis.","The proposed experiments demonstrate the significance of considering occlusion and enhancing the reliability of facial analysis models in classroom environments.","These findings can also be extended to other settings where occlusions are prevalent."],"url":"http://arxiv.org/abs/2307.09465v1"}
{"created":"2023-07-18 17:39:04","title":"Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla","abstract":"\\emph{Circuit analysis} is a promising technique for understanding the internal mechanisms of language models. However, existing analyses are done in small models far from the state of the art. To address this, we present a case study of circuit analysis in the 70B Chinchilla model, aiming to test the scalability of circuit analysis. In particular, we study multiple-choice question answering, and investigate Chinchilla's capability to identify the correct answer \\emph{label} given knowledge of the correct answer \\emph{text}. We find that the existing techniques of logit attribution, attention pattern visualization, and activation patching naturally scale to Chinchilla, allowing us to identify and categorize a small set of `output nodes' (attention heads and MLPs).   We further study the `correct letter' category of attention heads aiming to understand the semantics of their features, with mixed results. For normal multiple-choice question answers, we significantly compress the query, key and value subspaces of the head without loss of performance when operating on the answer labels for multiple-choice questions, and we show that the query and key subspaces represent an `Nth item in an enumeration' feature to at least some extent. However, when we attempt to use this explanation to understand the heads' behaviour on a more general distribution including randomized answer labels, we find that it is only a partial explanation, suggesting there is more to learn about the operation of `correct letter' heads on multiple choice question answering.","sentences":["\\emph{Circuit analysis} is a promising technique for understanding the internal mechanisms of language models.","However, existing analyses are done in small models far from the state of the art.","To address this, we present a case study of circuit analysis in the 70B Chinchilla model, aiming to test the scalability of circuit analysis.","In particular, we study multiple-choice question answering, and investigate Chinchilla's capability to identify the correct answer \\emph{label} given knowledge of the correct answer \\emph{text}.","We find that the existing techniques of logit attribution, attention pattern visualization, and activation patching naturally scale to Chinchilla, allowing us to identify and categorize a small set of `output nodes' (attention heads and MLPs).   ","We further study the `correct letter' category of attention heads aiming to understand the semantics of their features, with mixed results.","For normal multiple-choice question answers, we significantly compress the query, key and value subspaces of the head without loss of performance when operating on the answer labels for multiple-choice questions, and we show that the query and key subspaces represent an `Nth item in an enumeration' feature to at least some extent.","However, when we attempt to use this explanation to understand the heads' behaviour on a more general distribution including randomized answer labels, we find that it is only a partial explanation, suggesting there is more to learn about the operation of `correct letter' heads on multiple choice question answering."],"url":"http://arxiv.org/abs/2307.09458v1"}
{"created":"2023-07-18 17:35:45","title":"A comparative analysis of SR-GAN models","abstract":"In this study, we evaluate the performance of multiple state-of-the-art SR GAN (Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN and EDSR, on a benchmark dataset of real-world images which undergo degradation using a pipeline. Our results show that some models seem to significantly increase the resolution of the input images while preserving their visual quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE model from huggingface outperforms the remaining candidate models in terms of both quantitative metrics and subjective visual quality assessments with least compute overhead. Specifically, EDSR generates images with higher peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and are seen to return high quality OCR results with Tesseract OCR engine. These findings suggest that EDSR is a robust and effective approach for single-image super-resolution and may be particularly well-suited for applications where high-quality visual fidelity is critical and optimized compute.","sentences":["In this study, we evaluate the performance of multiple state-of-the-art SR GAN (Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN and EDSR, on a benchmark dataset of real-world images which undergo degradation using a pipeline.","Our results show that some models seem to significantly increase the resolution of the input images while preserving their visual quality, this is assessed using Tesseract OCR engine.","We observe that EDSR-BASE model from huggingface outperforms the remaining candidate models in terms of both quantitative metrics and subjective visual quality assessments with least compute overhead.","Specifically, EDSR generates images with higher peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and are seen to return high quality OCR results with Tesseract OCR engine.","These findings suggest that EDSR is a robust and effective approach for single-image super-resolution and may be particularly well-suited for applications where high-quality visual fidelity is critical and optimized compute."],"url":"http://arxiv.org/abs/2307.09456v1"}
{"created":"2023-07-18 17:29:23","title":"Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers","abstract":"For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold. A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers. A comprehensive comparison with state-of-the-art algorithms demonstrates POE's competitiveness on several text classification benchmarks.","sentences":["For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples.","However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples.","In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold.","A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection.","In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes.","The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network.","Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers.","A comprehensive comparison with state-of-the-art algorithms demonstrates POE's competitiveness on several text classification benchmarks."],"url":"http://arxiv.org/abs/2307.09455v2"}
{"created":"2023-07-18 17:28:45","title":"Solving Knapsack with Small Items via L0-Proximity","abstract":"We study pseudo-polynomial time algorithms for the fundamental \\emph{0-1 Knapsack} problem. In terms of $n$ and $w_{\\max}$, previous algorithms for 0-1 Knapsack have cubic time complexities: $O(n^2w_{\\max})$ (Bellman 1957), $O(nw_{\\max}^2)$ (Kellerer and Pferschy 2004), and $O(n + w_{\\max}^3)$ (Polak, Rohwedder, and W\\k{e}grzycki 2021). On the other hand, fine-grained complexity only rules out $O((n+w_{\\max})^{2-\\delta})$ running time, and it is an important question in this area whether $\\tilde O(n+w_{\\max}^2)$ time is achievable. Our main result makes significant progress towards solving this question:   - The 0-1 Knapsack problem has a deterministic algorithm in $\\tilde O(n + w_{\\max}^{2.5})$ time.   Our techniques also apply to the easier \\emph{Subset Sum} problem:   - The Subset Sum problem has a randomized algorithm in $\\tilde O(n + w_{\\max}^{1.5})$ time.   This improves (and simplifies) the previous $\\tilde O(n + w_{\\max}^{5/3})$-time algorithm by Polak, Rohwedder, and W\\k{e}grzycki (2021) (based on Galil and Margalit (1991), and Bringmann and Wellnitz (2021)).   Similar to recent works on Knapsack (and integer programs in general), our algorithms also utilize the \\emph{proximity} between optimal integral solutions and fractional solutions. Our new ideas are as follows: - Previous works used an $O(w_{\\max})$ proximity bound in the $\\ell_1$-norm. As our main conceptual contribution, we use an additive-combinatorial theorem by Erd\\H{o}s and S\\'{a}rk\\\"{o}zy (1990) to derive an $\\ell_0$-proximity bound of $\\tilde O(\\sqrt{w_{\\max}})$. - Then, the main technical component of our Knapsack result is a dynamic programming algorithm that exploits both $\\ell_0$- and $\\ell_1$-proximity. It is based on a vast extension of the ``witness propagation'' method, originally designed by Deng, Mao, and Zhong (2023) for the easier \\emph{unbounded} setting only.","sentences":["We study pseudo-polynomial time algorithms for the fundamental \\emph{0-1 Knapsack} problem.","In terms of $n$ and $w_{\\max}$, previous algorithms for 0-1 Knapsack have cubic time complexities: $O(n^2w_{\\max})$ (Bellman 1957), $O(nw_{\\max}^2)$ (Kellerer and Pferschy 2004), and $O(n + w_{\\max}^3)$ (Polak, Rohwedder, and W\\k{e}grzycki 2021).","On the other hand, fine-grained complexity only rules out $O((n+w_{\\max})^{2-\\delta})$ running time, and it is an important question in this area whether $\\tilde O(n+w_{\\max}^2)$ time is achievable.","Our main result makes significant progress towards solving this question:   - The 0-1 Knapsack problem has a deterministic algorithm in $\\tilde O(n + w_{\\max}^{2.5})$ time.   ","Our techniques also apply to the easier \\emph{Subset Sum} problem:   - The Subset Sum problem has a randomized algorithm in $\\tilde O(n","+ w_{\\max}^{1.5})$ time.   ","This improves (and simplifies) the previous $\\tilde O(n + w_{\\max}^{5/3})$-time algorithm by Polak, Rohwedder, and W\\k{e}grzycki (2021) (based on Galil and Margalit (1991), and Bringmann and Wellnitz (2021)).   ","Similar to recent works on Knapsack (and integer programs in general), our algorithms also utilize the \\emph{proximity} between optimal integral solutions and fractional solutions.","Our new ideas are as follows: - Previous works used an $O(w_{\\max})$ proximity bound in the $\\ell_1$-norm.","As our main conceptual contribution, we use an additive-combinatorial theorem by Erd\\H{o}s and S\\'{a}rk\\\"{o}zy (1990) to derive an $\\ell_0$-proximity bound of $\\tilde O(\\sqrt{w_{\\max}})$. - Then, the main technical component of our Knapsack result is a dynamic programming algorithm that exploits both $\\ell_0$- and $\\ell_1$-proximity.","It is based on a vast extension of the ``witness propagation'' method, originally designed by Deng, Mao, and Zhong (2023) for the easier \\emph{unbounded} setting only."],"url":"http://arxiv.org/abs/2307.09454v1"}
{"created":"2023-07-18 17:22:19","title":"Deep Neural Aggregation for Recommending Items to Group of Users","abstract":"Modern society devotes a significant amount of time to digital interaction. Many of our daily actions are carried out through digital means. This has led to the emergence of numerous Artificial Intelligence tools that assist us in various aspects of our lives. One key tool for the digital society is Recommender Systems, intelligent systems that learn from our past actions to propose new ones that align with our interests. Some of these systems have specialized in learning from the behavior of user groups to make recommendations to a group of individuals who want to perform a joint task. In this article, we analyze the current state of Group Recommender Systems and propose two new models that use emerging Deep Learning architectures. Experimental results demonstrate the improvement achieved by employing the proposed models compared to the state-of-the-art models using four different datasets. The source code of the models, as well as that of all the experiments conducted, is available in a public repository.","sentences":["Modern society devotes a significant amount of time to digital interaction.","Many of our daily actions are carried out through digital means.","This has led to the emergence of numerous Artificial Intelligence tools that assist us in various aspects of our lives.","One key tool for the digital society is Recommender Systems, intelligent systems that learn from our past actions to propose new ones that align with our interests.","Some of these systems have specialized in learning from the behavior of user groups to make recommendations to a group of individuals who want to perform a joint task.","In this article, we analyze the current state of Group Recommender Systems and propose two new models that use emerging Deep Learning architectures.","Experimental results demonstrate the improvement achieved by employing the proposed models compared to the state-of-the-art models using four different datasets.","The source code of the models, as well as that of all the experiments conducted, is available in a public repository."],"url":"http://arxiv.org/abs/2307.09447v1"}
{"created":"2023-07-18 17:17:27","title":"No distributed quantum advantage for approximate graph coloring","abstract":"We give an almost complete characterization of the hardness of $c$-coloring $\\chi$-chromatic graphs with distributed algorithms, for a wide range of models of distributed computing. In particular, we show that these problems do not admit any distributed quantum advantage. To do that:   1. We give a new distributed algorithm that finds a $c$-coloring in $\\chi$-chromatic graphs in $\\tilde{\\mathcal{O}}(n^{\\frac{1}{\\alpha}})$ rounds, with $\\alpha = \\bigl\\lceil\\frac{c-1}{\\chi - 1}\\bigr\\rceil$.   2. We prove that any distributed algorithm for this problem requires $\\Omega(n^{\\frac{1}{\\alpha}})$ rounds.   Our upper bound holds in the classical, deterministic LOCAL model, while the near-matching lower bound holds in the \\emph{non-signaling} model. This model, introduced by Arfaoui and Fraigniaud in 2014, captures all models of distributed graph algorithms that obey physical causality; this includes not only classical deterministic LOCAL and randomized LOCAL but also quantum-LOCAL, even with a pre-shared quantum state.   We also show that similar arguments can be used to prove that, e.g., 3-coloring 2-dimensional grids or $c$-coloring trees remain hard problems even for the non-signaling model, and in particular do not admit any quantum advantage. Our lower-bound arguments are purely graph-theoretic at heart; no background on quantum information theory is needed to establish the proofs.","sentences":["We give an almost complete characterization of the hardness of $c$-coloring $\\chi$-chromatic graphs with distributed algorithms, for a wide range of models of distributed computing.","In particular, we show that these problems do not admit any distributed quantum advantage.","To do that:   1.","We give a new distributed algorithm that finds a $c$-coloring in $\\chi$-chromatic graphs in $\\tilde{\\mathcal{O}}(n^{\\frac{1}{\\alpha}})$ rounds, with $\\alpha = \\bigl\\lceil\\frac{c-1}{\\chi - 1}\\bigr\\rceil$.   2.","We prove that any distributed algorithm for this problem requires $\\Omega(n^{\\frac{1}{\\alpha}})$ rounds.   ","Our upper bound holds in the classical, deterministic LOCAL model, while the near-matching lower bound holds in the \\emph{non-signaling} model.","This model, introduced by Arfaoui and Fraigniaud in 2014, captures all models of distributed graph algorithms that obey physical causality; this includes not only classical deterministic LOCAL and randomized LOCAL but also quantum-LOCAL, even with a pre-shared quantum state.   ","We also show that similar arguments can be used to prove that, e.g., 3-coloring 2-dimensional grids or $c$-coloring trees remain hard problems even for the non-signaling model, and in particular do not admit any quantum advantage.","Our lower-bound arguments are purely graph-theoretic at heart; no background on quantum information theory is needed to establish the proofs."],"url":"http://arxiv.org/abs/2307.09444v1"}
{"created":"2023-07-18 17:16:49","title":"Age-Based Cache Updating Under Timestomping","abstract":"We consider a slotted communication system consisting of a source, a cache, a user and a timestomping adversary. The time horizon consists of total $T$ time slots, such that the source transmits update packets to the user directly over $T_{1}$ time slots and to the cache over $T_{2}$ time slots. We consider $T_{1}\\ll T_{2}$, $T_{1}+T_{2} < T$, such that the source transmits to the user once between two consecutive cache updates. Update packets are marked with timestamps corresponding to their generation times at the source. All nodes have a buffer size of one and store the packet with the latest timestamp to minimize their age of information. In this setting, we consider the presence of an oblivious adversary that fully controls the communication link between the cache and the user. The adversary manipulates the timestamps of outgoing packets from the cache to the user, with the goal of bringing staleness at the user node. At each time slot, the adversary can choose to either forward the cached packet to the user, after changing its timestamp to current time $t$, thereby rebranding an old packet as a fresh packet and misleading the user into accepting it, or stay idle. The user compares the timestamps of every received packet with the latest packet in its possession to keep the fresher one and discard the staler packet. If the user receives update packets from both cache and source in a time slot, then the packet from source prevails. The goal of the source is to design an algorithm to minimize the average age at the user, and the goal of the adversary is to increase the average age at the user. We formulate this problem in an online learning setting and provide a fundamental lower bound on the competitive ratio for this problem. We further propose a deterministic algorithm with a provable guarantee on its competitive ratio.","sentences":["We consider a slotted communication system consisting of a source, a cache, a user and a timestomping adversary.","The time horizon consists of total $T$ time slots, such that the source transmits update packets to the user directly over $T_{1}$ time slots and to the cache over $T_{2}$ time slots.","We consider $T_{1}\\ll T_{2}$, $T_{1}+T_{2} < T$, such that the source transmits to the user once between two consecutive cache updates.","Update packets are marked with timestamps corresponding to their generation times at the source.","All nodes have a buffer size of one and store the packet with the latest timestamp to minimize their age of information.","In this setting, we consider the presence of an oblivious adversary that fully controls the communication link between the cache and the user.","The adversary manipulates the timestamps of outgoing packets from the cache to the user, with the goal of bringing staleness at the user node.","At each time slot, the adversary can choose to either forward the cached packet to the user, after changing its timestamp to current time $t$, thereby rebranding an old packet as a fresh packet and misleading the user into accepting it, or stay idle.","The user compares the timestamps of every received packet with the latest packet in its possession to keep the fresher one and discard the staler packet.","If the user receives update packets from both cache and source in a time slot, then the packet from source prevails.","The goal of the source is to design an algorithm to minimize the average age at the user, and the goal of the adversary is to increase the average age at the user.","We formulate this problem in an online learning setting and provide a fundamental lower bound on the competitive ratio for this problem.","We further propose a deterministic algorithm with a provable guarantee on its competitive ratio."],"url":"http://arxiv.org/abs/2307.09443v1"}
{"created":"2023-07-18 17:11:55","title":"Unsupervised Conditional Slot Attention for Object Centric Learning","abstract":"Extracting object-level representations for downstream reasoning tasks is an emerging area in AI. Learning object-centric representations in an unsupervised setting presents multiple challenges, a key one being binding an arbitrary number of object instances to a specialized object slot. Recent object-centric representation methods like Slot Attention utilize iterative attention to learn composable representations with dynamic inference level binding but fail to achieve specialized slot level binding. To address this, in this paper we propose Unsupervised Conditional Slot Attention using a novel Probabilistic Slot Dictionary (PSD). We define PSD with (i) abstract object-level property vectors as key and (ii) parametric Gaussian distribution as its corresponding value. We demonstrate the benefits of the learnt specific object-level conditioning distributions in multiple downstream tasks, namely object discovery, compositional scene generation, and compositional visual reasoning. We show that our method provides scene composition capabilities and a significant boost in a few shot adaptability tasks of compositional visual reasoning, while performing similarly or better than slot attention in object discovery tasks","sentences":["Extracting object-level representations for downstream reasoning tasks is an emerging area in AI.","Learning object-centric representations in an unsupervised setting presents multiple challenges, a key one being binding an arbitrary number of object instances to a specialized object slot.","Recent object-centric representation methods like Slot Attention utilize iterative attention to learn composable representations with dynamic inference level binding but fail to achieve specialized slot level binding.","To address this, in this paper we propose Unsupervised Conditional Slot Attention using a novel Probabilistic Slot Dictionary (PSD).","We define PSD with (i) abstract object-level property vectors as key and (ii) parametric Gaussian distribution as its corresponding value.","We demonstrate the benefits of the learnt specific object-level conditioning distributions in multiple downstream tasks, namely object discovery, compositional scene generation, and compositional visual reasoning.","We show that our method provides scene composition capabilities and a significant boost in a few shot adaptability tasks of compositional visual reasoning, while performing similarly or better than slot attention in object discovery tasks"],"url":"http://arxiv.org/abs/2307.09437v1"}
{"created":"2023-07-18 16:53:07","title":"Balancing Privacy and Progress in Artificial Intelligence: Anonymization in Histopathology for Biomedical Research and Education","abstract":"The advancement of biomedical research heavily relies on access to large amounts of medical data. In the case of histopathology, Whole Slide Images (WSI) and clinicopathological information are valuable for developing Artificial Intelligence (AI) algorithms for Digital Pathology (DP). Transferring medical data \"as open as possible\" enhances the usability of the data for secondary purposes but poses a risk to patient privacy. At the same time, existing regulations push towards keeping medical data \"as closed as necessary\" to avoid re-identification risks. Generally, these legal regulations require the removal of sensitive data but do not consider the possibility of data linkage attacks due to modern image-matching algorithms. In addition, the lack of standardization in DP makes it harder to establish a single solution for all formats of WSIs. These challenges raise problems for bio-informatics researchers in balancing privacy and progress while developing AI algorithms. This paper explores the legal regulations and terminologies for medical data-sharing. We review existing approaches and highlight challenges from the histopathological perspective. We also present a data-sharing guideline for histological data to foster multidisciplinary research and education.","sentences":["The advancement of biomedical research heavily relies on access to large amounts of medical data.","In the case of histopathology, Whole Slide Images (WSI) and clinicopathological information are valuable for developing Artificial Intelligence (AI) algorithms for Digital Pathology (DP).","Transferring medical data \"as open as possible\" enhances the usability of the data for secondary purposes but poses a risk to patient privacy.","At the same time, existing regulations push towards keeping medical data \"as closed as necessary\" to avoid re-identification risks.","Generally, these legal regulations require the removal of sensitive data but do not consider the possibility of data linkage attacks due to modern image-matching algorithms.","In addition, the lack of standardization in DP makes it harder to establish a single solution for all formats of WSIs.","These challenges raise problems for bio-informatics researchers in balancing privacy and progress while developing AI algorithms.","This paper explores the legal regulations and terminologies for medical data-sharing.","We review existing approaches and highlight challenges from the histopathological perspective.","We also present a data-sharing guideline for histological data to foster multidisciplinary research and education."],"url":"http://arxiv.org/abs/2307.09426v1"}
{"created":"2023-07-18 16:43:03","title":"Scaling Laws for Imitation Learning in NetHack","abstract":"Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where \"scaling up\" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL and find they outperform prior state-of-the-art by at least 2x in all settings. Our work both demonstrates the scaling behavior of imitation learning in a challenging domain, as well as the viability of scaling up current approaches for increasingly capable agents in NetHack, a game that remains elusively hard for current AI systems.","sentences":["Imitation Learning (IL) is one of the most widely used methods in machine learning.","Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior.","However, none of these works deeply investigate the role of scaling up the model and data size.","Inspired by recent work in Natural Language Processing (NLP) where \"scaling up\" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting.","To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability.","We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples.","We forecast and train several NetHack agents with IL and find they outperform prior state-of-the-art by at least 2x in all settings.","Our work both demonstrates the scaling behavior of imitation learning in a challenging domain, as well as the viability of scaling up current approaches for increasingly capable agents in NetHack, a game that remains elusively hard for current AI systems."],"url":"http://arxiv.org/abs/2307.09423v1"}
{"created":"2023-07-18 16:37:37","title":"Measuring Student Behavioral Engagement using Histogram of Actions","abstract":"In this paper, we propose a novel technique for measuring behavioral engagement through students' actions recognition. The proposed approach recognizes student actions then predicts the student behavioral engagement level. For student action recognition, we use human skeletons to model student postures and upper body movements. To learn the dynamics of student upper body, a 3D-CNN model is used. The trained 3D-CNN model is used to recognize actions within every 2minute video segment then these actions are used to build a histogram of actions which encodes the student actions and their frequencies. This histogram is utilized as an input to SVM classifier to classify whether the student is engaged or disengaged. To evaluate the proposed framework, we build a dataset consisting of 1414 2-minute video segments annotated with 13 actions and 112 video segments annotated with two engagement levels. Experimental results indicate that student actions can be recognized with top 1 accuracy 83.63% and the proposed framework can capture the average engagement of the class.","sentences":["In this paper, we propose a novel technique for measuring behavioral engagement through students' actions recognition.","The proposed approach recognizes student actions then predicts the student behavioral engagement level.","For student action recognition, we use human skeletons to model student postures and upper body movements.","To learn the dynamics of student upper body, a 3D-CNN model is used.","The trained 3D-CNN model is used to recognize actions within every 2minute video segment then these actions are used to build a histogram of actions which encodes the student actions and their frequencies.","This histogram is utilized as an input to SVM classifier to classify whether the student is engaged or disengaged.","To evaluate the proposed framework, we build a dataset consisting of 1414 2-minute video segments annotated with 13 actions and 112 video segments annotated with two engagement levels.","Experimental results indicate that student actions can be recognized with top 1 accuracy 83.63% and the proposed framework can capture the average engagement of the class."],"url":"http://arxiv.org/abs/2307.09420v1"}
{"created":"2023-07-18 16:35:17","title":"RIS-Aided Index Modulation with Greedy Detection over Rician Fading Channels","abstract":"Index modulation schemes for reconfigurable intelligent surfaces (RIS)-assisted systems are envisioned as promising technologies for fifth-generation-advanced and sixth-generation (6G) wireless communication systems to enhance various system capabilities such as coverage area and network capacity. In this paper, we consider a receive diversity RIS-assisted wireless communication system employing IM schemes, namely, space-shift keying (SSK) for binary modulation and spatial modulation (SM) for M-ary modulation for data transmission. The RIS lies in close proximity to the transmitter, and the transmitted data is subjected to a fading environment with a prominent line-of-sight component modeled by a Rician distribution. A receiver structure based on a greedy detection rule is employed to select the receive diversity branch with the highest received signal energy for demodulation. The performance of the considered system is evaluated by obtaining a series-form expression for the probability of erroneous index detection (PED) of the considered target antenna using a characteristic function approach. In addition, closed-form and asymptotic expressions at high and low signal-to-noise ratios (SNRs) for the bit error rate (BER) for the SSK-based system, and the SM-based system employing M-ary phase-shift keying and M-ary quadrature amplitude modulation schemes, are derived. The dependencies of the system performance on the various parameters are corroborated via numerical results. The asymptotic expressions and results of PED and BER at high and low SNR values lead to the observation of a performance saturation and the presence of an SNR value as a point of inflection, which is attributed to the greedy detector's structure.","sentences":["Index modulation schemes for reconfigurable intelligent surfaces (RIS)-assisted systems are envisioned as promising technologies for fifth-generation-advanced and sixth-generation (6G) wireless communication systems to enhance various system capabilities such as coverage area and network capacity.","In this paper, we consider a receive diversity RIS-assisted wireless communication system employing IM schemes, namely, space-shift keying (SSK) for binary modulation and spatial modulation (SM) for M-ary modulation for data transmission.","The RIS lies in close proximity to the transmitter, and the transmitted data is subjected to a fading environment with a prominent line-of-sight component modeled by a Rician distribution.","A receiver structure based on a greedy detection rule is employed to select the receive diversity branch with the highest received signal energy for demodulation.","The performance of the considered system is evaluated by obtaining a series-form expression for the probability of erroneous index detection (PED) of the considered target antenna using a characteristic function approach.","In addition, closed-form and asymptotic expressions at high and low signal-to-noise ratios (SNRs) for the bit error rate (BER) for the SSK-based system, and the SM-based system employing M-ary phase-shift keying and M-ary quadrature amplitude modulation schemes, are derived.","The dependencies of the system performance on the various parameters are corroborated via numerical results.","The asymptotic expressions and results of PED and BER at high and low SNR values lead to the observation of a performance saturation and the presence of an SNR value as a point of inflection, which is attributed to the greedy detector's structure."],"url":"http://arxiv.org/abs/2307.09417v1"}
{"created":"2023-07-18 16:33:30","title":"Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation","abstract":"Research in Image Generation has recently made significant progress, particularly boosted by the introduction of Vision-Language models which are able to produce high-quality visual content based on textual inputs. Despite ongoing advancements in terms of generation quality and realism, no methodical frameworks have been defined yet to quantitatively measure the quality of the generated content and the adherence with the prompted requests: so far, only human-based evaluations have been adopted for quality satisfaction and for comparing different generative methods. We introduce a novel automated method for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a generated/edited image and the corresponding prompt/instructions, with a process inspired by the human cognitive behaviour. ViCE combines the strengths of Large Language Models (LLMs) and Visual Question Answering (VQA) into a unified pipeline, aiming to replicate the human cognitive process in quality assessment. This method outlines visual concepts, formulates image-specific verification questions, utilizes the Q&A system to investigate the image, and scores the combined outcome. Although this brave new hypothesis of mimicking humans in the image evaluation process is in its preliminary assessment stage, results are promising and open the door to a new form of automatic evaluation which could have significant impact as the image generation or the image target editing tasks become more and more sophisticated.","sentences":["Research in Image Generation has recently made significant progress, particularly boosted by the introduction of Vision-Language models which are able to produce high-quality visual content based on textual inputs.","Despite ongoing advancements in terms of generation quality and realism, no methodical frameworks have been defined yet to quantitatively measure the quality of the generated content and the adherence with the prompted requests: so far, only human-based evaluations have been adopted for quality satisfaction and for comparing different generative methods.","We introduce a novel automated method for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a generated/edited image and the corresponding prompt/instructions, with a process inspired by the human cognitive behaviour.","ViCE combines the strengths of Large Language Models (LLMs) and Visual Question Answering (VQA) into a unified pipeline, aiming to replicate the human cognitive process in quality assessment.","This method outlines visual concepts, formulates image-specific verification questions, utilizes the Q&A system to investigate the image, and scores the combined outcome.","Although this brave new hypothesis of mimicking humans in the image evaluation process is in its preliminary assessment stage, results are promising and open the door to a new form of automatic evaluation which could have significant impact as the image generation or the image target editing tasks become more and more sophisticated."],"url":"http://arxiv.org/abs/2307.09416v1"}
{"created":"2023-07-18 16:27:39","title":"Resilience of the reported global human-nature interaction network to pandemic conditions","abstract":"Understanding human-nature interactions and the architecture of coupled human-nature systems is crucial for sustainable development. Cultural ecosystem services (CES), defined as intangible benefits derived from nature exposure, contribute to maintaining and improving human well-being. However, we have limited understanding of how well-being benefits emerge from CES co-production. In this study, for the first time, we estimated the global CES network from self-reported interactions between nature features and human activities underpinning CES co-production using social media. First, we used a bottom-up, approach to define the global repertoire of nature features and human activities used during CES co-production using 682,000 posts on Reddit. We then sampled Twitter to estimate the co-occurrence of these features and activities over the past five years, retrieving 41.7 millions tweets. These tweets were used to estimate the CES bipartite network, where each link was weighted by the number of times nature features and human activities co-occurred in tweets. We expected to observe large changes in the CES network topology in relation to the global mobility restrictions during the COVID-19 pandemic. This was not the case and the global CES network was generally resilient. However, a higher order singular value decomposition of the CES tensor revealed an impulse on the link between self care activities and urban greenspace. This could be due to an increased need for self care during the pandemic and urban greenspace enabling CES to be produced locally. Thus, providing resilience for maintaining well-being during the pandemic. Our user based analysis also indicated a shift towards local CES production during the beginning of the pandemic. Thus, supporting that CES was produced locally. These findings suggest an overall need for CES and access to features providing CES in local communities.","sentences":["Understanding human-nature interactions and the architecture of coupled human-nature systems is crucial for sustainable development.","Cultural ecosystem services (CES), defined as intangible benefits derived from nature exposure, contribute to maintaining and improving human well-being.","However, we have limited understanding of how well-being benefits emerge from CES co-production.","In this study, for the first time, we estimated the global CES network from self-reported interactions between nature features and human activities underpinning CES co-production using social media.","First, we used a bottom-up, approach to define the global repertoire of nature features and human activities used during CES co-production using 682,000 posts on Reddit.","We then sampled Twitter to estimate the co-occurrence of these features and activities over the past five years, retrieving 41.7 millions tweets.","These tweets were used to estimate the CES bipartite network, where each link was weighted by the number of times nature features and human activities co-occurred in tweets.","We expected to observe large changes in the CES network topology in relation to the global mobility restrictions during the COVID-19 pandemic.","This was not the case and the global CES network was generally resilient.","However, a higher order singular value decomposition of the CES tensor revealed an impulse on the link between self care activities and urban greenspace.","This could be due to an increased need for self care during the pandemic and urban greenspace enabling CES to be produced locally.","Thus, providing resilience for maintaining well-being during the pandemic.","Our user based analysis also indicated a shift towards local CES production during the beginning of the pandemic.","Thus, supporting that CES was produced locally.","These findings suggest an overall need for CES and access to features providing CES in local communities."],"url":"http://arxiv.org/abs/2307.09408v1"}
{"created":"2023-07-18 16:13:35","title":"Online Learning with Costly Features in Non-stationary Environments","abstract":"Maximizing long-term rewards is the primary goal in sequential decision-making problems. The majority of existing methods assume that side information is freely available, enabling the learning agent to observe all features' states before making a decision. In real-world problems, however, collecting beneficial information is often costly. That implies that, besides individual arms' reward, learning the observations of the features' states is essential to improve the decision-making strategy. The problem is aggravated in a non-stationary environment where reward and cost distributions undergo abrupt changes over time. To address the aforementioned dual learning problem, we extend the contextual bandit setting and allow the agent to observe subsets of features' states. The objective is to maximize the long-term average gain, which is the difference between the accumulated rewards and the paid costs on average. Therefore, the agent faces a trade-off between minimizing the cost of information acquisition and possibly improving the decision-making process using the obtained information. To this end, we develop an algorithm that guarantees a sublinear regret in time. Numerical results demonstrate the superiority of our proposed policy in a real-world scenario.","sentences":["Maximizing long-term rewards is the primary goal in sequential decision-making problems.","The majority of existing methods assume that side information is freely available, enabling the learning agent to observe all features' states before making a decision.","In real-world problems, however, collecting beneficial information is often costly.","That implies that, besides individual arms' reward, learning the observations of the features' states is essential to improve the decision-making strategy.","The problem is aggravated in a non-stationary environment where reward and cost distributions undergo abrupt changes over time.","To address the aforementioned dual learning problem, we extend the contextual bandit setting and allow the agent to observe subsets of features' states.","The objective is to maximize the long-term average gain, which is the difference between the accumulated rewards and the paid costs on average.","Therefore, the agent faces a trade-off between minimizing the cost of information acquisition and possibly improving the decision-making process using the obtained information.","To this end, we develop an algorithm that guarantees a sublinear regret in time.","Numerical results demonstrate the superiority of our proposed policy in a real-world scenario."],"url":"http://arxiv.org/abs/2307.09388v1"}
{"created":"2023-07-18 16:05:25","title":"Zero-shot Query Reformulation for Conversational Search","abstract":"As the popularity of voice assistants continues to surge, conversational search has gained increased attention in Information Retrieval. However, data sparsity issues in conversational search significantly hinder the progress of supervised conversational search methods. Consequently, researchers are focusing more on zero-shot conversational search approaches. Nevertheless, existing zero-shot methods face three primary limitations: they are not universally applicable to all retrievers, their effectiveness lacks sufficient explainability, and they struggle to resolve common conversational ambiguities caused by omission. To address these limitations, we introduce a novel Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based on previous dialogue contexts without requiring supervision from conversational search data. Specifically, our framework utilizes language models designed for machine reading comprehension tasks to explicitly resolve two common ambiguities: coreference and omission, in raw queries. In comparison to existing zero-shot methods, our approach is universally applicable to any retriever without additional adaptation or indexing. It also provides greater explainability and effectively enhances query intent understanding because ambiguities are explicitly and proactively resolved. Through extensive experiments on four TREC conversational datasets, we demonstrate the effectiveness of our method, which consistently outperforms state-of-the-art baselines.","sentences":["As the popularity of voice assistants continues to surge, conversational search has gained increased attention in Information Retrieval.","However, data sparsity issues in conversational search significantly hinder the progress of supervised conversational search methods.","Consequently, researchers are focusing more on zero-shot conversational search approaches.","Nevertheless, existing zero-shot methods face three primary limitations: they are not universally applicable to all retrievers, their effectiveness lacks sufficient explainability, and they struggle to resolve common conversational ambiguities caused by omission.","To address these limitations, we introduce a novel Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based on previous dialogue contexts without requiring supervision from conversational search data.","Specifically, our framework utilizes language models designed for machine reading comprehension tasks to explicitly resolve two common ambiguities: coreference and omission, in raw queries.","In comparison to existing zero-shot methods, our approach is universally applicable to any retriever without additional adaptation or indexing.","It also provides greater explainability and effectively enhances query intent understanding because ambiguities are explicitly and proactively resolved.","Through extensive experiments on four TREC conversational datasets, we demonstrate the effectiveness of our method, which consistently outperforms state-of-the-art baselines."],"url":"http://arxiv.org/abs/2307.09384v1"}
{"created":"2023-07-18 16:03:33","title":"Soundly Handling Linearity","abstract":"We propose a novel approach to soundly combining linear types with effect handlers. Linear type systems statically ensure that resources such as file handles are used exactly once. Effect handlers provide a modular programming abstraction for implementing features ranging from exceptions to concurrency. Whereas linear type systems bake in the assumption that continuations are invoked exactly once, effect handlers allow continuations to be discarded or invoked more than once. This mismatch leads to soundness bugs in existing systems such as the programming language Links, which combines linearity (for session types) with effect handlers. We introduce control flow linearity as a means to ensure that continuations are used in accordance with the linearity of any resources they capture, ruling out such soundness bugs.   We formalise control flow linearity in a System F-style core calculus Feffpop equipped with linear types, effect types, and effect handlers. We define a linearity-aware semantics to formally prove that Feffpop preserves the integrity of linear values in the sense that no linear value is discarded or duplicated. In order to show that control flow linearity can be made practical, we adapt Links based on the design of Feffpop, in doing so fixing a long-standing soundness bug.   Finally, to better expose the potential of control flow linearity, we define an ML-style core calculus Qeffpop, based on qualified types, which requires no programmer provided annotations, and instead relies entirely on type inference to infer control flow linearity. Both linearity and effects are captured by qualified types. Qeffpop overcomes a number of practical limitations of Feffpop, supporting abstraction over linearity, linearity dependencies between type variables, and a much more fine-grained notion of control flow linearity.","sentences":["We propose a novel approach to soundly combining linear types with effect handlers.","Linear type systems statically ensure that resources such as file handles are used exactly once.","Effect handlers provide a modular programming abstraction for implementing features ranging from exceptions to concurrency.","Whereas linear type systems bake in the assumption that continuations are invoked exactly once, effect handlers allow continuations to be discarded or invoked more than once.","This mismatch leads to soundness bugs in existing systems such as the programming language Links, which combines linearity (for session types) with effect handlers.","We introduce control flow linearity as a means to ensure that continuations are used in accordance with the linearity of any resources they capture, ruling out such soundness bugs.   ","We formalise control flow linearity in a System F-style core calculus Feffpop equipped with linear types, effect types, and effect handlers.","We define a linearity-aware semantics to formally prove that Feffpop preserves the integrity of linear values in the sense that no linear value is discarded or duplicated.","In order to show that control flow linearity can be made practical, we adapt Links based on the design of Feffpop, in doing so fixing a long-standing soundness bug.   ","Finally, to better expose the potential of control flow linearity, we define an ML-style core calculus Qeffpop, based on qualified types, which requires no programmer provided annotations, and instead relies entirely on type inference to infer control flow linearity.","Both linearity and effects are captured by qualified types.","Qeffpop overcomes a number of practical limitations of Feffpop, supporting abstraction over linearity, linearity dependencies between type variables, and a much more fine-grained notion of control flow linearity."],"url":"http://arxiv.org/abs/2307.09383v1"}
{"created":"2023-07-18 16:01:15","title":"Is this Snippet Written by ChatGPT? An Empirical Study with a CodeBERT-Based Classifier","abstract":"Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it as a tool to solve development problems. However, while offering a practical solution to programming problems, ChatGPT should be mainly used as a supporting tool (e.g., in software education) rather than as a replacement for the human being. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content may need to be adapted to work effectively with source code. This paper presents an empirical study to investigate the feasibility of automated identification of AI-generated code snippets, and the factors that influence this ability. To this end, we propose a novel approach called GPTSniffer, which builds on top of CodeBERT to detect source code written by AI. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, and outperforms two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps to boost classification performances.","sentences":["Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it as a tool to solve development problems.","However, while offering a practical solution to programming problems, ChatGPT should be mainly used as a supporting tool (e.g., in software education) rather than as a replacement for the human being.","Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content may need to be adapted to work effectively with source code.","This paper presents an empirical study to investigate the feasibility of automated identification of AI-generated code snippets, and the factors that influence this ability.","To this end, we propose a novel approach called GPTSniffer, which builds on top of CodeBERT to detect source code written by AI.","The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, and outperforms two baselines, GPTZero and OpenAI Text Classifier.","Also, the study shows how similar training data or a classification context with paired snippets helps to boost classification performances."],"url":"http://arxiv.org/abs/2307.09381v1"}
{"created":"2023-07-18 16:00:02","title":"Data Cross-Segmentation for Improved Generalization in Reinforcement Learning Based Algorithmic Trading","abstract":"The use of machine learning in algorithmic trading systems is increasingly common. In a typical set-up, supervised learning is used to predict the future prices of assets, and those predictions drive a simple trading and execution strategy. This is quite effective when the predictions have sufficient signal, markets are liquid, and transaction costs are low. However, those conditions often do not hold in thinly traded financial markets and markets for differentiated assets such as real estate or vehicles. In these markets, the trading strategy must consider the long-term effects of taking positions that are relatively more difficult to change. In this work, we propose a Reinforcement Learning (RL) algorithm that trades based on signals from a learned predictive model and addresses these challenges. We test our algorithm on 20+ years of equity data from Bursa Malaysia.","sentences":["The use of machine learning in algorithmic trading systems is increasingly common.","In a typical set-up, supervised learning is used to predict the future prices of assets, and those predictions drive a simple trading and execution strategy.","This is quite effective when the predictions have sufficient signal, markets are liquid, and transaction costs are low.","However, those conditions often do not hold in thinly traded financial markets and markets for differentiated assets such as real estate or vehicles.","In these markets, the trading strategy must consider the long-term effects of taking positions that are relatively more difficult to change.","In this work, we propose a Reinforcement Learning (RL) algorithm that trades based on signals from a learned predictive model and addresses these challenges.","We test our algorithm on 20+ years of equity data from Bursa Malaysia."],"url":"http://arxiv.org/abs/2307.09377v1"}
{"created":"2023-07-18 15:59:40","title":"Closing star-free closure","abstract":"We introduce an operator on classes of regular languages, the star-free closure. Our motivation is to generalize standard results of automata theory within a unified framework. Given an arbitrary input class $C$, the star-free closure operator outputs the least class closed under Boolean operations and language concatenation, and containing all languages of $C$ as well as all finite languages. We establish several equivalent characterizations of star-free closure: in terms of regular expressions, first-order logic, pure future and future-past temporal logic, and recognition by finite monoids. A key ingredient is that star-free closure coincides with another closure operator, defined in terms of regular operations where Kleene stars are allowed in restricted~contexts.   A consequence of this first result is that we can decide membership of a regular language in the star-free closure of a class whose separation problem is decidable. Moreover, we prove that separation itself is decidable for the star-free closure of any finite class, and of any class of group languages having itself decidable separation (plus mild additional properties). We actually show decidability of a stronger property, called covering.","sentences":["We introduce an operator on classes of regular languages, the star-free closure.","Our motivation is to generalize standard results of automata theory within a unified framework.","Given an arbitrary input class $C$, the star-free closure operator outputs the least class closed under Boolean operations and language concatenation, and containing all languages of $C$ as well as all finite languages.","We establish several equivalent characterizations of star-free closure: in terms of regular expressions, first-order logic, pure future and future-past temporal logic, and recognition by finite monoids.","A key ingredient is that star-free closure coincides with another closure operator, defined in terms of regular operations where Kleene stars are allowed in restricted~contexts.   ","A consequence of this first result is that we can decide membership of a regular language in the star-free closure of a class whose separation problem is decidable.","Moreover, we prove that separation itself is decidable for the star-free closure of any finite class, and of any class of group languages having itself decidable separation (plus mild additional properties).","We actually show decidability of a stronger property, called covering."],"url":"http://arxiv.org/abs/2307.09376v1"}
{"created":"2023-07-18 15:59:37","title":"CertPri: Certifiable Prioritization for Deep Neural Networks via Movement Cost in Feature Space","abstract":"Deep neural networks (DNNs) have demonstrated their outperformance in various software systems, but also exhibit misbehavior and even result in irreversible disasters. Therefore, it is crucial to identify the misbehavior of DNN-based software and improve DNNs' quality. Test input prioritization is one of the most appealing ways to guarantee DNNs' quality, which prioritizes test inputs so that more bug-revealing inputs can be identified earlier with limited time and manual labeling efforts. However, the existing prioritization methods are still limited from three aspects: certifiability, effectiveness, and generalizability. To overcome the challenges, we propose CertPri, a test input prioritization technique designed based on a movement cost perspective of test inputs in DNNs' feature space. CertPri differs from previous works in three key aspects: (1) certifiable: it provides a formal robustness guarantee for the movement cost; (2) effective: it leverages formally guaranteed movement costs to identify malicious bug-revealing inputs; and (3) generic: it can be applied to various tasks, data, models, and scenarios. Extensive evaluations across 2 tasks (i.e., classification and regression), 6 data forms, 4 model structures, and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri's superior performance. For instance, it significantly improves 53.97% prioritization effectiveness on average compared with baselines. Its robustness and generalizability are 1.41~2.00 times and 1.33~3.39 times that of baselines on average, respectively.","sentences":["Deep neural networks (DNNs) have demonstrated their outperformance in various software systems, but also exhibit misbehavior and even result in irreversible disasters.","Therefore, it is crucial to identify the misbehavior of DNN-based software and improve DNNs' quality.","Test input prioritization is one of the most appealing ways to guarantee DNNs' quality, which prioritizes test inputs so that more bug-revealing inputs can be identified earlier with limited time and manual labeling efforts.","However, the existing prioritization methods are still limited from three aspects: certifiability, effectiveness, and generalizability.","To overcome the challenges, we propose CertPri, a test input prioritization technique designed based on a movement cost perspective of test inputs in DNNs' feature space.","CertPri differs from previous works in three key aspects: (1) certifiable: it provides a formal robustness guarantee for the movement cost; (2) effective: it leverages formally guaranteed movement costs to identify malicious bug-revealing inputs; and (3) generic: it can be applied to various tasks, data, models, and scenarios.","Extensive evaluations across 2 tasks (i.e., classification and regression), 6 data forms, 4 model structures, and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri's superior performance.","For instance, it significantly improves 53.97% prioritization effectiveness on average compared with baselines.","Its robustness and generalizability are 1.41~2.00 times and 1.33~3.39 times that of baselines on average, respectively."],"url":"http://arxiv.org/abs/2307.09375v1"}
{"created":"2023-07-18 15:56:39","title":"Enhancing Pattern Classification in Support Vector Machines through Matrix Formulation","abstract":"Support Vector Machines (SVM) have gathered significant acclaim as classifiers due to their successful implementation of Statistical Learning Theory. However, in the context of multiclass and multilabel settings, the reliance on vector-based formulations in existing SVM-based models poses limitations regarding flexibility and ease of incorporating additional terms to handle specific challenges. To overcome these limitations, our research paper focuses on introducing a matrix formulation for SVM that effectively addresses these constraints. By employing the Accelerated Gradient Descent method in the dual, we notably enhance the efficiency of solving the Matrix-SVM problem. Experimental evaluations on multilabel and multiclass datasets demonstrate that Matrix SVM achieves superior time efficacy while delivering similar results to Binary Relevance SVM.   Moreover, our matrix formulation unveils crucial insights and advantages that may not be readily apparent in traditional vector-based notations. We emphasize that numerous multilabel models can be viewed as extensions of SVM, with customised modifications to meet specific requirements. The matrix formulation presented in this paper establishes a solid foundation for developing more sophisticated models capable of effectively addressing the distinctive challenges encountered in multilabel learning.","sentences":["Support Vector Machines (SVM) have gathered significant acclaim as classifiers due to their successful implementation of Statistical Learning Theory.","However, in the context of multiclass and multilabel settings, the reliance on vector-based formulations in existing SVM-based models poses limitations regarding flexibility and ease of incorporating additional terms to handle specific challenges.","To overcome these limitations, our research paper focuses on introducing a matrix formulation for SVM that effectively addresses these constraints.","By employing the Accelerated Gradient Descent method in the dual, we notably enhance the efficiency of solving the Matrix-SVM problem.","Experimental evaluations on multilabel and multiclass datasets demonstrate that Matrix SVM achieves superior time efficacy while delivering similar results to Binary Relevance SVM.   ","Moreover, our matrix formulation unveils crucial insights and advantages that may not be readily apparent in traditional vector-based notations.","We emphasize that numerous multilabel models can be viewed as extensions of SVM, with customised modifications to meet specific requirements.","The matrix formulation presented in this paper establishes a solid foundation for developing more sophisticated models capable of effectively addressing the distinctive challenges encountered in multilabel learning."],"url":"http://arxiv.org/abs/2307.09372v1"}
{"created":"2023-07-18 15:51:43","title":"The ExaNeSt Prototype: Evaluation of Efficient HPC Communication Hardware in an ARM-based Multi-FPGA Rack","abstract":"We present and evaluate the ExaNeSt Prototype, a liquid-cooled rack prototype consisting of 256 Xilinx ZU9EG MPSoCs, 4 TBytes of DRAM, 16 TBytes of SSD, and configurable interconnection 10-Gbps hardware. We developed this testbed in 2016-2019 to validate the flexibility of FPGAs for experimenting with efficient hardware support for HPC communication among tens of thousands of processors and accelerators in the quest towards Exascale systems and beyond. We present our key design choices reagrding overall system architecture, PCBs and runtime software, and summarize insights resulting from measurement and analysis. Of particular note, our custom interconnect includes a low-cost low-latency network interface, offering user-level zero-copy RDMA, which we have tightly coupled with the ARMv8 processors in the MPSoCs. We have developed a system software runtime on top of these features, and have been able to run MPI. We have evaluated our testbed through MPI microbenchmarks, mini, and full MPI applications. Single hop, one way latency is $1.3$~$\\mu$s; approximately $0.47$~$\\mu$s out of these are attributed to network interface and the user-space library that exposes its functionality to the runtime. Latency over longer paths increases as expected, reaching $2.55$~$\\mu$s for a five-hop path. Bandwidth tests show that, for a single hop, link utilization reaches $82\\%$ of the theoretical capacity. Microbenchmarks based on MPI collectives reveal that broadcast latency scales as expected when the number of participating ranks increases. We also implemented a custom Allreduce accelerator in the network interface, which reduces the latency of such collectives by up to $88\\%$. We assess performance scaling through weak and strong scaling tests for HPCG, LAMMPS, and the miniFE mini application; for all these tests, parallelization efficiency is at least $69\\%$, or better.","sentences":["We present and evaluate the ExaNeSt Prototype, a liquid-cooled rack prototype consisting of 256 Xilinx ZU9EG MPSoCs, 4 TBytes of DRAM, 16 TBytes of SSD, and configurable interconnection 10-Gbps hardware.","We developed this testbed in 2016-2019 to validate the flexibility of FPGAs for experimenting with efficient hardware support for HPC communication among tens of thousands of processors and accelerators in the quest towards Exascale systems and beyond.","We present our key design choices reagrding overall system architecture, PCBs and runtime software, and summarize insights resulting from measurement and analysis.","Of particular note, our custom interconnect includes a low-cost low-latency network interface, offering user-level zero-copy RDMA, which we have tightly coupled with the ARMv8 processors in the MPSoCs.","We have developed a system software runtime on top of these features, and have been able to run MPI.","We have evaluated our testbed through MPI microbenchmarks, mini, and full MPI applications.","Single hop, one way latency is $1.3$~$\\mu$s; approximately $0.47$~$\\mu$s out of these are attributed to network interface and the user-space library that exposes its functionality to the runtime.","Latency over longer paths increases as expected, reaching $2.55$~$\\mu$s for a five-hop path.","Bandwidth tests show that, for a single hop, link utilization reaches $82\\%$ of the theoretical capacity.","Microbenchmarks based on MPI collectives reveal that broadcast latency scales as expected when the number of participating ranks increases.","We also implemented a custom Allreduce accelerator in the network interface, which reduces the latency of such collectives by up to $88\\%$. We assess performance scaling through weak and strong scaling tests for HPCG, LAMMPS, and the miniFE mini application; for all these tests, parallelization efficiency is at least $69\\%$, or better."],"url":"http://arxiv.org/abs/2307.09371v1"}
{"created":"2023-07-18 15:50:32","title":"Identifying Explanation Needs of End-users: Applying and Extending the XAI Question Bank","abstract":"Explanations in XAI are typically developed by AI experts and focus on algorithmic transparency and the inner workings of AI systems. Research has shown that such explanations do not meet the needs of users who do not have AI expertise. As a result, explanations are often ineffective in making system decisions interpretable and understandable. We aim to strengthen a socio-technical view of AI by following a Human-Centered Explainable Artificial Intelligence (HC-XAI) approach, which investigates the explanation needs of end-users (i.e., subject matter experts and lay users) in specific usage contexts. One of the most influential works in this area is the XAI Question Bank (XAIQB) by Liao et al. The authors propose a set of questions that end-users might ask when using an AI system, which in turn is intended to help developers and designers identify and address explanation needs. Although the XAIQB is widely referenced, there are few reports of its use in practice. In particular, it is unclear to what extent the XAIQB sufficiently captures the explanation needs of end-users and what potential problems exist in the practical application of the XAIQB. To explore these open questions, we used the XAIQB as the basis for analyzing 12 think-aloud software explorations with subject matter experts. We investigated the suitability of the XAIQB as a tool for identifying explanation needs in a specific usage context. Our analysis revealed a number of explanation needs that were missing from the question bank, but that emerged repeatedly as our study participants interacted with an AI system. We also found that some of the XAIQB questions were difficult to distinguish and required interpretation during use. Our contribution is an extension of the XAIQB with 11 new questions. In addition, we have expanded the descriptions of all new and existing questions to facilitate their use.","sentences":["Explanations in XAI are typically developed by AI experts and focus on algorithmic transparency and the inner workings of AI systems.","Research has shown that such explanations do not meet the needs of users who do not have AI expertise.","As a result, explanations are often ineffective in making system decisions interpretable and understandable.","We aim to strengthen a socio-technical view of AI by following a Human-Centered Explainable Artificial Intelligence (HC-XAI) approach, which investigates the explanation needs of end-users (i.e., subject matter experts and lay users) in specific usage contexts.","One of the most influential works in this area is the XAI Question Bank (XAIQB) by Liao et al.","The authors propose a set of questions that end-users might ask when using an AI system, which in turn is intended to help developers and designers identify and address explanation needs.","Although the XAIQB is widely referenced, there are few reports of its use in practice.","In particular, it is unclear to what extent the XAIQB sufficiently captures the explanation needs of end-users and what potential problems exist in the practical application of the XAIQB.","To explore these open questions, we used the XAIQB as the basis for analyzing 12 think-aloud software explorations with subject matter experts.","We investigated the suitability of the XAIQB as a tool for identifying explanation needs in a specific usage context.","Our analysis revealed a number of explanation needs that were missing from the question bank, but that emerged repeatedly as our study participants interacted with an AI system.","We also found that some of the XAIQB questions were difficult to distinguish and required interpretation during use.","Our contribution is an extension of the XAIQB with 11 new questions.","In addition, we have expanded the descriptions of all new and existing questions to facilitate their use."],"url":"http://arxiv.org/abs/2307.09369v1"}
{"created":"2023-07-18 15:50:04","title":"Plug the Leaks: Advancing Audio-driven Talking Face Generation by Preventing Unintended Information Flow","abstract":"Audio-driven talking face generation is the task of creating a lip-synchronized, realistic face video from given audio and reference frames. This involves two major challenges: overall visual quality of generated images on the one hand, and audio-visual synchronization of the mouth part on the other hand. In this paper, we start by identifying several problematic aspects of synchronization methods in recent audio-driven talking face generation approaches. Specifically, this involves unintended flow of lip and pose information from the reference to the generated image, as well as instabilities during model training. Subsequently, we propose various techniques for obviating these issues: First, a silent-lip reference image generator prevents leaking of lips from the reference to the generated image. Second, an adaptive triplet loss handles the pose leaking problem. Finally, we propose a stabilized formulation of synchronization loss, circumventing aforementioned training instabilities while additionally further alleviating the lip leaking issue. Combining the individual improvements, we present state-of-the art performance on LRS2 and LRW in both synchronization and visual quality. We further validate our design in various ablation experiments, confirming the individual contributions as well as their complementary effects.","sentences":["Audio-driven talking face generation is the task of creating a lip-synchronized, realistic face video from given audio and reference frames.","This involves two major challenges: overall visual quality of generated images on the one hand, and audio-visual synchronization of the mouth part on the other hand.","In this paper, we start by identifying several problematic aspects of synchronization methods in recent audio-driven talking face generation approaches.","Specifically, this involves unintended flow of lip and pose information from the reference to the generated image, as well as instabilities during model training.","Subsequently, we propose various techniques for obviating these issues: First, a silent-lip reference image generator prevents leaking of lips from the reference to the generated image.","Second, an adaptive triplet loss handles the pose leaking problem.","Finally, we propose a stabilized formulation of synchronization loss, circumventing aforementioned training instabilities while additionally further alleviating the lip leaking issue.","Combining the individual improvements, we present state-of-the art performance on LRS2 and LRW in both synchronization and visual quality.","We further validate our design in various ablation experiments, confirming the individual contributions as well as their complementary effects."],"url":"http://arxiv.org/abs/2307.09368v1"}
{"created":"2023-07-18 15:49:02","title":"Sparse Gaussian Graphical Models with Discrete Optimization: Computational and Statistical Perspectives","abstract":"We consider the problem of learning a sparse graph underlying an undirected Gaussian graphical model, a key problem in statistical machine learning. Given $n$ samples from a multivariate Gaussian distribution with $p$ variables, the goal is to estimate the $p \\times p$ inverse covariance matrix (aka precision matrix), assuming it is sparse (i.e., has a few nonzero entries). We propose GraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the pseudolikelihood function, while most earlier approaches are based on the $\\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer program (MIP) which can be difficult to compute at scale using off-the-shelf commercial solvers. To solve the MIP, we propose a custom nonlinear branch-and-bound (BnB) framework that solves node relaxations with tailored first-order methods. As a by-product of our BnB framework, we propose large-scale solvers for obtaining good primal solutions that are of independent interest. We derive novel statistical guarantees (estimation and variable selection) for our estimator and discuss how our approach improves upon existing estimators. Our numerical experiments on real/synthetic datasets suggest that our method can solve, to near-optimality, problem instances with $p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with $p^2/2$ binary variables. We demonstrate the usefulness of GraphL0BnB versus various state-of-the-art approaches on a range of datasets.","sentences":["We consider the problem of learning a sparse graph underlying an undirected Gaussian graphical model, a key problem in statistical machine learning.","Given $n$ samples from a multivariate Gaussian distribution with $p$ variables, the goal is to estimate the $p \\times p$ inverse covariance matrix (aka precision matrix), assuming it is sparse (i.e., has a few nonzero entries).","We propose GraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the pseudolikelihood function, while most earlier approaches are based on the $\\ell_1$-relaxation.","Our estimator can be formulated as a convex mixed integer program (MIP) which can be difficult to compute at scale using off-the-shelf commercial solvers.","To solve the MIP, we propose a custom nonlinear branch-and-bound (BnB) framework that solves node relaxations with tailored first-order methods.","As a by-product of our BnB framework, we propose large-scale solvers for obtaining good primal solutions that are of independent interest.","We derive novel statistical guarantees (estimation and variable selection) for our estimator and discuss how our approach improves upon existing estimators.","Our numerical experiments on real/synthetic datasets suggest that our method can solve, to near-optimality, problem instances with $p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with $p^2/2$ binary variables.","We demonstrate the usefulness of GraphL0BnB versus various state-of-the-art approaches on a range of datasets."],"url":"http://arxiv.org/abs/2307.09366v1"}
{"created":"2023-07-18 15:48:53","title":"An Evaluation of Zero-Cost Proxies -- from Neural Architecture Performance to Model Robustness","abstract":"Zero-cost proxies are nowadays frequently studied and used to search for neural architectures. They show an impressive ability to predict the performance of architectures by making use of their untrained weights. These techniques allow for immense search speed-ups. So far the joint search for well-performing and robust architectures has received much less attention in the field of NAS. Therefore, the main focus of zero-cost proxies is the clean accuracy of architectures, whereas the model robustness should play an evenly important part. In this paper, we analyze the ability of common zero-cost proxies to serve as performance predictors for robustness in the popular NAS-Bench-201 search space. We are interested in the single prediction task for robustness and the joint multi-objective of clean and robust accuracy. We further analyze the feature importance of the proxies and show that predicting the robustness makes the prediction task from existing zero-cost proxies more challenging. As a result, the joint consideration of several proxies becomes necessary to predict a model's robustness while the clean accuracy can be regressed from a single such feature.","sentences":["Zero-cost proxies are nowadays frequently studied and used to search for neural architectures.","They show an impressive ability to predict the performance of architectures by making use of their untrained weights.","These techniques allow for immense search speed-ups.","So far the joint search for well-performing and robust architectures has received much less attention in the field of NAS.","Therefore, the main focus of zero-cost proxies is the clean accuracy of architectures, whereas the model robustness should play an evenly important part.","In this paper, we analyze the ability of common zero-cost proxies to serve as performance predictors for robustness in the popular NAS-Bench-201 search space.","We are interested in the single prediction task for robustness and the joint multi-objective of clean and robust accuracy.","We further analyze the feature importance of the proxies and show that predicting the robustness makes the prediction task from existing zero-cost proxies more challenging.","As a result, the joint consideration of several proxies becomes necessary to predict a model's robustness while the clean accuracy can be regressed from a single such feature."],"url":"http://arxiv.org/abs/2307.09365v1"}
{"created":"2023-07-18 15:48:37","title":"Local Minima Drive Communications in Cooperative Interaction","abstract":"An important open question in human-robot interaction (HRI) is precisely when an agent should decide to communicate, particularly in a cooperative task. Perceptual Control Theory (PCT) tells us that agents are able to cooperate on a joint task simply by sharing the same 'intention', thereby distributing the effort required to complete the task among the agents. This is even true for agents that do not possess the same abilities, so long as the goal is observable, the combined actions are sufficient to complete the task, and there is no local minimum in the search space. If these conditions hold, then a cooperative task can be accomplished without any communication between the contributing agents. However, for tasks that do contain local minima, the global solution can only be reached if at least one of the agents adapts its intention at the appropriate moments, and this can only be achieved by appropriately timed communication. In other words, it is hypothesised that in cooperative tasks, the function of communication is to coordinate actions in a complex search space that contains local minima. These principles have been verified in a computer-based simulation environment in which two independent one-dimensional agents are obliged to cooperate in order to solve a two-dimensional path-finding task.","sentences":["An important open question in human-robot interaction (HRI) is precisely when an agent should decide to communicate, particularly in a cooperative task.","Perceptual Control Theory (PCT) tells us that agents are able to cooperate on a joint task simply by sharing the same 'intention', thereby distributing the effort required to complete the task among the agents.","This is even true for agents that do not possess the same abilities, so long as the goal is observable, the combined actions are sufficient to complete the task, and there is no local minimum in the search space.","If these conditions hold, then a cooperative task can be accomplished without any communication between the contributing agents.","However, for tasks that do contain local minima, the global solution can only be reached if at least one of the agents adapts its intention at the appropriate moments, and this can only be achieved by appropriately timed communication.","In other words, it is hypothesised that in cooperative tasks, the function of communication is to coordinate actions in a complex search space that contains local minima.","These principles have been verified in a computer-based simulation environment in which two independent one-dimensional agents are obliged to cooperate in order to solve a two-dimensional path-finding task."],"url":"http://arxiv.org/abs/2307.09364v1"}
{"created":"2023-07-18 15:46:21","title":"Disentangle then Parse:Night-time Semantic Segmentation with Illumination Disentanglement","abstract":"Most prior semantic segmentation methods have been developed for day-time scenes, while typically underperforming in night-time scenes due to insufficient and complicated lighting conditions. In this work, we tackle this challenge by proposing a novel night-time semantic segmentation paradigm, i.e., disentangle then parse (DTP). DTP explicitly disentangles night-time images into light-invariant reflectance and light-specific illumination components and then recognizes semantics based on their adaptive fusion. Concretely, the proposed DTP comprises two key components: 1) Instead of processing lighting-entangled features as in prior works, our Semantic-Oriented Disentanglement (SOD) framework enables the extraction of reflectance component without being impeded by lighting, allowing the network to consistently recognize the semantics under cover of varying and complicated lighting conditions. 2) Based on the observation that the illumination component can serve as a cue for some semantically confused regions, we further introduce an Illumination-Aware Parser (IAParser) to explicitly learn the correlation between semantics and lighting, and aggregate the illumination features to yield more precise predictions. Extensive experiments on the night-time segmentation task with various settings demonstrate that DTP significantly outperforms state-of-the-art methods. Furthermore, with negligible additional parameters, DTP can be directly used to benefit existing day-time methods for night-time segmentation.","sentences":["Most prior semantic segmentation methods have been developed for day-time scenes, while typically underperforming in night-time scenes due to insufficient and complicated lighting conditions.","In this work, we tackle this challenge by proposing a novel night-time semantic segmentation paradigm, i.e., disentangle then parse (DTP).","DTP explicitly disentangles night-time images into light-invariant reflectance and light-specific illumination components and then recognizes semantics based on their adaptive fusion.","Concretely, the proposed DTP comprises two key components: 1) Instead of processing lighting-entangled features as in prior works, our Semantic-Oriented Disentanglement (SOD) framework enables the extraction of reflectance component without being impeded by lighting, allowing the network to consistently recognize the semantics under cover of varying and complicated lighting conditions.","2) Based on the observation that the illumination component can serve as a cue for some semantically confused regions, we further introduce an Illumination-Aware Parser (IAParser) to explicitly learn the correlation between semantics and lighting, and aggregate the illumination features to yield more precise predictions.","Extensive experiments on the night-time segmentation task with various settings demonstrate that DTP significantly outperforms state-of-the-art methods.","Furthermore, with negligible additional parameters, DTP can be directly used to benefit existing day-time methods for night-time segmentation."],"url":"http://arxiv.org/abs/2307.09362v1"}
{"created":"2023-07-18 15:46:20","title":"MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments","abstract":"Self-supervised learning can be used for mitigating the greedy needs of Vision Transformer networks for very large fully-annotated datasets. Different classes of self-supervised learning offer representations with either good contextual reasoning properties, e.g., using masked image modeling strategies, or invariance to image perturbations, e.g., with contrastive methods. In this work, we propose a single-stage and standalone method, MOCA, which unifies both desired properties using novel mask-and-predict objectives defined with high-level features (instead of pixel-level details). Moreover, we show how to effectively employ both learning paradigms in a synergistic and computation-efficient way. Doing so, we achieve new state-of-the-art results on low-shot settings and strong experimental results in various evaluation protocols with a training that is at least 3 times faster than prior methods.","sentences":["Self-supervised learning can be used for mitigating the greedy needs of Vision Transformer networks for very large fully-annotated datasets.","Different classes of self-supervised learning offer representations with either good contextual reasoning properties, e.g., using masked image modeling strategies, or invariance to image perturbations, e.g., with contrastive methods.","In this work, we propose a single-stage and standalone method, MOCA, which unifies both desired properties using novel mask-and-predict objectives defined with high-level features (instead of pixel-level details).","Moreover, we show how to effectively employ both learning paradigms in a synergistic and computation-efficient way.","Doing so, we achieve new state-of-the-art results on low-shot settings and strong experimental results in various evaluation protocols with a training that is at least 3 times faster than prior methods."],"url":"http://arxiv.org/abs/2307.09361v1"}
{"created":"2023-07-18 15:44:24","title":"Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural Network Training and Inference","abstract":"Analog In-Memory Computing (AIMC) is a promising approach to reduce the latency and energy consumption of Deep Neural Network (DNN) inference and training. However, the noisy and non-linear device characteristics, and the non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be deployed on such hardware to achieve equivalent accuracy to digital computing. In this tutorial, we provide a deep dive into how such adaptations can be achieved and evaluated using the recently released IBM Analog Hardware Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit. The AIHWKit is a Python library that simulates inference and training of DNNs using AIMC. We present an in-depth description of the AIHWKit design, functionality, and best practices to properly perform inference and training. We also present an overview of the Analog AI Cloud Composer, that provides the benefits of using the AIHWKit simulation platform in a fully managed cloud setting. Finally, we show examples on how users can expand and customize AIHWKit for their own needs. This tutorial is accompanied by comprehensive Jupyter Notebook code examples that can be run using AIHWKit, which can be downloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.","sentences":["Analog In-Memory Computing (AIMC) is a promising approach to reduce the latency and energy consumption of Deep Neural Network (DNN) inference and training.","However, the noisy and non-linear device characteristics, and the non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be deployed on such hardware to achieve equivalent accuracy to digital computing.","In this tutorial, we provide a deep dive into how such adaptations can be achieved and evaluated using the recently released IBM Analog Hardware Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit.","The AIHWKit is a Python library that simulates inference and training of DNNs using AIMC.","We present an in-depth description of the AIHWKit design, functionality, and best practices to properly perform inference and training.","We also present an overview of the Analog AI Cloud Composer, that provides the benefits of using the AIHWKit simulation platform in a fully managed cloud setting.","Finally, we show examples on how users can expand and customize AIHWKit for their own needs.","This tutorial is accompanied by comprehensive Jupyter Notebook code examples that can be run using AIHWKit, which can be downloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial."],"url":"http://arxiv.org/abs/2307.09357v1"}
{"created":"2023-07-18 15:43:35","title":"OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation","abstract":"Referring video object segmentation (RVOS) aims at segmenting an object in a video following human instruction. Current state-of-the-art methods fall into an offline pattern, in which each clip independently interacts with text embedding for cross-modal understanding. They usually present that the offline pattern is necessary for RVOS, yet model limited temporal association within each clip. In this work, we break up the previous offline belief and propose a simple yet effective online model using explicit query propagation, named OnlineRefer. Specifically, our approach leverages target cues that gather semantic information and position prior to improve the accuracy and ease of referring predictions for the current frame. Furthermore, we generalize our online model into a semi-online framework to be compatible with video-based backbones. To show the effectiveness of our method, we evaluate it on four benchmarks, \\ie, Refer-Youtube-VOS, Refer-DAVIS17, A2D-Sentences, and JHMDB-Sentences. Without bells and whistles, our OnlineRefer with a Swin-L backbone achieves 63.5 J&F and 64.8 J&F on Refer-Youtube-VOS and Refer-DAVIS17, outperforming all other offline methods.","sentences":["Referring video object segmentation (RVOS) aims at segmenting an object in a video following human instruction.","Current state-of-the-art methods fall into an offline pattern, in which each clip independently interacts with text embedding for cross-modal understanding.","They usually present that the offline pattern is necessary for RVOS, yet model limited temporal association within each clip.","In this work, we break up the previous offline belief and propose a simple yet effective online model using explicit query propagation, named OnlineRefer.","Specifically, our approach leverages target cues that gather semantic information and position prior to improve the accuracy and ease of referring predictions for the current frame.","Furthermore, we generalize our online model into a semi-online framework to be compatible with video-based backbones.","To show the effectiveness of our method, we evaluate it on four benchmarks, \\ie, Refer-Youtube-VOS, Refer-DAVIS17, A2D-Sentences, and JHMDB-Sentences.","Without bells and whistles, our OnlineRefer with a Swin-L backbone achieves 63.5 J&F and 64.8 J&F on Refer-Youtube-VOS and Refer-DAVIS17, outperforming all other offline methods."],"url":"http://arxiv.org/abs/2307.09356v1"}
{"created":"2023-07-18 15:37:35","title":"SphereNet: Learning a Noise-Robust and General Descriptor for Point Cloud Registration","abstract":"Point cloud registration is to estimate a transformation to align point clouds collected in different perspectives. In learning-based point cloud registration, a robust descriptor is vital for high-accuracy registration. However, most methods are susceptible to noise and have poor generalization ability on unseen datasets. Motivated by this, we introduce SphereNet to learn a noise-robust and unseen-general descriptor for point cloud registration. In our method, first, the spheroid generator builds a geometric domain based on spherical voxelization to encode initial features. Then, the spherical interpolation of the sphere is introduced to realize robustness against noise. Finally, a new spherical convolutional neural network with spherical integrity padding completes the extraction of descriptors, which reduces the loss of features and fully captures the geometric features. To evaluate our methods, a new benchmark 3DMatch-noise with strong noise is introduced. Extensive experiments are carried out on both indoor and outdoor datasets. Under high-intensity noise, SphereNet increases the feature matching recall by more than 25 percentage points on 3DMatch-noise. In addition, it sets a new state-of-the-art performance for the 3DMatch and 3DLoMatch benchmarks with 93.5\\% and 75.6\\% registration recall and also has the best generalization ability on unseen datasets.","sentences":["Point cloud registration is to estimate a transformation to align point clouds collected in different perspectives.","In learning-based point cloud registration, a robust descriptor is vital for high-accuracy registration.","However, most methods are susceptible to noise and have poor generalization ability on unseen datasets.","Motivated by this, we introduce SphereNet to learn a noise-robust and unseen-general descriptor for point cloud registration.","In our method, first, the spheroid generator builds a geometric domain based on spherical voxelization to encode initial features.","Then, the spherical interpolation of the sphere is introduced to realize robustness against noise.","Finally, a new spherical convolutional neural network with spherical integrity padding completes the extraction of descriptors, which reduces the loss of features and fully captures the geometric features.","To evaluate our methods, a new benchmark 3DMatch-noise with strong noise is introduced.","Extensive experiments are carried out on both indoor and outdoor datasets.","Under high-intensity noise, SphereNet increases the feature matching recall by more than 25 percentage points on 3DMatch-noise.","In addition, it sets a new state-of-the-art performance for the 3DMatch and 3DLoMatch benchmarks with 93.5\\% and 75.6\\% registration recall and also has the best generalization ability on unseen datasets."],"url":"http://arxiv.org/abs/2307.09351v1"}
{"created":"2023-07-18 15:36:59","title":"The Role of Dimension in the Online Chasing Problem","abstract":"Let $(X, d)$ be a metric space and $\\mathcal{C} \\subseteq 2^X$ -- a collection of special objects. In the $(X,d,\\mathcal{C})$-chasing problem, an online player receives a sequence of online requests $\\{B_t\\}_{t=1}^T \\subseteq \\mathcal{C}$ and responds with a trajectory $\\{x_t\\}_{t=1}^T$ such that $x_t \\in B_t$. This response incurs a movement cost $\\sum_{t=1}^T d(x_t, x_{t-1})$, and the online player strives to minimize the competitive ratio -- the worst case ratio over all input sequences between the online movement cost and the optimal movement cost in hindsight. Under this setup, we call the $(X,d,\\mathcal{C})$-chasing problem $\\textit{chaseable}$ if there exists an online algorithm with finite competitive ratio. In the case of Convex Body Chasing (CBC) over real normed vector spaces, (Bubeck et al. 2019) proved the chaseability of the problem. Furthermore, in the vector space setting, the dimension of the ambient space appears to be the factor controlling the size of the competitive ratio. Indeed, recently, (Sellke 2020) provided a $d-$competitive online algorithm over arbitrary real normed vector spaces $(\\mathbb{R}^d, ||\\cdot||)$, and we will shortly present a general strategy for obtaining novel lower bounds of the form $\\Omega(d^c), \\enspace c > 0$, for CBC in the same setting. In this paper, we also prove that the $\\textit{doubling}$ and $\\textit{Assouad}$ dimensions of a metric space exert no control on the hardness of ball chasing over the said metric space. More specifically, we show that for any large enough $\\rho \\in \\mathbb{R}$, there exists a metric space $(X,d)$ of doubling dimension $\\Theta(\\rho)$ and Assouad dimension $\\rho$ such that no online selector can achieve a finite competitive ratio in the general ball chasing regime.","sentences":["Let $(X, d)$ be a metric space and $\\mathcal{C} \\subseteq 2^X$ -- a collection of special objects.","In the $(X,d,\\mathcal{C})$-chasing problem, an online player receives a sequence of online requests $\\{B_t\\}_{t=1}^T \\subseteq \\mathcal{C}$ and responds with a trajectory $\\{x_t\\}_{t=1}^T$ such that $x_t \\in B_t$. This response incurs a movement cost $\\sum_{t=1}^T d(x_t, x_{t-1})$, and the online player strives to minimize the competitive ratio -- the worst case ratio over all input sequences between the online movement cost and the optimal movement cost in hindsight.","Under this setup, we call the $(X,d,\\mathcal{C})$-chasing problem $\\textit{chaseable}$ if there exists an online algorithm with finite competitive ratio.","In the case of Convex Body Chasing (CBC) over real normed vector spaces, (Bubeck et al. 2019) proved the chaseability of the problem.","Furthermore, in the vector space setting, the dimension of the ambient space appears to be the factor controlling the size of the competitive ratio.","Indeed, recently, (Sellke 2020) provided a $d-$competitive online algorithm over arbitrary real normed vector spaces $(\\mathbb{R}^d, ||\\cdot||)$, and we will shortly present a general strategy for obtaining novel lower bounds of the form $\\Omega(d^c), \\enspace c > 0$, for CBC in the same setting.","In this paper, we also prove that the $\\textit{doubling}$ and $\\textit{Assouad}$ dimensions of a metric space exert no control on the hardness of ball chasing over the said metric space.","More specifically, we show that for any large enough $\\rho \\in \\mathbb{R}$, there exists a metric space $(X,d)$ of doubling dimension $\\Theta(\\rho)$ and Assouad dimension $\\rho$ such that no online selector can achieve a finite competitive ratio in the general ball chasing regime."],"url":"http://arxiv.org/abs/2307.09350v1"}
{"created":"2023-07-18 15:36:07","title":"A generic characterization of generalized unary temporal logic and two-variable first-order logic","abstract":"We investigate an operator on classes of languages. For each class $C$, it outputs a new class $FO^2(I_C)$ associated with a variant of two-variable first-order logic equipped with a signature$I_C$ built from $C$. For $C = \\{\\emptyset, A^*\\}$, we get the variant $FO^2(<)$ equipped with the linear order. For $C = \\{\\emptyset, \\{\\varepsilon\\},A^+, A^*\\}$, we get the variant $FO^2(<,+1)$, which also includes the successor. If $C$ consists of all Boolean combinations of languages $A^*aA^*$ where $a$ is a letter, we get the variant $FO^2(<,Bet)$, which also includes ``between relations''. We prove a generic algebraic characterization of the classes $FO^2(I_C)$. It smoothly and elegantly generalizes the known ones for all aforementioned cases. Moreover, it implies that if $C$ has decidable separation (plus mild properties), then $FO^2(I_C)$ has a decidable membership problem.   We actually work with an equivalent definition of \\fodc in terms of unary temporal logic. For each class $C$, we consider a variant $TL(C)$ of unary temporal logic whose future/past modalities depend on $C$ and such that $TL(C) = FO^2(I_C)$. Finally, we also characterize $FL(C)$ and $PL(C)$, the pure-future and pure-past restrictions of $TL(C)$. These characterizations as well imply that if \\Cs is a class with decidable separation, then $FL(C)$ and $PL(C)$ have decidable membership.","sentences":["We investigate an operator on classes of languages.","For each class $C$, it outputs a new class $FO^2(I_C)$ associated with a variant of two-variable first-order logic equipped with a signature$I_C$ built from $C$.","For $C = \\{\\emptyset, A^*\\}$, we get the variant $FO^2(<)$ equipped with the linear order.","For $C = \\{\\emptyset, \\{\\varepsilon\\},A^+, A^*\\}$, we get the variant $FO^2(<,+1)$, which also includes the successor.","If $C$ consists of all Boolean combinations of languages $A^*aA^*$ where $a$ is a letter, we get the variant $FO^2(<,Bet)$, which also includes ``between relations''.","We prove a generic algebraic characterization of the classes $FO^2(I_C)$. It smoothly and elegantly generalizes the known ones for all aforementioned cases.","Moreover, it implies that if $C$ has decidable separation (plus mild properties), then $FO^2(I_C)$ has a decidable membership problem.   ","We actually work with an equivalent definition of \\fodc in terms of unary temporal logic.","For each class $C$, we consider a variant $TL(C)$ of unary temporal logic whose future/past modalities depend on $C$ and such that $TL(C) =","FO^2(I_C)$. Finally, we also characterize $FL(C)$ and $PL(C)$, the pure-future and pure-past restrictions of $TL(C)$. These characterizations as well imply that if \\Cs is a class with decidable separation, then $FL(C)$ and $PL(C)$ have decidable membership."],"url":"http://arxiv.org/abs/2307.09349v1"}
{"created":"2023-07-18 15:26:46","title":"Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints","abstract":"Many constraint satisfaction and optimisation problems can be solved effectively by encoding them as instances of the Boolean Satisfiability problem (SAT). However, even the simplest types of constraints have many encodings in the literature with widely varying performance, and the problem of selecting suitable encodings for a given problem instance is not trivial. We explore the problem of selecting encodings for pseudo-Boolean and linear constraints using a supervised machine learning approach. We show that it is possible to select encodings effectively using a standard set of features for constraint problems; however we obtain better performance with a new set of features specifically designed for the pseudo-Boolean and linear constraints. In fact, we achieve good results when selecting encodings for unseen problem classes. Our results compare favourably to AutoFolio when using the same feature set. We discuss the relative importance of instance features to the task of selecting the best encodings, and compare several variations of the machine learning method.","sentences":["Many constraint satisfaction and optimisation problems can be solved effectively by encoding them as instances of the Boolean Satisfiability problem (SAT).","However, even the simplest types of constraints have many encodings in the literature with widely varying performance, and the problem of selecting suitable encodings for a given problem instance is not trivial.","We explore the problem of selecting encodings for pseudo-Boolean and linear constraints using a supervised machine learning approach.","We show that it is possible to select encodings effectively using a standard set of features for constraint problems; however we obtain better performance with a new set of features specifically designed for the pseudo-Boolean and linear constraints.","In fact, we achieve good results when selecting encodings for unseen problem classes.","Our results compare favourably to AutoFolio when using the same feature set.","We discuss the relative importance of instance features to the task of selecting the best encodings, and compare several variations of the machine learning method."],"url":"http://arxiv.org/abs/2307.09342v1"}
{"created":"2023-07-18 15:26:09","title":"Trajectory Data Collection with Local Differential Privacy","abstract":"Trajectory data collection is a common task with many applications in our daily lives. Analyzing trajectory data enables service providers to enhance their services, which ultimately benefits users. However, directly collecting trajectory data may give rise to privacy-related issues that cannot be ignored. Local differential privacy (LDP), as the de facto privacy protection standard in a decentralized setting, enables users to perturb their trajectories locally and provides a provable privacy guarantee. Existing approaches to private trajectory data collection in a local setting typically use relaxed versions of LDP, which cannot provide a strict privacy guarantee, or require some external knowledge that is impractical to obtain and update in a timely manner. To tackle these problems, we propose a novel trajectory perturbation mechanism that relies solely on an underlying location set and satisfies pure $\\epsilon$-LDP to provide a stringent privacy guarantee. In the proposed mechanism, each point's adjacent direction information in the trajectory is used in its perturbation process. Such information serves as an effective clue to connect neighboring points and can be used to restrict the possible region of a perturbed point in order to enhance utility. To the best of our knowledge, our study is the first to use direction information for trajectory perturbation under LDP. Furthermore, based on this mechanism, we present an anchor-based method that adaptively restricts the region of each perturbed trajectory, thereby significantly boosting performance without violating the privacy constraint. Extensive experiments on both real-world and synthetic datasets demonstrate the effectiveness of the proposed mechanisms.","sentences":["Trajectory data collection is a common task with many applications in our daily lives.","Analyzing trajectory data enables service providers to enhance their services, which ultimately benefits users.","However, directly collecting trajectory data may give rise to privacy-related issues that cannot be ignored.","Local differential privacy (LDP), as the de facto privacy protection standard in a decentralized setting, enables users to perturb their trajectories locally and provides a provable privacy guarantee.","Existing approaches to private trajectory data collection in a local setting typically use relaxed versions of LDP, which cannot provide a strict privacy guarantee, or require some external knowledge that is impractical to obtain and update in a timely manner.","To tackle these problems, we propose a novel trajectory perturbation mechanism that relies solely on an underlying location set and satisfies pure $\\epsilon$-LDP to provide a stringent privacy guarantee.","In the proposed mechanism, each point's adjacent direction information in the trajectory is used in its perturbation process.","Such information serves as an effective clue to connect neighboring points and can be used to restrict the possible region of a perturbed point in order to enhance utility.","To the best of our knowledge, our study is the first to use direction information for trajectory perturbation under LDP.","Furthermore, based on this mechanism, we present an anchor-based method that adaptively restricts the region of each perturbed trajectory, thereby significantly boosting performance without violating the privacy constraint.","Extensive experiments on both real-world and synthetic datasets demonstrate the effectiveness of the proposed mechanisms."],"url":"http://arxiv.org/abs/2307.09339v1"}
{"created":"2023-07-18 15:14:10","title":"$\\mathcal{P}$-matchings Parameterized by Treewidth","abstract":"A \\emph{matching} is a subset of edges in a graph $G$ that do not share an endpoint. A matching $M$ is a \\emph{$\\mathcal{P}$-matching} if the subgraph of $G$ induced by the endpoints of the edges of $M$ satisfies property $\\mathcal{P}$. For example, if the property $\\mathcal{P}$ is that of being a matching, being acyclic, or being disconnected, then we obtain an \\emph{induced matching}, an \\emph{acyclic matching}, and a \\emph{disconnected matching}, respectively. In this paper, we analyze the problems of the computation of these matchings from the viewpoint of Parameterized Complexity with respect to the parameter \\emph{treewidth}.","sentences":["A \\emph{matching} is a subset of edges in a graph $G$ that do not share an endpoint.","A matching $M$ is a \\emph{$\\mathcal{P}$-matching} if the subgraph of $G$ induced by the endpoints of the edges of $M$ satisfies property $\\mathcal{P}$. For example, if the property $\\mathcal{P}$ is that of being a matching, being acyclic, or being disconnected, then we obtain an \\emph{induced matching}, an \\emph{acyclic matching}, and a \\emph{disconnected matching}, respectively.","In this paper, we analyze the problems of the computation of these matchings from the viewpoint of Parameterized Complexity with respect to the parameter \\emph{treewidth}."],"url":"http://arxiv.org/abs/2307.09333v1"}
{"created":"2023-07-18 15:14:09","title":"Company2Vec -- German Company Embeddings based on Corporate Websites","abstract":"With Company2Vec, the paper proposes a novel application in representation learning. The model analyzes business activities from unstructured company website data using Word2Vec and dimensionality reduction. Company2Vec maintains semantic language structures and thus creates efficient company embeddings in fine-granular industries. These semantic embeddings can be used for various applications in banking. Direct relations between companies and words allow semantic business analytics (e.g. top-n words for a company). Furthermore, industry prediction is presented as a supervised learning application and evaluation method. The vectorized structure of the embeddings allows measuring companies similarities with the cosine distance. Company2Vec hence offers a more fine-grained comparison of companies than the standard industry labels (NACE). This property is relevant for unsupervised learning tasks, such as clustering. An alternative industry segmentation is shown with k-means clustering on the company embeddings. Finally, this paper proposes three algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric peer-firm identification.","sentences":["With Company2Vec, the paper proposes a novel application in representation learning.","The model analyzes business activities from unstructured company website data using Word2Vec and dimensionality reduction.","Company2Vec maintains semantic language structures and thus creates efficient company embeddings in fine-granular industries.","These semantic embeddings can be used for various applications in banking.","Direct relations between companies and words allow semantic business analytics (e.g. top-n words for a company).","Furthermore, industry prediction is presented as a supervised learning application and evaluation method.","The vectorized structure of the embeddings allows measuring companies similarities with the cosine distance.","Company2Vec hence offers a more fine-grained comparison of companies than the standard industry labels (NACE).","This property is relevant for unsupervised learning tasks, such as clustering.","An alternative industry segmentation is shown with k-means clustering on the company embeddings.","Finally, this paper proposes three algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric peer-firm identification."],"url":"http://arxiv.org/abs/2307.09332v1"}
{"created":"2023-07-18 15:13:15","title":"Visual Validation versus Visual Estimation: A Study on the Average Value in Scatterplots","abstract":"We investigate the ability of individuals to visually validate statistical models in terms of their fit to the data. While visual model estimation has been studied extensively, visual model validation remains under-investigated. It is unknown how well people are able to visually validate models, and how their performance compares to visual and computational estimation. As a starting point, we conducted a study across two populations (crowdsourced and volunteers). Participants had to both visually estimate (i.e, draw) and visually validate (i.e., accept or reject) the frequently studied model of averages. Across both populations, the level of accuracy of the models that were considered valid was lower than the accuracy of the estimated models. We find that participants' validation and estimation were unbiased. Moreover, their natural critical point between accepting and rejecting a given mean value is close to the boundary of its 95% confidence interval, indicating that the visually perceived confidence interval corresponds to a common statistical standard. Our work contributes to the understanding of visual model validation and opens new research opportunities.","sentences":["We investigate the ability of individuals to visually validate statistical models in terms of their fit to the data.","While visual model estimation has been studied extensively, visual model validation remains under-investigated.","It is unknown how well people are able to visually validate models, and how their performance compares to visual and computational estimation.","As a starting point, we conducted a study across two populations (crowdsourced and volunteers).","Participants had to both visually estimate (i.e, draw) and visually validate (i.e., accept or reject) the frequently studied model of averages.","Across both populations, the level of accuracy of the models that were considered valid was lower than the accuracy of the estimated models.","We find that participants' validation and estimation were unbiased.","Moreover, their natural critical point between accepting and rejecting a given mean value is close to the boundary of its 95% confidence interval, indicating that the visually perceived confidence interval corresponds to a common statistical standard.","Our work contributes to the understanding of visual model validation and opens new research opportunities."],"url":"http://arxiv.org/abs/2307.09330v1"}
{"created":"2023-07-18 15:11:40","title":"Towards a performance analysis on pre-trained Visual Question Answering models for autonomous driving","abstract":"This short paper presents a preliminary analysis of three popular Visual Question Answering (VQA) models, namely ViLBERT, ViLT, and LXMERT, in the context of answering questions relating to driving scenarios. The performance of these models is evaluated by comparing the similarity of responses to reference answers provided by computer vision experts. Model selection is predicated on the analysis of transformer utilization in multimodal architectures. The results indicate that models incorporating cross-modal attention and late fusion techniques exhibit promising potential for generating improved answers within a driving perspective. This initial analysis serves as a launchpad for a forthcoming comprehensive comparative study involving nine VQA models and sets the scene for further investigations into the effectiveness of VQA model queries in self-driving scenarios. Supplementary material is available at https://github.com/KaavyaRekanar/Towards-a-performance-analysis-on-pre-trained-VQA-models-for-autonomous-driving.","sentences":["This short paper presents a preliminary analysis of three popular Visual Question Answering (VQA) models, namely ViLBERT, ViLT, and LXMERT, in the context of answering questions relating to driving scenarios.","The performance of these models is evaluated by comparing the similarity of responses to reference answers provided by computer vision experts.","Model selection is predicated on the analysis of transformer utilization in multimodal architectures.","The results indicate that models incorporating cross-modal attention and late fusion techniques exhibit promising potential for generating improved answers within a driving perspective.","This initial analysis serves as a launchpad for a forthcoming comprehensive comparative study involving nine VQA models and sets the scene for further investigations into the effectiveness of VQA model queries in self-driving scenarios.","Supplementary material is available at https://github.com/KaavyaRekanar/Towards-a-performance-analysis-on-pre-trained-VQA-models-for-autonomous-driving."],"url":"http://arxiv.org/abs/2307.09329v1"}
{"created":"2023-07-18 15:07:39","title":"Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis","abstract":"This paper presents ER-NeRF, a novel conditional Neural Radiance Fields (NeRF) based architecture for talking portrait synthesis that can concurrently achieve fast convergence, real-time rendering, and state-of-the-art performance with small model size. Our idea is to explicitly exploit the unequal contribution of spatial regions to guide talking portrait modeling. Specifically, to improve the accuracy of dynamic head reconstruction, a compact and expressive NeRF-based Tri-Plane Hash Representation is introduced by pruning empty spatial regions with three planar hash encoders. For speech audio, we propose a Region Attention Module to generate region-aware condition feature via an attention mechanism. Different from existing methods that utilize an MLP-based encoder to learn the cross-modal relation implicitly, the attention mechanism builds an explicit connection between audio features and spatial regions to capture the priors of local motions. Moreover, a direct and fast Adaptive Pose Encoding is introduced to optimize the head-torso separation problem by mapping the complex transformation of the head pose into spatial coordinates. Extensive experiments demonstrate that our method renders better high-fidelity and audio-lips synchronized talking portrait videos, with realistic details and high efficiency compared to previous methods.","sentences":["This paper presents ER-NeRF, a novel conditional Neural Radiance Fields (NeRF) based architecture for talking portrait synthesis that can concurrently achieve fast convergence, real-time rendering, and state-of-the-art performance with small model size.","Our idea is to explicitly exploit the unequal contribution of spatial regions to guide talking portrait modeling.","Specifically, to improve the accuracy of dynamic head reconstruction, a compact and expressive NeRF-based Tri-Plane Hash Representation is introduced by pruning empty spatial regions with three planar hash encoders.","For speech audio, we propose a Region Attention Module to generate region-aware condition feature via an attention mechanism.","Different from existing methods that utilize an MLP-based encoder to learn the cross-modal relation implicitly, the attention mechanism builds an explicit connection between audio features and spatial regions to capture the priors of local motions.","Moreover, a direct and fast Adaptive Pose Encoding is introduced to optimize the head-torso separation problem by mapping the complex transformation of the head pose into spatial coordinates.","Extensive experiments demonstrate that our method renders better high-fidelity and audio-lips synchronized talking portrait videos, with realistic details and high efficiency compared to previous methods."],"url":"http://arxiv.org/abs/2307.09323v1"}
{"created":"2023-07-18 15:06:35","title":"A New Hybrid Cryptosystem Involving DNA,Rabin, One Time Pad and Fiestel","abstract":"Information security is a crucial need in the modern world. Data security is a real concern, and many customers and organizations need to protect their sensitive information from unauthorized parties and attackers. In previous years, numerous cryptographic schemes have been proposed. DNA cryptography is a new and developing field that combines the computational and biological worlds. DNA cryptography is intriguing due to its high storage capacity, secure data transport, and massive parallel computing. In this paper, a new combination is proposed that offers good security by combining DNA, the Rabin algorithm, one time pad, and a structure inspired by Fiestel. This algorithm employs two keys. The first key is a DNA OTP key which is used for only one secure communication session. The second key, which combines the public and private keys, is a Rabin key. Additionally, by using a Feistel inspired scheme and randomness provided by DNA, the ciphertext is made harder to obtain without the private key.","sentences":["Information security is a crucial need in the modern world.","Data security is a real concern, and many customers and organizations need to protect their sensitive information from unauthorized parties and attackers.","In previous years, numerous cryptographic schemes have been proposed.","DNA cryptography is a new and developing field that combines the computational and biological worlds.","DNA cryptography is intriguing due to its high storage capacity, secure data transport, and massive parallel computing.","In this paper, a new combination is proposed that offers good security by combining DNA, the Rabin algorithm, one time pad, and a structure inspired by Fiestel.","This algorithm employs two keys.","The first key is a DNA OTP key which is used for only one secure communication session.","The second key, which combines the public and private keys, is a Rabin key.","Additionally, by using a Feistel inspired scheme and randomness provided by DNA, the ciphertext is made harder to obtain without the private key."],"url":"http://arxiv.org/abs/2307.09322v1"}
{"created":"2023-07-18 15:03:56","title":"Exploiting Field Dependencies for Learning on Categorical Data","abstract":"Traditional approaches for learning on categorical data underexploit the dependencies between columns (\\aka fields) in a dataset because they rely on the embedding of data points driven alone by the classification/regression loss. In contrast, we propose a novel method for learning on categorical data with the goal of exploiting dependencies between fields. Instead of modelling statistics of features globally (i.e., by the covariance matrix of features), we learn a global field dependency matrix that captures dependencies between fields and then we refine the global field dependency matrix at the instance-wise level with different weights (so-called local dependency modelling) w.r.t. each field to improve the modelling of the field dependencies. Our algorithm exploits the meta-learning paradigm, i.e., the dependency matrices are refined in the inner loop of the meta-learning algorithm without the use of labels, whereas the outer loop intertwines the updates of the embedding matrix (the matrix performing projection) and global dependency matrix in a supervised fashion (with the use of labels). Our method is simple yet it outperforms several state-of-the-art methods on six popular dataset benchmarks. Detailed ablation studies provide additional insights into our method.","sentences":["Traditional approaches for learning on categorical data underexploit the dependencies between columns (\\aka fields) in a dataset because they rely on the embedding of data points driven alone by the classification/regression loss.","In contrast, we propose a novel method for learning on categorical data with the goal of exploiting dependencies between fields.","Instead of modelling statistics of features globally (i.e., by the covariance matrix of features), we learn a global field dependency matrix that captures dependencies between fields and then we refine the global field dependency matrix at the instance-wise level with different weights (so-called local dependency modelling)","w.r.t.","each field to improve the modelling of the field dependencies.","Our algorithm exploits the meta-learning paradigm, i.e., the dependency matrices are refined in the inner loop of the meta-learning algorithm without the use of labels, whereas the outer loop intertwines the updates of the embedding matrix (the matrix performing projection) and global dependency matrix in a supervised fashion (with the use of labels).","Our method is simple yet it outperforms several state-of-the-art methods on six popular dataset benchmarks.","Detailed ablation studies provide additional insights into our method."],"url":"http://arxiv.org/abs/2307.09321v1"}
{"created":"2023-07-18 15:03:40","title":"Biomaker CA: a Biome Maker project using Cellular Automata","abstract":"We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA). In Biomaker CA, morphogenesis is a first class citizen and small seeds need to grow into plant-like organisms to survive in a nutrient starved environment and eventually reproduce with variation so that a biome survives for long timelines. We simulate complex biomes by means of CA rules in 2D grids and parallelize all of its computation on GPUs through the Python JAX framework. We show how this project allows for several different kinds of environments and laws of 'physics', alongside different model architectures and mutation strategies. We further analyze some configurations to show how plant agents can grow, survive, reproduce, and evolve, forming stable and unstable biomes. We then demonstrate how one can meta-evolve models to survive in a harsh environment either through end-to-end meta-evolution or by a more surgical and efficient approach, called Petri dish meta-evolution. Finally, we show how to perform interactive evolution, where the user decides how to evolve a plant model interactively and then deploys it in a larger environment. We open source Biomaker CA at: https://tinyurl.com/2x8yu34s .","sentences":["We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA).","In Biomaker CA, morphogenesis is a first class citizen and small seeds need to grow into plant-like organisms to survive in a nutrient starved environment and eventually reproduce with variation so that a biome survives for long timelines.","We simulate complex biomes by means of CA rules in 2D grids and parallelize all of its computation on GPUs through the Python JAX framework.","We show how this project allows for several different kinds of environments and laws of 'physics', alongside different model architectures and mutation strategies.","We further analyze some configurations to show how plant agents can grow, survive, reproduce, and evolve, forming stable and unstable biomes.","We then demonstrate how one can meta-evolve models to survive in a harsh environment either through end-to-end meta-evolution or by a more surgical and efficient approach, called Petri dish meta-evolution.","Finally, we show how to perform interactive evolution, where the user decides how to evolve a plant model interactively and then deploys it in a larger environment.","We open source Biomaker CA at: https://tinyurl.com/2x8yu34s ."],"url":"http://arxiv.org/abs/2307.09320v1"}
{"created":"2023-07-18 14:59:32","title":"Measuring the Leakage and Exploitability of Authentication Secrets in Super-apps: The WeChat Case","abstract":"We conduct a large-scale measurement of developers' insecure practices leading to mini-app to super-app authentication bypass, among which hard-coding developer secrets for such authentication is a major contributor. We also analyze the exploitability and security consequences of developer secret leakage in mini-apps by examining individual super-app server-side APIs. We develop an analysis framework for measuring such secret leakage, and primarily analyze 110,993 WeChat mini-apps, and 10,000 Baidu mini-apps (two of the most prominent super-app platforms), along with a few more datasets to test the evolution of developer practices and platform security enforcement over time. We found a large number of WeChat mini-apps (36,425, 32.8%) and a few Baidu mini-apps (112) leak their developer secrets, which can cause severe security and privacy problems for the users and developers of mini-apps. A network attacker who does not even have an account on the super-app platform, can effectively take down a mini-app, send malicious and phishing links to users, and access sensitive information of the mini-app developer and its users. We responsibly disclosed our findings and also put forward potential directions that could be considered to alleviate/eliminate the root causes of developers hard-coding the app secrets in the mini-app's front-end code.","sentences":["We conduct a large-scale measurement of developers' insecure practices leading to mini-app to super-app authentication bypass, among which hard-coding developer secrets for such authentication is a major contributor.","We also analyze the exploitability and security consequences of developer secret leakage in mini-apps by examining individual super-app server-side APIs.","We develop an analysis framework for measuring such secret leakage, and primarily analyze 110,993 WeChat mini-apps, and 10,000 Baidu mini-apps (two of the most prominent super-app platforms), along with a few more datasets to test the evolution of developer practices and platform security enforcement over time.","We found a large number of WeChat mini-apps (36,425, 32.8%) and a few Baidu mini-apps (112) leak their developer secrets, which can cause severe security and privacy problems for the users and developers of mini-apps.","A network attacker who does not even have an account on the super-app platform, can effectively take down a mini-app, send malicious and phishing links to users, and access sensitive information of the mini-app developer and its users.","We responsibly disclosed our findings and also put forward potential directions that could be considered to alleviate/eliminate the root causes of developers hard-coding the app secrets in the mini-app's front-end code."],"url":"http://arxiv.org/abs/2307.09317v1"}
{"created":"2023-07-18 14:59:19","title":"MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds","abstract":"3D semantic segmentation on multi-scan large-scale point clouds plays an important role in autonomous systems. Unlike the single-scan-based semantic segmentation task, this task requires distinguishing the motion states of points in addition to their semantic categories. However, methods designed for single-scan-based segmentation tasks perform poorly on the multi-scan task due to the lacking of an effective way to integrate temporal information. We propose MarS3D, a plug-and-play motion-aware module for semantic segmentation on multi-scan 3D point clouds. This module can be flexibly combined with single-scan models to allow them to have multi-scan perception abilities. The model encompasses two key designs: the Cross-Frame Feature Embedding module for enriching representation learning and the Motion-Aware Feature Learning module for enhancing motion awareness. Extensive experiments show that MarS3D can improve the performance of the baseline model by a large margin. The code is available at https://github.com/CVMI-Lab/MarS3D.","sentences":["3D semantic segmentation on multi-scan large-scale point clouds plays an important role in autonomous systems.","Unlike the single-scan-based semantic segmentation task, this task requires distinguishing the motion states of points in addition to their semantic categories.","However, methods designed for single-scan-based segmentation tasks perform poorly on the multi-scan task due to the lacking of an effective way to integrate temporal information.","We propose MarS3D, a plug-and-play motion-aware module for semantic segmentation on multi-scan 3D point clouds.","This module can be flexibly combined with single-scan models to allow them to have multi-scan perception abilities.","The model encompasses two key designs: the Cross-Frame Feature Embedding module for enriching representation learning and the Motion-Aware Feature Learning module for enhancing motion awareness.","Extensive experiments show that MarS3D can improve the performance of the baseline model by a large margin.","The code is available at https://github.com/CVMI-Lab/MarS3D."],"url":"http://arxiv.org/abs/2307.09316v1"}
{"created":"2023-07-18 14:57:12","title":"Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media","abstract":"We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal graph-based transformer model for detecting hate speech in online social networks. In contrast to traditional text-only methods, our approach to labelling a comment as hate speech centers around the holistic analysis of text and images. This is done by leveraging graph transformers to capture the contextual relationships in the entire discussion that surrounds a comment, with interwoven fusion layers to combine text and image embeddings instead of processing different modalities separately. We compare the performance of our model to baselines that only process text; we also conduct extensive ablation studies. We conclude with future work for multimodal solutions to deliver social value in online contexts, arguing that capturing a holistic view of a conversation greatly advances the effort to detect anti-social behavior.","sentences":["We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal graph-based transformer model for detecting hate speech in online social networks.","In contrast to traditional text-only methods, our approach to labelling a comment as hate speech centers around the holistic analysis of text and images.","This is done by leveraging graph transformers to capture the contextual relationships in the entire discussion that surrounds a comment, with interwoven fusion layers to combine text and image embeddings instead of processing different modalities separately.","We compare the performance of our model to baselines that only process text; we also conduct extensive ablation studies.","We conclude with future work for multimodal solutions to deliver social value in online contexts, arguing that capturing a holistic view of a conversation greatly advances the effort to detect anti-social behavior."],"url":"http://arxiv.org/abs/2307.09312v1"}
{"created":"2023-07-18 14:56:12","title":"Automatic Differentiation for Inverse Problems with Applications in Quantum Transport","abstract":"A neural solver and differentiable simulation of the quantum transmitting boundary model is presented for the inverse quantum transport problem. The neural solver is used to engineer continuous transmission properties and the differentiable simulation is used to engineer current-voltage characteristics.","sentences":["A neural solver and differentiable simulation of the quantum transmitting boundary model is presented for the inverse quantum transport problem.","The neural solver is used to engineer continuous transmission properties and the differentiable simulation is used to engineer current-voltage characteristics."],"url":"http://arxiv.org/abs/2307.09311v1"}
{"created":"2023-07-18 14:52:54","title":"Impact of gate-level clustering on automated system partitioning of 3D-ICs","abstract":"When partitioning gate-level netlists using graphs, it is beneficial to cluster gates to reduce the order of the graph and preserve some characteristics of the circuit that the partitioning might degrade. Gate clustering is even more important for netlist partitioning targeting 3D system integration. In this paper, we make the argument that the choice of clustering method for 3D-ICs partitioning is not trivial and deserves careful consideration. To support our claim, we implemented three clustering methods that were used prior to partitioning two synthetic designs representing two extremes of the circuits medium/long interconnect diversity spectrum. Automatically partitioned netlists are then placed and routed in 3D to compare the impact of clustering methods on several metrics. From our experiments, we see that the clustering method indeed has a different impact depending on the design considered and that a circuit-blind, universal partitioning method is not the way to go, with wire-length savings of up to 31%, total power of up to 22%, and effective frequency of up to 15% compared to other methods. Furthermore, we highlight that 3D-ICs open new opportunities to design systems with a denser interconnect, drastically reducing the design utilization of circuits that would not be considered viable in 2D.","sentences":["When partitioning gate-level netlists using graphs, it is beneficial to cluster gates to reduce the order of the graph and preserve some characteristics of the circuit that the partitioning might degrade.","Gate clustering is even more important for netlist partitioning targeting 3D system integration.","In this paper, we make the argument that the choice of clustering method for 3D-ICs partitioning is not trivial and deserves careful consideration.","To support our claim, we implemented three clustering methods that were used prior to partitioning two synthetic designs representing two extremes of the circuits medium/long interconnect diversity spectrum.","Automatically partitioned netlists are then placed and routed in 3D to compare the impact of clustering methods on several metrics.","From our experiments, we see that the clustering method indeed has a different impact depending on the design considered and that a circuit-blind, universal partitioning method is not the way to go, with wire-length savings of up to 31%, total power of up to 22%, and effective frequency of up to 15% compared to other methods.","Furthermore, we highlight that 3D-ICs open new opportunities to design systems with a denser interconnect, drastically reducing the design utilization of circuits that would not be considered viable in 2D."],"url":"http://arxiv.org/abs/2307.09308v1"}
{"created":"2023-07-18 14:52:08","title":"EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting","abstract":"Capturing high-dimensional social interactions and feasible futures is essential for predicting trajectories. To address this complex nature, several attempts have been devoted to reducing the dimensionality of the output variables via parametric curve fitting such as the B\\'ezier curve and B-spline function. However, these functions, which originate in computer graphics fields, are not suitable to account for socially acceptable human dynamics. In this paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction approach that uses a novel trajectory descriptor to form a compact space, known here as $\\mathbb{ET}$ space, in place of Euclidean space, for representing pedestrian movements. We first reduce the complexity of the trajectory descriptor via a low-rank approximation. We transform the pedestrians' history paths into our $\\mathbb{ET}$ space represented by spatio-temporal principle components, and feed them into off-the-shelf trajectory forecasting models. The inputs and outputs of the models as well as social interactions are all gathered and aggregated in the corresponding $\\mathbb{ET}$ space. Lastly, we propose a trajectory anchor-based refinement method to cover all possible futures in the proposed $\\mathbb{ET}$ space. Extensive experiments demonstrate that our EigenTrajectory predictor can significantly improve both the prediction accuracy and reliability of existing trajectory forecasting models on public benchmarks, indicating that the proposed descriptor is suited to represent pedestrian behaviors. Code is publicly available at https://github.com/inhwanbae/EigenTrajectory .","sentences":["Capturing high-dimensional social interactions and feasible futures is essential for predicting trajectories.","To address this complex nature, several attempts have been devoted to reducing the dimensionality of the output variables via parametric curve fitting such as the B\\'ezier curve and B-spline function.","However, these functions, which originate in computer graphics fields, are not suitable to account for socially acceptable human dynamics.","In this paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction approach that uses a novel trajectory descriptor to form a compact space, known here as $\\mathbb{ET}$ space, in place of Euclidean space, for representing pedestrian movements.","We first reduce the complexity of the trajectory descriptor via a low-rank approximation.","We transform the pedestrians' history paths into our $\\mathbb{ET}$ space represented by spatio-temporal principle components, and feed them into off-the-shelf trajectory forecasting models.","The inputs and outputs of the models as well as social interactions are all gathered and aggregated in the corresponding $\\mathbb{ET}$ space.","Lastly, we propose a trajectory anchor-based refinement method to cover all possible futures in the proposed $\\mathbb{ET}$ space.","Extensive experiments demonstrate that our EigenTrajectory predictor can significantly improve both the prediction accuracy and reliability of existing trajectory forecasting models on public benchmarks, indicating that the proposed descriptor is suited to represent pedestrian behaviors.","Code is publicly available at https://github.com/inhwanbae/EigenTrajectory ."],"url":"http://arxiv.org/abs/2307.09306v1"}
{"created":"2023-07-18 14:40:48","title":"Conformal prediction under ambiguous ground truth","abstract":"In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability. This generally assumes the availability of a held-out calibration set with access to ground truth labels. Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions. In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet. Applying conformal prediction using such labels underestimates uncertainty. Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels. That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration. In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlying posterior distribution of labels given inputs. We demonstrate our methodology on synthetic and real datasets, including a case study of skin condition classification in dermatology.","sentences":["In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability.","This generally assumes the availability of a held-out calibration set with access to ground truth labels.","Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions.","In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet.","Applying conformal prediction using such labels underestimates uncertainty.","Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels.","That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration.","In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlying posterior distribution of labels given inputs.","We demonstrate our methodology on synthetic and real datasets, including a case study of skin condition classification in dermatology."],"url":"http://arxiv.org/abs/2307.09302v1"}
{"created":"2023-07-18 14:38:26","title":"Subfield subcodes of projective Reed-Muller codes","abstract":"Explicit bases for the subfield subcodes of projective Reed-Muller codes over the projective plane and their duals are obtained. In particular, we provide a formula for the dimension of these codes. For the general case over the projective space, we are able to generalize the necessary tools to deal with this case as well: we obtain a universal Gr\\\"obner basis for the vanishing ideal of the set of standard representatives of the projective space and we are able to reduce any monomial with respect to this Gr\\\"obner basis. With respect to the parameters of these codes, by considering subfield subcodes of projective Reed-Muller codes we are able to obtain long linear codes with good parameters over a small finite field.","sentences":["Explicit bases for the subfield subcodes of projective Reed-Muller codes over the projective plane and their duals are obtained.","In particular, we provide a formula for the dimension of these codes.","For the general case over the projective space, we are able to generalize the necessary tools to deal with this case as well: we obtain a universal Gr\\\"obner basis for the vanishing ideal of the set of standard representatives of the projective space and we are able to reduce any monomial with respect to this Gr\\\"obner basis.","With respect to the parameters of these codes, by considering subfield subcodes of projective Reed-Muller codes we are able to obtain long linear codes with good parameters over a small finite field."],"url":"http://arxiv.org/abs/2307.09298v1"}
{"created":"2023-07-18 14:37:23","title":"Rumor Detection with Diverse Counterfactual Evidence","abstract":"The growth in social media has exacerbated the threat of fake news to individuals and communities. This draws increasing attention to developing efficient and timely rumor detection methods. The prevailing approaches resort to graph neural networks (GNNs) to exploit the post-propagation patterns of the rumor-spreading process. However, these methods lack inherent interpretation of rumor detection due to the black-box nature of GNNs. Moreover, these methods suffer from less robust results as they employ all the propagation patterns for rumor detection. In this paper, we address the above issues with the proposed Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). Our intuition is to exploit the diverse counterfactual evidence of an event graph to serve as multi-view interpretations, which are further aggregated for robust rumor detection results. Specifically, our method first designs a subgraph generation strategy to efficiently generate different subgraphs of the event graph. We constrain the removal of these subgraphs to cause the change in rumor detection results. Thus, these subgraphs naturally serve as counterfactual evidence for rumor detection. To achieve multi-view interpretation, we design a diversity loss inspired by Determinantal Point Processes (DPP) to encourage diversity among the counterfactual evidence. A GNN-based rumor detection model further aggregates the diverse counterfactual evidence discovered by the proposed DCE-RD to achieve interpretable and robust rumor detection results. Extensive experiments on two real-world datasets show the superior performance of our method. Our code is available at https://github.com/Vicinity111/DCE-RD.","sentences":["The growth in social media has exacerbated the threat of fake news to individuals and communities.","This draws increasing attention to developing efficient and timely rumor detection methods.","The prevailing approaches resort to graph neural networks (GNNs) to exploit the post-propagation patterns of the rumor-spreading process.","However, these methods lack inherent interpretation of rumor detection due to the black-box nature of GNNs.","Moreover, these methods suffer from less robust results as they employ all the propagation patterns for rumor detection.","In this paper, we address the above issues with the proposed Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD).","Our intuition is to exploit the diverse counterfactual evidence of an event graph to serve as multi-view interpretations, which are further aggregated for robust rumor detection results.","Specifically, our method first designs a subgraph generation strategy to efficiently generate different subgraphs of the event graph.","We constrain the removal of these subgraphs to cause the change in rumor detection results.","Thus, these subgraphs naturally serve as counterfactual evidence for rumor detection.","To achieve multi-view interpretation, we design a diversity loss inspired by Determinantal Point Processes (DPP) to encourage diversity among the counterfactual evidence.","A GNN-based rumor detection model further aggregates the diverse counterfactual evidence discovered by the proposed DCE-RD to achieve interpretable and robust rumor detection results.","Extensive experiments on two real-world datasets show the superior performance of our method.","Our code is available at https://github.com/Vicinity111/DCE-RD."],"url":"http://arxiv.org/abs/2307.09296v1"}
{"created":"2023-07-18 14:31:57","title":"Llama 2: Open Foundation and Fine-Tuned Chat Models","abstract":"In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.","sentences":["In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.","Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases.","Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models.","We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs."],"url":"http://arxiv.org/abs/2307.09288v1"}
{"created":"2023-07-18 14:30:47","title":"FlexiAST: Flexibility is What AST Needs","abstract":"The objective of this work is to give patch-size flexibility to Audio Spectrogram Transformers (AST). Recent advancements in ASTs have shown superior performance in various audio-based tasks. However, the performance of standard ASTs degrades drastically when evaluated using different patch sizes from that used during training. As a result, AST models are typically re-trained to accommodate changes in patch sizes. To overcome this limitation, this paper proposes a training procedure to provide flexibility to standard AST models without architectural changes, allowing them to work with various patch sizes at the inference stage - FlexiAST. This proposed training approach simply utilizes random patch size selection and resizing of patch and positional embedding weights. Our experiments show that FlexiAST gives similar performance to standard AST models while maintaining its evaluation ability at various patch sizes on different datasets for audio classification tasks.","sentences":["The objective of this work is to give patch-size flexibility to Audio Spectrogram Transformers (AST).","Recent advancements in ASTs have shown superior performance in various audio-based tasks.","However, the performance of standard ASTs degrades drastically when evaluated using different patch sizes from that used during training.","As a result, AST models are typically re-trained to accommodate changes in patch sizes.","To overcome this limitation, this paper proposes a training procedure to provide flexibility to standard AST models without architectural changes, allowing them to work with various patch sizes at the inference stage - FlexiAST.","This proposed training approach simply utilizes random patch size selection and resizing of patch and positional embedding weights.","Our experiments show that FlexiAST gives similar performance to standard AST models while maintaining its evaluation ability at various patch sizes on different datasets for audio classification tasks."],"url":"http://arxiv.org/abs/2307.09286v1"}
{"created":"2023-07-18 14:24:33","title":"RepViT: Revisiting Mobile CNN From ViT Perspective","abstract":"Recently, lightweight Vision Transformers (ViTs) demonstrate superior performance and lower latency compared with lightweight Convolutional Neural Networks (CNNs) on resource-constrained mobile devices. This improvement is usually attributed to the multi-head self-attention module, which enables the model to learn global representations. However, the architectural disparities between lightweight ViTs and lightweight CNNs have not been adequately examined. In this study, we revisit the efficient design of lightweight CNNs and emphasize their potential for mobile devices. We incrementally enhance the mobile-friendliness of a standard lightweight CNN, specifically MobileNetV3, by integrating the efficient architectural choices of lightweight ViTs. This ends up with a new family of pure lightweight CNNs, namely RepViT. Extensive experiments show that RepViT outperforms existing state-of-the-art lightweight ViTs and exhibits favorable latency in various vision tasks. On ImageNet, RepViT achieves over 80\\% top-1 accuracy with nearly 1ms latency on an iPhone 12, which is the first time for a lightweight model, to the best of our knowledge. Our largest model, RepViT-M3, obtains 81.4\\% accuracy with only 1.3ms latency. The code and trained models are available at \\url{https://github.com/jameslahm/RepViT}.","sentences":["Recently, lightweight Vision Transformers (ViTs) demonstrate superior performance and lower latency compared with lightweight Convolutional Neural Networks (CNNs) on resource-constrained mobile devices.","This improvement is usually attributed to the multi-head self-attention module, which enables the model to learn global representations.","However, the architectural disparities between lightweight ViTs and lightweight CNNs have not been adequately examined.","In this study, we revisit the efficient design of lightweight CNNs and emphasize their potential for mobile devices.","We incrementally enhance the mobile-friendliness of a standard lightweight CNN, specifically MobileNetV3, by integrating the efficient architectural choices of lightweight ViTs.","This ends up with a new family of pure lightweight CNNs, namely RepViT. Extensive experiments show that RepViT outperforms existing state-of-the-art lightweight ViTs and exhibits favorable latency in various vision tasks.","On ImageNet, RepViT achieves over 80\\% top-1 accuracy with nearly 1ms latency on an iPhone 12, which is the first time for a lightweight model, to the best of our knowledge.","Our largest model, RepViT-M3, obtains 81.4\\% accuracy with only 1.3ms latency.","The code and trained models are available at \\url{https://github.com/jameslahm/RepViT}."],"url":"http://arxiv.org/abs/2307.09283v1"}
{"created":"2023-07-18 14:19:28","title":"Regression-free Blind Image Quality Assessment","abstract":"Regression-based blind image quality assessment (IQA) models are susceptible to biased training samples, leading to a biased estimation of model parameters. To mitigate this issue, we propose a regression-free framework for image quality evaluation, which is founded upon retrieving similar instances by incorporating semantic and distortion features. The motivation behind this approach is rooted in the observation that the human visual system (HVS) has analogous visual responses to semantically similar image contents degraded by the same distortion. The proposed framework comprises two classification-based modules: semantic-based classification (SC) module and distortion-based classification (DC) module. Given a test image and an IQA database, the SC module retrieves multiple pristine images based on semantic similarity. The DC module then retrieves instances based on distortion similarity from the distorted images that correspond to each retrieved pristine image. Finally, the predicted quality score is derived by aggregating the subjective quality scores of multiple retrieved instances. Experimental results on four benchmark databases validate that the proposed model can remarkably outperform the state-of-the-art regression-based models.","sentences":["Regression-based blind image quality assessment (IQA) models are susceptible to biased training samples, leading to a biased estimation of model parameters.","To mitigate this issue, we propose a regression-free framework for image quality evaluation, which is founded upon retrieving similar instances by incorporating semantic and distortion features.","The motivation behind this approach is rooted in the observation that the human visual system (HVS) has analogous visual responses to semantically similar image contents degraded by the same distortion.","The proposed framework comprises two classification-based modules: semantic-based classification (SC) module and distortion-based classification (DC) module.","Given a test image and an IQA database, the SC module retrieves multiple pristine images based on semantic similarity.","The DC module then retrieves instances based on distortion similarity from the distorted images that correspond to each retrieved pristine image.","Finally, the predicted quality score is derived by aggregating the subjective quality scores of multiple retrieved instances.","Experimental results on four benchmark databases validate that the proposed model can remarkably outperform the state-of-the-art regression-based models."],"url":"http://arxiv.org/abs/2307.09279v1"}
{"created":"2023-07-18 14:11:58","title":"Improving Text Semantic Similarity Modeling through a 3D Siamese Network","abstract":"Siamese networks have gained popularity as a method for modeling text semantic similarity. Traditional methods rely on pooling operation to compress the semantic representations from Transformer blocks in encoding, resulting in two-dimensional semantic vectors and the loss of hierarchical semantic information from Transformer blocks. Moreover, this limited structure of semantic vectors is akin to a flattened landscape, which restricts the methods that can be applied in downstream modeling, as they can only navigate this flat terrain. To address this issue, we propose a novel 3D Siamese network for text semantic similarity modeling, which maps semantic information to a higher-dimensional space. The three-dimensional semantic tensors not only retains more precise spatial and feature domain information but also provides the necessary structural condition for comprehensive downstream modeling strategies to capture them. Leveraging this structural advantage, we introduce several modules to reinforce this 3D framework, focusing on three aspects: feature extraction, attention, and feature fusion. Our extensive experiments on four text semantic similarity benchmarks demonstrate the effectiveness and efficiency of our 3D Siamese Network.","sentences":["Siamese networks have gained popularity as a method for modeling text semantic similarity.","Traditional methods rely on pooling operation to compress the semantic representations from Transformer blocks in encoding, resulting in two-dimensional semantic vectors and the loss of hierarchical semantic information from Transformer blocks.","Moreover, this limited structure of semantic vectors is akin to a flattened landscape, which restricts the methods that can be applied in downstream modeling, as they can only navigate this flat terrain.","To address this issue, we propose a novel 3D Siamese network for text semantic similarity modeling, which maps semantic information to a higher-dimensional space.","The three-dimensional semantic tensors not only retains more precise spatial and feature domain information but also provides the necessary structural condition for comprehensive downstream modeling strategies to capture them.","Leveraging this structural advantage, we introduce several modules to reinforce this 3D framework, focusing on three aspects: feature extraction, attention, and feature fusion.","Our extensive experiments on four text semantic similarity benchmarks demonstrate the effectiveness and efficiency of our 3D Siamese Network."],"url":"http://arxiv.org/abs/2307.09274v1"}
{"created":"2023-07-18 13:56:43","title":"Linearized Relative Positional Encoding","abstract":"Relative positional encoding is widely used in vanilla and linear transformers to represent positional information. However, existing encoding methods of a vanilla transformer are not always directly applicable to a linear transformer, because the latter requires a decomposition of the query and key representations into separate kernel functions. Nevertheless, principles for designing encoding methods suitable for linear transformers remain understudied. In this work, we put together a variety of existing linear relative positional encoding approaches under a canonical form and further propose a family of linear relative positional encoding algorithms via unitary transformation. Our formulation leads to a principled framework that can be used to develop new relative positional encoding methods that preserve linear space-time complexity. Equipped with different models, the proposed linearized relative positional encoding (LRPE) family derives effective encoding for various applications. Experiments show that compared with existing methods, LRPE achieves state-of-the-art performance in language modeling, text classification, and image classification. Meanwhile, it emphasizes a general paradigm for designing broadly more relative positional encoding methods that are applicable to linear transformers. The code is available at https://github.com/OpenNLPLab/Lrpe.","sentences":["Relative positional encoding is widely used in vanilla and linear transformers to represent positional information.","However, existing encoding methods of a vanilla transformer are not always directly applicable to a linear transformer, because the latter requires a decomposition of the query and key representations into separate kernel functions.","Nevertheless, principles for designing encoding methods suitable for linear transformers remain understudied.","In this work, we put together a variety of existing linear relative positional encoding approaches under a canonical form and further propose a family of linear relative positional encoding algorithms via unitary transformation.","Our formulation leads to a principled framework that can be used to develop new relative positional encoding methods that preserve linear space-time complexity.","Equipped with different models, the proposed linearized relative positional encoding (LRPE) family derives effective encoding for various applications.","Experiments show that compared with existing methods, LRPE achieves state-of-the-art performance in language modeling, text classification, and image classification.","Meanwhile, it emphasizes a general paradigm for designing broadly more relative positional encoding methods that are applicable to linear transformers.","The code is available at https://github.com/OpenNLPLab/Lrpe."],"url":"http://arxiv.org/abs/2307.09270v1"}
{"created":"2023-07-18 13:52:12","title":"End-to-End Neural Network Training for Hyperbox-Based Classification","abstract":"Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays. We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks. In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results.","sentences":["Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable.","However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays.","We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks.","In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results."],"url":"http://arxiv.org/abs/2307.09269v1"}
{"created":"2023-07-18 13:49:49","title":"Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding","abstract":"3D visual grounding involves finding a target object in a 3D scene that corresponds to a given sentence query. Although many approaches have been proposed and achieved impressive performance, they all require dense object-sentence pair annotations in 3D point clouds, which are both time-consuming and expensive. To address the problem that fine-grained annotated data is difficult to obtain, we propose to leverage weakly supervised annotations to learn the 3D visual grounding model, i.e., only coarse scene-sentence correspondences are used to learn object-sentence links. To accomplish this, we design a novel semantic matching model that analyzes the semantic similarity between object proposals and sentences in a coarse-to-fine manner. Specifically, we first extract object proposals and coarsely select the top-K candidates based on feature and class similarity matrices. Next, we reconstruct the masked keywords of the sentence using each candidate one by one, and the reconstructed accuracy finely reflects the semantic similarity of each candidate to the query. Additionally, we distill the coarse-to-fine semantic matching knowledge into a typical two-stage 3D visual grounding model, which reduces inference costs and improves performance by taking full advantage of the well-studied structure of the existing architectures. We conduct extensive experiments on ScanRefer, Nr3D, and Sr3D, which demonstrate the effectiveness of our proposed method.","sentences":["3D visual grounding involves finding a target object in a 3D scene that corresponds to a given sentence query.","Although many approaches have been proposed and achieved impressive performance, they all require dense object-sentence pair annotations in 3D point clouds, which are both time-consuming and expensive.","To address the problem that fine-grained annotated data is difficult to obtain, we propose to leverage weakly supervised annotations to learn the 3D visual grounding model, i.e., only coarse scene-sentence correspondences are used to learn object-sentence links.","To accomplish this, we design a novel semantic matching model that analyzes the semantic similarity between object proposals and sentences in a coarse-to-fine manner.","Specifically, we first extract object proposals and coarsely select the top-K candidates based on feature and class similarity matrices.","Next, we reconstruct the masked keywords of the sentence using each candidate one by one, and the reconstructed accuracy finely reflects the semantic similarity of each candidate to the query.","Additionally, we distill the coarse-to-fine semantic matching knowledge into a typical two-stage 3D visual grounding model, which reduces inference costs and improves performance by taking full advantage of the well-studied structure of the existing architectures.","We conduct extensive experiments on ScanRefer, Nr3D, and Sr3D, which demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2307.09267v1"}
{"created":"2023-07-18 13:49:00","title":"Knowledge Distillation for Object Detection: from generic to remote sensing datasets","abstract":"Knowledge distillation, a well-known model compression technique, is an active research area in both computer vision and remote sensing communities. In this paper, we evaluate in a remote sensing context various off-the-shelf object detection knowledge distillation methods which have been originally developed on generic computer vision datasets such as Pascal VOC. In particular, methods covering both logit mimicking and feature imitation approaches are applied for vehicle detection using the well-known benchmarks such as xView and VEDAI datasets. Extensive experiments are performed to compare the relative performance and interrelationships of the methods. Experimental results show high variations and confirm the importance of result aggregation and cross validation on remote sensing datasets.","sentences":["Knowledge distillation, a well-known model compression technique, is an active research area in both computer vision and remote sensing communities.","In this paper, we evaluate in a remote sensing context various off-the-shelf object detection knowledge distillation methods which have been originally developed on generic computer vision datasets such as Pascal VOC.","In particular, methods covering both logit mimicking and feature imitation approaches are applied for vehicle detection using the well-known benchmarks such as xView and VEDAI datasets.","Extensive experiments are performed to compare the relative performance and interrelationships of the methods.","Experimental results show high variations and confirm the importance of result aggregation and cross validation on remote sensing datasets."],"url":"http://arxiv.org/abs/2307.09264v1"}
{"created":"2023-07-18 13:48:05","title":"Mobility-Aware Joint User Scheduling and Resource Allocation for Low Latency Federated Learning","abstract":"As an efficient distributed machine learning approach, Federated learning (FL) can obtain a shared model by iterative local model training at the user side and global model aggregating at the central server side, thereby protecting privacy of users. Mobile users in FL systems typically communicate with base stations (BSs) via wireless channels, where training performance could be degraded due to unreliable access caused by user mobility. However, existing work only investigates a static scenario or random initialization of user locations, which fail to capture mobility in real-world networks. To tackle this issue, we propose a practical model for user mobility in FL across multiple BSs, and develop a user scheduling and resource allocation method to minimize the training delay with constrained communication resources. Specifically, we first formulate an optimization problem with user mobility that jointly considers user selection, BS assignment to users, and bandwidth allocation to minimize the latency in each communication round. This optimization problem turned out to be NP-hard and we proposed a delay-aware greedy search algorithm (DAGSA) to solve it. Simulation results show that the proposed algorithm achieves better performance than the state-of-the-art baselines and a certain level of user mobility could improve training performance.","sentences":["As an efficient distributed machine learning approach, Federated learning (FL) can obtain a shared model by iterative local model training at the user side and global model aggregating at the central server side, thereby protecting privacy of users.","Mobile users in FL systems typically communicate with base stations (BSs) via wireless channels, where training performance could be degraded due to unreliable access caused by user mobility.","However, existing work only investigates a static scenario or random initialization of user locations, which fail to capture mobility in real-world networks.","To tackle this issue, we propose a practical model for user mobility in FL across multiple BSs, and develop a user scheduling and resource allocation method to minimize the training delay with constrained communication resources.","Specifically, we first formulate an optimization problem with user mobility that jointly considers user selection, BS assignment to users, and bandwidth allocation to minimize the latency in each communication round.","This optimization problem turned out to be NP-hard and we proposed a delay-aware greedy search algorithm (DAGSA) to solve it.","Simulation results show that the proposed algorithm achieves better performance than the state-of-the-art baselines and a certain level of user mobility could improve training performance."],"url":"http://arxiv.org/abs/2307.09263v1"}
{"created":"2023-07-18 13:47:57","title":"Neuromorphic spintronics simulated using an unconventional data-driven Thiele equation approach","abstract":"In this study, we developed a quantitative description of the dynamics of spin-torque vortex nano-oscillators (STVOs) through an unconventional model based on the combination of the Thiele equation approach (TEA) and data from micromagnetic simulations (MMS). Solving the STVO dynamics with our analytical model allows to accelerate the simulations by 9 orders of magnitude compared to MMS while reaching the same level of accuracy. Here, we showcase our model by simulating a STVO-based neural network for solving a classification task. We assess its performance with respect to the input signal current intensity and the level of noise that might affect such a system. Our approach is promising for accelerating the design of STVO-based neuromorphic computing devices while decreasing drastically its computational cost.","sentences":["In this study, we developed a quantitative description of the dynamics of spin-torque vortex nano-oscillators (STVOs) through an unconventional model based on the combination of the Thiele equation approach (TEA) and data from micromagnetic simulations (MMS).","Solving the STVO dynamics with our analytical model allows to accelerate the simulations by 9 orders of magnitude compared to MMS while reaching the same level of accuracy.","Here, we showcase our model by simulating a STVO-based neural network for solving a classification task.","We assess its performance with respect to the input signal current intensity and the level of noise that might affect such a system.","Our approach is promising for accelerating the design of STVO-based neuromorphic computing devices while decreasing drastically its computational cost."],"url":"http://arxiv.org/abs/2307.09262v1"}
{"created":"2023-07-18 13:43:53","title":"Adaptive Topological Feature via Persistent Homology: Filtration Learning for Point Clouds","abstract":"Machine learning for point clouds has been attracting much attention, with many applications in various fields, such as shape recognition and material science. To enhance the accuracy of such machine learning methods, it is known to be effective to incorporate global topological features, which are typically extracted by persistent homology. In the calculation of persistent homology for a point cloud, we need to choose a filtration for the point clouds, an increasing sequence of spaces. Because the performance of machine learning methods combined with persistent homology is highly affected by the choice of a filtration, we need to tune it depending on data and tasks. In this paper, we propose a framework that learns a filtration adaptively with the use of neural networks. In order to make the resulting persistent homology isometry-invariant, we develop a neural network architecture with such invariance. Additionally, we theoretically show a finite-dimensional approximation result that justifies our architecture. Experimental results demonstrated the efficacy of our framework in several classification tasks.","sentences":["Machine learning for point clouds has been attracting much attention, with many applications in various fields, such as shape recognition and material science.","To enhance the accuracy of such machine learning methods, it is known to be effective to incorporate global topological features, which are typically extracted by persistent homology.","In the calculation of persistent homology for a point cloud, we need to choose a filtration for the point clouds, an increasing sequence of spaces.","Because the performance of machine learning methods combined with persistent homology is highly affected by the choice of a filtration, we need to tune it depending on data and tasks.","In this paper, we propose a framework that learns a filtration adaptively with the use of neural networks.","In order to make the resulting persistent homology isometry-invariant, we develop a neural network architecture with such invariance.","Additionally, we theoretically show a finite-dimensional approximation result that justifies our architecture.","Experimental results demonstrated the efficacy of our framework in several classification tasks."],"url":"http://arxiv.org/abs/2307.09259v1"}
{"created":"2023-07-18 13:42:55","title":"Fast 2-Approximate All-Pairs Shortest Paths","abstract":"In this paper, we revisit the classic approximate All-Pairs Shortest Paths (APSP) problem in undirected graphs. For unweighted graphs, we provide an algorithm for $2$-approximate APSP in $\\tilde O(n^{2.5-r}+n^{\\omega(r)})$ time, for any $r\\in[0,1]$. This is $O(n^{2.032})$ time, using known bounds for rectangular matrix multiplication~$n^{\\omega(r)}$~[Le Gall, Urrutia, SODA 2018]. Our result improves on the $\\tilde{O}(n^{2.25})$ bound of [Roddity, STOC 2023], and on the $\\tilde{O}(m\\sqrt n+n^2)$ bound of [Baswana, Kavitha, SICOMP 2010] for graphs with $m\\geq n^{1.532}$ edges.   For weighted graphs, we obtain $(2+\\epsilon)$-approximate APSP in $\\tilde O(n^{3-r}+n^{\\omega(r)})$ time, for any $r\\in [0,1]$. This is $O(n^{2.214})$ time using known bounds for $\\omega(r)$. It improves on the state of the art bound of $O(n^{2.25})$ by [Kavitha, Algorithmica 2012]. Our techniques further lead to improved bounds in a wide range of density for weighted graphs. In particular, for the sparse regime we construct a distance oracle in $\\tilde O(mn^{2/3})$ time that supports $2$-approximate queries in constant time. For sparse graphs, the preprocessing time of the algorithm matches conditional lower bounds [Patrascu, Roditty, Thorup, FOCS 2012; Abboud, Bringmann, Fischer, STOC 2023]. To the best of our knowledge, this is the first 2-approximate distance oracle that has subquadratic preprocessing time in sparse graphs.   We also obtain new bounds in the near additive regime for unweighted graphs. We give faster algorithms for $(1+\\epsilon,k)$-approximate APSP, for $k=2,4,6,8$.   We obtain these results by incorporating fast rectangular matrix multiplications into various combinatorial algorithms that carefully balance out distance computation on layers of sparse graphs preserving certain distance information.","sentences":["In this paper, we revisit the classic approximate All-Pairs Shortest Paths (APSP) problem in undirected graphs.","For unweighted graphs, we provide an algorithm for $2$-approximate APSP in $\\tilde O(n^{2.5-r}+n^{\\omega(r)})$ time, for any $r\\in[0,1]$. This is $O(n^{2.032})$ time, using known bounds for rectangular matrix multiplication~$n^{\\omega(r)}$~[Le Gall, Urrutia, SODA 2018].","Our result improves on the $\\tilde{O}(n^{2.25})$ bound of [Roddity, STOC 2023], and on the $\\tilde{O}(m\\sqrt n+n^2)$ bound of [Baswana, Kavitha, SICOMP 2010] for graphs with $m\\geq n^{1.532}$ edges.   ","For weighted graphs, we obtain $(2+\\epsilon)$-approximate APSP in $\\tilde O(n^{3-r}+n^{\\omega(r)})$ time, for any $r\\in [0,1]$. This is $O(n^{2.214})$ time using known bounds for $\\omega(r)$. It improves on the state of the art bound of $O(n^{2.25})$ by [Kavitha, Algorithmica 2012].","Our techniques further lead to improved bounds in a wide range of density for weighted graphs.","In particular, for the sparse regime we construct a distance oracle in $\\tilde O(mn^{2/3})$ time that supports $2$-approximate queries in constant time.","For sparse graphs, the preprocessing time of the algorithm matches conditional lower bounds","[Patrascu, Roditty, Thorup, FOCS 2012; Abboud, Bringmann, Fischer, STOC 2023].","To the best of our knowledge, this is the first 2-approximate distance oracle that has subquadratic preprocessing time in sparse graphs.   ","We also obtain new bounds in the near additive regime for unweighted graphs.","We give faster algorithms for $(1+\\epsilon,k)$-approximate APSP, for $k=2,4,6,8$.   We obtain these results by incorporating fast rectangular matrix multiplications into various combinatorial algorithms that carefully balance out distance computation on layers of sparse graphs preserving certain distance information."],"url":"http://arxiv.org/abs/2307.09258v1"}
{"created":"2023-07-18 13:39:34","title":"Two-layer Space-oriented Partitioning for Non-point Data","abstract":"Non-point spatial objects (e.g., polygons, linestrings, etc.) are ubiquitous. We study the problem of indexing non-point objects in memory for range queries and spatial intersection joins. We propose a secondary partitioning technique for space-oriented partitioning indices (e.g., grids), which improves their performance significantly, by avoiding the generation and elimination of duplicate results. Our approach is easy to implement and can be used by any space-partitioning index to significantly reduce the cost of range queries and intersection joins. In addition, the secondary partitions can be processed independently, which makes our method appropriate for distributed and parallel indexing. Experiments on real datasets confirm the advantage of our approach against alternative duplicate elimination techniques and data-oriented state-of-the-art spatial indices. We also show that our partitioning technique, paired with optimized partition-to-partition join algorithms, typically reduces the cost of spatial joins by around 50%.","sentences":["Non-point spatial objects (e.g., polygons, linestrings, etc.) are ubiquitous.","We study the problem of indexing non-point objects in memory for range queries and spatial intersection joins.","We propose a secondary partitioning technique for space-oriented partitioning indices (e.g., grids), which improves their performance significantly, by avoiding the generation and elimination of duplicate results.","Our approach is easy to implement and can be used by any space-partitioning index to significantly reduce the cost of range queries and intersection joins.","In addition, the secondary partitions can be processed independently, which makes our method appropriate for distributed and parallel indexing.","Experiments on real datasets confirm the advantage of our approach against alternative duplicate elimination techniques and data-oriented state-of-the-art spatial indices.","We also show that our partitioning technique, paired with optimized partition-to-partition join algorithms, typically reduces the cost of spatial joins by around 50%."],"url":"http://arxiv.org/abs/2307.09256v1"}
{"created":"2023-07-18 13:38:39","title":"Text vectorization via transformer-based language models and n-gram perplexities","abstract":"As the probability (and thus perplexity) of a text is calculated based on the product of the probabilities of individual tokens, it may happen that one unlikely token significantly reduces the probability (i.e., increase the perplexity) of some otherwise highly probable input, while potentially representing a simple typographical error. Also, given that perplexity is a scalar value that refers to the entire input, information about the probability distribution within it is lost in the calculation (a relatively good text that has one unlikely token and another text in which each token is equally likely they can have the same perplexity value), especially for longer texts. As an alternative to scalar perplexity this research proposes a simple algorithm used to calculate vector values based on n-gram perplexities within the input. Such representations consider the previously mentioned aspects, and instead of a unique value, the relative perplexity of each text token is calculated, and these values are combined into a single vector representing the input.","sentences":["As the probability (and thus perplexity) of a text is calculated based on the product of the probabilities of individual tokens, it may happen that one unlikely token significantly reduces the probability (i.e., increase the perplexity) of some otherwise highly probable input, while potentially representing a simple typographical error.","Also, given that perplexity is a scalar value that refers to the entire input, information about the probability distribution within it is lost in the calculation (a relatively good text that has one unlikely token and another text in which each token is equally likely they can have the same perplexity value), especially for longer texts.","As an alternative to scalar perplexity this research proposes a simple algorithm used to calculate vector values based on n-gram perplexities within the input.","Such representations consider the previously mentioned aspects, and instead of a unique value, the relative perplexity of each text token is calculated, and these values are combined into a single vector representing the input."],"url":"http://arxiv.org/abs/2307.09255v1"}
{"created":"2023-07-18 13:36:24","title":"PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models","abstract":"Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\\%$ on average, compared to a standard baseline method.","sentences":["Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models.","Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts.","In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs.","Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee.","We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\\%$ on average, compared to a standard baseline method."],"url":"http://arxiv.org/abs/2307.09254v1"}
{"created":"2023-07-18 13:35:31","title":"Higher Catoids, Higher Quantales and their Correspondences","abstract":"We establish modal correspondences between omega-catoids and convolution omega-quantales. These are related to J\\'onsson-Tarski style-dualities between relational structures and lattices with operators. We introduce omega-catoids as generalisations of (strict) omega-categories and in particular of the higher path categories generated by polygraphs (or computads) in higher rewriting. Convolution omega-quantales generalise the powerset omega-Kleene algebras recently proposed for algebraic coherence proofs in higher rewriting to weighted variants. We extend these correspondences to ({\\omega},p)-catoids and convolution ({\\omega},p)-quantales suitable for modelling homotopies in higher rewriting. We also specialise them to finitely decomposable ({\\omega}, p)-catoids, an appropriate setting for defining ({\\omega}, p)-semirings and ({\\omega}, p)-Kleene algebras. These constructions support the systematic development and justification of higher quantale axioms relative to a previous ad hoc approach.","sentences":["We establish modal correspondences between omega-catoids and convolution omega-quantales.","These are related to J\\'onsson-Tarski style-dualities between relational structures and lattices with operators.","We introduce omega-catoids as generalisations of (strict) omega-categories and in particular of the higher path categories generated by polygraphs (or computads) in higher rewriting.","Convolution omega-quantales generalise the powerset omega-Kleene algebras recently proposed for algebraic coherence proofs in higher rewriting to weighted variants.","We extend these correspondences to ({\\omega},p)-catoids and convolution ({\\omega},p)-quantales suitable for modelling homotopies in higher rewriting.","We also specialise them to finitely decomposable ({\\omega}, p)-catoids, an appropriate setting for defining ({\\omega}, p)-semirings and ({\\omega}, p)-Kleene algebras.","These constructions support the systematic development and justification of higher quantale axioms relative to a previous ad hoc approach."],"url":"http://arxiv.org/abs/2307.09253v1"}
{"created":"2023-07-18 13:28:31","title":"UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data","abstract":"Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks. This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks. The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time. In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures. UniTabE's core concept relies on representing each basic table element with a module, termed TabUnit. This is subsequently followed by a Transformer encoder to refine the representation. Moreover, our model is designed to facilitate pretraining and finetuning through the utilization of free-form prompts. In order to implement the pretraining phase, we curated an expansive tabular dataset comprising approximately 13 billion samples, meticulously gathered from the Kaggle platform. Rigorous experimental testing and analyses were performed under a myriad of scenarios to validate the effectiveness of our methodology. The experimental results demonstrate UniTabE's superior performance against several baseline models across a multitude of benchmark datasets. This, therefore, underscores UniTabE's potential to significantly enhance the semantic representation of tabular data, thereby marking a significant stride in the field of tabular data analysis.","sentences":["Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks.","This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks.","The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time.","In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures.","UniTabE's core concept relies on representing each basic table element with a module, termed TabUnit.","This is subsequently followed by a Transformer encoder to refine the representation.","Moreover, our model is designed to facilitate pretraining and finetuning through the utilization of free-form prompts.","In order to implement the pretraining phase, we curated an expansive tabular dataset comprising approximately 13 billion samples, meticulously gathered from the Kaggle platform.","Rigorous experimental testing and analyses were performed under a myriad of scenarios to validate the effectiveness of our methodology.","The experimental results demonstrate UniTabE's superior performance against several baseline models across a multitude of benchmark datasets.","This, therefore, underscores UniTabE's potential to significantly enhance the semantic representation of tabular data, thereby marking a significant stride in the field of tabular data analysis."],"url":"http://arxiv.org/abs/2307.09249v1"}
{"created":"2023-07-18 13:28:30","title":"Application of BERT in Wind Power Forecasting-Teletraan's Solution in Baidu KDD Cup 2022","abstract":"Nowadays, wind energy has drawn increasing attention as its important role in carbon neutrality and sustainable development. When wind power is integrated into the power grid, precise forecasting is necessary for the sustainability and security of the system. However, the unpredictable nature and long sequence prediction make it especially challenging. In this technical report, we introduce the BERT model applied for Baidu KDD Cup 2022, and the daily fluctuation is added by post-processing to make the predicted results in line with daily periodicity. Our solution achieves 3rd place of 2490 teams. The code is released athttps://github.com/LongxingTan/KDD2022-Baidu","sentences":["Nowadays, wind energy has drawn increasing attention as its important role in carbon neutrality and sustainable development.","When wind power is integrated into the power grid, precise forecasting is necessary for the sustainability and security of the system.","However, the unpredictable nature and long sequence prediction make it especially challenging.","In this technical report, we introduce the BERT model applied for Baidu KDD Cup 2022, and the daily fluctuation is added by post-processing to make the predicted results in line with daily periodicity.","Our solution achieves 3rd place of 2490 teams.","The code is released athttps://github.com/LongxingTan/KDD2022-Baidu"],"url":"http://arxiv.org/abs/2307.09248v1"}
{"created":"2023-07-18 13:25:48","title":"Task Space Control of Hydraulic Construction Machines using Reinforcement Learning","abstract":"Teleoperation is vital in the construction industry, allowing safe machine manipulation from a distance. However, controlling machines at a joint level requires extensive training due to their complex degrees of freedom. Task space control offers intuitive maneuvering, but precise control often requires dynamic models, posing challenges for hydraulic machines. To address this, we use a data-driven actuator model to capture machine dynamics in real-world operations. By integrating this model into simulation and reinforcement learning, an optimal control policy for task space control is obtained. Experiments with Brokk 170 validate the framework, comparing it to a well-known Jacobian-based approach.","sentences":["Teleoperation is vital in the construction industry, allowing safe machine manipulation from a distance.","However, controlling machines at a joint level requires extensive training due to their complex degrees of freedom.","Task space control offers intuitive maneuvering, but precise control often requires dynamic models, posing challenges for hydraulic machines.","To address this, we use a data-driven actuator model to capture machine dynamics in real-world operations.","By integrating this model into simulation and reinforcement learning, an optimal control policy for task space control is obtained.","Experiments with Brokk 170 validate the framework, comparing it to a well-known Jacobian-based approach."],"url":"http://arxiv.org/abs/2307.09246v1"}
{"created":"2023-07-18 13:23:23","title":"Towards Sustainable Deep Learning for Multi-Label Classification on NILM","abstract":"Non-intrusive load monitoring (NILM) is the process of obtaining appliance-level data from a single metering point, measuring total electricity consumption of a household or a business. Appliance-level data can be directly used for demand response applications and energy management systems as well as for awareness raising and motivation for improvements in energy efficiency and reduction in the carbon footprint. Recently, classical machine learning and deep learning (DL) techniques became very popular and proved as highly effective for NILM classification, but with the growing complexity these methods are faced with significant computational and energy demands during both their training and operation. In this paper, we introduce a novel DL model aimed at enhanced multi-label classification of NILM with improved computation and energy efficiency. We also propose a testing methodology for comparison of different models using data synthesized from the measurement datasets so as to better represent real-world scenarios. Compared to the state-of-the-art, the proposed model has its carbon footprint reduced by more than 23% while providing on average approximately 8 percentage points in performance improvement when testing on data derived from REFIT and UK-DALE datasets.","sentences":["Non-intrusive load monitoring (NILM) is the process of obtaining appliance-level data from a single metering point, measuring total electricity consumption of a household or a business.","Appliance-level data can be directly used for demand response applications and energy management systems as well as for awareness raising and motivation for improvements in energy efficiency and reduction in the carbon footprint.","Recently, classical machine learning and deep learning (DL) techniques became very popular and proved as highly effective for NILM classification, but with the growing complexity these methods are faced with significant computational and energy demands during both their training and operation.","In this paper, we introduce a novel DL model aimed at enhanced multi-label classification of NILM with improved computation and energy efficiency.","We also propose a testing methodology for comparison of different models using data synthesized from the measurement datasets so as to better represent real-world scenarios.","Compared to the state-of-the-art, the proposed model has its carbon footprint reduced by more than 23% while providing on average approximately 8 percentage points in performance improvement when testing on data derived from REFIT and UK-DALE datasets."],"url":"http://arxiv.org/abs/2307.09244v1"}
{"created":"2023-07-18 13:22:21","title":"From Dragondoom to Dragonstar: Side-channel Attacks and Formally Verified Implementation of WPA3 Dragonfly Handshake","abstract":"It is universally acknowledged that Wi-Fi communications are important to secure. Thus, the Wi-Fi Alliance published WPA3 in 2018 with a distinctive security feature: it leverages a Password-Authenticated Key Exchange (PAKE) protocol to protect users' passwords from offline dictionary attacks. Unfortunately, soon after its release, several attacks were reported against its implementations, in response to which the protocol was updated in a best-effort manner.   In this paper, we show that the proposed mitigations are not enough, especially for a complex protocol to implement even for savvy developers. Indeed, we present **Dragondoom**, a collection of side-channel vulnerabilities of varying strength allowing attackers to recover users' passwords in widely deployed Wi-Fi daemons, such as hostap in its default settings. Our findings target both password conversion methods, namely the default probabilistic hunting-and-pecking and its newly standardized deterministic alternative based on SSWU. We successfully exploit our leakage in practice through microarchitectural mechanisms, and overcome the limited spatial resolution of Flush+Reload. Our attacks outperform previous works in terms of required measurements.   Then, driven by the need to end the spiral of patch-and-hack in Dragonfly implementations, we propose **Dragonstar**, an implementation of Dragonfly leveraging a formally verified implementation of the underlying mathematical operations, thereby removing all the related leakage vector. Our implementation relies on HACL*, a formally verified crypto library guaranteeing secret-independence. We design Dragonstar, so that its integration within hostap requires minimal modifications to the existing project. Our experiments show that the performance of HACL*-based hostap is comparable to OpenSSL-based, implying that Dragonstar is both efficient and proved to be leakage-free.","sentences":["It is universally acknowledged that Wi-Fi communications are important to secure.","Thus, the Wi-Fi Alliance published WPA3 in 2018 with a distinctive security feature: it leverages a Password-Authenticated Key Exchange (PAKE) protocol to protect users' passwords from offline dictionary attacks.","Unfortunately, soon after its release, several attacks were reported against its implementations, in response to which the protocol was updated in a best-effort manner.   ","In this paper, we show that the proposed mitigations are not enough, especially for a complex protocol to implement even for savvy developers.","Indeed, we present **Dragondoom**, a collection of side-channel vulnerabilities of varying strength allowing attackers to recover users' passwords in widely deployed Wi-Fi daemons, such as hostap in its default settings.","Our findings target both password conversion methods, namely the default probabilistic hunting-and-pecking and its newly standardized deterministic alternative based on SSWU.","We successfully exploit our leakage in practice through microarchitectural mechanisms, and overcome the limited spatial resolution of Flush+Reload.","Our attacks outperform previous works in terms of required measurements.   ","Then, driven by the need to end the spiral of patch-and-hack in Dragonfly implementations, we propose **Dragonstar**, an implementation of Dragonfly leveraging a formally verified implementation of the underlying mathematical operations, thereby removing all the related leakage vector.","Our implementation relies on HACL*, a formally verified crypto library guaranteeing secret-independence.","We design Dragonstar, so that its integration within hostap requires minimal modifications to the existing project.","Our experiments show that the performance of HACL*-based hostap is comparable to OpenSSL-based, implying that Dragonstar is both efficient and proved to be leakage-free."],"url":"http://arxiv.org/abs/2307.09243v1"}
{"created":"2023-07-18 13:19:39","title":"Generation of High Spatial Resolution Terrestrial Surface from Low Spatial Resolution Elevation Contour Maps via Hierarchical Computation of Median Elevation Regions","abstract":"We proposed a simple yet effective morphological approach to convert a sparse Digital Elevation Model (DEM) to a dense Digital Elevation Model. The conversion is similar to that of the generation of high-resolution DEM from its low-resolution DEM. The approach involves the generation of median contours to achieve the purpose. It is a sequential step of the I) decomposition of the existing sparse Contour map into the maximum possible Threshold Elevation Region (TERs). II) Computing all possible non-negative and non-weighted Median Elevation Region (MER) hierarchically between the successive TER decomposed from a sparse contour map. III) Computing the gradient of all TER, and MER computed from previous steps would yield the predicted intermediate elevation contour at a higher spatial resolution. We presented this approach initially with some self-made synthetic data to show how the contour prediction works and then experimented with the available contour map of Washington, NH to justify its usefulness. This approach considers the geometric information of existing contours and interpolates the elevation contour at a new spatial region of a topographic surface until no elevation contours are necessary to generate. This novel approach is also very low-cost and robust as it uses elevation contours.","sentences":["We proposed a simple yet effective morphological approach to convert a sparse Digital Elevation Model (DEM) to a dense Digital Elevation Model.","The conversion is similar to that of the generation of high-resolution DEM from its low-resolution DEM.","The approach involves the generation of median contours to achieve the purpose.","It is a sequential step of the I) decomposition of the existing sparse Contour map into the maximum possible Threshold Elevation Region (TERs).","II) Computing all possible non-negative and non-weighted Median Elevation Region (MER) hierarchically between the successive TER decomposed from a sparse contour map.","III)","Computing the gradient of all TER, and MER computed from previous steps would yield the predicted intermediate elevation contour at a higher spatial resolution.","We presented this approach initially with some self-made synthetic data to show how the contour prediction works and then experimented with the available contour map of Washington, NH to justify its usefulness.","This approach considers the geometric information of existing contours and interpolates the elevation contour at a new spatial region of a topographic surface until no elevation contours are necessary to generate.","This novel approach is also very low-cost and robust as it uses elevation contours."],"url":"http://arxiv.org/abs/2307.09239v1"}
{"created":"2023-07-18 13:18:52","title":"Fusing Hand and Body Skeletons for Human Action Recognition in Assembly","abstract":"As collaborative robots (cobots) continue to gain popularity in industrial manufacturing, effective human-robot collaboration becomes crucial. Cobots should be able to recognize human actions to assist with assembly tasks and act autonomously. To achieve this, skeleton-based approaches are often used due to their ability to generalize across various people and environments. Although body skeleton approaches are widely used for action recognition, they may not be accurate enough for assembly actions where the worker's fingers and hands play a significant role. To address this limitation, we propose a method in which less detailed body skeletons are combined with highly detailed hand skeletons. We investigate CNNs and transformers, the latter of which are particularly adept at extracting and combining important information from both skeleton types using attention. This paper demonstrates the effectiveness of our proposed approach in enhancing action recognition in assembly scenarios.","sentences":["As collaborative robots (cobots) continue to gain popularity in industrial manufacturing, effective human-robot collaboration becomes crucial.","Cobots should be able to recognize human actions to assist with assembly tasks and act autonomously.","To achieve this, skeleton-based approaches are often used due to their ability to generalize across various people and environments.","Although body skeleton approaches are widely used for action recognition, they may not be accurate enough for assembly actions where the worker's fingers and hands play a significant role.","To address this limitation, we propose a method in which less detailed body skeletons are combined with highly detailed hand skeletons.","We investigate CNNs and transformers, the latter of which are particularly adept at extracting and combining important information from both skeleton types using attention.","This paper demonstrates the effectiveness of our proposed approach in enhancing action recognition in assembly scenarios."],"url":"http://arxiv.org/abs/2307.09238v1"}
{"created":"2023-07-18 13:10:11","title":"Augmenting CLIP with Improved Visio-Linguistic Reasoning","abstract":"Image-text contrastive models such as CLIP are useful for a variety of downstream applications including zero-shot classification, image-text retrieval and transfer learning. However, these contrastively trained vision-language models often fail on compositional visio-linguistic tasks such as Winoground with performance equivalent to random chance. In our paper, we address this issue and propose a sample-efficient light-weight method called SDS-CLIP to improve the compositional visio-linguistic reasoning capabilities of CLIP. The core idea of our method is to use differentiable image parameterizations to fine-tune CLIP with a distillation objective from large text-to-image generative models such as Stable-Diffusion which are relatively good at visio-linguistic reasoning tasks. On the challenging Winoground compositional reasoning benchmark, our method improves the absolute visio-linguistic performance of different CLIP models by up to 7%, while on the ARO dataset, our method improves the visio-linguistic performance by upto 3%. As a byproduct of inducing visio-linguistic reasoning into CLIP, we also find that the zero-shot performance improves marginally on a variety of downstream datasets. Our method reinforces that carefully designed distillation objectives from generative models can be leveraged to extend existing contrastive image-text models with improved visio-linguistic reasoning capabilities.","sentences":["Image-text contrastive models such as CLIP are useful for a variety of downstream applications including zero-shot classification, image-text retrieval and transfer learning.","However, these contrastively trained vision-language models often fail on compositional visio-linguistic tasks such as Winoground with performance equivalent to random chance.","In our paper, we address this issue and propose a sample-efficient light-weight method called SDS-CLIP to improve the compositional visio-linguistic reasoning capabilities of CLIP.","The core idea of our method is to use differentiable image parameterizations to fine-tune CLIP with a distillation objective from large text-to-image generative models such as Stable-Diffusion which are relatively good at visio-linguistic reasoning tasks.","On the challenging Winoground compositional reasoning benchmark, our method improves the absolute visio-linguistic performance of different CLIP models by up to 7%, while on the ARO dataset, our method improves the visio-linguistic performance by upto 3%.","As a byproduct of inducing visio-linguistic reasoning into CLIP, we also find that the zero-shot performance improves marginally on a variety of downstream datasets.","Our method reinforces that carefully designed distillation objectives from generative models can be leveraged to extend existing contrastive image-text models with improved visio-linguistic reasoning capabilities."],"url":"http://arxiv.org/abs/2307.09233v1"}
{"created":"2023-07-18 13:09:03","title":"Intelligent Reflecting Surface Assisted Localization: Performance Analysis and Algorithm Design","abstract":"The target sensing/localization performance is fundamentally limited by the line-of-sight link and severe signal attenuation over long distances. This paper considers a challenging scenario where the direct link between the base station (BS) and the target is blocked due to the surrounding blockages and leverages the intelligent reflecting surface (IRS) with some active sensors, termed as \\textit{semi-passive IRS}, for localization. To be specific, the active sensors receive echo signals reflected by the target and apply signal processing techniques to estimate the target location. We consider the joint time-of-arrival (ToA) and direction-of-arrival (DoA) estimation for localization and derive the corresponding Cram\\'{e}r-Rao bound (CRB), and then a simple ToA/DoA estimator without iteration is proposed. In particular, the relationships of the CRB for ToA/DoA with the number of frames for IRS beam adjustments, number of IRS reflecting elements, and number of sensors are theoretically analyzed and demystified. Simulation results show that the proposed semi-passive IRS architecture provides sub-meter level positioning accuracy even over a long localization range from the BS to the target and also demonstrate a significant localization accuracy improvement compared to the fully passive IRS architecture.","sentences":["The target sensing/localization performance is fundamentally limited by the line-of-sight link and severe signal attenuation over long distances.","This paper considers a challenging scenario where the direct link between the base station (BS) and the target is blocked due to the surrounding blockages and leverages the intelligent reflecting surface (IRS) with some active sensors, termed as \\textit{semi-passive IRS}, for localization.","To be specific, the active sensors receive echo signals reflected by the target and apply signal processing techniques to estimate the target location.","We consider the joint time-of-arrival (ToA) and direction-of-arrival (DoA) estimation for localization and derive the corresponding Cram\\'{e}r-Rao bound (CRB), and then a simple ToA/DoA estimator without iteration is proposed.","In particular, the relationships of the CRB for ToA/DoA with the number of frames for IRS beam adjustments, number of IRS reflecting elements, and number of sensors are theoretically analyzed and demystified.","Simulation results show that the proposed semi-passive IRS architecture provides sub-meter level positioning accuracy even over a long localization range from the BS to the target and also demonstrate a significant localization accuracy improvement compared to the fully passive IRS architecture."],"url":"http://arxiv.org/abs/2307.09232v1"}
{"created":"2023-07-18 13:06:17","title":"Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review","abstract":"In this work we perform a scoping review of the current literature on the detection of throat cancer from speech recordings using machine learning and artificial intelligence. We find 22 papers within this area and discuss their methods and results. We split these papers into two groups - nine performing binary classification, and 13 performing multi-class classification. The papers present a range of methods with neural networks being most commonly implemented. Many features are also extracted from the audio before classification, with the most common bring mel-frequency cepstral coefficients. None of the papers found in this search have associated code repositories and as such are not reproducible. Therefore, we create a publicly available code repository of our own classifiers. We use transfer learning on a multi-class problem, classifying three pathologies and healthy controls. Using this technique we achieve an unweighted average recall of 53.54%, sensitivity of 83.14%, and specificity of 64.00%. We compare our classifiers with the results obtained on the same dataset and find similar results.","sentences":["In this work we perform a scoping review of the current literature on the detection of throat cancer from speech recordings using machine learning and artificial intelligence.","We find 22 papers within this area and discuss their methods and results.","We split these papers into two groups - nine performing binary classification, and 13 performing multi-class classification.","The papers present a range of methods with neural networks being most commonly implemented.","Many features are also extracted from the audio before classification, with the most common bring mel-frequency cepstral coefficients.","None of the papers found in this search have associated code repositories and as such are not reproducible.","Therefore, we create a publicly available code repository of our own classifiers.","We use transfer learning on a multi-class problem, classifying three pathologies and healthy controls.","Using this technique we achieve an unweighted average recall of 53.54%, sensitivity of 83.14%, and specificity of 64.00%.","We compare our classifiers with the results obtained on the same dataset and find similar results."],"url":"http://arxiv.org/abs/2307.09230v1"}
{"created":"2023-07-18 12:57:35","title":"Human Body Digital Twin: A Master Plan","abstract":"The human body DT has the potential to revolutionize healthcare and wellness, but its responsible and effective implementation requires consideration of various factors. This article presents a comprehensive overview of the current status and future prospects of the human body DT and proposes a five-level roadmap for its development. The roadmap covers the development of various components, such as wearable devices, data collection, data analysis, and decision-making systems. The article also highlights the necessary support, security, cost, and ethical considerations that must be addressed in order to ensure responsible and effective implementation of the human body DT. The proposed roadmap provides a framework for guiding future development and offers a unique perspective on the future of the human body DT, facilitating new interdisciplinary research and innovative solutions in this rapidly evolving field.","sentences":["The human body DT has the potential to revolutionize healthcare and wellness, but its responsible and effective implementation requires consideration of various factors.","This article presents a comprehensive overview of the current status and future prospects of the human body DT and proposes a five-level roadmap for its development.","The roadmap covers the development of various components, such as wearable devices, data collection, data analysis, and decision-making systems.","The article also highlights the necessary support, security, cost, and ethical considerations that must be addressed in order to ensure responsible and effective implementation of the human body DT.","The proposed roadmap provides a framework for guiding future development and offers a unique perspective on the future of the human body DT, facilitating new interdisciplinary research and innovative solutions in this rapidly evolving field."],"url":"http://arxiv.org/abs/2307.09225v1"}
{"created":"2023-07-18 12:52:49","title":"A Survey on Open-Vocabulary Detection and Segmentation: Past, Present, and Future","abstract":"As the most fundamental tasks of computer vision, object detection and segmentation have made tremendous progress in the deep learning era. Due to the expensive manual labeling, the annotated categories in existing datasets are often small-scale and pre-defined, i.e., state-of-the-art detectors and segmentors fail to generalize beyond the closed-vocabulary. To resolve this limitation, the last few years have witnessed increasing attention toward Open-Vocabulary Detection (OVD) and Segmentation (OVS). In this survey, we provide a comprehensive review on the past and recent development of OVD and OVS. To this end, we develop a taxonomy according to the type of task and methodology. We find that the permission and usage of weak supervision signals can well discriminate different methodologies, including: visual-semantic space mapping, novel visual feature synthesis, region-aware training, pseudo-labeling, knowledge distillation-based, and transfer learning-based. The proposed taxonomy is universal across different tasks, covering object detection, semantic/instance/panoptic segmentation, 3D scene and video understanding. In each category, its main principles, key challenges, development routes, strengths, and weaknesses are thoroughly discussed. In addition, we benchmark each task along with the vital components of each method. Finally, several promising directions are provided to stimulate future research.","sentences":["As the most fundamental tasks of computer vision, object detection and segmentation have made tremendous progress in the deep learning era.","Due to the expensive manual labeling, the annotated categories in existing datasets are often small-scale and pre-defined, i.e., state-of-the-art detectors and segmentors fail to generalize beyond the closed-vocabulary.","To resolve this limitation, the last few years have witnessed increasing attention toward Open-Vocabulary Detection (OVD) and Segmentation (OVS).","In this survey, we provide a comprehensive review on the past and recent development of OVD and OVS.","To this end, we develop a taxonomy according to the type of task and methodology.","We find that the permission and usage of weak supervision signals can well discriminate different methodologies, including: visual-semantic space mapping, novel visual feature synthesis, region-aware training, pseudo-labeling, knowledge distillation-based, and transfer learning-based.","The proposed taxonomy is universal across different tasks, covering object detection, semantic/instance/panoptic segmentation, 3D scene and video understanding.","In each category, its main principles, key challenges, development routes, strengths, and weaknesses are thoroughly discussed.","In addition, we benchmark each task along with the vital components of each method.","Finally, several promising directions are provided to stimulate future research."],"url":"http://arxiv.org/abs/2307.09220v1"}
{"created":"2023-07-18 12:48:59","title":"Patrolling Grids with a Bit of Memory","abstract":"We study the following problem in elementary robotics: can a mobile agent with $b$ bits of memory, which is able to sense only locations at Manhattan distance $V$ or less from itself, patrol a $d$-dimensional grid graph? We show that it is impossible to patrol some grid graphs with $0$ bits of memory, regardless of $V$, and give an exact characterization of those grid graphs that can be patrolled with $0$ bits of memory and visibility range $V$. On the other hand, we show that, surprisingly, an algorithm exists using $1$ bit of memory and $V=1$ that patrols any $d$-dimensional grid graph.","sentences":["We study the following problem in elementary robotics: can a mobile agent with $b$ bits of memory, which is able to sense only locations at Manhattan distance $V$ or less from itself, patrol a $d$-dimensional grid graph?","We show that it is impossible to patrol some grid graphs with $0$ bits of memory, regardless of $V$, and give an exact characterization of those grid graphs that can be patrolled with $0$ bits of memory and visibility range $V$. On the other hand, we show that, surprisingly, an algorithm exists using $1$ bit of memory and $V=1$ that patrols any $d$-dimensional grid graph."],"url":"http://arxiv.org/abs/2307.09214v1"}
{"created":"2023-07-18 12:47:35","title":"How Many Neurons Does it Take to Approximate the Maximum?","abstract":"We study the size of a neural network needed to approximate the maximum function over $d$ inputs, in the most basic setting of approximating with respect to the $L_2$ norm, for continuous distributions, for a network that uses ReLU activations. We provide new lower and upper bounds on the width required for approximation across various depths. Our results establish new depth separations between depth 2 and 3, and depth 3 and 5 networks, as well as providing a depth $\\mathcal{O}(\\log(\\log(d)))$ and width $\\mathcal{O}(d)$ construction which approximates the maximum function, significantly improving upon the depth requirements of the best previously known bounds for networks with linearly-bounded width. Our depth separation results are facilitated by a new lower bound for depth 2 networks approximating the maximum function over the uniform distribution, assuming an exponential upper bound on the size of the weights. Furthermore, we are able to use this depth 2 lower bound to provide tight bounds on the number of neurons needed to approximate the maximum by a depth 3 network. Our lower bounds are of potentially broad interest as they apply to the widely studied and used \\emph{max} function, in contrast to many previous results that base their bounds on specially constructed or pathological functions and distributions.","sentences":["We study the size of a neural network needed to approximate the maximum function over $d$ inputs, in the most basic setting of approximating with respect to the $L_2$ norm, for continuous distributions, for a network that uses ReLU activations.","We provide new lower and upper bounds on the width required for approximation across various depths.","Our results establish new depth separations between depth 2 and 3, and depth 3 and 5 networks, as well as providing a depth $\\mathcal{O}(\\log(\\log(d)))$ and width $\\mathcal{O}(d)$ construction which approximates the maximum function, significantly improving upon the depth requirements of the best previously known bounds for networks with linearly-bounded width.","Our depth separation results are facilitated by a new lower bound for depth 2 networks approximating the maximum function over the uniform distribution, assuming an exponential upper bound on the size of the weights.","Furthermore, we are able to use this depth 2 lower bound to provide tight bounds on the number of neurons needed to approximate the maximum by a depth 3 network.","Our lower bounds are of potentially broad interest as they apply to the widely studied and used \\emph{max} function, in contrast to many previous results that base their bounds on specially constructed or pathological functions and distributions."],"url":"http://arxiv.org/abs/2307.09212v1"}
{"created":"2023-07-18 12:45:54","title":"Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models","abstract":"We analyze sentiment analysis and toxicity detection models to detect the presence of explicit bias against people with disability (PWD). We employ the bias identification framework of Perturbation Sensitivity Analysis to examine conversations related to PWD on social media platforms, specifically Twitter and Reddit, in order to gain insight into how disability bias is disseminated in real-world social settings. We then create the \\textit{Bias Identification Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any sentiment analysis and toxicity detection models. Our study utilizes BITS to uncover significant biases in four open AIaaS (AI as a Service) sentiment analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API, DistilBERT and two toxicity detection models, namely two versions of Toxic-BERT. Our findings indicate that all of these models exhibit statistically significant explicit bias against PWD.","sentences":["We analyze sentiment analysis and toxicity detection models to detect the presence of explicit bias against people with disability (PWD).","We employ the bias identification framework of Perturbation Sensitivity Analysis to examine conversations related to PWD on social media platforms, specifically Twitter and Reddit, in order to gain insight into how disability bias is disseminated in real-world social settings.","We then create the \\textit{Bias Identification Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any sentiment analysis and toxicity detection models.","Our study utilizes BITS to uncover significant biases in four open AIaaS (AI as a Service) sentiment analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API, DistilBERT and two toxicity detection models, namely two versions of Toxic-BERT.","Our findings indicate that all of these models exhibit statistically significant explicit bias against PWD."],"url":"http://arxiv.org/abs/2307.09209v1"}
{"created":"2023-07-18 12:42:59","title":"Context-Conditional Navigation with a Learning-Based Terrain- and Robot-Aware Dynamics Model","abstract":"In autonomous navigation settings, several quantities can be subject to variations. Terrain properties such as friction coefficients may vary over time depending on the location of the robot. Also, the dynamics of the robot may change due to, e.g., different payloads, changing the system's mass, or wear and tear, changing actuator gains or joint friction. An autonomous agent should thus be able to adapt to such variations. In this paper, we develop a novel probabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN, which is able to adapt to the above-mentioned variations. It builds on recent advances in meta-learning forward dynamics models based on Neural Processes. We evaluate our method in a simulated 2D navigation setting with a unicycle-like robot and different terrain layouts with spatially varying friction coefficients. In our experiments, the proposed model exhibits lower prediction error for the task of long-horizon trajectory prediction, compared to non-adaptive ablation models. We also evaluate our model on the downstream task of navigation planning, which demonstrates improved performance in planning control-efficient paths by taking robot and terrain properties into account.","sentences":["In autonomous navigation settings, several quantities can be subject to variations.","Terrain properties such as friction coefficients may vary over time depending on the location of the robot.","Also, the dynamics of the robot may change due to, e.g., different payloads, changing the system's mass, or wear and tear, changing actuator gains or joint friction.","An autonomous agent should thus be able to adapt to such variations.","In this paper, we develop a novel probabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN, which is able to adapt to the above-mentioned variations.","It builds on recent advances in meta-learning forward dynamics models based on Neural Processes.","We evaluate our method in a simulated 2D navigation setting with a unicycle-like robot and different terrain layouts with spatially varying friction coefficients.","In our experiments, the proposed model exhibits lower prediction error for the task of long-horizon trajectory prediction, compared to non-adaptive ablation models.","We also evaluate our model on the downstream task of navigation planning, which demonstrates improved performance in planning control-efficient paths by taking robot and terrain properties into account."],"url":"http://arxiv.org/abs/2307.09206v1"}
{"created":"2023-07-18 12:41:28","title":"Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning","abstract":"In many reinforcement learning tasks, the agent has to learn to interact with many objects of different types and generalize to unseen combinations and numbers of objects. Often a task is a composition of previously learned tasks (e.g. block stacking). These are examples of compositional generalization, in which we compose object-centric representations to solve complex tasks. Recent works have shown the benefits of object-factored representations and hierarchical abstractions for improving sample efficiency in these settings. On the other hand, these methods do not fully exploit the benefits of factorization in terms of object attributes. In this paper, we address this opportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL) framework. In DAFT-RL, we leverage object-centric representation learning to extract objects from visual inputs. We learn to classify them in classes and infer their latent parameters. For each class of object, we learn a class template graph that describes how the dynamics and reward of an object of this class factorize according to its attributes. We also learn an interaction pattern graph that describes how objects of different classes interact with each other at the attribute level. Through these graphs and a dynamic interaction graph that models the interactions between objects, we can learn a policy that can then be directly applied in a new environment by just estimating the interactions and latent parameters. We evaluate DAFT-RL in three benchmark datasets and show our framework outperforms the state-of-the-art in generalizing across unseen objects with varying attributes and latent parameters, as well as in the composition of previously learned tasks.","sentences":["In many reinforcement learning tasks, the agent has to learn to interact with many objects of different types and generalize to unseen combinations and numbers of objects.","Often a task is a composition of previously learned tasks (e.g. block stacking).","These are examples of compositional generalization, in which we compose object-centric representations to solve complex tasks.","Recent works have shown the benefits of object-factored representations and hierarchical abstractions for improving sample efficiency in these settings.","On the other hand, these methods do not fully exploit the benefits of factorization in terms of object attributes.","In this paper, we address this opportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL) framework.","In DAFT-RL, we leverage object-centric representation learning to extract objects from visual inputs.","We learn to classify them in classes and infer their latent parameters.","For each class of object, we learn a class template graph that describes how the dynamics and reward of an object of this class factorize according to its attributes.","We also learn an interaction pattern graph that describes how objects of different classes interact with each other at the attribute level.","Through these graphs and a dynamic interaction graph that models the interactions between objects, we can learn a policy that can then be directly applied in a new environment by just estimating the interactions and latent parameters.","We evaluate DAFT-RL in three benchmark datasets and show our framework outperforms the state-of-the-art in generalizing across unseen objects with varying attributes and latent parameters, as well as in the composition of previously learned tasks."],"url":"http://arxiv.org/abs/2307.09205v1"}
{"created":"2023-07-18 12:25:40","title":"ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint","abstract":"Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations. However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues. Entire space models were proposed to address the two issues via tracing the decision-making path of \"exposure_click_purchase\". Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance. Thus, the decision-making path has been extended to \"exposure_click_in-shop action_purchase\" and can be modeled with conditional probability approach. Nevertheless, we observe that the chain rule of conditional probability does not always hold. We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematically. We propose a novel Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue. Specifically, we handle \"exposure_click_in-shop action\" and \"in-shop action_purchase\" separately in the light of characteristics of in-shop action. The first path is still treated with conditional probability while the second one is treated with parameter constraint strategy. Experiments on both offline and online environments in a large-scale recommendation system illustrate the superiority of our proposed methods over state-of-the-art models. The real-world datasets will be released.","sentences":["Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations.","However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues.","Entire space models were proposed to address the two issues via tracing the decision-making path of \"exposure_click_purchase\".","Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance.","Thus, the decision-making path has been extended to \"exposure_click_in-shop action_purchase\" and can be modeled with conditional probability approach.","Nevertheless, we observe that the chain rule of conditional probability does not always hold.","We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematically.","We propose a novel Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.","Specifically, we handle \"exposure_click_in-shop action\" and \"in-shop action_purchase\" separately in the light of characteristics of in-shop action.","The first path is still treated with conditional probability while the second one is treated with parameter constraint strategy.","Experiments on both offline and online environments in a large-scale recommendation system illustrate the superiority of our proposed methods over state-of-the-art models.","The real-world datasets will be released."],"url":"http://arxiv.org/abs/2307.09193v1"}
{"created":"2023-07-18 12:19:47","title":"Need-driven decision-making and prototyping for DLT: Framework and web-based tool","abstract":"In its 14 years, distributed ledger technology has attracted increasing attention, investments, enthusiasm, and user base. However, ongoing doubts about its usefulness and recent losses of trust in prominent cryptocurrencies have fueled deeply skeptical assessments. Multiple groups attempted to disentangle the technology from the associated hype and controversy by building workflows for rapid prototyping and informed decision-making, but their mostly isolated work leaves users only with fewer unclarities. To bridge the gaps between these contributions, we develop a holistic analytical framework and open-source web tool for making evidence-based decisions. Consisting of three stages - evaluation, elicitation, and design - the framework relies on input from the users' domain knowledge, maps their choices, and provides an output of needed technology bundles. We apply it to an example clinical use case to clarify the directions of our contribution charts for prototyping, hopefully driving the conversation towards ways to enhance further tools and approaches.","sentences":["In its 14 years, distributed ledger technology has attracted increasing attention, investments, enthusiasm, and user base.","However, ongoing doubts about its usefulness and recent losses of trust in prominent cryptocurrencies have fueled deeply skeptical assessments.","Multiple groups attempted to disentangle the technology from the associated hype and controversy by building workflows for rapid prototyping and informed decision-making, but their mostly isolated work leaves users only with fewer unclarities.","To bridge the gaps between these contributions, we develop a holistic analytical framework and open-source web tool for making evidence-based decisions.","Consisting of three stages - evaluation, elicitation, and design - the framework relies on input from the users' domain knowledge, maps their choices, and provides an output of needed technology bundles.","We apply it to an example clinical use case to clarify the directions of our contribution charts for prototyping, hopefully driving the conversation towards ways to enhance further tools and approaches."],"url":"http://arxiv.org/abs/2307.09188v1"}
{"created":"2023-07-18 12:18:21","title":"You've Got Two Teachers: Co-evolutionary Image and Report Distillation for Semi-supervised Anatomical Abnormality Detection in Chest X-ray","abstract":"Chest X-ray (CXR) anatomical abnormality detection aims at localizing and characterising cardiopulmonary radiological findings in the radiographs, which can expedite clinical workflow and reduce observational oversights. Most existing methods attempted this task in either fully supervised settings which demanded costly mass per-abnormality annotations, or weakly supervised settings which still lagged badly behind fully supervised methods in performance. In this work, we propose a co-evolutionary image and report distillation (CEIRD) framework, which approaches semi-supervised abnormality detection in CXR by grounding the visual detection results with text-classified abnormalities from paired radiology reports, and vice versa. Concretely, based on the classical teacher-student pseudo label distillation (TSD) paradigm, we additionally introduce an auxiliary report classification model, whose prediction is used for report-guided pseudo detection label refinement (RPDLR) in the primary vision detection task. Inversely, we also use the prediction of the vision detection model for abnormality-guided pseudo classification label refinement (APCLR) in the auxiliary report classification task, and propose a co-evolution strategy where the vision and report models mutually promote each other with RPDLR and APCLR performed alternatively. To this end, we effectively incorporate the weak supervision by reports into the semi-supervised TSD pipeline. Besides the cross-modal pseudo label refinement, we further propose an intra-image-modal self-adaptive non-maximum suppression, where the pseudo detection labels generated by the teacher vision model are dynamically rectified by high-confidence predictions by the student. Experimental results on the public MIMIC-CXR benchmark demonstrate CEIRD's superior performance to several up-to-date weakly and semi-supervised methods.","sentences":["Chest X-ray (CXR) anatomical abnormality detection aims at localizing and characterising cardiopulmonary radiological findings in the radiographs, which can expedite clinical workflow and reduce observational oversights.","Most existing methods attempted this task in either fully supervised settings which demanded costly mass per-abnormality annotations, or weakly supervised settings which still lagged badly behind fully supervised methods in performance.","In this work, we propose a co-evolutionary image and report distillation (CEIRD) framework, which approaches semi-supervised abnormality detection in CXR by grounding the visual detection results with text-classified abnormalities from paired radiology reports, and vice versa.","Concretely, based on the classical teacher-student pseudo label distillation (TSD) paradigm, we additionally introduce an auxiliary report classification model, whose prediction is used for report-guided pseudo detection label refinement (RPDLR) in the primary vision detection task.","Inversely, we also use the prediction of the vision detection model for abnormality-guided pseudo classification label refinement (APCLR) in the auxiliary report classification task, and propose a co-evolution strategy where the vision and report models mutually promote each other with RPDLR and APCLR performed alternatively.","To this end, we effectively incorporate the weak supervision by reports into the semi-supervised TSD pipeline.","Besides the cross-modal pseudo label refinement, we further propose an intra-image-modal self-adaptive non-maximum suppression, where the pseudo detection labels generated by the teacher vision model are dynamically rectified by high-confidence predictions by the student.","Experimental results on the public MIMIC-CXR benchmark demonstrate CEIRD's superior performance to several up-to-date weakly and semi-supervised methods."],"url":"http://arxiv.org/abs/2307.09184v1"}
{"created":"2023-07-18 12:12:42","title":"Pixel-wise Graph Attention Networks for Person Re-identification","abstract":"Graph convolutional networks (GCN) is widely used to handle irregular data since it updates node features by using the structure information of graph. With the help of iterated GCN, high-order information can be obtained to further enhance the representation of nodes. However, how to apply GCN to structured data (such as pictures) has not been deeply studied. In this paper, we explore the application of graph attention networks (GAT) in image feature extraction. First of all, we propose a novel graph generation algorithm to convert images into graphs through matrix transformation. It is one magnitude faster than the algorithm based on K Nearest Neighbors (KNN). Then, GAT is used on the generated graph to update the node features. Thus, a more robust representation is obtained. These two steps are combined into a module called pixel-wise graph attention module (PGA). Since the graph obtained by our graph generation algorithm can still be transformed into a picture after processing, PGA can be well combined with CNN. Based on these two modules, we consulted the ResNet and design a pixel-wise graph attention network (PGANet). The PGANet is applied to the task of person re-identification in the datasets Market1501, DukeMTMC-reID and Occluded-DukeMTMC (outperforms state-of-the-art by 0.8\\%, 1.1\\% and 11\\% respectively, in mAP scores). Experiment results show that it achieves the state-of-the-art performance. \\href{https://github.com/wenyu1009/PGANet}{The code is available here}.","sentences":["Graph convolutional networks (GCN) is widely used to handle irregular data since it updates node features by using the structure information of graph.","With the help of iterated GCN, high-order information can be obtained to further enhance the representation of nodes.","However, how to apply GCN to structured data (such as pictures) has not been deeply studied.","In this paper, we explore the application of graph attention networks (GAT) in image feature extraction.","First of all, we propose a novel graph generation algorithm to convert images into graphs through matrix transformation.","It is one magnitude faster than the algorithm based on K Nearest Neighbors (KNN).","Then, GAT is used on the generated graph to update the node features.","Thus, a more robust representation is obtained.","These two steps are combined into a module called pixel-wise graph attention module (PGA).","Since the graph obtained by our graph generation algorithm can still be transformed into a picture after processing, PGA can be well combined with CNN.","Based on these two modules, we consulted the ResNet and design a pixel-wise graph attention network (PGANet).","The PGANet is applied to the task of person re-identification in the datasets Market1501, DukeMTMC-reID and Occluded-DukeMTMC (outperforms state-of-the-art by 0.8\\%, 1.1\\% and 11\\% respectively, in mAP scores).","Experiment results show that it achieves the state-of-the-art performance.","\\href{https://github.com/wenyu1009/PGANet}{The code is available here}."],"url":"http://arxiv.org/abs/2307.09183v1"}
{"created":"2023-07-18 12:05:36","title":"Federated Learning for Computationally-Constrained Heterogeneous Devices: A Survey","abstract":"With an increasing number of smart devices like internet of things (IoT) devices deployed in the field, offloadingtraining of neural networks (NNs) to a central server becomes more and more infeasible. Recent efforts toimprove users' privacy have led to on-device learning emerging as an alternative. However, a model trainedonly on a single device, using only local data, is unlikely to reach a high accuracy. Federated learning (FL)has been introduced as a solution, offering a privacy-preserving trade-off between communication overheadand model accuracy by sharing knowledge between devices but disclosing the devices' private data. Theapplicability and the benefit of applying baseline FL are, however, limited in many relevant use cases dueto the heterogeneity present in such environments. In this survey, we outline the heterogeneity challengesFL has to overcome to be widely applicable in real-world applications. We especially focus on the aspect ofcomputation heterogeneity among the participating devices and provide a comprehensive overview of recentworks on heterogeneity-aware FL. We discuss two groups: works that adapt the NN architecture and worksthat approach heterogeneity on a system level, covering Federated Averaging (FedAvg), distillation, and splitlearning-based approaches, as well as synchronous and asynchronous aggregation schemes.","sentences":["With an increasing number of smart devices like internet of things (IoT) devices deployed in the field, offloadingtraining of neural networks (NNs) to a central server becomes more and more infeasible.","Recent efforts toimprove users' privacy have led to on-device learning emerging as an alternative.","However, a model trainedonly on a single device, using only local data, is unlikely to reach a high accuracy.","Federated learning (FL)has been introduced as a solution, offering a privacy-preserving trade-off between communication overheadand model accuracy by sharing knowledge between devices but disclosing the devices' private data.","Theapplicability and the benefit of applying baseline FL are, however, limited in many relevant use cases dueto the heterogeneity present in such environments.","In this survey, we outline the heterogeneity challengesFL has to overcome to be widely applicable in real-world applications.","We especially focus on the aspect ofcomputation heterogeneity among the participating devices and provide a comprehensive overview of recentworks on heterogeneity-aware FL.","We discuss two groups: works that adapt the NN architecture and worksthat approach heterogeneity on a system level, covering Federated Averaging (FedAvg), distillation, and splitlearning-based approaches, as well as synchronous and asynchronous aggregation schemes."],"url":"http://arxiv.org/abs/2307.09182v1"}
{"created":"2023-07-18 11:49:40","title":"Jean-Luc Picard at Touch\u00e9 2023: Comparing Image Generation, Stance Detection and Feature Matching for Image Retrieval for Arguments","abstract":"Participating in the shared task \"Image Retrieval for arguments\", we used different pipelines for image retrieval containing Image Generation, Stance Detection, Preselection and Feature Matching. We submitted four different runs with different pipeline layout and compare them to given baseline. Our pipelines perform similarly to the baseline.","sentences":["Participating in the shared task \"Image Retrieval for arguments\", we used different pipelines for image retrieval containing Image Generation, Stance Detection, Preselection and Feature Matching.","We submitted four different runs with different pipeline layout and compare them to given baseline.","Our pipelines perform similarly to the baseline."],"url":"http://arxiv.org/abs/2307.09172v1"}
{"created":"2023-07-18 11:43:01","title":"Towards Trustworthy Dataset Distillation","abstract":"Efficiency and trustworthiness are two eternal pursuits when applying deep learning in real-world applications. With regard to efficiency, dataset distillation (DD) endeavors to reduce training costs by distilling the large dataset into a tiny synthetic dataset. However, existing methods merely concentrate on in-distribution (InD) classification in a closed-world setting, disregarding out-of-distribution (OOD) samples. On the other hand, OOD detection aims to enhance models' trustworthiness, which is always inefficiently achieved in full-data settings. For the first time, we simultaneously consider both issues and propose a novel paradigm called Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and outliers, the condensed datasets are capable to train models competent in both InD classification and OOD detection. To alleviate the requirement of real outlier data and make OOD detection more practical, we further propose to corrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier Exposure (POE). Comprehensive experiments on various settings demonstrate the effectiveness of TrustDD, and the proposed POE surpasses state-of-the-art method Outlier Exposure (OE). Compared with the preceding DD, TrustDD is more trustworthy and applicable to real open-world scenarios. Our code will be publicly available.","sentences":["Efficiency and trustworthiness are two eternal pursuits when applying deep learning in real-world applications.","With regard to efficiency, dataset distillation (DD) endeavors to reduce training costs by distilling the large dataset into a tiny synthetic dataset.","However, existing methods merely concentrate on in-distribution (InD) classification in a closed-world setting, disregarding out-of-distribution (OOD) samples.","On the other hand, OOD detection aims to enhance models' trustworthiness, which is always inefficiently achieved in full-data settings.","For the first time, we simultaneously consider both issues and propose a novel paradigm called Trustworthy Dataset Distillation (TrustDD).","By distilling both InD samples and outliers, the condensed datasets are capable to train models competent in both InD classification and OOD detection.","To alleviate the requirement of real outlier data and make OOD detection more practical, we further propose to corrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier Exposure (POE).","Comprehensive experiments on various settings demonstrate the effectiveness of TrustDD, and the proposed POE surpasses state-of-the-art method Outlier Exposure (OE).","Compared with the preceding DD, TrustDD is more trustworthy and applicable to real open-world scenarios.","Our code will be publicly available."],"url":"http://arxiv.org/abs/2307.09165v1"}
{"created":"2023-07-18 11:40:31","title":"Generative Type Inference for Python","abstract":"Python is a popular dynamic programming language, evidenced by its ranking as the second most commonly used language on GitHub. However, its dynamic type system can lead to potential type errors, leading researchers to explore automatic type inference approaches for Python programs. The rule-based type inference approaches can ensure the accuracy of predicted variable types, but they suffer from low coverage problems. Supervised type inference approaches, while feature-agnostic, require large, high-quality annotated datasets and are limited to pre-defined types. As zero-shot approaches, the cloze-style approaches reformulate the type inference problem into a fill-in-the-blank problem. However, their performance is limited.   This paper introduces TypeGen, a few-shot generative type inference approach that incorporates static domain knowledge from static analysis. TypeGen creates chain-of-thought (COT) prompts by translating the type inference steps of static analysis into prompts based on the type dependency graphs (TDGs), enabling language models to learn from how static analysis infers types. By combining COT prompts with code slices and type hints, TypeGen constructs example prompts from human annotations. TypeGen only requires very few annotated examples to teach language models to generate similar COT prompts via in-context learning. Moreover, TypeGen enhances the interpretability of results through the use of the input-explanation-output strategy. Experiments show that TypeGen outperforms the best baseline Type4Py by 10.0% for argument type prediction and 22.5% in return value type prediction in terms of top-1 Exact Match by using only five examples. Furthermore, TypeGen achieves substantial improvements of 27% to 84% compared to the zero-shot performance of large language models with parameter sizes ranging from 1.3B to 175B in terms of top-1 Exact Match.","sentences":["Python is a popular dynamic programming language, evidenced by its ranking as the second most commonly used language on GitHub.","However, its dynamic type system can lead to potential type errors, leading researchers to explore automatic type inference approaches for Python programs.","The rule-based type inference approaches can ensure the accuracy of predicted variable types, but they suffer from low coverage problems.","Supervised type inference approaches, while feature-agnostic, require large, high-quality annotated datasets and are limited to pre-defined types.","As zero-shot approaches, the cloze-style approaches reformulate the type inference problem into a fill-in-the-blank problem.","However, their performance is limited.   ","This paper introduces TypeGen, a few-shot generative type inference approach that incorporates static domain knowledge from static analysis.","TypeGen creates chain-of-thought (COT) prompts by translating the type inference steps of static analysis into prompts based on the type dependency graphs (TDGs), enabling language models to learn from how static analysis infers types.","By combining COT prompts with code slices and type hints, TypeGen constructs example prompts from human annotations.","TypeGen only requires very few annotated examples to teach language models to generate similar COT prompts via in-context learning.","Moreover, TypeGen enhances the interpretability of results through the use of the input-explanation-output strategy.","Experiments show that TypeGen outperforms the best baseline Type4Py by 10.0% for argument type prediction and 22.5% in return value type prediction in terms of top-1 Exact Match by using only five examples.","Furthermore, TypeGen achieves substantial improvements of 27% to 84% compared to the zero-shot performance of large language models with parameter sizes ranging from 1.3B to 175B in terms of top-1 Exact Match."],"url":"http://arxiv.org/abs/2307.09163v1"}
{"created":"2023-07-18 11:38:45","title":"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications","abstract":"Gender bias in artificial intelligence (AI) and natural language processing has garnered significant attention due to its potential impact on societal perceptions and biases. This research paper aims to analyze gender bias in Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2 and GPT-3.5, some prominent language models, to better understand its implications. Through a comprehensive literature review, the study examines existing research on gender bias in AI language models and identifies gaps in the current knowledge. The methodology involves collecting and preprocessing data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis techniques to evaluate gender bias in the generated text. The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models. The discussion explores the ethical implications of gender bias and its potential consequences on social perceptions and marginalized communities. Additionally, the paper presents strategies for reducing gender bias in LLMs, including algorithmic approaches and data augmentation techniques. The research highlights the importance of interdisciplinary collaborations and the role of sociological studies in mitigating gender bias in AI models. By addressing these issues, we can pave the way for more inclusive and unbiased AI systems that have a positive impact on society.","sentences":["Gender bias in artificial intelligence (AI) and natural language processing has garnered significant attention due to its potential impact on societal perceptions and biases.","This research paper aims to analyze gender bias in Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2 and GPT-3.5, some prominent language models, to better understand its implications.","Through a comprehensive literature review, the study examines existing research on gender bias in AI language models and identifies gaps in the current knowledge.","The methodology involves collecting and preprocessing data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis techniques to evaluate gender bias in the generated text.","The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models.","The discussion explores the ethical implications of gender bias and its potential consequences on social perceptions and marginalized communities.","Additionally, the paper presents strategies for reducing gender bias in LLMs, including algorithmic approaches and data augmentation techniques.","The research highlights the importance of interdisciplinary collaborations and the role of sociological studies in mitigating gender bias in AI models.","By addressing these issues, we can pave the way for more inclusive and unbiased AI systems that have a positive impact on society."],"url":"http://arxiv.org/abs/2307.09162v1"}
{"created":"2023-07-18 11:38:20","title":"CG-fusion CAM: Online segmentation of laser-induced damage on large-aperture optics","abstract":"Online segmentation of laser-induced damage on large-aperture optics in high-power laser facilities is challenged by complicated damage morphology, uneven illumination and stray light interference. Fully supervised semantic segmentation algorithms have achieved state-of-the-art performance, but rely on plenty of pixel-level labels, which are time-consuming and labor-consuming to produce. LayerCAM, an advanced weakly supervised semantic segmentation algorithm, can generate pixel-accurate results using only image-level labels, but its scattered and partially under-activated class activation regions degrade segmentation performance. In this paper, we propose a weakly supervised semantic segmentation method with Continuous Gradient CAM and its nonlinear multi-scale fusion (CG-fusion CAM). The method redesigns the way of back-propagating gradients and non-linearly activates the multi-scale fused heatmaps to generate more fine-grained class activation maps with appropriate activation degree for different sizes of damage sites. Experiments on our dataset show that the proposed method can achieve segmentation performance comparable to that of fully supervised algorithms.","sentences":["Online segmentation of laser-induced damage on large-aperture optics in high-power laser facilities is challenged by complicated damage morphology, uneven illumination and stray light interference.","Fully supervised semantic segmentation algorithms have achieved state-of-the-art performance, but rely on plenty of pixel-level labels, which are time-consuming and labor-consuming to produce.","LayerCAM, an advanced weakly supervised semantic segmentation algorithm, can generate pixel-accurate results using only image-level labels, but its scattered and partially under-activated class activation regions degrade segmentation performance.","In this paper, we propose a weakly supervised semantic segmentation method with Continuous Gradient CAM and its nonlinear multi-scale fusion (CG-fusion CAM).","The method redesigns the way of back-propagating gradients and non-linearly activates the multi-scale fused heatmaps to generate more fine-grained class activation maps with appropriate activation degree for different sizes of damage sites.","Experiments on our dataset show that the proposed method can achieve segmentation performance comparable to that of fully supervised algorithms."],"url":"http://arxiv.org/abs/2307.09161v1"}
{"created":"2023-07-18 11:37:53","title":"Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells","abstract":"Learning-based multi-view stereo (MVS) methods deal with predicting accurate depth maps to achieve an accurate and complete 3D representation. Despite the excellent performance, existing methods ignore the fact that a suitable depth geometry is also critical in MVS. In this paper, we demonstrate that different depth geometries have significant performance gaps, even using the same depth prediction error. Therefore, we introduce an ideal depth geometry composed of Saddle-Shaped Cells, whose predicted depth map oscillates upward and downward around the ground-truth surface, rather than maintaining a continuous and smooth depth plane. To achieve it, we develop a coarse-to-fine framework called Dual-MVSNet (DMVSNet), which can produce an oscillating depth plane. Technically, we predict two depth values for each pixel (Dual-Depth), and propose a novel loss function and a checkerboard-shaped selecting strategy to constrain the predicted depth geometry. Compared to existing methods,DMVSNet achieves a high rank on the DTU benchmark and obtains the top performance on challenging scenes of Tanks and Temples, demonstrating its strong performance and generalization ability. Our method also points to a new research direction for considering depth geometry in MVS.","sentences":["Learning-based multi-view stereo (MVS) methods deal with predicting accurate depth maps to achieve an accurate and complete 3D representation.","Despite the excellent performance, existing methods ignore the fact that a suitable depth geometry is also critical in MVS.","In this paper, we demonstrate that different depth geometries have significant performance gaps, even using the same depth prediction error.","Therefore, we introduce an ideal depth geometry composed of Saddle-Shaped Cells, whose predicted depth map oscillates upward and downward around the ground-truth surface, rather than maintaining a continuous and smooth depth plane.","To achieve it, we develop a coarse-to-fine framework called Dual-MVSNet (DMVSNet), which can produce an oscillating depth plane.","Technically, we predict two depth values for each pixel (Dual-Depth), and propose a novel loss function and a checkerboard-shaped selecting strategy to constrain the predicted depth geometry.","Compared to existing methods,DMVSNet achieves a high rank on the DTU benchmark and obtains the top performance on challenging scenes of Tanks and Temples, demonstrating its strong performance and generalization ability.","Our method also points to a new research direction for considering depth geometry in MVS."],"url":"http://arxiv.org/abs/2307.09160v1"}
{"created":"2023-07-18 11:35:57","title":"Class-relation Knowledge Distillation for Novel Class Discovery","abstract":"We tackle the problem of novel class discovery, which aims to learn novel classes without supervision based on labeled data from known classes. A key challenge lies in transferring the knowledge in the known-class data to the learning of novel classes. Previous methods mainly focus on building a shared representation space for knowledge transfer and often ignore modeling class relations. To address this, we introduce a class relation representation for the novel classes based on the predicted class distribution of a model trained on known classes. Empirically, we find that such class relation becomes less informative during typical discovery training. To prevent such information loss, we propose a novel knowledge distillation framework, which utilizes our class-relation representation to regularize the learning of novel classes. In addition, to enable a flexible knowledge distillation scheme for each data point in novel classes, we develop a learnable weighting function for the regularization, which adaptively promotes knowledge transfer based on the semantic similarity between the novel and known classes. To validate the effectiveness and generalization of our method, we conduct extensive experiments on multiple benchmarks, including CIFAR100, Stanford Cars, CUB, and FGVC-Aircraft datasets. Our results demonstrate that the proposed method outperforms the previous state-of-the-art methods by a significant margin on almost all benchmarks. Code is available at \\href{https://github.com/kleinzcy/Cr-KD-NCD}{here}.","sentences":["We tackle the problem of novel class discovery, which aims to learn novel classes without supervision based on labeled data from known classes.","A key challenge lies in transferring the knowledge in the known-class data to the learning of novel classes.","Previous methods mainly focus on building a shared representation space for knowledge transfer and often ignore modeling class relations.","To address this, we introduce a class relation representation for the novel classes based on the predicted class distribution of a model trained on known classes.","Empirically, we find that such class relation becomes less informative during typical discovery training.","To prevent such information loss, we propose a novel knowledge distillation framework, which utilizes our class-relation representation to regularize the learning of novel classes.","In addition, to enable a flexible knowledge distillation scheme for each data point in novel classes, we develop a learnable weighting function for the regularization, which adaptively promotes knowledge transfer based on the semantic similarity between the novel and known classes.","To validate the effectiveness and generalization of our method, we conduct extensive experiments on multiple benchmarks, including CIFAR100, Stanford Cars, CUB, and FGVC-Aircraft datasets.","Our results demonstrate that the proposed method outperforms the previous state-of-the-art methods by a significant margin on almost all benchmarks.","Code is available at \\href{https://github.com/kleinzcy/Cr-KD-NCD}{here}."],"url":"http://arxiv.org/abs/2307.09158v1"}
{"created":"2023-07-18 11:34:28","title":"Design Patterns for Situated Visualization in Augmented Reality","abstract":"Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics. Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore. However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts. In this work, we leverage the richness of AR research and apply it to situated visualization. We derive design patterns which summarize common approaches of visualizing data in situ. The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise. We discuss design dimensions that help to describe both our patterns and previous work in the literature. This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world. We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows.","sentences":["Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics.","Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore.","However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts.","In this work, we leverage the richness of AR research and apply it to situated visualization.","We derive design patterns which summarize common approaches of visualizing data in situ.","The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise.","We discuss design dimensions that help to describe both our patterns and previous work in the literature.","This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world.","We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows."],"url":"http://arxiv.org/abs/2307.09157v1"}
{"created":"2023-07-18 11:33:14","title":"Reversible cyclic codes over finite chain rings","abstract":"In this paper, necessary and sufficient conditions for the reversibility of a cyclic code of arbitrary length over a finite commutative chain ring have been derived. MDS reversible cyclic codes having length p^s over a finite chain ring with nilpotency index 2 have been characterized and a few examples of MDS reversible cyclic codes have been presented. Further, it is shown that the torsion codes of a reversible cyclic code over a finite chain ring are reversible. Also, an example of a non-reversible cyclic code for which all its torsion codes are reversible has been presented to show that the converse of this statement is not true. The cardinality and Hamming distance of a cyclic code over a finite commutative chain ring have also been determined.","sentences":["In this paper, necessary and sufficient conditions for the reversibility of a cyclic code of arbitrary length over a finite commutative chain ring have been derived.","MDS reversible cyclic codes having length p^s over a finite chain ring with nilpotency index 2 have been characterized and a few examples of MDS reversible cyclic codes have been presented.","Further, it is shown that the torsion codes of a reversible cyclic code over a finite chain ring are reversible.","Also, an example of a non-reversible cyclic code for which all its torsion codes are reversible has been presented to show that the converse of this statement is not true.","The cardinality and Hamming distance of a cyclic code over a finite commutative chain ring have also been determined."],"url":"http://arxiv.org/abs/2307.09156v1"}
{"created":"2023-07-18 11:26:02","title":"MLF-DET: Multi-Level Fusion for Cross-Modal 3D Object Detection","abstract":"In this paper, we propose a novel and effective Multi-Level Fusion network, named as MLF-DET, for high-performance cross-modal 3D object DETection, which integrates both the feature-level fusion and decision-level fusion to fully utilize the information in the image. For the feature-level fusion, we present the Multi-scale Voxel Image fusion (MVI) module, which densely aligns multi-scale voxel features with image features. For the decision-level fusion, we propose the lightweight Feature-cued Confidence Rectification (FCR) module which further exploits image semantics to rectify the confidence of detection candidates. Besides, we design an effective data augmentation strategy termed Occlusion-aware GT Sampling (OGS) to reserve more sampled objects in the training scenes, so as to reduce overfitting. Extensive experiments on the KITTI dataset demonstrate the effectiveness of our method. Notably, on the extremely competitive KITTI car 3D object detection benchmark, our method reaches 82.89% moderate AP and achieves state-of-the-art performance without bells and whistles.","sentences":["In this paper, we propose a novel and effective Multi-Level Fusion network, named as MLF-DET, for high-performance cross-modal 3D object DETection, which integrates both the feature-level fusion and decision-level fusion to fully utilize the information in the image.","For the feature-level fusion, we present the Multi-scale Voxel Image fusion (MVI) module, which densely aligns multi-scale voxel features with image features.","For the decision-level fusion, we propose the lightweight Feature-cued Confidence Rectification (FCR) module which further exploits image semantics to rectify the confidence of detection candidates.","Besides, we design an effective data augmentation strategy termed Occlusion-aware GT Sampling (OGS) to reserve more sampled objects in the training scenes, so as to reduce overfitting.","Extensive experiments on the KITTI dataset demonstrate the effectiveness of our method.","Notably, on the extremely competitive KITTI car 3D object detection benchmark, our method reaches 82.89% moderate AP and achieves state-of-the-art performance without bells and whistles."],"url":"http://arxiv.org/abs/2307.09155v1"}
{"created":"2023-07-18 11:24:42","title":"OPHAvatars: One-shot Photo-realistic Head Avatars","abstract":"We propose a method for synthesizing photo-realistic digital avatars from only one portrait as the reference. Given a portrait, our method synthesizes a coarse talking head video using driving keypoints features. And with the coarse video, our method synthesizes a coarse talking head avatar with a deforming neural radiance field. With rendered images of the coarse avatar, our method updates the low-quality images with a blind face restoration model. With updated images, we retrain the avatar for higher quality. After several iterations, our method can synthesize a photo-realistic animatable 3D neural head avatar. The motivation of our method is deformable neural radiance field can eliminate the unnatural distortion caused by the image2video method. Our method outperforms state-of-the-art methods in quantitative and qualitative studies on various subjects.","sentences":["We propose a method for synthesizing photo-realistic digital avatars from only one portrait as the reference.","Given a portrait, our method synthesizes a coarse talking head video using driving keypoints features.","And with the coarse video, our method synthesizes a coarse talking head avatar with a deforming neural radiance field.","With rendered images of the coarse avatar, our method updates the low-quality images with a blind face restoration model.","With updated images, we retrain the avatar for higher quality.","After several iterations, our method can synthesize a photo-realistic animatable 3D neural head avatar.","The motivation of our method is deformable neural radiance field can eliminate the unnatural distortion caused by the image2video method.","Our method outperforms state-of-the-art methods in quantitative and qualitative studies on various subjects."],"url":"http://arxiv.org/abs/2307.09153v2"}
{"created":"2023-07-18 11:22:31","title":"Enhancing Network Slicing Architectures with Machine Learning, Security, Sustainability and Experimental Networks Integration","abstract":"Network Slicing (NS) is an essential technique extensively used in 5G networks computing strategies, mobile edge computing, mobile cloud computing, and verticals like the Internet of Vehicles and industrial IoT, among others. NS is foreseen as one of the leading enablers for 6G futuristic and highly demanding applications since it allows the optimization and customization of scarce and disputed resources among dynamic, demanding clients with highly distinct application requirements. Various standardization organizations, like 3GPP's proposal for new generation networks and state-of-the-art 5G/6G research projects, are proposing new NS architectures. However, new NS architectures have to deal with an extensive range of requirements that inherently result in having NS architecture proposals typically fulfilling the needs of specific sets of domains with commonalities. The Slicing Future Internet Infrastructures (SFI2) architecture proposal explores the gap resulting from the diversity of NS architectures target domains by proposing a new NS reference architecture with a defined focus on integrating experimental networks and enhancing the NS architecture with Machine Learning (ML) native optimizations, energy-efficient slicing, and slicing-tailored security functionalities. The SFI2 architectural main contribution includes the utilization of the slice-as-a-service paradigm for end-to-end orchestration of resources across multi-domains and multi-technology experimental networks. In addition, the SFI2 reference architecture instantiations will enhance the multi-domain and multi-technology integrated experimental network deployment with native ML optimization, energy-efficient aware slicing, and slicing-tailored security functionalities for the practical domain.","sentences":["Network Slicing (NS) is an essential technique extensively used in 5G networks computing strategies, mobile edge computing, mobile cloud computing, and verticals like the Internet of Vehicles and industrial IoT, among others.","NS is foreseen as one of the leading enablers for 6G futuristic and highly demanding applications since it allows the optimization and customization of scarce and disputed resources among dynamic, demanding clients with highly distinct application requirements.","Various standardization organizations, like 3GPP's proposal for new generation networks and state-of-the-art 5G/6G research projects, are proposing new NS architectures.","However, new NS architectures have to deal with an extensive range of requirements that inherently result in having NS architecture proposals typically fulfilling the needs of specific sets of domains with commonalities.","The Slicing Future Internet Infrastructures (SFI2) architecture proposal explores the gap resulting from the diversity of NS architectures target domains by proposing a new NS reference architecture with a defined focus on integrating experimental networks and enhancing the NS architecture with Machine Learning (ML) native optimizations, energy-efficient slicing, and slicing-tailored security functionalities.","The SFI2 architectural main contribution includes the utilization of the slice-as-a-service paradigm for end-to-end orchestration of resources across multi-domains and multi-technology experimental networks.","In addition, the SFI2 reference architecture instantiations will enhance the multi-domain and multi-technology integrated experimental network deployment with native ML optimization, energy-efficient aware slicing, and slicing-tailored security functionalities for the practical domain."],"url":"http://arxiv.org/abs/2307.09151v1"}
{"created":"2023-07-18 11:20:54","title":"Rule-based Graph Repair using Minimally Restricted Consistency-Improving Transformations","abstract":"Model-driven software engineering is a suitable method for dealing with the ever-increasing complexity of software development processes. Graphs and graph transformations have proven useful for representing such models and changes to them. These models must satisfy certain sets of constraints. An example are the multiplicities of a class structure. During the development process, a change to a model may result in an inconsistent model that must at some point be repaired. This problem is called model repair. In particular, we will consider rule-based graph repair which is defined as follows: Given a graph $G$, a constraint $c$ such that $G$ does not satisfy $c$, and a set of rules $R$, use the rules of $\\mathcal{R}$ to transform $G$ into a graph that satisfies $c$.   Known notions of consistency have either viewed consistency as a binary property, either a graph is consistent w.r.t. a constraint $c$ or not, or only viewed the number of violations of the first graph of a constraint. In this thesis, we introduce new notions of consistency, which we call consistency-maintaining and consistency-increasing transformations and rules, respectively. This is based on the possibility that a constraint can be satisfied up to a certain nesting level.   We present constructions for direct consistency-maintaining or direct consistency-increasing application conditions, respectively. Finally, we present an rule-based graph repair approach that is able to repair so-called \\emph{circular conflict-free constraints}, and so-called circular conflict-free sets of constraints. Intuitively, a set of constraint $C$ is circular conflict free, if there is an ordering $c_1, \\ldots, c_n$ of all constraints of $C$ such that there is no $j <i$ such that a repair of $c_i$ at all graphs satisfying $c_j$ leads to a graph not satisfying $c_j$.","sentences":["Model-driven software engineering is a suitable method for dealing with the ever-increasing complexity of software development processes.","Graphs and graph transformations have proven useful for representing such models and changes to them.","These models must satisfy certain sets of constraints.","An example are the multiplicities of a class structure.","During the development process, a change to a model may result in an inconsistent model that must at some point be repaired.","This problem is called model repair.","In particular, we will consider rule-based graph repair which is defined as follows:","Given a graph $G$, a constraint $c$ such that $G$ does not satisfy $c$, and a set of rules $R$, use the rules of $\\mathcal{R}$ to transform $G$ into a graph that satisfies $c$.   Known notions of consistency have either viewed consistency as a binary property, either a graph is consistent w.r.t.","a constraint $c$ or not, or only viewed the number of violations of the first graph of a constraint.","In this thesis, we introduce new notions of consistency, which we call consistency-maintaining and consistency-increasing transformations and rules, respectively.","This is based on the possibility that a constraint can be satisfied up to a certain nesting level.   ","We present constructions for direct consistency-maintaining or direct consistency-increasing application conditions, respectively.","Finally, we present an rule-based graph repair approach that is able to repair so-called \\emph{circular conflict-free constraints}, and so-called circular conflict-free sets of constraints.","Intuitively, a set of constraint $C$ is circular conflict free, if there is an ordering $c_1, \\ldots, c_n$ of all constraints of $C$ such that there is no $j <i$ such that a repair of $c_i$ at all graphs satisfying $c_j$ leads to a graph not satisfying $c_j$."],"url":"http://arxiv.org/abs/2307.09150v1"}
{"created":"2023-07-18 10:55:54","title":"PRO-Face S: Privacy-preserving Reversible Obfuscation of Face Images via Secure Flow","abstract":"This paper proposes a novel paradigm for facial privacy protection that unifies multiple characteristics including anonymity, diversity, reversibility and security within a single lightweight framework. We name it PRO-Face S, short for Privacy-preserving Reversible Obfuscation of Face images via Secure flow-based model. In the framework, an Invertible Neural Network (INN) is utilized to process the input image along with its pre-obfuscated form, and generate the privacy protected image that visually approximates to the pre-obfuscated one, thus ensuring privacy. The pre-obfuscation applied can be in diversified form with different strengths and styles specified by users. Along protection, a secret key is injected into the network such that the original image can only be recovered from the protection image via the same model given the correct key provided. Two modes of image recovery are devised to deal with malicious recovery attempts in different scenarios. Finally, extensive experiments conducted on three public image datasets demonstrate the superiority of the proposed framework over multiple state-of-the-art approaches.","sentences":["This paper proposes a novel paradigm for facial privacy protection that unifies multiple characteristics including anonymity, diversity, reversibility and security within a single lightweight framework.","We name it PRO-Face S, short for Privacy-preserving Reversible Obfuscation of Face images via Secure flow-based model.","In the framework, an Invertible Neural Network (INN) is utilized to process the input image along with its pre-obfuscated form, and generate the privacy protected image that visually approximates to the pre-obfuscated one, thus ensuring privacy.","The pre-obfuscation applied can be in diversified form with different strengths and styles specified by users.","Along protection, a secret key is injected into the network such that the original image can only be recovered from the protection image via the same model given the correct key provided.","Two modes of image recovery are devised to deal with malicious recovery attempts in different scenarios.","Finally, extensive experiments conducted on three public image datasets demonstrate the superiority of the proposed framework over multiple state-of-the-art approaches."],"url":"http://arxiv.org/abs/2307.09146v1"}
{"created":"2023-07-18 10:54:04","title":"Polynomial Time and Dependent Types","abstract":"We combine dependent types with linear type systems that soundly and completely capture polynomial time computation. We explore two systems for capturing polynomial time: one system that disallows construction of iterable data, and one, based on the LFPL system of Martin Hofmann, that controls construction via a payment method. Both of these are extended to full dependent types via Quantitative Type Theory, allowing for arbitrary computation in types alongside guaranteed polynomial time computation in terms. We prove the soundness of the systems using a realisability technique due to Dal Lago and Hofmann.   Our long-term goal is to combine the extensional reasoning of type theory with intensional reasoning about the resources intrinsically consumed by programs. This paper is a step along this path, which we hope will lead both to practical systems for reasoning about programs' resource usage, and to theoretical use as a form of synthetic computational complexity theory.","sentences":["We combine dependent types with linear type systems that soundly and completely capture polynomial time computation.","We explore two systems for capturing polynomial time: one system that disallows construction of iterable data, and one, based on the LFPL system of Martin Hofmann, that controls construction via a payment method.","Both of these are extended to full dependent types via Quantitative Type Theory, allowing for arbitrary computation in types alongside guaranteed polynomial time computation in terms.","We prove the soundness of the systems using a realisability technique due to Dal Lago and Hofmann.   ","Our long-term goal is to combine the extensional reasoning of type theory with intensional reasoning about the resources intrinsically consumed by programs.","This paper is a step along this path, which we hope will lead both to practical systems for reasoning about programs' resource usage, and to theoretical use as a form of synthetic computational complexity theory."],"url":"http://arxiv.org/abs/2307.09145v1"}
{"created":"2023-07-18 10:52:24","title":"MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset, Methods, and Results","abstract":"Small Object Detection (SOD) is an important machine vision topic because (i) a variety of real-world applications require object detection for distant objects and (ii) SOD is a challenging task due to the noisy, blurred, and less-informative image appearances of small objects. This paper proposes a new SOD dataset consisting of 39,070 images including 137,121 bird instances, which is called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The detail of the challenge with the SOD4SB dataset is introduced in this paper. In total, 223 participants joined this challenge. This paper briefly introduces the award-winning methods. The dataset, the baseline code, and the website for evaluation on the public testset are publicly available.","sentences":["Small Object Detection (SOD) is an important machine vision topic because (i) a variety of real-world applications require object detection for distant objects and (ii) SOD is a challenging task due to the noisy, blurred, and less-informative image appearances of small objects.","This paper proposes a new SOD dataset consisting of 39,070 images including 137,121 bird instances, which is called the Small Object Detection for Spotting Birds (SOD4SB) dataset.","The detail of the challenge with the SOD4SB dataset is introduced in this paper.","In total, 223 participants joined this challenge.","This paper briefly introduces the award-winning methods.","The dataset, the baseline code, and the website for evaluation on the public testset are publicly available."],"url":"http://arxiv.org/abs/2307.09143v1"}
{"created":"2023-07-18 10:46:28","title":"Machine Learning for SAT: Restricted Heuristics and New Graph Representations","abstract":"Boolean satisfiability (SAT) is a fundamental NP-complete problem with many applications, including automated planning and scheduling. To solve large instances, SAT solvers have to rely on heuristics, e.g., choosing a branching variable in DPLL and CDCL solvers. Such heuristics can be improved with machine learning (ML) models; they can reduce the number of steps but usually hinder the running time because useful models are relatively large and slow. We suggest the strategy of making a few initial steps with a trained ML model and then releasing control to classical heuristics; this simplifies cold start for SAT solving and can decrease both the number of steps and overall runtime, but requires a separate decision of when to release control to the solver. Moreover, we introduce a modification of Graph-Q-SAT tailored to SAT problems converted from other domains, e.g., open shop scheduling problems. We validate the feasibility of our approach with random and industrial SAT problems.","sentences":["Boolean satisfiability (SAT) is a fundamental NP-complete problem with many applications, including automated planning and scheduling.","To solve large instances, SAT solvers have to rely on heuristics, e.g., choosing a branching variable in DPLL and CDCL solvers.","Such heuristics can be improved with machine learning (ML) models; they can reduce the number of steps but usually hinder the running time because useful models are relatively large and slow.","We suggest the strategy of making a few initial steps with a trained ML model and then releasing control to classical heuristics; this simplifies cold start for SAT solving and can decrease both the number of steps and overall runtime, but requires a separate decision of when to release control to the solver.","Moreover, we introduce a modification of Graph-Q-SAT tailored to SAT problems converted from other domains, e.g., open shop scheduling problems.","We validate the feasibility of our approach with random and industrial SAT problems."],"url":"http://arxiv.org/abs/2307.09141v1"}
{"created":"2023-07-18 10:34:21","title":"DropMix: Reducing Class Dependency in Mixed Sample Data Augmentation","abstract":"Mixed sample data augmentation (MSDA) is a widely used technique that has been found to improve performance in a variety of tasks. However, in this paper, we show that the effects of MSDA are class-dependent, with some classes seeing an improvement in performance while others experience a decline. To reduce class dependency, we propose the DropMix method, which excludes a specific percentage of data from the MSDA computation. By training on a combination of MSDA and non-MSDA data, the proposed method not only improves the performance of classes that were previously degraded by MSDA, but also increases overall average accuracy, as shown in experiments on two datasets (CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and PuzzleMix).","sentences":["Mixed sample data augmentation (MSDA) is a widely used technique that has been found to improve performance in a variety of tasks.","However, in this paper, we show that the effects of MSDA are class-dependent, with some classes seeing an improvement in performance while others experience a decline.","To reduce class dependency, we propose the DropMix method, which excludes a specific percentage of data from the MSDA computation.","By training on a combination of MSDA and non-MSDA data, the proposed method not only improves the performance of classes that were previously degraded by MSDA, but also increases overall average accuracy, as shown in experiments on two datasets (CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and PuzzleMix)."],"url":"http://arxiv.org/abs/2307.09136v1"}
{"created":"2023-07-18 10:28:55","title":"Cloud-native RStudio on Kubernetes for Hopsworks","abstract":"In order to fully benefit from cloud computing, services are designed following the \"multi-tenant\" architectural model, which is aimed at maximizing resource sharing among users. However, multi-tenancy introduces challenges of security, performance isolation, scaling, and customization. RStudio server is an open-source Integrated Development Environment (IDE) accessible over a web browser for the R programming language. We present the design and implementation of a multi-user distributed system on Hopsworks, a data-intensive AI platform, following the multi-tenant model that provides RStudio as Software as a Service (SaaS). We use the most popular cloud-native technologies: Docker and Kubernetes, to solve the problems of performance isolation, security, and scaling that are present in a multi-tenant environment. We further enable secure data sharing in RStudio server instances to provide data privacy and allow collaboration among RStudio users. We integrate our system with Apache Spark, which can scale and handle Big Data processing workloads. Also, we provide a UI where users can provide custom configurations and have full control of their own RStudio server instances. Our system was tested on a Google Cloud Platform cluster with four worker nodes, each with 30GB of RAM allocated to them. The tests on this cluster showed that 44 RStudio servers, each with 2GB of RAM, can be run concurrently. Our system can scale out to potentially support hundreds of concurrently running RStudio servers by adding more resources (CPUs and RAM) to the cluster or system.","sentences":["In order to fully benefit from cloud computing, services are designed following the \"multi-tenant\" architectural model, which is aimed at maximizing resource sharing among users.","However, multi-tenancy introduces challenges of security, performance isolation, scaling, and customization.","RStudio server is an open-source Integrated Development Environment (IDE) accessible over a web browser for the R programming language.","We present the design and implementation of a multi-user distributed system on Hopsworks, a data-intensive AI platform, following the multi-tenant model that provides RStudio as Software as a Service (SaaS).","We use the most popular cloud-native technologies: Docker and Kubernetes, to solve the problems of performance isolation, security, and scaling that are present in a multi-tenant environment.","We further enable secure data sharing in RStudio server instances to provide data privacy and allow collaboration among RStudio users.","We integrate our system with Apache Spark, which can scale and handle Big Data processing workloads.","Also, we provide a UI where users can provide custom configurations and have full control of their own RStudio server instances.","Our system was tested on a Google Cloud Platform cluster with four worker nodes, each with 30GB of RAM allocated to them.","The tests on this cluster showed that 44 RStudio servers, each with 2GB of RAM, can be run concurrently.","Our system can scale out to potentially support hundreds of concurrently running RStudio servers by adding more resources (CPUs and RAM) to the cluster or system."],"url":"http://arxiv.org/abs/2307.09132v1"}
{"created":"2023-07-18 10:07:06","title":"Light-Weight Vision Transformer with Parallel Local and Global Self-Attention","abstract":"While transformer architectures have dominated computer vision in recent years, these models cannot easily be deployed on hardware with limited resources for autonomous driving tasks that require real-time-performance. Their computational complexity and memory requirements limits their use, especially for applications with high-resolution inputs. In our work, we redesign the powerful state-of-the-art Vision Transformer PLG-ViT to a much more compact and efficient architecture that is suitable for such tasks. We identify computationally expensive blocks in the original PLG-ViT architecture and propose several redesigns aimed at reducing the number of parameters and floating-point operations. As a result of our redesign, we are able to reduce PLG-ViT in size by a factor of 5, with a moderate drop in performance. We propose two variants, optimized for the best trade-off between parameter count to runtime as well as parameter count to accuracy. With only 5 million parameters, we achieve 79.5$\\%$ top-1 accuracy on the ImageNet-1K classification benchmark. Our networks demonstrate great performance on general vision benchmarks like COCO instance segmentation. In addition, we conduct a series of experiments, demonstrating the potential of our approach in solving various tasks specifically tailored to the challenges of autonomous driving and transportation.","sentences":["While transformer architectures have dominated computer vision in recent years, these models cannot easily be deployed on hardware with limited resources for autonomous driving tasks that require real-time-performance.","Their computational complexity and memory requirements limits their use, especially for applications with high-resolution inputs.","In our work, we redesign the powerful state-of-the-art Vision Transformer PLG-ViT to a much more compact and efficient architecture that is suitable for such tasks.","We identify computationally expensive blocks in the original PLG-ViT architecture and propose several redesigns aimed at reducing the number of parameters and floating-point operations.","As a result of our redesign, we are able to reduce PLG-ViT in size by a factor of 5, with a moderate drop in performance.","We propose two variants, optimized for the best trade-off between parameter count to runtime as well as parameter count to accuracy.","With only 5 million parameters, we achieve 79.5$\\%$ top-1 accuracy on the ImageNet-1K classification benchmark.","Our networks demonstrate great performance on general vision benchmarks like COCO instance segmentation.","In addition, we conduct a series of experiments, demonstrating the potential of our approach in solving various tasks specifically tailored to the challenges of autonomous driving and transportation."],"url":"http://arxiv.org/abs/2307.09120v1"}
{"created":"2023-07-18 10:02:09","title":"NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and Repulsive UDF","abstract":"Remarkable progress has been made in 3D reconstruction from single-view RGB-D inputs. MCC is the current state-of-the-art method in this field, which achieves unprecedented success by combining vision Transformers with large-scale training. However, we identified two key limitations of MCC: 1) The Transformer decoder is inefficient in handling large number of query points; 2) The 3D representation struggles to recover high-fidelity details. In this paper, we propose a new approach called NU-MCC that addresses these limitations. NU-MCC includes two key innovations: a Neighborhood decoder and a Repulsive Unsigned Distance Function (Repulsive UDF). First, our Neighborhood decoder introduces center points as an efficient proxy of input visual features, allowing each query point to only attend to a small neighborhood. This design not only results in much faster inference speed but also enables the exploitation of finer-scale visual features for improved recovery of 3D textures. Second, our Repulsive UDF is a novel alternative to the occupancy field used in MCC, significantly improving the quality of 3D object reconstruction. Compared to standard UDFs that suffer from holes in results, our proposed Repulsive UDF can achieve more complete surface reconstruction. Experimental results demonstrate that NU-MCC is able to learn a strong 3D representation, significantly advancing the state of the art in single-view 3D reconstruction. Particularly, it outperforms MCC by 9.7% in terms of the F1-score on the CO3D-v2 dataset with more than 5x faster running speed.","sentences":["Remarkable progress has been made in 3D reconstruction from single-view RGB-D inputs.","MCC is the current state-of-the-art method in this field, which achieves unprecedented success by combining vision Transformers with large-scale training.","However, we identified two key limitations of MCC: 1) The Transformer decoder is inefficient in handling large number of query points; 2)","The 3D representation struggles to recover high-fidelity details.","In this paper, we propose a new approach called NU-MCC that addresses these limitations.","NU-MCC includes two key innovations: a Neighborhood decoder and a Repulsive Unsigned Distance Function (Repulsive UDF).","First, our Neighborhood decoder introduces center points as an efficient proxy of input visual features, allowing each query point to only attend to a small neighborhood.","This design not only results in much faster inference speed but also enables the exploitation of finer-scale visual features for improved recovery of 3D textures.","Second, our Repulsive UDF is a novel alternative to the occupancy field used in MCC, significantly improving the quality of 3D object reconstruction.","Compared to standard UDFs that suffer from holes in results, our proposed Repulsive UDF can achieve more complete surface reconstruction.","Experimental results demonstrate that NU-MCC is able to learn a strong 3D representation, significantly advancing the state of the art in single-view 3D reconstruction.","Particularly, it outperforms MCC by 9.7% in terms of the F1-score on the CO3D-v2 dataset with more than 5x faster running speed."],"url":"http://arxiv.org/abs/2307.09112v1"}
{"created":"2023-07-18 09:58:19","title":"Minimum Target Sets in Non-Progressive Threshold Models: When Timing Matters","abstract":"Let $G$ be a graph, which represents a social network, and suppose each node $v$ has a threshold value $\\tau(v)$. Consider an initial configuration, where each node is either positive or negative. In each discrete time step, a node $v$ becomes/remains positive if at least $\\tau(v)$ of its neighbors are positive and negative otherwise. A node set $\\mathcal{S}$ is a Target Set (TS) whenever the following holds: if $\\mathcal{S}$ is fully positive initially, all nodes in the graph become positive eventually. We focus on a generalization of TS, called Timed TS (TTS), where it is permitted to assign a positive state to a node at any step of the process, rather than just at the beginning.   We provide graph structures for which the minimum TTS is significantly smaller than the minimum TS, indicating that timing is an essential aspect of successful target selection strategies. Furthermore, we prove tight bounds on the minimum size of a TTS in terms of the number of nodes and maximum degree when the thresholds are assigned based on the majority rule.   We show that the problem of determining the minimum size of a TTS is NP-hard and provide an Integer Linear Programming formulation and a greedy algorithm. We evaluate the performance of our algorithm by conducting experiments on various synthetic and real-world networks. We also present a linear-time exact algorithm for trees.","sentences":["Let $G$ be a graph, which represents a social network, and suppose each node $v$ has a threshold value $\\tau(v)$. Consider an initial configuration, where each node is either positive or negative.","In each discrete time step, a node $v$ becomes/remains positive if at least $\\tau(v)$ of its neighbors are positive and negative otherwise.","A node set $\\mathcal{S}$ is a Target Set (TS) whenever the following holds: if $\\mathcal{S}$ is fully positive initially, all nodes in the graph become positive eventually.","We focus on a generalization of TS, called Timed TS (TTS), where it is permitted to assign a positive state to a node at any step of the process, rather than just at the beginning.   ","We provide graph structures for which the minimum TTS is significantly smaller than the minimum TS, indicating that timing is an essential aspect of successful target selection strategies.","Furthermore, we prove tight bounds on the minimum size of a TTS in terms of the number of nodes and maximum degree when the thresholds are assigned based on the majority rule.   ","We show that the problem of determining the minimum size of a TTS is NP-hard and provide an Integer Linear Programming formulation and a greedy algorithm.","We evaluate the performance of our algorithm by conducting experiments on various synthetic and real-world networks.","We also present a linear-time exact algorithm for trees."],"url":"http://arxiv.org/abs/2307.09111v1"}
{"created":"2023-07-18 09:58:15","title":"Mining of Single-Class by Active Learning for Semantic Segmentation","abstract":"Several Active Learning (AL) policies require retraining a target model several times in order to identify the most informative samples and rarely offer the option to focus on the acquisition of samples from underrepresented classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm is introduced where an AL policy is constructed through deep reinforcement learning and exploits quantity-accuracy correlations to build datasets on which high-performance models can be trained with regards to specific classes. MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions as is common in other AL methods. This is thanks to its ability to exploit fixed representations of the candidate data points. We find that MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes, while the strongest baseline only outperforms random on 101 classes.","sentences":["Several Active Learning (AL) policies require retraining a target model several times in order to identify the most informative samples and rarely offer the option to focus on the acquisition of samples from underrepresented classes.","Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm is introduced where an AL policy is constructed through deep reinforcement learning and exploits quantity-accuracy correlations to build datasets on which high-performance models can be trained with regards to specific classes.","MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions as is common in other AL methods.","This is thanks to its ability to exploit fixed representations of the candidate data points.","We find that MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes, while the strongest baseline only outperforms random on 101 classes."],"url":"http://arxiv.org/abs/2307.09109v1"}
{"created":"2023-07-18 09:58:15","title":"Cut Sparsification and Succinct Representation of Submodular Hypergraphs","abstract":"In cut sparsification, all cuts of a hypergraph $H=(V,E,w)$ are approximated within $1\\pm\\epsilon$ factor by a small hypergraph $H'$. This widely applied method was generalized recently to a setting where the cost of cutting each $e\\in E$ is provided by a splitting function, $g_e: 2^e\\to\\mathbb{R}_+$. This generalization is called a submodular hypergraph when the functions $\\{g_e\\}_{e\\in E}$ are submodular, and it arises in machine learning, combinatorial optimization, and algorithmic game theory. Previous work focused on the setting where $H'$ is a reweighted sub-hypergraph of $H$, and measured size by the number of hyperedges in $H'$. We study such sparsification, and also a more general notion of representing $H$ succinctly, where size is measured in bits.   In the sparsification setting, where size is the number of hyperedges, we present three results: (i) all submodular hypergraphs admit sparsifiers of size polynomial in $n=|V|$; (ii) monotone-submodular hypergraphs admit sparsifiers of size $O(\\epsilon^{-2} n^3)$; and (iii) we propose a new parameter, called spread, to obtain even smaller sparsifiers in some cases.   In the succinct-representation setting, we show that a natural family of splitting functions admits a succinct representation of much smaller size than via reweighted subgraphs (almost by factor $n$). This large gap is surprising because for graphs, the most succinct representation is attained by reweighted subgraphs. Along the way, we introduce the notion of deformation, where $g_e$ is decomposed into a sum of functions of small description, and we provide upper and lower bounds for deformation of common splitting functions.","sentences":["In cut sparsification, all cuts of a hypergraph $H=(V,E,w)$ are approximated within $1\\pm\\epsilon$ factor by a small hypergraph $H'$. This widely applied method was generalized recently to a setting where the cost of cutting each $e\\in E$ is provided by a splitting function, $g_e: 2^e\\to\\mathbb{R}_+$.","This generalization is called a submodular hypergraph when the functions $\\{g_e\\}_{e\\in E}$ are submodular, and it arises in machine learning, combinatorial optimization, and algorithmic game theory.","Previous work focused on the setting where $H'$ is a reweighted sub-hypergraph of $H$, and measured size by the number of hyperedges in $H'$. We study such sparsification, and also a more general notion of representing $H$ succinctly, where size is measured in bits.   ","In the sparsification setting, where size is the number of hyperedges, we present three results: (i) all submodular hypergraphs admit sparsifiers of size polynomial in $n=|V|$; (ii) monotone-submodular hypergraphs admit sparsifiers of size $O(\\epsilon^{-2} n^3)$; and (iii) we propose a new parameter, called spread, to obtain even smaller sparsifiers in some cases.   ","In the succinct-representation setting, we show that a natural family of splitting functions admits a succinct representation of much smaller size than via reweighted subgraphs (almost by factor $n$).","This large gap is surprising because for graphs, the most succinct representation is attained by reweighted subgraphs.","Along the way, we introduce the notion of deformation, where $g_e$ is decomposed into a sum of functions of small description, and we provide upper and lower bounds for deformation of common splitting functions."],"url":"http://arxiv.org/abs/2307.09110v1"}
{"created":"2023-07-18 09:54:01","title":"Sampling-based Model Predictive Control Leveraging Parallelizable Physics Simulations","abstract":"We present a method for sampling-based model predictive control that makes use of a generic physics simulator as the dynamical model. In particular, we propose a Model Predictive Path Integral controller (MPPI), that uses the GPU-parallelizable IsaacGym simulator to compute the forward dynamics of a problem. By doing so, we eliminate the need for manual encoding of robot dynamics and interactions among objects and allow one to effortlessly solve complex navigation and contact-rich tasks. Since no explicit dynamic modeling is required, the method is easily extendable to different objects and robots. We demonstrate the effectiveness of this method in several simulated and real-world settings, among which mobile navigation with collision avoidance, non-prehensile manipulation, and whole-body control for high-dimensional configuration spaces. This method is a powerful and accessible tool to solve a large variety of contact-rich motion planning tasks.","sentences":["We present a method for sampling-based model predictive control that makes use of a generic physics simulator as the dynamical model.","In particular, we propose a Model Predictive Path Integral controller (MPPI), that uses the GPU-parallelizable IsaacGym simulator to compute the forward dynamics of a problem.","By doing so, we eliminate the need for manual encoding of robot dynamics and interactions among objects and allow one to effortlessly solve complex navigation and contact-rich tasks.","Since no explicit dynamic modeling is required, the method is easily extendable to different objects and robots.","We demonstrate the effectiveness of this method in several simulated and real-world settings, among which mobile navigation with collision avoidance, non-prehensile manipulation, and whole-body control for high-dimensional configuration spaces.","This method is a powerful and accessible tool to solve a large variety of contact-rich motion planning tasks."],"url":"http://arxiv.org/abs/2307.09105v1"}
{"created":"2023-07-18 09:52:48","title":"Division Gets Better: Learning Brightness-Aware and Detail-Sensitive Representations for Low-Light Image Enhancement","abstract":"Low-light image enhancement strives to improve the contrast, adjust the visibility, and restore the distortion in color and texture. Existing methods usually pay more attention to improving the visibility and contrast via increasing the lightness of low-light images, while disregarding the significance of color and texture restoration for high-quality images. Against above issue, we propose a novel luminance and chrominance dual branch network, termed LCDBNet, for low-light image enhancement, which divides low-light image enhancement into two sub-tasks, e.g., luminance adjustment and chrominance restoration. Specifically, LCDBNet is composed of two branches, namely luminance adjustment network (LAN) and chrominance restoration network (CRN). LAN takes responsibility for learning brightness-aware features leveraging long-range dependency and local attention correlation. While CRN concentrates on learning detail-sensitive features via multi-level wavelet decomposition. Finally, a fusion network is designed to blend their learned features to produce visually impressive images. Extensive experiments conducted on seven benchmark datasets validate the effectiveness of our proposed LCDBNet, and the results manifest that LCDBNet achieves superior performance in terms of multiple reference/non-reference quality evaluators compared to other state-of-the-art competitors. Our code and pretrained model will be available.","sentences":["Low-light image enhancement strives to improve the contrast, adjust the visibility, and restore the distortion in color and texture.","Existing methods usually pay more attention to improving the visibility and contrast via increasing the lightness of low-light images, while disregarding the significance of color and texture restoration for high-quality images.","Against above issue, we propose a novel luminance and chrominance dual branch network, termed LCDBNet, for low-light image enhancement, which divides low-light image enhancement into two sub-tasks, e.g., luminance adjustment and chrominance restoration.","Specifically, LCDBNet is composed of two branches, namely luminance adjustment network (LAN) and chrominance restoration network (CRN).","LAN takes responsibility for learning brightness-aware features leveraging long-range dependency and local attention correlation.","While CRN concentrates on learning detail-sensitive features via multi-level wavelet decomposition.","Finally, a fusion network is designed to blend their learned features to produce visually impressive images.","Extensive experiments conducted on seven benchmark datasets validate the effectiveness of our proposed LCDBNet, and the results manifest that LCDBNet achieves superior performance in terms of multiple reference/non-reference quality evaluators compared to other state-of-the-art competitors.","Our code and pretrained model will be available."],"url":"http://arxiv.org/abs/2307.09104v1"}
{"created":"2023-07-18 09:42:51","title":"A Survey on Multi-Objective Neural Architecture Search","abstract":"Recently, the expert-crafted neural architectures is increasing overtaken by the utilization of neural architecture search (NAS) and automatic generation (and tuning) of network structures which has a close relation to the Hyperparameter Optimization and Auto Machine Learning (AutoML). After the earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective Neural architecture Search (MONAS) has been attracting attentions which considers more goals such as computational complexity, power consumption, and size of the network for optimization, reaching a trade-off between the accuracy and other features like the computational cost. In this paper, we present an overview of principal and state-of-the-art works in the field of MONAS. Starting from a well-categorized taxonomy and formulation for the NAS, we address and correct some miscategorizations in previous surveys of the NAS field. We also provide a list of all known objectives used and add a number of new ones and elaborate their specifications. We have provides analyses about the most important objectives and shown that the stochastic properties of some the them should be differed from deterministic ones in the multi-objective optimization procedure of NAS. We finalize this paper with a number of future directions and topics in the field of MONAS.","sentences":["Recently, the expert-crafted neural architectures is increasing overtaken by the utilization of neural architecture search (NAS) and automatic generation (and tuning) of network structures which has a close relation to the Hyperparameter Optimization and Auto Machine Learning (AutoML).","After the earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective Neural architecture Search (MONAS) has been attracting attentions which considers more goals such as computational complexity, power consumption, and size of the network for optimization, reaching a trade-off between the accuracy and other features like the computational cost.","In this paper, we present an overview of principal and state-of-the-art works in the field of MONAS.","Starting from a well-categorized taxonomy and formulation for the NAS, we address and correct some miscategorizations in previous surveys of the NAS field.","We also provide a list of all known objectives used and add a number of new ones and elaborate their specifications.","We have provides analyses about the most important objectives and shown that the stochastic properties of some the them should be differed from deterministic ones in the multi-objective optimization procedure of NAS.","We finalize this paper with a number of future directions and topics in the field of MONAS."],"url":"http://arxiv.org/abs/2307.09099v1"}
{"created":"2023-07-18 09:22:33","title":"Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related Rewards","abstract":"Sequential decision-making under uncertainty is often associated with long feedback delays. Such delays degrade the performance of the learning agent in identifying a subset of arms with the optimal collective reward in the long run. This problem becomes significantly challenging in a non-stationary environment with structural dependencies amongst the reward distributions associated with the arms. Therefore, besides adapting to delays and environmental changes, learning the causal relations alleviates the adverse effects of feedback delay on the decision-making process. We formalize the described setting as a non-stationary and delayed combinatorial semi-bandit problem with causally related rewards. We model the causal relations by a directed graph in a stationary structural equation model. The agent maximizes the long-term average payoff, defined as a linear function of the base arms' rewards. We develop a policy that learns the structural dependencies from delayed feedback and utilizes that to optimize the decision-making while adapting to drifts. We prove a regret bound for the performance of the proposed algorithm. Besides, we evaluate our method via numerical analysis using synthetic and real-world datasets to detect the regions that contribute the most to the spread of Covid-19 in Italy.","sentences":["Sequential decision-making under uncertainty is often associated with long feedback delays.","Such delays degrade the performance of the learning agent in identifying a subset of arms with the optimal collective reward in the long run.","This problem becomes significantly challenging in a non-stationary environment with structural dependencies amongst the reward distributions associated with the arms.","Therefore, besides adapting to delays and environmental changes, learning the causal relations alleviates the adverse effects of feedback delay on the decision-making process.","We formalize the described setting as a non-stationary and delayed combinatorial semi-bandit problem with causally related rewards.","We model the causal relations by a directed graph in a stationary structural equation model.","The agent maximizes the long-term average payoff, defined as a linear function of the base arms' rewards.","We develop a policy that learns the structural dependencies from delayed feedback and utilizes that to optimize the decision-making while adapting to drifts.","We prove a regret bound for the performance of the proposed algorithm.","Besides, we evaluate our method via numerical analysis using synthetic and real-world datasets to detect the regions that contribute the most to the spread of Covid-19 in Italy."],"url":"http://arxiv.org/abs/2307.09093v1"}
{"created":"2023-07-18 09:17:13","title":"Cr\u00e8me de la Crem: Composable Representable Executable Machines (Architectural Pearl)","abstract":"In this paper we describe how to build software architectures as a composition of state machines, using ideas and principles from the field of Domain-Driven Design. By definition, our approach is modular, allowing one to compose independent subcomponents to create bigger systems, and representable, allowing the implementation of a system to be kept in sync with its graphical representation.   In addition to the design itself we introduce the Crem library, which provides a concrete state machine implementation that is both compositional and representable, Crem uses Haskell's advanced type-level features to allow users to specify allowed and forbidden state transitions, and to encode complex state machine -- and therefore domain-specific -- properties. Moreover, since Crem's state machines are representable, Crem can automatically generate graphical representations of systems from their domain implementations.","sentences":["In this paper we describe how to build software architectures as a composition of state machines, using ideas and principles from the field of Domain-Driven Design.","By definition, our approach is modular, allowing one to compose independent subcomponents to create bigger systems, and representable, allowing the implementation of a system to be kept in sync with its graphical representation.   ","In addition to the design itself we introduce the Crem library, which provides a concrete state machine implementation that is both compositional and representable, Crem uses Haskell's advanced type-level features to allow users to specify allowed and forbidden state transitions, and to encode complex state machine -- and therefore domain-specific -- properties.","Moreover, since Crem's state machines are representable, Crem can automatically generate graphical representations of systems from their domain implementations."],"url":"http://arxiv.org/abs/2307.09090v1"}
{"created":"2023-07-18 09:16:35","title":"Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task Framework to Predicting User Post-click Conversion","abstract":"User post-click conversion prediction is of high interest to researchers and developers. Recent studies employ multi-task learning to tackle the selection bias and data sparsity problem, two severe challenges in post-click behavior prediction, by incorporating click data. However, prior works mainly focused on pointwise learning and the orders of labels (i.e., click and post-click) are not well explored, which naturally poses a listwise learning problem. Inspired by recent advances on differentiable sorting, in this paper, we propose a novel multi-task framework that leverages orders of user behaviors to predict user post-click conversion in an end-to-end approach. Specifically, we define an aggregation operator to combine predicted outputs of different tasks to a unified score, then we use the computed scores to model the label relations via differentiable sorting. Extensive experiments on public and industrial datasets show the superiority of our proposed model against competitive baselines.","sentences":["User post-click conversion prediction is of high interest to researchers and developers.","Recent studies employ multi-task learning to tackle the selection bias and data sparsity problem, two severe challenges in post-click behavior prediction, by incorporating click data.","However, prior works mainly focused on pointwise learning and the orders of labels (i.e., click and post-click) are not well explored, which naturally poses a listwise learning problem.","Inspired by recent advances on differentiable sorting, in this paper, we propose a novel multi-task framework that leverages orders of user behaviors to predict user post-click conversion in an end-to-end approach.","Specifically, we define an aggregation operator to combine predicted outputs of different tasks to a unified score, then we use the computed scores to model the label relations via differentiable sorting.","Extensive experiments on public and industrial datasets show the superiority of our proposed model against competitive baselines."],"url":"http://arxiv.org/abs/2307.09089v1"}
{"created":"2023-07-18 09:12:06","title":"The Hitchhiker's Guide to Malicious Third-Party Dependencies","abstract":"The increasing popularity of certain programming languages has spurred the creation of ecosystem-specific package repositories and package managers. Such repositories (e.g., NPM, PyPI) serve as public databases that users can query to retrieve packages for various functionalities, whereas package managers automatically handle dependency resolution and package installation on the client side. These mechanisms enhance software modularization and accelerate implementation. However, they have become a target for malicious actors seeking to propagate malware on a large scale.   In this work, we show how attackers can leverage capabilities of popular package managers and languages to achieve arbitrary code execution on victim machines, thereby realizing open-source software supply chain attacks. Based on the analysis of 7 ecosystems, we identify 3 install-time and 5 runtime techniques, and we provide recommendations describing how to reduce the risk when consuming third-party dependencies. We will provide proof-of-concepts that demonstrate the identified techniques. Furthermore, we describe evasion strategies employed by attackers to circumvent detection mechanisms.","sentences":["The increasing popularity of certain programming languages has spurred the creation of ecosystem-specific package repositories and package managers.","Such repositories (e.g., NPM, PyPI) serve as public databases that users can query to retrieve packages for various functionalities, whereas package managers automatically handle dependency resolution and package installation on the client side.","These mechanisms enhance software modularization and accelerate implementation.","However, they have become a target for malicious actors seeking to propagate malware on a large scale.   ","In this work, we show how attackers can leverage capabilities of popular package managers and languages to achieve arbitrary code execution on victim machines, thereby realizing open-source software supply chain attacks.","Based on the analysis of 7 ecosystems, we identify 3 install-time and 5 runtime techniques, and we provide recommendations describing how to reduce the risk when consuming third-party dependencies.","We will provide proof-of-concepts that demonstrate the identified techniques.","Furthermore, we describe evasion strategies employed by attackers to circumvent detection mechanisms."],"url":"http://arxiv.org/abs/2307.09087v1"}
{"created":"2023-07-18 09:06:35","title":"Attention over pre-trained Sentence Embeddings for Long Document Classification","abstract":"Despite being the current de-facto models in most NLP tasks, transformers are often limited to short sequences due to their quadratic attention complexity on the number of tokens. Several attempts to address this issue were studied, either by reducing the cost of the self-attention computation or by modeling smaller sequences and combining them through a recurrence mechanism or using a new transformer model. In this paper, we suggest to take advantage of pre-trained sentence transformers to start from semantically meaningful embeddings of the individual sentences, and then combine them through a small attention layer that scales linearly with the document length. We report the results obtained by this simple architecture on three standard document classification datasets. When compared with the current state-of-the-art models using standard fine-tuning, the studied method obtains competitive results (even if there is no clear best model in this configuration). We also showcase that the studied architecture obtains better results when freezing the underlying transformers. A configuration that is useful when we need to avoid complete fine-tuning (e.g. when the same frozen transformer is shared by different applications). Finally, two additional experiments are provided to further evaluate the relevancy of the studied architecture over simpler baselines.","sentences":["Despite being the current de-facto models in most NLP tasks, transformers are often limited to short sequences due to their quadratic attention complexity on the number of tokens.","Several attempts to address this issue were studied, either by reducing the cost of the self-attention computation or by modeling smaller sequences and combining them through a recurrence mechanism or using a new transformer model.","In this paper, we suggest to take advantage of pre-trained sentence transformers to start from semantically meaningful embeddings of the individual sentences, and then combine them through a small attention layer that scales linearly with the document length.","We report the results obtained by this simple architecture on three standard document classification datasets.","When compared with the current state-of-the-art models using standard fine-tuning, the studied method obtains competitive results (even if there is no clear best model in this configuration).","We also showcase that the studied architecture obtains better results when freezing the underlying transformers.","A configuration that is useful when we need to avoid complete fine-tuning (e.g. when the same frozen transformer is shared by different applications).","Finally, two additional experiments are provided to further evaluate the relevancy of the studied architecture over simpler baselines."],"url":"http://arxiv.org/abs/2307.09084v1"}
{"created":"2023-07-18 09:00:26","title":"A Federated learning model for Electric Energy management using Blockchain Technology","abstract":"Energy shortfall and electricity load shedding are the main problems for developing countries. The main causes are lack of management in the energy sector and the use of non-renewable energy sources. The improved energy management and use of renewable sources can be significant to resolve energy crisis. It is necessary to increase the use of renewable energy sources (RESs) to meet the increasing energy demand due to high prices of fossil-fuel based energy. Federated learning (FL) is the most emerging technique in the field of artificial intelligence. Federated learning helps to generate global model at server side by ensemble locally trained models at remote edges sites while preserving data privacy. The global model used to predict energy demand to satisfy the needs of consumers. In this article, we have proposed Blockchain based safe distributed ledger technology for transaction of data between prosumer and consumer to ensure their transparency, traceability and security. Furthermore, we have also proposed a Federated learning model to forecast the energy requirements of consumer and prosumer. Moreover, Blockchain has been used to store excess energy data from prosumer for better management of energy between prosumer and grid. Lastly, the experiment results revealed that renewable energy sources have produced better and comparable results to other non-renewable energy resources.","sentences":["Energy shortfall and electricity load shedding are the main problems for developing countries.","The main causes are lack of management in the energy sector and the use of non-renewable energy sources.","The improved energy management and use of renewable sources can be significant to resolve energy crisis.","It is necessary to increase the use of renewable energy sources (RESs) to meet the increasing energy demand due to high prices of fossil-fuel based energy.","Federated learning (FL) is the most emerging technique in the field of artificial intelligence.","Federated learning helps to generate global model at server side by ensemble locally trained models at remote edges sites while preserving data privacy.","The global model used to predict energy demand to satisfy the needs of consumers.","In this article, we have proposed Blockchain based safe distributed ledger technology for transaction of data between prosumer and consumer to ensure their transparency, traceability and security.","Furthermore, we have also proposed a Federated learning model to forecast the energy requirements of consumer and prosumer.","Moreover, Blockchain has been used to store excess energy data from prosumer for better management of energy between prosumer and grid.","Lastly, the experiment results revealed that renewable energy sources have produced better and comparable results to other non-renewable energy resources."],"url":"http://arxiv.org/abs/2307.09080v1"}
{"created":"2023-07-18 08:52:37","title":"Implementation and Evaluation of Networked Model Predictive Control System on Universal Robot","abstract":"Networked control systems are closed-loop feedback control systems containing system components that may be distributed geographically in different locations and interconnected via a communication network such as the Internet. The quality of network communication is a crucial factor that significantly affects the performance of remote control. This is due to the fact that network uncertainties can occur in the transmission of packets in the forward and backward channels of the system. The two most significant among these uncertainties are network time delay and packet loss. To overcome these challenges, the networked predictive control system has been proposed to provide improved performance and robustness using predictive controllers and compensation strategies. In particular, the model predictive control method is well-suited as an advanced approach compared to conventional methods. In this paper, a networked model predictive control system consisting of a model predictive control method and compensation strategies is implemented to control and stabilize a robot arm as a physical system. In particular, this work aims to analyze the performance of the system under the influence of network time delay and packet loss. Using appropriate performance and robustness metrics, an in-depth investigation of the impacts of these network uncertainties is performed. Furthermore, the forward and backward channels of the network are examined in detail in this study.","sentences":["Networked control systems are closed-loop feedback control systems containing system components that may be distributed geographically in different locations and interconnected via a communication network such as the Internet.","The quality of network communication is a crucial factor that significantly affects the performance of remote control.","This is due to the fact that network uncertainties can occur in the transmission of packets in the forward and backward channels of the system.","The two most significant among these uncertainties are network time delay and packet loss.","To overcome these challenges, the networked predictive control system has been proposed to provide improved performance and robustness using predictive controllers and compensation strategies.","In particular, the model predictive control method is well-suited as an advanced approach compared to conventional methods.","In this paper, a networked model predictive control system consisting of a model predictive control method and compensation strategies is implemented to control and stabilize a robot arm as a physical system.","In particular, this work aims to analyze the performance of the system under the influence of network time delay and packet loss.","Using appropriate performance and robustness metrics, an in-depth investigation of the impacts of these network uncertainties is performed.","Furthermore, the forward and backward channels of the network are examined in detail in this study."],"url":"http://arxiv.org/abs/2307.09076v1"}
{"created":"2023-07-18 08:45:54","title":"DiTTO: Diffusion-inspired Temporal Transformer Operator","abstract":"Solving partial differential equations (PDEs) using a data-driven approach has become increasingly common. The recent development of the operator learning paradigm has enabled the solution of a broader range of PDE-related problems. We propose an operator learning method to solve time-dependent PDEs continuously in time without needing any temporal discretization. The proposed approach, named DiTTO, is inspired by latent diffusion models. While diffusion models are usually used in generative artificial intelligence tasks, their time-conditioning mechanism is extremely useful for PDEs. The diffusion-inspired framework is combined with elements from the Transformer architecture to improve its capabilities.   We demonstrate the effectiveness of the new approach on a wide variety of PDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO achieves state-of-the-art results in terms of accuracy for these problems. We also present a method to improve the performance of DiTTO by using fast sampling concepts from diffusion models. Finally, we show that DiTTO can accurately perform zero-shot super-resolution in time.","sentences":["Solving partial differential equations (PDEs) using a data-driven approach has become increasingly common.","The recent development of the operator learning paradigm has enabled the solution of a broader range of PDE-related problems.","We propose an operator learning method to solve time-dependent PDEs continuously in time without needing any temporal discretization.","The proposed approach, named DiTTO, is inspired by latent diffusion models.","While diffusion models are usually used in generative artificial intelligence tasks, their time-conditioning mechanism is extremely useful for PDEs.","The diffusion-inspired framework is combined with elements from the Transformer architecture to improve its capabilities.   ","We demonstrate the effectiveness of the new approach on a wide variety of PDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO achieves state-of-the-art results in terms of accuracy for these problems.","We also present a method to improve the performance of DiTTO by using fast sampling concepts from diffusion models.","Finally, we show that DiTTO can accurately perform zero-shot super-resolution in time."],"url":"http://arxiv.org/abs/2307.09072v1"}
{"created":"2023-07-18 08:41:17","title":"PixelHuman: Animatable Neural Radiance Fields from Few Images","abstract":"In this paper, we propose PixelHuman, a novel human rendering model that generates animatable human scenes from a few images of a person with unseen identity, views, and poses. Previous work have demonstrated reasonable performance in novel view and pose synthesis, but they rely on a large number of images to train and are trained per scene from videos, which requires significant amount of time to produce animatable scenes from unseen human images. Our method differs from existing methods in that it can generalize to any input image for animatable human synthesis. Given a random pose sequence, our method synthesizes each target scene using a neural radiance field that is conditioned on a canonical representation and pose-aware pixel-aligned features, both of which can be obtained through deformation fields learned in a data-driven manner. Our experiments show that our method achieves state-of-the-art performance in multiview and novel pose synthesis from few-shot images.","sentences":["In this paper, we propose PixelHuman, a novel human rendering model that generates animatable human scenes from a few images of a person with unseen identity, views, and poses.","Previous work have demonstrated reasonable performance in novel view and pose synthesis, but they rely on a large number of images to train and are trained per scene from videos, which requires significant amount of time to produce animatable scenes from unseen human images.","Our method differs from existing methods in that it can generalize to any input image for animatable human synthesis.","Given a random pose sequence, our method synthesizes each target scene using a neural radiance field that is conditioned on a canonical representation and pose-aware pixel-aligned features, both of which can be obtained through deformation fields learned in a data-driven manner.","Our experiments show that our method achieves state-of-the-art performance in multiview and novel pose synthesis from few-shot images."],"url":"http://arxiv.org/abs/2307.09070v1"}
{"created":"2023-07-18 08:39:01","title":"Mitigating Intersection Attacks in Anonymous Microblogging","abstract":"Anonymous microblogging systems are known to be vulnerable to intersection attacks due to network churn. An adversary that monitors all communications can leverage the churn to learn who is publishing what with increasing confidence over time. In this paper, we propose a protocol for mitigating intersection attacks in anonymous microblogging systems by grouping users into anonymity sets based on similarities in their publishing behavior. The protocol provides a configurable communication schedule for users in each set to manage the inevitable trade-off between latency and bandwidth overhead. In our evaluation, we use real-world datasets from two popular microblogging platforms, Twitter and Reddit, to simulate user publishing behavior. The results demonstrate that the protocol can protect users against intersection attacks at low bandwidth overhead when the users adhere to communication schedules. In addition, the protocol can sustain a slow degradation in the size of the anonymity set over time under various churn rates.","sentences":["Anonymous microblogging systems are known to be vulnerable to intersection attacks due to network churn.","An adversary that monitors all communications can leverage the churn to learn who is publishing what with increasing confidence over time.","In this paper, we propose a protocol for mitigating intersection attacks in anonymous microblogging systems by grouping users into anonymity sets based on similarities in their publishing behavior.","The protocol provides a configurable communication schedule for users in each set to manage the inevitable trade-off between latency and bandwidth overhead.","In our evaluation, we use real-world datasets from two popular microblogging platforms, Twitter and Reddit, to simulate user publishing behavior.","The results demonstrate that the protocol can protect users against intersection attacks at low bandwidth overhead when the users adhere to communication schedules.","In addition, the protocol can sustain a slow degradation in the size of the anonymity set over time under various churn rates."],"url":"http://arxiv.org/abs/2307.09069v1"}
{"created":"2023-07-18 08:37:37","title":"PatchCT: Aligning Patch Set and Label Set with Conditional Transport for Multi-Label Image Classification","abstract":"Multi-label image classification is a prediction task that aims to identify more than one label from a given image. This paper considers the semantic consistency of the latent space between the visual patch and linguistic label domains and introduces the conditional transport (CT) theory to bridge the acknowledged gap. While recent cross-modal attention-based studies have attempted to align such two representations and achieved impressive performance, they required carefully-designed alignment modules and extra complex operations in the attention computation. We find that by formulating the multi-label classification as a CT problem, we can exploit the interactions between the image and label efficiently by minimizing the bidirectional CT cost. Specifically, after feeding the images and textual labels into the modality-specific encoders, we view each image as a mixture of patch embeddings and a mixture of label embeddings, which capture the local region features and the class prototypes, respectively. CT is then employed to learn and align those two semantic sets by defining the forward and backward navigators. Importantly, the defined navigators in CT distance model the similarities between patches and labels, which provides an interpretable tool to visualize the learned prototypes. Extensive experiments on three public image benchmarks show that the proposed model consistently outperforms the previous methods. Our code is available at https://github.com/keepgoingjkg/PatchCT.","sentences":["Multi-label image classification is a prediction task that aims to identify more than one label from a given image.","This paper considers the semantic consistency of the latent space between the visual patch and linguistic label domains and introduces the conditional transport (CT) theory to bridge the acknowledged gap.","While recent cross-modal attention-based studies have attempted to align such two representations and achieved impressive performance, they required carefully-designed alignment modules and extra complex operations in the attention computation.","We find that by formulating the multi-label classification as a CT problem, we can exploit the interactions between the image and label efficiently by minimizing the bidirectional CT cost.","Specifically, after feeding the images and textual labels into the modality-specific encoders, we view each image as a mixture of patch embeddings and a mixture of label embeddings, which capture the local region features and the class prototypes, respectively.","CT is then employed to learn and align those two semantic sets by defining the forward and backward navigators.","Importantly, the defined navigators in CT distance model the similarities between patches and labels, which provides an interpretable tool to visualize the learned prototypes.","Extensive experiments on three public image benchmarks show that the proposed model consistently outperforms the previous methods.","Our code is available at https://github.com/keepgoingjkg/PatchCT."],"url":"http://arxiv.org/abs/2307.09066v1"}
{"created":"2023-07-18 08:37:25","title":"Learning Adaptive Neighborhoods for Graph Neural Networks","abstract":"Graph convolutional networks (GCNs) enable end-to-end learning on graph structured data. However, many works assume a given graph structure. When the input graph is noisy or unavailable, one approach is to construct or learn a latent graph structure. These methods typically fix the choice of node degree for the entire graph, which is suboptimal. Instead, we propose a novel end-to-end differentiable graph generator which builds graph topologies where each node selects both its neighborhood and its size. Our module can be readily integrated into existing pipelines involving graph convolution operations, replacing the predetermined or existing adjacency matrix with one that is learned, and optimized, as part of the general objective. As such it is applicable to any GCN. We integrate our module into trajectory prediction, point cloud classification and node classification pipelines resulting in improved accuracy over other structure-learning methods across a wide range of datasets and GCN backbones.","sentences":["Graph convolutional networks (GCNs) enable end-to-end learning on graph structured data.","However, many works assume a given graph structure.","When the input graph is noisy or unavailable, one approach is to construct or learn a latent graph structure.","These methods typically fix the choice of node degree for the entire graph, which is suboptimal.","Instead, we propose a novel end-to-end differentiable graph generator which builds graph topologies where each node selects both its neighborhood and its size.","Our module can be readily integrated into existing pipelines involving graph convolution operations, replacing the predetermined or existing adjacency matrix with one that is learned, and optimized, as part of the general objective.","As such it is applicable to any GCN.","We integrate our module into trajectory prediction, point cloud classification and node classification pipelines resulting in improved accuracy over other structure-learning methods across a wide range of datasets and GCN backbones."],"url":"http://arxiv.org/abs/2307.09065v1"}
{"created":"2023-07-18 08:37:02","title":"Newtonian Program Analysis of Probabilistic Programs","abstract":"Due to their quantitative nature, probabilistic programs pose non-trivial challenges for designing compositional and efficient program analyses. Many analyses for probabilistic programs rely on iterative approximation. This article presents an interprocedural dataflow-analysis framework, called NPA-PMA, for designing and implementing (partially) non-iterative program analyses of probabilistic programs with unstructured control-flow, nondeterminism, and general recursion. NPA-PMA is based on Newtonian Program Analysis (NPA), a generalization of Newton's method to solve equation systems over semirings. The key challenge for developing NPA-PMA is to handle multiple kinds of confluences in both the algebraic structures that specify analyses and the equation systems that encode control flow: semirings support a single confluence operation, whereas NPA-PMA involves three confluence operations (conditional, probabilistic, and nondeterministic).   Our work introduces $\\omega$-continuous pre-Markov algebras ($\\omega$PMAs) to factor out common parts of different analyses; adopts regular infinite-tree expressions to encode program-execution paths in control-flow hyper-graphs; and presents a linearization method that makes Newton's method applicable to the setting of regular-infinite-tree equations over $\\omega$PMAs. NPA-PMA allows analyses to supply a non-iterative strategy to solve linearized equations. Our experimental evaluation demonstrates that (i) NPA-PMA holds considerable promise for outperforming Kleene iteration, and (ii) provides great generality for designing program analyses.","sentences":["Due to their quantitative nature, probabilistic programs pose non-trivial challenges for designing compositional and efficient program analyses.","Many analyses for probabilistic programs rely on iterative approximation.","This article presents an interprocedural dataflow-analysis framework, called NPA-PMA, for designing and implementing (partially) non-iterative program analyses of probabilistic programs with unstructured control-flow, nondeterminism, and general recursion.","NPA-PMA is based on Newtonian Program Analysis (NPA), a generalization of Newton's method to solve equation systems over semirings.","The key challenge for developing NPA-PMA is to handle multiple kinds of confluences in both the algebraic structures that specify analyses and the equation systems that encode control flow: semirings support a single confluence operation, whereas NPA-PMA involves three confluence operations (conditional, probabilistic, and nondeterministic).   ","Our work introduces $\\omega$-continuous pre-Markov algebras ($\\omega$PMAs) to factor out common parts of different analyses; adopts regular infinite-tree expressions to encode program-execution paths in control-flow hyper-graphs; and presents a linearization method that makes Newton's method applicable to the setting of regular-infinite-tree equations over $\\omega$PMAs.","NPA-PMA allows analyses to supply a non-iterative strategy to solve linearized equations.","Our experimental evaluation demonstrates that (i) NPA-PMA holds considerable promise for outperforming Kleene iteration, and (ii) provides great generality for designing program analyses."],"url":"http://arxiv.org/abs/2307.09064v1"}
{"created":"2023-07-18 08:23:46","title":"Unleashing the Imagination of Text: A Novel Framework for Text-to-image Person Retrieval via Exploring the Power of Words","abstract":"The goal of Text-to-image person retrieval is to retrieve person images from a large gallery that match the given textual descriptions. The main challenge of this task lies in the significant differences in information representation between the visual and textual modalities. The textual modality conveys abstract and precise information through vocabulary and grammatical structures, while the visual modality conveys concrete and intuitive information through images. To fully leverage the expressive power of textual representations, it is essential to accurately map abstract textual descriptions to specific images.   To address this issue, we propose a novel framework to Unleash the Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully explore the power of words in sentences. Specifically, the framework employs the pre-trained full CLIP model as a dual encoder for the images and texts , taking advantage of prior cross-modal alignment knowledge. The Text-guided Image Restoration auxiliary task is proposed with the aim of implicitly mapping abstract textual entities to specific image regions, facilitating alignment between textual and visual embeddings. Additionally, we introduce a cross-modal triplet loss tailored for handling hard samples, enhancing the model's ability to distinguish minor differences.   To focus the model on the key components within sentences, we propose a novel text data augmentation technique. Our proposed methods achieve state-of-the-art results on three popular benchmark datasets, and the source code will be made publicly available shortly.","sentences":["The goal of Text-to-image person retrieval is to retrieve person images from a large gallery that match the given textual descriptions.","The main challenge of this task lies in the significant differences in information representation between the visual and textual modalities.","The textual modality conveys abstract and precise information through vocabulary and grammatical structures, while the visual modality conveys concrete and intuitive information through images.","To fully leverage the expressive power of textual representations, it is essential to accurately map abstract textual descriptions to specific images.   ","To address this issue, we propose a novel framework to Unleash the Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully explore the power of words in sentences.","Specifically, the framework employs the pre-trained full CLIP model as a dual encoder for the images and texts , taking advantage of prior cross-modal alignment knowledge.","The Text-guided Image Restoration auxiliary task is proposed with the aim of implicitly mapping abstract textual entities to specific image regions, facilitating alignment between textual and visual embeddings.","Additionally, we introduce a cross-modal triplet loss tailored for handling hard samples, enhancing the model's ability to distinguish minor differences.   ","To focus the model on the key components within sentences, we propose a novel text data augmentation technique.","Our proposed methods achieve state-of-the-art results on three popular benchmark datasets, and the source code will be made publicly available shortly."],"url":"http://arxiv.org/abs/2307.09059v1"}
{"created":"2023-07-18 08:19:53","title":"Investigating drug translational research using PubMed articles","abstract":"Drug research and development are embracing translational research for its potential to increase the number of drugs successfully brought to clinical applications. Using the publicly available PubMed database, we sought to describe the status of drug translational research, the distribution of translational lags for all drugs as well as the collaborations between basic science and clinical science in drug research. For each drug, an indicator called Translational Lag was proposed to quantify the interval time from its first PubMed article to its first clinical article. Meanwhile, the triangle of biomedicine was also used to visualize the status and multidisciplinary collaboration of drug translational research. The results showed that only 18.1% (24,410) of drugs/compounds had been successfully entering clinical research. It averagely took 14.38 years (interquartile range, 4 to 21 years) for a drug from the initial basic discovery to its first clinical research. In addition, the results also revealed that, in drug research, there was rare cooperation between basic science and clinical science, which were more inclined to cooperate within disciplines.","sentences":["Drug research and development are embracing translational research for its potential to increase the number of drugs successfully brought to clinical applications.","Using the publicly available PubMed database, we sought to describe the status of drug translational research, the distribution of translational lags for all drugs as well as the collaborations between basic science and clinical science in drug research.","For each drug, an indicator called Translational Lag was proposed to quantify the interval time from its first PubMed article to its first clinical article.","Meanwhile, the triangle of biomedicine was also used to visualize the status and multidisciplinary collaboration of drug translational research.","The results showed that only 18.1% (24,410) of drugs/compounds had been successfully entering clinical research.","It averagely took 14.38 years (interquartile range, 4 to 21 years) for a drug from the initial basic discovery to its first clinical research.","In addition, the results also revealed that, in drug research, there was rare cooperation between basic science and clinical science, which were more inclined to cooperate within disciplines."],"url":"http://arxiv.org/abs/2307.09056v1"}
{"created":"2023-07-18 08:06:14","title":"Connections between Operator-splitting Methods and Deep Neural Networks with Applications in Image Segmentation","abstract":"Deep neural network is a powerful tool for many tasks. Understanding why it is so successful and providing a mathematical explanation is an important problem and has been one popular research direction in past years. In the literature of mathematical analysis of deep deep neural networks, a lot of works are dedicated to establishing representation theories. How to make connections between deep neural networks and mathematical algorithms is still under development. In this paper, we give an algorithmic explanation for deep neural networks, especially in their connection with operator splitting and multigrid methods. We show that with certain splitting strategies, operator-splitting methods have the same structure as networks. Utilizing this connection and the Potts model for image segmentation, two networks inspired by operator-splitting methods are proposed. The two networks are essentially two operator-splitting algorithms solving the Potts model. Numerical experiments are presented to demonstrate the effectiveness of the proposed networks.","sentences":["Deep neural network is a powerful tool for many tasks.","Understanding why it is so successful and providing a mathematical explanation is an important problem and has been one popular research direction in past years.","In the literature of mathematical analysis of deep deep neural networks, a lot of works are dedicated to establishing representation theories.","How to make connections between deep neural networks and mathematical algorithms is still under development.","In this paper, we give an algorithmic explanation for deep neural networks, especially in their connection with operator splitting and multigrid methods.","We show that with certain splitting strategies, operator-splitting methods have the same structure as networks.","Utilizing this connection and the Potts model for image segmentation, two networks inspired by operator-splitting methods are proposed.","The two networks are essentially two operator-splitting algorithms solving the Potts model.","Numerical experiments are presented to demonstrate the effectiveness of the proposed networks."],"url":"http://arxiv.org/abs/2307.09052v1"}
{"created":"2023-07-18 08:04:27","title":"QMNet: Importance-Aware Message Exchange for Decentralized Multi-Agent Reinforcement Learning","abstract":"To improve the performance of multi-agent reinforcement learning under the constraint of wireless resources, we propose a message importance metric and design an importance-aware scheduling policy to effectively exchange messages. The key insight is spending the precious communication resources on important messages. The message importance depends not only on the messages themselves, but also on the needs of agents who receive them. Accordingly, we propose a query-message-based architecture, called QMNet. Agents generate queries and messages with the environment observation. Sharing queries can help calculate message importance. Exchanging messages can help agents cooperate better. Besides, we exploit the message importance to deal with random access collisions in decentralized systems. Furthermore, a message prediction mechanism is proposed to compensate for messages that are not transmitted. Finally, we evaluate the proposed schemes in a traffic junction environment, where only a fraction of agents can send messages due to limited wireless resources. Results show that QMNet can extract valuable information to guarantee the system performance even when only $30\\%$ of agents can share messages. By exploiting message prediction, the system can further save $40\\%$ of wireless resources. The importance-aware decentralized multi-access mechanism can effectively avoid collisions, achieving almost the same performance as centralized scheduling.","sentences":["To improve the performance of multi-agent reinforcement learning under the constraint of wireless resources, we propose a message importance metric and design an importance-aware scheduling policy to effectively exchange messages.","The key insight is spending the precious communication resources on important messages.","The message importance depends not only on the messages themselves, but also on the needs of agents who receive them.","Accordingly, we propose a query-message-based architecture, called QMNet.","Agents generate queries and messages with the environment observation.","Sharing queries can help calculate message importance.","Exchanging messages can help agents cooperate better.","Besides, we exploit the message importance to deal with random access collisions in decentralized systems.","Furthermore, a message prediction mechanism is proposed to compensate for messages that are not transmitted.","Finally, we evaluate the proposed schemes in a traffic junction environment, where only a fraction of agents can send messages due to limited wireless resources.","Results show that QMNet can extract valuable information to guarantee the system performance even when only $30\\%$ of agents can share messages.","By exploiting message prediction, the system can further save $40\\%$ of wireless resources.","The importance-aware decentralized multi-access mechanism can effectively avoid collisions, achieving almost the same performance as centralized scheduling."],"url":"http://arxiv.org/abs/2307.09051v1"}
{"created":"2023-07-18 08:03:51","title":"R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut","abstract":"Transformer-based models have gained popularity in the field of natural language processing (NLP) and are extensively utilized in computer vision tasks and multi-modal models such as GPT4. This paper presents a novel method to enhance the explainability of Transformer-based image classification models. Our method aims to improve trust in classification results and empower users to gain a deeper understanding of the model for downstream tasks by providing visualizations of class-specific maps. We introduce two modules: the ``Relationship Weighted Out\" and the ``Cut\" modules. The ``Relationship Weighted Out\" module focuses on extracting class-specific information from intermediate layers, enabling us to highlight relevant features. Additionally, the ``Cut\" module performs fine-grained feature decomposition, taking into account factors such as position, texture, and color. By integrating these modules, we generate dense class-specific visual explainability maps. We validate our method with extensive qualitative and quantitative experiments on the ImageNet dataset. Furthermore, we conduct a large number of experiments on the LRN dataset, specifically designed for automatic driving danger alerts, to evaluate the explainability of our method in complex backgrounds. The results demonstrate a significant improvement over previous methods. Moreover, we conduct ablation experiments to validate the effectiveness of each module. Through these experiments, we are able to confirm the respective contributions of each module, thus solidifying the overall effectiveness of our proposed approach.","sentences":["Transformer-based models have gained popularity in the field of natural language processing (NLP) and are extensively utilized in computer vision tasks and multi-modal models such as GPT4.","This paper presents a novel method to enhance the explainability of Transformer-based image classification models.","Our method aims to improve trust in classification results and empower users to gain a deeper understanding of the model for downstream tasks by providing visualizations of class-specific maps.","We introduce two modules: the ``Relationship Weighted Out\" and the ``Cut\" modules.","The ``Relationship Weighted Out\" module focuses on extracting class-specific information from intermediate layers, enabling us to highlight relevant features.","Additionally, the ``Cut\" module performs fine-grained feature decomposition, taking into account factors such as position, texture, and color.","By integrating these modules, we generate dense class-specific visual explainability maps.","We validate our method with extensive qualitative and quantitative experiments on the ImageNet dataset.","Furthermore, we conduct a large number of experiments on the LRN dataset, specifically designed for automatic driving danger alerts, to evaluate the explainability of our method in complex backgrounds.","The results demonstrate a significant improvement over previous methods.","Moreover, we conduct ablation experiments to validate the effectiveness of each module.","Through these experiments, we are able to confirm the respective contributions of each module, thus solidifying the overall effectiveness of our proposed approach."],"url":"http://arxiv.org/abs/2307.09050v1"}
{"created":"2023-07-18 08:00:41","title":"FedDefender: Client-Side Attack-Tolerant Federated Learning","abstract":"Federated learning enables learning from decentralized data sources without compromising privacy, which makes it a crucial technique. However, it is vulnerable to model poisoning attacks, where malicious clients interfere with the training process. Previous defense mechanisms have focused on the server-side by using careful model aggregation, but this may not be effective when the data is not identically distributed or when attackers can access the information of benign clients. In this paper, we propose a new defense mechanism that focuses on the client-side, called FedDefender, to help benign clients train robust local models and avoid the adverse impact of malicious model updates from attackers, even when a server-side defense cannot identify or remove adversaries. Our method consists of two main components: (1) attack-tolerant local meta update and (2) attack-tolerant global knowledge distillation. These components are used to find noise-resilient model parameters while accurately extracting knowledge from a potentially corrupted global model. Our client-side defense strategy has a flexible structure and can work in conjunction with any existing server-side strategies. Evaluations of real-world scenarios across multiple datasets show that the proposed method enhances the robustness of federated learning against model poisoning attacks.","sentences":["Federated learning enables learning from decentralized data sources without compromising privacy, which makes it a crucial technique.","However, it is vulnerable to model poisoning attacks, where malicious clients interfere with the training process.","Previous defense mechanisms have focused on the server-side by using careful model aggregation, but this may not be effective when the data is not identically distributed or when attackers can access the information of benign clients.","In this paper, we propose a new defense mechanism that focuses on the client-side, called FedDefender, to help benign clients train robust local models and avoid the adverse impact of malicious model updates from attackers, even when a server-side defense cannot identify or remove adversaries.","Our method consists of two main components: (1) attack-tolerant local meta update and (2) attack-tolerant global knowledge distillation.","These components are used to find noise-resilient model parameters while accurately extracting knowledge from a potentially corrupted global model.","Our client-side defense strategy has a flexible structure and can work in conjunction with any existing server-side strategies.","Evaluations of real-world scenarios across multiple datasets show that the proposed method enhances the robustness of federated learning against model poisoning attacks."],"url":"http://arxiv.org/abs/2307.09048v1"}
{"created":"2023-07-18 07:59:37","title":"Multimodal Machine Learning for Extraction of Theorems and Proofs in the Scientific Literature","abstract":"Scholarly articles in mathematical fields feature mathematical statements such as theorems, propositions, etc., as well as their proofs. Extracting them from the PDF representation of the articles requires understanding of scientific text along with visual and font-based indicators. We pose this problem as a multimodal classification problem using text, font features, and bitmap image rendering of the PDF as different modalities. In this paper we propose a multimodal machine learning approach for extraction of theorem-like environments and proofs, based on late fusion of features extracted by individual unimodal classifiers, taking into account the sequential succession of blocks in the document. For the text modality, we pretrain a new language model on a 11 GB scientific corpus; experiments shows similar performance for our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence while requiring much less fine-tuning data. Font-based information relies on training a 128-cell LSTM on the sequence of font names and sizes within each block. Bitmap renderings are dealt with using an EfficientNetv2 deep network tuned to classify each image block. Finally, a simple CRF-based approach uses the features of the multimodal model along with information on block sequences. Experimental results show the benefits of using a multimodal approach vs any single modality, as well as major performance improvements using the CRF modeling of block sequences.","sentences":["Scholarly articles in mathematical fields feature mathematical statements such as theorems, propositions, etc., as well as their proofs.","Extracting them from the PDF representation of the articles requires understanding of scientific text along with visual and font-based indicators.","We pose this problem as a multimodal classification problem using text, font features, and bitmap image rendering of the PDF as different modalities.","In this paper we propose a multimodal machine learning approach for extraction of theorem-like environments and proofs, based on late fusion of features extracted by individual unimodal classifiers, taking into account the sequential succession of blocks in the document.","For the text modality, we pretrain a new language model on a 11 GB scientific corpus; experiments shows similar performance for our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence while requiring much less fine-tuning data.","Font-based information relies on training a 128-cell LSTM on the sequence of font names and sizes within each block.","Bitmap renderings are dealt with using an EfficientNetv2 deep network tuned to classify each image block.","Finally, a simple CRF-based approach uses the features of the multimodal model along with information on block sequences.","Experimental results show the benefits of using a multimodal approach vs any single modality, as well as major performance improvements using the CRF modeling of block sequences."],"url":"http://arxiv.org/abs/2307.09047v1"}
{"created":"2023-07-18 07:56:54","title":"6G Network Operation Support System","abstract":"6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society. As the core support system for mobile communication network, 6G OSS needs to achieve high-level network automation, intelligence and digital twinning capabilities to achieve end-to-end autonomous network operation and maintenance, support the operation of typical 6G business scenarios and play a greater social responsibility in the fields of environment, society, and governance (ESG).This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G OSS . It also presents an evolutionary roadmap and technological prospects for the OSS from 5G to 6G.","sentences":["6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society.","As the core support system for mobile communication network, 6G OSS needs to achieve high-level network automation, intelligence and digital twinning capabilities to achieve end-to-end autonomous network operation and maintenance, support the operation of typical 6G business scenarios and play a greater social responsibility in the fields of environment, society, and governance (ESG).This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G OSS .","It also presents an evolutionary roadmap and technological prospects for the OSS from 5G to 6G."],"url":"http://arxiv.org/abs/2307.09045v2"}
{"created":"2023-07-18 07:55:17","title":"3D-SeqMOS: A Novel Sequential 3D Moving Object Segmentation in Autonomous Driving","abstract":"For the SLAM system in robotics and autonomous driving, the accuracy of front-end odometry and back-end loop-closure detection determine the whole intelligent system performance. But the LiDAR-SLAM could be disturbed by current scene moving objects, resulting in drift errors and even loop-closure failure. Thus, the ability to detect and segment moving objects is essential for high-precision positioning and building a consistent map. In this paper, we address the problem of moving object segmentation from 3D LiDAR scans to improve the odometry and loop-closure accuracy of SLAM. We propose a novel 3D Sequential Moving-Object-Segmentation (3D-SeqMOS) method that can accurately segment the scene into moving and static objects, such as moving and static cars. Different from the existing projected-image method, we process the raw 3D point cloud and build a 3D convolution neural network for MOS task. In addition, to make full use of the spatio-temporal information of point cloud, we propose a point cloud residual mechanism using the spatial features of current scan and the temporal features of previous residual scans. Besides, we build a complete SLAM framework to verify the effectiveness and accuracy of 3D-SeqMOS. Experiments on SemanticKITTI dataset show that our proposed 3D-SeqMOS method can effectively detect moving objects and improve the accuracy of LiDAR odometry and loop-closure detection. The test results show our 3D-SeqMOS outperforms the state-of-the-art method by 12.4%. We extend the proposed method to the SemanticKITTI: Moving Object Segmentation competition and achieve the 2nd in the leaderboard, showing its effectiveness.","sentences":["For the SLAM system in robotics and autonomous driving, the accuracy of front-end odometry and back-end loop-closure detection determine the whole intelligent system performance.","But the LiDAR-SLAM could be disturbed by current scene moving objects, resulting in drift errors and even loop-closure failure.","Thus, the ability to detect and segment moving objects is essential for high-precision positioning and building a consistent map.","In this paper, we address the problem of moving object segmentation from 3D LiDAR scans to improve the odometry and loop-closure accuracy of SLAM.","We propose a novel 3D Sequential Moving-Object-Segmentation (3D-SeqMOS) method that can accurately segment the scene into moving and static objects, such as moving and static cars.","Different from the existing projected-image method, we process the raw 3D point cloud and build a 3D convolution neural network for MOS task.","In addition, to make full use of the spatio-temporal information of point cloud, we propose a point cloud residual mechanism using the spatial features of current scan and the temporal features of previous residual scans.","Besides, we build a complete SLAM framework to verify the effectiveness and accuracy of 3D-SeqMOS.","Experiments on SemanticKITTI dataset show that our proposed 3D-SeqMOS method can effectively detect moving objects and improve the accuracy of LiDAR odometry and loop-closure detection.","The test results show our 3D-SeqMOS outperforms the state-of-the-art method by 12.4%.","We extend the proposed method to the SemanticKITTI: Moving Object Segmentation competition and achieve the 2nd in the leaderboard, showing its effectiveness."],"url":"http://arxiv.org/abs/2307.09044v1"}
{"created":"2023-07-18 07:49:38","title":"Emotional Intelligence of Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI, suitable for both humans and LLMs. This test requires evaluating complex emotions (e.g., surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite feeling underperformed, John surprisingly achieved a top score). With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not reply on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-intelligence.github.io/","sentences":["Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning.","However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated.","Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions.","Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI, suitable for both humans and LLMs.","This test requires evaluating complex emotions (e.g., surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite feeling underperformed, John surprisingly achieved a top score).","With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs.","Most achieved above-average EQ scores, with GPT-4 exceeding 89% of human participants with an EQ of 117.","Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not reply on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans.","In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ.","In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence.","Project website: https://emotional-intelligence.github.io/"],"url":"http://arxiv.org/abs/2307.09042v1"}
{"created":"2023-07-18 07:48:48","title":"PottsMGNet: A Mathematical Explanation of Encoder-Decoder Based Neural Networks","abstract":"For problems in image processing and many other fields, a large class of effective neural networks has encoder-decoder-based architectures. Although these networks have made impressive performances, mathematical explanations of their architectures are still underdeveloped. In this paper, we study the encoder-decoder-based network architecture from the algorithmic perspective and provide a mathematical explanation. We use the two-phase Potts model for image segmentation as an example for our explanations. We associate the segmentation problem with a control problem in the continuous setting. Then, multigrid method and operator splitting scheme, the PottsMGNet, are used to discretize the continuous control model. We show that the resulting discrete PottsMGNet is equivalent to an encoder-decoder-based network. With minor modifications, it is shown that a number of the popular encoder-decoder-based neural networks are just instances of the proposed PottsMGNet. By incorporating the Soft-Threshold-Dynamics into the PottsMGNet as a regularizer, the PottsMGNet has shown to be robust with the network parameters such as network width and depth and achieved remarkable performance on datasets with very large noise. In nearly all our experiments, the new network always performs better or as good on accuracy and dice score than existing networks for image segmentation.","sentences":["For problems in image processing and many other fields, a large class of effective neural networks has encoder-decoder-based architectures.","Although these networks have made impressive performances, mathematical explanations of their architectures are still underdeveloped.","In this paper, we study the encoder-decoder-based network architecture from the algorithmic perspective and provide a mathematical explanation.","We use the two-phase Potts model for image segmentation as an example for our explanations.","We associate the segmentation problem with a control problem in the continuous setting.","Then, multigrid method and operator splitting scheme, the PottsMGNet, are used to discretize the continuous control model.","We show that the resulting discrete PottsMGNet is equivalent to an encoder-decoder-based network.","With minor modifications, it is shown that a number of the popular encoder-decoder-based neural networks are just instances of the proposed PottsMGNet.","By incorporating the Soft-Threshold-Dynamics into the PottsMGNet as a regularizer, the PottsMGNet has shown to be robust with the network parameters such as network width and depth and achieved remarkable performance on datasets with very large noise.","In nearly all our experiments, the new network always performs better or as good on accuracy and dice score than existing networks for image segmentation."],"url":"http://arxiv.org/abs/2307.09039v1"}
{"created":"2023-07-18 07:46:25","title":"PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation","abstract":"Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model.","sentences":["Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts.","However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language.","This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts.","The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords.","To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration.","Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model."],"url":"http://arxiv.org/abs/2307.09036v1"}
{"created":"2023-07-18 07:35:28","title":"Online Self-Supervised Thermal Water Segmentation for Aerial Vehicles","abstract":"We present a new method to adapt an RGB-trained water segmentation network to target-domain aerial thermal imagery using online self-supervision by leveraging texture and motion cues as supervisory signals. This new thermal capability enables current autonomous aerial robots operating in near-shore environments to perform tasks such as visual navigation, bathymetry, and flow tracking at night. Our method overcomes the problem of scarce and difficult-to-obtain near-shore thermal data that prevents the application of conventional supervised and unsupervised methods. In this work, we curate the first aerial thermal near-shore dataset, show that our approach outperforms fully-supervised segmentation models trained on limited target-domain thermal data, and demonstrate real-time capabilities onboard an Nvidia Jetson embedded computing platform. Code and datasets used in this work will be available at: https://github.com/connorlee77/uav-thermal-water-segmentation.","sentences":["We present a new method to adapt an RGB-trained water segmentation network to target-domain aerial thermal imagery using online self-supervision by leveraging texture and motion cues as supervisory signals.","This new thermal capability enables current autonomous aerial robots operating in near-shore environments to perform tasks such as visual navigation, bathymetry, and flow tracking at night.","Our method overcomes the problem of scarce and difficult-to-obtain near-shore thermal data that prevents the application of conventional supervised and unsupervised methods.","In this work, we curate the first aerial thermal near-shore dataset, show that our approach outperforms fully-supervised segmentation models trained on limited target-domain thermal data, and demonstrate real-time capabilities onboard an Nvidia Jetson embedded computing platform.","Code and datasets used in this work will be available at: https://github.com/connorlee77/uav-thermal-water-segmentation."],"url":"http://arxiv.org/abs/2307.09027v1"}
{"created":"2023-07-18 07:34:04","title":"ActionPrompt: Action-Guided 3D Human Pose Estimation With Text and Pose Prompting","abstract":"Recent 2D-to-3D human pose estimation (HPE) utilizes temporal consistency across sequences to alleviate the depth ambiguity problem but ignore the action related prior knowledge hidden in the pose sequence. In this paper, we propose a plug-and-play module named Action Prompt Module (APM) that effectively mines different kinds of action clues for 3D HPE. The highlight is that, the mining scheme of APM can be widely adapted to different frameworks and bring consistent benefits. Specifically, we first present a novel Action-related Text Prompt module (ATP) that directly embeds action labels and transfers the rich language information in the label to the pose sequence. Besides, we further introduce Action-specific Pose Prompt module (APP) to mine the position-aware pose pattern of each action, and exploit the correlation between the mined patterns and input pose sequence for further pose refinement. Experiments show that APM can improve the performance of most video-based 2D-to-3D HPE frameworks by a large margin.","sentences":["Recent 2D-to-3D human pose estimation (HPE) utilizes temporal consistency across sequences to alleviate the depth ambiguity problem but ignore the action related prior knowledge hidden in the pose sequence.","In this paper, we propose a plug-and-play module named Action Prompt Module (APM) that effectively mines different kinds of action clues for 3D HPE.","The highlight is that, the mining scheme of APM can be widely adapted to different frameworks and bring consistent benefits.","Specifically, we first present a novel Action-related Text Prompt module (ATP) that directly embeds action labels and transfers the rich language information in the label to the pose sequence.","Besides, we further introduce Action-specific Pose Prompt module (APP) to mine the position-aware pose pattern of each action, and exploit the correlation between the mined patterns and input pose sequence for further pose refinement.","Experiments show that APM can improve the performance of most video-based 2D-to-3D HPE frameworks by a large margin."],"url":"http://arxiv.org/abs/2307.09026v1"}
{"created":"2023-07-18 07:25:38","title":"LA-Net: Landmark-Aware Learning for Reliable Facial Expression Recognition under Label Noise","abstract":"Facial expression recognition (FER) remains a challenging task due to the ambiguity of expressions. The derived noisy labels significantly harm the performance in real-world scenarios. To address this issue, we present a new FER model named Landmark-Aware Net~(LA-Net), which leverages facial landmarks to mitigate the impact of label noise from two perspectives. Firstly, LA-Net uses landmark information to suppress the uncertainty in expression space and constructs the label distribution of each sample by neighborhood aggregation, which in turn improves the quality of training supervision. Secondly, the model incorporates landmark information into expression representations using the devised expression-landmark contrastive loss. The enhanced expression feature extractor can be less susceptible to label noise. Our method can be integrated with any deep neural network for better training supervision without introducing extra inference costs. We conduct extensive experiments on both in-the-wild datasets and synthetic noisy datasets and demonstrate that LA-Net achieves state-of-the-art performance.","sentences":["Facial expression recognition (FER) remains a challenging task due to the ambiguity of expressions.","The derived noisy labels significantly harm the performance in real-world scenarios.","To address this issue, we present a new FER model named Landmark-Aware Net~(LA-Net), which leverages facial landmarks to mitigate the impact of label noise from two perspectives.","Firstly, LA-Net uses landmark information to suppress the uncertainty in expression space and constructs the label distribution of each sample by neighborhood aggregation, which in turn improves the quality of training supervision.","Secondly, the model incorporates landmark information into expression representations using the devised expression-landmark contrastive loss.","The enhanced expression feature extractor can be less susceptible to label noise.","Our method can be integrated with any deep neural network for better training supervision without introducing extra inference costs.","We conduct extensive experiments on both in-the-wild datasets and synthetic noisy datasets and demonstrate that LA-Net achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2307.09023v2"}
{"created":"2023-07-18 07:20:43","title":"Towards a Neural Era in Dialogue Management for Collaboration: A Literature Survey","abstract":"Dialogue-based human-AI collaboration can revolutionize collaborative problem-solving, creative exploration, and social support. To realize this goal, the development of automated agents proficient in skills such as negotiating, following instructions, establishing common ground, and progressing shared tasks is essential. This survey begins by reviewing the evolution of dialogue management paradigms in collaborative dialogue systems, from traditional handcrafted and information-state based methods to AI planning-inspired approaches. It then shifts focus to contemporary data-driven dialogue management techniques, which seek to transfer deep learning successes from form-filling and open-domain settings to collaborative contexts. The paper proceeds to analyze a selected set of recent works that apply neural approaches to collaborative dialogue management, spotlighting prevailing trends in the field. This survey hopes to provide foundational background for future advancements in collaborative dialogue management, particularly as the dialogue systems community continues to embrace the potential of large language models.","sentences":["Dialogue-based human-AI collaboration can revolutionize collaborative problem-solving, creative exploration, and social support.","To realize this goal, the development of automated agents proficient in skills such as negotiating, following instructions, establishing common ground, and progressing shared tasks is essential.","This survey begins by reviewing the evolution of dialogue management paradigms in collaborative dialogue systems, from traditional handcrafted and information-state based methods to AI planning-inspired approaches.","It then shifts focus to contemporary data-driven dialogue management techniques, which seek to transfer deep learning successes from form-filling and open-domain settings to collaborative contexts.","The paper proceeds to analyze a selected set of recent works that apply neural approaches to collaborative dialogue management, spotlighting prevailing trends in the field.","This survey hopes to provide foundational background for future advancements in collaborative dialogue management, particularly as the dialogue systems community continues to embrace the potential of large language models."],"url":"http://arxiv.org/abs/2307.09021v1"}
{"created":"2023-07-18 07:20:31","title":"Face-PAST: Facial Pose Awareness and Style Transfer Networks","abstract":"Facial style transfer has been quite popular among researchers due to the rise of emerging technologies such as eXtended Reality (XR), Metaverse, and Non-Fungible Tokens (NFTs). Furthermore, StyleGAN methods along with transfer-learning strategies have reduced the problem of limited data to some extent. However, most of the StyleGAN methods overfit the styles while adding artifacts to facial images. In this paper, we propose a facial pose awareness and style transfer (Face-PAST) network that preserves facial details and structures while generating high-quality stylized images. Dual StyleGAN inspires our work, but in contrast, our work uses a pre-trained style generation network in an external style pass with a residual modulation block instead of a transform coding block. Furthermore, we use the gated mapping unit and facial structure, identity, and segmentation losses to preserve the facial structure and details. This enables us to train the network with a very limited amount of data while generating high-quality stylized images. Our training process adapts curriculum learning strategy to perform efficient and flexible style mixing in the generative space. We perform extensive experiments to show the superiority of Face-PAST in comparison to existing state-of-the-art methods.","sentences":["Facial style transfer has been quite popular among researchers due to the rise of emerging technologies such as eXtended Reality (XR), Metaverse, and Non-Fungible Tokens (NFTs).","Furthermore, StyleGAN methods along with transfer-learning strategies have reduced the problem of limited data to some extent.","However, most of the StyleGAN methods overfit the styles while adding artifacts to facial images.","In this paper, we propose a facial pose awareness and style transfer (Face-PAST) network that preserves facial details and structures while generating high-quality stylized images.","Dual StyleGAN inspires our work, but in contrast, our work uses a pre-trained style generation network in an external style pass with a residual modulation block instead of a transform coding block.","Furthermore, we use the gated mapping unit and facial structure, identity, and segmentation losses to preserve the facial structure and details.","This enables us to train the network with a very limited amount of data while generating high-quality stylized images.","Our training process adapts curriculum learning strategy to perform efficient and flexible style mixing in the generative space.","We perform extensive experiments to show the superiority of Face-PAST in comparison to existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.09020v1"}
{"created":"2023-07-18 07:15:26","title":"U-shaped Transformer: Retain High Frequency Context in Time Series Analysis","abstract":"Time series prediction plays a crucial role in various industrial fields. In recent years, neural networks with a transformer backbone have achieved remarkable success in many domains, including computer vision and NLP. In time series analysis domain, some studies have suggested that even the simplest MLP networks outperform advanced transformer-based networks on time series forecast tasks. However, we believe these findings indicate there to be low-rank properties in time series sequences. In this paper, we consider the low-pass characteristics of transformers and try to incorporate the advantages of MLP. We adopt skip-layer connections inspired by Unet into traditional transformer backbone, thus preserving high-frequency context from input to output, namely U-shaped Transformer. We introduce patch merge and split operation to extract features with different scales and use larger datasets to fully make use of the transformer backbone. Our experiments demonstrate that the model performs at an advanced level across multiple datasets with relatively low cost.","sentences":["Time series prediction plays a crucial role in various industrial fields.","In recent years, neural networks with a transformer backbone have achieved remarkable success in many domains, including computer vision and NLP.","In time series analysis domain, some studies have suggested that even the simplest MLP networks outperform advanced transformer-based networks on time series forecast tasks.","However, we believe these findings indicate there to be low-rank properties in time series sequences.","In this paper, we consider the low-pass characteristics of transformers and try to incorporate the advantages of MLP.","We adopt skip-layer connections inspired by Unet into traditional transformer backbone, thus preserving high-frequency context from input to output, namely U-shaped Transformer.","We introduce patch merge and split operation to extract features with different scales and use larger datasets to fully make use of the transformer backbone.","Our experiments demonstrate that the model performs at an advanced level across multiple datasets with relatively low cost."],"url":"http://arxiv.org/abs/2307.09019v1"}
{"created":"2023-07-18 07:03:29","title":"Exploring acceptance of autonomous vehicle policies using KeyBERT and SNA: Targeting engineering students","abstract":"This study aims to explore user acceptance of Autonomous Vehicle (AV) policies with improved text-mining methods. Recently, South Korean policymakers have viewed Autonomous Driving Car (ADC) and Autonomous Driving Robot (ADR) as next-generation means of transportation that will reduce the cost of transporting passengers and goods. They support the construction of V2I and V2V communication infrastructures for ADC and recognize that ADR is equivalent to pedestrians to promote its deployment into sidewalks. To fill the gap where end-user acceptance of these policies is not well considered, this study applied two text-mining methods to the comments of graduate students in the fields of Industrial, Mechanical, and Electronics-Electrical-Computer. One is the Co-occurrence Network Analysis (CNA) based on TF-IWF and Dice coefficient, and the other is the Contextual Semantic Network Analysis (C-SNA) based on both KeyBERT, which extracts keywords that contextually represent the comments, and double cosine similarity. The reason for comparing these approaches is to balance interest not only in the implications for the AV policies but also in the need to apply quality text mining to this research domain. Significantly, the limitation of frequency-based text mining, which does not reflect textual context, and the trade-off of adjusting thresholds in Semantic Network Analysis (SNA) were considered. As the results of comparing the two approaches, the C-SNA provided the information necessary to understand users' voices using fewer nodes and features than the CNA. The users who pre-emptively understood the AV policies based on their engineering literacy and the given texts revealed potential risks of the AV accident policies. This study adds suggestions to manage these risks to support the successful deployment of AVs on public roads.","sentences":["This study aims to explore user acceptance of Autonomous Vehicle (AV) policies with improved text-mining methods.","Recently, South Korean policymakers have viewed Autonomous Driving Car (ADC) and Autonomous Driving Robot (ADR) as next-generation means of transportation that will reduce the cost of transporting passengers and goods.","They support the construction of V2I and V2V communication infrastructures for ADC and recognize that ADR is equivalent to pedestrians to promote its deployment into sidewalks.","To fill the gap where end-user acceptance of these policies is not well considered, this study applied two text-mining methods to the comments of graduate students in the fields of Industrial, Mechanical, and Electronics-Electrical-Computer.","One is the Co-occurrence Network Analysis (CNA) based on TF-IWF and Dice coefficient, and the other is the Contextual Semantic Network Analysis (C-SNA) based on both KeyBERT, which extracts keywords that contextually represent the comments, and double cosine similarity.","The reason for comparing these approaches is to balance interest not only in the implications for the AV policies but also in the need to apply quality text mining to this research domain.","Significantly, the limitation of frequency-based text mining, which does not reflect textual context, and the trade-off of adjusting thresholds in Semantic Network Analysis (SNA) were considered.","As the results of comparing the two approaches, the C-SNA provided the information necessary to understand users' voices using fewer nodes and features than the CNA.","The users who pre-emptively understood the AV policies based on their engineering literacy and the given texts revealed potential risks of the AV accident policies.","This study adds suggestions to manage these risks to support the successful deployment of AVs on public roads."],"url":"http://arxiv.org/abs/2307.09014v1"}
{"created":"2023-07-18 06:56:08","title":"How is ChatGPT's behavior changing over time?","abstract":"GPT-3.5 and GPT-4 are the two most widely used large language model (LLM) services. However, when and how these models are updated over time is opaque. Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on four diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous questions, 3) generating code and 4) visual reasoning. We find that the performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time. For example, GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions (accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5 (March 2023) in this task. GPT-4 was less willing to answer sensitive questions in June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes in code generation in June than in March. Overall, our findings shows that the behavior of the same LLM service can change substantially in a relatively short amount of time, highlighting the need for continuous monitoring of LLM quality.","sentences":["GPT-3.5 and GPT-4 are the two most widely used large language model (LLM) services.","However, when and how these models are updated over time is opaque.","Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on four diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous questions, 3) generating code and 4) visual reasoning.","We find that the performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.","For example, GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions (accuracy 2.4%).","Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5 (March 2023) in this task.","GPT-4 was less willing to answer sensitive questions in June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes in code generation in June than in March.","Overall, our findings shows that the behavior of the same LLM service can change substantially in a relatively short amount of time, highlighting the need for continuous monitoring of LLM quality."],"url":"http://arxiv.org/abs/2307.09009v1"}
{"created":"2023-07-18 06:48:52","title":"On the (In)Effectiveness of Large Language Models for Chinese Text Correction","abstract":"Recently, the development and progress of Large Language Models (LLMs) have amazed the entire Artificial Intelligence community. As an outstanding representative of LLMs and the foundation model that set off this wave of research on LLMs, ChatGPT has attracted more and more researchers to study its capabilities and performance on various downstream Natural Language Processing (NLP) tasks. While marveling at ChatGPT's incredible performance on kinds of tasks, we notice that ChatGPT also has excellent multilingual processing capabilities, such as Chinese. To explore the Chinese processing ability of ChatGPT, we focus on Chinese Text Correction, a fundamental and challenging Chinese NLP task. Specifically, we evaluate ChatGPT on the Chinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC) tasks, which are two main Chinese Text Correction scenarios. From extensive analyses and comparisons with previous state-of-the-art fine-tuned models, we empirically find that the ChatGPT currently has both amazing performance and unsatisfactory behavior for Chinese Text Correction. We believe our findings will promote the landing and application of LLMs in the Chinese NLP community.","sentences":["Recently, the development and progress of Large Language Models (LLMs) have amazed the entire Artificial Intelligence community.","As an outstanding representative of LLMs and the foundation model that set off this wave of research on LLMs, ChatGPT has attracted more and more researchers to study its capabilities and performance on various downstream Natural Language Processing (NLP) tasks.","While marveling at ChatGPT's incredible performance on kinds of tasks, we notice that ChatGPT also has excellent multilingual processing capabilities, such as Chinese.","To explore the Chinese processing ability of ChatGPT, we focus on Chinese Text Correction, a fundamental and challenging Chinese NLP task.","Specifically, we evaluate ChatGPT on the Chinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC) tasks, which are two main Chinese Text Correction scenarios.","From extensive analyses and comparisons with previous state-of-the-art fine-tuned models, we empirically find that the ChatGPT currently has both amazing performance and unsatisfactory behavior for Chinese Text Correction.","We believe our findings will promote the landing and application of LLMs in the Chinese NLP community."],"url":"http://arxiv.org/abs/2307.09007v1"}
{"created":"2023-07-18 06:48:39","title":"OxfordVGG Submission to the EGO4D AV Transcription Challenge","abstract":"This report presents the technical details of our submission on the EGO4D Audio-Visual (AV) Automatic Speech Recognition Challenge 2023 from the OxfordVGG team. We present WhisperX, a system for efficient speech transcription of long-form audio with word-level time alignment, along with two text normalisers which are publicly available. Our final submission obtained 56.0% of the Word Error Rate (WER) on the challenge test set, ranked 1st on the leaderboard. All baseline codes and models are available on https://github.com/m-bain/whisperX.","sentences":["This report presents the technical details of our submission on the EGO4D Audio-Visual (AV) Automatic Speech Recognition Challenge 2023 from the OxfordVGG team.","We present WhisperX, a system for efficient speech transcription of long-form audio with word-level time alignment, along with two text normalisers which are publicly available.","Our final submission obtained 56.0% of the Word Error Rate (WER) on the challenge test set, ranked 1st on the leaderboard.","All baseline codes and models are available on https://github.com/m-bain/whisperX."],"url":"http://arxiv.org/abs/2307.09006v1"}
{"created":"2023-07-18 06:44:20","title":"Ord2Seq: Regard Ordinal Regression as Label Sequence Prediction","abstract":"Ordinal regression refers to classifying object instances into ordinal categories. It has been widely studied in many scenarios, such as medical disease grading, movie rating, etc. Known methods focused only on learning inter-class ordinal relationships, but still incur limitations in distinguishing adjacent categories thus far. In this paper, we propose a simple sequence prediction framework for ordinal regression called Ord2Seq, which, for the first time, transforms each ordinal category label into a special label sequence and thus regards an ordinal regression task as a sequence prediction process. In this way, we decompose an ordinal regression task into a series of recursive binary classification steps, so as to subtly distinguish adjacent categories. Comprehensive experiments show the effectiveness of distinguishing adjacent categories for performance improvement and our new approach exceeds state-of-the-art performances in four different scenarios. Codes will be available upon acceptance.","sentences":["Ordinal regression refers to classifying object instances into ordinal categories.","It has been widely studied in many scenarios, such as medical disease grading, movie rating, etc. Known methods focused only on learning inter-class ordinal relationships, but still incur limitations in distinguishing adjacent categories thus far.","In this paper, we propose a simple sequence prediction framework for ordinal regression called Ord2Seq, which, for the first time, transforms each ordinal category label into a special label sequence and thus regards an ordinal regression task as a sequence prediction process.","In this way, we decompose an ordinal regression task into a series of recursive binary classification steps, so as to subtly distinguish adjacent categories.","Comprehensive experiments show the effectiveness of distinguishing adjacent categories for performance improvement and our new approach exceeds state-of-the-art performances in four different scenarios.","Codes will be available upon acceptance."],"url":"http://arxiv.org/abs/2307.09004v1"}
{"created":"2023-07-18 06:38:20","title":"CBSeq: A Channel-level Behavior Sequence For Encrypted Malware Traffic Detection","abstract":"Machine learning and neural networks have become increasingly popular solutions for encrypted malware traffic detection. They mine and learn complex traffic patterns, enabling detection by fitting boundaries between malware traffic and benign traffic. Compared with signature-based methods, they have higher scalability and flexibility. However, affected by the frequent variants and updates of malware, current methods suffer from a high false positive rate and do not work well for unknown malware traffic detection. It remains a critical task to achieve effective malware traffic detection. In this paper, we introduce CBSeq to address the above problems. CBSeq is a method that constructs a stable traffic representation, behavior sequence, to characterize attacking intent and achieve malware traffic detection. We novelly propose the channels with similar behavior as the detection object and extract side-channel content to construct behavior sequence. Unlike benign activities, the behavior sequences of malware and its variant's traffic exhibit solid internal correlations. Moreover, we design the MSFormer, a powerful Transformer-based multi-sequence fusion classifier. It captures the internal similarity of behavior sequence, thereby distinguishing malware traffic from benign traffic. Our evaluations demonstrate that CBSeq performs effectively in various known malware traffic detection and exhibits superior performance in unknown malware traffic detection, outperforming state-of-the-art methods.","sentences":["Machine learning and neural networks have become increasingly popular solutions for encrypted malware traffic detection.","They mine and learn complex traffic patterns, enabling detection by fitting boundaries between malware traffic and benign traffic.","Compared with signature-based methods, they have higher scalability and flexibility.","However, affected by the frequent variants and updates of malware, current methods suffer from a high false positive rate and do not work well for unknown malware traffic detection.","It remains a critical task to achieve effective malware traffic detection.","In this paper, we introduce CBSeq to address the above problems.","CBSeq is a method that constructs a stable traffic representation, behavior sequence, to characterize attacking intent and achieve malware traffic detection.","We novelly propose the channels with similar behavior as the detection object and extract side-channel content to construct behavior sequence.","Unlike benign activities, the behavior sequences of malware and its variant's traffic exhibit solid internal correlations.","Moreover, we design the MSFormer, a powerful Transformer-based multi-sequence fusion classifier.","It captures the internal similarity of behavior sequence, thereby distinguishing malware traffic from benign traffic.","Our evaluations demonstrate that CBSeq performs effectively in various known malware traffic detection and exhibits superior performance in unknown malware traffic detection, outperforming state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.09002v1"}
{"created":"2023-07-18 06:36:04","title":"On Borrowed Time -- Preventing Static Power Side-Channel Analysis","abstract":"In recent years, static power side-channel analysis attacks have emerged as a serious threat to cryptographic implementations, overcoming state-of-the-art countermeasures against side-channel attacks. The continued down-scaling of semiconductor process technology, which results in an increase of the relative weight of static power in the total power budget of circuits, will only improve the viability of static power side-channel analysis attacks. Yet, despite the threat posed, limited work has been invested into mitigating this class of attack. In this work we address this gap. We observe that static power side-channel analysis relies on stopping the target circuit's clock over a prolonged period, during which the circuit holds secret information in its registers. We propose Borrowed Time, a countermeasure that hinders an attacker's ability to leverage such clock control. Borrowed Time detects a stopped clock and triggers a reset that wipes any registers containing sensitive intermediates, whose leakages would otherwise be exploitable. We demonstrate the effectiveness of our countermeasure by performing practical Correlation Power Analysis attacks under optimal conditions against an AES implementation on an FPGA target with and without our countermeasure in place. In the unprotected case, we can recover the entire secret key using traces from 1,500 encryptions. Under the same conditions, the protected implementation successfully prevents key recovery even with traces from 1,000,000 encryptions.","sentences":["In recent years, static power side-channel analysis attacks have emerged as a serious threat to cryptographic implementations, overcoming state-of-the-art countermeasures against side-channel attacks.","The continued down-scaling of semiconductor process technology, which results in an increase of the relative weight of static power in the total power budget of circuits, will only improve the viability of static power side-channel analysis attacks.","Yet, despite the threat posed, limited work has been invested into mitigating this class of attack.","In this work we address this gap.","We observe that static power side-channel analysis relies on stopping the target circuit's clock over a prolonged period, during which the circuit holds secret information in its registers.","We propose Borrowed Time, a countermeasure that hinders an attacker's ability to leverage such clock control.","Borrowed Time detects a stopped clock and triggers a reset that wipes any registers containing sensitive intermediates, whose leakages would otherwise be exploitable.","We demonstrate the effectiveness of our countermeasure by performing practical Correlation Power Analysis attacks under optimal conditions against an AES implementation on an FPGA target with and without our countermeasure in place.","In the unprotected case, we can recover the entire secret key using traces from 1,500 encryptions.","Under the same conditions, the protected implementation successfully prevents key recovery even with traces from 1,000,000 encryptions."],"url":"http://arxiv.org/abs/2307.09001v1"}
{"created":"2023-07-18 06:35:12","title":"TractCloud: Registration-free tractography parcellation with a novel local-global streamline point cloud representation","abstract":"Diffusion MRI tractography parcellation classifies streamlines into anatomical fiber tracts to enable quantification and visualization for clinical and scientific applications. Current tractography parcellation methods rely heavily on registration, but registration inaccuracies can affect parcellation and the computational cost of registration is high for large-scale datasets. Recently, deep-learning-based methods have been proposed for tractography parcellation using various types of representations for streamlines. However, these methods only focus on the information from a single streamline, ignoring geometric relationships between the streamlines in the brain. We propose TractCloud, a registration-free framework that performs whole-brain tractography parcellation directly in individual subject space. We propose a novel, learnable, local-global streamline representation that leverages information from neighboring and whole-brain streamlines to describe the local anatomy and global pose of the brain. We train our framework on a large-scale labeled tractography dataset, which we augment by applying synthetic transforms including rotation, scaling, and translations. We test our framework on five independently acquired datasets across populations and health conditions. TractCloud significantly outperforms several state-of-the-art methods on all testing datasets. TractCloud achieves efficient and consistent whole-brain white matter parcellation across the lifespan (from neonates to elderly subjects, including brain tumor patients) without the need for registration. The robustness and high inference speed of TractCloud make it suitable for large-scale tractography data analysis. Our project page is available at https://tractcloud.github.io/.","sentences":["Diffusion MRI tractography parcellation classifies streamlines into anatomical fiber tracts to enable quantification and visualization for clinical and scientific applications.","Current tractography parcellation methods rely heavily on registration, but registration inaccuracies can affect parcellation and the computational cost of registration is high for large-scale datasets.","Recently, deep-learning-based methods have been proposed for tractography parcellation using various types of representations for streamlines.","However, these methods only focus on the information from a single streamline, ignoring geometric relationships between the streamlines in the brain.","We propose TractCloud, a registration-free framework that performs whole-brain tractography parcellation directly in individual subject space.","We propose a novel, learnable, local-global streamline representation that leverages information from neighboring and whole-brain streamlines to describe the local anatomy and global pose of the brain.","We train our framework on a large-scale labeled tractography dataset, which we augment by applying synthetic transforms including rotation, scaling, and translations.","We test our framework on five independently acquired datasets across populations and health conditions.","TractCloud significantly outperforms several state-of-the-art methods on all testing datasets.","TractCloud achieves efficient and consistent whole-brain white matter parcellation across the lifespan (from neonates to elderly subjects, including brain tumor patients) without the need for registration.","The robustness and high inference speed of TractCloud make it suitable for large-scale tractography data analysis.","Our project page is available at https://tractcloud.github.io/."],"url":"http://arxiv.org/abs/2307.09000v1"}
{"created":"2023-07-18 06:34:32","title":"Oracle Efficient Online Multicalibration and Omniprediction","abstract":"A recent line of work has shown a surprising connection between multicalibration, a multi-group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions. Prior work studies omniprediction in the batch setting. We initiate the study of omniprediction in the online adversarial setting. Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting, unlike batch algorithms, they work only for small finite classes of benchmark functions $F$, because they require enumerating every function $f \\in F$ at every round. In contrast, omniprediction is most interesting for learning theoretic hypothesis classes $F$, which are generally continuously large.   We develop a new online multicalibration algorithm that is well defined for infinite benchmark classes $F$, and is oracle efficient (i.e. for any class $F$, the algorithm has the form of an efficient reduction to a no-regret learning algorithm for $F$). The result is the first efficient online omnipredictor -- an oracle efficient prediction algorithm that can be used to simultaneously obtain no regret guarantees to all Lipschitz convex loss functions. For the class $F$ of linear functions, we show how to make our algorithm efficient in the worst case. Also, we show upper and lower bounds on the extent to which our rates can be improved: our oracle efficient algorithm actually promises a stronger guarantee called swap-omniprediction, and we prove a lower bound showing that obtaining $O(\\sqrt{T})$ bounds for swap-omniprediction is impossible in the online setting. On the other hand, we give a (non-oracle efficient) algorithm which can obtain the optimal $O(\\sqrt{T})$ omniprediction bounds without going through multicalibration, giving an information theoretic separation between these two solution concepts.","sentences":["A recent line of work has shown a surprising connection between multicalibration, a multi-group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions.","Prior work studies omniprediction in the batch setting.","We initiate the study of omniprediction in the online adversarial setting.","Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting, unlike batch algorithms, they work only for small finite classes of benchmark functions $F$, because they require enumerating every function $f \\in F$ at every round.","In contrast, omniprediction is most interesting for learning theoretic hypothesis classes $F$, which are generally continuously large.   ","We develop a new online multicalibration algorithm that is well defined for infinite benchmark classes $F$, and is oracle efficient (i.e. for any class $F$, the algorithm has the form of an efficient reduction to a no-regret learning algorithm for $F$).","The result is the first efficient online omnipredictor -- an oracle efficient prediction algorithm that can be used to simultaneously obtain no regret guarantees to all Lipschitz convex loss functions.","For the class $F$ of linear functions, we show how to make our algorithm efficient in the worst case.","Also, we show upper and lower bounds on the extent to which our rates can be improved: our oracle efficient algorithm actually promises a stronger guarantee called swap-omniprediction, and we prove a lower bound showing that obtaining $O(\\sqrt{T})$ bounds for swap-omniprediction is impossible in the online setting.","On the other hand, we give a (non-oracle efficient) algorithm which can obtain the optimal $O(\\sqrt{T})$ omniprediction bounds without going through multicalibration, giving an information theoretic separation between these two solution concepts."],"url":"http://arxiv.org/abs/2307.08999v1"}
{"created":"2023-07-18 06:31:01","title":"Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond","abstract":"An authentic face restoration system is becoming increasingly demanding in many computer vision applications, e.g., image enhancement, video communication, and taking portrait. Most of the advanced face restoration models can recover high-quality faces from low-quality ones but usually fail to faithfully generate realistic and high-frequency details that are favored by users. To achieve authentic restoration, we propose $\\textbf{IDM}$, an $\\textbf{I}$teratively learned face restoration system based on denoising $\\textbf{D}$iffusion $\\textbf{M}$odels (DDMs). We define the criterion of an authentic face restoration system, and argue that denoising diffusion models are naturally endowed with this property from two aspects: intrinsic iterative refinement and extrinsic iterative enhancement. Intrinsic learning can preserve the content well and gradually refine the high-quality details, while extrinsic enhancement helps clean the data and improve the restoration task one step further. We demonstrate superior performance on blind face restoration tasks. Beyond restoration, we find the authentically cleaned data by the proposed restoration system is also helpful to image generation tasks in terms of training stabilization and sample quality. Without modifying the models, we achieve better quality than state-of-the-art on FFHQ and ImageNet generation using either GANs or diffusion models.","sentences":["An authentic face restoration system is becoming increasingly demanding in many computer vision applications, e.g., image enhancement, video communication, and taking portrait.","Most of the advanced face restoration models can recover high-quality faces from low-quality ones but usually fail to faithfully generate realistic and high-frequency details that are favored by users.","To achieve authentic restoration, we propose $\\textbf{IDM}$, an $\\textbf{I}$teratively learned face restoration system based on denoising $\\textbf{D}$iffusion $\\textbf{M}$odels (DDMs).","We define the criterion of an authentic face restoration system, and argue that denoising diffusion models are naturally endowed with this property from two aspects: intrinsic iterative refinement and extrinsic iterative enhancement.","Intrinsic learning can preserve the content well and gradually refine the high-quality details, while extrinsic enhancement helps clean the data and improve the restoration task one step further.","We demonstrate superior performance on blind face restoration tasks.","Beyond restoration, we find the authentically cleaned data by the proposed restoration system is also helpful to image generation tasks in terms of training stabilization and sample quality.","Without modifying the models, we achieve better quality than state-of-the-art on FFHQ and ImageNet generation using either GANs or diffusion models."],"url":"http://arxiv.org/abs/2307.08996v1"}
{"created":"2023-07-18 06:27:44","title":"Revisiting Latent Space of GAN Inversion for Real Image Editing","abstract":"The exploration of the latent space in StyleGANs and GAN inversion exemplify impressive real-world image editing, yet the trade-off between reconstruction quality and editing quality remains an open problem. In this study, we revisit StyleGANs' hyperspherical prior $\\mathcal{Z}$ and combine it with highly capable latent spaces to build combined spaces that faithfully invert real images while maintaining the quality of edited images. More specifically, we propose $\\mathcal{F}/\\mathcal{Z}^{+}$ space consisting of two subspaces: $\\mathcal{F}$ space of an intermediate feature map of StyleGANs enabling faithful reconstruction and $\\mathcal{Z}^{+}$ space of an extended StyleGAN prior supporting high editing quality. We project the real images into the proposed space to obtain the inverted codes, by which we then move along $\\mathcal{Z}^{+}$, enabling semantic editing without sacrificing image quality. Comprehensive experiments show that $\\mathcal{Z}^{+}$ can replace the most commonly-used $\\mathcal{W}$, $\\mathcal{W}^{+}$, and $\\mathcal{S}$ spaces while preserving reconstruction quality, resulting in reduced distortion of edited images.","sentences":["The exploration of the latent space in StyleGANs and GAN inversion exemplify impressive real-world image editing, yet the trade-off between reconstruction quality and editing quality remains an open problem.","In this study, we revisit StyleGANs' hyperspherical prior $\\mathcal{Z}$ and combine it with highly capable latent spaces to build combined spaces that faithfully invert real images while maintaining the quality of edited images.","More specifically, we propose $\\mathcal{F}/\\mathcal{Z}^{+}$ space consisting of two subspaces: $\\mathcal{F}$ space of an intermediate feature map of StyleGANs enabling faithful reconstruction and $\\mathcal{Z}^{+}$ space of an extended StyleGAN prior supporting high editing quality.","We project the real images into the proposed space to obtain the inverted codes, by which we then move along $\\mathcal{Z}^{+}$, enabling semantic editing without sacrificing image quality.","Comprehensive experiments show that $\\mathcal{Z}^{+}$ can replace the most commonly-used $\\mathcal{W}$, $\\mathcal{W}^{+}$, and $\\mathcal{S}$ spaces while preserving reconstruction quality, resulting in reduced distortion of edited images."],"url":"http://arxiv.org/abs/2307.08995v1"}
{"created":"2023-07-18 06:15:23","title":"Human Action Recognition in Still Images Using ConViT","abstract":"Understanding the relationship between different parts of the image plays a crucial role in many visual recognition tasks. Despite the fact that Convolutional Neural Networks (CNNs) have demonstrated impressive results in detecting single objects, they lack the capability to extract the relationship between various regions of an image, which is a crucial factor in human action recognition. To address this problem, this paper proposes a new module that functions like a convolutional layer using Vision Transformer (ViT). The proposed action recognition model comprises two components: the first part is a deep convolutional network that extracts high-level spatial features from the image, and the second component of the model utilizes a Vision Transformer that extracts the relationship between various regions of the image using the feature map generated by the CNN output. The proposed model has been evaluated on the Stanford40 and PASCAL VOC 2012 action datasets and has achieved 95.5% mAP and 91.5% mAP results, respectively, which are promising compared to other state-of-the-art methods.","sentences":["Understanding the relationship between different parts of the image plays a crucial role in many visual recognition tasks.","Despite the fact that Convolutional Neural Networks (CNNs) have demonstrated impressive results in detecting single objects, they lack the capability to extract the relationship between various regions of an image, which is a crucial factor in human action recognition.","To address this problem, this paper proposes a new module that functions like a convolutional layer using Vision Transformer (ViT).","The proposed action recognition model comprises two components: the first part is a deep convolutional network that extracts high-level spatial features from the image, and the second component of the model utilizes a Vision Transformer that extracts the relationship between various regions of the image using the feature map generated by the CNN output.","The proposed model has been evaluated on the Stanford40 and PASCAL VOC 2012 action datasets and has achieved 95.5% mAP and 91.5% mAP results, respectively, which are promising compared to other state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.08994v1"}
{"created":"2023-07-18 06:11:09","title":"Arbitrary point cloud upsampling via Dual Back-Projection Network","abstract":"Point clouds acquired from 3D sensors are usually sparse and noisy. Point cloud upsampling is an approach to increase the density of the point cloud so that detailed geometric information can be restored. In this paper, we propose a Dual Back-Projection network for point cloud upsampling (DBPnet). A Dual Back-Projection is formulated in an up-down-up manner for point cloud upsampling. It not only back projects feature residues but also coordinates residues so that the network better captures the point correlations in the feature and space domains, achieving lower reconstruction errors on both uniform and non-uniform sparse point clouds. Our proposed method is also generalizable for arbitrary upsampling tasks (e.g. 4x, 5.5x). Experimental results show that the proposed method achieves the lowest point set matching losses with respect to the benchmark. In addition, the success of our approach demonstrates that generative networks are not necessarily needed for non-uniform point clouds.","sentences":["Point clouds acquired from 3D sensors are usually sparse and noisy.","Point cloud upsampling is an approach to increase the density of the point cloud so that detailed geometric information can be restored.","In this paper, we propose a Dual Back-Projection network for point cloud upsampling (DBPnet).","A Dual Back-Projection is formulated in an up-down-up manner for point cloud upsampling.","It not only back projects feature residues but also coordinates residues so that the network better captures the point correlations in the feature and space domains, achieving lower reconstruction errors on both uniform and non-uniform sparse point clouds.","Our proposed method is also generalizable for arbitrary upsampling tasks (e.g. 4x, 5.5x).","Experimental results show that the proposed method achieves the lowest point set matching losses with respect to the benchmark.","In addition, the success of our approach demonstrates that generative networks are not necessarily needed for non-uniform point clouds."],"url":"http://arxiv.org/abs/2307.08992v1"}
{"created":"2023-07-18 06:07:25","title":"EgoVM: Achieving Precise Ego-Localization using Lightweight Vectorized Maps","abstract":"Accurate and reliable ego-localization is critical for autonomous driving. In this paper, we present EgoVM, an end-to-end localization network that achieves comparable localization accuracy to prior state-of-the-art methods, but uses lightweight vectorized maps instead of heavy point-based maps. To begin with, we extract BEV features from online multi-view images and LiDAR point cloud. Then, we employ a set of learnable semantic embeddings to encode the semantic types of map elements and supervise them with semantic segmentation, to make their feature representation consistent with BEV features. After that, we feed map queries, composed of learnable semantic embeddings and coordinates of map elements, into a transformer decoder to perform cross-modality matching with BEV features. Finally, we adopt a robust histogram-based pose solver to estimate the optimal pose by searching exhaustively over candidate poses. We comprehensively validate the effectiveness of our method using both the nuScenes dataset and a newly collected dataset. The experimental results show that our method achieves centimeter-level localization accuracy, and outperforms existing methods using vectorized maps by a large margin. Furthermore, our model has been extensively tested in a large fleet of autonomous vehicles under various challenging urban scenes.","sentences":["Accurate and reliable ego-localization is critical for autonomous driving.","In this paper, we present EgoVM, an end-to-end localization network that achieves comparable localization accuracy to prior state-of-the-art methods, but uses lightweight vectorized maps instead of heavy point-based maps.","To begin with, we extract BEV features from online multi-view images and LiDAR point cloud.","Then, we employ a set of learnable semantic embeddings to encode the semantic types of map elements and supervise them with semantic segmentation, to make their feature representation consistent with BEV features.","After that, we feed map queries, composed of learnable semantic embeddings and coordinates of map elements, into a transformer decoder to perform cross-modality matching with BEV features.","Finally, we adopt a robust histogram-based pose solver to estimate the optimal pose by searching exhaustively over candidate poses.","We comprehensively validate the effectiveness of our method using both the nuScenes dataset and a newly collected dataset.","The experimental results show that our method achieves centimeter-level localization accuracy, and outperforms existing methods using vectorized maps by a large margin.","Furthermore, our model has been extensively tested in a large fleet of autonomous vehicles under various challenging urban scenes."],"url":"http://arxiv.org/abs/2307.08991v1"}
{"created":"2023-07-18 06:04:20","title":"An Empirical Study on the Effectiveness of Noisy Label Learning for Program Understanding","abstract":"Recently, deep learning models have been widely applied in program understanding tasks, and these models achieve state-of-the-art results on many benchmark datasets. A major challenge of deep learning for program understanding is that the effectiveness of these approaches depends on the quality of their datasets, and these datasets often contain noisy data samples. A typical kind of noise in program understanding datasets is label noises, which means that the target outputs for some inputs are mislabeled.   Label noises may have a negative impact on the performance of deep learning models, so researchers have proposed various approaches to alleviate the impact of noisy labels, and formed a new research topic: noisy label learning (NLL). In this paper, we conduct an empirical study on the effectiveness of noisy label learning on deep learning for program understanding datasets. We evaluate various noisy label learning approaches and deep learning models on two tasks: program classification and code summarization. From the evaluation results, we find that the impact of label noise and NLL approaches on small deep learning models and large pre-trained models are different: small models are prone to label noises in program classification and NLL approaches can improve their robustness, while large pre-trained models are robust against label noises and NLL does not significantly improve their performances. On the other hand, NLL approaches have shown satisfying results in identifying noisy labeled samples for both tasks, indicating that these techniques can benefit researchers in building high-quality program understanding datasets.","sentences":["Recently, deep learning models have been widely applied in program understanding tasks, and these models achieve state-of-the-art results on many benchmark datasets.","A major challenge of deep learning for program understanding is that the effectiveness of these approaches depends on the quality of their datasets, and these datasets often contain noisy data samples.","A typical kind of noise in program understanding datasets is label noises, which means that the target outputs for some inputs are mislabeled.   ","Label noises may have a negative impact on the performance of deep learning models, so researchers have proposed various approaches to alleviate the impact of noisy labels, and formed a new research topic: noisy label learning (NLL).","In this paper, we conduct an empirical study on the effectiveness of noisy label learning on deep learning for program understanding datasets.","We evaluate various noisy label learning approaches and deep learning models on two tasks: program classification and code summarization.","From the evaluation results, we find that the impact of label noise and NLL approaches on small deep learning models and large pre-trained models are different: small models are prone to label noises in program classification and NLL approaches can improve their robustness, while large pre-trained models are robust against label noises and NLL does not significantly improve their performances.","On the other hand, NLL approaches have shown satisfying results in identifying noisy labeled samples for both tasks, indicating that these techniques can benefit researchers in building high-quality program understanding datasets."],"url":"http://arxiv.org/abs/2307.08990v1"}
{"created":"2023-07-18 06:01:37","title":"GraphCL-DTA: a graph contrastive learning with molecular semantics for drug-target binding affinity prediction","abstract":"Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets. However, the performance of previous computational models is limited by the following drawbacks. The learning of drug representation relies only on supervised data, without taking into account the information contained in the molecular graph itself. Moreover, most previous studies tended to design complicated representation learning module, while uniformity, which is used to measure representation quality, is ignored. In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. In GraphCL-DTA, we design a graph contrastive learning framework for molecular graphs to learn drug representations, so that the semantics of molecular graphs are preserved. Through this graph contrastive framework, a more essential and effective drug representation can be learned without additional supervised data. Next, we design a new loss function that can be directly used to smoothly adjust the uniformity of drug and target representations. By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved. The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis. The excellent performance of GraphCL-DTA on the above datasets suggests its superiority to the state-of-the-art model.","sentences":["Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets.","However, the performance of previous computational models is limited by the following drawbacks.","The learning of drug representation relies only on supervised data, without taking into account the information contained in the molecular graph itself.","Moreover, most previous studies tended to design complicated representation learning module, while uniformity, which is used to measure representation quality, is ignored.","In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction.","In GraphCL-DTA, we design a graph contrastive learning framework for molecular graphs to learn drug representations, so that the semantics of molecular graphs are preserved.","Through this graph contrastive framework, a more essential and effective drug representation can be learned without additional supervised data.","Next, we design a new loss function that can be directly used to smoothly adjust the uniformity of drug and target representations.","By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved.","The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis.","The excellent performance of GraphCL-DTA on the above datasets suggests its superiority to the state-of-the-art model."],"url":"http://arxiv.org/abs/2307.08989v1"}
{"created":"2023-07-18 05:59:27","title":"EVIL: Evidential Inference Learning for Trustworthy Semi-supervised Medical Image Segmentation","abstract":"Recently, uncertainty-aware methods have attracted increasing attention in semi-supervised medical image segmentation. However, current methods usually suffer from the drawback that it is difficult to balance the computational cost, estimation accuracy, and theoretical support in a unified framework. To alleviate this problem, we introduce the Dempster-Shafer Theory of Evidence (DST) into semi-supervised medical image segmentation, dubbed Evidential Inference Learning (EVIL). EVIL provides a theoretically guaranteed solution to infer accurate uncertainty quantification in a single forward pass. Trustworthy pseudo labels on unlabeled data are generated after uncertainty estimation. The recently proposed consistency regularization-based training paradigm is adopted in our framework, which enforces the consistency on the perturbed predictions to enhance the generalization with few labeled data. Experimental results show that EVIL achieves competitive performance in comparison with several state-of-the-art methods on the public dataset.","sentences":["Recently, uncertainty-aware methods have attracted increasing attention in semi-supervised medical image segmentation.","However, current methods usually suffer from the drawback that it is difficult to balance the computational cost, estimation accuracy, and theoretical support in a unified framework.","To alleviate this problem, we introduce the Dempster-Shafer Theory of Evidence (DST) into semi-supervised medical image segmentation, dubbed Evidential Inference Learning (EVIL).","EVIL provides a theoretically guaranteed solution to infer accurate uncertainty quantification in a single forward pass.","Trustworthy pseudo labels on unlabeled data are generated after uncertainty estimation.","The recently proposed consistency regularization-based training paradigm is adopted in our framework, which enforces the consistency on the perturbed predictions to enhance the generalization with few labeled data.","Experimental results show that EVIL achieves competitive performance in comparison with several state-of-the-art methods on the public dataset."],"url":"http://arxiv.org/abs/2307.08988v1"}
{"created":"2023-07-18 05:57:00","title":"AI-assisted Improved Service Provisioning for Low-latency XR over 5G NR","abstract":"Extended Reality (XR) is one of the most important 5G/6G media applications that will fundamentally transform human interactions. However, ensuring low latency, high data rate, and reliability to support XR services poses significant challenges. This letter presents a novel AI-assisted service provisioning scheme that leverages predicted frames for processing rather than relying solely on actual frames. This method virtually increases the network delay budget and consequently improves service provisioning, albeit at the expense of minor prediction errors. The proposed scheme is validated by extensive simulations demonstrating a multi-fold increase in supported XR users and also provides crucial network design insights.","sentences":["Extended Reality (XR) is one of the most important 5G/6G media applications that will fundamentally transform human interactions.","However, ensuring low latency, high data rate, and reliability to support XR services poses significant challenges.","This letter presents a novel AI-assisted service provisioning scheme that leverages predicted frames for processing rather than relying solely on actual frames.","This method virtually increases the network delay budget and consequently improves service provisioning, albeit at the expense of minor prediction errors.","The proposed scheme is validated by extensive simulations demonstrating a multi-fold increase in supported XR users and also provides crucial network design insights."],"url":"http://arxiv.org/abs/2307.08987v1"}
{"created":"2023-07-18 05:51:00","title":"PromptCrafter: Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM","abstract":"Text-to-image generation model is able to generate images across a diverse range of subjects and styles based on a single prompt. Recent works have proposed a variety of interaction methods that help users understand the capabilities of models and utilize them. However, how to support users to efficiently explore the model's capability and to create effective prompts are still open-ended research questions. In this paper, we present PromptCrafter, a novel mixed-initiative system that allows step-by-step crafting of text-to-image prompt. Through the iterative process, users can efficiently explore the model's capability, and clarify their intent. PromptCrafter also supports users to refine prompts by answering various responses to clarifying questions generated by a Large Language Model. Lastly, users can revert to a desired step by reviewing the work history. In this workshop paper, we discuss the design process of PromptCrafter and our plans for follow-up studies.","sentences":["Text-to-image generation model is able to generate images across a diverse range of subjects and styles based on a single prompt.","Recent works have proposed a variety of interaction methods that help users understand the capabilities of models and utilize them.","However, how to support users to efficiently explore the model's capability and to create effective prompts are still open-ended research questions.","In this paper, we present PromptCrafter, a novel mixed-initiative system that allows step-by-step crafting of text-to-image prompt.","Through the iterative process, users can efficiently explore the model's capability, and clarify their intent.","PromptCrafter also supports users to refine prompts by answering various responses to clarifying questions generated by a Large Language Model.","Lastly, users can revert to a desired step by reviewing the work history.","In this workshop paper, we discuss the design process of PromptCrafter and our plans for follow-up studies."],"url":"http://arxiv.org/abs/2307.08985v1"}
{"created":"2023-07-18 05:42:01","title":"In Defense of Clip-based Video Relation Detection","abstract":"Video Visual Relation Detection (VidVRD) aims to detect visual relationship triplets in videos using spatial bounding boxes and temporal boundaries. Existing VidVRD methods can be broadly categorized into bottom-up and top-down paradigms, depending on their approach to classifying relations. Bottom-up methods follow a clip-based approach where they classify relations of short clip tubelet pairs and then merge them into long video relations. On the other hand, top-down methods directly classify long video tubelet pairs. While recent video-based methods utilizing video tubelets have shown promising results, we argue that the effective modeling of spatial and temporal context plays a more significant role than the choice between clip tubelets and video tubelets. This motivates us to revisit the clip-based paradigm and explore the key success factors in VidVRD. In this paper, we propose a Hierarchical Context Model (HCM) that enriches the object-based spatial context and relation-based temporal context based on clips. We demonstrate that using clip tubelets can achieve superior performance compared to most video-based methods. Additionally, using clip tubelets offers more flexibility in model designs and helps alleviate the limitations associated with video tubelets, such as the challenging long-term object tracking problem and the loss of temporal information in long-term tubelet feature compression. Extensive experiments conducted on two challenging VidVRD benchmarks validate that our HCM achieves a new state-of-the-art performance, highlighting the effectiveness of incorporating advanced spatial and temporal context modeling within the clip-based paradigm.","sentences":["Video Visual Relation Detection (VidVRD) aims to detect visual relationship triplets in videos using spatial bounding boxes and temporal boundaries.","Existing VidVRD methods can be broadly categorized into bottom-up and top-down paradigms, depending on their approach to classifying relations.","Bottom-up methods follow a clip-based approach where they classify relations of short clip tubelet pairs and then merge them into long video relations.","On the other hand, top-down methods directly classify long video tubelet pairs.","While recent video-based methods utilizing video tubelets have shown promising results, we argue that the effective modeling of spatial and temporal context plays a more significant role than the choice between clip tubelets and video tubelets.","This motivates us to revisit the clip-based paradigm and explore the key success factors in VidVRD.","In this paper, we propose a Hierarchical Context Model (HCM) that enriches the object-based spatial context and relation-based temporal context based on clips.","We demonstrate that using clip tubelets can achieve superior performance compared to most video-based methods.","Additionally, using clip tubelets offers more flexibility in model designs and helps alleviate the limitations associated with video tubelets, such as the challenging long-term object tracking problem and the loss of temporal information in long-term tubelet feature compression.","Extensive experiments conducted on two challenging VidVRD benchmarks validate that our HCM achieves a new state-of-the-art performance, highlighting the effectiveness of incorporating advanced spatial and temporal context modeling within the clip-based paradigm."],"url":"http://arxiv.org/abs/2307.08984v1"}
{"created":"2023-07-18 05:39:32","title":"Neural Network Pruning as Spectrum Preserving Process","abstract":"Neural networks have achieved remarkable performance in various application domains. Nevertheless, a large number of weights in pre-trained deep neural networks prohibit them from being deployed on smartphones and embedded systems. It is highly desirable to obtain lightweight versions of neural networks for inference in edge devices. Many cost-effective approaches were proposed to prune dense and convolutional layers that are common in deep neural networks and dominant in the parameter space. However, a unified theoretical foundation for the problem mostly is missing. In this paper, we identify the close connection between matrix spectrum learning and neural network training for dense and convolutional layers and argue that weight pruning is essentially a matrix sparsification process to preserve the spectrum. Based on the analysis, we also propose a matrix sparsification algorithm tailored for neural network pruning that yields better pruning result. We carefully design and conduct experiments to support our arguments. Hence we provide a consolidated viewpoint for neural network pruning and enhance the interpretability of deep neural networks by identifying and preserving the critical neural weights.","sentences":["Neural networks have achieved remarkable performance in various application domains.","Nevertheless, a large number of weights in pre-trained deep neural networks prohibit them from being deployed on smartphones and embedded systems.","It is highly desirable to obtain lightweight versions of neural networks for inference in edge devices.","Many cost-effective approaches were proposed to prune dense and convolutional layers that are common in deep neural networks and dominant in the parameter space.","However, a unified theoretical foundation for the problem mostly is missing.","In this paper, we identify the close connection between matrix spectrum learning and neural network training for dense and convolutional layers and argue that weight pruning is essentially a matrix sparsification process to preserve the spectrum.","Based on the analysis, we also propose a matrix sparsification algorithm tailored for neural network pruning that yields better pruning result.","We carefully design and conduct experiments to support our arguments.","Hence we provide a consolidated viewpoint for neural network pruning and enhance the interpretability of deep neural networks by identifying and preserving the critical neural weights."],"url":"http://arxiv.org/abs/2307.08982v1"}
{"created":"2023-07-18 05:25:32","title":"Scalable Auction Algorithms for Bipartite Maximum Matching Problems","abstract":"In this paper, we give new auction algorithms for maximum weighted bipartite matching (MWM) and maximum cardinality bipartite $b$-matching (MCbM). Our algorithms run in $O\\left(\\log n/\\varepsilon^8\\right)$ and $O\\left(\\log n/\\varepsilon^2\\right)$ rounds, respectively, in the blackboard distributed setting. We show that our MWM algorithm can be implemented in the distributed, interactive setting using $O(\\log^2 n)$ and $O(\\log n)$ bit messages, respectively, directly answering the open question posed by Demange, Gale and Sotomayor [DNO14]. Furthermore, we implement our algorithms in a variety of other models including the the semi-streaming model, the shared-memory work-depth model, and the massively parallel computation model. Our semi-streaming MWM algorithm uses $O(1/\\varepsilon^8)$ passes in $O(n \\log n \\cdot \\log(1/\\varepsilon))$ space and our MCbM algorithm runs in $O(1/\\varepsilon^2)$ passes using $O\\left(\\left(\\sum_{i \\in L} b_i + |R|\\right)\\log(1/\\varepsilon)\\right)$ space (where parameters $b_i$ represent the degree constraints on the $b$-matching and $L$ and $R$ represent the left and right side of the bipartite graph, respectively). Both of these algorithms improves \\emph{exponentially} the dependence on $\\varepsilon$ in the space complexity in the semi-streaming model against the best-known algorithms for these problems, in addition to improvements in round complexity for MCbM. Finally, our algorithms eliminate the large polylogarithmic dependence on $n$ in depth and number of rounds in the work-depth and massively parallel computation models, respectively, improving on previous results which have large polylogarithmic dependence on $n$ (and exponential dependence on $\\varepsilon$ in the MPC model).","sentences":["In this paper, we give new auction algorithms for maximum weighted bipartite matching (MWM) and maximum cardinality bipartite $b$-matching (MCbM).","Our algorithms run in $O\\left(\\log n/\\varepsilon^8\\right)$ and $O\\left(\\log n/\\varepsilon^2\\right)$ rounds, respectively, in the blackboard distributed setting.","We show that our MWM algorithm can be implemented in the distributed, interactive setting using $O(\\log^2 n)$ and $O(\\log n)$ bit messages, respectively, directly answering the open question posed by Demange, Gale and Sotomayor","[DNO14].","Furthermore, we implement our algorithms in a variety of other models including the the semi-streaming model, the shared-memory work-depth model, and the massively parallel computation model.","Our semi-streaming MWM algorithm uses $O(1/\\varepsilon^8)$ passes in $O(n \\log n \\cdot \\log(1/\\varepsilon))$ space and our MCbM algorithm runs in $O(1/\\varepsilon^2)$ passes using $O\\left(\\left(\\sum_{i \\in L} b_i","+ |R|\\right)\\log(1/\\varepsilon)\\right)$ space (where parameters $b_i$ represent the degree constraints on the $b$-matching and $L$ and $R$ represent the left and right side of the bipartite graph, respectively).","Both of these algorithms improves \\emph{exponentially} the dependence on $\\varepsilon$ in the space complexity in the semi-streaming model against the best-known algorithms for these problems, in addition to improvements in round complexity for MCbM.","Finally, our algorithms eliminate the large polylogarithmic dependence on $n$ in depth and number of rounds in the work-depth and massively parallel computation models, respectively, improving on previous results which have large polylogarithmic dependence on $n$ (and exponential dependence on $\\varepsilon$ in the MPC model)."],"url":"http://arxiv.org/abs/2307.08979v1"}
{"created":"2023-07-18 05:12:52","title":"Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines","abstract":"The swift progress and ubiquitous adoption of Generative AI (GAI), Generative Pre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT, have spurred queries about their ethical application, use, and disclosure in scholarly research and scientific productions. A few publishers and journals have recently created their own sets of rules; however, the absence of a unified approach may lead to a 'Babel Tower Effect,' potentially resulting in confusion rather than desired standardization. In response to this, we present the ChatGPT, Generative Artificial Intelligence, and Natural Large Language Models for Accountable Reporting and Use Guidelines (CANGARU) initiative, with the aim of fostering a cross-disciplinary global inclusive consensus on the ethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies in academia. The present protocol consists of four distinct parts: a) an ongoing systematic review of GAI/GPT/LLM applications to understand the linked ideas, findings, and reporting standards in scholarly research, and to formulate guidelines for its use and disclosure, b) a bibliometric analysis of existing author guidelines in journals that mention GAI/GPT/LLM, with the goal of evaluating existing guidelines, analyzing the disparity in their recommendations, and identifying common rules that can be brought into the Delphi consensus process, c) a Delphi survey to establish agreement on the items for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, and reporting in academia, and d) the subsequent development and dissemination of the finalized guidelines and their supplementary explanation and elaboration documents.","sentences":["The swift progress and ubiquitous adoption of Generative AI (GAI), Generative Pre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT, have spurred queries about their ethical application, use, and disclosure in scholarly research and scientific productions.","A few publishers and journals have recently created their own sets of rules; however, the absence of a unified approach may lead to a 'Babel Tower Effect,' potentially resulting in confusion rather than desired standardization.","In response to this, we present the ChatGPT, Generative Artificial Intelligence, and Natural Large Language Models for Accountable Reporting and Use Guidelines (CANGARU) initiative, with the aim of fostering a cross-disciplinary global inclusive consensus on the ethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies in academia.","The present protocol consists of four distinct parts: a) an ongoing systematic review of GAI/GPT/LLM applications to understand the linked ideas, findings, and reporting standards in scholarly research, and to formulate guidelines for its use and disclosure, b) a bibliometric analysis of existing author guidelines in journals that mention GAI/GPT/LLM, with the goal of evaluating existing guidelines, analyzing the disparity in their recommendations, and identifying common rules that can be brought into the Delphi consensus process, c) a Delphi survey to establish agreement on the items for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, and reporting in academia, and d) the subsequent development and dissemination of the finalized guidelines and their supplementary explanation and elaboration documents."],"url":"http://arxiv.org/abs/2307.08974v1"}
{"created":"2023-07-18 05:04:11","title":"A Unifying Framework for Differentially Private Sums under Continual Observation","abstract":"We study the problem of maintaining a differentially private decaying sum under continual observation. We give a unifying framework and an efficient algorithm for this problem for \\emph{any sufficiently smooth} function. Our algorithm is the first differentially private algorithm that does not have a multiplicative error for polynomially-decaying weights. Our algorithm improves on all prior works on differentially private decaying sums under continual observation and recovers exactly the additive error for the special case of continual counting from Henzinger et al. (SODA 2023) as a corollary.   Our algorithm is a variant of the factorization mechanism whose error depends on the $\\gamma_2$ and $\\gamma_F$ norm of the underlying matrix. We give a constructive proof for an almost exact upper bound on the $\\gamma_2$ and $\\gamma_F$ norm and an almost tight lower bound on the $\\gamma_2$ norm for a large class of lower-triangular matrices. This is the first non-trivial lower bound for lower-triangular matrices whose non-zero entries are not all the same. It includes matrices for all continual decaying sums problems, resulting in an upper bound on the additive error of any differentially private decaying sums algorithm under continual observation.   We also explore some implications of our result in discrepancy theory and operator algebra. Given the importance of the $\\gamma_2$ norm in computer science and the extensive work in mathematics, we believe our result will have further applications.","sentences":["We study the problem of maintaining a differentially private decaying sum under continual observation.","We give a unifying framework and an efficient algorithm for this problem for \\emph{any sufficiently smooth} function.","Our algorithm is the first differentially private algorithm that does not have a multiplicative error for polynomially-decaying weights.","Our algorithm improves on all prior works on differentially private decaying sums under continual observation and recovers exactly the additive error for the special case of continual counting from Henzinger et al. (SODA 2023) as a corollary.   ","Our algorithm is a variant of the factorization mechanism whose error depends on the $\\gamma_2$ and $\\gamma_F$ norm of the underlying matrix.","We give a constructive proof for an almost exact upper bound on the $\\gamma_2$ and $\\gamma_F$ norm and an almost tight lower bound on the $\\gamma_2$ norm for a large class of lower-triangular matrices.","This is the first non-trivial lower bound for lower-triangular matrices whose non-zero entries are not all the same.","It includes matrices for all continual decaying sums problems, resulting in an upper bound on the additive error of any differentially private decaying sums algorithm under continual observation.   ","We also explore some implications of our result in discrepancy theory and operator algebra.","Given the importance of the $\\gamma_2$ norm in computer science and the extensive work in mathematics, we believe our result will have further applications."],"url":"http://arxiv.org/abs/2307.08970v1"}
{"created":"2023-07-18 04:34:43","title":"Multi-Robot Patrol Algorithm with Distributed Coordination and Consciousness of the Base Station's Situation Awareness","abstract":"Multi-robot patrolling is the potential application for robotic systems to survey wide areas efficiently without human burdens and mistakes. However, such systems have few examples of real-world applications due to their lack of human predictability. This paper proposes an algorithm: Local Reactive (LR) for multi-robot patrolling to satisfy both needs: (i)patrol efficiently and (ii)provide humans with better situation awareness to enhance system predictability. Each robot operating according to the proposed algorithm selects its patrol target from the local areas around the robot's current location by two requirements: (i)patrol location with greater need, (ii)report its achievements to the base station. The algorithm is distributed and coordinates the robots without centralized control by sharing their patrol achievements and degree of need to report to the base station. The proposed algorithm performed better than existing algorithms in both patrolling and the base station's situation awareness.","sentences":["Multi-robot patrolling is the potential application for robotic systems to survey wide areas efficiently without human burdens and mistakes.","However, such systems have few examples of real-world applications due to their lack of human predictability.","This paper proposes an algorithm: Local Reactive (LR) for multi-robot patrolling to satisfy both needs: (i)patrol efficiently and (ii)provide humans with better situation awareness to enhance system predictability.","Each robot operating according to the proposed algorithm selects its patrol target from the local areas around the robot's current location by two requirements: (i)patrol location with greater need, (ii)report its achievements to the base station.","The algorithm is distributed and coordinates the robots without centralized control by sharing their patrol achievements and degree of need to report to the base station.","The proposed algorithm performed better than existing algorithms in both patrolling and the base station's situation awareness."],"url":"http://arxiv.org/abs/2307.08966v1"}
{"created":"2023-07-18 04:29:16","title":"Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information","abstract":"Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable Landscape Surrogate $M$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems.","sentences":["Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning.","By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience.","The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing.","The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers.","To address these challenges, we propose using a smooth and learnable Landscape Surrogate $M$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization.","We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems."],"url":"http://arxiv.org/abs/2307.08964v1"}
{"created":"2023-07-18 04:26:33","title":"REX: Rapid Exploration and eXploitation for AI Agents","abstract":"In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL). REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance. This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning. Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniques. Notably, REX-based methods exhibit remarkable reductions in execution time, enhancing their practical applicability across a diverse set of scenarios.","sentences":["In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX.","Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL).","REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance.","This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning.","Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniques.","Notably, REX-based methods exhibit remarkable reductions in execution time, enhancing their practical applicability across a diverse set of scenarios."],"url":"http://arxiv.org/abs/2307.08962v1"}
{"created":"2023-07-18 03:53:19","title":"Data sharing and ontology use among agricultural genetics, genomics, and breeding databases and resources of the AgBioData Consortium","abstract":"Over the last several decades, there has been rapid growth in the number and scope of agricultural genetics, genomics and breeding (GGB) databases and resources. The AgBioData Consortium (https://www.agbiodata.org/) currently represents 44 databases and resources covering model or crop plant and animal GGB data, ontologies, pathways, genetic variation and breeding platforms (referred to as 'databases' throughout). One of the goals of the Consortium is to facilitate FAIR (Findable, Accessible, Interoperable, and Reusable) data management and the integration of datasets which requires data sharing, along with structured vocabularies and/or ontologies. Two AgBioData working groups, focused on Data Sharing and Ontologies, conducted a survey to assess the status and future needs of the members in those areas. A total of 33 researchers responded to the survey, representing 37 databases. Results suggest that data sharing practices by AgBioData databases are in a healthy state, but it is not clear whether this is true for all metadata and data types across all databases; and that ontology use has not substantially changed since a similar survey was conducted in 2017. We recommend 1) providing training for database personnel in specific data sharing techniques, as well as in ontology use; 2) further study on what metadata is shared, and how well it is shared among databases; 3) promoting an understanding of data sharing and ontologies in the stakeholder community; 4) improving data sharing and ontologies for specific phenotypic data types and formats; and 5) lowering specific barriers to data sharing and ontology use, by identifying sustainability solutions, and the identification, promotion, or development of data standards. Combined, these improvements are likely to help AgBioData databases increase development efforts towards improved ontology use, and data sharing via programmatic means.","sentences":["Over the last several decades, there has been rapid growth in the number and scope of agricultural genetics, genomics and breeding (GGB) databases and resources.","The AgBioData Consortium (https://www.agbiodata.org/) currently represents 44 databases and resources covering model or crop plant and animal GGB data, ontologies, pathways, genetic variation and breeding platforms (referred to as 'databases' throughout).","One of the goals of the Consortium is to facilitate FAIR (Findable, Accessible, Interoperable, and Reusable) data management and the integration of datasets which requires data sharing, along with structured vocabularies and/or ontologies.","Two AgBioData working groups, focused on Data Sharing and Ontologies, conducted a survey to assess the status and future needs of the members in those areas.","A total of 33 researchers responded to the survey, representing 37 databases.","Results suggest that data sharing practices by AgBioData databases are in a healthy state, but it is not clear whether this is true for all metadata and data types across all databases; and that ontology use has not substantially changed since a similar survey was conducted in 2017.","We recommend 1) providing training for database personnel in specific data sharing techniques, as well as in ontology use; 2) further study on what metadata is shared, and how well it is shared among databases; 3) promoting an understanding of data sharing and ontologies in the stakeholder community; 4) improving data sharing and ontologies for specific phenotypic data types and formats; and 5) lowering specific barriers to data sharing and ontology use, by identifying sustainability solutions, and the identification, promotion, or development of data standards.","Combined, these improvements are likely to help AgBioData databases increase development efforts towards improved ontology use, and data sharing via programmatic means."],"url":"http://arxiv.org/abs/2307.08958v1"}
{"created":"2023-07-18 03:48:27","title":"Discretization-based ensemble model for robust learning in IoT","abstract":"IoT device identification is the process of recognizing and verifying connected IoT devices to the network. This is an essential process for ensuring that only authorized devices can access the network, and it is necessary for network management and maintenance. In recent years, machine learning models have been used widely for automating the process of identifying devices in the network. However, these models are vulnerable to adversarial attacks that can compromise their accuracy and effectiveness. To better secure device identification models, discretization techniques enable reduction in the sensitivity of machine learning models to adversarial attacks contributing to the stability and reliability of the model. On the other hand, Ensemble methods combine multiple heterogeneous models to reduce the impact of remaining noise or errors in the model. Therefore, in this paper, we integrate discretization techniques and ensemble methods and examine it on model robustness against adversarial attacks. In other words, we propose a discretization-based ensemble stacking technique to improve the security of our ML models. We evaluate the performance of different ML-based IoT device identification models against white box and black box attacks using a real-world dataset comprised of network traffic from 28 IoT devices. We demonstrate that the proposed method enables robustness to the models for IoT device identification.","sentences":["IoT device identification is the process of recognizing and verifying connected IoT devices to the network.","This is an essential process for ensuring that only authorized devices can access the network, and it is necessary for network management and maintenance.","In recent years, machine learning models have been used widely for automating the process of identifying devices in the network.","However, these models are vulnerable to adversarial attacks that can compromise their accuracy and effectiveness.","To better secure device identification models, discretization techniques enable reduction in the sensitivity of machine learning models to adversarial attacks contributing to the stability and reliability of the model.","On the other hand, Ensemble methods combine multiple heterogeneous models to reduce the impact of remaining noise or errors in the model.","Therefore, in this paper, we integrate discretization techniques and ensemble methods and examine it on model robustness against adversarial attacks.","In other words, we propose a discretization-based ensemble stacking technique to improve the security of our ML models.","We evaluate the performance of different ML-based IoT device identification models against white box and black box attacks using a real-world dataset comprised of network traffic from 28 IoT devices.","We demonstrate that the proposed method enables robustness to the models for IoT device identification."],"url":"http://arxiv.org/abs/2307.08955v1"}
{"created":"2023-07-18 03:39:03","title":"Knowledge-infused Deep Learning Enables Interpretable Landslide Forecasting","abstract":"Forecasting how landslides will evolve over time or whether they will fail is a challenging task due to a variety of factors, both internal and external. Despite their considerable potential to address these challenges, deep learning techniques lack interpretability, undermining the credibility of the forecasts they produce. The recent development of transformer-based deep learning offers untapped possibilities for forecasting landslides with unprecedented interpretability and nonlinear feature learning capabilities. Here, we present a deep learning pipeline that is capable of predicting landslide behavior holistically, which employs a transformer-based network called LFIT to learn complex nonlinear relationships from prior knowledge and multiple source data, identifying the most relevant variables, and demonstrating a comprehensive understanding of landslide evolution and temporal patterns. By integrating prior knowledge, we provide improvement in holistic landslide forecasting, enabling us to capture diverse responses to various influencing factors in different local landslide areas. Using deformation observations as proxies for measuring the kinetics of landslides, we validate our approach by training models to forecast reservoir landslides in the Three Gorges Reservoir and creeping landslides on the Tibetan Plateau. When prior knowledge is incorporated, we show that interpretable landslide forecasting effectively identifies influential factors across various landslides. It further elucidates how local areas respond to these factors, making landslide behavior and trends more interpretable and predictable. The findings from this study will contribute to understanding landslide behavior in a new way and make the proposed approach applicable to other complex disasters influenced by internal and external factors in the future.","sentences":["Forecasting how landslides will evolve over time or whether they will fail is a challenging task due to a variety of factors, both internal and external.","Despite their considerable potential to address these challenges, deep learning techniques lack interpretability, undermining the credibility of the forecasts they produce.","The recent development of transformer-based deep learning offers untapped possibilities for forecasting landslides with unprecedented interpretability and nonlinear feature learning capabilities.","Here, we present a deep learning pipeline that is capable of predicting landslide behavior holistically, which employs a transformer-based network called LFIT to learn complex nonlinear relationships from prior knowledge and multiple source data, identifying the most relevant variables, and demonstrating a comprehensive understanding of landslide evolution and temporal patterns.","By integrating prior knowledge, we provide improvement in holistic landslide forecasting, enabling us to capture diverse responses to various influencing factors in different local landslide areas.","Using deformation observations as proxies for measuring the kinetics of landslides, we validate our approach by training models to forecast reservoir landslides in the Three Gorges Reservoir and creeping landslides on the Tibetan Plateau.","When prior knowledge is incorporated, we show that interpretable landslide forecasting effectively identifies influential factors across various landslides.","It further elucidates how local areas respond to these factors, making landslide behavior and trends more interpretable and predictable.","The findings from this study will contribute to understanding landslide behavior in a new way and make the proposed approach applicable to other complex disasters influenced by internal and external factors in the future."],"url":"http://arxiv.org/abs/2307.08951v1"}
{"created":"2023-07-18 03:37:10","title":"Deep Physics-Guided Unrolling Generalization for Compressed Sensing","abstract":"By absorbing the merits of both the model- and data-driven methods, deep physics-engaged learning scheme achieves high-accuracy and interpretable image reconstruction. It has attracted growing attention and become the mainstream for inverse imaging tasks. Focusing on the image compressed sensing (CS) problem, we find the intrinsic defect of this emerging paradigm, widely implemented by deep algorithm-unrolled networks, in which more plain iterations involving real physics will bring enormous computation cost and long inference time, hindering their practical application. A novel deep $\\textbf{P}$hysics-guided un$\\textbf{R}$olled recovery $\\textbf{L}$earning ($\\textbf{PRL}$) framework is proposed by generalizing the traditional iterative recovery model from image domain (ID) to the high-dimensional feature domain (FD). A compact multiscale unrolling architecture is then developed to enhance the network capacity and keep real-time inference speeds. Taking two different perspectives of optimization and range-nullspace decomposition, instead of building an algorithm-specific unrolled network, we provide two implementations: $\\textbf{PRL-PGD}$ and $\\textbf{PRL-RND}$. Experiments exhibit the significant performance and efficiency leading of PRL networks over other state-of-the-art methods with a large potential for further improvement and real application to other inverse imaging problems or optimization models.","sentences":["By absorbing the merits of both the model- and data-driven methods, deep physics-engaged learning scheme achieves high-accuracy and interpretable image reconstruction.","It has attracted growing attention and become the mainstream for inverse imaging tasks.","Focusing on the image compressed sensing (CS) problem, we find the intrinsic defect of this emerging paradigm, widely implemented by deep algorithm-unrolled networks, in which more plain iterations involving real physics will bring enormous computation cost and long inference time, hindering their practical application.","A novel deep $\\textbf{P}$hysics-guided un$\\textbf{R}$olled recovery $\\textbf{L}$earning ($\\textbf{PRL}$) framework is proposed by generalizing the traditional iterative recovery model from image domain (ID) to the high-dimensional feature domain (FD).","A compact multiscale unrolling architecture is then developed to enhance the network capacity and keep real-time inference speeds.","Taking two different perspectives of optimization and range-nullspace decomposition, instead of building an algorithm-specific unrolled network, we provide two implementations: $\\textbf{PRL-PGD}$ and $\\textbf{PRL-RND}$. Experiments exhibit the significant performance and efficiency leading of PRL networks over other state-of-the-art methods with a large potential for further improvement and real application to other inverse imaging problems or optimization models."],"url":"http://arxiv.org/abs/2307.08950v1"}
{"created":"2023-07-18 03:34:33","title":"Alioth: A Machine Learning Based Interference-Aware Performance Monitor for Multi-Tenancy Applications in Public Cloud","abstract":"Multi-tenancy in public clouds may lead to co-location interference on shared resources, which possibly results in performance degradation of cloud applications. Cloud providers want to know when such events happen and how serious the degradation is, to perform interference-aware migrations and alleviate the problem. However, virtual machines (VM) in Infrastructure-as-a-Service public clouds are black-boxes to providers, where application-level performance information cannot be acquired. This makes performance monitoring intensely challenging as cloud providers can only rely on low-level metrics such as CPU usage and hardware counters.   We propose a novel machine learning framework, Alioth, to monitor the performance degradation of cloud applications. To feed the data-hungry models, we first elaborate interference generators and conduct comprehensive co-location experiments on a testbed to build Alioth-dataset which reflects the complexity and dynamicity in real-world scenarios. Then we construct Alioth by (1) augmenting features via recovering low-level metrics under no interference using denoising auto-encoders, (2) devising a transfer learning model based on domain adaptation neural network to make models generalize on test cases unseen in offline training, and (3) developing a SHAP explainer to automate feature selection and enhance model interpretability. Experiments show that Alioth achieves an average mean absolute error of 5.29% offline and 10.8% when testing on applications unseen in the training stage, outperforming the baseline methods. Alioth is also robust in signaling quality-of-service violation under dynamicity. Finally, we demonstrate a possible application of Alioth's interpretability, providing insights to benefit the decision-making of cloud operators. The dataset and code of Alioth have been released on GitHub.","sentences":["Multi-tenancy in public clouds may lead to co-location interference on shared resources, which possibly results in performance degradation of cloud applications.","Cloud providers want to know when such events happen and how serious the degradation is, to perform interference-aware migrations and alleviate the problem.","However, virtual machines (VM) in Infrastructure-as-a-Service public clouds are black-boxes to providers, where application-level performance information cannot be acquired.","This makes performance monitoring intensely challenging as cloud providers can only rely on low-level metrics such as CPU usage and hardware counters.   ","We propose a novel machine learning framework, Alioth, to monitor the performance degradation of cloud applications.","To feed the data-hungry models, we first elaborate interference generators and conduct comprehensive co-location experiments on a testbed to build Alioth-dataset which reflects the complexity and dynamicity in real-world scenarios.","Then we construct Alioth by (1) augmenting features via recovering low-level metrics under no interference using denoising auto-encoders, (2) devising a transfer learning model based on domain adaptation neural network to make models generalize on test cases unseen in offline training, and (3) developing a SHAP explainer to automate feature selection and enhance model interpretability.","Experiments show that Alioth achieves an average mean absolute error of 5.29% offline and 10.8% when testing on applications unseen in the training stage, outperforming the baseline methods.","Alioth is also robust in signaling quality-of-service violation under dynamicity.","Finally, we demonstrate a possible application of Alioth's interpretability, providing insights to benefit the decision-making of cloud operators.","The dataset and code of Alioth have been released on GitHub."],"url":"http://arxiv.org/abs/2307.08949v1"}
{"created":"2023-07-18 03:28:39","title":"An Effective Data-Driven Approach for Localizing Deep Learning Faults","abstract":"Deep Learning (DL) applications are being used to solve problems in critical domains (e.g., autonomous driving or medical diagnosis systems). Thus, developers need to debug their systems to ensure that the expected behavior is delivered. However, it is hard and expensive to debug DNNs. When the failure symptoms or unsatisfied accuracies are reported after training, we lose the traceability as to which part of the DNN program is responsible for the failure. Even worse, sometimes, a deep learning program has different types of bugs. To address the challenges of debugging DNN models, we propose a novel data-driven approach that leverages model features to learn problem patterns. Our approach extracts these features, which represent semantic information of faults during DNN training. Our technique uses these features as a training dataset to learn and infer DNN fault patterns. Also, our methodology automatically links bug symptoms to their root causes, without the need for manually crafted mappings, so that developers can take the necessary steps to fix faults. We evaluate our approach using real-world and mutated models. Our results demonstrate that our technique can effectively detect and diagnose different bug types. Finally, our technique achieved better accuracy, precision, and recall than prior work for mutated models. Also, our approach achieved comparable results for real-world models in terms of accuracy and performance to the state-of-the-art.","sentences":["Deep Learning (DL) applications are being used to solve problems in critical domains (e.g., autonomous driving or medical diagnosis systems).","Thus, developers need to debug their systems to ensure that the expected behavior is delivered.","However, it is hard and expensive to debug DNNs.","When the failure symptoms or unsatisfied accuracies are reported after training, we lose the traceability as to which part of the DNN program is responsible for the failure.","Even worse, sometimes, a deep learning program has different types of bugs.","To address the challenges of debugging DNN models, we propose a novel data-driven approach that leverages model features to learn problem patterns.","Our approach extracts these features, which represent semantic information of faults during DNN training.","Our technique uses these features as a training dataset to learn and infer DNN fault patterns.","Also, our methodology automatically links bug symptoms to their root causes, without the need for manually crafted mappings, so that developers can take the necessary steps to fix faults.","We evaluate our approach using real-world and mutated models.","Our results demonstrate that our technique can effectively detect and diagnose different bug types.","Finally, our technique achieved better accuracy, precision, and recall than prior work for mutated models.","Also, our approach achieved comparable results for real-world models in terms of accuracy and performance to the state-of-the-art."],"url":"http://arxiv.org/abs/2307.08947v1"}
{"created":"2023-07-18 03:28:26","title":"EsaNet: Environment Semantics Enabled Physical Layer Authentication","abstract":"Wireless networks are vulnerable to physical layer spoofing attacks due to the wireless broadcast nature, thus, integrating communications and security (ICAS) is urgently needed for 6G endogenous security. In this letter, we propose an environment semantics enabled physical layer authentication network based on deep learning, namely EsaNet, to authenticate the spoofing from the underlying wireless protocol. Specifically, the frequency independent wireless channel fingerprint (FiFP) is extracted from the channel state information (CSI) of a massive multi-input multi-output (MIMO) system based on environment semantics knowledge. Then, we transform the received signal into a two-dimensional red green blue (RGB) image and apply the you only look once (YOLO), a single-stage object detection network, to quickly capture the FiFP. Next, a lightweight classification network is designed to distinguish the legitimate from the illegitimate users. Finally, the experimental results show that the proposed EsaNet can effectively detect physical layer spoofing attacks and is robust in time-varying wireless environments.","sentences":["Wireless networks are vulnerable to physical layer spoofing attacks due to the wireless broadcast nature, thus, integrating communications and security (ICAS) is urgently needed for 6G endogenous security.","In this letter, we propose an environment semantics enabled physical layer authentication network based on deep learning, namely EsaNet, to authenticate the spoofing from the underlying wireless protocol.","Specifically, the frequency independent wireless channel fingerprint (FiFP) is extracted from the channel state information (CSI) of a massive multi-input multi-output (MIMO) system based on environment semantics knowledge.","Then, we transform the received signal into a two-dimensional red green blue (RGB) image and apply the you only look once (YOLO), a single-stage object detection network, to quickly capture the FiFP.","Next, a lightweight classification network is designed to distinguish the legitimate from the illegitimate users.","Finally, the experimental results show that the proposed EsaNet can effectively detect physical layer spoofing attacks and is robust in time-varying wireless environments."],"url":"http://arxiv.org/abs/2307.08946v1"}
{"created":"2023-07-18 03:28:03","title":"Mitigating Label Bias via Decoupled Confident Learning","abstract":"Growing concerns regarding algorithmic fairness have led to a surge in methodologies to mitigate algorithmic bias. However, such methodologies largely assume that observed labels in training data are correct. This is problematic because bias in labels is pervasive across important domains, including healthcare, hiring, and content moderation. In particular, human-generated labels are prone to encoding societal biases. While the presence of labeling bias has been discussed conceptually, there is a lack of methodologies to address this problem. We propose a pruning method -- Decoupled Confident Learning (DeCoLe) -- specifically designed to mitigate label bias. After illustrating its performance on a synthetic dataset, we apply DeCoLe in the context of hate speech detection, where label bias has been recognized as an important challenge, and show that it successfully identifies biased labels and outperforms competing approaches.","sentences":["Growing concerns regarding algorithmic fairness have led to a surge in methodologies to mitigate algorithmic bias.","However, such methodologies largely assume that observed labels in training data are correct.","This is problematic because bias in labels is pervasive across important domains, including healthcare, hiring, and content moderation.","In particular, human-generated labels are prone to encoding societal biases.","While the presence of labeling bias has been discussed conceptually, there is a lack of methodologies to address this problem.","We propose a pruning method -- Decoupled Confident Learning (DeCoLe) -- specifically designed to mitigate label bias.","After illustrating its performance on a synthetic dataset, we apply DeCoLe in the context of hate speech detection, where label bias has been recognized as an important challenge, and show that it successfully identifies biased labels and outperforms competing approaches."],"url":"http://arxiv.org/abs/2307.08945v1"}
{"created":"2023-07-18 03:23:34","title":"Siamese Networks for Weakly Supervised Human Activity Recognition","abstract":"Deep learning has been successfully applied to human activity recognition. However, training deep neural networks requires explicitly labeled data which is difficult to acquire. In this paper, we present a model with multiple siamese networks that are trained by using only the information about the similarity between pairs of data samples without knowing the explicit labels. The trained model maps the activity data samples into fixed size representation vectors such that the distance between the vectors in the representation space approximates the similarity of the data samples in the input space. Thus, the trained model can work as a metric for a wide range of different clustering algorithms. The training process minimizes a similarity loss function that forces the distance metric to be small for pairs of samples from the same kind of activity, and large for pairs of samples from different kinds of activities. We evaluate the model on three datasets to verify its effectiveness in segmentation and recognition of continuous human activity sequences.","sentences":["Deep learning has been successfully applied to human activity recognition.","However, training deep neural networks requires explicitly labeled data which is difficult to acquire.","In this paper, we present a model with multiple siamese networks that are trained by using only the information about the similarity between pairs of data samples without knowing the explicit labels.","The trained model maps the activity data samples into fixed size representation vectors such that the distance between the vectors in the representation space approximates the similarity of the data samples in the input space.","Thus, the trained model can work as a metric for a wide range of different clustering algorithms.","The training process minimizes a similarity loss function that forces the distance metric to be small for pairs of samples from the same kind of activity, and large for pairs of samples from different kinds of activities.","We evaluate the model on three datasets to verify its effectiveness in segmentation and recognition of continuous human activity sequences."],"url":"http://arxiv.org/abs/2307.08944v1"}
{"created":"2023-07-18 03:12:51","title":"NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning","abstract":"Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications. However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power. Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored. In this paper, we investigate the neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM. Extensive experiments of PLM fine-tuning on both natural language understanding (NLU) and generation (NLG) tasks are provided to verify the effectiveness of the proposed method MLP fusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.","sentences":["Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications.","However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power.","Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored.","In this paper, we investigate the neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion.","To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM.","Extensive experiments of PLM fine-tuning on both natural language understanding (NLU) and generation (NLG) tasks are provided to verify the effectiveness of the proposed method MLP fusion.","Our code is available at https://github.com/weitianxin/MLP_Fusion."],"url":"http://arxiv.org/abs/2307.08941v1"}
{"created":"2023-07-18 03:12:03","title":"Experimental Security Analysis of DNN-based Adaptive Cruise Control under Context-Aware Perception Attacks","abstract":"Adaptive Cruise Control (ACC) is a widely used driver assistance feature for maintaining desired speed and safe distance to the leading vehicles. This paper evaluates the security of the deep neural network (DNN) based ACC systems under stealthy perception attacks that strategically inject perturbations into camera data to cause forward collisions. We present a combined knowledge-and-data-driven approach to design a context-aware strategy for the selection of the most critical times for triggering the attacks and a novel optimization-based method for the adaptive generation of image perturbations at run-time. We evaluate the effectiveness of the proposed attack using an actual driving dataset and a realistic simulation platform with the control software from a production ACC system and a physical-world driving simulator while considering interventions by the driver and safety features such as Automatic Emergency Braking (AEB) and Forward Collision Warning (FCW). Experimental results show that the proposed attack achieves 142.9x higher success rate in causing accidents than random attacks and is mitigated 89.6% less by the safety features while being stealthy and robust to real-world factors and dynamic changes in the environment. This study provides insights into the role of human operators and basic safety interventions in preventing attacks.","sentences":["Adaptive Cruise Control (ACC) is a widely used driver assistance feature for maintaining desired speed and safe distance to the leading vehicles.","This paper evaluates the security of the deep neural network (DNN) based ACC systems under stealthy perception attacks that strategically inject perturbations into camera data to cause forward collisions.","We present a combined knowledge-and-data-driven approach to design a context-aware strategy for the selection of the most critical times for triggering the attacks and a novel optimization-based method for the adaptive generation of image perturbations at run-time.","We evaluate the effectiveness of the proposed attack using an actual driving dataset and a realistic simulation platform with the control software from a production ACC system and a physical-world driving simulator while considering interventions by the driver and safety features such as Automatic Emergency Braking (AEB) and Forward Collision Warning (FCW).","Experimental results show that the proposed attack achieves 142.9x higher success rate in causing accidents than random attacks and is mitigated 89.6% less by the safety features while being stealthy and robust to real-world factors and dynamic changes in the environment.","This study provides insights into the role of human operators and basic safety interventions in preventing attacks."],"url":"http://arxiv.org/abs/2307.08939v1"}
