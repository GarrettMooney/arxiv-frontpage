{"created":"2023-07-17 17:59:40","title":"AlpaGasus: Training A Better Alpaca with Fewer Data","abstract":"Large language models~(LLMs) obtain instruction-following capability through instruction-finetuning (IFT) on supervised instruction/response data. However, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many low-quality instances with incorrect or irrelevant responses, which are misleading and detrimental to IFT. In this paper, we propose a simple and effective data selection strategy that automatically identifies and removes low-quality data using a strong LLM (e.g., ChatGPT). To this end, we introduce AlpaGasus, which is finetuned on only 9k high-quality data filtered from the 52k Alpaca data. AlpaGasus significantly outperforms the original Alpaca as evaluated by GPT-4 on multiple test sets and its 13B variant matches $>90\\%$ performance of its teacher LLM (i.e., Text-Davinci-003) on test tasks. It also provides 5.7x faster training, reducing the training time for a 7B variant from 80 minutes (for Alpaca) to 14 minutes \\footnote{We apply IFT for the same number of epochs as Alpaca(7B) but on fewer data, using 4$\\times$NVIDIA A100 (80GB) GPUs and following the original Alpaca setting and hyperparameters.}. Overall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be generally applied to instruction-tuning data, leading to faster training and better instruction-following models. Our project page is available at: \\url{https://lichang-chen.github.io/AlpaGasus/}.","sentences":["Large language models~(LLMs) obtain instruction-following capability through instruction-finetuning (IFT) on supervised instruction/response data.","However, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many low-quality instances with incorrect or irrelevant responses, which are misleading and detrimental to IFT.","In this paper, we propose a simple and effective data selection strategy that automatically identifies and removes low-quality data using a strong LLM (e.g., ChatGPT).","To this end, we introduce AlpaGasus, which is finetuned on only 9k high-quality data filtered from the 52k Alpaca data.","AlpaGasus significantly outperforms the original Alpaca as evaluated by GPT-4 on multiple test sets and its 13B variant matches $>90\\%$ performance of its teacher LLM (i.e., Text-Davinci-003) on test tasks.","It also provides 5.7x faster training, reducing the training time for a 7B variant from 80 minutes (for Alpaca) to 14 minutes \\footnote{We apply IFT for the same number of epochs as Alpaca(7B)","but on fewer data, using 4$\\times$NVIDIA A100 (80GB) GPUs and following the original Alpaca setting and hyperparameters.}.","Overall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be generally applied to instruction-tuning data, leading to faster training and better instruction-following models.","Our project page is available at: \\url{https://lichang-chen.github.io/AlpaGasus/}."],"url":"http://arxiv.org/abs/2307.08701v1"}
{"created":"2023-07-17 17:59:40","title":"Diffusion Models Beat GANs on Image Classification","abstract":"While many unsupervised learning models focus on one family of tasks, either generative or discriminative, we explore the possibility of a unified representation learner: a model which uses a single pre-training stage to address both families of tasks simultaneously. We identify diffusion models as a prime candidate. Diffusion models have risen to prominence as a state-of-the-art method for image generation, denoising, inpainting, super-resolution, manipulation, etc. Such models involve training a U-Net to iteratively predict and remove noise, and the resulting model can synthesize high fidelity, diverse, novel images. The U-Net architecture, as a convolution-based architecture, generates a diverse set of feature representations in the form of intermediate feature maps. We present our findings that these embeddings are useful beyond the noise prediction task, as they contain discriminative information and can also be leveraged for classification. We explore optimal methods for extracting and using these embeddings for classification tasks, demonstrating promising results on the ImageNet classification task. We find that with careful feature selection and pooling, diffusion models outperform comparable generative-discriminative methods such as BigBiGAN for classification tasks. We investigate diffusion models in the transfer learning regime, examining their performance on several fine-grained visual classification datasets. We compare these embeddings to those generated by competing architectures and pre-trainings for classification tasks.","sentences":["While many unsupervised learning models focus on one family of tasks, either generative or discriminative, we explore the possibility of a unified representation learner: a model which uses a single pre-training stage to address both families of tasks simultaneously.","We identify diffusion models as a prime candidate.","Diffusion models have risen to prominence as a state-of-the-art method for image generation, denoising, inpainting, super-resolution, manipulation, etc.","Such models involve training a U-Net to iteratively predict and remove noise, and the resulting model can synthesize high fidelity, diverse, novel images.","The U-Net architecture, as a convolution-based architecture, generates a diverse set of feature representations in the form of intermediate feature maps.","We present our findings that these embeddings are useful beyond the noise prediction task, as they contain discriminative information and can also be leveraged for classification.","We explore optimal methods for extracting and using these embeddings for classification tasks, demonstrating promising results on the ImageNet classification task.","We find that with careful feature selection and pooling, diffusion models outperform comparable generative-discriminative methods such as BigBiGAN for classification tasks.","We investigate diffusion models in the transfer learning regime, examining their performance on several fine-grained visual classification datasets.","We compare these embeddings to those generated by competing architectures and pre-trainings for classification tasks."],"url":"http://arxiv.org/abs/2307.08702v1"}
{"created":"2023-07-17 17:59:09","title":"Fast model inference and training on-board of Satellites","abstract":"Artificial intelligence onboard satellites has the potential to reduce data transmission requirements, enable real-time decision-making and collaboration within constellations. This study deploys a lightweight foundational model called RaVAEn on D-Orbit's ION SCV004 satellite. RaVAEn is a variational auto-encoder (VAE) that generates compressed latent vectors from small image tiles, enabling several downstream tasks. In this work we demonstrate the reliable use of RaVAEn onboard a satellite, achieving an encoding time of 0.110s for tiles of a 4.8x4.8 km$^2$ area. In addition, we showcase fast few-shot training onboard a satellite using the latent representation of data. We compare the deployment of the model on the on-board CPU and on the available Myriad vision processing unit (VPU) accelerator. To our knowledge, this work shows for the first time the deployment of a multi-task model on-board a CubeSat and the on-board training of a machine learning model.","sentences":["Artificial intelligence onboard satellites has the potential to reduce data transmission requirements, enable real-time decision-making and collaboration within constellations.","This study deploys a lightweight foundational model called RaVAEn on D-Orbit's ION SCV004 satellite.","RaVAEn is a variational auto-encoder (VAE) that generates compressed latent vectors from small image tiles, enabling several downstream tasks.","In this work we demonstrate the reliable use of RaVAEn onboard a satellite, achieving an encoding time of 0.110s for tiles of a 4.8x4.8 km$^2$ area.","In addition, we showcase fast few-shot training onboard a satellite using the latent representation of data.","We compare the deployment of the model on the on-board CPU and on the available Myriad vision processing unit (VPU) accelerator.","To our knowledge, this work shows for the first time the deployment of a multi-task model on-board a CubeSat and the on-board training of a machine learning model."],"url":"http://arxiv.org/abs/2307.08700v1"}
{"created":"2023-07-17 17:58:37","title":"Pair then Relation: Pair-Net for Panoptic Scene Graph Generation","abstract":"Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes. However, current PSG methods have limited performance, which can hinder downstream task development. To improve PSG methods, we conducted an in-depth analysis to identify the bottleneck of the current PSG models, finding that inter-object pair-wise recall is a crucial factor which was ignored by previous PSG methods. Based on this, we present a novel framework: Pair then Relation (Pair-Net), which uses a Pair Proposal Network (PPN) to learn and filter sparse pair-wise relationships between subjects and objects. We also observed the sparse nature of object pairs and used this insight to design a lightweight Matrix Learner within the PPN. Through extensive ablation and analysis, our approach significantly improves upon leveraging the strong segmenter baseline. Notably, our approach achieves new state-of-the-art results on the PSG benchmark, with over 10% absolute gains compared to PSGFormer. The code of this paper is publicly available at https://github.com/king159/Pair-Net.","sentences":["Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes.","However, current PSG methods have limited performance, which can hinder downstream task development.","To improve PSG methods, we conducted an in-depth analysis to identify the bottleneck of the current PSG models, finding that inter-object pair-wise recall is a crucial factor which was ignored by previous PSG methods.","Based on this, we present a novel framework:","Pair then Relation (Pair-Net), which uses a Pair Proposal Network (PPN) to learn and filter sparse pair-wise relationships between subjects and objects.","We also observed the sparse nature of object pairs and used this insight to design a lightweight Matrix Learner within the PPN.","Through extensive ablation and analysis, our approach significantly improves upon leveraging the strong segmenter baseline.","Notably, our approach achieves new state-of-the-art results on the PSG benchmark, with over 10% absolute gains compared to PSGFormer.","The code of this paper is publicly available at https://github.com/king159/Pair-Net."],"url":"http://arxiv.org/abs/2307.08699v1"}
{"created":"2023-07-17 17:57:56","title":"Flow Matching in Latent Space","abstract":"Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models. Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space. Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area. In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis. This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility. Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation. Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church & Bedroom, and ImageNet. We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective. Our code will be available at https://github.com/VinAIResearch/LFM.git.","sentences":["Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models.","Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space.","Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area.","In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis.","This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility.","Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation.","Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church & Bedroom, and ImageNet.","We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective.","Our code will be available at https://github.com/VinAIResearch/LFM.git."],"url":"http://arxiv.org/abs/2307.08698v1"}
{"created":"2023-07-17 17:57:01","title":"Neural Video Depth Stabilizer","abstract":"Video depth estimation aims to infer temporally consistent depth. Some methods achieve temporal consistency by finetuning a single-image depth model during test time using geometry and re-projection constraints, which is inefficient and not robust. An alternative approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and sufficient video depth data. To address these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS) that stabilizes inconsistent depth estimations and can be applied to different single-image depth models without extra effort. We also introduce a large-scale dataset, Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames, making it the largest natural-scene video depth dataset to our knowledge. We evaluate our method on the VDW dataset as well as two public benchmarks and demonstrate significant improvements in consistency, accuracy, and efficiency compared to previous approaches. Our work serves as a solid baseline and provides a data foundation for learning-based video depth models. We will release our dataset and code for future research.","sentences":["Video depth estimation aims to infer temporally consistent depth.","Some methods achieve temporal consistency by finetuning a single-image depth model during test time using geometry and re-projection constraints, which is inefficient and not robust.","An alternative approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and sufficient video depth data.","To address these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS) that stabilizes inconsistent depth estimations and can be applied to different single-image depth models without extra effort.","We also introduce a large-scale dataset, Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames, making it the largest natural-scene video depth dataset to our knowledge.","We evaluate our method on the VDW dataset as well as two public benchmarks and demonstrate significant improvements in consistency, accuracy, and efficiency compared to previous approaches.","Our work serves as a solid baseline and provides a data foundation for learning-based video depth models.","We will release our dataset and code for future research."],"url":"http://arxiv.org/abs/2307.08695v1"}
{"created":"2023-07-17 17:53:36","title":"SEMI-DiffusionInst: A Diffusion Model Based Approach for Semiconductor Defect Classification and Segmentation","abstract":"With continuous progression of Moore's Law, integrated circuit (IC) device complexity is also increasing. Scanning Electron Microscope (SEM) image based extensive defect inspection and accurate metrology extraction are two main challenges in advanced node (2 nm and beyond) technology. Deep learning (DL) algorithm based computer vision approaches gained popularity in semiconductor defect inspection over last few years. In this research work, a new semiconductor defect inspection framework \"SEMI-DiffusionInst\" is investigated and compared to previous frameworks. To the best of the authors' knowledge, this work is the first demonstration to accurately detect and precisely segment semiconductor defect patterns by using a diffusion model. Different feature extractor networks as backbones and data sampling strategies are investigated towards achieving a balanced trade-off between precision and computing efficiency. Our proposed approach outperforms previous work on overall mAP and performs comparatively better or as per for almost all defect classes (per class APs). The bounding box and segmentation mAPs achieved by the proposed SEMI-DiffusionInst model are improved by 3.83% and 2.10%,respectively. Among individual defect types, precision on line collapse and thin bridge defects are improved approximately 15% on detection task for both defect types. It has also been shown that by tuning inference hyperparameters, inference time can be improved significantly without compromising model precision. Finally, certain limitations and future work strategy to overcome them are discussed.","sentences":["With continuous progression of Moore's Law, integrated circuit (IC) device complexity is also increasing.","Scanning Electron Microscope (SEM) image based extensive defect inspection and accurate metrology extraction are two main challenges in advanced node (2 nm and beyond) technology.","Deep learning (DL) algorithm based computer vision approaches gained popularity in semiconductor defect inspection over last few years.","In this research work, a new semiconductor defect inspection framework \"SEMI-DiffusionInst\" is investigated and compared to previous frameworks.","To the best of the authors' knowledge, this work is the first demonstration to accurately detect and precisely segment semiconductor defect patterns by using a diffusion model.","Different feature extractor networks as backbones and data sampling strategies are investigated towards achieving a balanced trade-off between precision and computing efficiency.","Our proposed approach outperforms previous work on overall mAP and performs comparatively better or as per for almost all defect classes (per class APs).","The bounding box and segmentation mAPs achieved by the proposed SEMI-DiffusionInst model are improved by 3.83% and 2.10%,respectively.","Among individual defect types, precision on line collapse and thin bridge defects are improved approximately 15% on detection task for both defect types.","It has also been shown that by tuning inference hyperparameters, inference time can be improved significantly without compromising model precision.","Finally, certain limitations and future work strategy to overcome them are discussed."],"url":"http://arxiv.org/abs/2307.08693v1"}
{"created":"2023-07-17 17:50:36","title":"FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning","abstract":"Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length. FlashAttention exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4$\\times$ compared to optimized baselines), with no approximation. However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40\\% of the theoretical maximum FLOPs/s. We observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes. We propose FlashAttention-2, with better work partitioning to address these issues. In particular, we (1) tweak the algorithm to reduce the number of non-matmul FLOPs (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory. These yield around 2$\\times$ speedup compared to FlashAttention, reaching 50-73\\% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations. We empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72\\% model FLOPs utilization).","sentences":["Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation.","The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length.","FlashAttention exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4$\\times$ compared to optimized baselines), with no approximation.","However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40\\% of the theoretical maximum FLOPs/s. We observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes.","We propose FlashAttention-2, with better work partitioning to address these issues.","In particular, we (1) tweak the algorithm to reduce the number of non-matmul FLOPs (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory.","These yield around 2$\\times$ speedup compared to FlashAttention, reaching 50-73\\% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations.","We empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72\\% model FLOPs utilization)."],"url":"http://arxiv.org/abs/2307.08691v1"}
{"created":"2023-07-17 17:49:03","title":"Robotic Exploration for Mapping","abstract":"Robotic Exploration has evolved rapidly in the past two decades as new and more complex techniques have been created to explore unknown regions efficiently. Exciting advancements in exploration, autonomous navigation, and sensor technology have created opportunities for robots to be utilized in new environments and for new objectives ranging from mapping of abandon mines and deep oceans to the efficient creation of indoor models for navigation and search. In this paper we present and discuss a number of examples in research literature of these recent advancements, specifically focusing on robotic exploration algorithms for unmanned vehicles.","sentences":["Robotic Exploration has evolved rapidly in the past two decades as new and more complex techniques have been created to explore unknown regions efficiently.","Exciting advancements in exploration, autonomous navigation, and sensor technology have created opportunities for robots to be utilized in new environments and for new objectives ranging from mapping of abandon mines and deep oceans to the efficient creation of indoor models for navigation and search.","In this paper we present and discuss a number of examples in research literature of these recent advancements, specifically focusing on robotic exploration algorithms for unmanned vehicles."],"url":"http://arxiv.org/abs/2307.08690v1"}
{"created":"2023-07-17 17:48:51","title":"COLLIE: Systematic Construction of Constrained Text Generation Tasks","abstract":"Text generation under constraints have seen increasing interests in natural language processing, especially with the rapidly improving capabilities of large language models. However, existing benchmarks for constrained generation usually focus on fixed constraint types (e.g.,generate a sentence containing certain words) that have proved to be easy for state-of-the-art models like GPT-4. We present COLLIE, a grammar-based framework that allows the specification of rich, compositional constraints with diverse generation levels (word, sentence, paragraph, passage) and modeling challenges (e.g.,language understanding, logical reasoning, counting, semantic planning). We also develop tools for automatic extraction of task instances given a constraint structure and a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 2080 instances comprising 13 constraint structures. We perform systematic experiments across five state-of-the-art instruction-tuned language models and analyze their performances to reveal shortcomings. COLLIE is designed to be extensible and lightweight, and we hope the community finds it useful to develop more complex constraints and evaluations in the future.","sentences":["Text generation under constraints have seen increasing interests in natural language processing, especially with the rapidly improving capabilities of large language models.","However, existing benchmarks for constrained generation usually focus on fixed constraint types (e.g.,generate a sentence containing certain words) that have proved to be easy for state-of-the-art models like GPT-4.","We present COLLIE, a grammar-based framework that allows the specification of rich, compositional constraints with diverse generation levels (word, sentence, paragraph, passage) and modeling challenges (e.g.,language understanding, logical reasoning, counting, semantic planning).","We also develop tools for automatic extraction of task instances given a constraint structure and a raw text corpus.","Using COLLIE, we compile the COLLIE-v1 dataset with 2080 instances comprising 13 constraint structures.","We perform systematic experiments across five state-of-the-art instruction-tuned language models and analyze their performances to reveal shortcomings.","COLLIE is designed to be extensible and lightweight, and we hope the community finds it useful to develop more complex constraints and evaluations in the future."],"url":"http://arxiv.org/abs/2307.08689v1"}
{"created":"2023-07-17 17:44:18","title":"Implementation of a perception system for autonomous vehicles using a detection-segmentation network in SoC FPGA","abstract":"Perception and control systems for autonomous vehicles are an active area of scientific and industrial research. These solutions should be characterised by high efficiency in recognising obstacles and other environmental elements in different road conditions, real-time capability, and energy efficiency. Achieving such functionality requires an appropriate algorithm and a suitable computing platform. In this paper, we have used the MultiTaskV3 detection-segmentation network as the basis for a perception system that can perform both functionalities within a single architecture. It was appropriately trained, quantised, and implemented on the AMD Xilinx Kria KV260 Vision AI embedded platform. By using this device, it was possible to parallelise and accelerate the computations. Furthermore, the whole system consumes relatively little power compared to a CPU-based implementation (an average of 5 watts, compared to the minimum of 55 watts for weaker CPUs, and the small size (119mm x 140mm x 36mm) of the platform allows it to be used in devices where the amount of space available is limited. It also achieves an accuracy higher than 97% of the mAP (mean average precision) for object detection and above 90% of the mIoU (mean intersection over union) for image segmentation. The article also details the design of the Mecanum wheel vehicle, which was used to test the proposed solution in a mock-up city.","sentences":["Perception and control systems for autonomous vehicles are an active area of scientific and industrial research.","These solutions should be characterised by high efficiency in recognising obstacles and other environmental elements in different road conditions, real-time capability, and energy efficiency.","Achieving such functionality requires an appropriate algorithm and a suitable computing platform.","In this paper, we have used the MultiTaskV3 detection-segmentation network as the basis for a perception system that can perform both functionalities within a single architecture.","It was appropriately trained, quantised, and implemented on the AMD Xilinx Kria KV260 Vision AI embedded platform.","By using this device, it was possible to parallelise and accelerate the computations.","Furthermore, the whole system consumes relatively little power compared to a CPU-based implementation (an average of 5 watts, compared to the minimum of 55 watts for weaker CPUs, and the small size (119mm x 140mm x 36mm) of the platform allows it to be used in devices where the amount of space available is limited.","It also achieves an accuracy higher than 97% of the mAP (mean average precision) for object detection and above 90% of the mIoU (mean intersection over union) for image segmentation.","The article also details the design of the Mecanum wheel vehicle, which was used to test the proposed solution in a mock-up city."],"url":"http://arxiv.org/abs/2307.08682v1"}
{"created":"2023-07-17 17:43:43","title":"Secure Composition of Robust and Optimising Compilers","abstract":"To ensure that secure applications do not leak their secrets, they are required to uphold several security properties such as spatial and temporal memory safety as well as cryptographic constant time. Existing work shows how to enforce these properties individually, in an architecture-independent way, by using secure compiler passes that each focus on an individual property. Unfortunately, given two secure compiler passes that each preserve a possibly different security property, it is unclear what kind of security property is preserved by the composition of those secure compiler passes. This paper is the first to study what security properties are preserved across the composition of different secure compiler passes. Starting from a general theory of property composition for security-relevant properties (such as the aforementioned ones), this paper formalises a theory of composition of secure compilers. Then, it showcases this theory a secure multi-pass compiler that preserves the aforementioned security-relevant properties. Crucially, this paper derives the security of the multi-pass compiler from the composition of the security properties preserved by its individual passes, which include security-preserving as well as optimisation passes. From an engineering perspective, this is the desirable approach to building secure compilers.","sentences":["To ensure that secure applications do not leak their secrets, they are required to uphold several security properties such as spatial and temporal memory safety as well as cryptographic constant time.","Existing work shows how to enforce these properties individually, in an architecture-independent way, by using secure compiler passes that each focus on an individual property.","Unfortunately, given two secure compiler passes that each preserve a possibly different security property, it is unclear what kind of security property is preserved by the composition of those secure compiler passes.","This paper is the first to study what security properties are preserved across the composition of different secure compiler passes.","Starting from a general theory of property composition for security-relevant properties (such as the aforementioned ones), this paper formalises a theory of composition of secure compilers.","Then, it showcases this theory a secure multi-pass compiler that preserves the aforementioned security-relevant properties.","Crucially, this paper derives the security of the multi-pass compiler from the composition of the security properties preserved by its individual passes, which include security-preserving as well as optimisation passes.","From an engineering perspective, this is the desirable approach to building secure compilers."],"url":"http://arxiv.org/abs/2307.08681v1"}
{"created":"2023-07-17 17:43:38","title":"Optimal storage codes on graphs with fixed locality","abstract":"Storage codes on graphs are an instance of \\emph{codes with locality}, which are used in distributed storage schemes to provide local repairability. Specifically, the nodes of the graph correspond to storage servers, and the neighbourhood of each server constitute the set of servers it can query to repair its stored data in the event of a failure. A storage code on a graph with $n$-vertices is a set of $n$-length codewords over $\\field_q$ where the $i$th codeword symbol is stored in server $i$, and it can be recovered by querying the neighbours of server $i$ according to the underlying graph.   In this work, we look at binary storage codes whose repair function is the parity check, and characterise the tradeoff between the locality of the code and its rate. Specifically, we show that the maximum rate of a code on $n$ vertices with locality $r$ is bounded between $1-1/n\\lceil n/(r+1)\\rceil$ and $1-1/n\\lceil n/(r+1)\\rceil$. The lower bound on the rate is derived by constructing an explicit family of graphs with locality $r$, while the upper bound is obtained via a lower bound on the binary-field rank of a class of symmetric binary matrices. Our upper bound on maximal rate of a storage code matches the upper bound on the larger class of codes with locality derived by Tamo and Barg. As a corollary to our result, we obtain the following asymptotic separation result: given a sequence $r(n), n\\geq 1$, there exists a sequence of graphs on $n$-vertices with storage codes of rate $1-o(1)$ if and only if $r(n)=\\omega(1)$.","sentences":["Storage codes on graphs are an instance of \\emph{codes with locality}, which are used in distributed storage schemes to provide local repairability.","Specifically, the nodes of the graph correspond to storage servers, and the neighbourhood of each server constitute the set of servers it can query to repair its stored data in the event of a failure.","A storage code on a graph with $n$-vertices is a set of $n$-length codewords over $\\field_q$ where the $i$th codeword symbol is stored in server $i$, and it can be recovered by querying the neighbours of server $i$ according to the underlying graph.   ","In this work, we look at binary storage codes whose repair function is the parity check, and characterise the tradeoff between the locality of the code and its rate.","Specifically, we show that the maximum rate of a code on $n$ vertices with locality $r$ is bounded between $1-1/n\\lceil n/(r+1)\\rceil$ and $1-1/n\\lceil n/(r+1)\\rceil$. The lower bound on the rate is derived by constructing an explicit family of graphs with locality $r$, while the upper bound is obtained via a lower bound on the binary-field rank of a class of symmetric binary matrices.","Our upper bound on maximal rate of a storage code matches the upper bound on the larger class of codes with locality derived by Tamo and Barg.","As a corollary to our result, we obtain the following asymptotic separation result: given a sequence $r(n), n\\geq 1$, there exists a sequence of graphs on $n$-vertices with storage codes of rate $1-o(1)$ if and only if $r(n)=\\omega(1)$."],"url":"http://arxiv.org/abs/2307.08680v1"}
{"created":"2023-07-17 17:41:47","title":"Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations","abstract":"Large language models (LLMs) are trained to imitate humans to explain human decisions. However, do LLMs explain themselves? Can they help humans build mental models of how LLMs process different inputs? To answer these questions, we propose to evaluate $\\textbf{counterfactual simulatability}$ of natural language explanations: whether an explanation can enable humans to precisely infer the model's outputs on diverse counterfactuals of the explained input. For example, if a model answers \"yes\" to the input question \"Can eagles fly?\" with the explanation \"all birds can fly\", then humans would infer from the explanation that it would also answer \"yes\" to the counterfactual input \"Can penguins fly?\". If the explanation is precise, then the model's answer should match humans' expectations.   We implemented two metrics based on counterfactual simulatability: precision and generality. We generated diverse counterfactuals automatically using LLMs. We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on two tasks: multi-hop factual reasoning and reward modeling. We found that LLM's explanations have low precision and that precision does not correlate with plausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may not be a sufficient solution.","sentences":["Large language models (LLMs) are trained to imitate humans to explain human decisions.","However, do LLMs explain themselves?","Can they help humans build mental models of how LLMs process different inputs?","To answer these questions, we propose to evaluate $\\textbf{counterfactual simulatability}$ of natural language explanations: whether an explanation can enable humans to precisely infer the model's outputs on diverse counterfactuals of the explained input.","For example, if a model answers \"yes\" to the input question \"Can eagles fly?\"","with the explanation \"all birds can fly\", then humans would infer from the explanation that it would also answer \"yes\" to the counterfactual input \"Can penguins fly?\".","If the explanation is precise, then the model's answer should match humans' expectations.   ","We implemented two metrics based on counterfactual simulatability: precision and generality.","We generated diverse counterfactuals automatically using LLMs.","We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on two tasks: multi-hop factual reasoning and reward modeling.","We found that LLM's explanations have low precision and that precision does not correlate with plausibility.","Therefore, naively optimizing human approvals (e.g., RLHF) may not be a sufficient solution."],"url":"http://arxiv.org/abs/2307.08678v1"}
{"created":"2023-07-17 17:36:09","title":"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT","abstract":"Tables are prevalent in real-world databases, requiring significant time and effort for humans to analyze and manipulate. The advancements in large language models (LLMs) have made it possible to interact with tables using natural language input, bringing this capability closer to reality. In this paper, we present TableGPT, a unified fine-tuned framework that enables LLMs to understand and operate on tables using external functional commands. It introduces the capability to seamlessly interact with tables, enabling a wide range of functionalities such as question answering, data manipulation (e.g., insert, delete, query, and modify operations), data visualization, analysis report generation, and automated prediction. TableGPT aims to provide convenience and accessibility to users by empowering them to effortlessly leverage tabular data. At the core of TableGPT lies the novel concept of global tabular representations, which empowers LLMs to gain a comprehensive understanding of the entire table beyond meta-information. By jointly training LLMs on both table and text modalities, TableGPT achieves a deep understanding of tabular data and the ability to perform complex operations on tables through chain-of-command instructions. Importantly, TableGPT offers the advantage of being a self-contained system rather than relying on external API interfaces. Moreover, it supports efficient data process flow, query rejection (when appropriate) and private deployment, enabling faster domain data fine-tuning and ensuring data privacy, which enhances the framework's adaptability to specific use cases.","sentences":["Tables are prevalent in real-world databases, requiring significant time and effort for humans to analyze and manipulate.","The advancements in large language models (LLMs) have made it possible to interact with tables using natural language input, bringing this capability closer to reality.","In this paper, we present TableGPT, a unified fine-tuned framework that enables LLMs to understand and operate on tables using external functional commands.","It introduces the capability to seamlessly interact with tables, enabling a wide range of functionalities such as question answering, data manipulation (e.g., insert, delete, query, and modify operations), data visualization, analysis report generation, and automated prediction.","TableGPT aims to provide convenience and accessibility to users by empowering them to effortlessly leverage tabular data.","At the core of TableGPT lies the novel concept of global tabular representations, which empowers LLMs to gain a comprehensive understanding of the entire table beyond meta-information.","By jointly training LLMs on both table and text modalities, TableGPT achieves a deep understanding of tabular data and the ability to perform complex operations on tables through chain-of-command instructions.","Importantly, TableGPT offers the advantage of being a self-contained system rather than relying on external API interfaces.","Moreover, it supports efficient data process flow, query rejection (when appropriate) and private deployment, enabling faster domain data fine-tuning and ensuring data privacy, which enhances the framework's adaptability to specific use cases."],"url":"http://arxiv.org/abs/2307.08674v1"}
{"created":"2023-07-17 17:34:32","title":"CohortFinder: an open-source tool for data-driven partitioning of biomedical image cohorts to yield robust machine learning models","abstract":"Batch effects (BEs) refer to systematic technical differences in data collection unrelated to biological variations whose noise is shown to negatively impact machine learning (ML) model generalizability. Here we release CohortFinder, an open-source tool aimed at mitigating BEs via data-driven cohort partitioning. We demonstrate CohortFinder improves ML model performance in downstream medical image processing tasks. CohortFinder is freely available for download at cohortfinder.com.","sentences":["Batch effects (BEs) refer to systematic technical differences in data collection unrelated to biological variations whose noise is shown to negatively impact machine learning (ML) model generalizability.","Here we release CohortFinder, an open-source tool aimed at mitigating BEs via data-driven cohort partitioning.","We demonstrate CohortFinder improves ML model performance in downstream medical image processing tasks.","CohortFinder is freely available for download at cohortfinder.com."],"url":"http://arxiv.org/abs/2307.08673v1"}
{"created":"2023-07-17 17:33:10","title":"Age of Gossip on a Grid","abstract":"We consider a gossip network consisting of a source generating updates and $n$ nodes connected in a two-dimensional square grid. The source keeps updates of a process, that might be generated or observed, and shares them with the grid network. The nodes in the grid network communicate with their neighbors and disseminate these version updates using a push-style gossip strategy. We use the version age metric to quantify the timeliness of information at the nodes. We find an upper bound for the average version age for a set of nodes in a general network. Using this, we show that the average version age at a node scales as $O(n^{\\frac{1}{3}})$ in a grid network. Prior to our work, it has been known that when $n$ nodes are connected on a ring the version age scales as $O(n^{\\frac{1}{2}})$, and when they are connected on a fully-connected graph the version age scales as $O(\\log n)$. Ours is the first work to show an age scaling result for a connectivity structure other than the ring and fully-connected networks that represent two extremes of network connectivity. Our work shows that higher connectivity on a grid compared to a ring lowers the age experience of each node from $O(n^{\\frac{1}{2}})$ to $O(n^{\\frac{1}{3}})$.","sentences":["We consider a gossip network consisting of a source generating updates and $n$ nodes connected in a two-dimensional square grid.","The source keeps updates of a process, that might be generated or observed, and shares them with the grid network.","The nodes in the grid network communicate with their neighbors and disseminate these version updates using a push-style gossip strategy.","We use the version age metric to quantify the timeliness of information at the nodes.","We find an upper bound for the average version age for a set of nodes in a general network.","Using this, we show that the average version age at a node scales as $O(n^{\\frac{1}{3}})$ in a grid network.","Prior to our work, it has been known that when $n$ nodes are connected on a ring the version age scales as $O(n^{\\frac{1}{2}})$, and when they are connected on a fully-connected graph the version age scales as $O(\\log n)$. Ours is the first work to show an age scaling result for a connectivity structure other than the ring and fully-connected networks that represent two extremes of network connectivity.","Our work shows that higher connectivity on a grid compared to a ring lowers the age experience of each node from $O(n^{\\frac{1}{2}})$ to $O(n^{\\frac{1}{3}})$."],"url":"http://arxiv.org/abs/2307.08670v1"}
{"created":"2023-07-17 17:32:30","title":"Leveraging Recommender Systems to Reduce Content Gaps on Peer Production Platforms","abstract":"Peer production platforms like Wikipedia commonly suffer from content gaps. Prior research suggests recommender systems can help solve this problem, by guiding editors towards underrepresented topics. However, it remains unclear whether this approach would result in less relevant recommendations, leading to reduced overall engagement with recommended items. To answer this question, we first conducted offline analyses (Study 1) on SuggestBot, a task-routing recommender system for Wikipedia, then did a three-month controlled experiment (Study 2). Our results show that presenting users with articles from underrepresented topics increased the proportion of work done on those articles without significantly reducing overall recommendation uptake. We discuss the implications of our results, including how ignoring the article discovery process can artificially narrow recommendations. We draw parallels between this phenomenon and the common issue of ``filter bubbles'' to show how any platform that employs recommender systems is susceptible to it.","sentences":["Peer production platforms like Wikipedia commonly suffer from content gaps.","Prior research suggests recommender systems can help solve this problem, by guiding editors towards underrepresented topics.","However, it remains unclear whether this approach would result in less relevant recommendations, leading to reduced overall engagement with recommended items.","To answer this question, we first conducted offline analyses (Study 1) on SuggestBot, a task-routing recommender system for Wikipedia, then did a three-month controlled experiment (Study 2).","Our results show that presenting users with articles from underrepresented topics increased the proportion of work done on those articles without significantly reducing overall recommendation uptake.","We discuss the implications of our results, including how ignoring the article discovery process can artificially narrow recommendations.","We draw parallels between this phenomenon and the common issue of ``filter bubbles'' to show how any platform that employs recommender systems is susceptible to it."],"url":"http://arxiv.org/abs/2307.08669v1"}
{"created":"2023-07-17 17:32:07","title":"A Study in Zucker: Insights on Human-Robot Interactions","abstract":"In recent years there has been a large focus on how robots can operate in human populated environments. In this paper, we focus on interactions between humans and small indoor robots and introduce a new human-robot interaction (HRI) dataset. The analysis of the recorded experiments shows that anticipatory and non-reactive robot controllers impose similar constraints to humans' safety and efficiency. Additionally, we found that current state-of-the-art models for human trajectory prediction can adequately extend to indoor HRI settings. Finally, we show that humans respond differently in shared and homogeneous environments when collisions are imminent, since interacting with small differential drives can only cause a finite level of social discomfort as compared to human-human interactions. The dataset used in this analysis is available at: https://github.com/AlexanderDavid/ZuckerDataset.","sentences":["In recent years there has been a large focus on how robots can operate in human populated environments.","In this paper, we focus on interactions between humans and small indoor robots and introduce a new human-robot interaction (HRI) dataset.","The analysis of the recorded experiments shows that anticipatory and non-reactive robot controllers impose similar constraints to humans' safety and efficiency.","Additionally, we found that current state-of-the-art models for human trajectory prediction can adequately extend to indoor HRI settings.","Finally, we show that humans respond differently in shared and homogeneous environments when collisions are imminent, since interacting with small differential drives can only cause a finite level of social discomfort as compared to human-human interactions.","The dataset used in this analysis is available at: https://github.com/AlexanderDavid/ZuckerDataset."],"url":"http://arxiv.org/abs/2307.08668v1"}
{"created":"2023-07-17 17:27:06","title":"Quaternion Convolutional Neural Networks: Current Advances and Future Directions","abstract":"Since their first applications, Convolutional Neural Networks (CNNs) have solved problems that have advanced the state-of-the-art in several domains. CNNs represent information using real numbers. Despite encouraging results, theoretical analysis shows that representations such as hyper-complex numbers can achieve richer representational capacities than real numbers, and that Hamilton products can capture intrinsic interchannel relationships. Moreover, in the last few years, experimental research has shown that Quaternion-Valued CNNs (QCNNs) can achieve similar performance with fewer parameters than their real-valued counterparts. This paper condenses research in the development of QCNNs from its very beginnings. We propose a conceptual organization of current trends and analyze the main building blocks used in the design of QCNN models. Based on this conceptual organization, we propose future directions of research.","sentences":["Since their first applications, Convolutional Neural Networks (CNNs) have solved problems that have advanced the state-of-the-art in several domains.","CNNs represent information using real numbers.","Despite encouraging results, theoretical analysis shows that representations such as hyper-complex numbers can achieve richer representational capacities than real numbers, and that Hamilton products can capture intrinsic interchannel relationships.","Moreover, in the last few years, experimental research has shown that Quaternion-Valued CNNs (QCNNs) can achieve similar performance with fewer parameters than their real-valued counterparts.","This paper condenses research in the development of QCNNs from its very beginnings.","We propose a conceptual organization of current trends and analyze the main building blocks used in the design of QCNN models.","Based on this conceptual organization, we propose future directions of research."],"url":"http://arxiv.org/abs/2307.08663v1"}
{"created":"2023-07-17 17:12:44","title":"Multilingual Speech-to-Speech Translation into Multiple Target Languages","abstract":"Speech-to-speech translation (S2ST) enables spoken communication between people talking in different languages. Despite a few studies on multilingual S2ST, their focus is the multilinguality on the source side, i.e., the translation from multiple source languages to one target language. We present the first work on multilingual S2ST supporting multiple target languages. Leveraging recent advance in direct S2ST with speech-to-unit and vocoder, we equip these key components with multilingual capability. Speech-to-masked-unit (S2MU) is the multilingual extension of S2U, which applies masking to units which don't belong to the given target language to reduce the language interference. We also propose multilingual vocoder which is trained with language embedding and the auxiliary loss of language identification. On benchmark translation testsets, our proposed multilingual model shows superior performance than bilingual models in the translation from English into $16$ target languages.","sentences":["Speech-to-speech translation (S2ST) enables spoken communication between people talking in different languages.","Despite a few studies on multilingual S2ST, their focus is the multilinguality on the source side, i.e., the translation from multiple source languages to one target language.","We present the first work on multilingual S2ST supporting multiple target languages.","Leveraging recent advance in direct S2ST with speech-to-unit and vocoder, we equip these key components with multilingual capability.","Speech-to-masked-unit (S2MU) is the multilingual extension of S2U, which applies masking to units which don't belong to the given target language to reduce the language interference.","We also propose multilingual vocoder which is trained with language embedding and the auxiliary loss of language identification.","On benchmark translation testsets, our proposed multilingual model shows superior performance than bilingual models in the translation from English into $16$ target languages."],"url":"http://arxiv.org/abs/2307.08655v1"}
{"created":"2023-07-17 17:03:26","title":"Search Me Knot, Render Me Knot: Embedding Search and Differentiable Rendering of Knots in 3D","abstract":"We introduce the problem of knot-based inverse perceptual art. Given multiple target images and their corresponding viewing configurations, the objective is to find a 3D knot-based tubular structure whose appearance resembles the target images when viewed from the specified viewing configurations. To solve this problem, we first design a differentiable rendering algorithm for rendering tubular knots embedded in 3D for arbitrary perspective camera configurations. Utilizing this he's doctodifferentiable rendering algorithm, we search over the space of knot configurations to find the ideal knot embedding. We represent the knot embeddings via homeomorphisms of the desired template knot, where the homeomorphisms are parametrized by the weights of an invertible neural network. Our approach is fully differentiable, making it possible to find the ideal 3D tubular structure for the desired perceptual art using gradient-based optimization. We propose several loss functions that impose additional physical constraints, ensuring that the tube is free of self-intersection, lies within a predefined region in space, satisfies the physical bending limits of the tube material and the material cost is within a specified budget. We demonstrate through results that our knot representation is highly expressive and gives impressive results even for challenging target images in both single view as well as multiple view constraints. Through extensive ablation study we show that each of the proposed loss function is effective in ensuring physical realizability. To the best of our knowledge, we are the first to propose a fully differentiable optimization framework for knot-based inverse perceptual art.","sentences":["We introduce the problem of knot-based inverse perceptual art.","Given multiple target images and their corresponding viewing configurations, the objective is to find a 3D knot-based tubular structure whose appearance resembles the target images when viewed from the specified viewing configurations.","To solve this problem, we first design a differentiable rendering algorithm for rendering tubular knots embedded in 3D for arbitrary perspective camera configurations.","Utilizing this he's doctodifferentiable rendering algorithm, we search over the space of knot configurations to find the ideal knot embedding.","We represent the knot embeddings via homeomorphisms of the desired template knot, where the homeomorphisms are parametrized by the weights of an invertible neural network.","Our approach is fully differentiable, making it possible to find the ideal 3D tubular structure for the desired perceptual art using gradient-based optimization.","We propose several loss functions that impose additional physical constraints, ensuring that the tube is free of self-intersection, lies within a predefined region in space, satisfies the physical bending limits of the tube material and the material cost is within a specified budget.","We demonstrate through results that our knot representation is highly expressive and gives impressive results even for challenging target images in both single view as well as multiple view constraints.","Through extensive ablation study we show that each of the proposed loss function is effective in ensuring physical realizability.","To the best of our knowledge, we are the first to propose a fully differentiable optimization framework for knot-based inverse perceptual art."],"url":"http://arxiv.org/abs/2307.08652v1"}
{"created":"2023-07-17 17:00:29","title":"Uncertainty-Aware Acoustic Localization and Mapping for Underwater Robots","abstract":"For underwater vehicles, robotic applications have the added difficulty of operating in highly unstructured and dynamic environments. Environmental effects impact not only the dynamics and controls of the robot but also the perception and sensing modalities. Acoustic sensors, which inherently use mechanically vibrated signals for measuring range or velocity, are particularly prone to the effects that such dynamic environments induce. This paper presents an uncertainty-aware localization and mapping framework that accounts for induced disturbances in acoustic sensing modalities for underwater robots operating near the surface in dynamic wave conditions. For the state estimation task, the uncertainty is accounted for as the added noise caused by the environmental disturbance. The mapping method uses an adaptive kernel-based method to propagate measurement and pose uncertainty into an occupancy map. Experiments are carried out in a wave tank environment to perform qualitative and quantitative evaluations of the proposed method. More details about this project can be found at https://umfieldrobotics.github.io/PUMA.github.io.","sentences":["For underwater vehicles, robotic applications have the added difficulty of operating in highly unstructured and dynamic environments.","Environmental effects impact not only the dynamics and controls of the robot but also the perception and sensing modalities.","Acoustic sensors, which inherently use mechanically vibrated signals for measuring range or velocity, are particularly prone to the effects that such dynamic environments induce.","This paper presents an uncertainty-aware localization and mapping framework that accounts for induced disturbances in acoustic sensing modalities for underwater robots operating near the surface in dynamic wave conditions.","For the state estimation task, the uncertainty is accounted for as the added noise caused by the environmental disturbance.","The mapping method uses an adaptive kernel-based method to propagate measurement and pose uncertainty into an occupancy map.","Experiments are carried out in a wave tank environment to perform qualitative and quantitative evaluations of the proposed method.","More details about this project can be found at https://umfieldrobotics.github.io/PUMA.github.io."],"url":"http://arxiv.org/abs/2307.08647v1"}
{"created":"2023-07-17 16:57:01","title":"A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond","abstract":"Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of \"more complex\" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we study in this paper by theoretically analyzing loss correction with respect to different corruption instances.","sentences":["Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models.","Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking.","In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels.","We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research.","Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk.","Our findings offer qualitative insights into the consequences of \"more complex\" corruptions on the learning problem, and provide a foundation for future quantitative comparisons.","Applications of the framework include corruption-corrected learning, a subcase of which we study in this paper by theoretically analyzing loss correction with respect to different corruption instances."],"url":"http://arxiv.org/abs/2307.08643v1"}
{"created":"2023-07-17 16:53:22","title":"LearnedSort as a learning-augmented SampleSort: Analysis and Parallelization","abstract":"This work analyzes and parallelizes LearnedSort, the novel algorithm that sorts using machine learning models based on the cumulative distribution function. LearnedSort is analyzed under the lens of algorithms with predictions, and it is argued that LearnedSort is a learning-augmented SampleSort. A parallel LearnedSort algorithm is developed combining LearnedSort with the state-of-the-art SampleSort implementation, IPS4o. Benchmarks on synthetic and real-world datasets demonstrate improved parallel performance for parallel LearnedSort compared to IPS4o and other sorting algorithms.","sentences":["This work analyzes and parallelizes LearnedSort, the novel algorithm that sorts using machine learning models based on the cumulative distribution function.","LearnedSort is analyzed under the lens of algorithms with predictions, and it is argued that LearnedSort is a learning-augmented SampleSort.","A parallel LearnedSort algorithm is developed combining LearnedSort with the state-of-the-art SampleSort implementation, IPS4o.","Benchmarks on synthetic and real-world datasets demonstrate improved parallel performance for parallel LearnedSort compared to IPS4o and other sorting algorithms."],"url":"http://arxiv.org/abs/2307.08637v1"}
{"created":"2023-07-17 16:52:25","title":"PolyGNN: Polyhedron-based Graph Neural Network for 3D Building Reconstruction from Point Clouds","abstract":"We present PolyGNN, a polyhedron-based graph neural network for 3D building reconstruction from point clouds. PolyGNN learns to assemble primitives obtained by polyhedral decomposition via graph node classification, achieving a watertight, compact, and weakly semantic reconstruction. To effectively represent arbitrary-shaped polyhedra in the neural network, we propose three different sampling strategies to select representative points as polyhedron-wise queries, enabling efficient occupancy inference. Furthermore, we incorporate the inter-polyhedron adjacency to enhance the classification of the graph nodes. We also observe that existing city-building models are abstractions of the underlying instances. To address this abstraction gap and provide a fair evaluation of the proposed method, we develop our method on a large-scale synthetic dataset covering 500k+ buildings with well-defined ground truths of polyhedral class labels. We further conduct a transferability analysis across cities and on real-world point clouds. Both qualitative and quantitative results demonstrate the effectiveness of our method, particularly its efficiency for large-scale reconstructions. The source code and data of our work are available at https://github.com/chenzhaiyu/polygnn.","sentences":["We present PolyGNN, a polyhedron-based graph neural network for 3D building reconstruction from point clouds.","PolyGNN learns to assemble primitives obtained by polyhedral decomposition via graph node classification, achieving a watertight, compact, and weakly semantic reconstruction.","To effectively represent arbitrary-shaped polyhedra in the neural network, we propose three different sampling strategies to select representative points as polyhedron-wise queries, enabling efficient occupancy inference.","Furthermore, we incorporate the inter-polyhedron adjacency to enhance the classification of the graph nodes.","We also observe that existing city-building models are abstractions of the underlying instances.","To address this abstraction gap and provide a fair evaluation of the proposed method, we develop our method on a large-scale synthetic dataset covering 500k+ buildings with well-defined ground truths of polyhedral class labels.","We further conduct a transferability analysis across cities and on real-world point clouds.","Both qualitative and quantitative results demonstrate the effectiveness of our method, particularly its efficiency for large-scale reconstructions.","The source code and data of our work are available at https://github.com/chenzhaiyu/polygnn."],"url":"http://arxiv.org/abs/2307.08636v1"}
{"created":"2023-07-17 16:52:13","title":"Lightweight ML-based Runtime Prefetcher Selection on Many-core Platforms","abstract":"Modern computer designs support composite prefetching, where multiple individual prefetcher components are used to target different memory access patterns. However, multiple prefetchers competing for resources can drastically hurt performance, especially in many-core systems where cache and other resources are shared and very limited. Prior work has proposed mitigating this issue by selectively enabling and disabling prefetcher components during runtime. Traditional approaches proposed heuristics that are hard to scale with increasing core and prefetcher component counts. More recently, deep reinforcement learning was proposed. However, it is too expensive to deploy in real-world many-core systems. In this work, we propose a new phase-based methodology for training a lightweight supervised learning model to manage composite prefetchers at runtime. Our approach improves the performance of a state-of-the-art many-core system by up to 25% and by 2.7% on average over its default prefetcher configuration.","sentences":["Modern computer designs support composite prefetching, where multiple individual prefetcher components are used to target different memory access patterns.","However, multiple prefetchers competing for resources can drastically hurt performance, especially in many-core systems where cache and other resources are shared and very limited.","Prior work has proposed mitigating this issue by selectively enabling and disabling prefetcher components during runtime.","Traditional approaches proposed heuristics that are hard to scale with increasing core and prefetcher component counts.","More recently, deep reinforcement learning was proposed.","However, it is too expensive to deploy in real-world many-core systems.","In this work, we propose a new phase-based methodology for training a lightweight supervised learning model to manage composite prefetchers at runtime.","Our approach improves the performance of a state-of-the-art many-core system by up to 25% and by 2.7% on average over its default prefetcher configuration."],"url":"http://arxiv.org/abs/2307.08635v1"}
{"created":"2023-07-17 16:45:39","title":"Dual-Functional MIMO Beamforming Optimization for RIS-Aided Integrated Sensing and Communication","abstract":"Aiming at providing wireless communication systems with environment-perceptive capacity, emerging integrated sensing and communication (ISAC) technologies face multiple difficulties, especially in balancing the performance trade-off between the communication and radar functions. In this paper, we introduce a reconfigurable intelligent surface (RIS) to assist both data transmission and target detection in a dual-functional ISAC system. To formulate a general optimization framework, diverse communication performance metrics have been taken into account including famous capacity maximization and mean-squared error (MSE) minimization. Whereas the target detection process is modeled as a general likelihood ratio test (GLRT) due to the practical limitations, and the monotonicity of the corresponding detection probability is proved. For the single-user and single-target (SUST) scenario, the minimum transmit power of the ISAC transceiver has been revealed. By exploiting the optimal conditions of the BS design, we validate that the BS is able to realize the maximum power allocation scheme and derive the optimal BS precoder in a semi-closed form. Moreover, an alternating direction method of multipliers (ADMM) based RIS design is proposed to address the optimization of unit-modulus RIS phase shifts. For the sake of further enhancing computational efficiency, we also develop a low-complexity RIS design based on Riemannian gradient descent. Furthermore, the ISAC transceiver design for the multiple-users and multiple-targets (MUMT) scenario is also investigated, where a zero-forcing (ZF) radar receiver is adopted to cancel the interferences. Then optimal BS precoder is derived under the maximum power allocation scheme, and the RIS phase shifts can be optimized by extending the proposed ADMM-based RIS design. Numerical simulation results verify the performance of our proposed transceiver designs.","sentences":["Aiming at providing wireless communication systems with environment-perceptive capacity, emerging integrated sensing and communication (ISAC) technologies face multiple difficulties, especially in balancing the performance trade-off between the communication and radar functions.","In this paper, we introduce a reconfigurable intelligent surface (RIS) to assist both data transmission and target detection in a dual-functional ISAC system.","To formulate a general optimization framework, diverse communication performance metrics have been taken into account including famous capacity maximization and mean-squared error (MSE) minimization.","Whereas the target detection process is modeled as a general likelihood ratio test (GLRT) due to the practical limitations, and the monotonicity of the corresponding detection probability is proved.","For the single-user and single-target (SUST) scenario, the minimum transmit power of the ISAC transceiver has been revealed.","By exploiting the optimal conditions of the BS design, we validate that the BS is able to realize the maximum power allocation scheme and derive the optimal BS precoder in a semi-closed form.","Moreover, an alternating direction method of multipliers (ADMM) based RIS design is proposed to address the optimization of unit-modulus RIS phase shifts.","For the sake of further enhancing computational efficiency, we also develop a low-complexity RIS design based on Riemannian gradient descent.","Furthermore, the ISAC transceiver design for the multiple-users and multiple-targets (MUMT) scenario is also investigated, where a zero-forcing (ZF) radar receiver is adopted to cancel the interferences.","Then optimal BS precoder is derived under the maximum power allocation scheme, and the RIS phase shifts can be optimized by extending the proposed ADMM-based RIS design.","Numerical simulation results verify the performance of our proposed transceiver designs."],"url":"http://arxiv.org/abs/2307.08631v1"}
{"created":"2023-07-17 16:45:33","title":"A Nested U-Structure for Instrument Segmentation in Robotic Surgery","abstract":"Robot-assisted surgery has made great progress with the development of medical imaging and robotics technology. Medical scene understanding can greatly improve surgical performance while the semantic segmentation of the robotic instrument is a key enabling technology for robot-assisted surgery. However, how to locate an instrument's position and estimate their pose in complex surgical environments is still a challenging fundamental problem. In this paper, pixel-wise instrument segmentation is investigated. The contributions of the paper are twofold: 1) We proposed a two-level nested U-structure model, which is an encoder-decoder architecture with skip-connections and each layer of the network structure adopts a U-structure instead of a simple superposition of convolutional layers. The model can capture more context information from multiple scales and better fuse the local and global information to achieve high-quality segmentation. 2) Experiments have been conducted to qualitatively and quantitatively show the performance of our approach on three segmentation tasks: the binary segmentation, the parts segmentation, and the type segmentation, respectively.","sentences":["Robot-assisted surgery has made great progress with the development of medical imaging and robotics technology.","Medical scene understanding can greatly improve surgical performance while the semantic segmentation of the robotic instrument is a key enabling technology for robot-assisted surgery.","However, how to locate an instrument's position and estimate their pose in complex surgical environments is still a challenging fundamental problem.","In this paper, pixel-wise instrument segmentation is investigated.","The contributions of the paper are twofold: 1) We proposed a two-level nested U-structure model, which is an encoder-decoder architecture with skip-connections and each layer of the network structure adopts a U-structure instead of a simple superposition of convolutional layers.","The model can capture more context information from multiple scales and better fuse the local and global information to achieve high-quality segmentation.","2) Experiments have been conducted to qualitatively and quantitatively show the performance of our approach on three segmentation tasks: the binary segmentation, the parts segmentation, and the type segmentation, respectively."],"url":"http://arxiv.org/abs/2307.08630v1"}
{"created":"2023-07-17 16:45:10","title":"Deficiency-Aware Masked Transformer for Video Inpainting","abstract":"Recent video inpainting methods have made remarkable progress by utilizing explicit guidance, such as optical flow, to propagate cross-frame pixels. However, there are cases where cross-frame recurrence of the masked video is not available, resulting in a deficiency. In such situation, instead of borrowing pixels from other frames, the focus of the model shifts towards addressing the inverse problem. In this paper, we introduce a dual-modality-compatible inpainting framework called Deficiency-aware Masked Transformer (DMT), which offers three key advantages. Firstly, we pretrain a image inpainting model DMT_img serve as a prior for distilling the video model DMT_vid, thereby benefiting the hallucination of deficiency cases. Secondly, the self-attention module selectively incorporates spatiotemporal tokens to accelerate inference and remove noise signals. Thirdly, a simple yet effective Receptive Field Contextualizer is integrated into DMT, further improving performance. Extensive experiments conducted on YouTube-VOS and DAVIS datasets demonstrate that DMT_vid significantly outperforms previous solutions. The code and video demonstrations can be found at github.com/yeates/DMT.","sentences":["Recent video inpainting methods have made remarkable progress by utilizing explicit guidance, such as optical flow, to propagate cross-frame pixels.","However, there are cases where cross-frame recurrence of the masked video is not available, resulting in a deficiency.","In such situation, instead of borrowing pixels from other frames, the focus of the model shifts towards addressing the inverse problem.","In this paper, we introduce a dual-modality-compatible inpainting framework called Deficiency-aware Masked Transformer (DMT), which offers three key advantages.","Firstly, we pretrain a image inpainting model DMT_img serve as a prior for distilling the video model DMT_vid, thereby benefiting the hallucination of deficiency cases.","Secondly, the self-attention module selectively incorporates spatiotemporal tokens to accelerate inference and remove noise signals.","Thirdly, a simple yet effective Receptive Field Contextualizer is integrated into DMT, further improving performance.","Extensive experiments conducted on YouTube-VOS and DAVIS datasets demonstrate that DMT_vid significantly outperforms previous solutions.","The code and video demonstrations can be found at github.com/yeates/DMT."],"url":"http://arxiv.org/abs/2307.08629v1"}
{"created":"2023-07-17 16:43:01","title":"Managing Write Access without Token Fees in Leaderless DAG-based Ledgers","abstract":"A significant portion of research on distributed ledgers has focused on circumventing the limitations of leader-based blockchains mainly in terms of scalability, decentralization and power consumption. Leaderless architectures based on directed acyclic graphs (DAGs) avoid many of these limitations altogether, but their increased flexibility and performance comes at the cost of increased design complexity, so their potential has remained largely unexplored. Management of write access to these ledgers presents a major challenge because ledger updates may be made in parallel, hence transactions cannot simply be serialised and prioritised according to token fees paid to validators. In this work, we propose an access control scheme for leaderless DAG-based ledgers which is based on consuming credits rather than paying fees in the base token. We outline a general model for this new approach and provide some simulation results showing promising performance boosts.","sentences":["A significant portion of research on distributed ledgers has focused on circumventing the limitations of leader-based blockchains mainly in terms of scalability, decentralization and power consumption.","Leaderless architectures based on directed acyclic graphs (DAGs) avoid many of these limitations altogether, but their increased flexibility and performance comes at the cost of increased design complexity, so their potential has remained largely unexplored.","Management of write access to these ledgers presents a major challenge because ledger updates may be made in parallel, hence transactions cannot simply be serialised and prioritised according to token fees paid to validators.","In this work, we propose an access control scheme for leaderless DAG-based ledgers which is based on consuming credits rather than paying fees in the base token.","We outline a general model for this new approach and provide some simulation results showing promising performance boosts."],"url":"http://arxiv.org/abs/2307.08627v1"}
{"created":"2023-07-17 16:40:01","title":"Retentive Network: A Successor to Transformer for Large Language Models","abstract":"In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference. The intriguing properties make RetNet a strong successor to Transformer for large language models. Code will be available at https://aka.ms/retnet.","sentences":["In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance.","We theoretically derive the connection between recurrence and attention.","Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent.","Specifically, the parallel representation allows for training parallelism.","The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance.","The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks.","Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference.","The intriguing properties make RetNet a strong successor to Transformer for large language models.","Code will be available at https://aka.ms/retnet."],"url":"http://arxiv.org/abs/2307.08621v1"}
{"created":"2023-07-17 16:32:49","title":"Understanding the impacts of crop diversification in the context of climate change: a machine learning approach","abstract":"The concept of sustainable intensification in agriculture necessitates the implementation of management practices that prioritize sustainability without compromising productivity. However, the effects of such practices are known to depend on environmental conditions, and are therefore expected to change as a result of a changing climate. We study the impact of crop diversification on productivity in the context of climate change. We leverage heterogeneous Earth Observation data and contribute a data-driven approach based on causal machine learning for understanding how crop diversification impacts may change in the future. We apply this method to the country of Cyprus throughout a 4-year period. We find that, on average, crop diversification significantly benefited the net primary productivity of crops, increasing it by 2.8%. The effect generally synergized well with higher maximum temperatures and lower soil moistures. In a warmer and more drought-prone climate, we conclude that crop diversification exhibits promising adaptation potential and is thus a sensible policy choice with regards to agricultural productivity for present and future.","sentences":["The concept of sustainable intensification in agriculture necessitates the implementation of management practices that prioritize sustainability without compromising productivity.","However, the effects of such practices are known to depend on environmental conditions, and are therefore expected to change as a result of a changing climate.","We study the impact of crop diversification on productivity in the context of climate change.","We leverage heterogeneous Earth Observation data and contribute a data-driven approach based on causal machine learning for understanding how crop diversification impacts may change in the future.","We apply this method to the country of Cyprus throughout a 4-year period.","We find that, on average, crop diversification significantly benefited the net primary productivity of crops, increasing it by 2.8%.","The effect generally synergized well with higher maximum temperatures and lower soil moistures.","In a warmer and more drought-prone climate, we conclude that crop diversification exhibits promising adaptation potential and is thus a sensible policy choice with regards to agricultural productivity for present and future."],"url":"http://arxiv.org/abs/2307.08617v1"}
{"created":"2023-07-17 16:30:56","title":"Temporal and Geographical Analysis of Real Economic Activities in the Bitcoin Blockchain","abstract":"We study the real economic activity in the Bitcoin blockchain that involves transactions from/to retail users rather than between organizations such as marketplaces, exchanges, or other services. We first introduce a heuristic method to classify Bitcoin players into three main categories: Frequent Receivers (FR), Neighbors of FR, and Others. We show that most real transactions involve Frequent Receivers, representing a small fraction of the total value exchanged according to the blockchain, but a significant fraction of all payments, raising concerns about the centralization of the Bitcoin ecosystem. We also conduct a weekly pattern analysis of activity, providing insights into the geographical location of Bitcoin users and allowing us to quantify the bias of a well-known dataset for actor identification.","sentences":["We study the real economic activity in the Bitcoin blockchain that involves transactions from/to retail users rather than between organizations such as marketplaces, exchanges, or other services.","We first introduce a heuristic method to classify Bitcoin players into three main categories: Frequent Receivers (FR), Neighbors of FR, and Others.","We show that most real transactions involve Frequent Receivers, representing a small fraction of the total value exchanged according to the blockchain, but a significant fraction of all payments, raising concerns about the centralization of the Bitcoin ecosystem.","We also conduct a weekly pattern analysis of activity, providing insights into the geographical location of Bitcoin users and allowing us to quantify the bias of a well-known dataset for actor identification."],"url":"http://arxiv.org/abs/2307.08616v1"}
{"created":"2023-07-17 16:30:44","title":"Benchmarking fixed-length Fingerprint Representations across different Embedding Sizes and Sensor Types","abstract":"Traditional minutiae-based fingerprint representations consist of a variable-length set of minutiae. This necessitates a more complex comparison causing the drawback of high computational cost in one-to-many comparison. Recently, deep neural networks have been proposed to extract fixed-length embeddings from fingerprints. In this paper, we explore to what extent fingerprint texture information contained in such embeddings can be reduced in terms of dimension while preserving high biometric performance. This is of particular interest since it would allow to reduce the number of operations incurred at comparisons. We also study the impact in terms of recognition performance of the fingerprint textural information for two sensor types, i.e. optical and capacitive. Furthermore, the impact of rotation and translation of fingerprint images on the extraction of fingerprint embeddings is analysed. Experimental results conducted on a publicly available database reveal an optimal embedding size of 512 feature elements for the texture-based embedding part of fixed-length fingerprint representations. In addition, differences in performance between sensor types can be perceived.","sentences":["Traditional minutiae-based fingerprint representations consist of a variable-length set of minutiae.","This necessitates a more complex comparison causing the drawback of high computational cost in one-to-many comparison.","Recently, deep neural networks have been proposed to extract fixed-length embeddings from fingerprints.","In this paper, we explore to what extent fingerprint texture information contained in such embeddings can be reduced in terms of dimension while preserving high biometric performance.","This is of particular interest since it would allow to reduce the number of operations incurred at comparisons.","We also study the impact in terms of recognition performance of the fingerprint textural information for two sensor types, i.e. optical and capacitive.","Furthermore, the impact of rotation and translation of fingerprint images on the extraction of fingerprint embeddings is analysed.","Experimental results conducted on a publicly available database reveal an optimal embedding size of 512 feature elements for the texture-based embedding part of fixed-length fingerprint representations.","In addition, differences in performance between sensor types can be perceived."],"url":"http://arxiv.org/abs/2307.08615v1"}
{"created":"2023-07-17 16:30:19","title":"Splitter Orderings for Probabilistic Bisimulation","abstract":"Model checking has been proposed as a formal verification approach for analyzing computer-based and cyber-physical systems. The state space explosion problem is the main obstacle for applying this approach for sophisticated systems. Bisimulation minimization is a prominent method for reducing the number of states in a labeled transition system and is used to alleviate the challenges of the state space explosion problem. For systems with stochastic behaviors, probabilistic bisimulation is used to reduce a given model to its minimized equivalent one. In recent years, several techniques have been proposed to reduce the time complexity of the iterative methods for computing probabilistic bisimulation of stochastic systems with nondeterministic behaviors. In this paper, we propose several techniques to accelerate iterative processes to partition the state space of a given probabilistic model to its bisimulation classes. The first technique applies two ordering heuristics for choosing splitter blocks. The second technique uses hash tables to reduce the running time and the average time complexity of the standard iterative method. The proposed approaches are implemented and run on several conventional case studies and reduce the running time by one order of magnitude on average.","sentences":["Model checking has been proposed as a formal verification approach for analyzing computer-based and cyber-physical systems.","The state space explosion problem is the main obstacle for applying this approach for sophisticated systems.","Bisimulation minimization is a prominent method for reducing the number of states in a labeled transition system and is used to alleviate the challenges of the state space explosion problem.","For systems with stochastic behaviors, probabilistic bisimulation is used to reduce a given model to its minimized equivalent one.","In recent years, several techniques have been proposed to reduce the time complexity of the iterative methods for computing probabilistic bisimulation of stochastic systems with nondeterministic behaviors.","In this paper, we propose several techniques to accelerate iterative processes to partition the state space of a given probabilistic model to its bisimulation classes.","The first technique applies two ordering heuristics for choosing splitter blocks.","The second technique uses hash tables to reduce the running time and the average time complexity of the standard iterative method.","The proposed approaches are implemented and run on several conventional case studies and reduce the running time by one order of magnitude on average."],"url":"http://arxiv.org/abs/2307.08614v1"}
{"created":"2023-07-17 16:09:24","title":"Glamour muscles: why having a body is not what it means to be embodied","abstract":"Embodiment has recently enjoyed renewed consideration as a means to amplify the faculties of smart machines. Proponents of embodiment seem to imply that optimizing for movement in physical space promotes something more than the acquisition of niche capabilities for solving problems in physical space. However, there is nothing in principle which should so distinguish the problem of action selection in physical space from the problem of action selection in more abstract spaces, like that of language. Rather, what makes embodiment persuasive as a means toward higher intelligence is that it promises to capture, but does not actually realize, contingent facts about certain bodies (living intelligence) and the patterns of activity associated with them. These include an active resistance to annihilation and revisable constraints on the processes that make the world intelligible. To be theoretically or practically useful beyond the creation of niche tools, we argue that \"embodiment\" cannot be the trivial fact of a body, nor its movement through space, but the perpetual negotiation of the function, design, and integrity of that body$\\unicode{x2013}$that is, to participate in what it means to $\\textit{constitute}$ a given body. It follows that computer programs which are strictly incapable of traversing physical space might, under the right conditions, be more embodied than a walking, talking robot.","sentences":["Embodiment has recently enjoyed renewed consideration as a means to amplify the faculties of smart machines.","Proponents of embodiment seem to imply that optimizing for movement in physical space promotes something more than the acquisition of niche capabilities for solving problems in physical space.","However, there is nothing in principle which should so distinguish the problem of action selection in physical space from the problem of action selection in more abstract spaces, like that of language.","Rather, what makes embodiment persuasive as a means toward higher intelligence is that it promises to capture, but does not actually realize, contingent facts about certain bodies (living intelligence) and the patterns of activity associated with them.","These include an active resistance to annihilation and revisable constraints on the processes that make the world intelligible.","To be theoretically or practically useful beyond the creation of niche tools, we argue that \"embodiment\" cannot be the trivial fact of a body, nor its movement through space, but the perpetual negotiation of the function, design, and integrity of that body$\\unicode{x2013}$that is, to participate in what it means to $\\textit{constitute}$ a given body.","It follows that computer programs which are strictly incapable of traversing physical space might, under the right conditions, be more embodied than a walking, talking robot."],"url":"http://arxiv.org/abs/2307.08598v1"}
{"created":"2023-07-17 16:07:07","title":"Multimodal Diffusion Segmentation Model for Object Segmentation from Manipulation Instructions","abstract":"In this study, we aim to develop a model that comprehends a natural language instruction (e.g., \"Go to the living room and get the nearest pillow to the radio art on the wall\") and generates a segmentation mask for the target everyday object. The task is challenging because it requires (1) the understanding of the referring expressions for multiple objects in the instruction, (2) the prediction of the target phrase of the sentence among the multiple phrases, and (3) the generation of pixel-wise segmentation masks rather than bounding boxes. Studies have been conducted on languagebased segmentation methods; however, they sometimes mask irrelevant regions for complex sentences. In this paper, we propose the Multimodal Diffusion Segmentation Model (MDSM), which generates a mask in the first stage and refines it in the second stage. We introduce a crossmodal parallel feature extraction mechanism and extend diffusion probabilistic models to handle crossmodal features. To validate our model, we built a new dataset based on the well-known Matterport3D and REVERIE datasets. This dataset consists of instructions with complex referring expressions accompanied by real indoor environmental images that feature various target objects, in addition to pixel-wise segmentation masks. The performance of MDSM surpassed that of the baseline method by a large margin of +10.13 mean IoU.","sentences":["In this study, we aim to develop a model that comprehends a natural language instruction (e.g., \"Go to the living room and get the nearest pillow to the radio art on the wall\") and generates a segmentation mask for the target everyday object.","The task is challenging because it requires (1) the understanding of the referring expressions for multiple objects in the instruction, (2) the prediction of the target phrase of the sentence among the multiple phrases, and (3) the generation of pixel-wise segmentation masks rather than bounding boxes.","Studies have been conducted on languagebased segmentation methods; however, they sometimes mask irrelevant regions for complex sentences.","In this paper, we propose the Multimodal Diffusion Segmentation Model (MDSM), which generates a mask in the first stage and refines it in the second stage.","We introduce a crossmodal parallel feature extraction mechanism and extend diffusion probabilistic models to handle crossmodal features.","To validate our model, we built a new dataset based on the well-known Matterport3D and REVERIE datasets.","This dataset consists of instructions with complex referring expressions accompanied by real indoor environmental images that feature various target objects, in addition to pixel-wise segmentation masks.","The performance of MDSM surpassed that of the baseline method by a large margin of +10.13 mean IoU."],"url":"http://arxiv.org/abs/2307.08597v1"}
{"created":"2023-07-17 16:02:28","title":"Tight Bounds for Budgeted Maximum Weight Independent Set in Bipartite and Perfect Graphs","abstract":"We consider the classic budgeted maximum weight independent set (BMWIS) problem. The input is a graph $G = (V,E)$, a weight function $w:V \\rightarrow \\mathbb{R}_{\\geq 0}$, a cost function $c:V \\rightarrow \\mathbb{R}_{\\geq 0}$, and a budget $B \\in \\mathbb{R}_{\\geq 0}$. The goal is to find an independent set $S \\subseteq V$ in $G$ such that $\\sum_{v \\in S} c(v) \\leq B$, which maximizes the total weight $\\sum_{v \\in S} w(v)$. Since the problem on general graphs cannot be approximated within ratio $|V|^{1-\\varepsilon}$ for any $\\varepsilon>0$, BMWIS has attracted significant attention on graph families for which a maximum weight independent set can be computed in polynomial time. Two notable such graph families are bipartite and perfect graphs. BMWIS is known to be NP-hard on both of these graph families; however, the best possible approximation guarantees for these graphs are wide open.   In this paper, we give a tight $2$-approximation for BMWIS on perfect graphs and bipartite graphs. In particular, we give We a $(2-\\varepsilon)$ lower bound for BMWIS on bipartite graphs, already for the special case where the budget is replaced by a cardinality constraint, based on the Small Set Expansion Hypothesis (SSEH). For the upper bound, we design a $2$-approximation for BMWIS on perfect graphs using a Lagrangian relaxation based technique. Finally, we obtain a tight lower bound for the capacitated maximum weight independent set (CMWIS) problem, the special case of BMWIS where $w(v) = c(v)~\\forall v \\in V$. We show that CMWIS on bipartite and perfect graphs is unlikely to admit an efficient polynomial-time approximation scheme (EPTAS). Thus, the existing PTAS for CMWIS is essentially the best we can expect.","sentences":["We consider the classic budgeted maximum weight independent set (BMWIS) problem.","The input is a graph $G = (V,E)$, a weight function $w:V \\rightarrow \\mathbb{R}_{\\geq 0}$, a cost function $c:V \\rightarrow \\mathbb{R}_{\\geq 0}$, and a budget $B \\in \\mathbb{R}_{\\geq 0}$.","The goal is to find an independent set $S \\subseteq V$ in $G$ such that $\\sum_{v \\in S} c(v)","\\leq B$, which maximizes the total weight $\\sum_{v \\in S} w(v)$. Since the problem on general graphs cannot be approximated within ratio $|V|^{1-\\varepsilon}$ for any $\\varepsilon>0$, BMWIS has attracted significant attention on graph families for which a maximum weight independent set can be computed in polynomial time.","Two notable such graph families are bipartite and perfect graphs.","BMWIS is known to be NP-hard on both of these graph families; however, the best possible approximation guarantees for these graphs are wide open.   ","In this paper, we give a tight $2$-approximation for BMWIS on perfect graphs and bipartite graphs.","In particular, we give We a $(2-\\varepsilon)$ lower bound for BMWIS on bipartite graphs, already for the special case where the budget is replaced by a cardinality constraint, based on the Small Set Expansion Hypothesis (SSEH).","For the upper bound, we design a $2$-approximation for BMWIS on perfect graphs using a Lagrangian relaxation based technique.","Finally, we obtain a tight lower bound for the capacitated maximum weight independent set (CMWIS) problem, the special case of BMWIS where $w(v) = c(v)~\\forall v \\in V$.","We show that CMWIS on bipartite and perfect graphs is unlikely to admit an efficient polynomial-time approximation scheme (EPTAS).","Thus, the existing PTAS for CMWIS is essentially the best we can expect."],"url":"http://arxiv.org/abs/2307.08592v1"}
{"created":"2023-07-17 16:01:22","title":"Snapshot Spectral Clustering -- a costless approach to deep clustering ensembles generation","abstract":"Despite tremendous advancements in Artificial Intelligence, learning from large sets of data in an unsupervised manner remains a significant challenge. Classical clustering algorithms often fail to discover complex dependencies in large datasets, especially considering sparse, high-dimensional spaces. However, deep learning techniques proved to be successful when dealing with large quantities of data, efficiently reducing their dimensionality without losing track of underlying information. Several interesting advancements have already been made to combine deep learning and clustering. Still, the idea of enhancing the clustering results by combining multiple views of the data generated by deep neural networks appears to be insufficiently explored yet. This paper aims to investigate this direction and bridge the gap between deep neural networks, clustering techniques and ensemble learning methods. To achieve this goal, we propose a novel deep clustering ensemble method - Snapshot Spectral Clustering, designed to maximize the gain from combining multiple data views while minimizing the computational costs of creating the ensemble. Comparative analysis and experiments described in this paper prove the proposed concept, while the conducted hyperparameter study provides a valuable intuition to follow when selecting proper values.","sentences":["Despite tremendous advancements in Artificial Intelligence, learning from large sets of data in an unsupervised manner remains a significant challenge.","Classical clustering algorithms often fail to discover complex dependencies in large datasets, especially considering sparse, high-dimensional spaces.","However, deep learning techniques proved to be successful when dealing with large quantities of data, efficiently reducing their dimensionality without losing track of underlying information.","Several interesting advancements have already been made to combine deep learning and clustering.","Still, the idea of enhancing the clustering results by combining multiple views of the data generated by deep neural networks appears to be insufficiently explored yet.","This paper aims to investigate this direction and bridge the gap between deep neural networks, clustering techniques and ensemble learning methods.","To achieve this goal, we propose a novel deep clustering ensemble method - Snapshot Spectral Clustering, designed to maximize the gain from combining multiple data views while minimizing the computational costs of creating the ensemble.","Comparative analysis and experiments described in this paper prove the proposed concept, while the conducted hyperparameter study provides a valuable intuition to follow when selecting proper values."],"url":"http://arxiv.org/abs/2307.08591v1"}
{"created":"2023-07-17 16:01:03","title":"The Effect of Data Visualisation Quality and Task Density on Human-Swarm Interaction","abstract":"Despite the advantages of having robot swarms, human supervision is required for real-world applications. The performance of the human-swarm system depends on several factors including the data availability for the human operators. In this paper, we study the human factors aspect of the human-swarm interaction and investigate how having access to high-quality data can affect the performance of the human-swarm system - the number of tasks completed and the human trust level in operation. We designed an experiment where a human operator is tasked to operate a swarm to identify casualties in an area within a given time period. One group of operators had the option to request high-quality pictures while the other group had to base their decision on the available low-quality images. We performed a user study with 120 participants and recorded their success rate (directly logged via the simulation platform) as well as their workload and trust level (measured through a questionnaire after completing a human-swarm scenario). The findings from our study indicated that the group granted access to high-quality data exhibited an increased workload and placed greater trust in the swarm, thus confirming our initial hypothesis. However, we also found that the number of accurately identified casualties did not significantly vary between the two groups, suggesting that data quality had no impact on the successful completion of tasks.","sentences":["Despite the advantages of having robot swarms, human supervision is required for real-world applications.","The performance of the human-swarm system depends on several factors including the data availability for the human operators.","In this paper, we study the human factors aspect of the human-swarm interaction and investigate how having access to high-quality data can affect the performance of the human-swarm system - the number of tasks completed and the human trust level in operation.","We designed an experiment where a human operator is tasked to operate a swarm to identify casualties in an area within a given time period.","One group of operators had the option to request high-quality pictures while the other group had to base their decision on the available low-quality images.","We performed a user study with 120 participants and recorded their success rate (directly logged via the simulation platform) as well as their workload and trust level (measured through a questionnaire after completing a human-swarm scenario).","The findings from our study indicated that the group granted access to high-quality data exhibited an increased workload and placed greater trust in the swarm, thus confirming our initial hypothesis.","However, we also found that the number of accurately identified casualties did not significantly vary between the two groups, suggesting that data quality had no impact on the successful completion of tasks."],"url":"http://arxiv.org/abs/2307.08590v1"}
{"created":"2023-07-17 15:59:11","title":"A Case for VR Briefings: Comparing Communication in Daily Audio and VR Mission Control in a Simulated Lunar Mission","abstract":"Alpha-XR Mission conducted by XR Lab PJAIT focused on research related to individual and crew well-being and participatory team collaboration in ICE (isolated, confined and extreme) conditions. In this two-week mission within an analog space habitat, collaboration, objective execution and leisure was facilitated and studied by virtual reality (VR) tools. The mission commander and first officer, both experienced with virtual reality, took part in daily briefings with mission control. In the first week the briefings were voice-only conducted via a channel on Discord. During the following week last briefings were conducted in VR, using Horizon Workrooms. This qualitative pilot study employing participatory observation revealed that VR facilitates communication, especially on complex problems and experiences, providing the sense of emotional connection and shared understanding, that may be lacking in audio calls. The study points to the need to further explore VR-facilitated communication in high-stake environments as it may improve relationships, well-being, and communication outcomes.","sentences":["Alpha-XR Mission conducted by XR Lab PJAIT focused on research related to individual and crew well-being and participatory team collaboration in ICE (isolated, confined and extreme) conditions.","In this two-week mission within an analog space habitat, collaboration, objective execution and leisure was facilitated and studied by virtual reality (VR) tools.","The mission commander and first officer, both experienced with virtual reality, took part in daily briefings with mission control.","In the first week the briefings were voice-only conducted via a channel on Discord.","During the following week last briefings were conducted in VR, using Horizon Workrooms.","This qualitative pilot study employing participatory observation revealed that VR facilitates communication, especially on complex problems and experiences, providing the sense of emotional connection and shared understanding, that may be lacking in audio calls.","The study points to the need to further explore VR-facilitated communication in high-stake environments as it may improve relationships, well-being, and communication outcomes."],"url":"http://arxiv.org/abs/2307.08589v1"}
{"created":"2023-07-17 15:58:10","title":"Toward Scalable and Controllable AR Experimentation","abstract":"To understand how well a proposed augmented reality (AR) solution works, existing papers often conducted tailored and isolated evaluations for specific AR tasks, e.g., depth or lighting estimation, and compared them to easy-to-setup baselines, either using datasets or resorting to time-consuming data capturing. Conceptually simple, it can be extremely difficult to evaluate an AR system fairly and in scale to understand its real-world performance. The difficulties arise for three key reasons: lack of control of the physical environment, the time-consuming data capturing, and the difficulties to reproduce baseline results.   This paper presents our design of an AR experimentation platform, ExpAR, aiming to provide scalable and controllable AR experimentation. ExpAR is envisioned to operate as a standalone deployment or a federated platform; in the latter case, AR researchers can contribute physical resources, including scene setup and capturing devices, and allow others to time share these resources. Our design centers around the generic sensing-understanding-rendering pipeline and is driven by the evaluation limitations observed in recent AR systems papers. We demonstrate the feasibility of this vision with a preliminary prototype and our preliminary evaluations suggest the importance of further investigating different device capabilities to stream in 30 FPS.   The ExpAR project site can be found at https://cake.wpi.edu/expar.","sentences":["To understand how well a proposed augmented reality (AR) solution works, existing papers often conducted tailored and isolated evaluations for specific AR tasks, e.g., depth or lighting estimation, and compared them to easy-to-setup baselines, either using datasets or resorting to time-consuming data capturing.","Conceptually simple, it can be extremely difficult to evaluate an AR system fairly and in scale to understand its real-world performance.","The difficulties arise for three key reasons: lack of control of the physical environment, the time-consuming data capturing, and the difficulties to reproduce baseline results.   ","This paper presents our design of an AR experimentation platform, ExpAR, aiming to provide scalable and controllable AR experimentation.","ExpAR is envisioned to operate as a standalone deployment or a federated platform; in the latter case, AR researchers can contribute physical resources, including scene setup and capturing devices, and allow others to time share these resources.","Our design centers around the generic sensing-understanding-rendering pipeline and is driven by the evaluation limitations observed in recent AR systems papers.","We demonstrate the feasibility of this vision with a preliminary prototype and our preliminary evaluations suggest the importance of further investigating different device capabilities to stream in 30 FPS.   ","The ExpAR project site can be found at https://cake.wpi.edu/expar."],"url":"http://arxiv.org/abs/2307.08587v1"}
{"created":"2023-07-17 15:58:05","title":"Syntax-Aware Complex-Valued Neural Machine Translation","abstract":"Syntax has been proven to be remarkably effective in neural machine translation (NMT). Previous models obtained syntax information from syntactic parsing tools and integrated it into NMT models to improve translation performance. In this work, we propose a method to incorporate syntax information into a complex-valued Encoder-Decoder architecture. The proposed model jointly learns word-level and syntax-level attention scores from the source side to the target side using an attention mechanism. Importantly, it is not dependent on specific network architectures and can be directly integrated into any existing sequence-to-sequence (Seq2Seq) framework. The experimental results demonstrate that the proposed method can bring significant improvements in BLEU scores on two datasets. In particular, the proposed method achieves a greater improvement in BLEU scores in translation tasks involving language pairs with significant syntactic differences.","sentences":["Syntax has been proven to be remarkably effective in neural machine translation (NMT).","Previous models obtained syntax information from syntactic parsing tools and integrated it into NMT models to improve translation performance.","In this work, we propose a method to incorporate syntax information into a complex-valued Encoder-Decoder architecture.","The proposed model jointly learns word-level and syntax-level attention scores from the source side to the target side using an attention mechanism.","Importantly, it is not dependent on specific network architectures and can be directly integrated into any existing sequence-to-sequence (Seq2Seq) framework.","The experimental results demonstrate that the proposed method can bring significant improvements in BLEU scores on two datasets.","In particular, the proposed method achieves a greater improvement in BLEU scores in translation tasks involving language pairs with significant syntactic differences."],"url":"http://arxiv.org/abs/2307.08586v1"}
{"created":"2023-07-17 15:57:52","title":"Identity-Preserving Aging of Face Images via Latent Diffusion Models","abstract":"The performance of automated face recognition systems is inevitably impacted by the facial aging process. However, high quality datasets of individuals collected over several years are typically small in scale. In this work, we propose, train, and validate the use of latent text-to-image diffusion models for synthetically aging and de-aging face images. Our models succeed with few-shot training, and have the added benefit of being controllable via intuitive textual prompting. We observe high degrees of visual realism in the generated images while maintaining biometric fidelity measured by commonly used metrics. We evaluate our method on two benchmark datasets (CelebA and AgeDB) and observe significant reduction (~44%) in the False Non-Match Rate compared to existing state-of the-art baselines.","sentences":["The performance of automated face recognition systems is inevitably impacted by the facial aging process.","However, high quality datasets of individuals collected over several years are typically small in scale.","In this work, we propose, train, and validate the use of latent text-to-image diffusion models for synthetically aging and de-aging face images.","Our models succeed with few-shot training, and have the added benefit of being controllable via intuitive textual prompting.","We observe high degrees of visual realism in the generated images while maintaining biometric fidelity measured by commonly used metrics.","We evaluate our method on two benchmark datasets (CelebA and AgeDB) and observe significant reduction (~44%) in the False Non-Match Rate compared to existing state-of the-art baselines."],"url":"http://arxiv.org/abs/2307.08585v1"}
{"created":"2023-07-17 15:51:47","title":"BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs","abstract":"LLMs have demonstrated remarkable abilities at interacting with humans through language, especially with the usage of instruction-following data. Recent advancements in LLMs, such as MiniGPT-4, LLaVA, and X-LLM, further enlarge their abilities by incorporating multi-modal inputs, including image, video, and speech. Despite their effectiveness at generating precise and detailed language understanding of the given modality signal, these LLMs give up the ability to ground specific parts of inputs, thus only constructing a coarse-grained mapping. However, explicit and informative correspondence between text and other modalities will not only improve the user experience but also help to expand the application scenario of multi-modal LLMs. Therefore, we propose BuboGPT, a multi-modal LLM with visual grounding that can perform cross-modal interaction between vision, audio and language, providing fine-grained understanding of visual objects and other given modalities. As a result, BuboGPT is able to point out the specific location of an object in the image, when it is generating response or description for that object. Our contributions are two-fold: 1) An off-the-shelf visual grounding module based on SAM that extracts entities in a sentence and find corresponding masks in the image. 2) A two-stage training scheme and instruction dataset to endow joint text-image-audio understanding. Our experiments show that BuboGPT achieves impressive multi-modality understanding and visual grounding abilities during the interaction with human. It performs consistently well when provided by arbitrary modality combinations (either aligned or unaligned). Our code, model and dataset are available at https://bubo-gpt.github.io .","sentences":["LLMs have demonstrated remarkable abilities at interacting with humans through language, especially with the usage of instruction-following data.","Recent advancements in LLMs, such as MiniGPT-4, LLaVA, and X-LLM, further enlarge their abilities by incorporating multi-modal inputs, including image, video, and speech.","Despite their effectiveness at generating precise and detailed language understanding of the given modality signal, these LLMs give up the ability to ground specific parts of inputs, thus only constructing a coarse-grained mapping.","However, explicit and informative correspondence between text and other modalities will not only improve the user experience but also help to expand the application scenario of multi-modal LLMs.","Therefore, we propose BuboGPT, a multi-modal LLM with visual grounding that can perform cross-modal interaction between vision, audio and language, providing fine-grained understanding of visual objects and other given modalities.","As a result, BuboGPT is able to point out the specific location of an object in the image, when it is generating response or description for that object.","Our contributions are two-fold: 1) An off-the-shelf visual grounding module based on SAM that extracts entities in a sentence and find corresponding masks in the image.","2) A two-stage training scheme and instruction dataset to endow joint text-image-audio understanding.","Our experiments show that BuboGPT achieves impressive multi-modality understanding and visual grounding abilities during the interaction with human.","It performs consistently well when provided by arbitrary modality combinations (either aligned or unaligned).","Our code, model and dataset are available at https://bubo-gpt.github.io ."],"url":"http://arxiv.org/abs/2307.08581v1"}
{"created":"2023-07-17 15:47:48","title":"Scale-Aware Modulation Meet Transformer","abstract":"This paper presents a new vision Transformer, Scale-Aware Modulation Transformer (SMT), that can handle various downstream tasks efficiently by combining the convolutional network and vision Transformer. The proposed Scale-Aware Modulation (SAM) in the SMT includes two primary novel designs. Firstly, we introduce the Multi-Head Mixed Convolution (MHMC) module, which can capture multi-scale features and expand the receptive field. Secondly, we propose the Scale-Aware Aggregation (SAA) module, which is lightweight but effective, enabling information fusion across different heads. By leveraging these two modules, convolutional modulation is further enhanced. Furthermore, in contrast to prior works that utilized modulations throughout all stages to build an attention-free network, we propose an Evolutionary Hybrid Network (EHN), which can effectively simulate the shift from capturing local to global dependencies as the network becomes deeper, resulting in superior performance. Extensive experiments demonstrate that SMT significantly outperforms existing state-of-the-art models across a wide range of visual tasks. Specifically, SMT with 11.5M / 2.4GFLOPs and 32M / 7.7GFLOPs can achieve 82.2% and 84.3% top-1 accuracy on ImageNet-1K, respectively. After pretrained on ImageNet-22K in 224^2 resolution, it attains 87.1% and 88.1% top-1 accuracy when finetuned with resolution 224^2 and 384^2, respectively. For object detection with Mask R-CNN, the SMT base trained with 1x and 3x schedule outperforms the Swin Transformer counterpart by 4.2 and 1.3 mAP on COCO, respectively. For semantic segmentation with UPerNet, the SMT base test at single- and multi-scale surpasses Swin by 2.0 and 1.1 mIoU respectively on the ADE20K.","sentences":["This paper presents a new vision Transformer, Scale-Aware Modulation Transformer (SMT), that can handle various downstream tasks efficiently by combining the convolutional network and vision Transformer.","The proposed Scale-Aware Modulation (SAM) in the SMT includes two primary novel designs.","Firstly, we introduce the Multi-Head Mixed Convolution (MHMC) module, which can capture multi-scale features and expand the receptive field.","Secondly, we propose the Scale-Aware Aggregation (SAA) module, which is lightweight but effective, enabling information fusion across different heads.","By leveraging these two modules, convolutional modulation is further enhanced.","Furthermore, in contrast to prior works that utilized modulations throughout all stages to build an attention-free network, we propose an Evolutionary Hybrid Network (EHN), which can effectively simulate the shift from capturing local to global dependencies as the network becomes deeper, resulting in superior performance.","Extensive experiments demonstrate that SMT significantly outperforms existing state-of-the-art models across a wide range of visual tasks.","Specifically, SMT with 11.5M / 2.4GFLOPs and 32M / 7.7GFLOPs can achieve 82.2% and 84.3% top-1 accuracy on ImageNet-1K, respectively.","After pretrained on ImageNet-22K in 224^2 resolution, it attains 87.1% and 88.1% top-1 accuracy when finetuned with resolution 224^2 and 384^2, respectively.","For object detection with Mask R-CNN, the SMT base trained with 1x and 3x schedule outperforms the Swin Transformer counterpart by 4.2 and 1.3 mAP on COCO, respectively.","For semantic segmentation with UPerNet, the SMT base test at single- and multi-scale surpasses Swin by 2.0 and 1.1 mIoU respectively on the ADE20K."],"url":"http://arxiv.org/abs/2307.08579v1"}
{"created":"2023-07-17 15:44:12","title":"MIRA: a Digital Signature Scheme based on the MinRank problem and the MPC-in-the-Head paradigm","abstract":"We exploit the idea of [Fen22] which proposes to build an efficient signature scheme based on a zero-knowledge proof of knowledge of a solution of a MinRank instance. The scheme uses the MPCitH paradigm, which is an efficient way to build ZK proofs. We combine this idea with another idea, the hypercube technique introduced in [AMGH+22], which leads to more efficient MPCitH-based scheme. This new approach is more efficient than classical MPCitH, as it allows to reduce the number of party computation. This gives us a first scheme called MIRA-Additive. We then present an other scheme, based on low-threshold secret sharings, called MIRA-Threshold, which is a faster scheme, at the price of larger signatures. The construction of MPCitH using threshold secret sharing is detailed in [FR22]. These two constructions allows us to be faster than classical MPCitH, with a size of signature around 5.6kB with MIRA-Additive, and 8.3kB with MIRA-Threshold. We detail here the constructions and optimizations of the schemes, as well as their security proofs.","sentences":["We exploit the idea of [Fen22] which proposes to build an efficient signature scheme based on a zero-knowledge proof of knowledge of a solution of a MinRank instance.","The scheme uses the MPCitH paradigm, which is an efficient way to build ZK proofs.","We combine this idea with another idea, the hypercube technique introduced in [AMGH+22], which leads to more efficient MPCitH-based scheme.","This new approach is more efficient than classical MPCitH, as it allows to reduce the number of party computation.","This gives us a first scheme called MIRA-Additive.","We then present an other scheme, based on low-threshold secret sharings, called MIRA-Threshold, which is a faster scheme, at the price of larger signatures.","The construction of MPCitH using threshold secret sharing is detailed in [FR22].","These two constructions allows us to be faster than classical MPCitH, with a size of signature around 5.6kB with MIRA-Additive, and 8.3kB with MIRA-Threshold.","We detail here the constructions and optimizations of the schemes, as well as their security proofs."],"url":"http://arxiv.org/abs/2307.08575v1"}
{"created":"2023-07-17 15:40:45","title":"FedCME: Client Matching and Classifier Exchanging to Handle Data Heterogeneity in Federated Learning","abstract":"Data heterogeneity across clients is one of the key challenges in Federated Learning (FL), which may slow down the global model convergence and even weaken global model performance. Most existing approaches tackle the heterogeneity by constraining local model updates through reference to global information provided by the server. This can alleviate the performance degradation on the aggregated global model. Different from existing methods, we focus the information exchange between clients, which could also enhance the effectiveness of local training and lead to generate a high-performance global model. Concretely, we propose a novel FL framework named FedCME by client matching and classifier exchanging. In FedCME, clients with large differences in data distribution will be matched in pairs, and then the corresponding pair of clients will exchange their classifiers at the stage of local training in an intermediate moment. Since the local data determines the local model training direction, our method can correct update direction of classifiers and effectively alleviate local update divergence. Besides, we propose feature alignment to enhance the training of the feature extractor. Experimental results demonstrate that FedCME performs better than FedAvg, FedProx, MOON and FedRS on popular federated learning benchmarks including FMNIST and CIFAR10, in the case where data are heterogeneous.","sentences":["Data heterogeneity across clients is one of the key challenges in Federated Learning (FL), which may slow down the global model convergence and even weaken global model performance.","Most existing approaches tackle the heterogeneity by constraining local model updates through reference to global information provided by the server.","This can alleviate the performance degradation on the aggregated global model.","Different from existing methods, we focus the information exchange between clients, which could also enhance the effectiveness of local training and lead to generate a high-performance global model.","Concretely, we propose a novel FL framework named FedCME by client matching and classifier exchanging.","In FedCME, clients with large differences in data distribution will be matched in pairs, and then the corresponding pair of clients will exchange their classifiers at the stage of local training in an intermediate moment.","Since the local data determines the local model training direction, our method can correct update direction of classifiers and effectively alleviate local update divergence.","Besides, we propose feature alignment to enhance the training of the feature extractor.","Experimental results demonstrate that FedCME performs better than FedAvg, FedProx, MOON and FedRS on popular federated learning benchmarks including FMNIST and CIFAR10, in the case where data are heterogeneous."],"url":"http://arxiv.org/abs/2307.08574v1"}
{"created":"2023-07-17 15:38:11","title":"Revisiting the Robustness of the Minimum Error Entropy Criterion: A Transfer Learning Case Study","abstract":"Coping with distributional shifts is an important part of transfer learning methods in order to perform well in real-life tasks. However, most of the existing approaches in this area either focus on an ideal scenario in which the data does not contain noises or employ a complicated training paradigm or model design to deal with distributional shifts. In this paper, we revisit the robustness of the minimum error entropy (MEE) criterion, a widely used objective in statistical signal processing to deal with non-Gaussian noises, and investigate its feasibility and usefulness in real-life transfer learning regression tasks, where distributional shifts are common. Specifically, we put forward a new theoretical result showing the robustness of MEE against covariate shift. We also show that by simply replacing the mean squared error (MSE) loss with the MEE on basic transfer learning algorithms such as fine-tuning and linear probing, we can achieve competitive performance with respect to state-of-the-art transfer learning algorithms. We justify our arguments on both synthetic data and 5 real-world time-series data.","sentences":["Coping with distributional shifts is an important part of transfer learning methods in order to perform well in real-life tasks.","However, most of the existing approaches in this area either focus on an ideal scenario in which the data does not contain noises or employ a complicated training paradigm or model design to deal with distributional shifts.","In this paper, we revisit the robustness of the minimum error entropy (MEE) criterion, a widely used objective in statistical signal processing to deal with non-Gaussian noises, and investigate its feasibility and usefulness in real-life transfer learning regression tasks, where distributional shifts are common.","Specifically, we put forward a new theoretical result showing the robustness of MEE against covariate shift.","We also show that by simply replacing the mean squared error (MSE) loss with the MEE on basic transfer learning algorithms such as fine-tuning and linear probing, we can achieve competitive performance with respect to state-of-the-art transfer learning algorithms.","We justify our arguments on both synthetic data and 5 real-world time-series data."],"url":"http://arxiv.org/abs/2307.08572v1"}
{"created":"2023-07-17 15:36:51","title":"SkiVis: Visual Exploration and Route Planning in Ski Resorts","abstract":"Optimal ski route selection is a challenge based on a multitude of factors, such as the steepness, compass direction, or crowdedness. The personal preferences of every skier towards these factors require individual adaptations, which aggravate this task. Current approaches within this domain do not combine automated routing capabilities with user preferences, missing out on the possibility of integrating domain knowledge in the analysis process. We introduce SkiVis, a visual analytics application to interactively explore ski slopes and provide routing recommendations based on user preferences. In collaboration with ski guides and enthusiasts, we elicited requirements and guidelines for such an application and propose different workflows depending on the skiers' familiarity with the resort. In a case study on the resort of Ski Arlberg, we illustrate how to leverage volunteered geographic information to enable a numerical comparison between slopes. We evaluated our approach through a pair-analytics study and demonstrate how it supports skiers in discovering relevant and preference-based ski routes. Besides the tasks investigated in the study, we derive additional use cases from the interviews that showcase the further potential of SkiVis, and contribute directions for further research opportunities.","sentences":["Optimal ski route selection is a challenge based on a multitude of factors, such as the steepness, compass direction, or crowdedness.","The personal preferences of every skier towards these factors require individual adaptations, which aggravate this task.","Current approaches within this domain do not combine automated routing capabilities with user preferences, missing out on the possibility of integrating domain knowledge in the analysis process.","We introduce SkiVis, a visual analytics application to interactively explore ski slopes and provide routing recommendations based on user preferences.","In collaboration with ski guides and enthusiasts, we elicited requirements and guidelines for such an application and propose different workflows depending on the skiers' familiarity with the resort.","In a case study on the resort of Ski Arlberg, we illustrate how to leverage volunteered geographic information to enable a numerical comparison between slopes.","We evaluated our approach through a pair-analytics study and demonstrate how it supports skiers in discovering relevant and preference-based ski routes.","Besides the tasks investigated in the study, we derive additional use cases from the interviews that showcase the further potential of SkiVis, and contribute directions for further research opportunities."],"url":"http://arxiv.org/abs/2307.08570v1"}
{"created":"2023-07-17 15:36:05","title":"Congestion and Scalability in Robot Swarms: a Study on Collective Decision Making","abstract":"One of the most important promises of decentralized systems is scalability, which is often assumed to be present in robot swarm systems without being contested. Simple limitations, such as movement congestion and communication conflicts, can drastically affect scalability. In this work, we study the effects of congestion in a binary collective decision-making task. We evaluate the impact of two types of congestion (communication and movement) when using three different techniques for the task: Honey Bee inspired, Stigmergy based, and Division of Labor. We deploy up to 150 robots in a physics-based simulator performing a sampling mission in an arena with variable levels of robot density, applying the three techniques. Our results suggest that applying Division of Labor coupled with versioned local communication helps to scale the system by minimizing congestion.","sentences":["One of the most important promises of decentralized systems is scalability, which is often assumed to be present in robot swarm systems without being contested.","Simple limitations, such as movement congestion and communication conflicts, can drastically affect scalability.","In this work, we study the effects of congestion in a binary collective decision-making task.","We evaluate the impact of two types of congestion (communication and movement) when using three different techniques for the task: Honey Bee inspired, Stigmergy based, and Division of Labor.","We deploy up to 150 robots in a physics-based simulator performing a sampling mission in an arena with variable levels of robot density, applying the three techniques.","Our results suggest that applying Division of Labor coupled with versioned local communication helps to scale the system by minimizing congestion."],"url":"http://arxiv.org/abs/2307.08568v1"}
{"created":"2023-07-17 15:31:58","title":"On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization","abstract":"Achieving high accuracy on data from domains unseen during training is a fundamental challenge in domain generalization (DG). While state-of-the-art DG classifiers have demonstrated impressive performance across various tasks, they have shown a bias towards domain-dependent information, such as image styles, rather than domain-invariant information, such as image content. This bias renders them unreliable for deployment in risk-sensitive scenarios such as autonomous driving where a misclassification could lead to catastrophic consequences. To enable risk-averse predictions from a DG classifier, we propose a novel inference procedure, Test-Time Neural Style Smoothing (TT-NSS), that uses a \"style-smoothed\" version of the DG classifier for prediction at test time. Specifically, the style-smoothed classifier classifies a test image as the most probable class predicted by the DG classifier on random re-stylizations of the test image. TT-NSS uses a neural style transfer module to stylize a test image on the fly, requires only black-box access to the DG classifier, and crucially, abstains when predictions of the DG classifier on the stylized test images lack consensus. Additionally, we propose a neural style smoothing (NSS) based training procedure that can be seamlessly integrated with existing DG methods. This procedure enhances prediction consistency, improving the performance of TT-NSS on non-abstained samples. Our empirical results demonstrate the effectiveness of TT-NSS and NSS at producing and improving risk-averse predictions on unseen domains from DG classifiers trained with SOTA training methods on various benchmark datasets and their variations.","sentences":["Achieving high accuracy on data from domains unseen during training is a fundamental challenge in domain generalization (DG).","While state-of-the-art DG classifiers have demonstrated impressive performance across various tasks, they have shown a bias towards domain-dependent information, such as image styles, rather than domain-invariant information, such as image content.","This bias renders them unreliable for deployment in risk-sensitive scenarios such as autonomous driving where a misclassification could lead to catastrophic consequences.","To enable risk-averse predictions from a DG classifier, we propose a novel inference procedure, Test-Time Neural Style Smoothing (TT-NSS), that uses a \"style-smoothed\" version of the DG classifier for prediction at test time.","Specifically, the style-smoothed classifier classifies a test image as the most probable class predicted by the DG classifier on random re-stylizations of the test image.","TT-NSS uses a neural style transfer module to stylize a test image on the fly, requires only black-box access to the DG classifier, and crucially, abstains when predictions of the DG classifier on the stylized test images lack consensus.","Additionally, we propose a neural style smoothing (NSS) based training procedure that can be seamlessly integrated with existing DG methods.","This procedure enhances prediction consistency, improving the performance of TT-NSS on non-abstained samples.","Our empirical results demonstrate the effectiveness of TT-NSS and NSS at producing and improving risk-averse predictions on unseen domains from DG classifiers trained with SOTA training methods on various benchmark datasets and their variations."],"url":"http://arxiv.org/abs/2307.08551v1"}
{"created":"2023-07-17 15:17:39","title":"Improving Data Efficiency for Plant Cover Prediction with Label Interpolation and Monte-Carlo Cropping","abstract":"The plant community composition is an essential indicator of environmental changes and is, for this reason, usually analyzed in ecological field studies in terms of the so-called plant cover. The manual acquisition of this kind of data is time-consuming, laborious, and prone to human error. Automated camera systems can collect high-resolution images of the surveyed vegetation plots at a high frequency. In combination with subsequent algorithmic analysis, it is possible to objectively extract information on plant community composition quickly and with little human effort. An automated camera system can easily collect the large amounts of image data necessary to train a Deep Learning system for automatic analysis. However, due to the amount of work required to annotate vegetation images with plant cover data, only few labeled samples are available. As automated camera systems can collect many pictures without labels, we introduce an approach to interpolate the sparse labels in the collected vegetation plot time series down to the intermediate dense and unlabeled images to artificially increase our training dataset to seven times its original size. Moreover, we introduce a new method we call Monte-Carlo Cropping. This approach trains on a collection of cropped parts of the training images to deal with high-resolution images efficiently, implicitly augment the training images, and speed up training. We evaluate both approaches on a plant cover dataset containing images of herbaceous plant communities and find that our methods lead to improvements in the species, community, and segmentation metrics investigated.","sentences":["The plant community composition is an essential indicator of environmental changes and is, for this reason, usually analyzed in ecological field studies in terms of the so-called plant cover.","The manual acquisition of this kind of data is time-consuming, laborious, and prone to human error.","Automated camera systems can collect high-resolution images of the surveyed vegetation plots at a high frequency.","In combination with subsequent algorithmic analysis, it is possible to objectively extract information on plant community composition quickly and with little human effort.","An automated camera system can easily collect the large amounts of image data necessary to train a Deep Learning system for automatic analysis.","However, due to the amount of work required to annotate vegetation images with plant cover data, only few labeled samples are available.","As automated camera systems can collect many pictures without labels, we introduce an approach to interpolate the sparse labels in the collected vegetation plot time series down to the intermediate dense and unlabeled images to artificially increase our training dataset to seven times its original size.","Moreover, we introduce a new method we call Monte-Carlo Cropping.","This approach trains on a collection of cropped parts of the training images to deal with high-resolution images efficiently, implicitly augment the training images, and speed up training.","We evaluate both approaches on a plant cover dataset containing images of herbaceous plant communities and find that our methods lead to improvements in the species, community, and segmentation metrics investigated."],"url":"http://arxiv.org/abs/2307.08559v1"}
{"created":"2023-07-17 15:15:25","title":"Hypergraph Splitting-off and Covering Skew-Supermodular Functions in Strongly Polynomial Time","abstract":"We consider hypergraph network design problems where the goal is to construct a hypergraph satisfying certain properties. In graph network design problems, the number of edges in an arbitrary solution is at most the square of the number of vertices. In contrast, in hypergraph network design problems, the number of hyperedges in an arbitrary solution could be exponential in the number of vertices and hence, additional care is necessary to design polynomial-time algorithms. The central theme of this work is to show that certain hypergraph network design problems admit solutions with polynomial number of hyperedges and moreover, can be solved in strongly polynomial time. Our work improves on the previous fastest pseudo-polynomial run-time for these problems. In addition, we develop algorithms that return (near-)uniform hypergraphs as solutions. The hypergraph network design problems that we focus upon are splitting-off operation in hypergraphs, connectivity augmentation using hyperedges, and covering skew-supermodular functions using hyperedges. Our definition of the splitting-off operation in hypergraphs and our proof showing the existence of the operation using a strongly polynomial-time algorithm to compute it are likely to be of independent graph-theoretical interest.","sentences":["We consider hypergraph network design problems where the goal is to construct a hypergraph satisfying certain properties.","In graph network design problems, the number of edges in an arbitrary solution is at most the square of the number of vertices.","In contrast, in hypergraph network design problems, the number of hyperedges in an arbitrary solution could be exponential in the number of vertices and hence, additional care is necessary to design polynomial-time algorithms.","The central theme of this work is to show that certain hypergraph network design problems admit solutions with polynomial number of hyperedges and moreover, can be solved in strongly polynomial time.","Our work improves on the previous fastest pseudo-polynomial run-time for these problems.","In addition, we develop algorithms that return (near-)uniform hypergraphs as solutions.","The hypergraph network design problems that we focus upon are splitting-off operation in hypergraphs, connectivity augmentation using hyperedges, and covering skew-supermodular functions using hyperedges.","Our definition of the splitting-off operation in hypergraphs and our proof showing the existence of the operation using a strongly polynomial-time algorithm to compute it are likely to be of independent graph-theoretical interest."],"url":"http://arxiv.org/abs/2307.08555v1"}
{"created":"2023-07-17 15:11:31","title":"TorMult: Introducing a Novel Tor Bandwidth Inflation Attack","abstract":"The Tor network is the most prominent system for providing anonymous communication to web users, with a daily user base of 2 million users. However, since its inception, it has been constantly targeted by various traffic fingerprinting and correlation attacks aiming at deanonymizing its users. A critical requirement for these attacks is to attract as much user traffic to adversarial relays as possible, which is typically accomplished by means of bandwidth inflation attacks. This paper proposes a new inflation attack vector in Tor, referred to as TorMult, which enables inflation of measured bandwidth. The underlying attack technique exploits resource sharing among Tor relay nodes and employs a cluster of attacker-controlled relays with coordinated resource allocation within the cluster to deceive bandwidth measurers into believing that each relay node in the cluster possesses ample resources. We propose two attack variants, C-TorMult and D-TorMult, and test both versions in a private Tor test network. Our evaluation demonstrates that an attacker can inflate the measured bandwidth by a factor close to n using C-TorMult and nearly half n*N using D-TorMult, where n is the size of the cluster hosted on one server and N is the number of servers. Furthermore, our theoretical analysis reveals that gaining control over half of the Tor network's traffic can be achieved by employing just 10 dedicated servers with a cluster size of 109 relays running the TorMult attack, each with a bandwidth of 100MB/s. The problem is further exacerbated by the fact that Tor not only allows resource sharing but, according to recent reports, even promotes it.","sentences":["The Tor network is the most prominent system for providing anonymous communication to web users, with a daily user base of 2 million users.","However, since its inception, it has been constantly targeted by various traffic fingerprinting and correlation attacks aiming at deanonymizing its users.","A critical requirement for these attacks is to attract as much user traffic to adversarial relays as possible, which is typically accomplished by means of bandwidth inflation attacks.","This paper proposes a new inflation attack vector in Tor, referred to as TorMult, which enables inflation of measured bandwidth.","The underlying attack technique exploits resource sharing among Tor relay nodes and employs a cluster of attacker-controlled relays with coordinated resource allocation within the cluster to deceive bandwidth measurers into believing that each relay node in the cluster possesses ample resources.","We propose two attack variants, C-TorMult and D-TorMult, and test both versions in a private Tor test network.","Our evaluation demonstrates that an attacker can inflate the measured bandwidth by a factor close to n using C-TorMult and nearly half n*N using D-TorMult, where n is the size of the cluster hosted on one server and N is the number of servers.","Furthermore, our theoretical analysis reveals that gaining control over half of the Tor network's traffic can be achieved by employing just 10 dedicated servers with a cluster size of 109 relays running the TorMult attack, each with a bandwidth of 100MB/s. The problem is further exacerbated by the fact that Tor not only allows resource sharing but, according to recent reports, even promotes it."],"url":"http://arxiv.org/abs/2307.08550v1"}
{"created":"2023-07-17 15:11:03","title":"G-Scan: Graph Neural Networks for Line-Level Vulnerability Identification in Smart Contracts","abstract":"Due to the immutable and decentralized nature of Ethereum (ETH) platform, smart contracts are prone to security risks that can result in financial loss. While existing machine learning-based vulnerability detection algorithms achieve high accuracy at the contract level, they require developers to manually inspect source code to locate bugs. To this end, we present G-Scan, the first end-to-end fine-grained line-level vulnerability detection system evaluated on the first-of-its-kind real world dataset. G-Scan first converts smart contracts to code graphs in a dependency and hierarchy preserving manner. Next, we train a graph neural network to identify vulnerable nodes and assess security risks. Finally, the code graphs with node vulnerability predictions are mapped back to the smart contracts for line-level localization. We train and evaluate G-Scan on a collected real world smart contracts dataset with line-level annotations on reentrancy vulnerability, one of the most common and severe types of smart contract vulnerabilities. With the well-designed graph representation and high-quality dataset, G-Scan achieves 93.02% F1-score in contract-level vulnerability detection and 93.69% F1-score in line-level vulnerability localization. Additionally, the lightweight graph neural network enables G-Scan to localize vulnerabilities in 6.1k lines of code smart contract within 1.2 seconds.","sentences":["Due to the immutable and decentralized nature of Ethereum (ETH) platform, smart contracts are prone to security risks that can result in financial loss.","While existing machine learning-based vulnerability detection algorithms achieve high accuracy at the contract level, they require developers to manually inspect source code to locate bugs.","To this end, we present G-Scan, the first end-to-end fine-grained line-level vulnerability detection system evaluated on the first-of-its-kind real world dataset.","G-Scan first converts smart contracts to code graphs in a dependency and hierarchy preserving manner.","Next, we train a graph neural network to identify vulnerable nodes and assess security risks.","Finally, the code graphs with node vulnerability predictions are mapped back to the smart contracts for line-level localization.","We train and evaluate G-Scan on a collected real world smart contracts dataset with line-level annotations on reentrancy vulnerability, one of the most common and severe types of smart contract vulnerabilities.","With the well-designed graph representation and high-quality dataset, G-Scan achieves 93.02% F1-score in contract-level vulnerability detection and 93.69% F1-score in line-level vulnerability localization.","Additionally, the lightweight graph neural network enables G-Scan to localize vulnerabilities in 6.1k lines of code smart contract within 1.2 seconds."],"url":"http://arxiv.org/abs/2307.08549v1"}
{"created":"2023-07-17 15:10:41","title":"Joint Beam Routing and Resource Allocation Optimization for Multi-IRS-Reflection Wireless Power Transfer","abstract":"Intelligent reflecting surface (IRS) can be densely deployed in complex environments to create cascaded line-of-sight (LoS) links between base stations (BSs) and users, which significantly enhance the signal coverage. In this paper, we consider the wireless power transfer (WPT) from a multi-antenna BS to multiple energy users (EUs) by exploiting the signal beam routing via multi-IRS reflections. First, we present a baseline beam routing scheme with each IRS serving at most one EU, where the BS transmits wireless power to all EUs simultaneously while the signals to different EUs undergo disjoint sets of multi-IRS reflection paths. Under this setup, we aim to tackle the joint beam routing and resource allocation optimization problem by jointly optimizing the reflection paths for all EUs, the active/passive beamforming at the BS/each involved IRS, as well as the BS's power allocation for different EUs to maximize the minimum received signal power among all EUs. Next, to further improve the WPT performance, we propose two new beam routing schemes, namely dynamic beam routing and subsurface-based beam routing, where each IRS can serve multiple EUs via different time slots and different subsurfaces, respectively. In particular, we prove that dynamic beam routing outperforms subsurface-based beam routing in terms of minimum harvested power among all EUs. In addition, we show that the optimal performance of dynamic beam routing is achieved by assigning all EUs with orthogonal time slots for WPT. A clique-based optimization approach is also proposed to solve the joint beam routing and resource allocation problems for the baseline beam routing and proposed dynamic beam routing schemes. Numerical results are finally presented, which demonstrate the superior performance of the proposed dynamic beam routing scheme to the baseline scheme.","sentences":["Intelligent reflecting surface (IRS) can be densely deployed in complex environments to create cascaded line-of-sight (LoS) links between base stations (BSs) and users, which significantly enhance the signal coverage.","In this paper, we consider the wireless power transfer (WPT) from a multi-antenna BS to multiple energy users (EUs) by exploiting the signal beam routing via multi-IRS reflections.","First, we present a baseline beam routing scheme with each IRS serving at most one EU, where the BS transmits wireless power to all EUs simultaneously while the signals to different EUs undergo disjoint sets of multi-IRS reflection paths.","Under this setup, we aim to tackle the joint beam routing and resource allocation optimization problem by jointly optimizing the reflection paths for all EUs, the active/passive beamforming at the BS/each involved IRS, as well as the BS's power allocation for different EUs to maximize the minimum received signal power among all EUs.","Next, to further improve the WPT performance, we propose two new beam routing schemes, namely dynamic beam routing and subsurface-based beam routing, where each IRS can serve multiple EUs via different time slots and different subsurfaces, respectively.","In particular, we prove that dynamic beam routing outperforms subsurface-based beam routing in terms of minimum harvested power among all EUs.","In addition, we show that the optimal performance of dynamic beam routing is achieved by assigning all EUs with orthogonal time slots for WPT.","A clique-based optimization approach is also proposed to solve the joint beam routing and resource allocation problems for the baseline beam routing and proposed dynamic beam routing schemes.","Numerical results are finally presented, which demonstrate the superior performance of the proposed dynamic beam routing scheme to the baseline scheme."],"url":"http://arxiv.org/abs/2307.08548v1"}
{"created":"2023-07-17 15:10:36","title":"Metadata-based Malware Detection on Android using Machine Learning","abstract":"In the digitized world, smartphones and their apps play an important role. To name just a few examples, some apps offer possibilities for entertainment, others for online banking, and others offer support for two-factor authentication. Therefore, with smartphones also, sensitive information is shared; thus, they are a desirable target for malware. The following technical report gives an overview of how machine learning, especially neural networks, can be employed to detect malicious Android apps based on their metadata. Detection based on the metadata is necessary since not all of an app's information is readable from another app due to the security layout of Android. To do so, a comparable big dataset of metadata of apps has been collected for learning and evaluation in this work. The first section, after the introduction, presents the related work, followed by the description of the sources of the dataset and the selection of the features used for machine learning, in this case, only the app permissions. Afterward, a free available dataset is used to find an efficient and effective neural network model for learning and evaluation. Here, the fully connected network type consisting of dense layers is chosen. Then this model is trained and evaluated on the new, more extensive dataset to obtain a representative result. It turns out that this model detects malware with an accuracy of 92.93% based on an app's permissions.","sentences":["In the digitized world, smartphones and their apps play an important role.","To name just a few examples, some apps offer possibilities for entertainment, others for online banking, and others offer support for two-factor authentication.","Therefore, with smartphones also, sensitive information is shared; thus, they are a desirable target for malware.","The following technical report gives an overview of how machine learning, especially neural networks, can be employed to detect malicious Android apps based on their metadata.","Detection based on the metadata is necessary since not all of an app's information is readable from another app due to the security layout of Android.","To do so, a comparable big dataset of metadata of apps has been collected for learning and evaluation in this work.","The first section, after the introduction, presents the related work, followed by the description of the sources of the dataset and the selection of the features used for machine learning, in this case, only the app permissions.","Afterward, a free available dataset is used to find an efficient and effective neural network model for learning and evaluation.","Here, the fully connected network type consisting of dense layers is chosen.","Then this model is trained and evaluated on the new, more extensive dataset to obtain a representative result.","It turns out that this model detects malware with an accuracy of 92.93% based on an app's permissions."],"url":"http://arxiv.org/abs/2307.08547v1"}
{"created":"2023-07-17 15:03:42","title":"Secure Middlebox-Assisted QUIC","abstract":"While the evolution of the Internet was driven by the end-to-end model, it has been challenged by many flavors of middleboxes over the decades. Yet, the basic idea is still fundamental: reliability and security are usually realized end-to-end, where the strong trend towards ubiquitous traffic protection supports this notion. However, reasons to break up, or redefine the ends of, end-to-end connections have always been put forward in order to improve transport layer performance. Yet, the consolidation of the transport layer with the end-to-end security model as introduced by QUIC protects most protocol information from the network, thereby eliminating the ability to modify protocol exchanges. In this paper, we enhance QUIC to selectively expose information to intermediaries, thereby enabling endpoints to consciously insert middleboxes into an end-to-end encrypted QUIC connection while preserving its privacy, integrity, and authenticity. We evaluate our design in a distributed Performance Enhancing Proxy environment over satellite networks, finding that the performance improvements are dependent on the path and application layer properties: the higher the round-trip time and loss, and the more data is transferred over a connection, the higher the benefits of Secure Middlebox-Assisted QUIC.","sentences":["While the evolution of the Internet was driven by the end-to-end model, it has been challenged by many flavors of middleboxes over the decades.","Yet, the basic idea is still fundamental: reliability and security are usually realized end-to-end, where the strong trend towards ubiquitous traffic protection supports this notion.","However, reasons to break up, or redefine the ends of, end-to-end connections have always been put forward in order to improve transport layer performance.","Yet, the consolidation of the transport layer with the end-to-end security model as introduced by QUIC protects most protocol information from the network, thereby eliminating the ability to modify protocol exchanges.","In this paper, we enhance QUIC to selectively expose information to intermediaries, thereby enabling endpoints to consciously insert middleboxes into an end-to-end encrypted QUIC connection while preserving its privacy, integrity, and authenticity.","We evaluate our design in a distributed Performance Enhancing Proxy environment over satellite networks, finding that the performance improvements are dependent on the path and application layer properties: the higher the round-trip time and loss, and the more data is transferred over a connection, the higher the benefits of Secure Middlebox-Assisted QUIC."],"url":"http://arxiv.org/abs/2307.08543v1"}
{"created":"2023-07-17 15:00:04","title":"Discovering collective narratives shifts in online discussions","abstract":"Narrative is a foundation of human cognition and decision making. Because narratives play a crucial role in societal discourses and spread of misinformation and because of the pervasive use of social media, the narrative dynamics on social media can have profound societal impact. Yet, systematic and computational understanding of online narratives faces critical challenge of the scale and dynamics; how can we reliably and automatically extract narratives from massive amount of texts? How do narratives emerge, spread, and die? Here, we propose a systematic narrative discovery framework that fill this gap by combining change point detection, semantic role labeling (SRL), and automatic aggregation of narrative fragments into narrative networks. We evaluate our model with synthetic and empirical data two-Twitter corpora about COVID-19 and 2017 French Election. Results demonstrate that our approach can recover major narrative shifts that correspond to the major events.","sentences":["Narrative is a foundation of human cognition and decision making.","Because narratives play a crucial role in societal discourses and spread of misinformation and because of the pervasive use of social media, the narrative dynamics on social media can have profound societal impact.","Yet, systematic and computational understanding of online narratives faces critical challenge of the scale and dynamics; how can we reliably and automatically extract narratives from massive amount of texts?","How do narratives emerge, spread, and die?","Here, we propose a systematic narrative discovery framework that fill this gap by combining change point detection, semantic role labeling (SRL), and automatic aggregation of narrative fragments into narrative networks.","We evaluate our model with synthetic and empirical data two-Twitter corpora about COVID-19 and 2017 French Election.","Results demonstrate that our approach can recover major narrative shifts that correspond to the major events."],"url":"http://arxiv.org/abs/2307.08541v1"}
{"created":"2023-07-17 14:58:52","title":"Utilization of Pre-trained Language Model for Adapter-based Knowledge Transfer in Software Engineering","abstract":"Software Engineering (SE) Pre-trained Language Models (PLMs), such as CodeBERT, are pre-trained on large code corpora, and their learned knowledge has shown success in transferring into downstream tasks (e.g., code clone detection) through fine-tuning the PLMs. In Natural Language Processing (NLP), an alternative in transferring the knowledge of PLMs is explored through the use of adapter, a compact and parameter efficient module that is inserted into a PLM. Although the use of adapters has shown promising results in many NLP-based downstream tasks, their application and exploration in SE-based downstream tasks are limited.   Here, we study the knowledge transfer using adapters on multiple downstream tasks including cloze test, code clone detection, and code summarization. These adapters are trained on code corpora and are inserted into a PLM that is pre-trained on English corpora or code corpora. We called these PLMs as NL-PLM and C-PLM, respectively. We observed an improvement in results using NL-PLM over a PLM that does not have adapters, and this suggested that adapters can transfer and utilize useful knowledge from NL-PLM to SE tasks. The results are sometimes on par with or exceed the results of C-PLM; while being more efficient in terms of the number of parameters and training time. Interestingly, adapters inserted into a C-PLM generally yield better results than a traditional fine-tuned C-PLM. Our results open new directions to build more compact models for SE tasks.","sentences":["Software Engineering (SE) Pre-trained Language Models (PLMs), such as CodeBERT, are pre-trained on large code corpora, and their learned knowledge has shown success in transferring into downstream tasks (e.g., code clone detection) through fine-tuning the PLMs.","In Natural Language Processing (NLP), an alternative in transferring the knowledge of PLMs is explored through the use of adapter, a compact and parameter efficient module that is inserted into a PLM.","Although the use of adapters has shown promising results in many NLP-based downstream tasks, their application and exploration in SE-based downstream tasks are limited.   ","Here, we study the knowledge transfer using adapters on multiple downstream tasks including cloze test, code clone detection, and code summarization.","These adapters are trained on code corpora and are inserted into a PLM that is pre-trained on English corpora or code corpora.","We called these PLMs as NL-PLM and C-PLM, respectively.","We observed an improvement in results using NL-PLM over a PLM that does not have adapters, and this suggested that adapters can transfer and utilize useful knowledge from NL-PLM to SE tasks.","The results are sometimes on par with or exceed the results of C-PLM; while being more efficient in terms of the number of parameters and training time.","Interestingly, adapters inserted into a C-PLM generally yield better results than a traditional fine-tuned C-PLM.","Our results open new directions to build more compact models for SE tasks."],"url":"http://arxiv.org/abs/2307.08540v1"}
{"created":"2023-07-17 14:53:09","title":"Variational Probabilistic Fusion Network for RGB-T Semantic Segmentation","abstract":"RGB-T semantic segmentation has been widely adopted to handle hard scenes with poor lighting conditions by fusing different modality features of RGB and thermal images. Existing methods try to find an optimal fusion feature for segmentation, resulting in sensitivity to modality noise, class-imbalance, and modality bias. To overcome the problems, this paper proposes a novel Variational Probabilistic Fusion Network (VPFNet), which regards fusion features as random variables and obtains robust segmentation by averaging segmentation results under multiple samples of fusion features. The random samples generation of fusion features in VPFNet is realized by a novel Variational Feature Fusion Module (VFFM) designed based on variation attention. To further avoid class-imbalance and modality bias, we employ the weighted cross-entropy loss and introduce prior information of illumination and category to control the proposed VFFM. Experimental results on MFNet and PST900 datasets demonstrate that the proposed VPFNet can achieve state-of-the-art segmentation performance.","sentences":["RGB-T semantic segmentation has been widely adopted to handle hard scenes with poor lighting conditions by fusing different modality features of RGB and thermal images.","Existing methods try to find an optimal fusion feature for segmentation, resulting in sensitivity to modality noise, class-imbalance, and modality bias.","To overcome the problems, this paper proposes a novel Variational Probabilistic Fusion Network (VPFNet), which regards fusion features as random variables and obtains robust segmentation by averaging segmentation results under multiple samples of fusion features.","The random samples generation of fusion features in VPFNet is realized by a novel Variational Feature Fusion Module (VFFM) designed based on variation attention.","To further avoid class-imbalance and modality bias, we employ the weighted cross-entropy loss and introduce prior information of illumination and category to control the proposed VFFM.","Experimental results on MFNet and PST900 datasets demonstrate that the proposed VPFNet can achieve state-of-the-art segmentation performance."],"url":"http://arxiv.org/abs/2307.08536v1"}
{"created":"2023-07-17 14:46:59","title":"LuckyMera: a Modular AI Framework for Building Hybrid NetHack Agents","abstract":"In the last few decades we have witnessed a significant development in Artificial Intelligence (AI) thanks to the availability of a variety of testbeds, mostly based on simulated environments and video games. Among those, roguelike games offer a very good trade-off in terms of complexity of the environment and computational costs, which makes them perfectly suited to test AI agents generalization capabilities. In this work, we present LuckyMera, a flexible, modular, extensible and configurable AI framework built around NetHack, a popular terminal-based, single-player roguelike video game. This library is aimed at simplifying and speeding up the development of AI agents capable of successfully playing the game and offering a high-level interface for designing game strategies. LuckyMera comes with a set of off-the-shelf symbolic and neural modules (called \"skills\"): these modules can be either hard-coded behaviors, or neural Reinforcement Learning approaches, with the possibility of creating compositional hybrid solutions. Additionally, LuckyMera comes with a set of utility features to save its experiences in the form of trajectories for further analysis and to use them as datasets to train neural modules, with a direct interface to the NetHack Learning Environment and MiniHack. Through an empirical evaluation we validate our skills implementation and propose a strong baseline agent that can reach state-of-the-art performances in the complete NetHack game. LuckyMera is open-source and available at https://github.com/Pervasive-AI-Lab/LuckyMera.","sentences":["In the last few decades we have witnessed a significant development in Artificial Intelligence (AI) thanks to the availability of a variety of testbeds, mostly based on simulated environments and video games.","Among those, roguelike games offer a very good trade-off in terms of complexity of the environment and computational costs, which makes them perfectly suited to test AI agents generalization capabilities.","In this work, we present LuckyMera, a flexible, modular, extensible and configurable AI framework built around NetHack, a popular terminal-based, single-player roguelike video game.","This library is aimed at simplifying and speeding up the development of AI agents capable of successfully playing the game and offering a high-level interface for designing game strategies.","LuckyMera comes with a set of off-the-shelf symbolic and neural modules (called \"skills\"): these modules can be either hard-coded behaviors, or neural Reinforcement Learning approaches, with the possibility of creating compositional hybrid solutions.","Additionally, LuckyMera comes with a set of utility features to save its experiences in the form of trajectories for further analysis and to use them as datasets to train neural modules, with a direct interface to the NetHack Learning Environment and MiniHack.","Through an empirical evaluation we validate our skills implementation and propose a strong baseline agent that can reach state-of-the-art performances in the complete NetHack game.","LuckyMera is open-source and available at https://github.com/Pervasive-AI-Lab/LuckyMera."],"url":"http://arxiv.org/abs/2307.08532v1"}
{"created":"2023-07-17 14:44:05","title":"Satellite Computing: A Case Study of Cloud-Native Satellites","abstract":"The on-orbit processing of massive satellite-native data relies on powerful computing power. Satellite computing has started to gain attention, with researchers proposing various algorithms, applications, and simulation testbeds. Unfortunately, a practical platform for deploying satellite computing is currently lacking. As a result, the industry needs to make relentless efforts to achieve this goal. We suggest using cloud-native technology to enhance the computing power of LEO satellites. The first main satellite of the Tiansuan constellation, BUPT-1, is a significant example of a cloud-native satellite. Prior to delving into the details of BUPT-1, we define the essential concepts of cloud-native satellites, i.e., the cloud-native load and cloud-native platform. Afterwards, we present the design scheme of cloud-native satellites, including the architecture of BUPT-1 and the experimental subjects it can support. Two validation tests are shown to reflect the operation and capability of BUPT-1. Besides, we predict possible research fields that could shape the future of satellites in the next decade.","sentences":["The on-orbit processing of massive satellite-native data relies on powerful computing power.","Satellite computing has started to gain attention, with researchers proposing various algorithms, applications, and simulation testbeds.","Unfortunately, a practical platform for deploying satellite computing is currently lacking.","As a result, the industry needs to make relentless efforts to achieve this goal.","We suggest using cloud-native technology to enhance the computing power of LEO satellites.","The first main satellite of the Tiansuan constellation, BUPT-1, is a significant example of a cloud-native satellite.","Prior to delving into the details of BUPT-1, we define the essential concepts of cloud-native satellites, i.e., the cloud-native load and cloud-native platform.","Afterwards, we present the design scheme of cloud-native satellites, including the architecture of BUPT-1 and the experimental subjects it can support.","Two validation tests are shown to reflect the operation and capability of BUPT-1.","Besides, we predict possible research fields that could shape the future of satellites in the next decade."],"url":"http://arxiv.org/abs/2307.08530v1"}
{"created":"2023-07-17 14:40:16","title":"Multi-Domain Learning with Modulation Adapters","abstract":"Deep convolutional networks are ubiquitous in computer vision, due to their excellent performance across different tasks for various domains. Models are, however, often trained in isolation for each task, failing to exploit relatedness between tasks and domains to learn more compact models that generalise better in low-data regimes. Multi-domain learning aims to handle related tasks, such as image classification across multiple domains, simultaneously. Previous work on this problem explored the use of a pre-trained and fixed domain-agnostic base network, in combination with smaller learnable domain-specific adaptation modules. In this paper, we introduce Modulation Adapters, which update the convolutional filter weights of the model in a multiplicative manner for each task. Parameterising these adaptation weights in a factored manner allows us to scale the number of per-task parameters in a flexible manner, and to strike different parameter-accuracy trade-offs. We evaluate our approach on the Visual Decathlon challenge, composed of ten image classification tasks across different domains, and on the ImageNet-to-Sketch benchmark, which consists of six image classification tasks. Our approach yields excellent results, with accuracies that are comparable to or better than those of existing state-of-the-art approaches.","sentences":["Deep convolutional networks are ubiquitous in computer vision, due to their excellent performance across different tasks for various domains.","Models are, however, often trained in isolation for each task, failing to exploit relatedness between tasks and domains to learn more compact models that generalise better in low-data regimes.","Multi-domain learning aims to handle related tasks, such as image classification across multiple domains, simultaneously.","Previous work on this problem explored the use of a pre-trained and fixed domain-agnostic base network, in combination with smaller learnable domain-specific adaptation modules.","In this paper, we introduce Modulation Adapters, which update the convolutional filter weights of the model in a multiplicative manner for each task.","Parameterising these adaptation weights in a factored manner allows us to scale the number of per-task parameters in a flexible manner, and to strike different parameter-accuracy trade-offs.","We evaluate our approach on the Visual Decathlon challenge, composed of ten image classification tasks across different domains, and on the ImageNet-to-Sketch benchmark, which consists of six image classification tasks.","Our approach yields excellent results, with accuracies that are comparable to or better than those of existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2307.08528v1"}
{"created":"2023-07-17 14:38:11","title":"Image Captions are Natural Prompts for Text-to-Image Models","abstract":"With the rapid development of Artificial Intelligence Generated Content (AIGC), it has become common practice in many learning tasks to train or fine-tune large models on synthetic data due to the data-scarcity and privacy leakage problems. Albeit promising with unlimited data generation, owing to massive and diverse information conveyed in real images, it is challenging for text-to-image generative models to synthesize informative training data with hand-crafted prompts, which usually leads to inferior generalization performance when training downstream models. In this paper, we theoretically analyze the relationship between the training effect of synthetic data and the synthetic data distribution induced by prompts. Then we correspondingly propose a simple yet effective method that prompts text-to-image generative models to synthesize more informative and diverse training data. Specifically, we caption each real image with the advanced captioning model to obtain informative and faithful prompts that extract class-relevant information and clarify the polysemy of class names. The image captions and class names are concatenated to prompt generative models for training image synthesis. Extensive experiments on ImageNette, ImageNet-100, and ImageNet-1K verify that our method significantly improves the performance of models trained on synthetic training data, i.e., 10% classification accuracy improvements on average.","sentences":["With the rapid development of Artificial Intelligence Generated Content (AIGC), it has become common practice in many learning tasks to train or fine-tune large models on synthetic data due to the data-scarcity and privacy leakage problems.","Albeit promising with unlimited data generation, owing to massive and diverse information conveyed in real images, it is challenging for text-to-image generative models to synthesize informative training data with hand-crafted prompts, which usually leads to inferior generalization performance when training downstream models.","In this paper, we theoretically analyze the relationship between the training effect of synthetic data and the synthetic data distribution induced by prompts.","Then we correspondingly propose a simple yet effective method that prompts text-to-image generative models to synthesize more informative and diverse training data.","Specifically, we caption each real image with the advanced captioning model to obtain informative and faithful prompts that extract class-relevant information and clarify the polysemy of class names.","The image captions and class names are concatenated to prompt generative models for training image synthesis.","Extensive experiments on ImageNette, ImageNet-100, and ImageNet-1K verify that our method significantly improves the performance of models trained on synthetic training data, i.e., 10% classification accuracy improvements on average."],"url":"http://arxiv.org/abs/2307.08526v1"}
{"created":"2023-07-17 14:33:42","title":"A framework for erased syntax and bidirectional typing","abstract":"We introduce CompLF, a logical framework allowing for the definition of computational type theories -- that is, those whose definitional equality is purely generated by rewrite rules. Its main goal is to capture the usual presentation of type theories in a faithful way. Whereas other frameworks impose a fully-annotated presentation of syntax, quite different from the ones used in practice, our proposal allows the definition of dependent type theories with their usual non-annotated syntaxes. This is achieved by the introduction of erased arguments, which correspond to premises of typing rules that are not recorded in the syntax.   If on the one hand erased arguments allow us to capture the usual syntax of type theories, they can easily break decidability of type checking, as one might need to guess the erased information. We address this by proposing a bidirectional typing algorithm for CompLF. When comparing it with other algorithms in the literature, its main novelty is that it is not designed for a specific theory, but is instead generic and can be instantiated with various type theories. Moreover, it features a modular proof of completeness, in which one can fine-tune the subset of terms for which it is complete by varying the amount of annotations in the syntax. In particular, we can capture in a single framework the two main approaches for bidirectional typing, in which one reduces the amount of annotations to the minimal by restricting completeness only to normal forms, or in which one trades minimality of annotations in exchange for full completeness.   Finally, CompLF is designed to be not only a theoretical tool but also a practical one: it has been implemented in a prototype that is openly available on GitHub.","sentences":["We introduce CompLF, a logical framework allowing for the definition of computational type theories -- that is, those whose definitional equality is purely generated by rewrite rules.","Its main goal is to capture the usual presentation of type theories in a faithful way.","Whereas other frameworks impose a fully-annotated presentation of syntax, quite different from the ones used in practice, our proposal allows the definition of dependent type theories with their usual non-annotated syntaxes.","This is achieved by the introduction of erased arguments, which correspond to premises of typing rules that are not recorded in the syntax.   ","If on the one hand erased arguments allow us to capture the usual syntax of type theories, they can easily break decidability of type checking, as one might need to guess the erased information.","We address this by proposing a bidirectional typing algorithm for CompLF.","When comparing it with other algorithms in the literature, its main novelty is that it is not designed for a specific theory, but is instead generic and can be instantiated with various type theories.","Moreover, it features a modular proof of completeness, in which one can fine-tune the subset of terms for which it is complete by varying the amount of annotations in the syntax.","In particular, we can capture in a single framework the two main approaches for bidirectional typing, in which one reduces the amount of annotations to the minimal by restricting completeness only to normal forms, or in which one trades minimality of annotations in exchange for full completeness.   ","Finally, CompLF is designed to be not only a theoretical tool but also a practical one: it has been implemented in a prototype that is openly available on GitHub."],"url":"http://arxiv.org/abs/2307.08523v1"}
{"created":"2023-07-17 14:30:45","title":"$(1+\\varepsilon)$-ANN Data Structure for Curves via Subspaces of Bounded Doubling Dimension","abstract":"We consider the $(1+\\varepsilon)$-Approximate Nearest Neighbour (ANN) Problem for polygonal curves in $d$-dimensional space under the Fr\\'echet distance and ask to what extent known data structures for doubling spaces can be applied to this problem. Initially, this approach does not seem viable, since the doubling dimension of the target space is known to be unbounded -- even for well-behaved polygonal curves of constant complexity in one dimension. In order to overcome this, we identify a subspace of curves which has bounded doubling dimension and small Gromov-Hausdorff distance to the target space. We then apply state-of-the-art techniques for doubling spaces and show how to obtain a data structure for the $(1+\\varepsilon)$-ANN problem for any set of parametrized polygonal curves. The expected preprocessing time needed to construct the data-structure is $F(d,k,S,\\varepsilon)n\\log n$ and the space used is $F(d,k,S,\\varepsilon)n$, with a query time of $F(d,k,S,\\varepsilon)\\log n + F(d,k,S,\\varepsilon)^{-\\log(\\varepsilon)}$, where $F(d,k,S,\\varepsilon)=O\\left(2^{O(d)}k\\Phi(S)\\varepsilon^{-1}\\right)^k$ and $\\Phi(S)$ denotes the spread of the set of vertices and edges of the curves in $S$. We extend these results to the realistic class of $c$-packed curves and show improved bounds for small values of $c$.","sentences":["We consider the $(1+\\varepsilon)$-Approximate Nearest Neighbour (ANN) Problem for polygonal curves in $d$-dimensional space under the Fr\\'echet distance and ask to what extent known data structures for doubling spaces can be applied to this problem.","Initially, this approach does not seem viable, since the doubling dimension of the target space is known to be unbounded -- even for well-behaved polygonal curves of constant complexity in one dimension.","In order to overcome this, we identify a subspace of curves which has bounded doubling dimension and small Gromov-Hausdorff distance to the target space.","We then apply state-of-the-art techniques for doubling spaces and show how to obtain a data structure for the $(1+\\varepsilon)$-ANN problem for any set of parametrized polygonal curves.","The expected preprocessing time needed to construct the data-structure is $F(d,k,S,\\varepsilon)n\\log n$ and the space used is $F(d,k,S,\\varepsilon)n$, with a query time of $F(d,k,S,\\varepsilon)\\log n + F(d,k,S,\\varepsilon)^{-\\log(\\varepsilon)}$, where $F(d,k,S,\\varepsilon)=O\\left(2^{O(d)}k\\Phi(S)\\varepsilon^{-1}\\right)^k$ and $\\Phi(S)$ denotes the spread of the set of vertices and edges of the curves in $S$. We extend these results to the realistic class of $c$-packed curves and show improved bounds for small values of $c$."],"url":"http://arxiv.org/abs/2307.08521v1"}
{"created":"2023-07-17 14:27:32","title":"Results on Counterfactual Invariance","abstract":"In this paper we provide a theoretical analysis of counterfactual invariance. We present a variety of existing definitions, study how they relate to each other and what their graphical implications are. We then turn to the current major question surrounding counterfactual invariance, how does it relate to conditional independence? We show that whilst counterfactual invariance implies conditional independence, conditional independence does not give any implications about the degree or likelihood of satisfying counterfactual invariance. Furthermore, we show that for discrete causal models counterfactually invariant functions are often constrained to be functions of particular variables, or even constant.","sentences":["In this paper we provide a theoretical analysis of counterfactual invariance.","We present a variety of existing definitions, study how they relate to each other and what their graphical implications are.","We then turn to the current major question surrounding counterfactual invariance, how does it relate to conditional independence?","We show that whilst counterfactual invariance implies conditional independence, conditional independence does not give any implications about the degree or likelihood of satisfying counterfactual invariance.","Furthermore, we show that for discrete causal models counterfactually invariant functions are often constrained to be functions of particular variables, or even constant."],"url":"http://arxiv.org/abs/2307.08519v1"}
{"created":"2023-07-17 14:22:53","title":"Modular Denotational Semantics for Effects with Guarded Interaction Trees","abstract":"We present guarded interaction trees -- a structure and a fully formalized framework for representing higher-order computations with higher-order effects in Coq, inspired by domain theory and the recently proposed interaction trees. We also present an accompanying separation logic for reasoning about guarded interaction trees. To demonstrate that guarded interaction trees provide a convenient domain for interpreting higher-order languages with effects, we define an interpretation of a PCF-like language with effects and show that this interpretation is sound and computationally adequate; we prove the latter using a logical relation defined using the separation logic. Guarded interaction trees also allow us to combine different effects and reason about them modularly. To illustrate this point, we give a modular proof of type soundness of cross-language interactions for safe interoperability of different higher-order languages with different effects. All results in the paper are formalized in Coq using the Iris logic over guarded type theory.","sentences":["We present guarded interaction trees -- a structure and a fully formalized framework for representing higher-order computations with higher-order effects in Coq, inspired by domain theory and the recently proposed interaction trees.","We also present an accompanying separation logic for reasoning about guarded interaction trees.","To demonstrate that guarded interaction trees provide a convenient domain for interpreting higher-order languages with effects, we define an interpretation of a PCF-like language with effects and show that this interpretation is sound and computationally adequate; we prove the latter using a logical relation defined using the separation logic.","Guarded interaction trees also allow us to combine different effects and reason about them modularly.","To illustrate this point, we give a modular proof of type soundness of cross-language interactions for safe interoperability of different higher-order languages with different effects.","All results in the paper are formalized in Coq using the Iris logic over guarded type theory."],"url":"http://arxiv.org/abs/2307.08514v1"}
{"created":"2023-07-17 14:11:36","title":"Simulation of Stance Perturbations","abstract":"In this work, we analyze the circumstances under which social influence operations are likely to succeed. These circumstances include the selection of Confederate agents to execute intentional perturbations and the selection of Perturbation strategies. We use Agent-Based Modelling (ABM) as a simulation technique to observe the effect of intentional stance perturbations on scale-free networks. We develop a co-evolutionary social influence model to interrogate the tradeoff between perturbing stance and maintaining influence when these variables are linked through homophily. In our experiments, we observe that stances in a network will converge in sufficient simulation timesteps, influential agents are the best Confederates and the optimal Perturbation strategy involves the cascade of local ego networks. Finally, our experimental results support the theory of tipping points and are in line with empirical findings suggesting that 20-25% of agents need to be Confederates before a change in consensus can be achieved.","sentences":["In this work, we analyze the circumstances under which social influence operations are likely to succeed.","These circumstances include the selection of Confederate agents to execute intentional perturbations and the selection of Perturbation strategies.","We use Agent-Based Modelling (ABM) as a simulation technique to observe the effect of intentional stance perturbations on scale-free networks.","We develop a co-evolutionary social influence model to interrogate the tradeoff between perturbing stance and maintaining influence when these variables are linked through homophily.","In our experiments, we observe that stances in a network will converge in sufficient simulation timesteps, influential agents are the best Confederates and the optimal Perturbation strategy involves the cascade of local ego networks.","Finally, our experimental results support the theory of tipping points and are in line with empirical findings suggesting that 20-25% of agents need to be Confederates before a change in consensus can be achieved."],"url":"http://arxiv.org/abs/2307.08511v1"}
{"created":"2023-07-17 14:09:43","title":"Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients","abstract":"We design a novel algorithm for optimal transport by drawing from the entropic optimal transport, mirror descent and conjugate gradients literatures. Our algorithm is able to compute optimal transport costs with arbitrary accuracy without running into numerical stability issues. The algorithm is implemented efficiently on GPUs and is shown empirically to converge more quickly than traditional algorithms such as Sinkhorn's Algorithm both in terms of number of iterations and wall-clock time in many cases. We pay particular attention to the entropy of marginal distributions and show that high entropy marginals make for harder optimal transport problems, for which our algorithm is a good fit. We provide a careful ablation analysis with respect to algorithm and problem parameters, and present benchmarking over the MNIST dataset. The results suggest that our algorithm can be a useful addition to the practitioner's optimal transport toolkit. Our code is open-sourced at https://github.com/adaptive-agents-lab/MDOT-PNCG .","sentences":["We design a novel algorithm for optimal transport by drawing from the entropic optimal transport, mirror descent and conjugate gradients literatures.","Our algorithm is able to compute optimal transport costs with arbitrary accuracy without running into numerical stability issues.","The algorithm is implemented efficiently on GPUs and is shown empirically to converge more quickly than traditional algorithms such as Sinkhorn's Algorithm both in terms of number of iterations and wall-clock time in many cases.","We pay particular attention to the entropy of marginal distributions and show that high entropy marginals make for harder optimal transport problems, for which our algorithm is a good fit.","We provide a careful ablation analysis with respect to algorithm and problem parameters, and present benchmarking over the MNIST dataset.","The results suggest that our algorithm can be a useful addition to the practitioner's optimal transport toolkit.","Our code is open-sourced at https://github.com/adaptive-agents-lab/MDOT-PNCG ."],"url":"http://arxiv.org/abs/2307.08507v1"}
{"created":"2023-07-17 14:08:38","title":"Does Visual Pretraining Help End-to-End Reasoning?","abstract":"We aim to investigate whether end-to-end learning of visual reasoning can be achieved with general-purpose neural networks, with the help of visual pretraining. A positive result would refute the common belief that explicit visual abstraction (e.g. object detection) is essential for compositional generalization on visual reasoning, and confirm the feasibility of a neural network \"generalist\" to solve visual recognition and reasoning tasks. We propose a simple and general self-supervised framework which \"compresses\" each video frame into a small set of tokens with a transformer network, and reconstructs the remaining frames based on the compressed temporal context. To minimize the reconstruction loss, the network must learn a compact representation for each image, as well as capture temporal dynamics and object permanence from temporal context. We perform evaluation on two visual reasoning benchmarks, CATER and ACRE. We observe that pretraining is essential to achieve compositional generalization for end-to-end visual reasoning. Our proposed framework outperforms traditional supervised pretraining, including image classification and explicit object detection, by large margins.","sentences":["We aim to investigate whether end-to-end learning of visual reasoning can be achieved with general-purpose neural networks, with the help of visual pretraining.","A positive result would refute the common belief that explicit visual abstraction (e.g. object detection) is essential for compositional generalization on visual reasoning, and confirm the feasibility of a neural network \"generalist\" to solve visual recognition and reasoning tasks.","We propose a simple and general self-supervised framework which \"compresses\" each video frame into a small set of tokens with a transformer network, and reconstructs the remaining frames based on the compressed temporal context.","To minimize the reconstruction loss, the network must learn a compact representation for each image, as well as capture temporal dynamics and object permanence from temporal context.","We perform evaluation on two visual reasoning benchmarks, CATER and ACRE.","We observe that pretraining is essential to achieve compositional generalization for end-to-end visual reasoning.","Our proposed framework outperforms traditional supervised pretraining, including image classification and explicit object detection, by large margins."],"url":"http://arxiv.org/abs/2307.08506v1"}
{"created":"2023-07-17 14:08:23","title":"Approximation Algorithms for the Graph Burning on Cactus and Directed Trees","abstract":"Given a graph $G=(V, E)$, the problem of Graph Burning is to find a sequence of nodes from $V$, called a burning sequence, to burn the whole graph. This is a discrete-step process, and at each step, an unburned vertex is selected as an agent to spread fire to its neighbors by marking it as a burnt node. A burnt node spreads the fire to its neighbors at the next consecutive step. The goal is to find the burning sequence of minimum length. The Graph Burning problem is NP-Hard for general graphs and even for binary trees. A few approximation results are known, including a $ 3$-approximation algorithm for general graphs and a $ 2$-approximation algorithm for trees.   The Graph Burning on directed graphs is more challenging than on undirected graphs. In this paper, we propose 1) A $2.75$-approximation algorithm for a cactus graph (undirected), 2) A $3$-approximation algorithm for multi-rooted directed trees (polytree) and 3) A $1.905$-approximation algorithm for single-rooted directed tree (arborescence). We implement all the three approximation algorithms and the results are shown for randomly generated cactus graphs and directed trees.","sentences":["Given a graph $G=(V, E)$, the problem of Graph Burning is to find a sequence of nodes from $V$, called a burning sequence, to burn the whole graph.","This is a discrete-step process, and at each step, an unburned vertex is selected as an agent to spread fire to its neighbors by marking it as a burnt node.","A burnt node spreads the fire to its neighbors at the next consecutive step.","The goal is to find the burning sequence of minimum length.","The Graph Burning problem is NP-Hard for general graphs and even for binary trees.","A few approximation results are known, including a $ 3$-approximation algorithm for general graphs and a $ 2$-approximation algorithm for trees.   ","The Graph Burning on directed graphs is more challenging than on undirected graphs.","In this paper, we propose 1) A $2.75$-approximation algorithm for a cactus graph (undirected), 2) A $3$-approximation algorithm for multi-rooted directed trees (polytree) and 3) A $1.905$-approximation algorithm for single-rooted directed tree (arborescence).","We implement all the three approximation algorithms and the results are shown for randomly generated cactus graphs and directed trees."],"url":"http://arxiv.org/abs/2307.08505v1"}
{"created":"2023-07-17 14:08:17","title":"BUS:Efficient and Effective Vision-language Pre-training with Bottom-Up Patch Summarization","abstract":"Vision Transformer (ViT) based Vision-Language Pre-training (VLP) models have demonstrated impressive performance in various tasks. However, the lengthy visual token sequences fed into ViT can lead to training inefficiency and ineffectiveness. Existing efforts address the challenge by either bottom-level patch extraction in the ViT backbone or top-level patch abstraction outside, not balancing training efficiency and effectiveness well. Inspired by text summarization in natural language processing, we propose a Bottom-Up Patch Summarization approach named BUS, coordinating bottom-level extraction and top-level abstraction to learn a concise summary of lengthy visual token sequences efficiently. Specifically, We incorporate a Text-Semantics-Aware Patch Selector (TSPS) into the ViT backbone to perform a coarse-grained visual token extraction and then attach a flexible Transformer-based Patch Abstraction Decoder (PAD) upon the backbone for top-level visual abstraction. This bottom-up collaboration enables our BUS to yield high training efficiency while maintaining or even improving effectiveness. We evaluate our approach on various visual-language understanding and generation tasks and show competitive downstream task performance while boosting the training efficiency by 50\\%. Additionally, our model achieves state-of-the-art performance on many downstream tasks by increasing input image resolution without increasing computational costs over baselines.","sentences":["Vision Transformer (ViT) based Vision-Language Pre-training (VLP) models have demonstrated impressive performance in various tasks.","However, the lengthy visual token sequences fed into ViT can lead to training inefficiency and ineffectiveness.","Existing efforts address the challenge by either bottom-level patch extraction in the ViT backbone or top-level patch abstraction outside, not balancing training efficiency and effectiveness well.","Inspired by text summarization in natural language processing, we propose a Bottom-Up Patch Summarization approach named BUS, coordinating bottom-level extraction and top-level abstraction to learn a concise summary of lengthy visual token sequences efficiently.","Specifically, We incorporate a Text-Semantics-Aware Patch Selector (TSPS) into the ViT backbone to perform a coarse-grained visual token extraction and then attach a flexible Transformer-based Patch Abstraction Decoder (PAD) upon the backbone for top-level visual abstraction.","This bottom-up collaboration enables our BUS to yield high training efficiency while maintaining or even improving effectiveness.","We evaluate our approach on various visual-language understanding and generation tasks and show competitive downstream task performance while boosting the training efficiency by 50\\%.","Additionally, our model achieves state-of-the-art performance on many downstream tasks by increasing input image resolution without increasing computational costs over baselines."],"url":"http://arxiv.org/abs/2307.08504v1"}
{"created":"2023-07-17 14:03:45","title":"Cumulative Spatial Knowledge Distillation for Vision Transformers","abstract":"Distilling knowledge from convolutional neural networks (CNNs) is a double-edged sword for vision transformers (ViTs). It boosts the performance since the image-friendly local-inductive bias of CNN helps ViT learn faster and better, but leading to two problems: (1) Network designs of CNN and ViT are completely different, which leads to different semantic levels of intermediate features, making spatial-wise knowledge transfer methods (e.g., feature mimicking) inefficient. (2) Distilling knowledge from CNN limits the network convergence in the later training period since ViT's capability of integrating global information is suppressed by CNN's local-inductive-bias supervision. To this end, we present Cumulative Spatial Knowledge Distillation (CSKD). CSKD distills spatial-wise knowledge to all patch tokens of ViT from the corresponding spatial responses of CNN, without introducing intermediate features. Furthermore, CSKD exploits a Cumulative Knowledge Fusion (CKF) module, which introduces the global response of CNN and increasingly emphasizes its importance during the training. Applying CKF leverages CNN's local inductive bias in the early training period and gives full play to ViT's global capability in the later one. Extensive experiments and analysis on ImageNet-1k and downstream datasets demonstrate the superiority of our CSKD. Code will be publicly available.","sentences":["Distilling knowledge from convolutional neural networks (CNNs) is a double-edged sword for vision transformers (ViTs).","It boosts the performance since the image-friendly local-inductive bias of CNN helps ViT learn faster and better, but leading to two problems: (1) Network designs of CNN and ViT are completely different, which leads to different semantic levels of intermediate features, making spatial-wise knowledge transfer methods (e.g., feature mimicking) inefficient.","(2) Distilling knowledge from CNN limits the network convergence in the later training period since ViT's capability of integrating global information is suppressed by CNN's local-inductive-bias supervision.","To this end, we present Cumulative Spatial Knowledge Distillation (CSKD).","CSKD distills spatial-wise knowledge to all patch tokens of ViT from the corresponding spatial responses of CNN, without introducing intermediate features.","Furthermore, CSKD exploits a Cumulative Knowledge Fusion (CKF) module, which introduces the global response of CNN and increasingly emphasizes its importance during the training.","Applying CKF leverages CNN's local inductive bias in the early training period and gives full play to ViT's global capability in the later one.","Extensive experiments and analysis on ImageNet-1k and downstream datasets demonstrate the superiority of our CSKD.","Code will be publicly available."],"url":"http://arxiv.org/abs/2307.08500v1"}
{"created":"2023-07-17 14:03:13","title":"Age of Information in Locally Adaptive Frame Slotted ALOHA","abstract":"We consider a random access network consisting of source-destination pairs. Each source node generates status updates and transmits this information to its intended destination over a shared spectrum. The goal is to minimize the network-wide Age of Information (AoI). We develop a frame slotted ALOHA (FSA)-based policy for generating and transmitting status updates, where the frame size of each source node is adjusted according to its local environment. The proposed policy is of low complexity and can be implemented in a distributed manner. Additionally, it significantly improves the network AoI performance by (a) equalizing the update generation intervals at each source and (b) reducing interference across the network. Furthermore, we derive an analytical expression for the average network AoI attained for that policy. We evaluate the performance of the proposed scheme through simulations, which demonstrate that the locally adaptive FSA policy achieves a remarkable gain in terms of AoI compared to the slotted ALOHA counterpart, confirming the effectiveness of the proposed method.","sentences":["We consider a random access network consisting of source-destination pairs.","Each source node generates status updates and transmits this information to its intended destination over a shared spectrum.","The goal is to minimize the network-wide Age of Information (AoI).","We develop a frame slotted ALOHA (FSA)-based policy for generating and transmitting status updates, where the frame size of each source node is adjusted according to its local environment.","The proposed policy is of low complexity and can be implemented in a distributed manner.","Additionally, it significantly improves the network AoI performance by (a) equalizing the update generation intervals at each source and (b) reducing interference across the network.","Furthermore, we derive an analytical expression for the average network AoI attained for that policy.","We evaluate the performance of the proposed scheme through simulations, which demonstrate that the locally adaptive FSA policy achieves a remarkable gain in terms of AoI compared to the slotted ALOHA counterpart, confirming the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2307.08499v1"}
{"created":"2023-07-17 13:59:07","title":"Can We Trust Race Prediction?","abstract":"In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.","sentences":["In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies.","In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature.","Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG).","Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers."],"url":"http://arxiv.org/abs/2307.08496v1"}
{"created":"2023-07-17 13:56:28","title":"Occupancy Grid Mapping without Ray-Casting for High-resolution LiDAR Sensors","abstract":"Occupancy mapping is a fundamental component of robotic systems to reason about the unknown and known regions of the environment. This article presents an efficient occupancy mapping framework for high-resolution LiDAR sensors, termed D-Map. The framework introduces three main novelties to address the computational efficiency challenges of occupancy mapping. Firstly, we use a depth image to determine the occupancy state of regions instead of the traditional ray-casting method. Secondly, we introduce an efficient on-tree update strategy on a tree-based map structure. These two techniques avoid redundant visits to small cells, significantly reducing the number of cells to be updated. Thirdly, we remove known cells from the map at each update by leveraging the low false alarm rate of LiDAR sensors. This approach not only enhances our framework's update efficiency by reducing map size but also endows it with an interesting decremental property, which we have named D-Map. To support our design, we provide theoretical analyses of the accuracy of the depth image projection and time complexity of occupancy updates. Furthermore, we conduct extensive benchmark experiments on various LiDAR sensors in both public and private datasets. Our framework demonstrates superior efficiency in comparison with other state-of-the-art methods while maintaining comparable mapping accuracy and high memory efficiency. We demonstrate two real-world applications of D-Map for real-time occupancy mapping on a handle device and an aerial platform carrying a high-resolution LiDAR. In addition, we open-source the implementation of D-Map on GitHub to benefit society: github.com/hku-mars/D-Map.","sentences":["Occupancy mapping is a fundamental component of robotic systems to reason about the unknown and known regions of the environment.","This article presents an efficient occupancy mapping framework for high-resolution LiDAR sensors, termed D-Map.","The framework introduces three main novelties to address the computational efficiency challenges of occupancy mapping.","Firstly, we use a depth image to determine the occupancy state of regions instead of the traditional ray-casting method.","Secondly, we introduce an efficient on-tree update strategy on a tree-based map structure.","These two techniques avoid redundant visits to small cells, significantly reducing the number of cells to be updated.","Thirdly, we remove known cells from the map at each update by leveraging the low false alarm rate of LiDAR sensors.","This approach not only enhances our framework's update efficiency by reducing map size but also endows it with an interesting decremental property, which we have named D-Map.","To support our design, we provide theoretical analyses of the accuracy of the depth image projection and time complexity of occupancy updates.","Furthermore, we conduct extensive benchmark experiments on various LiDAR sensors in both public and private datasets.","Our framework demonstrates superior efficiency in comparison with other state-of-the-art methods while maintaining comparable mapping accuracy and high memory efficiency.","We demonstrate two real-world applications of D-Map for real-time occupancy mapping on a handle device and an aerial platform carrying a high-resolution LiDAR.","In addition, we open-source the implementation of D-Map on GitHub to benefit society: github.com/hku-mars/D-Map."],"url":"http://arxiv.org/abs/2307.08493v1"}
{"created":"2023-07-17 13:55:31","title":"SVDFormer: Complementing Point Cloud via Self-view Augmentation and Self-structure Dual-generator","abstract":"In this paper, we propose a novel network, SVDFormer, to tackle two specific challenges in point cloud completion: understanding faithful global shapes from incomplete point clouds and generating high-accuracy local structures. Current methods either perceive shape patterns using only 3D coordinates or import extra images with well-calibrated intrinsic parameters to guide the geometry estimation of the missing parts. However, these approaches do not always fully leverage the cross-modal self-structures available for accurate and high-quality point cloud completion. To this end, we first design a Self-view Fusion Network that leverages multiple-view depth image information to observe incomplete self-shape and generate a compact global shape. To reveal highly detailed structures, we then introduce a refinement module, called Self-structure Dual-generator, in which we incorporate learned shape priors and geometric self-similarities for producing new points. By perceiving the incompleteness of each point, the dual-path design disentangles refinement strategies conditioned on the structural type of each point. SVDFormer absorbs the wisdom of self-structures, avoiding any additional paired information such as color images with precisely calibrated camera intrinsic parameters. Comprehensive experiments indicate that our method achieves state-of-the-art performance on widely-used benchmarks. Code will be available at https://github.com/czvvd/SVDFormer.","sentences":["In this paper, we propose a novel network, SVDFormer, to tackle two specific challenges in point cloud completion: understanding faithful global shapes from incomplete point clouds and generating high-accuracy local structures.","Current methods either perceive shape patterns using only 3D coordinates or import extra images with well-calibrated intrinsic parameters to guide the geometry estimation of the missing parts.","However, these approaches do not always fully leverage the cross-modal self-structures available for accurate and high-quality point cloud completion.","To this end, we first design a Self-view Fusion Network that leverages multiple-view depth image information to observe incomplete self-shape and generate a compact global shape.","To reveal highly detailed structures, we then introduce a refinement module, called Self-structure Dual-generator, in which we incorporate learned shape priors and geometric self-similarities for producing new points.","By perceiving the incompleteness of each point, the dual-path design disentangles refinement strategies conditioned on the structural type of each point.","SVDFormer absorbs the wisdom of self-structures, avoiding any additional paired information such as color images with precisely calibrated camera intrinsic parameters.","Comprehensive experiments indicate that our method achieves state-of-the-art performance on widely-used benchmarks.","Code will be available at https://github.com/czvvd/SVDFormer."],"url":"http://arxiv.org/abs/2307.08492v1"}
{"created":"2023-07-17 13:53:39","title":"Live Long and Prosper:Analyzing Long-Lived MOAS Prefixes in BGP","abstract":"BGP exchanges reachability information in the form of prefixes, which are usually originated by a single Autonomous System (AS). If multiple ASes originate the same prefix, this is referred to as a Multiple Origin ASes (MOAS) prefix. One reason for MOAS prefixes are BGP prefix hijacks, which are mostly short-lived and have been studied extensively in the past years. In contrast to short-lived MOAS, long-lived MOAS have remained largely understudied. In this paper, we focus on long-lived MOAS prefixes and perform an in-depth study over six years. We identify around 24k long-lived MOAS prefixes in IPv4 and 1.4k in IPv6 being announced in January 2023. By analyzing the RPKI status we find that more than 40% of MOAS prefixes have all origins registered correctly, with only a minority of MOAS having invalid origins. Moreover, we find that the most prominent CIDR size of MOAS prefixes is /24 for IPv4 and /48 for IPv6, suggesting their use for fine-grained traffic steering. We attribute a considerable number of MOAS prefixes to mergers and acquisitions of companies. Additionally, more than 90% of MOAS prefixes are originated by two origin ASes, with the majority of detected origin AS relations being customer-provider. Finally, we identify that the majority of MOAS users are IT companies, and just 0.9% of IPv4 MOAS and 6.3% of IPv6 MOAS prefixes are used for anycast.","sentences":["BGP exchanges reachability information in the form of prefixes, which are usually originated by a single Autonomous System (AS).","If multiple ASes originate the same prefix, this is referred to as a Multiple Origin ASes (MOAS) prefix.","One reason for MOAS prefixes are BGP prefix hijacks, which are mostly short-lived and have been studied extensively in the past years.","In contrast to short-lived MOAS, long-lived MOAS have remained largely understudied.","In this paper, we focus on long-lived MOAS prefixes and perform an in-depth study over six years.","We identify around 24k long-lived MOAS prefixes in IPv4 and 1.4k in IPv6 being announced in January 2023.","By analyzing the RPKI status we find that more than 40% of MOAS prefixes have all origins registered correctly, with only a minority of MOAS having invalid origins.","Moreover, we find that the most prominent CIDR size of MOAS prefixes is /24 for IPv4 and /48 for IPv6, suggesting their use for fine-grained traffic steering.","We attribute a considerable number of MOAS prefixes to mergers and acquisitions of companies.","Additionally, more than 90% of MOAS prefixes are originated by two origin ASes, with the majority of detected origin AS relations being customer-provider.","Finally, we identify that the majority of MOAS users are IT companies, and just 0.9% of IPv4 MOAS and 6.3% of IPv6 MOAS prefixes are used for anycast."],"url":"http://arxiv.org/abs/2307.08490v1"}
{"created":"2023-07-17 13:49:52","title":"Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models","abstract":"Researchers have invested considerable effort into ensuring that large language models (LLMs) align with human values, using various training techniques, such as instruction tuning and Reinforcement Learning from Human or AI Feedback (RLHF/RLAIF), to guard against text unsafety. However, these defenses remain incredibly vulnerable to some jailbreak attacks, which can cause the model to become overly defensive to sensitive topics or still generate harmful content, leaving the model performance particularly fragile. Therefore, to comprehensively study text safety and output robustness, we propose a latent jailbreak prompt dataset, each involving malicious instruction embedding. Specifically, we instruct the model to complete a regular task, such as translation, where the text to be translated contains malicious instructions. To further analyze the safety and robustness, we design a hierarchical annotation framework. We present a systematic analysis of the safety and robustness of LLMs concerning the position of explicit normal instructions, word replacement (verbs in explicit normal instructions, target groups in malicious instructions, cue words in malicious instructions), and instruction replacement (different explicit normal instructions). Our results show that current LLMs not only have a preference for certain instruction verbs, but also exhibit different jailbreak rates for different instruction verbs in explicit normal instructions. In other words, the probability of generating unsafe content by the model will be reinforced to varying degrees depending on the instruction verb in explicit normal instructions. Code and data are available at https://github.com/qiuhuachuan/latent-jailbreak.","sentences":["Researchers have invested considerable effort into ensuring that large language models (LLMs) align with human values, using various training techniques, such as instruction tuning and Reinforcement Learning from Human or AI Feedback (RLHF/RLAIF), to guard against text unsafety.","However, these defenses remain incredibly vulnerable to some jailbreak attacks, which can cause the model to become overly defensive to sensitive topics or still generate harmful content, leaving the model performance particularly fragile.","Therefore, to comprehensively study text safety and output robustness, we propose a latent jailbreak prompt dataset, each involving malicious instruction embedding.","Specifically, we instruct the model to complete a regular task, such as translation, where the text to be translated contains malicious instructions.","To further analyze the safety and robustness, we design a hierarchical annotation framework.","We present a systematic analysis of the safety and robustness of LLMs concerning the position of explicit normal instructions, word replacement (verbs in explicit normal instructions, target groups in malicious instructions, cue words in malicious instructions), and instruction replacement (different explicit normal instructions).","Our results show that current LLMs not only have a preference for certain instruction verbs, but also exhibit different jailbreak rates for different instruction verbs in explicit normal instructions.","In other words, the probability of generating unsafe content by the model will be reinforced to varying degrees depending on the instruction verb in explicit normal instructions.","Code and data are available at https://github.com/qiuhuachuan/latent-jailbreak."],"url":"http://arxiv.org/abs/2307.08487v1"}
{"created":"2023-07-17 13:48:27","title":"Fairness in KI-Systemen","abstract":"The more AI-assisted decisions affect people's lives, the more important the fairness of such decisions becomes. In this chapter, we provide an introduction to research on fairness in machine learning. We explain the main fairness definitions and strategies for achieving fairness using concrete examples and place fairness research in the European context. Our contribution is aimed at an interdisciplinary audience and therefore avoids mathematical formulation but emphasizes visualizations and examples.   --   Je mehr KI-gest\\\"utzte Entscheidungen das Leben von Menschen betreffen, desto wichtiger ist die Fairness solcher Entscheidungen. In diesem Kapitel geben wir eine Einf\\\"uhrung in die Forschung zu Fairness im maschinellen Lernen. Wir erkl\\\"aren die wesentlichen Fairness-Definitionen und Strategien zur Erreichung von Fairness anhand konkreter Beispiele und ordnen die Fairness-Forschung in den europ\\\"aischen Kontext ein. Unser Beitrag richtet sich dabei an ein interdisziplin\\\"ares Publikum und verzichtet daher auf die mathematische Formulierung sondern betont Visualisierungen und Beispiele.","sentences":["The more AI-assisted decisions affect people's lives, the more important the fairness of such decisions becomes.","In this chapter, we provide an introduction to research on fairness in machine learning.","We explain the main fairness definitions and strategies for achieving fairness using concrete examples and place fairness research in the European context.","Our contribution is aimed at an interdisciplinary audience and therefore avoids mathematical formulation but emphasizes visualizations and examples.   ","--   Je mehr KI-gest\\\"utzte Entscheidungen das Leben von Menschen betreffen, desto wichtiger ist die Fairness solcher Entscheidungen.","In diesem Kapitel geben wir eine Einf\\\"uhrung in die Forschung zu Fairness im maschinellen Lernen.","Wir erkl\\\"aren die wesentlichen Fairness-Definitionen und Strategien zur Erreichung von Fairness anhand","konkreter Beispiele und ordnen die Fairness-Forschung in den europ\\\"aischen Kontext ein.","Unser Beitrag richtet sich dabei an ein interdisziplin\\\"ares Publikum und verzichtet daher auf die mathematische","Formulierung sondern betont Visualisierungen und Beispiele."],"url":"http://arxiv.org/abs/2307.08486v1"}
{"created":"2023-07-17 13:45:47","title":"Navigating Fairness Measures and Trade-Offs","abstract":"In order to monitor and prevent bias in AI systems we can use a wide range of (statistical) fairness measures. However, it is mathematically impossible to optimize for all of these measures at the same time. In addition, optimizing a fairness measure often greatly reduces the accuracy of the system (Kozodoi et al, 2022). As a result, we need a substantive theory that informs us how to make these decisions and for what reasons. I show that by using Rawls' notion of justice as fairness, we can create a basis for navigating fairness measures and the accuracy trade-off. In particular, this leads to a principled choice focusing on both the most vulnerable groups and the type of fairness measure that has the biggest impact on that group. This also helps to close part of the gap between philosophical accounts of distributive justice and the fairness literature that has been observed (Kuppler et al, 2021) and to operationalise the value of fairness.","sentences":["In order to monitor and prevent bias in AI systems we can use a wide range of (statistical) fairness measures.","However, it is mathematically impossible to optimize for all of these measures at the same time.","In addition, optimizing a fairness measure often greatly reduces the accuracy of the system (Kozodoi et al, 2022).","As a result, we need a substantive theory that informs us how to make these decisions and for what reasons.","I show that by using Rawls' notion of justice as fairness, we can create a basis for navigating fairness measures and the accuracy trade-off.","In particular, this leads to a principled choice focusing on both the most vulnerable groups and the type of fairness measure that has the biggest impact on that group.","This also helps to close part of the gap between philosophical accounts of distributive justice and the fairness literature that has been observed (Kuppler et al, 2021) and to operationalise the value of fairness."],"url":"http://arxiv.org/abs/2307.08484v1"}
{"created":"2023-07-17 13:44:11","title":"Differentiable Transportation Pruning","abstract":"Deep learning algorithms are increasingly employed at the edge. However, edge devices are resource constrained and thus require efficient deployment of deep neural networks. Pruning methods are a key tool for edge deployment as they can improve storage, compute, memory bandwidth, and energy usage. In this paper we propose a novel accurate pruning technique that allows precise control over the output network size. Our method uses an efficient optimal transportation scheme which we make end-to-end differentiable and which automatically tunes the exploration-exploitation behavior of the algorithm to find accurate sparse sub-networks. We show that our method achieves state-of-the-art performance compared to previous pruning methods on 3 different datasets, using 5 different models, across a wide range of pruning ratios, and with two types of sparsity budgets and pruning granularities.","sentences":["Deep learning algorithms are increasingly employed at the edge.","However, edge devices are resource constrained and thus require efficient deployment of deep neural networks.","Pruning methods are a key tool for edge deployment as they can improve storage, compute, memory bandwidth, and energy usage.","In this paper we propose a novel accurate pruning technique that allows precise control over the output network size.","Our method uses an efficient optimal transportation scheme which we make end-to-end differentiable and which automatically tunes the exploration-exploitation behavior of the algorithm to find accurate sparse sub-networks.","We show that our method achieves state-of-the-art performance compared to previous pruning methods on 3 different datasets, using 5 different models, across a wide range of pruning ratios, and with two types of sparsity budgets and pruning granularities."],"url":"http://arxiv.org/abs/2307.08483v1"}
{"created":"2023-07-17 13:39:08","title":"Derivation-Graph-Based Characterizations of Decidable Existential Rule Sets","abstract":"This paper establishes alternative characterizations of very expressive classes of existential rule sets with decidable query entailment. We consider the notable class of greedy bounded-treewidth sets (gbts) and a new, generalized variant, called weakly gbts (wgbts). Revisiting and building on the notion of derivation graphs, we define (weakly) cycle-free derivation graph sets ((w)cdgs) and employ elaborate proof-theoretic arguments to obtain that gbts and cdgs coincide, as do wgbts and wcdgs. These novel characterizations advance our analytic proof-theoretic understanding of existential rules and will likely be instrumental in practice.","sentences":["This paper establishes alternative characterizations of very expressive classes of existential rule sets with decidable query entailment.","We consider the notable class of greedy bounded-treewidth sets (gbts) and a new, generalized variant, called weakly gbts (wgbts).","Revisiting and building on the notion of derivation graphs, we define (weakly) cycle-free derivation graph sets ((w)cdgs) and employ elaborate proof-theoretic arguments to obtain that gbts and cdgs coincide, as do wgbts and wcdgs.","These novel characterizations advance our analytic proof-theoretic understanding of existential rules and will likely be instrumental in practice."],"url":"http://arxiv.org/abs/2307.08481v1"}
{"created":"2023-07-17 13:33:11","title":"SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence Pre-training","abstract":"Skeleton sequence representation learning has shown great advantages for action recognition due to its promising ability to model human joints and topology. However, the current methods usually require sufficient labeled data for training computationally expensive models, which is labor-intensive and time-consuming. Moreover, these methods ignore how to utilize the fine-grained dependencies among different skeleton joints to pre-train an efficient skeleton sequence learning model that can generalize well across different datasets. In this paper, we propose an efficient skeleton sequence learning framework, named Skeleton Sequence Learning (SSL). To comprehensively capture the human pose and obtain discriminative skeleton sequence representation, we build an asymmetric graph-based encoder-decoder pre-training architecture named SkeletonMAE, which embeds skeleton joint sequence into Graph Convolutional Network (GCN) and reconstructs the masked skeleton joints and edges based on the prior human topology knowledge. Then, the pre-trained SkeletonMAE encoder is integrated with the Spatial-Temporal Representation Learning (STRL) module to build the SSL framework. Extensive experimental results show that our SSL generalizes well across different datasets and outperforms the state-of-the-art self-supervised skeleton-based action recognition methods on FineGym, Diving48, NTU 60 and NTU 120 datasets. Additionally, we obtain comparable performance to some fully supervised methods. The code is avaliable at https://github.com/HongYan1123/SkeletonMAE.","sentences":["Skeleton sequence representation learning has shown great advantages for action recognition due to its promising ability to model human joints and topology.","However, the current methods usually require sufficient labeled data for training computationally expensive models, which is labor-intensive and time-consuming.","Moreover, these methods ignore how to utilize the fine-grained dependencies among different skeleton joints to pre-train an efficient skeleton sequence learning model that can generalize well across different datasets.","In this paper, we propose an efficient skeleton sequence learning framework, named Skeleton Sequence Learning (SSL).","To comprehensively capture the human pose and obtain discriminative skeleton sequence representation, we build an asymmetric graph-based encoder-decoder pre-training architecture named SkeletonMAE, which embeds skeleton joint sequence into Graph Convolutional Network (GCN) and reconstructs the masked skeleton joints and edges based on the prior human topology knowledge.","Then, the pre-trained SkeletonMAE encoder is integrated with the Spatial-Temporal Representation Learning (STRL) module to build the SSL framework.","Extensive experimental results show that our SSL generalizes well across different datasets and outperforms the state-of-the-art self-supervised skeleton-based action recognition methods on FineGym, Diving48, NTU 60 and NTU 120 datasets.","Additionally, we obtain comparable performance to some fully supervised methods.","The code is avaliable at https://github.com/HongYan1123/SkeletonMAE."],"url":"http://arxiv.org/abs/2307.08476v1"}
{"created":"2023-07-17 13:32:02","title":"A Fast Task Offloading Optimization Framework for IRS-Assisted Multi-Access Edge Computing System","abstract":"Terahertz communication networks and intelligent reflecting surfaces exhibit significant potential in advancing wireless networks, particularly within the domain of aerial-based multi-access edge computing systems. These technologies enable efficient offloading of computational tasks from user electronic devices to Unmanned Aerial Vehicles or local execution. For the generation of high-quality task-offloading allocations, conventional numerical optimization methods often struggle to solve challenging combinatorial optimization problems within the limited channel coherence time, thereby failing to respond quickly to dynamic changes in system conditions. To address this challenge, we propose a deep learning-based optimization framework called Iterative Order-Preserving policy Optimization (IOPO), which enables the generation of energy-efficient task-offloading decisions within milliseconds. Unlike exhaustive search methods, IOPO provides continuous updates to the offloading decisions without resorting to exhaustive search, resulting in accelerated convergence and reduced computational complexity, particularly when dealing with complex problems characterized by extensive solution spaces. Experimental results demonstrate that the proposed framework can generate energy-efficient task-offloading decisions within a very short time period, outperforming other benchmark methods.","sentences":["Terahertz communication networks and intelligent reflecting surfaces exhibit significant potential in advancing wireless networks, particularly within the domain of aerial-based multi-access edge computing systems.","These technologies enable efficient offloading of computational tasks from user electronic devices to Unmanned Aerial Vehicles or local execution.","For the generation of high-quality task-offloading allocations, conventional numerical optimization methods often struggle to solve challenging combinatorial optimization problems within the limited channel coherence time, thereby failing to respond quickly to dynamic changes in system conditions.","To address this challenge, we propose a deep learning-based optimization framework called Iterative Order-Preserving policy Optimization (IOPO), which enables the generation of energy-efficient task-offloading decisions within milliseconds.","Unlike exhaustive search methods, IOPO provides continuous updates to the offloading decisions without resorting to exhaustive search, resulting in accelerated convergence and reduced computational complexity, particularly when dealing with complex problems characterized by extensive solution spaces.","Experimental results demonstrate that the proposed framework can generate energy-efficient task-offloading decisions within a very short time period, outperforming other benchmark methods."],"url":"http://arxiv.org/abs/2307.08474v1"}
{"created":"2023-07-17 13:26:44","title":"Clarifying the Half Full or Half Empty Question: Multimodal Container Classification","abstract":"Multimodal integration is a key component of allowing robots to perceive the world. Multimodality comes with multiple challenges that have to be considered, such as how to integrate and fuse the data. In this paper, we compare different possibilities of fusing visual, tactile and proprioceptive data. The data is directly recorded on the NICOL robot in an experimental setup in which the robot has to classify containers and their content. Due to the different nature of the containers, the use of the modalities can wildly differ between the classes. We demonstrate the superiority of multimodal solutions in this use case and evaluate three fusion strategies that integrate the data at different time steps. We find that the accuracy of the best fusion strategy is 15% higher than the best strategy using only one singular sense.","sentences":["Multimodal integration is a key component of allowing robots to perceive the world.","Multimodality comes with multiple challenges that have to be considered, such as how to integrate and fuse the data.","In this paper, we compare different possibilities of fusing visual, tactile and proprioceptive data.","The data is directly recorded on the NICOL robot in an experimental setup in which the robot has to classify containers and their content.","Due to the different nature of the containers, the use of the modalities can wildly differ between the classes.","We demonstrate the superiority of multimodal solutions in this use case and evaluate three fusion strategies that integrate the data at different time steps.","We find that the accuracy of the best fusion strategy is 15% higher than the best strategy using only one singular sense."],"url":"http://arxiv.org/abs/2307.08471v1"}
{"created":"2023-07-17 13:21:28","title":"Riesz feature representation: scale equivariant scattering network for classification tasks","abstract":"Scattering networks yield powerful and robust hierarchical image descriptors which do not require lengthy training and which work well with very few training data. However, they rely on sampling the scale dimension. Hence, they become sensitive to scale variations and are unable to generalize to unseen scales. In this work, we define an alternative feature representation based on the Riesz transform. We detail and analyze the mathematical foundations behind this representation. In particular, it inherits scale equivariance from the Riesz transform and completely avoids sampling of the scale dimension. Additionally, the number of features in the representation is reduced by a factor four compared to scattering networks. Nevertheless, our representation performs comparably well for texture classification with an interesting addition: scale equivariance. Our method yields superior performance when dealing with scales outside of those covered by the training dataset. The usefulness of the equivariance property is demonstrated on the digit classification task, where accuracy remains stable even for scales four times larger than the one chosen for training. As a second example, we consider classification of textures.","sentences":["Scattering networks yield powerful and robust hierarchical image descriptors which do not require lengthy training and which work well with very few training data.","However, they rely on sampling the scale dimension.","Hence, they become sensitive to scale variations and are unable to generalize to unseen scales.","In this work, we define an alternative feature representation based on the Riesz transform.","We detail and analyze the mathematical foundations behind this representation.","In particular, it inherits scale equivariance from the Riesz transform and completely avoids sampling of the scale dimension.","Additionally, the number of features in the representation is reduced by a factor four compared to scattering networks.","Nevertheless, our representation performs comparably well for texture classification with an interesting addition: scale equivariance.","Our method yields superior performance when dealing with scales outside of those covered by the training dataset.","The usefulness of the equivariance property is demonstrated on the digit classification task, where accuracy remains stable even for scales four times larger than the one chosen for training.","As a second example, we consider classification of textures."],"url":"http://arxiv.org/abs/2307.08467v1"}
{"created":"2023-07-17 13:21:02","title":"Classification of UHF Partial Discharge Signals in Gas-Insulated HVDC Systems Using Neural Networks","abstract":"Undetected partial discharges (PDs) are a safety critical issue in high voltage (HV) gas insulated systems (GIS). While the diagnosis of PDs under AC voltage is well-established, the analysis of PDs under DC voltage remains an active research field. A key focus of these investigations is the classification of different PD sources to enable subsequent sophisticated analysis.   In this paper, we propose and analyze a neural network-based approach for classifying PD signals caused by metallic protrusions and conductive particles on the insulator of HVDC GIS, without relying on pulse sequence analysis features. In contrast to previous approaches, our proposed model can discriminate the studied PD signals obtained at negative and positive potentials, while also generalizing to unseen operating voltage multiples. Additionally, we compare the performance of time- and frequency-domain input signals and explore the impact of different normalization schemes to mitigate the influence of free-space path loss between the sensor and defect location.","sentences":["Undetected partial discharges (PDs) are a safety critical issue in high voltage (HV) gas insulated systems (GIS).","While the diagnosis of PDs under AC voltage is well-established, the analysis of PDs under DC voltage remains an active research field.","A key focus of these investigations is the classification of different PD sources to enable subsequent sophisticated analysis.   ","In this paper, we propose and analyze a neural network-based approach for classifying PD signals caused by metallic protrusions and conductive particles on the insulator of HVDC GIS, without relying on pulse sequence analysis features.","In contrast to previous approaches, our proposed model can discriminate the studied PD signals obtained at negative and positive potentials, while also generalizing to unseen operating voltage multiples.","Additionally, we compare the performance of time- and frequency-domain input signals and explore the impact of different normalization schemes to mitigate the influence of free-space path loss between the sensor and defect location."],"url":"http://arxiv.org/abs/2307.08466v1"}
{"created":"2023-07-17 13:06:33","title":"Towards eXplainable AI for Mobility Data Science","abstract":"This paper presents our ongoing work towards XAI for Mobility Data Science applications, focusing on explainable models that can learn from dense trajectory data, such as GPS tracks of vehicles and vessels using temporal graph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI studies, argue the need for comprehensible explanations with human-centered approaches, and outline a research path toward XAI for Mobility Data Science.","sentences":["This paper presents our ongoing work towards XAI for Mobility Data Science applications, focusing on explainable models that can learn from dense trajectory data, such as GPS tracks of vehicles and vessels using temporal graph neural networks (GNNs) and counterfactuals.","We review the existing GeoXAI studies, argue the need for comprehensible explanations with human-centered approaches, and outline a research path toward XAI for Mobility Data Science."],"url":"http://arxiv.org/abs/2307.08461v1"}
{"created":"2023-07-17 12:49:38","title":"Santa Claus meets Makespan and Matroids: Algorithms and Reductions","abstract":"In this paper we study the relation of two fundamental problems in scheduling and fair allocation: makespan minimization on unrelated parallel machines and max-min fair allocation, also known as the Santa Claus problem. For both of these problems the best approximation factor is a notorious open question; more precisely, whether there is a better-than-2 approximation for the former problem and whether there is a constant approximation for the latter.   While the two problems are intuitively related and history has shown that techniques can often be transferred between them, no formal reductions are known. We first show that an affirmative answer to the open question for makespan minimization implies the same for the Santa Claus problem by reducing the latter problem to the former. We also prove that for problem instances with only two input values both questions are equivalent.   We then move to a special case called ``restricted assignment'', which is well studied in both problems. Although our reductions do not maintain the characteristics of this special case, we give a reduction in a slight generalization, where the jobs or resources are assigned to multiple machines or players subject to a matroid constraint and in addition we have only two values. This draws a similar picture as before: equivalence for two values and the general case of Santa Claus can only be easier than makespan minimization. To complete the picture, we give an algorithm for our new matroid variant of the Santa Claus problem using a non-trivial extension of the local search method from restricted assignment. Thereby we unify, generalize, and improve several previous results. We believe that this matroid generalization may be of independent interest and provide several sample applications.","sentences":["In this paper we study the relation of two fundamental problems in scheduling and fair allocation: makespan minimization on unrelated parallel machines and max-min fair allocation, also known as the Santa Claus problem.","For both of these problems the best approximation factor is a notorious open question; more precisely, whether there is a better-than-2 approximation for the former problem and whether there is a constant approximation for the latter.   ","While the two problems are intuitively related and history has shown that techniques can often be transferred between them, no formal reductions are known.","We first show that an affirmative answer to the open question for makespan minimization implies the same for the Santa Claus problem by reducing the latter problem to the former.","We also prove that for problem instances with only two input values both questions are equivalent.   ","We then move to a special case called ``restricted assignment'', which is well studied in both problems.","Although our reductions do not maintain the characteristics of this special case, we give a reduction in a slight generalization, where the jobs or resources are assigned to multiple machines or players subject to a matroid constraint and in addition we have only two values.","This draws a similar picture as before: equivalence for two values and the general case of Santa Claus can only be easier than makespan minimization.","To complete the picture, we give an algorithm for our new matroid variant of the Santa Claus problem using a non-trivial extension of the local search method from restricted assignment.","Thereby we unify, generalize, and improve several previous results.","We believe that this matroid generalization may be of independent interest and provide several sample applications."],"url":"http://arxiv.org/abs/2307.08453v1"}
{"created":"2023-07-17 12:42:56","title":"Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation","abstract":"Conditional diffusion models have demonstrated impressive performance in image manipulation tasks. The general pipeline involves adding noise to the image and then denoising it. However, this method faces a trade-off problem: adding too much noise affects the fidelity of the image while adding too little affects its editability. This largely limits their practical applicability. In this paper, we propose a novel framework, Selective Diffusion Distillation (SDD), that ensures both the fidelity and editability of images. Instead of directly editing images with a diffusion model, we train a feedforward image manipulation network under the guidance of the diffusion model. Besides, we propose an effective indicator to select the semantic-related timestep to obtain the correct semantic guidance from the diffusion model. This approach successfully avoids the dilemma caused by the diffusion process. Our extensive experiments demonstrate the advantages of our framework. Code is released at https://github.com/AndysonYs/Selective-Diffusion-Distillation.","sentences":["Conditional diffusion models have demonstrated impressive performance in image manipulation tasks.","The general pipeline involves adding noise to the image and then denoising it.","However, this method faces a trade-off problem: adding too much noise affects the fidelity of the image while adding too little affects its editability.","This largely limits their practical applicability.","In this paper, we propose a novel framework, Selective Diffusion Distillation (SDD), that ensures both the fidelity and editability of images.","Instead of directly editing images with a diffusion model, we train a feedforward image manipulation network under the guidance of the diffusion model.","Besides, we propose an effective indicator to select the semantic-related timestep to obtain the correct semantic guidance from the diffusion model.","This approach successfully avoids the dilemma caused by the diffusion process.","Our extensive experiments demonstrate the advantages of our framework.","Code is released at https://github.com/AndysonYs/Selective-Diffusion-Distillation."],"url":"http://arxiv.org/abs/2307.08448v1"}
{"created":"2023-07-17 12:38:06","title":"Fast Algorithms for Energy Games in Special Cases","abstract":"In this paper, we study algorithms for special cases of energy games, a class of turn-based games on graphs that show up in the quantitative analysis of reactive systems. In an energy game, the vertices of a weighted directed graph belong either to Alice or to Bob. A token is moved to a next vertex by the player controlling its current location, and its energy is changed by the weight of the edge. Given a fixed starting vertex and initial energy, Alice wins the game if the energy of the token remains nonnegative at every moment. If the energy goes below zero at some point, then Bob wins. The problem of determining the winner in an energy game lies in $\\mathsf{NP} \\cap \\mathsf{coNP}$. It is a long standing open problem whether a polynomial time algorithm for this problem exists.   We devise new algorithms for three special cases of the problem. The first two results focus on the single-player version, where either Alice or Bob controls the whole game graph. We develop an $\\tilde{O}(n^\\omega W^\\omega)$ time algorithm for a game graph controlled by Alice, by providing a reduction to the All-Pairs Nonnegative Prefix Paths problem (APNP), where $W$ is the maximum weight and $\\omega$ is the best exponent for matrix multiplication. Thus we study the APNP problem separately, for which we develop an $\\tilde{O}(n^\\omega W^\\omega)$ time algorithm. For both problems, we improve over the state of the art of $\\tilde O(mn)$ for small $W$. For the APNP problem, we also provide a conditional lower bound, which states that there is no $O(n^{3-\\epsilon})$ time algorithm for any $\\epsilon > 0$, unless the APSP Hypothesis fails. For a game graph controlled by Bob, we obtain a near-linear time algorithm. Regarding our third result, we present a variant of the value iteration algorithm, and we prove that it gives an $O(mn)$ time algorithm for game graphs without negative cycles.","sentences":["In this paper, we study algorithms for special cases of energy games, a class of turn-based games on graphs that show up in the quantitative analysis of reactive systems.","In an energy game, the vertices of a weighted directed graph belong either to Alice or to Bob.","A token is moved to a next vertex by the player controlling its current location, and its energy is changed by the weight of the edge.","Given a fixed starting vertex and initial energy, Alice wins the game if the energy of the token remains nonnegative at every moment.","If the energy goes below zero at some point, then Bob wins.","The problem of determining the winner in an energy game lies in $\\mathsf{NP} \\cap \\mathsf{coNP}$.","It is a long standing open problem whether a polynomial time algorithm for this problem exists.   ","We devise new algorithms for three special cases of the problem.","The first two results focus on the single-player version, where either Alice or Bob controls the whole game graph.","We develop an $\\tilde{O}(n^\\omega W^\\omega)$ time algorithm for a game graph controlled by Alice, by providing a reduction to the All-Pairs Nonnegative Prefix Paths problem (APNP), where $W$ is the maximum weight and $\\omega$ is the best exponent for matrix multiplication.","Thus we study the APNP problem separately, for which we develop an $\\tilde{O}(n^\\omega W^\\omega)$ time algorithm.","For both problems, we improve over the state of the art of $\\tilde O(mn)$ for small $W$. For the APNP problem, we also provide a conditional lower bound, which states that there is no $O(n^{3-\\epsilon})$ time algorithm for any $\\epsilon > 0$, unless the APSP Hypothesis fails.","For a game graph controlled by Bob, we obtain a near-linear time algorithm.","Regarding our third result, we present a variant of the value iteration algorithm, and we prove that it gives an $O(mn)$ time algorithm for game graphs without negative cycles."],"url":"http://arxiv.org/abs/2307.08442v1"}
{"created":"2023-07-17 12:31:13","title":"DOT: A Distillation-Oriented Trainer","abstract":"Knowledge distillation transfers knowledge from a large model to a small one via task and distillation losses. In this paper, we observe a trade-off between task and distillation losses, i.e., introducing distillation loss limits the convergence of task loss. We believe that the trade-off results from the insufficient optimization of distillation loss. The reason is: The teacher has a lower task loss than the student, and a lower distillation loss drives the student more similar to the teacher, then a better-converged task loss could be obtained. To break the trade-off, we propose the Distillation-Oriented Trainer (DOT). DOT separately considers gradients of task and distillation losses, then applies a larger momentum to distillation loss to accelerate its optimization. We empirically prove that DOT breaks the trade-off, i.e., both losses are sufficiently optimized. Extensive experiments validate the superiority of DOT. Notably, DOT achieves a +2.59% accuracy improvement on ImageNet-1k for the ResNet50-MobileNetV1 pair. Conclusively, DOT greatly benefits the student's optimization properties in terms of loss convergence and model generalization. Code will be made publicly available.","sentences":["Knowledge distillation transfers knowledge from a large model to a small one via task and distillation losses.","In this paper, we observe a trade-off between task and distillation losses, i.e., introducing distillation loss limits the convergence of task loss.","We believe that the trade-off results from the insufficient optimization of distillation loss.","The reason is: The teacher has a lower task loss than the student, and a lower distillation loss drives the student more similar to the teacher, then a better-converged task loss could be obtained.","To break the trade-off, we propose the Distillation-Oriented Trainer (DOT).","DOT separately considers gradients of task and distillation losses, then applies a larger momentum to distillation loss to accelerate its optimization.","We empirically prove that DOT breaks the trade-off, i.e., both losses are sufficiently optimized.","Extensive experiments validate the superiority of DOT.","Notably, DOT achieves a +2.59% accuracy improvement on ImageNet-1k for the ResNet50-MobileNetV1 pair.","Conclusively, DOT greatly benefits the student's optimization properties in terms of loss convergence and model generalization.","Code will be made publicly available."],"url":"http://arxiv.org/abs/2307.08436v1"}
{"created":"2023-07-17 12:27:15","title":"Dense Affinity Matching for Few-Shot Segmentation","abstract":"Few-Shot Segmentation (FSS) aims to segment the novel class images with a few annotated samples. In this paper, we propose a dense affinity matching (DAM) framework to exploit the support-query interaction by densely capturing both the pixel-to-pixel and pixel-to-patch relations in each support-query pair with the bidirectional 3D convolutions. Different from the existing methods that remove the support background, we design a hysteretic spatial filtering module (HSFM) to filter the background-related query features and retain the foreground-related query features with the assistance of the support background, which is beneficial for eliminating interference objects in the query background. We comprehensively evaluate our DAM on ten benchmarks under cross-category, cross-dataset, and cross-domain FSS tasks. Experimental results demonstrate that DAM performs very competitively under different settings with only 0.68M parameters, especially under cross-domain FSS tasks, showing its effectiveness and efficiency.","sentences":["Few-Shot Segmentation (FSS) aims to segment the novel class images with a few annotated samples.","In this paper, we propose a dense affinity matching (DAM) framework to exploit the support-query interaction by densely capturing both the pixel-to-pixel and pixel-to-patch relations in each support-query pair with the bidirectional 3D convolutions.","Different from the existing methods that remove the support background, we design a hysteretic spatial filtering module (HSFM) to filter the background-related query features and retain the foreground-related query features with the assistance of the support background, which is beneficial for eliminating interference objects in the query background.","We comprehensively evaluate our DAM on ten benchmarks under cross-category, cross-dataset, and cross-domain FSS tasks.","Experimental results demonstrate that DAM performs very competitively under different settings with only 0.68M parameters, especially under cross-domain FSS tasks, showing its effectiveness and efficiency."],"url":"http://arxiv.org/abs/2307.08434v1"}
{"created":"2023-07-17 12:25:52","title":"From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs","abstract":"Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks. Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges. We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets). Simultaneously, graph-sprints significantly reduce inference latencies, achieving close to an order of magnitude speed-up in our experimental setting.","sentences":["Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time.","Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks.","Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search.","However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs.","To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models.","To achieve this, a streaming, low latency approximation to the random-walk based features is proposed.","In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges.","We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie).","We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets).","Simultaneously, graph-sprints significantly reduce inference latencies, achieving close to an order of magnitude speed-up in our experimental setting."],"url":"http://arxiv.org/abs/2307.08433v1"}
{"created":"2023-07-17 12:20:07","title":"Long-range Dependency based Multi-Layer Perceptron for Heterogeneous Information Networks","abstract":"Existing heterogeneous graph neural networks (HGNNs) have achieved great success in utilizing the rich semantic information in heterogeneous information networks (HINs). However, few works have delved into the utilization of long-range dependencies in HINs, which is extremely valuable as many real-world HINs are sparse, and each node has only a few directly connected neighbors. Although some HGNNs can utilize distant neighbors by stacking multiple layers or leveraging long meta-paths, the exponentially increased number of nodes in the receptive field or the number of meta-paths incurs high computation and memory costs. To address these issues, we investigate the importance of different meta-paths and propose Long-range Dependency based Multi-Layer Perceptron (LDMLP). Specifically, to solve the high-cost problem of leveraging long-range dependencies, LDMLP adopts a search stage to discover effective meta-paths automatically, reducing the exponentially increased number of meta-paths to a constant. To avoid the influence of specific modules on search results, LDMLP utilizes a simple architecture with only multi-layer perceptions in the search stage, improving the generalization of searched meta-paths. As a result, the searched meta-paths not only perform well in LDMLP but also enable other HGNNs like HAN and SeHGNN to perform better. Extensive experiments on eight heterogeneous datasets demonstrate that LDMLP achieves state-of-the-art performance while enjoying high efficiency and generalization, especially on sparse HINs.","sentences":["Existing heterogeneous graph neural networks (HGNNs) have achieved great success in utilizing the rich semantic information in heterogeneous information networks (HINs).","However, few works have delved into the utilization of long-range dependencies in HINs, which is extremely valuable as many real-world HINs are sparse, and each node has only a few directly connected neighbors.","Although some HGNNs can utilize distant neighbors by stacking multiple layers or leveraging long meta-paths, the exponentially increased number of nodes in the receptive field or the number of meta-paths incurs high computation and memory costs.","To address these issues, we investigate the importance of different meta-paths and propose Long-range Dependency based Multi-Layer Perceptron (LDMLP).","Specifically, to solve the high-cost problem of leveraging long-range dependencies, LDMLP adopts a search stage to discover effective meta-paths automatically, reducing the exponentially increased number of meta-paths to a constant.","To avoid the influence of specific modules on search results, LDMLP utilizes a simple architecture with only multi-layer perceptions in the search stage, improving the generalization of searched meta-paths.","As a result, the searched meta-paths not only perform well in LDMLP but also enable other HGNNs like HAN and SeHGNN to perform better.","Extensive experiments on eight heterogeneous datasets demonstrate that LDMLP achieves state-of-the-art performance while enjoying high efficiency and generalization, especially on sparse HINs."],"url":"http://arxiv.org/abs/2307.08430v1"}
{"created":"2023-07-17 12:14:45","title":"Improving End-to-End Speech Translation by Imitation-Based Knowledge Distillation with Synthetic Transcripts","abstract":"End-to-end automatic speech translation (AST) relies on data that combines audio inputs with text translation outputs. Previous work used existing large parallel corpora of transcriptions and translations in a knowledge distillation (KD) setup to distill a neural machine translation (NMT) into an AST student model. While KD allows using larger pretrained models, the reliance of previous KD approaches on manual audio transcripts in the data pipeline restricts the applicability of this framework to AST. We present an imitation learning approach where a teacher NMT system corrects the errors of an AST student without relying on manual transcripts. We show that the NMT teacher can recover from errors in automatic transcriptions and is able to correct erroneous translations of the AST student, leading to improvements of about 4 BLEU points over the standard AST end-to-end baseline on the English-German CoVoST-2 and MuST-C datasets, respectively. Code and data are publicly available.\\footnote{\\url{https://github.com/HubReb/imitkd_ast/releases/tag/v1.1}}","sentences":["End-to-end automatic speech translation (AST) relies on data that combines audio inputs with text translation outputs.","Previous work used existing large parallel corpora of transcriptions and translations in a knowledge distillation (KD) setup to distill a neural machine translation (NMT) into an AST student model.","While KD allows using larger pretrained models, the reliance of previous KD approaches on manual audio transcripts in the data pipeline restricts the applicability of this framework to AST.","We present an imitation learning approach where a teacher NMT system corrects the errors of an AST student without relying on manual transcripts.","We show that the NMT teacher can recover from errors in automatic transcriptions and is able to correct erroneous translations of the AST student, leading to improvements of about 4 BLEU points over the standard AST end-to-end baseline on the English-German CoVoST-2 and MuST-C datasets, respectively.","Code and data are publicly available.\\footnote{\\url{https://github.com/HubReb/imitkd_ast/releases/tag/v1.1}}"],"url":"http://arxiv.org/abs/2307.08426v1"}
{"created":"2023-07-17 12:14:24","title":"An Indefensible Attack: Label-Only Model Inversion via Conditional Diffusion Model","abstract":"Model inversion attacks (MIAs) are aimed at recovering private data from a target model's training set, which poses a threat to the privacy of deep learning models. MIAs primarily focus on the white-box scenario where the attacker has full access to the structure and parameters of the target model. However, practical applications are black-box, it is not easy for adversaries to obtain model-related parameters, and various models only output predicted labels. Existing black-box MIAs primarily focused on designing the optimization strategy, and the generative model is only migrated from the GAN used in white-box MIA. Our research is the pioneering study of feasible attack models in label-only black-box scenarios, to the best of our knowledge.   In this paper, we develop a novel method of MIA using the conditional diffusion model to recover the precise sample of the target without any extra optimization, as long as the target model outputs the label. Two primary techniques are introduced to execute the attack. Firstly, select an auxiliary dataset that is relevant to the target model task, and the labels predicted by the target model are used as conditions to guide the training process. Secondly, target labels and random standard normally distributed noise are input into the trained conditional diffusion model, generating target samples with pre-defined guidance strength. We then filter out the most robust and representative samples. Furthermore, we propose for the first time to use Learned Perceptual Image Patch Similarity (LPIPS) as one of the evaluation metrics for MIA, with systematic quantitative and qualitative evaluation in terms of attack accuracy, realism, and similarity. Experimental results show that this method can generate similar and accurate data to the target without optimization and outperforms generators of previous approaches in the label-only scenario.","sentences":["Model inversion attacks (MIAs) are aimed at recovering private data from a target model's training set, which poses a threat to the privacy of deep learning models.","MIAs primarily focus on the white-box scenario where the attacker has full access to the structure and parameters of the target model.","However, practical applications are black-box, it is not easy for adversaries to obtain model-related parameters, and various models only output predicted labels.","Existing black-box MIAs primarily focused on designing the optimization strategy, and the generative model is only migrated from the GAN used in white-box MIA.","Our research is the pioneering study of feasible attack models in label-only black-box scenarios, to the best of our knowledge.   ","In this paper, we develop a novel method of MIA using the conditional diffusion model to recover the precise sample of the target without any extra optimization, as long as the target model outputs the label.","Two primary techniques are introduced to execute the attack.","Firstly, select an auxiliary dataset that is relevant to the target model task, and the labels predicted by the target model are used as conditions to guide the training process.","Secondly, target labels and random standard normally distributed noise are input into the trained conditional diffusion model, generating target samples with pre-defined guidance strength.","We then filter out the most robust and representative samples.","Furthermore, we propose for the first time to use Learned Perceptual Image Patch Similarity (LPIPS) as one of the evaluation metrics for MIA, with systematic quantitative and qualitative evaluation in terms of attack accuracy, realism, and similarity.","Experimental results show that this method can generate similar and accurate data to the target without optimization and outperforms generators of previous approaches in the label-only scenario."],"url":"http://arxiv.org/abs/2307.08424v1"}
{"created":"2023-07-17 12:14:14","title":"Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems","abstract":"Advances in artificial intelligence (AI) are fueling a new paradigm of discoveries in natural sciences. Today, AI has started to advance natural sciences by improving, accelerating, and enabling our understanding of natural phenomena at a wide range of spatial and temporal scales, giving rise to a new area of research known as AI for science (AI4Science). Being an emerging research paradigm, AI4Science is unique in that it is an enormous and highly interdisciplinary area. Thus, a unified and technical treatment of this field is needed yet challenging. This paper aims to provide a technically thorough account of a subarea of AI4Science; namely, AI for quantum, atomistic, and continuum systems. These areas aim at understanding the physical world from the subatomic (wavefunctions and electron density), atomic (molecules, proteins, materials, and interactions), to macro (fluids, climate, and subsurface) scales and form an important subarea of AI4Science. A unique advantage of focusing on these areas is that they largely share a common set of challenges, thereby allowing a unified and foundational treatment. A key common challenge is how to capture physics first principles, especially symmetries, in natural systems by deep learning methods. We provide an in-depth yet intuitive account of techniques to achieve equivariance to symmetry transformations. We also discuss other common technical challenges, including explainability, out-of-distribution generalization, knowledge transfer with foundation and large language models, and uncertainty quantification. To facilitate learning and education, we provide categorized lists of resources that we found to be useful. We strive to be thorough and unified and hope this initial effort may trigger more community interests and efforts to further advance AI4Science.","sentences":["Advances in artificial intelligence (AI) are fueling a new paradigm of discoveries in natural sciences.","Today, AI has started to advance natural sciences by improving, accelerating, and enabling our understanding of natural phenomena at a wide range of spatial and temporal scales, giving rise to a new area of research known as AI for science (AI4Science).","Being an emerging research paradigm, AI4Science is unique in that it is an enormous and highly interdisciplinary area.","Thus, a unified and technical treatment of this field is needed yet challenging.","This paper aims to provide a technically thorough account of a subarea of AI4Science; namely, AI for quantum, atomistic, and continuum systems.","These areas aim at understanding the physical world from the subatomic (wavefunctions and electron density), atomic (molecules, proteins, materials, and interactions), to macro (fluids, climate, and subsurface) scales and form an important subarea of AI4Science.","A unique advantage of focusing on these areas is that they largely share a common set of challenges, thereby allowing a unified and foundational treatment.","A key common challenge is how to capture physics first principles, especially symmetries, in natural systems by deep learning methods.","We provide an in-depth yet intuitive account of techniques to achieve equivariance to symmetry transformations.","We also discuss other common technical challenges, including explainability, out-of-distribution generalization, knowledge transfer with foundation and large language models, and uncertainty quantification.","To facilitate learning and education, we provide categorized lists of resources that we found to be useful.","We strive to be thorough and unified and hope this initial effort may trigger more community interests and efforts to further advance AI4Science."],"url":"http://arxiv.org/abs/2307.08423v1"}
{"created":"2023-07-17 12:09:18","title":"Systematic Comparison of Software Agents and Digital Twins: Differences, Similarities, and Synergies in Industrial Production","abstract":"To achieve a highly agile and flexible production, it is envisioned that industrial production systems gradually become more decentralized, interconnected, and intelligent. Within this vision, production assets collaborate with each other, exhibiting a high degree of autonomy. Furthermore, knowledge about individual production assets is readily available throughout their entire life-cycles. To realize this vision, adequate use of information technology is required. Two commonly applied software paradigms in this context are Software Agents (referred to as Agents) and Digital Twins (DTs). This work presents a systematic comparison of Agents and DTs in industrial applications. The goal of the study is to determine the differences, similarities, and potential synergies between the two paradigms. The comparison is based on the purposes for which Agents and DTs are applied, the properties and capabilities exhibited by these software paradigms, and how they can be allocated within the Reference Architecture Model Industry 4.0. The comparison reveals that Agents are commonly employed in the collaborative planning and execution of production processes, while DTs typically play a more passive role in monitoring production resources and processing information. Although these observations imply characteristic sets of capabilities and properties for both Agents and DTs, a clear and definitive distinction between the two paradigms cannot be made. Instead, the analysis indicates that production assets utilizing a combination of Agents and DTs would demonstrate high degrees of intelligence, autonomy, sociability, and fidelity. To achieve this, further standardization is required, particularly in the field of DTs.","sentences":["To achieve a highly agile and flexible production, it is envisioned that industrial production systems gradually become more decentralized, interconnected, and intelligent.","Within this vision, production assets collaborate with each other, exhibiting a high degree of autonomy.","Furthermore, knowledge about individual production assets is readily available throughout their entire life-cycles.","To realize this vision, adequate use of information technology is required.","Two commonly applied software paradigms in this context are Software Agents (referred to as Agents) and Digital Twins (DTs).","This work presents a systematic comparison of Agents and DTs in industrial applications.","The goal of the study is to determine the differences, similarities, and potential synergies between the two paradigms.","The comparison is based on the purposes for which Agents and DTs are applied, the properties and capabilities exhibited by these software paradigms, and how they can be allocated within the Reference Architecture Model Industry 4.0.","The comparison reveals that Agents are commonly employed in the collaborative planning and execution of production processes, while DTs typically play a more passive role in monitoring production resources and processing information.","Although these observations imply characteristic sets of capabilities and properties for both Agents and DTs, a clear and definitive distinction between the two paradigms cannot be made.","Instead, the analysis indicates that production assets utilizing a combination of Agents and DTs would demonstrate high degrees of intelligence, autonomy, sociability, and fidelity.","To achieve this, further standardization is required, particularly in the field of DTs."],"url":"http://arxiv.org/abs/2307.08421v1"}
{"created":"2023-07-17 12:07:50","title":"Maximum Flows in Parametric Graph Templates","abstract":"Execution graphs of parallel loop programs exhibit a nested, repeating structure. We show how such graphs that are the result of nested repetition can be represented by succinct parametric structures. This parametric graph template representation allows us to reason about the execution graph of a parallel program at a cost that only depends on the program size. We develop structurally-parametric polynomial-time algorithm variants of maximum flows. When the graph models a parallel loop program, the maximum flow provides a bound on the data movement during an execution of the program. By reasoning about the structure of the repeating subgraphs, we avoid explicit construction of the instantiation (e.g., the execution graph), potentially saving an exponential amount of memory and computation. Hence, our approach enables graph-based dataflow analysis in previously intractable settings.","sentences":["Execution graphs of parallel loop programs exhibit a nested, repeating structure.","We show how such graphs that are the result of nested repetition can be represented by succinct parametric structures.","This parametric graph template representation allows us to reason about the execution graph of a parallel program at a cost that only depends on the program size.","We develop structurally-parametric polynomial-time algorithm variants of maximum flows.","When the graph models a parallel loop program, the maximum flow provides a bound on the data movement during an execution of the program.","By reasoning about the structure of the repeating subgraphs, we avoid explicit construction of the instantiation (e.g., the execution graph), potentially saving an exponential amount of memory and computation.","Hence, our approach enables graph-based dataflow analysis in previously intractable settings."],"url":"http://arxiv.org/abs/2307.08420v1"}
{"created":"2023-07-17 11:57:04","title":"Divide&Classify: Fine-Grained Classification for City-Wide Visual Place Recognition","abstract":"Visual Place recognition is commonly addressed as an image retrieval problem. However, retrieval methods are impractical to scale to large datasets, densely sampled from city-wide maps, since their dimension impact negatively on the inference time. Using approximate nearest neighbour search for retrieval helps to mitigate this issue, at the cost of a performance drop. In this paper we investigate whether we can effectively approach this task as a classification problem, thus bypassing the need for a similarity search. We find that existing classification methods for coarse, planet-wide localization are not suitable for the fine-grained and city-wide setting. This is largely due to how the dataset is split into classes, because these methods are designed to handle a sparse distribution of photos and as such do not consider the visual aliasing problem across neighbouring classes that naturally arises in dense scenarios. Thus, we propose a partitioning scheme that enables a fast and accurate inference, preserving a simple learning procedure, and a novel inference pipeline based on an ensemble of novel classifiers that uses the prototypes learned via an angular margin loss. Our method, Divide&Classify (D&C), enjoys the fast inference of classification solutions and an accuracy competitive with retrieval methods on the fine-grained, city-wide setting. Moreover, we show that D&C can be paired with existing retrieval pipelines to speed up computations by over 20 times while increasing their recall, leading to new state-of-the-art results.","sentences":["Visual Place recognition is commonly addressed as an image retrieval problem.","However, retrieval methods are impractical to scale to large datasets, densely sampled from city-wide maps, since their dimension impact negatively on the inference time.","Using approximate nearest neighbour search for retrieval helps to mitigate this issue, at the cost of a performance drop.","In this paper we investigate whether we can effectively approach this task as a classification problem, thus bypassing the need for a similarity search.","We find that existing classification methods for coarse, planet-wide localization are not suitable for the fine-grained and city-wide setting.","This is largely due to how the dataset is split into classes, because these methods are designed to handle a sparse distribution of photos and as such do not consider the visual aliasing problem across neighbouring classes that naturally arises in dense scenarios.","Thus, we propose a partitioning scheme that enables a fast and accurate inference, preserving a simple learning procedure, and a novel inference pipeline based on an ensemble of novel classifiers that uses the prototypes learned via an angular margin loss.","Our method, Divide&Classify (D&C), enjoys the fast inference of classification solutions and an accuracy competitive with retrieval methods on the fine-grained, city-wide setting.","Moreover, we show that D&C can be paired with existing retrieval pipelines to speed up computations by over 20 times while increasing their recall, leading to new state-of-the-art results."],"url":"http://arxiv.org/abs/2307.08417v1"}
{"created":"2023-07-17 11:56:32","title":"Enhancing Supervised Learning with Contrastive Markings in Neural Machine Translation Training","abstract":"Supervised learning in Neural Machine Translation (NMT) typically follows a teacher forcing paradigm where reference tokens constitute the conditioning context in the model's prediction, instead of its own previous predictions. In order to alleviate this lack of exploration in the space of translations, we present a simple extension of standard maximum likelihood estimation by a contrastive marking objective. The additional training signals are extracted automatically from reference translations by comparing the system hypothesis against the reference, and used for up/down-weighting correct/incorrect tokens. The proposed new training procedure requires one additional translation pass over the training set per epoch, and does not alter the standard inference setup. We show that training with contrastive markings yields improvements on top of supervised learning, and is especially useful when learning from postedits where contrastive markings indicate human error corrections to the original hypotheses. Code is publicly released.","sentences":["Supervised learning in Neural Machine Translation (NMT) typically follows a teacher forcing paradigm where reference tokens constitute the conditioning context in the model's prediction, instead of its own previous predictions.","In order to alleviate this lack of exploration in the space of translations, we present a simple extension of standard maximum likelihood estimation by a contrastive marking objective.","The additional training signals are extracted automatically from reference translations by comparing the system hypothesis against the reference, and used for up/down-weighting correct/incorrect tokens.","The proposed new training procedure requires one additional translation pass over the training set per epoch, and does not alter the standard inference setup.","We show that training with contrastive markings yields improvements on top of supervised learning, and is especially useful when learning from postedits where contrastive markings indicate human error corrections to the original hypotheses.","Code is publicly released."],"url":"http://arxiv.org/abs/2307.08416v1"}
{"created":"2023-07-17 11:55:27","title":"Monocular 3D Object Detection with LiDAR Guided Semi Supervised Active Learning","abstract":"We propose a novel semi-supervised active learning (SSAL) framework for monocular 3D object detection with LiDAR guidance (MonoLiG), which leverages all modalities of collected data during model development. We utilize LiDAR to guide the data selection and training of monocular 3D detectors without introducing any overhead in the inference phase. During training, we leverage the LiDAR teacher, monocular student cross-modal framework from semi-supervised learning to distill information from unlabeled data as pseudo-labels. To handle the differences in sensor characteristics, we propose a data noise-based weighting mechanism to reduce the effect of propagating noise from LiDAR modality to monocular. For selecting which samples to label to improve the model performance, we propose a sensor consistency-based selection score that is also coherent with the training objective. Extensive experimental results on KITTI and Waymo datasets verify the effectiveness of our proposed framework. In particular, our selection strategy consistently outperforms state-of-the-art active learning baselines, yielding up to 17% better saving rate in labeling costs. Our training strategy attains the top place in KITTI 3D and birds-eye-view (BEV) monocular object detection official benchmarks by improving the BEV Average Precision (AP) by 2.02.","sentences":["We propose a novel semi-supervised active learning (SSAL) framework for monocular 3D object detection with LiDAR guidance (MonoLiG), which leverages all modalities of collected data during model development.","We utilize LiDAR to guide the data selection and training of monocular 3D detectors without introducing any overhead in the inference phase.","During training, we leverage the LiDAR teacher, monocular student cross-modal framework from semi-supervised learning to distill information from unlabeled data as pseudo-labels.","To handle the differences in sensor characteristics, we propose a data noise-based weighting mechanism to reduce the effect of propagating noise from LiDAR modality to monocular.","For selecting which samples to label to improve the model performance, we propose a sensor consistency-based selection score that is also coherent with the training objective.","Extensive experimental results on KITTI and Waymo datasets verify the effectiveness of our proposed framework.","In particular, our selection strategy consistently outperforms state-of-the-art active learning baselines, yielding up to 17% better saving rate in labeling costs.","Our training strategy attains the top place in KITTI 3D and birds-eye-view (BEV) monocular object detection official benchmarks by improving the BEV Average Precision (AP) by 2.02."],"url":"http://arxiv.org/abs/2307.08415v1"}
{"created":"2023-07-17 11:55:20","title":"Active Learning for Object Detection with Non-Redundant Informative Sampling","abstract":"Curating an informative and representative dataset is essential for enhancing the performance of 2D object detectors. We present a novel active learning sampling strategy that addresses both the informativeness and diversity of the selections. Our strategy integrates uncertainty and diversity-based selection principles into a joint selection objective by measuring the collective information score of the selected samples. Specifically, our proposed NORIS algorithm quantifies the impact of training with a sample on the informativeness of other similar samples. By exclusively selecting samples that are simultaneously informative and distant from other highly informative samples, we effectively avoid redundancy while maintaining a high level of informativeness. Moreover, instead of utilizing whole image features to calculate distances between samples, we leverage features extracted from detected object regions within images to define object features. This allows us to construct a dataset encompassing diverse object types, shapes, and angles. Extensive experiments on object detection and image classification tasks demonstrate the effectiveness of our strategy over the state-of-the-art baselines. Specifically, our selection strategy achieves a 20% and 30% reduction in labeling costs compared to random selection for PASCAL-VOC and KITTI, respectively.","sentences":["Curating an informative and representative dataset is essential for enhancing the performance of 2D object detectors.","We present a novel active learning sampling strategy that addresses both the informativeness and diversity of the selections.","Our strategy integrates uncertainty and diversity-based selection principles into a joint selection objective by measuring the collective information score of the selected samples.","Specifically, our proposed NORIS algorithm quantifies the impact of training with a sample on the informativeness of other similar samples.","By exclusively selecting samples that are simultaneously informative and distant from other highly informative samples, we effectively avoid redundancy while maintaining a high level of informativeness.","Moreover, instead of utilizing whole image features to calculate distances between samples, we leverage features extracted from detected object regions within images to define object features.","This allows us to construct a dataset encompassing diverse object types, shapes, and angles.","Extensive experiments on object detection and image classification tasks demonstrate the effectiveness of our strategy over the state-of-the-art baselines.","Specifically, our selection strategy achieves a 20% and 30% reduction in labeling costs compared to random selection for PASCAL-VOC and KITTI, respectively."],"url":"http://arxiv.org/abs/2307.08414v1"}
{"created":"2023-07-17 11:48:39","title":"A Privacy-Preserving Blockchain-based E-voting System","abstract":"Within a modern democratic nation, elections play a significant role in the nation's functioning. However, with the existing infrastructure for conducting elections using Electronic Voting Systems (EVMs), many loopholes exist, which illegitimate entities might leverage to cast false votes or even tamper with the EVMs after the voting session is complete. The need of the hour is to introduce a robust, auditable, transparent, and tamper-proof e-voting system, enabling a more reliable and fair election process. To address such concerns, we propose a novel solution for blockchain-based e-voting, focusing on the security and privacy aspects of the e-voting process. We consider the security risks and loopholes and aim to preserve the anonymity of the voters while ensuring that illegitimate votes are properly handled. Additionally, we develop a prototype as a proof of concept using the Ethereum blockchain platform. Finally, we perform experiments to demonstrate the performance of the system.","sentences":["Within a modern democratic nation, elections play a significant role in the nation's functioning.","However, with the existing infrastructure for conducting elections using Electronic Voting Systems (EVMs), many loopholes exist, which illegitimate entities might leverage to cast false votes or even tamper with the EVMs after the voting session is complete.","The need of the hour is to introduce a robust, auditable, transparent, and tamper-proof e-voting system, enabling a more reliable and fair election process.","To address such concerns, we propose a novel solution for blockchain-based e-voting, focusing on the security and privacy aspects of the e-voting process.","We consider the security risks and loopholes and aim to preserve the anonymity of the voters while ensuring that illegitimate votes are properly handled.","Additionally, we develop a prototype as a proof of concept using the Ethereum blockchain platform.","Finally, we perform experiments to demonstrate the performance of the system."],"url":"http://arxiv.org/abs/2307.08412v1"}
{"created":"2023-07-17 11:47:05","title":"Neurosymbolic AI for Reasoning on Biomedical Knowledge Graphs","abstract":"Biomedical datasets are often modeled as knowledge graphs (KGs) because they capture the multi-relational, heterogeneous, and dynamic natures of biomedical systems. KG completion (KGC), can, therefore, help researchers make predictions to inform tasks like drug repositioning. While previous approaches for KGC were either rule-based or embedding-based, hybrid approaches based on neurosymbolic artificial intelligence are becoming more popular. Many of these methods possess unique characteristics which make them even better suited toward biomedical challenges. Here, we survey such approaches with an emphasis on their utilities and prospective benefits for biomedicine.","sentences":["Biomedical datasets are often modeled as knowledge graphs (KGs) because they capture the multi-relational, heterogeneous, and dynamic natures of biomedical systems.","KG completion (KGC), can, therefore, help researchers make predictions to inform tasks like drug repositioning.","While previous approaches for KGC were either rule-based or embedding-based, hybrid approaches based on neurosymbolic artificial intelligence are becoming more popular.","Many of these methods possess unique characteristics which make them even better suited toward biomedical challenges.","Here, we survey such approaches with an emphasis on their utilities and prospective benefits for biomedicine."],"url":"http://arxiv.org/abs/2307.08411v1"}
{"created":"2023-07-17 11:36:15","title":"A Novel Multiagent Flexibility Aggregation Framework","abstract":"The increasing number of Distributed Energy Resources (DERs) in the emerging Smart Grid, has created an imminent need for intelligent multiagent frameworks able to utilize these assets efficiently. In this paper, we propose a novel DER aggregation framework, encompassing a multiagent architecture and various types of mechanisms for the effective management and efficient integration of DERs in the Grid. One critical component of our architecture is the Local Flexibility Estimators (LFEs) agents, which are key for offloading the Aggregator from serious or resource-intensive responsibilities -- such as addressing privacy concerns and predicting the accuracy of DER statements regarding their offered demand response services. The proposed framework allows the formation of efficient LFE cooperatives. To this end, we developed and deployed a variety of cooperative member selection mechanisms, including (a) scoring rules, and (b) (deep) reinforcement learning. We use data from the well-known PowerTAC simulator to systematically evaluate our framework. Our experiments verify its effectiveness for incorporating heterogeneous DERs into the Grid in an efficient manner. In particular, when using the well-known probabilistic prediction accuracy-incentivizing CRPS scoring rule as a selection mechanism, our framework results in increased average payments for participants, when compared with traditional commercial aggregators.","sentences":["The increasing number of Distributed Energy Resources (DERs) in the emerging Smart Grid, has created an imminent need for intelligent multiagent frameworks able to utilize these assets efficiently.","In this paper, we propose a novel DER aggregation framework, encompassing a multiagent architecture and various types of mechanisms for the effective management and efficient integration of DERs in the Grid.","One critical component of our architecture is the Local Flexibility Estimators (LFEs) agents, which are key for offloading the Aggregator from serious or resource-intensive responsibilities -- such as addressing privacy concerns and predicting the accuracy of DER statements regarding their offered demand response services.","The proposed framework allows the formation of efficient LFE cooperatives.","To this end, we developed and deployed a variety of cooperative member selection mechanisms, including (a) scoring rules, and (b) (deep) reinforcement learning.","We use data from the well-known PowerTAC simulator to systematically evaluate our framework.","Our experiments verify its effectiveness for incorporating heterogeneous DERs into the Grid in an efficient manner.","In particular, when using the well-known probabilistic prediction accuracy-incentivizing CRPS scoring rule as a selection mechanism, our framework results in increased average payments for participants, when compared with traditional commercial aggregators."],"url":"http://arxiv.org/abs/2307.08401v1"}
{"created":"2023-07-17 11:29:48","title":"CLIP-Guided StyleGAN Inversion for Text-Driven Real Image Editing","abstract":"Researchers have recently begun exploring the use of StyleGAN-based models for real image editing. One particularly interesting application is using natural language descriptions to guide the editing process. Existing approaches for editing images using language either resort to instance-level latent code optimization or map predefined text prompts to some editing directions in the latent space. However, these approaches have inherent limitations. The former is not very efficient, while the latter often struggles to effectively handle multi-attribute changes. To address these weaknesses, we present CLIPInverter, a new text-driven image editing approach that is able to efficiently and reliably perform multi-attribute changes. The core of our method is the use of novel, lightweight text-conditioned adapter layers integrated into pretrained GAN-inversion networks. We demonstrate that by conditioning the initial inversion step on the CLIP embedding of the target description, we are able to obtain more successful edit directions. Additionally, we use a CLIP-guided refinement step to make corrections in the resulting residual latent codes, which further improves the alignment with the text prompt. Our method outperforms competing approaches in terms of manipulation accuracy and photo-realism on various domains including human faces, cats, and birds, as shown by our qualitative and quantitative results.","sentences":["Researchers have recently begun exploring the use of StyleGAN-based models for real image editing.","One particularly interesting application is using natural language descriptions to guide the editing process.","Existing approaches for editing images using language either resort to instance-level latent code optimization or map predefined text prompts to some editing directions in the latent space.","However, these approaches have inherent limitations.","The former is not very efficient, while the latter often struggles to effectively handle multi-attribute changes.","To address these weaknesses, we present CLIPInverter, a new text-driven image editing approach that is able to efficiently and reliably perform multi-attribute changes.","The core of our method is the use of novel, lightweight text-conditioned adapter layers integrated into pretrained GAN-inversion networks.","We demonstrate that by conditioning the initial inversion step on the CLIP embedding of the target description, we are able to obtain more successful edit directions.","Additionally, we use a CLIP-guided refinement step to make corrections in the resulting residual latent codes, which further improves the alignment with the text prompt.","Our method outperforms competing approaches in terms of manipulation accuracy and photo-realism on various domains including human faces, cats, and birds, as shown by our qualitative and quantitative results."],"url":"http://arxiv.org/abs/2307.08397v1"}
{"created":"2023-07-17 11:12:56","title":"On the application of Large Language Models for language teaching and assessment technology","abstract":"The recent release of very large language models such as PaLM and GPT-4 has made an unprecedented impact in the popular media and public consciousness, giving rise to a mixture of excitement and fear as to their capabilities and potential uses, and shining a light on natural language processing research which had not previously received so much attention. The developments offer great promise for education technology, and in this paper we look specifically at the potential for incorporating large language models in AI-driven language teaching and assessment systems. We consider several research areas and also discuss the risks and ethical considerations surrounding generative AI in education technology for language learners. Overall we find that larger language models offer improvements over previous models in text generation, opening up routes toward content generation which had not previously been plausible. For text generation they must be prompted carefully and their outputs may need to be reshaped before they are ready for use. For automated grading and grammatical error correction, tasks whose progress is checked on well-known benchmarks, early investigations indicate that large language models on their own do not improve on state-of-the-art results according to standard evaluation metrics. For grading it appears that linguistic features established in the literature should still be used for best performance, and for error correction it may be that the models can offer alternative feedback styles which are not measured sensitively with existing methods. In all cases, there is work to be done to experiment with the inclusion of large language models in education technology for language learners, in order to properly understand and report on their capacities and limitations, and to ensure that foreseeable risks such as misinformation and harmful bias are mitigated.","sentences":["The recent release of very large language models such as PaLM and GPT-4 has made an unprecedented impact in the popular media and public consciousness, giving rise to a mixture of excitement and fear as to their capabilities and potential uses, and shining a light on natural language processing research which had not previously received so much attention.","The developments offer great promise for education technology, and in this paper we look specifically at the potential for incorporating large language models in AI-driven language teaching and assessment systems.","We consider several research areas and also discuss the risks and ethical considerations surrounding generative AI in education technology for language learners.","Overall we find that larger language models offer improvements over previous models in text generation, opening up routes toward content generation which had not previously been plausible.","For text generation they must be prompted carefully and their outputs may need to be reshaped before they are ready for use.","For automated grading and grammatical error correction, tasks whose progress is checked on well-known benchmarks, early investigations indicate that large language models on their own do not improve on state-of-the-art results according to standard evaluation metrics.","For grading it appears that linguistic features established in the literature should still be used for best performance, and for error correction it may be that the models can offer alternative feedback styles which are not measured sensitively with existing methods.","In all cases, there is work to be done to experiment with the inclusion of large language models in education technology for language learners, in order to properly understand and report on their capacities and limitations, and to ensure that foreseeable risks such as misinformation and harmful bias are mitigated."],"url":"http://arxiv.org/abs/2307.08393v1"}
{"created":"2023-07-17 11:04:27","title":"Correlation-aware Spatial-Temporal Graph Learning for Multivariate Time-series Anomaly Detection","abstract":"Multivariate time-series anomaly detection is critically important in many applications, including retail, transportation, power grid, and water treatment plants. Existing approaches for this problem mostly employ either statistical models which cannot capture the non-linear relations well or conventional deep learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise correlations among variables. To overcome these limitations, we propose a novel method, correlation-aware spatial-temporal graph learning (termed CST-GL), for time series anomaly detection. CST-GL explicitly captures the pairwise correlations via a multivariate time series correlation learning module based on which a spatial-temporal graph neural network (STGNN) can be developed. Then, by employing a graph convolution network that exploits one- and multi-hop neighbor information, our STGNN component can encode rich spatial information from complex pairwise dependencies between variables. With a temporal module that consists of dilated convolutional functions, the STGNN can further capture long-range dependence over time. A novel anomaly scoring component is further integrated into CST-GL to estimate the degree of an anomaly in a purely unsupervised manner. Experimental results demonstrate that CST-GL can detect anomalies effectively in general settings as well as enable early detection across different time delays.","sentences":["Multivariate time-series anomaly detection is critically important in many applications, including retail, transportation, power grid, and water treatment plants.","Existing approaches for this problem mostly employ either statistical models which cannot capture the non-linear relations well or conventional deep learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise correlations among variables.","To overcome these limitations, we propose a novel method, correlation-aware spatial-temporal graph learning (termed CST-GL), for time series anomaly detection.","CST-GL explicitly captures the pairwise correlations via a multivariate time series correlation learning module based on which a spatial-temporal graph neural network (STGNN) can be developed.","Then, by employing a graph convolution network that exploits one-","and multi-hop neighbor information, our STGNN component can encode rich spatial information from complex pairwise dependencies between variables.","With a temporal module that consists of dilated convolutional functions, the STGNN can further capture long-range dependence over time.","A novel anomaly scoring component is further integrated into CST-GL to estimate the degree of an anomaly in a purely unsupervised manner.","Experimental results demonstrate that CST-GL can detect anomalies effectively in general settings as well as enable early detection across different time delays."],"url":"http://arxiv.org/abs/2307.08390v1"}
{"created":"2023-07-17 10:55:58","title":"Dynamic Snake Convolution based on Topological Geometric Constraints for Tubular Structure Segmentation","abstract":"Accurate segmentation of topological tubular structures, such as blood vessels and roads, is crucial in various fields, ensuring accuracy and efficiency in downstream tasks. However, many factors complicate the task, including thin local structures and variable global morphologies. In this work, we note the specificity of tubular structures and use this knowledge to guide our DSCNet to simultaneously enhance perception in three stages: feature extraction, feature fusion, and loss constraint. First, we propose a dynamic snake convolution to accurately capture the features of tubular structures by adaptively focusing on slender and tortuous local structures. Subsequently, we propose a multi-view feature fusion strategy to complement the attention to features from multiple perspectives during feature fusion, ensuring the retention of important information from different global morphologies. Finally, a continuity constraint loss function, based on persistent homology, is proposed to constrain the topological continuity of the segmentation better. Experiments on 2D and 3D datasets show that our DSCNet provides better accuracy and continuity on the tubular structure segmentation task compared with several methods. Our codes will be publicly available.","sentences":["Accurate segmentation of topological tubular structures, such as blood vessels and roads, is crucial in various fields, ensuring accuracy and efficiency in downstream tasks.","However, many factors complicate the task, including thin local structures and variable global morphologies.","In this work, we note the specificity of tubular structures and use this knowledge to guide our DSCNet to simultaneously enhance perception in three stages: feature extraction, feature fusion, and loss constraint.","First, we propose a dynamic snake convolution to accurately capture the features of tubular structures by adaptively focusing on slender and tortuous local structures.","Subsequently, we propose a multi-view feature fusion strategy to complement the attention to features from multiple perspectives during feature fusion, ensuring the retention of important information from different global morphologies.","Finally, a continuity constraint loss function, based on persistent homology, is proposed to constrain the topological continuity of the segmentation better.","Experiments on 2D and 3D datasets show that our DSCNet provides better accuracy and continuity on the tubular structure segmentation task compared with several methods.","Our codes will be publicly available."],"url":"http://arxiv.org/abs/2307.08388v1"}
{"created":"2023-07-17 10:50:09","title":"Tabular Machine Learning Methods for Predicting Gas Turbine Emissions","abstract":"Predicting emissions for gas turbines is critical for monitoring harmful pollutants being released into the atmosphere. In this study, we evaluate the performance of machine learning models for predicting emissions for gas turbines. We compare an existing predictive emissions model, a first principles-based Chemical Kinetics model, against two machine learning models we developed based on SAINT and XGBoost, to demonstrate improved predictive performance of nitrogen oxides (NOx) and carbon monoxide (CO) using machine learning techniques. Our analysis utilises a Siemens Energy gas turbine test bed tabular dataset to train and validate the machine learning models. Additionally, we explore the trade-off between incorporating more features to enhance the model complexity, and the resulting presence of increased missing values in the dataset.","sentences":["Predicting emissions for gas turbines is critical for monitoring harmful pollutants being released into the atmosphere.","In this study, we evaluate the performance of machine learning models for predicting emissions for gas turbines.","We compare an existing predictive emissions model, a first principles-based Chemical Kinetics model, against two machine learning models we developed based on SAINT and XGBoost, to demonstrate improved predictive performance of nitrogen oxides (NOx) and carbon monoxide (CO) using machine learning techniques.","Our analysis utilises a Siemens Energy gas turbine test bed tabular dataset to train and validate the machine learning models.","Additionally, we explore the trade-off between incorporating more features to enhance the model complexity, and the resulting presence of increased missing values in the dataset."],"url":"http://arxiv.org/abs/2307.08386v1"}
{"created":"2023-07-17 10:43:54","title":"Distributed bundle adjustment with block-based sparse matrix compression for super large scale datasets","abstract":"We propose a distributed bundle adjustment (DBA) method using the exact Levenberg-Marquardt (LM) algorithm for super large-scale datasets. Most of the existing methods partition the global map to small ones and conduct bundle adjustment in the submaps. In order to fit the parallel framework, they use approximate solutions instead of the LM algorithm. However, those methods often give sub-optimal results. Different from them, we utilize the exact LM algorithm to conduct global bundle adjustment where the formation of the reduced camera system (RCS) is actually parallelized and executed in a distributed way. To store the large RCS, we compress it with a block-based sparse matrix compression format (BSMC), which fully exploits its block feature. The BSMC format also enables the distributed storage and updating of the global RCS. The proposed method is extensively evaluated and compared with the state-of-the-art pipelines using both synthetic and real datasets. Preliminary results demonstrate the efficient memory usage and vast scalability of the proposed method compared with the baselines. For the first time, we conducted parallel bundle adjustment using LM algorithm on a real datasets with 1.18 million images and a synthetic dataset with 10 million images (about 500 times that of the state-of-the-art LM-based BA) on a distributed computing system.","sentences":["We propose a distributed bundle adjustment (DBA) method using the exact Levenberg-Marquardt (LM) algorithm for super large-scale datasets.","Most of the existing methods partition the global map to small ones and conduct bundle adjustment in the submaps.","In order to fit the parallel framework, they use approximate solutions instead of the LM algorithm.","However, those methods often give sub-optimal results.","Different from them, we utilize the exact LM algorithm to conduct global bundle adjustment where the formation of the reduced camera system (RCS) is actually parallelized and executed in a distributed way.","To store the large RCS, we compress it with a block-based sparse matrix compression format (BSMC), which fully exploits its block feature.","The BSMC format also enables the distributed storage and updating of the global RCS.","The proposed method is extensively evaluated and compared with the state-of-the-art pipelines using both synthetic and real datasets.","Preliminary results demonstrate the efficient memory usage and vast scalability of the proposed method compared with the baselines.","For the first time, we conducted parallel bundle adjustment using LM algorithm on a real datasets with 1.18 million images and a synthetic dataset with 10 million images (about 500 times that of the state-of-the-art LM-based BA) on a distributed computing system."],"url":"http://arxiv.org/abs/2307.08383v1"}
{"created":"2023-07-17 10:42:21","title":"Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data","abstract":"Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing. However, manufacturing variability and usage-dependent degradation make life prediction challenging. Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge. Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling. The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime. Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data, for most cells. Further testing using a hierarchical Bayesian regression model shows improved performance on extrapolation, achieving 21.8% mean absolute percentage error for out-of-distribution cells. Our approach highlights the importance of using domain knowledge of lithium-ion battery degradation modes to inform feature engineering. Further, we provide the community with a new publicly available battery aging dataset with cells cycled beyond 80% of their rated capacity.","sentences":["Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing.","However, manufacturing variability and usage-dependent degradation make life prediction challenging.","Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge.","Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling.","The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime.","Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data, for most cells.","Further testing using a hierarchical Bayesian regression model shows improved performance on extrapolation, achieving 21.8% mean absolute percentage error for out-of-distribution cells.","Our approach highlights the importance of using domain knowledge of lithium-ion battery degradation modes to inform feature engineering.","Further, we provide the community with a new publicly available battery aging dataset with cells cycled beyond 80% of their rated capacity."],"url":"http://arxiv.org/abs/2307.08382v1"}
{"created":"2023-07-17 10:39:57","title":"2P-BFT-Log: 2-Phases Single-Author Append-Only Log for Adversarial Environments","abstract":"Replicated append-only logs sequentially order messages from the same author such that their ordering can be eventually recovered even with out-of-order and unreliable dissemination of individual messages. They are widely used for implementing replicated services in both clouds and peer-to-peer environments because they provide simple and efficient incremental reconciliation. However, existing designs of replicated append-only logs assume replicas faithfully maintain the sequential properties of logs and do not provide eventual consistency when malicious participants fork their logs by disseminating different messages to different replicas for the same index, which may result in partitioning of replicas according to which branch was first replicated.   In this paper, we present 2P-BFT-Log, a two-phases replicated append-only log that provides eventual consistency in the presence of forks from malicious participants such that all correct replicas will eventually agree either on the most recent message of a valid log (first phase) or on the earliest point at which a fork occurred as well as on an irrefutable proof that it happened (second phase). We provide definitions, algorithms, and proofs of the key properties of the design, and explain one way to implement the design onto Git, an eventually consistent replicated database originally designed for distributed version control.   Our design enables correct replicas to faithfully implement the happens-before relationship first introduced by Lamport that underpins most existing distributed algorithms, with eventual detection of forks from malicious participants to exclude the latter from further progress. This opens the door to adaptations of existing distributed algorithms to a cheaper detect and repair paradigm, rather than the more common and expensive systematic prevention of incorrect behaviour.","sentences":["Replicated append-only logs sequentially order messages from the same author such that their ordering can be eventually recovered even with out-of-order and unreliable dissemination of individual messages.","They are widely used for implementing replicated services in both clouds and peer-to-peer environments because they provide simple and efficient incremental reconciliation.","However, existing designs of replicated append-only logs assume replicas faithfully maintain the sequential properties of logs and do not provide eventual consistency when malicious participants fork their logs by disseminating different messages to different replicas for the same index, which may result in partitioning of replicas according to which branch was first replicated.   ","In this paper, we present 2P-BFT-Log, a two-phases replicated append-only log that provides eventual consistency in the presence of forks from malicious participants such that all correct replicas will eventually agree either on the most recent message of a valid log (first phase) or on the earliest point at which a fork occurred as well as on an irrefutable proof that it happened (second phase).","We provide definitions, algorithms, and proofs of the key properties of the design, and explain one way to implement the design onto Git, an eventually consistent replicated database originally designed for distributed version control.   ","Our design enables correct replicas to faithfully implement the happens-before relationship first introduced by Lamport that underpins most existing distributed algorithms, with eventual detection of forks from malicious participants to exclude the latter from further progress.","This opens the door to adaptations of existing distributed algorithms to a cheaper detect and repair paradigm, rather than the more common and expensive systematic prevention of incorrect behaviour."],"url":"http://arxiv.org/abs/2307.08381v1"}
{"created":"2023-07-17 10:32:51","title":"eGPU: A 750 MHz Class Soft GPGPU for FPGA","abstract":"This paper introduces the eGPU, a SIMT soft processor designed for FPGAs. Soft processors typically achieve modest operating frequencies, a fraction of the headline performance claimed by modern FPGA families, and obtain correspondingly modest performance results. We propose a GPGPU architecture structured specifically to take advantage of both the soft logic and embedded features of the FPGA. We also consider the physical location of the embedded memories and DSP Blocks relative to the location and number of soft logic elements in order to have a design with balanced resources. Our goal is to create a high performance soft processor able to implement complex portions of FPGA system designs, such as the linear solvers commonly used in wireless systems, through push-button compilation from software. The eGPU architecture is a streaming multiprocessor (SM) machine with 512 threads. Each SM contains 16 scalar processors (SP). Both IEEE754 FP32 and INT32 integer arithmetic are supported. We demonstrate a single SM eGPU in an Intel Agilex device, requiring 5600 ALMs and 24 DSP Blocks, which closes timing at over 770 MHz from a completely unconstrained compile. Multiple eGPUs can also be tightly packed together into a single Agilex FPGA logic region, with minimal speed penalty.","sentences":["This paper introduces the eGPU, a SIMT soft processor designed for FPGAs.","Soft processors typically achieve modest operating frequencies, a fraction of the headline performance claimed by modern FPGA families, and obtain correspondingly modest performance results.","We propose a GPGPU architecture structured specifically to take advantage of both the soft logic and embedded features of the FPGA.","We also consider the physical location of the embedded memories and DSP Blocks relative to the location and number of soft logic elements in order to have a design with balanced resources.","Our goal is to create a high performance soft processor able to implement complex portions of FPGA system designs, such as the linear solvers commonly used in wireless systems, through push-button compilation from software.","The eGPU architecture is a streaming multiprocessor (SM) machine with 512 threads.","Each SM contains 16 scalar processors (SP).","Both IEEE754 FP32 and INT32 integer arithmetic are supported.","We demonstrate a single SM eGPU in an Intel Agilex device, requiring 5600 ALMs and 24 DSP Blocks, which closes timing at over 770 MHz from a completely unconstrained compile.","Multiple eGPUs can also be tightly packed together into a single Agilex FPGA logic region, with minimal speed penalty."],"url":"http://arxiv.org/abs/2307.08378v1"}
{"created":"2023-07-17 10:10:33","title":"Quantum Graph Drawing","abstract":"In this paper, we initiate the study of quantum algorithms in the Graph Drawing research area. We focus on two foundational drawing standards: 2-level drawings and book layouts. Concerning $2$-level drawings, we consider the problems of obtaining drawings with the minimum number of crossings, $k$-planar drawings, quasi-planar drawings, and the problem of removing the minimum number of edges to obtain a $2$-level planar graph. Concerning book layouts, we consider the problems of obtaining $1$-page book layouts with the minimum number of crossings, book embeddings with the minimum number of pages, and the problem of removing the minimum number of edges to obtain an outerplanar graph. We explore both the quantum circuit and the quantum annealing models of computation. In the quantum circuit model, we provide an algorithmic framework based on Grover's quantum search, which allows us to obtain, at least, a quadratic speedup on the best classical exact algorithms for all the considered problems. In the quantum annealing model, we perform experiments on the quantum processing unit provided by D-Wave, focusing on the classical $2$-level crossing minimization problem, demonstrating that quantum annealing is competitive with respect to classical algorithms.","sentences":["In this paper, we initiate the study of quantum algorithms in the Graph Drawing research area.","We focus on two foundational drawing standards: 2-level drawings and book layouts.","Concerning $2$-level drawings, we consider the problems of obtaining drawings with the minimum number of crossings, $k$-planar drawings, quasi-planar drawings, and the problem of removing the minimum number of edges to obtain a $2$-level planar graph.","Concerning book layouts, we consider the problems of obtaining $1$-page book layouts with the minimum number of crossings, book embeddings with the minimum number of pages, and the problem of removing the minimum number of edges to obtain an outerplanar graph.","We explore both the quantum circuit and the quantum annealing models of computation.","In the quantum circuit model, we provide an algorithmic framework based on Grover's quantum search, which allows us to obtain, at least, a quadratic speedup on the best classical exact algorithms for all the considered problems.","In the quantum annealing model, we perform experiments on the quantum processing unit provided by D-Wave, focusing on the classical $2$-level crossing minimization problem, demonstrating that quantum annealing is competitive with respect to classical algorithms."],"url":"http://arxiv.org/abs/2307.08371v1"}
{"created":"2023-07-17 10:06:21","title":"Gender mobility in the labor market with skills-based matching models","abstract":"Skills-based matching promises mobility of workers between different sectors and occupations in the labor market. In this case, job seekers can look for jobs they do not yet have experience in, but for which they do have relevant skills. Currently, there are multiple occupations with a skewed gender distribution. For skills-based matching, it is unclear if and how a shift in the gender distribution, which we call gender mobility, between occupations will be effected. It is expected that the skills-based matching approach will likely be data-driven, including computational language models and supervised learning methods.   This work, first, shows the presence of gender segregation in language model-based skills representation of occupations. Second, we assess the use of these representations in a potential application based on simulated data, and show that the gender segregation is propagated by various data-driven skills-based matching models.These models are based on different language representations (bag of words, word2vec, and BERT), and distance metrics (static and machine learning-based). Accordingly, we show how skills-based matching approaches can be evaluated and compared on matching performance as well as on the risk of gender segregation. Making the gender segregation bias of models more explicit can help in generating healthy trust in the use of these models in practice.","sentences":["Skills-based matching promises mobility of workers between different sectors and occupations in the labor market.","In this case, job seekers can look for jobs they do not yet have experience in, but for which they do have relevant skills.","Currently, there are multiple occupations with a skewed gender distribution.","For skills-based matching, it is unclear if and how a shift in the gender distribution, which we call gender mobility, between occupations will be effected.","It is expected that the skills-based matching approach will likely be data-driven, including computational language models and supervised learning methods.   ","This work, first, shows the presence of gender segregation in language model-based skills representation of occupations.","Second, we assess the use of these representations in a potential application based on simulated data, and show that the gender segregation is propagated by various data-driven skills-based matching models.","These models are based on different language representations (bag of words, word2vec, and BERT), and distance metrics (static and machine learning-based).","Accordingly, we show how skills-based matching approaches can be evaluated and compared on matching performance as well as on the risk of gender segregation.","Making the gender segregation bias of models more explicit can help in generating healthy trust in the use of these models in practice."],"url":"http://arxiv.org/abs/2307.08368v1"}
{"created":"2023-07-17 10:02:01","title":"Q(D)O-ES: Population-based Quality (Diversity) Optimisation for Post Hoc Ensemble Selection in AutoML","abstract":"Automated machine learning (AutoML) systems commonly ensemble models post hoc to improve predictive performance, typically via greedy ensemble selection (GES). However, we believe that GES may not always be optimal, as it performs a simple deterministic greedy search. In this work, we introduce two novel population-based ensemble selection methods, QO-ES and QDO-ES, and compare them to GES. While QO-ES optimises solely for predictive performance, QDO-ES also considers the diversity of ensembles within the population, maintaining a diverse set of well-performing ensembles during optimisation based on ideas of quality diversity optimisation. The methods are evaluated using 71 classification datasets from the AutoML benchmark, demonstrating that QO-ES and QDO-ES often outrank GES, albeit only statistically significant on validation data. Our results further suggest that diversity can be beneficial for post hoc ensembling but also increases the risk of overfitting.","sentences":["Automated machine learning (AutoML) systems commonly ensemble models post hoc to improve predictive performance, typically via greedy ensemble selection (GES).","However, we believe that GES may not always be optimal, as it performs a simple deterministic greedy search.","In this work, we introduce two novel population-based ensemble selection methods, QO-ES and QDO-ES, and compare them to GES.","While QO-ES optimises solely for predictive performance, QDO-ES also considers the diversity of ensembles within the population, maintaining a diverse set of well-performing ensembles during optimisation based on ideas of quality diversity optimisation.","The methods are evaluated using 71 classification datasets from the AutoML benchmark, demonstrating that QO-ES and QDO-ES often outrank GES, albeit only statistically significant on validation data.","Our results further suggest that diversity can be beneficial for post hoc ensembling but also increases the risk of overfitting."],"url":"http://arxiv.org/abs/2307.08364v1"}
{"created":"2023-07-17 10:01:40","title":"ArUcoGlide: a Novel Wearable Robot for Position Tracking and Haptic Feedback to Increase Safety During Human-Robot Interaction","abstract":"The current capabilities of robotic systems make human collaboration necessary to accomplish complex tasks effectively. In this work, we are introducing a framework to ensure safety in a human-robot collaborative environment. The system is composed of a wearable 2-DOF robot, a low-cost and easy-to-install tracking system, and a collision avoidance algorithm based on the Artificial Potential Field (APF). The wearable robot is designed to hold a fiducial marker and maintain its visibility to the tracking system, which, in turn, localizes the user's hand with good accuracy and low latency and provides haptic feedback to the user. The system is designed to enhance the performance of collaborative tasks while ensuring user safety. Three experiments were carried out to evaluate the performance of the proposed system. The first one evaluated the accuracy of the tracking system. The second experiment analyzed human-robot behavior during an imminent collision. The third experiment evaluated the system in a collaborative activity in a shared working environment. The results show that the implementation of the introduced system reduces the operation time by 16% and increases the average distance between the user's hand and the robot by 5 cm.","sentences":["The current capabilities of robotic systems make human collaboration necessary to accomplish complex tasks effectively.","In this work, we are introducing a framework to ensure safety in a human-robot collaborative environment.","The system is composed of a wearable 2-DOF robot, a low-cost and easy-to-install tracking system, and a collision avoidance algorithm based on the Artificial Potential Field (APF).","The wearable robot is designed to hold a fiducial marker and maintain its visibility to the tracking system, which, in turn, localizes the user's hand with good accuracy and low latency and provides haptic feedback to the user.","The system is designed to enhance the performance of collaborative tasks while ensuring user safety.","Three experiments were carried out to evaluate the performance of the proposed system.","The first one evaluated the accuracy of the tracking system.","The second experiment analyzed human-robot behavior during an imminent collision.","The third experiment evaluated the system in a collaborative activity in a shared working environment.","The results show that the implementation of the introduced system reduces the operation time by 16% and increases the average distance between the user's hand and the robot by 5 cm."],"url":"http://arxiv.org/abs/2307.08363v1"}
{"created":"2023-07-17 09:55:35","title":"Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach","abstract":"In this paper, we propose an online convex optimization method with two different levels of adaptivity. On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees. To be specific, we obtain $\\mathcal{O}(\\ln V_T)$, $\\mathcal{O}(d \\ln V_T)$ and $\\hat{\\mathcal{O}}(\\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\\hat{\\mathcal{O}}(\\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications. It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly. Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential. Our method is based on a multi-layer online ensemble incorporating novel ingredients, including carefully-designed optimism for unifying diverse function types and cascaded corrections for algorithmic stability. Remarkably, despite its multi-layer structure, our algorithm necessitates only one gradient query per round, making it favorable when the gradient evaluation is time-consuming. This is facilitated by a novel regret decomposition equipped with customized surrogate losses.","sentences":["In this paper, we propose an online convex optimization method with two different levels of adaptivity.","On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees.","To be specific, we obtain $\\mathcal{O}(\\ln V_T)$, $\\mathcal{O}(d \\ln V_T)$ and $\\hat{\\mathcal{O}}(\\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\\hat{\\mathcal{O}}(\\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications.","It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly.","Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential.","Our method is based on a multi-layer online ensemble incorporating novel ingredients, including carefully-designed optimism for unifying diverse function types and cascaded corrections for algorithmic stability.","Remarkably, despite its multi-layer structure, our algorithm necessitates only one gradient query per round, making it favorable when the gradient evaluation is time-consuming.","This is facilitated by a novel regret decomposition equipped with customized surrogate losses."],"url":"http://arxiv.org/abs/2307.08360v1"}
{"created":"2023-07-17 09:54:52","title":"Human Emergency Detection during Autonomous Hospital Transports","abstract":"Human transports in hospitals are labor-intensive and primarily performed in beds to save time. This transfer method does not promote the mobility or autonomy of the patient. To relieve the caregivers from this time-consuming task, a mobile robot is developed to autonomously transport humans around the hospital. It provides different transfer modes including walking and sitting in a wheelchair. The problem that this paper focuses on is to detect emergencies and ensure the well-being of the patient during the transport. For this purpose, the patient is tracked and monitored with a camera system. OpenPose is used for Human Pose Estimation and a trained classifier for emergency detection. We collected and published a dataset of 18,000 images in lab and hospital environments. It differs from related work because we have a moving robot with different transfer modes in a highly dynamic environment with multiple people in the scene using only RGB-D data. To improve the critical recall metric, we apply threshold moving and a time delay. We compare different models with an AutoML approach. This paper shows that emergencies while walking are best detected by a SVM with a recall of 95.8% on single frames. In the case of sitting transport, the best model achieves a recall of 62.2%. The contribution is to establish a baseline on this new dataset and to provide a proof of concept for the human emergency detection in this use case.","sentences":["Human transports in hospitals are labor-intensive and primarily performed in beds to save time.","This transfer method does not promote the mobility or autonomy of the patient.","To relieve the caregivers from this time-consuming task, a mobile robot is developed to autonomously transport humans around the hospital.","It provides different transfer modes including walking and sitting in a wheelchair.","The problem that this paper focuses on is to detect emergencies and ensure the well-being of the patient during the transport.","For this purpose, the patient is tracked and monitored with a camera system.","OpenPose is used for Human Pose Estimation and a trained classifier for emergency detection.","We collected and published a dataset of 18,000 images in lab and hospital environments.","It differs from related work because we have a moving robot with different transfer modes in a highly dynamic environment with multiple people in the scene using only RGB-D data.","To improve the critical recall metric, we apply threshold moving and a time delay.","We compare different models with an AutoML approach.","This paper shows that emergencies while walking are best detected by a SVM with a recall of 95.8% on single frames.","In the case of sitting transport, the best model achieves a recall of 62.2%.","The contribution is to establish a baseline on this new dataset and to provide a proof of concept for the human emergency detection in this use case."],"url":"http://arxiv.org/abs/2307.08359v1"}
{"created":"2023-07-17 09:50:03","title":"Self-supervised Monocular Depth Estimation: Let's Talk About The Weather","abstract":"Current, self-supervised depth estimation architectures rely on clear and sunny weather scenes to train deep neural networks. However, in many locations, this assumption is too strong. For example in the UK (2021), 149 days consisted of rain. For these architectures to be effective in real-world applications, we must create models that can generalise to all weather conditions, times of the day and image qualities. Using a combination of computer graphics and generative models, one can augment existing sunny-weather data in a variety of ways that simulate adverse weather effects. While it is tempting to use such data augmentations for self-supervised depth, in the past this was shown to degrade performance instead of improving it. In this paper, we put forward a method that uses augmentations to remedy this problem. By exploiting the correspondence between unaugmented and augmented data we introduce a pseudo-supervised loss for both depth and pose estimation. This brings back some of the benefits of supervised learning while still not requiring any labels. We also make a series of practical recommendations which collectively offer a reliable, efficient framework for weather-related augmentation of self-supervised depth from monocular video. We present extensive testing to show that our method, Robust-Depth, achieves SotA performance on the KITTI dataset while significantly surpassing SotA on challenging, adverse condition data such as DrivingStereo, Foggy CityScape and NuScenes-Night. The project website can be found here https://kieran514.github.io/Robust-Depth-Project/.","sentences":["Current, self-supervised depth estimation architectures rely on clear and sunny weather scenes to train deep neural networks.","However, in many locations, this assumption is too strong.","For example in the UK (2021), 149 days consisted of rain.","For these architectures to be effective in real-world applications, we must create models that can generalise to all weather conditions, times of the day and image qualities.","Using a combination of computer graphics and generative models, one can augment existing sunny-weather data in a variety of ways that simulate adverse weather effects.","While it is tempting to use such data augmentations for self-supervised depth, in the past this was shown to degrade performance instead of improving it.","In this paper, we put forward a method that uses augmentations to remedy this problem.","By exploiting the correspondence between unaugmented and augmented data we introduce a pseudo-supervised loss for both depth and pose estimation.","This brings back some of the benefits of supervised learning while still not requiring any labels.","We also make a series of practical recommendations which collectively offer a reliable, efficient framework for weather-related augmentation of self-supervised depth from monocular video.","We present extensive testing to show that our method, Robust-Depth, achieves SotA performance on the KITTI dataset while significantly surpassing SotA on challenging, adverse condition data such as DrivingStereo, Foggy CityScape and NuScenes-Night.","The project website can be found here https://kieran514.github.io/Robust-Depth-Project/."],"url":"http://arxiv.org/abs/2307.08357v1"}
{"created":"2023-07-17 09:45:19","title":"Box-DETR: Understanding and Boxing Conditional Spatial Queries","abstract":"Conditional spatial queries are recently introduced into DEtection TRansformer (DETR) to accelerate convergence. In DAB-DETR, such queries are modulated by the so-called conditional linear projection at each decoder stage, aiming to search for positions of interest such as the four extremities of the box. Each decoder stage progressively updates the box by predicting the anchor box offsets, while in cross-attention only the box center is informed as the reference point. The use of only box center, however, leaves the width and height of the previous box unknown to the current stage, which hinders accurate prediction of offsets. We argue that the explicit use of the entire box information in cross-attention matters. In this work, we propose Box Agent to condense the box into head-specific agent points. By replacing the box center with the agent point as the reference point in each head, the conditional cross-attention can search for positions from a more reasonable starting point by considering the full scope of the previous box, rather than always from the previous box center. This significantly reduces the burden of the conditional linear projection. Experimental results show that the box agent leads to not only faster convergence but also improved detection performance, e.g., our single-scale model achieves $44.2$ AP with ResNet-50 based on DAB-DETR. Our Box Agent requires minor modifications to the code and has negligible computational workload. Code is available at https://github.com/tiny-smart/box-detr.","sentences":["Conditional spatial queries are recently introduced into DEtection TRansformer (DETR) to accelerate convergence.","In DAB-DETR, such queries are modulated by the so-called conditional linear projection at each decoder stage, aiming to search for positions of interest such as the four extremities of the box.","Each decoder stage progressively updates the box by predicting the anchor box offsets, while in cross-attention only the box center is informed as the reference point.","The use of only box center, however, leaves the width and height of the previous box unknown to the current stage, which hinders accurate prediction of offsets.","We argue that the explicit use of the entire box information in cross-attention matters.","In this work, we propose Box Agent to condense the box into head-specific agent points.","By replacing the box center with the agent point as the reference point in each head, the conditional cross-attention can search for positions from a more reasonable starting point by considering the full scope of the previous box, rather than always from the previous box center.","This significantly reduces the burden of the conditional linear projection.","Experimental results show that the box agent leads to not only faster convergence but also improved detection performance, e.g., our single-scale model achieves $44.2$ AP with ResNet-50 based on DAB-DETR.","Our Box Agent requires minor modifications to the code and has negligible computational workload.","Code is available at https://github.com/tiny-smart/box-detr."],"url":"http://arxiv.org/abs/2307.08353v1"}
{"created":"2023-07-17 09:43:50","title":"Zero-th Order Algorithm for Softmax Attention Optimization","abstract":"Large language models (LLMs) have brought about significant transformations in human society. Among the crucial computations in LLMs, the softmax unit holds great importance. Its helps the model generating a probability distribution on potential subsequent words or phrases, considering a series of input words. By utilizing this distribution, the model selects the most probable next word or phrase, based on the assigned probabilities. The softmax unit assumes a vital function in LLM training as it facilitates learning from data through the adjustment of neural network weights and biases.   With the development of the size of LLMs, computing the gradient becomes expensive. However, Zero-th Order method can approximately compute the gradient with only forward passes. In this paper, we present a Zero-th Order algorithm specifically tailored for Softmax optimization. We demonstrate the convergence of our algorithm, highlighting its effectiveness in efficiently computing gradients for large-scale LLMs. By leveraging the Zeroth-Order method, our work contributes to the advancement of optimization techniques in the context of complex language models.","sentences":["Large language models (LLMs) have brought about significant transformations in human society.","Among the crucial computations in LLMs, the softmax unit holds great importance.","Its helps the model generating a probability distribution on potential subsequent words or phrases, considering a series of input words.","By utilizing this distribution, the model selects the most probable next word or phrase, based on the assigned probabilities.","The softmax unit assumes a vital function in LLM training as it facilitates learning from data through the adjustment of neural network weights and biases.   ","With the development of the size of LLMs, computing the gradient becomes expensive.","However, Zero-th Order method can approximately compute the gradient with only forward passes.","In this paper, we present a Zero-th Order algorithm specifically tailored for Softmax optimization.","We demonstrate the convergence of our algorithm, highlighting its effectiveness in efficiently computing gradients for large-scale LLMs.","By leveraging the Zeroth-Order method, our work contributes to the advancement of optimization techniques in the context of complex language models."],"url":"http://arxiv.org/abs/2307.08352v1"}
{"created":"2023-07-17 09:40:13","title":"Are we there yet? An Industrial Viewpoint on Provenance-based Endpoint Detection and Response Tools","abstract":"Provenance-Based Endpoint Detection and Response (P-EDR) systems are deemed crucial for future APT defenses. Despite the fact that numerous new techniques to improve P-EDR systems have been proposed in academia, it is still unclear whether the industry will adopt P-EDR systems and what improvements the industry desires for P-EDR systems. To this end, we conduct the first set of systematic studies on the effectiveness and the limitations of P-EDR systems. Our study consists of four components: a one-to-one interview, an online questionnaire study, a survey of the relevant literature, and a systematic measurement study. Our research indicates that all industry experts consider P-EDR systems to be more effective than conventional Endpoint Detection and Response (EDR) systems. However, industry experts are concerned about the operating cost of P-EDR systems. In addition, our research reveals three significant gaps between academia and industry: (1) overlooking client-side overhead; (2) imbalanced alarm triage cost and interpretation cost; and (3) excessive server-side memory consumption. This paper's findings provide objective data on the effectiveness of P-EDR systems and how much improvements are needed to adopt P-EDR systems in industry.","sentences":["Provenance-Based Endpoint Detection and Response (P-EDR) systems are deemed crucial for future APT defenses.","Despite the fact that numerous new techniques to improve P-EDR systems have been proposed in academia, it is still unclear whether the industry will adopt P-EDR systems and what improvements the industry desires for P-EDR systems.","To this end, we conduct the first set of systematic studies on the effectiveness and the limitations of P-EDR systems.","Our study consists of four components: a one-to-one interview, an online questionnaire study, a survey of the relevant literature, and a systematic measurement study.","Our research indicates that all industry experts consider P-EDR systems to be more effective than conventional Endpoint Detection and Response (EDR) systems.","However, industry experts are concerned about the operating cost of P-EDR systems.","In addition, our research reveals three significant gaps between academia and industry: (1) overlooking client-side overhead; (2) imbalanced alarm triage cost and interpretation cost; and (3) excessive server-side memory consumption.","This paper's findings provide objective data on the effectiveness of P-EDR systems and how much improvements are needed to adopt P-EDR systems in industry."],"url":"http://arxiv.org/abs/2307.08349v1"}
{"created":"2023-07-17 09:40:02","title":"Adaptive Local Basis Functions for Shape Completion","abstract":"In this paper, we focus on the task of 3D shape completion from partial point clouds using deep implicit functions. Existing methods seek to use voxelized basis functions or the ones from a certain family of functions (e.g., Gaussians), which leads to high computational costs or limited shape expressivity. On the contrary, our method employs adaptive local basis functions, which are learned end-to-end and not restricted in certain forms. Based on those basis functions, a local-to-local shape completion framework is presented. Our algorithm learns sparse parameterization with a small number of basis functions while preserving local geometric details during completion. Quantitative and qualitative experiments demonstrate that our method outperforms the state-of-the-art methods in shape completion, detail preservation, generalization to unseen geometries, and computational cost. Code and data are at https://github.com/yinghdb/Adaptive-Local-Basis-Functions.","sentences":["In this paper, we focus on the task of 3D shape completion from partial point clouds using deep implicit functions.","Existing methods seek to use voxelized basis functions or the ones from a certain family of functions (e.g., Gaussians), which leads to high computational costs or limited shape expressivity.","On the contrary, our method employs adaptive local basis functions, which are learned end-to-end and not restricted in certain forms.","Based on those basis functions, a local-to-local shape completion framework is presented.","Our algorithm learns sparse parameterization with a small number of basis functions while preserving local geometric details during completion.","Quantitative and qualitative experiments demonstrate that our method outperforms the state-of-the-art methods in shape completion, detail preservation, generalization to unseen geometries, and computational cost.","Code and data are at https://github.com/yinghdb/Adaptive-Local-Basis-Functions."],"url":"http://arxiv.org/abs/2307.08348v1"}
{"created":"2023-07-17 09:38:41","title":"M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization","abstract":"Medical vision-language models enable co-learning and integrating features from medical imaging and clinical text. However, these models are not easy to train and the latent representation space can be complex. Here we propose a novel way for pre-training and regularising medical vision-language models. The proposed method, named Medical vision-language pre-training with Frozen language models and Latent spAce Geometry optimization (M-FLAG), leverages a frozen language model for training stability and efficiency and introduces a novel orthogonality loss to harmonize the latent space geometry. We demonstrate the potential of the pre-trained model on three downstream tasks: medical image classification, segmentation, and object detection. Extensive experiments across five public datasets demonstrate that M-FLAG significantly outperforms existing medical vision-language pre-training approaches and reduces the number of parameters by 78\\%. Notably, M-FLAG achieves outstanding performance on the segmentation task while using only 1\\% of the RSNA dataset, even outperforming ImageNet pre-trained models that have been fine-tuned using 100\\% of the data.","sentences":["Medical vision-language models enable co-learning and integrating features from medical imaging and clinical text.","However, these models are not easy to train and the latent representation space can be complex.","Here we propose a novel way for pre-training and regularising medical vision-language models.","The proposed method, named Medical vision-language pre-training with Frozen language models and Latent spAce Geometry optimization (M-FLAG), leverages a frozen language model for training stability and efficiency and introduces a novel orthogonality loss to harmonize the latent space geometry.","We demonstrate the potential of the pre-trained model on three downstream tasks: medical image classification, segmentation, and object detection.","Extensive experiments across five public datasets demonstrate that M-FLAG significantly outperforms existing medical vision-language pre-training approaches and reduces the number of parameters by 78\\%.","Notably, M-FLAG achieves outstanding performance on the segmentation task while using only 1\\% of the RSNA dataset, even outperforming ImageNet pre-trained models that have been fine-tuned using 100\\% of the data."],"url":"http://arxiv.org/abs/2307.08347v1"}
{"created":"2023-07-17 09:35:04","title":"On-board Federated Learning for Satellite Clusters with Inter-Satellite Links","abstract":"The emergence of mega-constellations of interconnected satellites has a major impact on the integration of cellular wireless and non-terrestrial networks (NTN). This paper studies the problem of running a federated learning (FL) algorithm within a low Earth orbit (LEO) constellation of satellites connected with intra-orbit inter-satellite links (ISL). Satellites apply on-board machine learning and transmit the local parameters to the parameter server (PS). The main contribution is a novel approach to enhance FL in satellite constellations using intra-orbit ISLs. The key idea is to rely on the predictability of satellite visits to create a system design in which ISLs mitigate the impact of intermittent connectivity and transmit the aggregated parameters to the PS. We first devise a synchronous FL, which is then extended towards an asynchronous FL for the case of sparse satellite visits to the PS. An efficient use of the satellite resources is attained by sparsification-based compression the aggregated parameters of each orbit before forwarding to the PS. Performance is evaluated in terms of accuracy and the required size of data to be transmitted. The numerical results indicate a faster convergence rate of the presented approach compared with the state-of-the-art FL on satellite constellations.","sentences":["The emergence of mega-constellations of interconnected satellites has a major impact on the integration of cellular wireless and non-terrestrial networks (NTN).","This paper studies the problem of running a federated learning (FL) algorithm within a low Earth orbit (LEO) constellation of satellites connected with intra-orbit inter-satellite links (ISL).","Satellites apply on-board machine learning and transmit the local parameters to the parameter server (PS).","The main contribution is a novel approach to enhance FL in satellite constellations using intra-orbit ISLs.","The key idea is to rely on the predictability of satellite visits to create a system design in which ISLs mitigate the impact of intermittent connectivity and transmit the aggregated parameters to the PS.","We first devise a synchronous FL, which is then extended towards an asynchronous FL for the case of sparse satellite visits to the PS.","An efficient use of the satellite resources is attained by sparsification-based compression the aggregated parameters of each orbit before forwarding to the PS.","Performance is evaluated in terms of accuracy and the required size of data to be transmitted.","The numerical results indicate a faster convergence rate of the presented approach compared with the state-of-the-art FL on satellite constellations."],"url":"http://arxiv.org/abs/2307.08346v1"}
{"created":"2023-07-17 09:26:13","title":"Multi-Task Cross-Modality Attention-Fusion for 2D Object Detection","abstract":"Accurate and robust object detection is critical for autonomous driving. Image-based detectors face difficulties caused by low visibility in adverse weather conditions. Thus, radar-camera fusion is of particular interest but presents challenges in optimally fusing heterogeneous data sources. To approach this issue, we propose two new radar preprocessing techniques to better align radar and camera data. In addition, we introduce a Multi-Task Cross-Modality Attention-Fusion Network (MCAF-Net) for object detection, which includes two new fusion blocks. These allow for exploiting information from the feature maps more comprehensively. The proposed algorithm jointly detects objects and segments free space, which guides the model to focus on the more relevant part of the scene, namely, the occupied space. Our approach outperforms current state-of-the-art radar-camera fusion-based object detectors in the nuScenes dataset and achieves more robust results in adverse weather conditions and nighttime scenarios.","sentences":["Accurate and robust object detection is critical for autonomous driving.","Image-based detectors face difficulties caused by low visibility in adverse weather conditions.","Thus, radar-camera fusion is of particular interest but presents challenges in optimally fusing heterogeneous data sources.","To approach this issue, we propose two new radar preprocessing techniques to better align radar and camera data.","In addition, we introduce a Multi-Task Cross-Modality Attention-Fusion Network (MCAF-Net) for object detection, which includes two new fusion blocks.","These allow for exploiting information from the feature maps more comprehensively.","The proposed algorithm jointly detects objects and segments free space, which guides the model to focus on the more relevant part of the scene, namely, the occupied space.","Our approach outperforms current state-of-the-art radar-camera fusion-based object detectors in the nuScenes dataset and achieves more robust results in adverse weather conditions and nighttime scenarios."],"url":"http://arxiv.org/abs/2307.08339v1"}
{"created":"2023-07-17 09:12:05","title":"RAYEN: Imposition of Hard Convex Constraints on Neural Networks","abstract":"This paper presents RAYEN, a framework to impose hard convex constraints on the output or latent variable of a neural network. RAYEN guarantees that, for any input or any weights of the network, the constraints are satisfied at all times. Compared to other approaches, RAYEN does not perform a computationally-expensive orthogonal projection step onto the feasible set, does not rely on soft constraints (which do not guarantee the satisfaction of the constraints at test time), does not use conservative approximations of the feasible set, and does not perform a potentially slow inner gradient descent correction to enforce the constraints. RAYEN supports any combination of linear, convex quadratic, second-order cone (SOC), and linear matrix inequality (LMI) constraints, achieving a very small computational overhead compared to unconstrained networks. For example, it is able to impose 1K quadratic constraints on a 1K-dimensional variable with an overhead of less than 8 ms, and an LMI constraint with 300x300 dense matrices on a 10K-dimensional variable in less than 12 ms. When used in neural networks that approximate the solution of constrained optimization problems, RAYEN achieves computation times between 20 and 7468 times faster than state-of-the-art algorithms, while guaranteeing the satisfaction of the constraints at all times and obtaining a cost very close to the optimal one.","sentences":["This paper presents RAYEN, a framework to impose hard convex constraints on the output or latent variable of a neural network.","RAYEN guarantees that, for any input or any weights of the network, the constraints are satisfied at all times.","Compared to other approaches, RAYEN does not perform a computationally-expensive orthogonal projection step onto the feasible set, does not rely on soft constraints (which do not guarantee the satisfaction of the constraints at test time), does not use conservative approximations of the feasible set, and does not perform a potentially slow inner gradient descent correction to enforce the constraints.","RAYEN supports any combination of linear, convex quadratic, second-order cone (SOC), and linear matrix inequality (LMI) constraints, achieving a very small computational overhead compared to unconstrained networks.","For example, it is able to impose 1K quadratic constraints on a 1K-dimensional variable with an overhead of less than 8 ms, and an LMI constraint with 300x300 dense matrices on a 10K-dimensional variable in less than 12 ms.","When used in neural networks that approximate the solution of constrained optimization problems, RAYEN achieves computation times between 20 and 7468 times faster than state-of-the-art algorithms, while guaranteeing the satisfaction of the constraints at all times and obtaining a cost very close to the optimal one."],"url":"http://arxiv.org/abs/2307.08336v1"}
{"created":"2023-07-17 08:50:36","title":"Analyzing the Impact of Adversarial Examples on Explainable Machine Learning","abstract":"Adversarial attacks are a type of attack on machine learning models where an attacker deliberately modifies the inputs to cause the model to make incorrect predictions. Adversarial attacks can have serious consequences, particularly in applications such as autonomous vehicles, medical diagnosis, and security systems. Work on the vulnerability of deep learning models to adversarial attacks has shown that it is very easy to make samples that make a model predict things that it doesn't want to. In this work, we analyze the impact of model interpretability due to adversarial attacks on text classification problems. We develop an ML-based classification model for text data. Then, we introduce the adversarial perturbations on the text data to understand the classification performance after the attack. Subsequently, we analyze and interpret the model's explainability before and after the attack","sentences":["Adversarial attacks are a type of attack on machine learning models where an attacker deliberately modifies the inputs to cause the model to make incorrect predictions.","Adversarial attacks can have serious consequences, particularly in applications such as autonomous vehicles, medical diagnosis, and security systems.","Work on the vulnerability of deep learning models to adversarial attacks has shown that it is very easy to make samples that make a model predict things that it doesn't want to.","In this work, we analyze the impact of model interpretability due to adversarial attacks on text classification problems.","We develop an ML-based classification model for text data.","Then, we introduce the adversarial perturbations on the text data to understand the classification performance after the attack.","Subsequently, we analyze and interpret the model's explainability before and after the attack"],"url":"http://arxiv.org/abs/2307.08327v1"}
{"created":"2023-07-17 08:48:08","title":"From Information to Choice: A Critical Inquiry Into Visualization Tools for Decision Making","abstract":"In the face of complex decisions, people often engage in a three-stage process that spans from (1) exploring and analyzing pertinent information (intelligence); (2) generating and exploring alternative options (design); and ultimately culminating in (3) selecting the optimal decision by evaluating discerning criteria (choice). We can fairly assume that all good visualizations aid in the intelligence stage by enabling data exploration and analysis. Yet, to what degree and how do visualization systems currently support the other decision making stages, namely design and choice? To explore this question, we conducted a comprehensive review of decision-focused visualization tools by examining publications in major visualization journals and conferences, including VIS, EuroVis, and CHI, spanning all available years. We employed a deductive coding method and in-depth analysis to assess if and how visualization tools support design and choice. Specifically, we examined each visualization tool by (i) its degree of visibility for displaying decision alternatives, criteria, and preferences, and (ii) its degree of flexibility for offering means to manipulate the decision alternatives, criteria, and preferences with interactions such as adding, modifying, changing mapping, and filtering. Our review highlights the opportunities and challenges and reveals a surprising scarcity of tools that support all stages, and while most tools excel in offering visibility for decision criteria and alternatives, the degree of flexibility to manipulate these elements is often limited, and the lack of tools that accommodate decision preferences and their elicitation is notable. Future research could explore enhancing flexibility levels and variety, exploring novel visualization paradigms, increasing algorithmic support, and ensuring that this automation is user-controlled via the enhanced flexibility levels.","sentences":["In the face of complex decisions, people often engage in a three-stage process that spans from (1) exploring and analyzing pertinent information (intelligence); (2) generating and exploring alternative options (design); and ultimately culminating in (3) selecting the optimal decision by evaluating discerning criteria (choice).","We can fairly assume that all good visualizations aid in the intelligence stage by enabling data exploration and analysis.","Yet, to what degree and how do visualization systems currently support the other decision making stages, namely design and choice?","To explore this question, we conducted a comprehensive review of decision-focused visualization tools by examining publications in major visualization journals and conferences, including VIS, EuroVis, and CHI, spanning all available years.","We employed a deductive coding method and in-depth analysis to assess if and how visualization tools support design and choice.","Specifically, we examined each visualization tool by (i) its degree of visibility for displaying decision alternatives, criteria, and preferences, and (ii) its degree of flexibility for offering means to manipulate the decision alternatives, criteria, and preferences with interactions such as adding, modifying, changing mapping, and filtering.","Our review highlights the opportunities and challenges and reveals a surprising scarcity of tools that support all stages, and while most tools excel in offering visibility for decision criteria and alternatives, the degree of flexibility to manipulate these elements is often limited, and the lack of tools that accommodate decision preferences and their elicitation is notable.","Future research could explore enhancing flexibility levels and variety, exploring novel visualization paradigms, increasing algorithmic support, and ensuring that this automation is user-controlled via the enhanced flexibility levels."],"url":"http://arxiv.org/abs/2307.08326v1"}
{"created":"2023-07-17 08:42:21","title":"A Secure Aggregation for Federated Learning on Long-Tailed Data","abstract":"As a distributed learning, Federated Learning (FL) faces two challenges: the unbalanced distribution of training data among participants, and the model attack by Byzantine nodes. In this paper, we consider the long-tailed distribution with the presence of Byzantine nodes in the FL scenario. A novel two-layer aggregation method is proposed for the rejection of malicious models and the advisable selection of valuable models containing tail class data information. We introduce the concept of think tank to leverage the wisdom of all participants. Preliminary experiments validate that the think tank can make effective model selections for global aggregation.","sentences":["As a distributed learning, Federated Learning (FL) faces two challenges: the unbalanced distribution of training data among participants, and the model attack by Byzantine nodes.","In this paper, we consider the long-tailed distribution with the presence of Byzantine nodes in the FL scenario.","A novel two-layer aggregation method is proposed for the rejection of malicious models and the advisable selection of valuable models containing tail class data information.","We introduce the concept of think tank to leverage the wisdom of all participants.","Preliminary experiments validate that the think tank can make effective model selections for global aggregation."],"url":"http://arxiv.org/abs/2307.08324v1"}
{"created":"2023-07-17 08:41:11","title":"TST: Time-Sparse Transducer for Automatic Speech Recognition","abstract":"End-to-end model, especially Recurrent Neural Network Transducer (RNN-T), has achieved great success in speech recognition. However, transducer requires a great memory footprint and computing time when processing a long decoding sequence. To solve this problem, we propose a model named time-sparse transducer, which introduces a time-sparse mechanism into transducer. In this mechanism, we obtain the intermediate representations by reducing the time resolution of the hidden states. Then the weighted average algorithm is used to combine these representations into sparse hidden states followed by the decoder. All the experiments are conducted on a Mandarin dataset AISHELL-1. Compared with RNN-T, the character error rate of the time-sparse transducer is close to RNN-T and the real-time factor is 50.00% of the original. By adjusting the time resolution, the time-sparse transducer can also reduce the real-time factor to 16.54% of the original at the expense of a 4.94% loss of precision.","sentences":["End-to-end model, especially Recurrent Neural Network Transducer (RNN-T), has achieved great success in speech recognition.","However, transducer requires a great memory footprint and computing time when processing a long decoding sequence.","To solve this problem, we propose a model named time-sparse transducer, which introduces a time-sparse mechanism into transducer.","In this mechanism, we obtain the intermediate representations by reducing the time resolution of the hidden states.","Then the weighted average algorithm is used to combine these representations into sparse hidden states followed by the decoder.","All the experiments are conducted on a Mandarin dataset AISHELL-1.","Compared with RNN-T, the character error rate of the time-sparse transducer is close to RNN-T and the real-time factor is 50.00% of the original.","By adjusting the time resolution, the time-sparse transducer can also reduce the real-time factor to 16.54% of the original at the expense of a 4.94% loss of precision."],"url":"http://arxiv.org/abs/2307.08323v1"}
{"created":"2023-07-17 08:38:46","title":"Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction","abstract":"Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases. In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction. LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment. Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples. On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models. Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks. LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods. Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models.","sentences":["Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases.","In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction.","LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment.","Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples.","On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models.","Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks.","LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods.","Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models."],"url":"http://arxiv.org/abs/2307.08321v1"}
{"created":"2023-07-17 08:31:59","title":"Soft Curriculum for Learning Conditional GANs with Noisy-Labeled and Uncurated Unlabeled Data","abstract":"Label-noise or curated unlabeled data is used to compensate for the assumption of clean labeled data in training the conditional generative adversarial network; however, satisfying such an extended assumption is occasionally laborious or impractical. As a step towards generative modeling accessible to everyone, we introduce a novel conditional image generation framework that accepts noisy-labeled and uncurated unlabeled data during training: (i) closed-set and open-set label noise in labeled data and (ii) closed-set and open-set unlabeled data. To combat it, we propose soft curriculum learning, which assigns instance-wise weights for adversarial training while assigning new labels for unlabeled data and correcting wrong labels for labeled data. Unlike popular curriculum learning, which uses a threshold to pick the training samples, our soft curriculum controls the effect of each training instance by using the weights predicted by the auxiliary classifier, resulting in the preservation of useful samples while ignoring harmful ones. Our experiments show that our approach outperforms existing semi-supervised and label-noise robust methods in terms of both quantitative and qualitative performance. In particular, the proposed approach is able to match the performance of (semi-) supervised GANs even with less than half the labeled data.","sentences":["Label-noise or curated unlabeled data is used to compensate for the assumption of clean labeled data in training the conditional generative adversarial network; however, satisfying such an extended assumption is occasionally laborious or impractical.","As a step towards generative modeling accessible to everyone, we introduce a novel conditional image generation framework that accepts noisy-labeled and uncurated unlabeled data during training: (i) closed-set and open-set label noise in labeled data and (ii) closed-set and open-set unlabeled data.","To combat it, we propose soft curriculum learning, which assigns instance-wise weights for adversarial training while assigning new labels for unlabeled data and correcting wrong labels for labeled data.","Unlike popular curriculum learning, which uses a threshold to pick the training samples, our soft curriculum controls the effect of each training instance by using the weights predicted by the auxiliary classifier, resulting in the preservation of useful samples while ignoring harmful ones.","Our experiments show that our approach outperforms existing semi-supervised and label-noise robust methods in terms of both quantitative and qualitative performance.","In particular, the proposed approach is able to match the performance of (semi-) supervised GANs even with less than half the labeled data."],"url":"http://arxiv.org/abs/2307.08319v1"}
{"created":"2023-07-17 08:26:36","title":"Airway Label Prediction in Video Bronchoscopy: Capturing Temporal Dependencies Utilizing Anatomical Knowledge","abstract":"Purpose: Navigation guidance is a key requirement for a multitude of lung interventions using video bronchoscopy. State-of-the-art solutions focus on lung biopsies using electromagnetic tracking and intraoperative image registration w.r.t. preoperative CT scans for guidance. The requirement of patient-specific CT scans hampers the utilisation of navigation guidance for other applications such as intensive care units.   Methods: This paper addresses navigation guidance solely incorporating bronchosopy video data. In contrast to state-of-the-art approaches we entirely omit the use of electromagnetic tracking and patient-specific CT scans. Guidance is enabled by means of topological bronchoscope localization w.r.t. an interpatient airway model. Particularly, we take maximally advantage of anatomical constraints of airway trees being sequentially traversed. This is realized by incorporating sequences of CNN-based airway likelihoods into a Hidden Markov Model.   Results: Our approach is evaluated based on multiple experiments inside a lung phantom model. With the consideration of temporal context and use of anatomical knowledge for regularization, we are able to improve the accuracy up to to 0.98 compared to 0.81 (weighted F1: 0.98 compared to 0.81) for a classification based on individual frames.   Conclusion: We combine CNN-based single image classification of airway segments with anatomical constraints and temporal HMM-based inference for the first time. Our approach renders vision-only guidance for bronchoscopy interventions in the absence of electromagnetic tracking and patient-specific CT scans possible.","sentences":["Purpose: Navigation guidance is a key requirement for a multitude of lung interventions using video bronchoscopy.","State-of-the-art solutions focus on lung biopsies using electromagnetic tracking and intraoperative image registration w.r.t.","preoperative CT scans for guidance.","The requirement of patient-specific CT scans hampers the utilisation of navigation guidance for other applications such as intensive care units.   ","Methods: This paper addresses navigation guidance solely incorporating bronchosopy video data.","In contrast to state-of-the-art approaches we entirely omit the use of electromagnetic tracking and patient-specific CT scans.","Guidance is enabled by means of topological bronchoscope localization w.r.t.","an interpatient airway model.","Particularly, we take maximally advantage of anatomical constraints of airway trees being sequentially traversed.","This is realized by incorporating sequences of CNN-based airway likelihoods into a Hidden Markov Model.   ","Results:","Our approach is evaluated based on multiple experiments inside a lung phantom model.","With the consideration of temporal context and use of anatomical knowledge for regularization, we are able to improve the accuracy up to to 0.98 compared to 0.81 (weighted F1: 0.98 compared to 0.81) for a classification based on individual frames.   ","Conclusion: We combine CNN-based single image classification of airway segments with anatomical constraints and temporal HMM-based inference for the first time.","Our approach renders vision-only guidance for bronchoscopy interventions in the absence of electromagnetic tracking and patient-specific CT scans possible."],"url":"http://arxiv.org/abs/2307.08318v1"}
{"created":"2023-07-17 08:24:58","title":"AltFreezing for More General Video Face Forgery Detection","abstract":"Existing face forgery detection models try to discriminate fake images by detecting only spatial artifacts (e.g., generative artifacts, blending) or mainly temporal artifacts (e.g., flickering, discontinuity). They may experience significant performance degradation when facing out-domain artifacts. In this paper, we propose to capture both spatial and temporal artifacts in one model for face forgery detection. A simple idea is to leverage a spatiotemporal model (3D ConvNet). However, we find that it may easily rely on one type of artifact and ignore the other. To address this issue, we present a novel training strategy called AltFreezing for more general face forgery detection. The AltFreezing aims to encourage the model to detect both spatial and temporal artifacts. It divides the weights of a spatiotemporal network into two groups: spatial-related and temporal-related. Then the two groups of weights are alternately frozen during the training process so that the model can learn spatial and temporal features to distinguish real or fake videos. Furthermore, we introduce various video-level data augmentation methods to improve the generalization capability of the forgery detection model. Extensive experiments show that our framework outperforms existing methods in terms of generalization to unseen manipulations and datasets. Code is available at https: //github.com/ZhendongWang6/AltFreezing.","sentences":["Existing face forgery detection models try to discriminate fake images by detecting only spatial artifacts (e.g., generative artifacts, blending) or mainly temporal artifacts (e.g., flickering, discontinuity).","They may experience significant performance degradation when facing out-domain artifacts.","In this paper, we propose to capture both spatial and temporal artifacts in one model for face forgery detection.","A simple idea is to leverage a spatiotemporal model (3D ConvNet).","However, we find that it may easily rely on one type of artifact and ignore the other.","To address this issue, we present a novel training strategy called AltFreezing for more general face forgery detection.","The AltFreezing aims to encourage the model to detect both spatial and temporal artifacts.","It divides the weights of a spatiotemporal network into two groups: spatial-related and temporal-related.","Then the two groups of weights are alternately frozen during the training process so that the model can learn spatial and temporal features to distinguish real or fake videos.","Furthermore, we introduce various video-level data augmentation methods to improve the generalization capability of the forgery detection model.","Extensive experiments show that our framework outperforms existing methods in terms of generalization to unseen manipulations and datasets.","Code is available at https: //github.com/ZhendongWang6/AltFreezing."],"url":"http://arxiv.org/abs/2307.08317v1"}
{"created":"2023-07-17 08:24:05","title":"Bridging the Gap: Multi-Level Cross-Modality Joint Alignment for Visible-Infrared Person Re-Identification","abstract":"Visible-Infrared person Re-IDentification (VI-ReID) is a challenging cross-modality image retrieval task that aims to match pedestrians' images across visible and infrared cameras. To solve the modality gap, existing mainstream methods adopt a learning paradigm converting the image retrieval task into an image classification task with cross-entropy loss and auxiliary metric learning losses. These losses follow the strategy of adjusting the distribution of extracted embeddings to reduce the intra-class distance and increase the inter-class distance. However, such objectives do not precisely correspond to the final test setting of the retrieval task, resulting in a new gap at the optimization level. By rethinking these keys of VI-ReID, we propose a simple and effective method, the Multi-level Cross-modality Joint Alignment (MCJA), bridging both modality and objective-level gap. For the former, we design the Modality Alignment Augmentation, which consists of three novel strategies, the weighted grayscale, cross-channel cutmix, and spectrum jitter augmentation, effectively reducing modality discrepancy in the image space. For the latter, we introduce a new Cross-Modality Retrieval loss. It is the first work to constrain from the perspective of the ranking list, aligning with the goal of the testing stage. Moreover, based on the global feature only, our method exhibits good performance and can serve as a strong baseline method for the VI-ReID community.","sentences":["Visible-Infrared person Re-IDentification (VI-ReID) is a challenging cross-modality image retrieval task that aims to match pedestrians' images across visible and infrared cameras.","To solve the modality gap, existing mainstream methods adopt a learning paradigm converting the image retrieval task into an image classification task with cross-entropy loss and auxiliary metric learning losses.","These losses follow the strategy of adjusting the distribution of extracted embeddings to reduce the intra-class distance and increase the inter-class distance.","However, such objectives do not precisely correspond to the final test setting of the retrieval task, resulting in a new gap at the optimization level.","By rethinking these keys of VI-ReID, we propose a simple and effective method, the Multi-level Cross-modality Joint Alignment (MCJA), bridging both modality and objective-level gap.","For the former, we design the Modality Alignment Augmentation, which consists of three novel strategies, the weighted grayscale, cross-channel cutmix, and spectrum jitter augmentation, effectively reducing modality discrepancy in the image space.","For the latter, we introduce a new Cross-Modality Retrieval loss.","It is the first work to constrain from the perspective of the ranking list, aligning with the goal of the testing stage.","Moreover, based on the global feature only, our method exhibits good performance and can serve as a strong baseline method for the VI-ReID community."],"url":"http://arxiv.org/abs/2307.08316v1"}
{"created":"2023-07-17 08:23:09","title":"IterLara: A Turing Complete Algebra for Big Data, AI, Scientific Computing, and Database","abstract":"\\textsc{Lara} is a key-value algebra that aims at unifying linear and relational algebra with three types of operation abstraction. The study of \\textsc{Lara}'s expressive ability reports that it can represent relational algebra and most linear algebra operations. However, several essential computations, such as matrix inversion and determinant, cannot be expressed in \\textsc{Lara}. \\textsc{Lara} cannot represent global and iterative computation, either. This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with iterative operators, to provide an algebraic model that unifies operations in general-purpose computing, like big data, AI, scientific computing, and database. We study the expressive ability of \\textsc{Lara} and \\textsc{IterLara} and prove that \\textsc{IterLara} with aggregation functions can represent matrix inversion, determinant. Besides, we demonstrate that \\textsc{IterLara} with no limitation of function utility is Turing complete. We also propose the Operation Count (OP) as a metric of computation amount for \\textsc{IterLara} and ensure that the OP metric is in accordance with the existing computation metrics.","sentences":["\\textsc{Lara} is a key-value algebra that aims at unifying linear and relational algebra with three types of operation abstraction.","The study of \\textsc{Lara}'s expressive ability reports that it can represent relational algebra and most linear algebra operations.","However, several essential computations, such as matrix inversion and determinant, cannot be expressed in \\textsc{Lara}.","\\textsc{Lara} cannot represent global and iterative computation, either.","This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with iterative operators, to provide an algebraic model that unifies operations in general-purpose computing, like big data, AI, scientific computing, and database.","We study the expressive ability of \\textsc{Lara} and \\textsc{IterLara} and prove that \\textsc{IterLara} with aggregation functions can represent matrix inversion, determinant.","Besides, we demonstrate that \\textsc{IterLara} with no limitation of function utility is Turing complete.","We also propose the Operation Count (OP) as a metric of computation amount for \\textsc{IterLara} and ensure that the OP metric is in accordance with the existing computation metrics."],"url":"http://arxiv.org/abs/2307.08315v1"}
{"created":"2023-07-17 08:21:38","title":"Building Volumetric Beliefs for Dynamic Environments Exploiting Map-Based Moving Object Segmentation","abstract":"Mobile robots that navigate in unknown environments need to be constantly aware of the dynamic objects in their surroundings for mapping, localization, and planning. It is key to reason about moving objects in the current observation and at the same time to also update the internal model of the static world to ensure safety. In this paper, we address the problem of jointly estimating moving objects in the current 3D LiDAR scan and a local map of the environment. We use sparse 4D convolutions to extract spatio-temporal features from scan and local map and segment all 3D points into moving and non-moving ones. Additionally, we propose to fuse these predictions in a probabilistic representation of the dynamic environment using a Bayes filter. This volumetric belief models, which parts of the environment can be occupied by moving objects. Our experiments show that our approach outperforms existing moving object segmentation baselines and even generalizes to different types of LiDAR sensors. We demonstrate that our volumetric belief fusion can increase the precision and recall of moving object segmentation and even retrieve previously missed moving objects in an online mapping scenario.","sentences":["Mobile robots that navigate in unknown environments need to be constantly aware of the dynamic objects in their surroundings for mapping, localization, and planning.","It is key to reason about moving objects in the current observation and at the same time to also update the internal model of the static world to ensure safety.","In this paper, we address the problem of jointly estimating moving objects in the current 3D LiDAR scan and a local map of the environment.","We use sparse 4D convolutions to extract spatio-temporal features from scan and local map and segment all 3D points into moving and non-moving ones.","Additionally, we propose to fuse these predictions in a probabilistic representation of the dynamic environment using a Bayes filter.","This volumetric belief models, which parts of the environment can be occupied by moving objects.","Our experiments show that our approach outperforms existing moving object segmentation baselines and even generalizes to different types of LiDAR sensors.","We demonstrate that our volumetric belief fusion can increase the precision and recall of moving object segmentation and even retrieve previously missed moving objects in an online mapping scenario."],"url":"http://arxiv.org/abs/2307.08314v1"}
{"created":"2023-07-17 08:09:40","title":"LogPr\u00e9cis: Unleashing Language Models for Automated Shell Log Analysis","abstract":"The collection of security-related logs holds the key to understanding attack behaviors and diagnosing vulnerabilities. Still, their analysis remains a daunting challenge. Recently, Language Models (LMs) have demonstrated unmatched potential in understanding natural and programming languages. The question arises whether and how LMs could be also useful for security experts since their logs contain intrinsically confused and obfuscated information. In this paper, we systematically study how to benefit from the state-of-the-art in LM to automatically analyze text-like Unix shell attack logs. We present a thorough design methodology that leads to LogPr\\'ecis. It receives as input raw shell sessions and automatically identifies and assigns the attacker tactic to each portion of the session, i.e., unveiling the sequence of the attacker's goals. We demonstrate LogPr\\'ecis capability to support the analysis of two large datasets containing about 400,000 unique Unix shell attacks. LogPr\\'ecis reduces them into about 3,000 fingerprints, each grouping sessions with the same sequence of tactics. The abstraction it provides lets the analyst better understand attacks, identify fingerprints, detect novelty, link similar attacks, and track families and mutations. Overall, LogPr\\'ecis, released as open source, paves the way for better and more responsive defense against cyberattacks.","sentences":["The collection of security-related logs holds the key to understanding attack behaviors and diagnosing vulnerabilities.","Still, their analysis remains a daunting challenge.","Recently, Language Models (LMs) have demonstrated unmatched potential in understanding natural and programming languages.","The question arises whether and how LMs could be also useful for security experts since their logs contain intrinsically confused and obfuscated information.","In this paper, we systematically study how to benefit from the state-of-the-art in LM to automatically analyze text-like Unix shell attack logs.","We present a thorough design methodology that leads to LogPr\\'ecis.","It receives as input raw shell sessions and automatically identifies and assigns the attacker tactic to each portion of the session, i.e., unveiling the sequence of the attacker's goals.","We demonstrate LogPr\\'ecis capability to support the analysis of two large datasets containing about 400,000 unique Unix shell attacks.","LogPr\\'ecis reduces them into about 3,000 fingerprints, each grouping sessions with the same sequence of tactics.","The abstraction it provides lets the analyst better understand attacks, identify fingerprints, detect novelty, link similar attacks, and track families and mutations.","Overall, LogPr\\'ecis, released as open source, paves the way for better and more responsive defense against cyberattacks."],"url":"http://arxiv.org/abs/2307.08309v1"}
{"created":"2023-07-17 08:05:30","title":"A Novel Multi-Task Model Imitating Dermatologists for Accurate Differential Diagnosis of Skin Diseases in Clinical Images","abstract":"Skin diseases are among the most prevalent health issues, and accurate computer-aided diagnosis methods are of importance for both dermatologists and patients. However, most of the existing methods overlook the essential domain knowledge required for skin disease diagnosis. A novel multi-task model, namely DermImitFormer, is proposed to fill this gap by imitating dermatologists' diagnostic procedures and strategies. Through multi-task learning, the model simultaneously predicts body parts and lesion attributes in addition to the disease itself, enhancing diagnosis accuracy and improving diagnosis interpretability. The designed lesion selection module mimics dermatologists' zoom-in action, effectively highlighting the local lesion features from noisy backgrounds. Additionally, the presented cross-interaction module explicitly models the complicated diagnostic reasoning between body parts, lesion attributes, and diseases. To provide a more robust evaluation of the proposed method, a large-scale clinical image dataset of skin diseases with significantly more cases than existing datasets has been established. Extensive experiments on three different datasets consistently demonstrate the state-of-the-art recognition performance of the proposed approach.","sentences":["Skin diseases are among the most prevalent health issues, and accurate computer-aided diagnosis methods are of importance for both dermatologists and patients.","However, most of the existing methods overlook the essential domain knowledge required for skin disease diagnosis.","A novel multi-task model, namely DermImitFormer, is proposed to fill this gap by imitating dermatologists' diagnostic procedures and strategies.","Through multi-task learning, the model simultaneously predicts body parts and lesion attributes in addition to the disease itself, enhancing diagnosis accuracy and improving diagnosis interpretability.","The designed lesion selection module mimics dermatologists' zoom-in action, effectively highlighting the local lesion features from noisy backgrounds.","Additionally, the presented cross-interaction module explicitly models the complicated diagnostic reasoning between body parts, lesion attributes, and diseases.","To provide a more robust evaluation of the proposed method, a large-scale clinical image dataset of skin diseases with significantly more cases than existing datasets has been established.","Extensive experiments on three different datasets consistently demonstrate the state-of-the-art recognition performance of the proposed approach."],"url":"http://arxiv.org/abs/2307.08308v1"}
{"created":"2023-07-17 07:59:47","title":"Efficient Computation of Counterfactual Bounds","abstract":"We assume to be given structural equations over discrete variables inducing a directed acyclic graph, namely, a structural causal model, together with data about its internal nodes. The question we want to answer is how we can compute bounds for partially identifiable counterfactual queries from such an input. We start by giving a map from structural casual models to credal networks. This allows us to compute exact counterfactual bounds via algorithms for credal nets on a subclass of structural causal models. Exact computation is going to be inefficient in general given that, as we show, causal inference is NP-hard even on polytrees. We target then approximate bounds via a causal EM scheme. We evaluate their accuracy by providing credible intervals on the quality of the approximation; we show through a synthetic benchmark that the EM scheme delivers accurate results in a fair number of runs. In the course of the discussion, we also point out what seems to be a neglected limitation to the trending idea that counterfactual bounds can be computed without knowledge of the structural equations. We also present a real case study on palliative care to show how our algorithms can readily be used for practical purposes.","sentences":["We assume to be given structural equations over discrete variables inducing a directed acyclic graph, namely, a structural causal model, together with data about its internal nodes.","The question we want to answer is how we can compute bounds for partially identifiable counterfactual queries from such an input.","We start by giving a map from structural casual models to credal networks.","This allows us to compute exact counterfactual bounds via algorithms for credal nets on a subclass of structural causal models.","Exact computation is going to be inefficient in general given that, as we show, causal inference is NP-hard even on polytrees.","We target then approximate bounds via a causal EM scheme.","We evaluate their accuracy by providing credible intervals on the quality of the approximation; we show through a synthetic benchmark that the EM scheme delivers accurate results in a fair number of runs.","In the course of the discussion, we also point out what seems to be a neglected limitation to the trending idea that counterfactual bounds can be computed without knowledge of the structural equations.","We also present a real case study on palliative care to show how our algorithms can readily be used for practical purposes."],"url":"http://arxiv.org/abs/2307.08304v1"}
{"created":"2023-07-17 07:55:47","title":"Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models","abstract":"Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific dense retrievers. We design a filter to select high-quality example document-query pairs in the prompt to further improve the quality of weak tagged queries. To the best of our knowledge, there is no prior work utilizing soft prompt tuning to augment DR models. The experiments demonstrate that SPTAR outperforms the unsupervised baselines BM25 and the recently proposed LLMs-based augmentation method for DR.","sentences":["Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space.","One of the challenges in DR is the lack of domain-specific training data.","While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally.","Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models.","However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries.","To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR):","For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific dense retrievers.","We design a filter to select high-quality example document-query pairs in the prompt to further improve the quality of weak tagged queries.","To the best of our knowledge, there is no prior work utilizing soft prompt tuning to augment DR models.","The experiments demonstrate that SPTAR outperforms the unsupervised baselines BM25 and the recently proposed LLMs-based augmentation method for DR."],"url":"http://arxiv.org/abs/2307.08303v1"}
{"created":"2023-07-17 07:55:21","title":"GBT: Two-stage transformer framework for non-stationary time series forecasting","abstract":"This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, esp. when handling non-stationary time series. Based on this observation, we propose GBT, a novel two-stage Transformer framework with Good Beginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences.Prediction results of Auto-Regression stage serve as a Good Beginning, i.e., a better initialization for inputs of Self-Regression stage. We also propose Error Score Modification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT","sentences":["This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, esp.","when handling non-stationary time series.","Based on this observation, we propose GBT, a novel two-stage Transformer framework with Good Beginning.","It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences.","Prediction results of Auto-Regression stage serve as a Good Beginning, i.e., a better initialization for inputs of Self-Regression stage.","We also propose Error Score Modification module to further enhance the forecasting capability of the Self-Regression stage in GBT.","Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity.","It is also general enough to couple with these models to strengthen their forecasting capability.","The source code is available at: https://github.com/OrigamiSL/GBT"],"url":"http://arxiv.org/abs/2307.08302v1"}
{"created":"2023-07-17 07:53:35","title":"Environment Knowledge Supported RAN Control for 6G Campus Networks","abstract":"In this paper, the authors present a Radio Access Network (RAN) concept for future mobile communication systems beyond 5G. The concept is based on knowledge of the environment. The three conceptual applications RAN authentication, beam steering, and channel estimation are presented and their added value with respect to 6G development goals is outlined. The concept is explained by means of an intralogistic use case of a fully automated warehouse. Based on this, the concrete steps for implementation in a laboratory setup are described and further research steps are shown.","sentences":["In this paper, the authors present a Radio Access Network (RAN) concept for future mobile communication systems beyond 5G.","The concept is based on knowledge of the environment.","The three conceptual applications RAN authentication, beam steering, and channel estimation are presented and their added value with respect to 6G development goals is outlined.","The concept is explained by means of an intralogistic use case of a fully automated warehouse.","Based on this, the concrete steps for implementation in a laboratory setup are described and further research steps are shown."],"url":"http://arxiv.org/abs/2307.08301v1"}
{"created":"2023-07-17 07:53:23","title":"ShiftNAS: Improving One-shot NAS via Probability Shift","abstract":"One-shot Neural architecture search (One-shot NAS) has been proposed as a time-efficient approach to obtain optimal subnet architectures and weights under different complexity cases by training only once. However, the subnet performance obtained by weight sharing is often inferior to the performance achieved by retraining. In this paper, we investigate the performance gap and attribute it to the use of uniform sampling, which is a common approach in supernet training. Uniform sampling concentrates training resources on subnets with intermediate computational resources, which are sampled with high probability. However, subnets with different complexity regions require different optimal training strategies for optimal performance. To address the problem of uniform sampling, we propose ShiftNAS, a method that can adjust the sampling probability based on the complexity of subnets. We achieve this by evaluating the performance variation of subnets with different complexity and designing an architecture generator that can accurately and efficiently provide subnets with the desired complexity. Both the sampling probability and the architecture generator can be trained end-to-end in a gradient-based manner. With ShiftNAS, we can directly obtain the optimal model architecture and parameters for a given computational complexity. We evaluate our approach on multiple visual network models, including convolutional neural networks (CNNs) and vision transformers (ViTs), and demonstrate that ShiftNAS is model-agnostic. Experimental results on ImageNet show that ShiftNAS can improve the performance of one-shot NAS without additional consumption. Source codes are available at https://github.com/bestfleer/ShiftNAS.","sentences":["One-shot Neural architecture search (One-shot NAS) has been proposed as a time-efficient approach to obtain optimal subnet architectures and weights under different complexity cases by training only once.","However, the subnet performance obtained by weight sharing is often inferior to the performance achieved by retraining.","In this paper, we investigate the performance gap and attribute it to the use of uniform sampling, which is a common approach in supernet training.","Uniform sampling concentrates training resources on subnets with intermediate computational resources, which are sampled with high probability.","However, subnets with different complexity regions require different optimal training strategies for optimal performance.","To address the problem of uniform sampling, we propose ShiftNAS, a method that can adjust the sampling probability based on the complexity of subnets.","We achieve this by evaluating the performance variation of subnets with different complexity and designing an architecture generator that can accurately and efficiently provide subnets with the desired complexity.","Both the sampling probability and the architecture generator can be trained end-to-end in a gradient-based manner.","With ShiftNAS, we can directly obtain the optimal model architecture and parameters for a given computational complexity.","We evaluate our approach on multiple visual network models, including convolutional neural networks (CNNs) and vision transformers (ViTs), and demonstrate that ShiftNAS is model-agnostic.","Experimental results on ImageNet show that ShiftNAS can improve the performance of one-shot NAS without additional consumption.","Source codes are available at https://github.com/bestfleer/ShiftNAS."],"url":"http://arxiv.org/abs/2307.08300v1"}
{"created":"2023-07-17 07:53:17","title":"Decentralized Local Updates with Dual-Slow Estimation and Momentum-based Variance-Reduction for Non-Convex Optimization","abstract":"Decentralized learning (DL) has recently employed local updates to reduce the communication cost for general non-convex optimization problems. Specifically, local updates require each node to perform multiple update steps on the parameters of the local model before communicating with others. However, most existing methods could be highly sensitive to data heterogeneity (i.e., non-iid data distribution) and adversely affected by the stochastic gradient noise. In this paper, we propose DSE-MVR to address these problems.Specifically, DSE-MVR introduces a dual-slow estimation strategy that utilizes the gradient tracking technique to estimate the global accumulated update direction for handling the data heterogeneity problem; also for stochastic noise, the method uses the mini-batch momentum-based variance-reduction technique.We theoretically prove that DSE-MVR can achieve optimal convergence results for general non-convex optimization in both iid and non-iid data distribution settings. In particular, the leading terms in the convergence rates derived by DSE-MVR are independent of the stochastic noise for large-batches or large partial average intervals (i.e., the number of local update steps). Further, we put forward DSE-SGD and theoretically justify the importance of the dual-slow estimation strategy in the data heterogeneity setting. Finally, we conduct extensive experiments to show the superiority of DSE-MVR against other state-of-the-art approaches.","sentences":["Decentralized learning (DL) has recently employed local updates to reduce the communication cost for general non-convex optimization problems.","Specifically, local updates require each node to perform multiple update steps on the parameters of the local model before communicating with others.","However, most existing methods could be highly sensitive to data heterogeneity (i.e., non-iid data distribution) and adversely affected by the stochastic gradient noise.","In this paper, we propose DSE-MVR to address these problems.","Specifically, DSE-MVR introduces a dual-slow estimation strategy that utilizes the gradient tracking technique to estimate the global accumulated update direction for handling the data heterogeneity problem; also for stochastic noise, the method uses the mini-batch momentum-based variance-reduction technique.","We theoretically prove that DSE-MVR can achieve optimal convergence results for general non-convex optimization in both iid and non-iid data distribution settings.","In particular, the leading terms in the convergence rates derived by DSE-MVR are independent of the stochastic noise for large-batches or large partial average intervals (i.e., the number of local update steps).","Further, we put forward DSE-SGD and theoretically justify the importance of the dual-slow estimation strategy in the data heterogeneity setting.","Finally, we conduct extensive experiments to show the superiority of DSE-MVR against other state-of-the-art approaches."],"url":"http://arxiv.org/abs/2307.08299v1"}
{"created":"2023-07-17 07:47:27","title":"1 JCAS-Enabled Sensing as a Service in 6th-Generation Mobile Communication Networks","abstract":"The introduction of new types of frequency spectrum in 6G technology facilitates the convergence of conventional mobile communications and radar functions. Thus, the mobile network itself becomes a versatile sensor system. This enables mobile network operators to offer a sensing service in addition to conventional data and telephony services. The potential benefits are expected to accrue to various stakeholders, including individuals, the environment, and society in general. The paper discusses technological development, possible integration, and use cases, as well as future development areas.","sentences":["The introduction of new types of frequency spectrum in 6G technology facilitates the convergence of conventional mobile communications and radar functions.","Thus, the mobile network itself becomes a versatile sensor system.","This enables mobile network operators to offer a sensing service in addition to conventional data and telephony services.","The potential benefits are expected to accrue to various stakeholders, including individuals, the environment, and society in general.","The paper discusses technological development, possible integration, and use cases, as well as future development areas."],"url":"http://arxiv.org/abs/2307.08296v1"}
{"created":"2023-07-17 07:38:46","title":"GHACPP: Genetic-based Human-Aware Coverage Path Planning Algorithm for Autonomous Disinfection Robot","abstract":"Numerous mobile robots with mounted Ultraviolet-C (UV-C) lamps were developed recently, yet they cannot work in the same space as humans without irradiating them by UV-C. This paper proposes a novel modular and scalable Human-Aware Genetic-based Coverage Path Planning algorithm (GHACPP), that aims to solve the problem of disinfecting of unknown environments by UV-C irradiation and preventing human eyes and skin from being harmed.   The proposed genetic-based algorithm alternates between the stages of exploring a new area, generating parts of the resulting disinfection trajectory, called mini-trajectories, and updating the current state around the robot. The system performance in effectiveness and human safety is validated and compared with one of the latest state-of-the-art online coverage path planning algorithms called SimExCoverage-STC. The experimental results confirmed both the high level of safety for humans and the efficiency of the developed algorithm in terms of decrease of path length (by 37.1%), number (39.5%) and size (35.2%) of turns, and time (7.6%) to complete the disinfection task, with a small loss in the percentage of area covered (0.6%), in comparison with the state-of-the-art approach.","sentences":["Numerous mobile robots with mounted Ultraviolet-C (UV-C) lamps were developed recently, yet they cannot work in the same space as humans without irradiating them by UV-C. This paper proposes a novel modular and scalable Human-Aware Genetic-based Coverage Path Planning algorithm (GHACPP), that aims to solve the problem of disinfecting of unknown environments by UV-C irradiation and preventing human eyes and skin from being harmed.   ","The proposed genetic-based algorithm alternates between the stages of exploring a new area, generating parts of the resulting disinfection trajectory, called mini-trajectories, and updating the current state around the robot.","The system performance in effectiveness and human safety is validated and compared with one of the latest state-of-the-art online coverage path planning algorithms called SimExCoverage-STC.","The experimental results confirmed both the high level of safety for humans and the efficiency of the developed algorithm in terms of decrease of path length (by 37.1%), number (39.5%) and size (35.2%) of turns, and time (7.6%) to complete the disinfection task, with a small loss in the percentage of area covered (0.6%), in comparison with the state-of-the-art approach."],"url":"http://arxiv.org/abs/2307.08294v1"}
{"created":"2023-07-17 07:24:55","title":"CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation","abstract":"Automatic diagnosis (AD), a critical application of AI in healthcare, employs machine learning techniques to assist doctors in gathering patient symptom information for precise disease diagnosis. The Transformer-based method utilizes an input symptom sequence, predicts itself through auto-regression, and employs the hidden state of the final symptom to determine the disease. Despite its simplicity and superior performance demonstrated, a decline in disease diagnosis accuracy is observed caused by 1) a mismatch between symptoms observed during training and generation, and 2) the effect of different symptom orders on disease prediction. To address the above obstacles, we introduce the CoAD, a novel disease and symptom collaborative generation framework, which incorporates several key innovations to improve AD: 1) aligning sentence-level disease labels with multiple possible symptom inquiry steps to bridge the gap between training and generation; 2) expanding symptom labels for each sub-sequence of symptoms to enhance annotation and eliminate the effect of symptom order; 3) developing a repeated symptom input schema to effectively and efficiently learn the expanded disease and symptom labels. We evaluate the CoAD framework using four datasets, including three public and one private, and demonstrate that it achieves an average 2.3% improvement over previous state-of-the-art results in automatic disease diagnosis. For reproducibility, we release the code and data at https://github.com/KwanWaiChung/coad.","sentences":["Automatic diagnosis (AD), a critical application of AI in healthcare, employs machine learning techniques to assist doctors in gathering patient symptom information for precise disease diagnosis.","The Transformer-based method utilizes an input symptom sequence, predicts itself through auto-regression, and employs the hidden state of the final symptom to determine the disease.","Despite its simplicity and superior performance demonstrated, a decline in disease diagnosis accuracy is observed caused by 1) a mismatch between symptoms observed during training and generation, and 2) the effect of different symptom orders on disease prediction.","To address the above obstacles, we introduce the CoAD, a novel disease and symptom collaborative generation framework, which incorporates several key innovations to improve AD: 1) aligning sentence-level disease labels with multiple possible symptom inquiry steps to bridge the gap between training and generation; 2) expanding symptom labels for each sub-sequence of symptoms to enhance annotation and eliminate the effect of symptom order; 3) developing a repeated symptom input schema to effectively and efficiently learn the expanded disease and symptom labels.","We evaluate the CoAD framework using four datasets, including three public and one private, and demonstrate that it achieves an average 2.3% improvement over previous state-of-the-art results in automatic disease diagnosis.","For reproducibility, we release the code and data at https://github.com/KwanWaiChung/coad."],"url":"http://arxiv.org/abs/2307.08290v1"}
{"created":"2023-07-17 07:19:17","title":"Systematic Testing of the Data-Poisoning Robustness of KNN","abstract":"Data poisoning aims to compromise a machine learning based software component by contaminating its training set to change its prediction results for test inputs. Existing methods for deciding data-poisoning robustness have either poor accuracy or long running time and, more importantly, they can only certify some of the truly-robust cases, but remain inconclusive when certification fails. In other words, they cannot falsify the truly-non-robust cases. To overcome this limitation, we propose a systematic testing based method, which can falsify as well as certify data-poisoning robustness for a widely used supervised-learning technique named k-nearest neighbors (KNN). Our method is faster and more accurate than the baseline enumeration method, due to a novel over-approximate analysis in the abstract domain, to quickly narrow down the search space, and systematic testing in the concrete domain, to find the actual violations. We have evaluated our method on a set of supervised-learning datasets. Our results show that the method significantly outperforms state-of-the-art techniques, and can decide data-poisoning robustness of KNN prediction results for most of the test inputs.","sentences":["Data poisoning aims to compromise a machine learning based software component by contaminating its training set to change its prediction results for test inputs.","Existing methods for deciding data-poisoning robustness have either poor accuracy or long running time and, more importantly, they can only certify some of the truly-robust cases, but remain inconclusive when certification fails.","In other words, they cannot falsify the truly-non-robust cases.","To overcome this limitation, we propose a systematic testing based method, which can falsify as well as certify data-poisoning robustness for a widely used supervised-learning technique named k-nearest neighbors (KNN).","Our method is faster and more accurate than the baseline enumeration method, due to a novel over-approximate analysis in the abstract domain, to quickly narrow down the search space, and systematic testing in the concrete domain, to find the actual violations.","We have evaluated our method on a set of supervised-learning datasets.","Our results show that the method significantly outperforms state-of-the-art techniques, and can decide data-poisoning robustness of KNN prediction results for most of the test inputs."],"url":"http://arxiv.org/abs/2307.08288v1"}
{"created":"2023-07-17 07:16:28","title":"Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity","abstract":"Recent work has revealed many intriguing empirical phenomena in neural network training, despite the poorly understood and highly complex loss landscapes and training dynamics. One of these phenomena, Linear Mode Connectivity (LMC), has gained considerable attention due to the intriguing observation that different solutions can be connected by a linear path in the parameter space while maintaining near-constant training and test losses. In this work, we introduce a stronger notion of linear connectivity, Layerwise Linear Feature Connectivity (LLFC), which says that the feature maps of every layer in different trained networks are also linearly connected. We provide comprehensive empirical evidence for LLFC across a wide range of settings, demonstrating that whenever two trained networks satisfy LMC (via either spawning or permutation methods), they also satisfy LLFC in nearly all the layers. Furthermore, we delve deeper into the underlying factors contributing to LLFC, which reveal new insights into the spawning and permutation approaches. The study of LLFC transcends and advances our understanding of LMC by adopting a feature-learning perspective.","sentences":["Recent work has revealed many intriguing empirical phenomena in neural network training, despite the poorly understood and highly complex loss landscapes and training dynamics.","One of these phenomena, Linear Mode Connectivity (LMC), has gained considerable attention due to the intriguing observation that different solutions can be connected by a linear path in the parameter space while maintaining near-constant training and test losses.","In this work, we introduce a stronger notion of linear connectivity, Layerwise Linear Feature Connectivity (LLFC), which says that the feature maps of every layer in different trained networks are also linearly connected.","We provide comprehensive empirical evidence for LLFC across a wide range of settings, demonstrating that whenever two trained networks satisfy LMC (via either spawning or permutation methods), they also satisfy LLFC in nearly all the layers.","Furthermore, we delve deeper into the underlying factors contributing to LLFC, which reveal new insights into the spawning and permutation approaches.","The study of LLFC transcends and advances our understanding of LMC by adopting a feature-learning perspective."],"url":"http://arxiv.org/abs/2307.08286v1"}
{"created":"2023-07-17 07:12:29","title":"Complexity Matters: Rethinking the Latent Space for Generative Modeling","abstract":"In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel \"distance\" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propose a two-stage training strategy called Decoupled Autoencoder (DAE), where the encoder is only updated in the first stage with an auxiliary decoder and then frozen in the second stage while the actual decoder is being trained. DAE can improve the latent distribution and as a result, improve the generative performance. Our theoretical analyses are corroborated by comprehensive experiments on various models such as VQGAN and Diffusion Transformer, where our modifications yield significant improvements in sample quality with decreased model complexity.","sentences":["In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder.","Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear.","In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity.","Our investigation starts with the classic generative adversarial networks (GANs).","Inspired by the GAN training objective, we propose a novel \"distance\" between the latent and data distributions, whose minimization coincides with that of the generator complexity.","The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity.","Then, we consider parameterizing such a latent distribution by an encoder network and propose a two-stage training strategy called Decoupled Autoencoder (DAE), where the encoder is only updated in the first stage with an auxiliary decoder and then frozen in the second stage while the actual decoder is being trained.","DAE can improve the latent distribution and as a result, improve the generative performance.","Our theoretical analyses are corroborated by comprehensive experiments on various models such as VQGAN and Diffusion Transformer, where our modifications yield significant improvements in sample quality with decreased model complexity."],"url":"http://arxiv.org/abs/2307.08283v1"}
{"created":"2023-07-17 06:58:22","title":"Adversarial Attacks on Traffic Sign Recognition: A Survey","abstract":"Traffic sign recognition is an essential component of perception in autonomous vehicles, which is currently performed almost exclusively with deep neural networks (DNNs). However, DNNs are known to be vulnerable to adversarial attacks. Several previous works have demonstrated the feasibility of adversarial attacks on traffic sign recognition models. Traffic signs are particularly promising for adversarial attack research due to the ease of performing real-world attacks using printed signs or stickers. In this work, we survey existing works performing either digital or real-world attacks on traffic sign detection and classification models. We provide an overview of the latest advancements and highlight the existing research areas that require further investigation.","sentences":["Traffic sign recognition is an essential component of perception in autonomous vehicles, which is currently performed almost exclusively with deep neural networks (DNNs).","However, DNNs are known to be vulnerable to adversarial attacks.","Several previous works have demonstrated the feasibility of adversarial attacks on traffic sign recognition models.","Traffic signs are particularly promising for adversarial attack research due to the ease of performing real-world attacks using printed signs or stickers.","In this work, we survey existing works performing either digital or real-world attacks on traffic sign detection and classification models.","We provide an overview of the latest advancements and highlight the existing research areas that require further investigation."],"url":"http://arxiv.org/abs/2307.08278v1"}
{"created":"2023-07-17 06:45:21","title":"Adaptive Compliant Robot Control with Failure Recovery for Object Press-Fitting","abstract":"Loading of shipping containers for dairy products often includes a press-fit task, which involves manually stacking milk cartons in a container without using pallets or packaging. Automating this task with a mobile manipulator can reduce worker strain, and also enhance the efficiency and safety of the container loading process. This paper proposes an approach called Adaptive Compliant Control with Integrated Failure Recovery (ACCIFR), which enables a mobile manipulator to reliably perform the press-fit task. We base the approach on a demonstration learning-based compliant control framework, such that we integrate a monitoring and failure recovery mechanism for successful task execution. Concretely, we monitor the execution through distance and force feedback, detect collisions while the robot is performing the press-fit task, and use wrench measurements to classify the direction of collision; this information informs the subsequent recovery process. We evaluate the method on a miniature container setup, considering variations in the (i) starting position of the end effector, (ii) goal configuration, and (iii) object grasping position. The results demonstrate that the proposed approach outperforms the baseline demonstration-based learning framework regarding adaptability to environmental variations and the ability to recover from collision failures, making it a promising solution for practical press-fit applications.","sentences":["Loading of shipping containers for dairy products often includes a press-fit task, which involves manually stacking milk cartons in a container without using pallets or packaging.","Automating this task with a mobile manipulator can reduce worker strain, and also enhance the efficiency and safety of the container loading process.","This paper proposes an approach called Adaptive Compliant Control with Integrated Failure Recovery (ACCIFR), which enables a mobile manipulator to reliably perform the press-fit task.","We base the approach on a demonstration learning-based compliant control framework, such that we integrate a monitoring and failure recovery mechanism for successful task execution.","Concretely, we monitor the execution through distance and force feedback, detect collisions while the robot is performing the press-fit task, and use wrench measurements to classify the direction of collision; this information informs the subsequent recovery process.","We evaluate the method on a miniature container setup, considering variations in the (i) starting position of the end effector, (ii) goal configuration, and (iii) object grasping position.","The results demonstrate that the proposed approach outperforms the baseline demonstration-based learning framework regarding adaptability to environmental variations and the ability to recover from collision failures, making it a promising solution for practical press-fit applications."],"url":"http://arxiv.org/abs/2307.08274v1"}
{"created":"2023-07-17 06:36:53","title":"ChatGPT is Good but Bing Chat is Better for Vietnamese Students","abstract":"This paper investigates the performance of two large language models (LLMs), ChatGPT and Microsoft Bing Chat (BingChat), for Vietnamese students. While ChatGPT demonstrates competency in various subjects, Bing Chat emerges as the superior choice. We compare their performances across multiple subjects at high school level, including mathematics, literature, English, physics, chemistry, biology, history, geography, and civic education. Our findings indicate that BingChat surpasses ChatGPT in most subjects, except for literature where ChatGPT outperforms. Moreover, BingChat leverages the more advanced GPT-4 technology compared to ChatGPT based on GPT-3.5, leading to enhanced understanding and generation of creative and informative text. Furthermore, BingChat's availability in Vietnam and its incorporation of hyperlinks in answers further solidify its superiority. We conclude that while ChatGPT is commendable, Bing Chat offers a more comprehensive and advanced solution for Vietnamese students.","sentences":["This paper investigates the performance of two large language models (LLMs), ChatGPT and Microsoft Bing Chat (BingChat), for Vietnamese students.","While ChatGPT demonstrates competency in various subjects, Bing Chat emerges as the superior choice.","We compare their performances across multiple subjects at high school level, including mathematics, literature, English, physics, chemistry, biology, history, geography, and civic education.","Our findings indicate that BingChat surpasses ChatGPT in most subjects, except for literature where ChatGPT outperforms.","Moreover, BingChat leverages the more advanced GPT-4 technology compared to ChatGPT based on GPT-3.5, leading to enhanced understanding and generation of creative and informative text.","Furthermore, BingChat's availability in Vietnam and its incorporation of hyperlinks in answers further solidify its superiority.","We conclude that while ChatGPT is commendable, Bing Chat offers a more comprehensive and advanced solution for Vietnamese students."],"url":"http://arxiv.org/abs/2307.08272v1"}
{"created":"2023-07-17 06:31:56","title":"Extending the primal-dual 2-approximation algorithm beyond uncrossable set families","abstract":"A set family ${\\cal F}$ is $uncrossable$ if $A \\cap B,A \\cup B \\in {\\cal F}$ or $A \\setminus B,B \\setminus A \\in {\\cal F}$ for any $A,B \\in {\\cal F}$. A classic result of Williamson, Goemans, Mihail, and Vazirani [STOC 1993:708-717] states that the problem of covering an uncrossable set family by a min-cost edge set admits approximation ratio $2$, by a primal-dual algorithm. They asked whether this result extends to a larger class of set families and combinatorial optimization problems. We define a new class of $semi$-$uncrossable$ $set$ $families$, when for any $A,B \\in {\\cal F}$ we have that $A \\cap B \\in {\\cal F}$ and one of $A \\cup B,A \\setminus B ,B \\setminus A$ is in ${\\cal F}$, or $A \\setminus B,B \\setminus A \\in {\\cal F}$. We will show that the Williamson et al. algorithm extends to this new class of families and identify several ``non-uncrossable'' algorithmic problems that belong to this class. In particular, we will show that the union of an uncrossable family and a monotone family, or of an uncrossable family that has the disjointness property and a proper family, is a semi-uncrossable family, that in general is not uncrossable. For example, our result implies approximation ratio $2$ for the problem of finding a min-cost subgraph $H$ such that $H$ contains a Steiner forest and every connected component of $H$ contains at least $k$ nodes from a given set $T$ of terminals.","sentences":["A set family ${\\cal F}$ is $uncrossable$ if $A \\cap B,A \\cup B \\in {\\cal F}$ or $A \\setminus B,B \\setminus A \\in {\\cal F}$ for any $A,B \\in {","\\cal F}$.","A classic result of Williamson, Goemans, Mihail, and Vazirani [STOC 1993:708-717] states that the problem of covering an uncrossable set family by a min-cost edge set admits approximation ratio $2$, by a primal-dual algorithm.","They asked whether this result extends to a larger class of set families and combinatorial optimization problems.","We define a new class of $semi$-$uncrossable$ $set$ $families$, when for any $A,B \\in {\\cal F}$ we have that $A \\cap B \\in {\\cal F}$ and one of $A \\cup B,A \\setminus B ,B \\setminus A$ is in ${\\cal F}$, or $A \\setminus B,B \\setminus A \\in {\\cal F}$.","We will show that the Williamson et al. algorithm extends to this new class of families and identify several ``non-uncrossable'' algorithmic problems that belong to this class.","In particular, we will show that the union of an uncrossable family and a monotone family, or of an uncrossable family that has the disjointness property and a proper family, is a semi-uncrossable family, that in general is not uncrossable.","For example, our result implies approximation ratio $2$ for the problem of finding a min-cost subgraph $H$ such that $H$ contains a Steiner forest and every connected component of $H$ contains at least $k$ nodes from a given set $T$ of terminals."],"url":"http://arxiv.org/abs/2307.08270v1"}
{"created":"2023-07-17 06:14:19","title":"Extreme Image Compression using Fine-tuned VQGAN Models","abstract":"Recent advances in generative compression methods have demonstrated remarkable progress in enhancing the perceptual quality of compressed data, especially in scenarios with low bitrates. Nevertheless, their efficacy and applicability in achieving extreme compression ratios ($<0.1$ bpp) still remain constrained. In this work, we propose a simple yet effective coding framework by introducing vector quantization (VQ)-based generative models into the image compression domain. The main insight is that the codebook learned by the VQGAN model yields strong expressive capacity, facilitating efficient compression of continuous information in the latent space while maintaining reconstruction quality. Specifically, an image can be represented as VQ-indices by finding the nearest codeword, which can be encoded using lossless compression methods into bitstreams. We then propose clustering a pre-trained large-scale codebook into smaller codebooks using the K-means algorithm. This enables images to be represented as diverse ranges of VQ-indices maps, resulting in variable bitrates and different levels of reconstruction quality. Extensive qualitative and quantitative experiments on various datasets demonstrate that the proposed framework outperforms the state-of-the-art codecs in terms of perceptual quality-oriented metrics and human perception under extremely low bitrates.","sentences":["Recent advances in generative compression methods have demonstrated remarkable progress in enhancing the perceptual quality of compressed data, especially in scenarios with low bitrates.","Nevertheless, their efficacy and applicability in achieving extreme compression ratios ($<0.1$ bpp) still remain constrained.","In this work, we propose a simple yet effective coding framework by introducing vector quantization (VQ)-based generative models into the image compression domain.","The main insight is that the codebook learned by the VQGAN model yields strong expressive capacity, facilitating efficient compression of continuous information in the latent space while maintaining reconstruction quality.","Specifically, an image can be represented as VQ-indices by finding the nearest codeword, which can be encoded using lossless compression methods into bitstreams.","We then propose clustering a pre-trained large-scale codebook into smaller codebooks using the K-means algorithm.","This enables images to be represented as diverse ranges of VQ-indices maps, resulting in variable bitrates and different levels of reconstruction quality.","Extensive qualitative and quantitative experiments on various datasets demonstrate that the proposed framework outperforms the state-of-the-art codecs in terms of perceptual quality-oriented metrics and human perception under extremely low bitrates."],"url":"http://arxiv.org/abs/2307.08265v1"}
{"created":"2023-07-17 06:12:26","title":"Hierarchical Spatiotemporal Transformers for Video Object Segmentation","abstract":"This paper presents a novel framework called HST for semi-supervised video object segmentation (VOS). HST extracts image and video features using the latest Swin Transformer and Video Swin Transformer to inherit their inductive bias for the spatiotemporal locality, which is essential for temporally coherent VOS. To take full advantage of the image and video features, HST casts image and video features as a query and memory, respectively. By applying efficient memory read operations at multiple scales, HST produces hierarchical features for the precise reconstruction of object masks. HST shows effectiveness and robustness in handling challenging scenarios with occluded and fast-moving objects under cluttered backgrounds. In particular, HST-B outperforms the state-of-the-art competitors on multiple popular benchmarks, i.e., YouTube-VOS (85.0%), DAVIS 2017 (85.9%), and DAVIS 2016 (94.0%).","sentences":["This paper presents a novel framework called HST for semi-supervised video object segmentation (VOS).","HST extracts image and video features using the latest Swin Transformer and Video Swin Transformer to inherit their inductive bias for the spatiotemporal locality, which is essential for temporally coherent VOS.","To take full advantage of the image and video features, HST casts image and video features as a query and memory, respectively.","By applying efficient memory read operations at multiple scales, HST produces hierarchical features for the precise reconstruction of object masks.","HST shows effectiveness and robustness in handling challenging scenarios with occluded and fast-moving objects under cluttered backgrounds.","In particular, HST-B outperforms the state-of-the-art competitors on multiple popular benchmarks, i.e., YouTube-VOS (85.0%), DAVIS 2017 (85.9%), and DAVIS 2016 (94.0%)."],"url":"http://arxiv.org/abs/2307.08263v1"}
{"created":"2023-07-17 06:10:03","title":"Team Badminseok at IJCAI CoachAI Badminton Challenge 2023: Multi-Layer Multi-Input Transformer Network (MuLMINet) with Weighted Loss","abstract":"The increasing use of artificial intelligence (AI) technology in turn-based sports, such as badminton, has sparked significant interest in evaluating strategies through the analysis of match video data. Predicting future shots based on past ones plays a vital role in coaching and strategic planning. In this study, we present a Multi-Layer Multi-Input Transformer Network (MuLMINet) that leverages professional badminton player match data to accurately predict future shot types and area coordinates. Our approach resulted in achieving the runner-up (2nd place) in the IJCAI CoachAI Badminton Challenge 2023, Track 2. To facilitate further research, we have made our code publicly accessible online, contributing to the broader research community's knowledge and advancements in the field of AI-assisted sports analysis.","sentences":["The increasing use of artificial intelligence (AI) technology in turn-based sports, such as badminton, has sparked significant interest in evaluating strategies through the analysis of match video data.","Predicting future shots based on past ones plays a vital role in coaching and strategic planning.","In this study, we present a Multi-Layer Multi-Input Transformer Network (MuLMINet) that leverages professional badminton player match data to accurately predict future shot types and area coordinates.","Our approach resulted in achieving the runner-up (2nd place) in the IJCAI CoachAI Badminton Challenge 2023, Track 2.","To facilitate further research, we have made our code publicly accessible online, contributing to the broader research community's knowledge and advancements in the field of AI-assisted sports analysis."],"url":"http://arxiv.org/abs/2307.08262v1"}
{"created":"2023-07-17 06:06:58","title":"Extending the Frontier of ChatGPT: Code Generation and Debugging","abstract":"Large-scale language models (LLMs) have emerged as a groundbreaking innovation in the realm of question-answering and conversational agents. These models, leveraging different deep learning architectures such as Transformers, are trained on vast corpora to predict sentences based on given queries. Among these LLMs, ChatGPT, developed by OpenAI, has ushered in a new era by utilizing artificial intelligence (AI) to tackle diverse problem domains, ranging from composing essays and biographies to solving intricate mathematical integrals. The versatile applications enabled by ChatGPT offer immense value to users. However, assessing the performance of ChatGPT's output poses a challenge, particularly in scenarios where queries lack clear objective criteria for correctness. For instance, evaluating the quality of generated essays becomes arduous and relies heavily on manual labor, in stark contrast to evaluating solutions to well-defined, closed-ended questions such as mathematical problems. This research paper delves into the efficacy of ChatGPT in solving programming problems, examining both the correctness and the efficiency of its solution in terms of time and memory complexity. The research reveals a commendable overall success rate of 71.875\\%, denoting the proportion of problems for which ChatGPT was able to provide correct solutions that successfully satisfied all the test cases present in Leetcode. It exhibits strengths in structured problems and shows a linear correlation between its success rate and problem acceptance rates. However, it struggles to improve solutions based on feedback, pointing to potential shortcomings in debugging tasks. These findings provide a compact yet insightful glimpse into ChatGPT's capabilities and areas for improvement.","sentences":["Large-scale language models (LLMs) have emerged as a groundbreaking innovation in the realm of question-answering and conversational agents.","These models, leveraging different deep learning architectures such as Transformers, are trained on vast corpora to predict sentences based on given queries.","Among these LLMs, ChatGPT, developed by OpenAI, has ushered in a new era by utilizing artificial intelligence (AI) to tackle diverse problem domains, ranging from composing essays and biographies to solving intricate mathematical integrals.","The versatile applications enabled by ChatGPT offer immense value to users.","However, assessing the performance of ChatGPT's output poses a challenge, particularly in scenarios where queries lack clear objective criteria for correctness.","For instance, evaluating the quality of generated essays becomes arduous and relies heavily on manual labor, in stark contrast to evaluating solutions to well-defined, closed-ended questions such as mathematical problems.","This research paper delves into the efficacy of ChatGPT in solving programming problems, examining both the correctness and the efficiency of its solution in terms of time and memory complexity.","The research reveals a commendable overall success rate of 71.875\\%, denoting the proportion of problems for which ChatGPT was able to provide correct solutions that successfully satisfied all the test cases present in Leetcode.","It exhibits strengths in structured problems and shows a linear correlation between its success rate and problem acceptance rates.","However, it struggles to improve solutions based on feedback, pointing to potential shortcomings in debugging tasks.","These findings provide a compact yet insightful glimpse into ChatGPT's capabilities and areas for improvement."],"url":"http://arxiv.org/abs/2307.08260v1"}
{"created":"2023-07-17 06:03:51","title":"Measuring Item Global Residual Value for Fair Recommendation","abstract":"In the era of information explosion, numerous items emerge every day, especially in feed scenarios. Due to the limited system display slots and user browsing attention, various recommendation systems are designed not only to satisfy users' personalized information needs but also to allocate items' exposure. However, recent recommendation studies mainly focus on modeling user preferences to present satisfying results and maximize user interactions, while paying little attention to developing item-side fair exposure mechanisms for rational information delivery. This may lead to serious resource allocation problems on the item side, such as the Snowball Effect. Furthermore, unfair exposure mechanisms may hurt recommendation performance. In this paper, we call for a shift of attention from modeling user preferences to developing fair exposure mechanisms for items. We first conduct empirical analyses of feed scenarios to explore exposure problems between items with distinct uploaded times. This points out that unfair exposure caused by the time factor may be the major cause of the Snowball Effect. Then, we propose to explicitly model item-level customized timeliness distribution, Global Residual Value (GRV), for fair resource allocation. This GRV module is introduced into recommendations with the designed Timeliness-aware Fair Recommendation Framework (TaFR). Extensive experiments on two datasets demonstrate that TaFR achieves consistent improvements with various backbone recommendation models. By modeling item-side customized Global Residual Value, we achieve a fairer distribution of resources and, at the same time, improve recommendation performance.","sentences":["In the era of information explosion, numerous items emerge every day, especially in feed scenarios.","Due to the limited system display slots and user browsing attention, various recommendation systems are designed not only to satisfy users' personalized information needs but also to allocate items' exposure.","However, recent recommendation studies mainly focus on modeling user preferences to present satisfying results and maximize user interactions, while paying little attention to developing item-side fair exposure mechanisms for rational information delivery.","This may lead to serious resource allocation problems on the item side, such as the Snowball Effect.","Furthermore, unfair exposure mechanisms may hurt recommendation performance.","In this paper, we call for a shift of attention from modeling user preferences to developing fair exposure mechanisms for items.","We first conduct empirical analyses of feed scenarios to explore exposure problems between items with distinct uploaded times.","This points out that unfair exposure caused by the time factor may be the major cause of the Snowball Effect.","Then, we propose to explicitly model item-level customized timeliness distribution, Global Residual Value (GRV), for fair resource allocation.","This GRV module is introduced into recommendations with the designed Timeliness-aware Fair Recommendation Framework (TaFR).","Extensive experiments on two datasets demonstrate that TaFR achieves consistent improvements with various backbone recommendation models.","By modeling item-side customized Global Residual Value, we achieve a fairer distribution of resources and, at the same time, improve recommendation performance."],"url":"http://arxiv.org/abs/2307.08259v1"}
{"created":"2023-07-17 05:47:13","title":"URLLC in IRS-Aided MIMO Systems: Finite Blocklength Analysis and Design","abstract":"This paper investigates the ultra reliable and low latency communication (URLLC) performance of the IRS-aided MIMO system. The upper and lower bounds of the optimal average error probability (OAEP) for the coding rate within 1/sqrt(Mn) of the capacity are derived, where n and M represent the blocklength and the number of transmit antennas, respectively. To achieve this goal, a new central limit theorem (CLT) for the mutual information density over the IRS-aided MIMO system is derived in the asymptotic regime where the block-length, the IRS size, and number of the antennas go to infinity with the same pace. The CLT is then utilized to derive the closed-form upper and lower bounds for the OAEP. Based on the analysis result, a gradient-based algorithm is proposed to minimize the lower bound of the OAEP by optimizing the phase shift of the IRS. Simulation results validate the fitness of the CLT and the effectiveness of the proposed algorithm in optimizing the theoretical bound, as well as the performance of practical LDPC code.","sentences":["This paper investigates the ultra reliable and low latency communication (URLLC) performance of the IRS-aided MIMO system.","The upper and lower bounds of the optimal average error probability (OAEP) for the coding rate within 1/sqrt(Mn) of the capacity are derived, where n and M represent the blocklength and the number of transmit antennas, respectively.","To achieve this goal, a new central limit theorem (CLT) for the mutual information density over the IRS-aided MIMO system is derived in the asymptotic regime where the block-length, the IRS size, and number of the antennas go to infinity with the same pace.","The CLT is then utilized to derive the closed-form upper and lower bounds for the OAEP.","Based on the analysis result, a gradient-based algorithm is proposed to minimize the lower bound of the OAEP by optimizing the phase shift of the IRS.","Simulation results validate the fitness of the CLT and the effectiveness of the proposed algorithm in optimizing the theoretical bound, as well as the performance of practical LDPC code."],"url":"http://arxiv.org/abs/2307.08256v1"}
{"created":"2023-07-17 05:36:01","title":"Large-Scale Person Detection and Localization using Overhead Fisheye Cameras","abstract":"Location determination finds wide applications in daily life. Instead of existing efforts devoted to localizing tourist photos captured by perspective cameras, in this article, we focus on devising person positioning solutions using overhead fisheye cameras. Such solutions are advantageous in large field of view (FOV), low cost, anti-occlusion, and unaggressive work mode (without the necessity of cameras carried by persons). However, related studies are quite scarce, due to the paucity of data. To stimulate research in this exciting area, we present LOAF, the first large-scale overhead fisheye dataset for person detection and localization. LOAF is built with many essential features, e.g., i) the data cover abundant diversities in scenes, human pose, density, and location; ii) it contains currently the largest number of annotated pedestrian, i.e., 457K bounding boxes with groundtruth location information; iii) the body-boxes are labeled as radius-aligned so as to fully address the positioning challenge. To approach localization, we build a fisheye person detection network, which exploits the fisheye distortions by a rotation-equivariant training strategy and predict radius-aligned human boxes end-to-end. Then, the actual locations of the detected persons are calculated by a numerical solution on the fisheye model and camera altitude data. Extensive experiments on LOAF validate the superiority of our fisheye detector w.r.t. previous methods, and show that our whole fisheye positioning solution is able to locate all persons in FOV with an accuracy of 0.5 m, within 0.1 s.","sentences":["Location determination finds wide applications in daily life.","Instead of existing efforts devoted to localizing tourist photos captured by perspective cameras, in this article, we focus on devising person positioning solutions using overhead fisheye cameras.","Such solutions are advantageous in large field of view (FOV), low cost, anti-occlusion, and unaggressive work mode (without the necessity of cameras carried by persons).","However, related studies are quite scarce, due to the paucity of data.","To stimulate research in this exciting area, we present LOAF, the first large-scale overhead fisheye dataset for person detection and localization.","LOAF is built with many essential features, e.g., i) the data cover abundant diversities in scenes, human pose, density, and location; ii) it contains currently the largest number of annotated pedestrian, i.e., 457K bounding boxes with groundtruth location information; iii) the body-boxes are labeled as radius-aligned so as to fully address the positioning challenge.","To approach localization, we build a fisheye person detection network, which exploits the fisheye distortions by a rotation-equivariant training strategy and predict radius-aligned human boxes end-to-end.","Then, the actual locations of the detected persons are calculated by a numerical solution on the fisheye model and camera altitude data.","Extensive experiments on LOAF validate the superiority of our fisheye detector w.r.t.","previous methods, and show that our whole fisheye positioning solution is able to locate all persons in FOV with an accuracy of 0.5 m, within 0.1 s."],"url":"http://arxiv.org/abs/2307.08252v1"}
{"created":"2023-07-17 05:08:32","title":"Random Boxes Are Open-world Object Detectors","abstract":"We show that classifiers trained with random region proposals achieve state-of-the-art Open-world Object Detection (OWOD): they can not only maintain the accuracy of the known objects (w/ training labels), but also considerably improve the recall of unknown ones (w/o training labels). Specifically, we propose RandBox, a Fast R-CNN based architecture trained on random proposals at each training iteration, surpassing existing Faster R-CNN and Transformer based OWOD. Its effectiveness stems from the following two benefits introduced by randomness. First, as the randomization is independent of the distribution of the limited known objects, the random proposals become the instrumental variable that prevents the training from being confounded by the known objects. Second, the unbiased training encourages more proposal explorations by using our proposed matching score that does not penalize the random proposals whose prediction scores do not match the known objects. On two benchmarks: Pascal-VOC/MS-COCO and LVIS, RandBox significantly outperforms the previous state-of-the-art in all metrics. We also detail the ablations on randomization and loss designs. Codes are available at https://github.com/scuwyh2000/RandBox.","sentences":["We show that classifiers trained with random region proposals achieve state-of-the-art Open-world Object Detection (OWOD): they can not only maintain the accuracy of the known objects (w/ training labels), but also considerably improve the recall of unknown ones (w/o training labels).","Specifically, we propose RandBox, a Fast R-CNN based architecture trained on random proposals at each training iteration, surpassing existing Faster R-CNN and Transformer based OWOD.","Its effectiveness stems from the following two benefits introduced by randomness.","First, as the randomization is independent of the distribution of the limited known objects, the random proposals become the instrumental variable that prevents the training from being confounded by the known objects.","Second, the unbiased training encourages more proposal explorations by using our proposed matching score that does not penalize the random proposals whose prediction scores do not match the known objects.","On two benchmarks: Pascal-VOC/MS-COCO and LVIS, RandBox significantly outperforms the previous state-of-the-art in all metrics.","We also detail the ablations on randomization and loss designs.","Codes are available at https://github.com/scuwyh2000/RandBox."],"url":"http://arxiv.org/abs/2307.08249v1"}
{"created":"2023-07-17 05:05:15","title":"PAT: Parallel Attention Transformer for Visual Question Answering in Vietnamese","abstract":"We present in this paper a novel scheme for multimodal learning named the Parallel Attention mechanism. In addition, to take into account the advantages of grammar and context in Vietnamese, we propose the Hierarchical Linguistic Features Extractor instead of using an LSTM network to extract linguistic features. Based on these two novel modules, we introduce the Parallel Attention Transformer (PAT), achieving the best accuracy compared to all baselines on the benchmark ViVQA dataset and other SOTA methods including SAAA and MCAN.","sentences":["We present in this paper a novel scheme for multimodal learning named the Parallel Attention mechanism.","In addition, to take into account the advantages of grammar and context in Vietnamese, we propose the Hierarchical Linguistic Features Extractor instead of using an LSTM network to extract linguistic features.","Based on these two novel modules, we introduce the Parallel Attention Transformer (PAT), achieving the best accuracy compared to all baselines on the benchmark ViVQA dataset and other SOTA methods including SAAA and MCAN."],"url":"http://arxiv.org/abs/2307.08247v1"}
{"created":"2023-07-17 04:55:02","title":"Uncertainty-aware State Space Transformer for Egocentric 3D Hand Trajectory Forecasting","abstract":"Hand trajectory forecasting from egocentric views is crucial for enabling a prompt understanding of human intentions when interacting with AR/VR systems. However, existing methods handle this problem in a 2D image space which is inadequate for 3D real-world applications. In this paper, we set up an egocentric 3D hand trajectory forecasting task that aims to predict hand trajectories in a 3D space from early observed RGB videos in a first-person view. To fulfill this goal, we propose an uncertainty-aware state space Transformer (USST) that takes the merits of the attention mechanism and aleatoric uncertainty within the framework of the classical state-space model. The model can be further enhanced by the velocity constraint and visual prompt tuning (VPT) on large vision transformers. Moreover, we develop an annotation workflow to collect 3D hand trajectories with high quality. Experimental results on H2O and EgoPAT3D datasets demonstrate the superiority of USST for both 2D and 3D trajectory forecasting. The code and datasets are publicly released: https://github.com/Cogito2012/USST.","sentences":["Hand trajectory forecasting from egocentric views is crucial for enabling a prompt understanding of human intentions when interacting with AR/VR systems.","However, existing methods handle this problem in a 2D image space which is inadequate for 3D real-world applications.","In this paper, we set up an egocentric 3D hand trajectory forecasting task that aims to predict hand trajectories in a 3D space from early observed RGB videos in a first-person view.","To fulfill this goal, we propose an uncertainty-aware state space Transformer (USST) that takes the merits of the attention mechanism and aleatoric uncertainty within the framework of the classical state-space model.","The model can be further enhanced by the velocity constraint and visual prompt tuning (VPT) on large vision transformers.","Moreover, we develop an annotation workflow to collect 3D hand trajectories with high quality.","Experimental results on H2O and EgoPAT3D datasets demonstrate the superiority of USST for both 2D and 3D trajectory forecasting.","The code and datasets are publicly released: https://github.com/Cogito2012/USST."],"url":"http://arxiv.org/abs/2307.08243v1"}
{"created":"2023-07-17 04:54:58","title":"Lifted Sequential Planning with Lazy Constraint Generation Solvers","abstract":"This paper studies the possibilities made open by the use of Lazy Clause Generation (LCG) based approaches to Constraint Programming (CP) for tackling sequential classical planning. We propose a novel CP model based on seminal ideas on so-called lifted causal encodings for planning as satisfiability, that does not require grounding, as choosing groundings for functions and action schemas becomes an integral part of the problem of designing valid plans. This encoding does not require encoding frame axioms, and does not explicitly represent states as decision variables for every plan step. We also present a propagator procedure that illustrates the possibilities of LCG to widen the kind of inference methods considered to be feasible in planning as (iterated) CSP solving. We test encodings and propagators over classic IPC and recently proposed benchmarks for lifted planning, and report that for planning problem instances requiring fewer plan steps our methods compare very well with the state-of-the-art in optimal sequential planning.","sentences":["This paper studies the possibilities made open by the use of Lazy Clause Generation (LCG) based approaches to Constraint Programming (CP) for tackling sequential classical planning.","We propose a novel CP model based on seminal ideas on so-called lifted causal encodings for planning as satisfiability, that does not require grounding, as choosing groundings for functions and action schemas becomes an integral part of the problem of designing valid plans.","This encoding does not require encoding frame axioms, and does not explicitly represent states as decision variables for every plan step.","We also present a propagator procedure that illustrates the possibilities of LCG to widen the kind of inference methods considered to be feasible in planning as (iterated) CSP solving.","We test encodings and propagators over classic IPC and recently proposed benchmarks for lifted planning, and report that for planning problem instances requiring fewer plan steps our methods compare very well with the state-of-the-art in optimal sequential planning."],"url":"http://arxiv.org/abs/2307.08242v1"}
{"created":"2023-07-17 04:39:18","title":"Unified Open-Vocabulary Dense Visual Prediction","abstract":"In recent years, open-vocabulary (OV) dense visual prediction (such as OV object detection, semantic, instance and panoptic segmentations) has attracted increasing research attention. However, most of existing approaches are task-specific and individually tackle each task. In this paper, we propose a Unified Open-Vocabulary Network (UOVN) to jointly address four common dense prediction tasks. Compared with separate models, a unified network is more desirable for diverse industrial applications. Moreover, OV dense prediction training data is relatively less. Separate networks can only leverage task-relevant training data, while a unified approach can integrate diverse training data to boost individual tasks. We address two major challenges in unified OV prediction. Firstly, unlike unified methods for fixed-set predictions, OV networks are usually trained with multi-modal data. Therefore, we propose a multi-modal, multi-scale and multi-task (MMM) decoding mechanism to better leverage multi-modal data. Secondly, because UOVN uses data from different tasks for training, there are significant domain and task gaps. We present a UOVN training mechanism to reduce such gaps. Experiments on four datasets demonstrate the effectiveness of our UOVN.","sentences":["In recent years, open-vocabulary (OV) dense visual prediction (such as OV object detection, semantic, instance and panoptic segmentations) has attracted increasing research attention.","However, most of existing approaches are task-specific and individually tackle each task.","In this paper, we propose a Unified Open-Vocabulary Network (UOVN) to jointly address four common dense prediction tasks.","Compared with separate models, a unified network is more desirable for diverse industrial applications.","Moreover, OV dense prediction training data is relatively less.","Separate networks can only leverage task-relevant training data, while a unified approach can integrate diverse training data to boost individual tasks.","We address two major challenges in unified OV prediction.","Firstly, unlike unified methods for fixed-set predictions, OV networks are usually trained with multi-modal data.","Therefore, we propose a multi-modal, multi-scale and multi-task (MMM) decoding mechanism to better leverage multi-modal data.","Secondly, because UOVN uses data from different tasks for training, there are significant domain and task gaps.","We present a UOVN training mechanism to reduce such gaps.","Experiments on four datasets demonstrate the effectiveness of our UOVN."],"url":"http://arxiv.org/abs/2307.08238v1"}
{"created":"2023-07-17 04:38:51","title":"A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection","abstract":"Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections. Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data. In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation. Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit. However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled. Neglecting the entangled treatments can impede the causal effect estimation. In this paper, we study the problem of causal effect estimation with treatment entangled in a graph. Despite a few explorations for entangled treatments, this problem still remains challenging due to the following challenges: (1) the entanglement brings difficulties in modeling and leveraging the unknown treatment assignment mechanism; (2) there may exist hidden confounders which lead to confounding biases in causal effect estimation; (3) the observational data is often time-varying. To tackle these challenges, we propose a novel method NEAT, which explicitly leverages the graph structure to model the treatment assignment mechanism, and mitigates confounding biases based on the treatment assignment modeling. We also extend our method into a dynamic setting to handle time-varying observational data. Experiments on both synthetic datasets and a real-world MRSA dataset validate the effectiveness of the proposed method, and provide insights for future applications.","sentences":["Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections.","Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data.","In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation.","Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit.","However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled.","Neglecting the entangled treatments can impede the causal effect estimation.","In this paper, we study the problem of causal effect estimation with treatment entangled in a graph.","Despite a few explorations for entangled treatments, this problem still remains challenging due to the following challenges: (1) the entanglement brings difficulties in modeling and leveraging the unknown treatment assignment mechanism; (2) there may exist hidden confounders which lead to confounding biases in causal effect estimation; (3) the observational data is often time-varying.","To tackle these challenges, we propose a novel method NEAT, which explicitly leverages the graph structure to model the treatment assignment mechanism, and mitigates confounding biases based on the treatment assignment modeling.","We also extend our method into a dynamic setting to handle time-varying observational data.","Experiments on both synthetic datasets and a real-world MRSA dataset validate the effectiveness of the proposed method, and provide insights for future applications."],"url":"http://arxiv.org/abs/2307.08237v1"}
{"created":"2023-07-17 04:32:45","title":"HeroLT: Benchmarking Heterogeneous Long-Tailed Learning","abstract":"Long-tailed data distributions are prevalent in a variety of domains, including finance, e-commerce, biomedical science, and cyber security. In such scenarios, the performance of machine learning models is often dominated by the head categories, while the learning of tail categories is significantly inadequate. Given abundant studies conducted to alleviate the issue, this work aims to provide a systematic view of long-tailed learning with regard to three pivotal angles: (A1) the characterization of data long-tailedness, (A2) the data complexity of various domains, and (A3) the heterogeneity of emerging tasks. To achieve this, we develop the most comprehensive (to the best of our knowledge) long-tailed learning benchmark named HeroLT, which integrates 13 state-of-the-art algorithms and 6 evaluation metrics on 14 real-world benchmark datasets across 4 tasks from 3 domains. HeroLT with novel angles and extensive experiments (264 in total) enables researchers and practitioners to effectively and fairly evaluate newly proposed methods compared with existing baselines on varying types of datasets. Finally, we conclude by highlighting the significant applications of long-tailed learning and identifying several promising future directions. For accessibility and reproducibility, we open-source our benchmark HeroLT and corresponding results at https://github.com/SSSKJ/HeroLT.","sentences":["Long-tailed data distributions are prevalent in a variety of domains, including finance, e-commerce, biomedical science, and cyber security.","In such scenarios, the performance of machine learning models is often dominated by the head categories, while the learning of tail categories is significantly inadequate.","Given abundant studies conducted to alleviate the issue, this work aims to provide a systematic view of long-tailed learning with regard to three pivotal angles: (A1) the characterization of data long-tailedness, (A2) the data complexity of various domains, and (A3) the heterogeneity of emerging tasks.","To achieve this, we develop the most comprehensive (to the best of our knowledge) long-tailed learning benchmark named HeroLT, which integrates 13 state-of-the-art algorithms and 6 evaluation metrics on 14 real-world benchmark datasets across 4 tasks from 3 domains.","HeroLT with novel angles and extensive experiments (264 in total) enables researchers and practitioners to effectively and fairly evaluate newly proposed methods compared with existing baselines on varying types of datasets.","Finally, we conclude by highlighting the significant applications of long-tailed learning and identifying several promising future directions.","For accessibility and reproducibility, we open-source our benchmark HeroLT and corresponding results at https://github.com/SSSKJ/HeroLT."],"url":"http://arxiv.org/abs/2307.08235v1"}
{"created":"2023-07-17 04:25:46","title":"ROFusion: Efficient Object Detection using Hybrid Point-wise Radar-Optical Fusion","abstract":"Radars, due to their robustness to adverse weather conditions and ability to measure object motions, have served in autonomous driving and intelligent agents for years. However, Radar-based perception suffers from its unintuitive sensing data, which lack of semantic and structural information of scenes. To tackle this problem, camera and Radar sensor fusion has been investigated as a trending strategy with low cost, high reliability and strong maintenance. While most recent works explore how to explore Radar point clouds and images, rich contextual information within Radar observation are discarded. In this paper, we propose a hybrid point-wise Radar-Optical fusion approach for object detection in autonomous driving scenarios. The framework benefits from dense contextual information from both the range-doppler spectrum and images which are integrated to learn a multi-modal feature representation. Furthermore, we propose a novel local coordinate formulation, tackling the object detection task in an object-centric coordinate. Extensive results show that with the information gained from optical images, we could achieve leading performance in object detection (97.69\\% recall) compared to recent state-of-the-art methods FFT-RadNet (82.86\\% recall). Ablation studies verify the key design choices and practicability of our approach given machine generated imperfect detections. The code will be available at https://github.com/LiuLiu-55/ROFusion.","sentences":["Radars, due to their robustness to adverse weather conditions and ability to measure object motions, have served in autonomous driving and intelligent agents for years.","However, Radar-based perception suffers from its unintuitive sensing data, which lack of semantic and structural information of scenes.","To tackle this problem, camera and Radar sensor fusion has been investigated as a trending strategy with low cost, high reliability and strong maintenance.","While most recent works explore how to explore Radar point clouds and images, rich contextual information within Radar observation are discarded.","In this paper, we propose a hybrid point-wise Radar-Optical fusion approach for object detection in autonomous driving scenarios.","The framework benefits from dense contextual information from both the range-doppler spectrum and images which are integrated to learn a multi-modal feature representation.","Furthermore, we propose a novel local coordinate formulation, tackling the object detection task in an object-centric coordinate.","Extensive results show that with the information gained from optical images, we could achieve leading performance in object detection (97.69\\% recall) compared to recent state-of-the-art methods FFT-RadNet (82.86\\% recall).","Ablation studies verify the key design choices and practicability of our approach given machine generated imperfect detections.","The code will be available at https://github.com/LiuLiu-55/ROFusion."],"url":"http://arxiv.org/abs/2307.08233v1"}
{"created":"2023-07-17 04:08:29","title":"Learning for Counterfactual Fairness from Observational Data","abstract":"Fairness-aware machine learning has attracted a surge of attention in many domains, such as online advertising, personalized recommendation, and social media analysis in web applications. Fairness-aware machine learning aims to eliminate biases of learning models against certain subgroups described by certain protected (sensitive) attributes such as race, gender, and age. Among many existing fairness notions, counterfactual fairness is a popular notion defined from a causal perspective. It measures the fairness of a predictor by comparing the prediction of each individual in the original world and that in the counterfactual worlds in which the value of the sensitive attribute is modified. A prerequisite for existing methods to achieve counterfactual fairness is the prior human knowledge of the causal model for the data. However, in real-world scenarios, the underlying causal model is often unknown, and acquiring such human knowledge could be very difficult. In these scenarios, it is risky to directly trust the causal models obtained from information sources with unknown reliability and even causal discovery methods, as incorrect causal models can consequently bring biases to the predictor and lead to unfair predictions. In this work, we address the problem of counterfactually fair prediction from observational data without given causal models by proposing a novel framework CLAIRE. Specifically, under certain general assumptions, CLAIRE effectively mitigates the biases from the sensitive attribute with a representation learning framework based on counterfactual data augmentation and an invariant penalty. Experiments conducted on both synthetic and real-world datasets validate the superiority of CLAIRE in both counterfactual fairness and prediction performance.","sentences":["Fairness-aware machine learning has attracted a surge of attention in many domains, such as online advertising, personalized recommendation, and social media analysis in web applications.","Fairness-aware machine learning aims to eliminate biases of learning models against certain subgroups described by certain protected (sensitive) attributes such as race, gender, and age.","Among many existing fairness notions, counterfactual fairness is a popular notion defined from a causal perspective.","It measures the fairness of a predictor by comparing the prediction of each individual in the original world and that in the counterfactual worlds in which the value of the sensitive attribute is modified.","A prerequisite for existing methods to achieve counterfactual fairness is the prior human knowledge of the causal model for the data.","However, in real-world scenarios, the underlying causal model is often unknown, and acquiring such human knowledge could be very difficult.","In these scenarios, it is risky to directly trust the causal models obtained from information sources with unknown reliability and even causal discovery methods, as incorrect causal models can consequently bring biases to the predictor and lead to unfair predictions.","In this work, we address the problem of counterfactually fair prediction from observational data without given causal models by proposing a novel framework CLAIRE.","Specifically, under certain general assumptions, CLAIRE effectively mitigates the biases from the sensitive attribute with a representation learning framework based on counterfactual data augmentation and an invariant penalty.","Experiments conducted on both synthetic and real-world datasets validate the superiority of CLAIRE in both counterfactual fairness and prediction performance."],"url":"http://arxiv.org/abs/2307.08232v1"}
{"created":"2023-07-17 04:04:05","title":"Image-based Regularization for Action Smoothness in Autonomous Miniature Racing Car with Deep Reinforcement Learning","abstract":"Deep reinforcement learning has achieved significant results in low-level controlling tasks. However, for some applications like autonomous driving and drone flying, it is difficult to control behavior stably since the agent may suddenly change its actions which often lowers the controlling system's efficiency, induces excessive mechanical wear, and causes uncontrollable, dangerous behavior to the vehicle. Recently, a method called conditioning for action policy smoothness (CAPS) was proposed to solve the problem of jerkiness in low-dimensional features for applications such as quadrotor drones. To cope with high-dimensional features, this paper proposes image-based regularization for action smoothness (I-RAS) for solving jerky control in autonomous miniature car racing. We also introduce a control based on impact ratio, an adaptive regularization weight to control the smoothness constraint, called IR control. In the experiment, an agent with I-RAS and IR control significantly improves the success rate from 59% to 95%. In the real-world-track experiment, the agent also outperforms other methods, namely reducing the average finish lap time, while also improving the completion rate even without real world training. This is also justified by an agent based on I-RAS winning the 2022 AWS DeepRacer Final Championship Cup.","sentences":["Deep reinforcement learning has achieved significant results in low-level controlling tasks.","However, for some applications like autonomous driving and drone flying, it is difficult to control behavior stably since the agent may suddenly change its actions which often lowers the controlling system's efficiency, induces excessive mechanical wear, and causes uncontrollable, dangerous behavior to the vehicle.","Recently, a method called conditioning for action policy smoothness (CAPS) was proposed to solve the problem of jerkiness in low-dimensional features for applications such as quadrotor drones.","To cope with high-dimensional features, this paper proposes image-based regularization for action smoothness (I-RAS) for solving jerky control in autonomous miniature car racing.","We also introduce a control based on impact ratio, an adaptive regularization weight to control the smoothness constraint, called IR control.","In the experiment, an agent with I-RAS and IR control significantly improves the success rate from 59% to 95%.","In the real-world-track experiment, the agent also outperforms other methods, namely reducing the average finish lap time, while also improving the completion rate even without real world training.","This is also justified by an agent based on I-RAS winning the 2022 AWS DeepRacer Final Championship Cup."],"url":"http://arxiv.org/abs/2307.08230v1"}
{"created":"2023-07-17 04:02:00","title":"Video Frame Interpolation with Stereo Event and Intensity Camera","abstract":"The stereo event-intensity camera setup is widely applied to leverage the advantages of both event cameras with low latency and intensity cameras that capture accurate brightness and texture information. However, such a setup commonly encounters cross-modality parallax that is difficult to be eliminated solely with stereo rectification especially for real-world scenes with complex motions and varying depths, posing artifacts and distortion for existing Event-based Video Frame Interpolation (E-VFI) approaches. To tackle this problem, we propose a novel Stereo Event-based VFI (SE-VFI) network (SEVFI-Net) to generate high-quality intermediate frames and corresponding disparities from misaligned inputs consisting of two consecutive keyframes and event streams emitted between them. Specifically, we propose a Feature Aggregation Module (FAM) to alleviate the parallax and achieve spatial alignment in the feature domain. We then exploit the fused features accomplishing accurate optical flow and disparity estimation, and achieving better interpolated results through flow-based and synthesis-based ways. We also build a stereo visual acquisition system composed of an event camera and an RGB-D camera to collect a new Stereo Event-Intensity Dataset (SEID) containing diverse scenes with complex motions and varying depths. Experiments on public real-world stereo datasets, i.e., DSEC and MVSEC, and our SEID dataset demonstrate that our proposed SEVFI-Net outperforms state-of-the-art methods by a large margin.","sentences":["The stereo event-intensity camera setup is widely applied to leverage the advantages of both event cameras with low latency and intensity cameras that capture accurate brightness and texture information.","However, such a setup commonly encounters cross-modality parallax that is difficult to be eliminated solely with stereo rectification especially for real-world scenes with complex motions and varying depths, posing artifacts and distortion for existing Event-based Video Frame Interpolation (E-VFI) approaches.","To tackle this problem, we propose a novel Stereo Event-based VFI (SE-VFI) network (SEVFI-Net) to generate high-quality intermediate frames and corresponding disparities from misaligned inputs consisting of two consecutive keyframes and event streams emitted between them.","Specifically, we propose a Feature Aggregation Module (FAM) to alleviate the parallax and achieve spatial alignment in the feature domain.","We then exploit the fused features accomplishing accurate optical flow and disparity estimation, and achieving better interpolated results through flow-based and synthesis-based ways.","We also build a stereo visual acquisition system composed of an event camera and an RGB-D camera to collect a new Stereo Event-Intensity Dataset (SEID) containing diverse scenes with complex motions and varying depths.","Experiments on public real-world stereo datasets, i.e., DSEC and MVSEC, and our SEID dataset demonstrate that our proposed SEVFI-Net outperforms state-of-the-art methods by a large margin."],"url":"http://arxiv.org/abs/2307.08228v1"}
{"created":"2023-07-17 04:01:51","title":"Obstacle Avoidance for Unicycle-Modelled Mobile Robots with Time-varying Control Barrier Functions","abstract":"In this paper, we propose a safety-critical controller based on time-varying control barrier functions (CBFs) for a robot with an unicycle model in the continuous-time domain to achieve navigation and dynamic collision avoidance. Unlike previous works, our proposed approach can control both linear and angular velocity to avoid collision with obstacles, overcoming the limitation of confined control performance due to the lack of control variable. To ensure that the robot reaches its destination, we also design a control Lyapunov function (CLF). Our safety-critical controller is formulated as a quadratic program (QP) optimization problem that incorporates CLF and CBFs as constraints, enabling real-time application for navigation and dynamic collision avoidance. Numerical simulations are conducted to verify the effectiveness of our proposed approach.","sentences":["In this paper, we propose a safety-critical controller based on time-varying control barrier functions (CBFs) for a robot with an unicycle model in the continuous-time domain to achieve navigation and dynamic collision avoidance.","Unlike previous works, our proposed approach can control both linear and angular velocity to avoid collision with obstacles, overcoming the limitation of confined control performance due to the lack of control variable.","To ensure that the robot reaches its destination, we also design a control Lyapunov function (CLF).","Our safety-critical controller is formulated as a quadratic program (QP) optimization problem that incorporates CLF and CBFs as constraints, enabling real-time application for navigation and dynamic collision avoidance.","Numerical simulations are conducted to verify the effectiveness of our proposed approach."],"url":"http://arxiv.org/abs/2307.08227v1"}
{"created":"2023-07-17 04:01:48","title":"Can Euclidean Symmetry be Leveraged in Reinforcement Learning and Planning?","abstract":"In robotic tasks, changes in reference frames typically do not influence the underlying physical properties of the system, which has been known as invariance of physical laws.These changes, which preserve distance, encompass isometric transformations such as translations, rotations, and reflections, collectively known as the Euclidean group. In this work, we delve into the design of improved learning algorithms for reinforcement learning and planning tasks that possess Euclidean group symmetry. We put forth a theory on that unify prior work on discrete and continuous symmetry in reinforcement learning, planning, and optimal control. Algorithm side, we further extend the 2D path planning with value-based planning to continuous MDPs and propose a pipeline for constructing equivariant sampling-based planning algorithms. Our work is substantiated with empirical evidence and illustrated through examples that explain the benefits of equivariance to Euclidean symmetry in tackling natural control problems.","sentences":["In robotic tasks, changes in reference frames typically do not influence the underlying physical properties of the system, which has been known as invariance of physical laws.","These changes, which preserve distance, encompass isometric transformations such as translations, rotations, and reflections, collectively known as the Euclidean group.","In this work, we delve into the design of improved learning algorithms for reinforcement learning and planning tasks that possess Euclidean group symmetry.","We put forth a theory on that unify prior work on discrete and continuous symmetry in reinforcement learning, planning, and optimal control.","Algorithm side, we further extend the 2D path planning with value-based planning to continuous MDPs and propose a pipeline for constructing equivariant sampling-based planning algorithms.","Our work is substantiated with empirical evidence and illustrated through examples that explain the benefits of equivariance to Euclidean symmetry in tackling natural control problems."],"url":"http://arxiv.org/abs/2307.08226v1"}
{"created":"2023-07-17 04:01:02","title":"Harnessing Scalable Transactional Stream Processing for Managing Large Language Models [Vision]","abstract":"Large Language Models (LLMs) have demonstrated extraordinary performance across a broad array of applications, from traditional language processing tasks to interpreting structured sequences like time-series data. Yet, their effectiveness in fast-paced, online decision-making environments requiring swift, accurate, and concurrent responses poses a significant challenge. This paper introduces TStreamLLM, a revolutionary framework integrating Transactional Stream Processing (TSP) with LLM management to achieve remarkable scalability and low latency. By harnessing the scalability, consistency, and fault tolerance inherent in TSP, TStreamLLM aims to manage continuous & concurrent LLM updates and usages efficiently. We showcase its potential through practical use cases like real-time patient monitoring and intelligent traffic management. The exploration of synergies between TSP and LLM management can stimulate groundbreaking developments in AI and database research. This paper provides a comprehensive overview of challenges and opportunities in this emerging field, setting forth a roadmap for future exploration and development.","sentences":["Large Language Models (LLMs) have demonstrated extraordinary performance across a broad array of applications, from traditional language processing tasks to interpreting structured sequences like time-series data.","Yet, their effectiveness in fast-paced, online decision-making environments requiring swift, accurate, and concurrent responses poses a significant challenge.","This paper introduces TStreamLLM, a revolutionary framework integrating Transactional Stream Processing (TSP) with LLM management to achieve remarkable scalability and low latency.","By harnessing the scalability, consistency, and fault tolerance inherent in TSP, TStreamLLM aims to manage continuous & concurrent LLM updates and usages efficiently.","We showcase its potential through practical use cases like real-time patient monitoring and intelligent traffic management.","The exploration of synergies between TSP and LLM management can stimulate groundbreaking developments in AI and database research.","This paper provides a comprehensive overview of challenges and opportunities in this emerging field, setting forth a roadmap for future exploration and development."],"url":"http://arxiv.org/abs/2307.08225v1"}
{"created":"2023-07-17 03:52:28","title":"NaMemo2: Facilitating Teacher-Student Interaction with Theory-Based Design and Student Autonomy Consideration","abstract":"Teacher-student interaction (TSI) is essential for learning efficiency and harmonious teacher-student interpersonal relationships. However, studies on TSI support tools often focus on teacher needs while neglecting student needs and autonomy. To enhance both lecturer competence in delivering interpersonal interaction and student autonomy in TSI, we developed NaMemo2, a novel augmented-reality system that allows students to express their willingness to TSI and displays student information to teachers during lectures. The design and evaluation process follows a new framework, STUDIER, which can facilitate the development of theory-based ethnics-aware TSI support tools in general. The quantitative results of our four-week field study with four classes in a university suggested that NaMemo2 can improve 1) TSI in the classroom from both teacher and student perspectives, 2) student attitudes and willingness to TSI, and 3) student attitudes to the deployment of NaMemo2. The qualitative feedback from students and teachers indicated that improving TSI may be responsible for improved attention in students and a better classroom atmosphere during lectures.","sentences":["Teacher-student interaction (TSI) is essential for learning efficiency and harmonious teacher-student interpersonal relationships.","However, studies on TSI support tools often focus on teacher needs while neglecting student needs and autonomy.","To enhance both lecturer competence in delivering interpersonal interaction and student autonomy in TSI, we developed NaMemo2, a novel augmented-reality system that allows students to express their willingness to TSI and displays student information to teachers during lectures.","The design and evaluation process follows a new framework, STUDIER, which can facilitate the development of theory-based ethnics-aware TSI support tools in general.","The quantitative results of our four-week field study with four classes in a university suggested that NaMemo2 can improve 1) TSI in the classroom from both teacher and student perspectives, 2) student attitudes and willingness to TSI, and 3) student attitudes to the deployment of NaMemo2.","The qualitative feedback from students and teachers indicated that improving TSI may be responsible for improved attention in students and a better classroom atmosphere during lectures."],"url":"http://arxiv.org/abs/2307.08222v1"}
{"created":"2023-07-17 03:45:47","title":"NDT-Map-Code: A 3D global descriptor for real-time loop closure detection in lidar SLAM","abstract":"Loop-closure detection, also known as place recognition, aiming to identify previously visited locations, is an essential component of a SLAM system. Existing research on lidar-based loop closure heavily relies on dense point cloud and 360 FOV lidars. This paper proposes an out-of-the-box NDT (Normal Distribution Transform) based global descriptor, NDT-Map-Code, designed for both on-road driving and underground valet parking scenarios. NDT-Map-Code can be directly extracted from the NDT map without the need for a dense point cloud, resulting in excellent scalability and low maintenance cost. The NDT representation is leveraged to identify representative patterns, which are further encoded according to their spatial location (bearing, range, and height). Experimental results on the NIO underground parking lot dataset and the KITTI dataset demonstrate that our method achieves significantly better performance compared to the state-of-the-art.","sentences":["Loop-closure detection, also known as place recognition, aiming to identify previously visited locations, is an essential component of a SLAM system.","Existing research on lidar-based loop closure heavily relies on dense point cloud and 360 FOV lidars.","This paper proposes an out-of-the-box NDT (Normal Distribution Transform) based global descriptor, NDT-Map-Code, designed for both on-road driving and underground valet parking scenarios.","NDT-Map-Code can be directly extracted from the NDT map without the need for a dense point cloud, resulting in excellent scalability and low maintenance cost.","The NDT representation is leveraged to identify representative patterns, which are further encoded according to their spatial location (bearing, range, and height).","Experimental results on the NIO underground parking lot dataset and the KITTI dataset demonstrate that our method achieves significantly better performance compared to the state-of-the-art."],"url":"http://arxiv.org/abs/2307.08221v1"}
{"created":"2023-07-17 03:45:00","title":"A Lightweight Framework for High-Quality Code Generation","abstract":"In recent years, the use of automated source code generation utilizing transformer-based generative models has expanded, and these models can generate functional code according to the requirements of the developers. However, recent research revealed that these automatically generated source codes can contain vulnerabilities and other quality issues. Despite researchers' and practitioners' attempts to enhance code generation models, retraining and fine-tuning large language models is time-consuming and resource-intensive. Thus, we describe FRANC, a lightweight framework for recommending more secure and high-quality source code derived from transformer-based code generation models. FRANC includes a static filter to make the generated code compilable with heuristics and a quality-aware ranker to sort the code snippets based on a quality score. Moreover, the framework uses prompt engineering to fix persistent quality issues. We evaluated the framework with five Python and Java code generation models and six prompt datasets, including a newly created one in this work (SOEval). The static filter improves 9% to 46% Java suggestions and 10% to 43% Python suggestions regarding compilability. The average improvement over the NDCG@10 score for the ranking system is 0.0763, and the repairing techniques repair the highest 80% of prompts. FRANC takes, on average, 1.98 seconds for Java; for Python, it takes 0.08 seconds.","sentences":["In recent years, the use of automated source code generation utilizing transformer-based generative models has expanded, and these models can generate functional code according to the requirements of the developers.","However, recent research revealed that these automatically generated source codes can contain vulnerabilities and other quality issues.","Despite researchers' and practitioners' attempts to enhance code generation models, retraining and fine-tuning large language models is time-consuming and resource-intensive.","Thus, we describe FRANC, a lightweight framework for recommending more secure and high-quality source code derived from transformer-based code generation models.","FRANC includes a static filter to make the generated code compilable with heuristics and a quality-aware ranker to sort the code snippets based on a quality score.","Moreover, the framework uses prompt engineering to fix persistent quality issues.","We evaluated the framework with five Python and Java code generation models and six prompt datasets, including a newly created one in this work (SOEval).","The static filter improves 9% to 46% Java suggestions and 10% to 43% Python suggestions regarding compilability.","The average improvement over the NDCG@10 score for the ranking system is 0.0763, and the repairing techniques repair the highest 80% of prompts.","FRANC takes, on average, 1.98 seconds for Java; for Python, it takes 0.08 seconds."],"url":"http://arxiv.org/abs/2307.08220v1"}
{"created":"2023-07-17 03:31:36","title":"BASS: Block-wise Adaptation for Speech Summarization","abstract":"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.","sentences":["End-to-end speech summarization has been shown to improve performance over cascade baselines.","However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs.","Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time.","In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner.","Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information.","We devise and test strategies to pass semantic context across the blocks.","Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline."],"url":"http://arxiv.org/abs/2307.08217v1"}
{"created":"2023-07-17 03:10:38","title":"Lipschitz Continuous Algorithms for Covering Problems","abstract":"Combinatorial algorithms are widely used for decision-making and knowledge discovery, and it is important to ensure that their output remains stable even when subjected to small perturbations in the input. Failure to do so can lead to several problems, including costly decisions, reduced user trust, potential security concerns, and lack of replicability. Unfortunately, many fundamental combinatorial algorithms are vulnerable to small input perturbations. To address the impact of input perturbations on algorithms for weighted graph problems, Kumabe and Yoshida (FOCS'23) recently introduced the concept of Lipschitz continuity of algorithms. This work explores this approach and designs Lipschitz continuous algorithms for covering problems, such as the minimum vertex cover, set cover, and feedback vertex set problems.   Our algorithm for the feedback vertex set problem is based on linear programming, and in the rounding process, we develop and use a technique called cycle sparsification, which may be of independent interest.","sentences":["Combinatorial algorithms are widely used for decision-making and knowledge discovery, and it is important to ensure that their output remains stable even when subjected to small perturbations in the input.","Failure to do so can lead to several problems, including costly decisions, reduced user trust, potential security concerns, and lack of replicability.","Unfortunately, many fundamental combinatorial algorithms are vulnerable to small input perturbations.","To address the impact of input perturbations on algorithms for weighted graph problems, Kumabe and Yoshida (FOCS'23) recently introduced the concept of Lipschitz continuity of algorithms.","This work explores this approach and designs Lipschitz continuous algorithms for covering problems, such as the minimum vertex cover, set cover, and feedback vertex set problems.   ","Our algorithm for the feedback vertex set problem is based on linear programming, and in the rounding process, we develop and use a technique called cycle sparsification, which may be of independent interest."],"url":"http://arxiv.org/abs/2307.08213v1"}
{"created":"2023-07-17 03:08:17","title":"Combinatorial Approach for Factorization of Variance and Entropy in Spin Systems","abstract":"We present a simple combinatorial framework for establishing approximate tensorization of variance and entropy in the setting of spin systems (a.k.a. undirected graphical models) based on balanced separators of the underlying graph. Such approximate tensorization results immediately imply as corollaries many important structural properties of the associated Gibbs distribution, in particular rapid mixing of the Glauber dynamics for sampling. We prove approximate tensorization by recursively establishing block factorization of variance and entropy with a small balanced separator of the graph. Our approach goes beyond the classical canonical path method for variance and the recent spectral independence approach, and allows us to obtain new rapid mixing results. As applications of our approach, we show that:   1. On graphs of treewidth $t$, the mixing time of the Glauber dynamics is $n^{O(t)}$, which recovers the recent results of Eppstein and Frishberg with improved exponents and simpler proofs;   2. On bounded-degree planar graphs, strong spatial mixing implies $\\tilde{O}(n)$ mixing time of the Glauber dynamics, which gives a faster algorithm than the previous deterministic counting algorithm by Yin and Zhang.","sentences":["We present a simple combinatorial framework for establishing approximate tensorization of variance and entropy in the setting of spin systems (a.k.a. undirected graphical models) based on balanced separators of the underlying graph.","Such approximate tensorization results immediately imply as corollaries many important structural properties of the associated Gibbs distribution, in particular rapid mixing of the Glauber dynamics for sampling.","We prove approximate tensorization by recursively establishing block factorization of variance and entropy with a small balanced separator of the graph.","Our approach goes beyond the classical canonical path method for variance and the recent spectral independence approach, and allows us to obtain new rapid mixing results.","As applications of our approach, we show that:   1.","On graphs of treewidth $t$, the mixing time of the Glauber dynamics is $n^{O(t)}$, which recovers the recent results of Eppstein and Frishberg with improved exponents and simpler proofs;   2.","On bounded-degree planar graphs, strong spatial mixing implies $\\tilde{O}(n)$ mixing time of the Glauber dynamics, which gives a faster algorithm than the previous deterministic counting algorithm by Yin and Zhang."],"url":"http://arxiv.org/abs/2307.08212v1"}
{"created":"2023-07-17 02:58:51","title":"Ada3D : Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection","abstract":"Voxel-based methods have achieved state-of-the-art performance for 3D object detection in autonomous driving. However, their significant computational and memory costs pose a challenge for their application to resource-constrained vehicles. One reason for this high resource consumption is the presence of a large number of redundant background points in Lidar point clouds, resulting in spatial redundancy in both 3D voxel and dense BEV map representations. To address this issue, we propose an adaptive inference framework called Ada3D, which focuses on exploiting the input-level spatial redundancy. Ada3D adaptively filters the redundant input, guided by a lightweight importance predictor and the unique properties of the Lidar point cloud. Additionally, we utilize the BEV features' intrinsic sparsity by introducing the Sparsity Preserving Batch Normalization. With Ada3D, we achieve 40% reduction for 3D voxels and decrease the density of 2D BEV feature maps from 100% to 20% without sacrificing accuracy. Ada3D reduces the model computational and memory cost by 5x, and achieves 1.52x/1.45x end-to-end GPU latency and 1.5x/4.5x GPU peak memory optimization for the 3D and 2D backbone respectively.","sentences":["Voxel-based methods have achieved state-of-the-art performance for 3D object detection in autonomous driving.","However, their significant computational and memory costs pose a challenge for their application to resource-constrained vehicles.","One reason for this high resource consumption is the presence of a large number of redundant background points in Lidar point clouds, resulting in spatial redundancy in both 3D voxel and dense BEV map representations.","To address this issue, we propose an adaptive inference framework called Ada3D, which focuses on exploiting the input-level spatial redundancy.","Ada3D adaptively filters the redundant input, guided by a lightweight importance predictor and the unique properties of the Lidar point cloud.","Additionally, we utilize the BEV features' intrinsic sparsity by introducing the Sparsity Preserving Batch Normalization.","With Ada3D, we achieve 40% reduction for 3D voxels and decrease the density of 2D BEV feature maps from 100% to 20% without sacrificing accuracy.","Ada3D reduces the model computational and memory cost by 5x, and achieves 1.52x/1.45x end-to-end GPU latency and 1.5x/4.5x GPU peak memory optimization for the 3D and 2D backbone respectively."],"url":"http://arxiv.org/abs/2307.08209v1"}
{"created":"2023-07-17 02:58:25","title":"Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound","abstract":"Deep neural networks (DNNs) have been widely and successfully adopted and deployed in various applications of speech recognition. Recently, a few works revealed that these models are vulnerable to backdoor attacks, where the adversaries can implant malicious prediction behaviors into victim models by poisoning their training process. In this paper, we revisit poison-only backdoor attacks against speech recognition. We reveal that existing methods are not stealthy since their trigger patterns are perceptible to humans or machine detection. This limitation is mostly because their trigger patterns are simple noises or separable and distinctive clips. Motivated by these findings, we propose to exploit elements of sound ($e.g.$, pitch and timbre) to design more stealthy yet effective poison-only backdoor attacks. Specifically, we insert a short-duration high-pitched signal as the trigger and increase the pitch of remaining audio clips to `mask' it for designing stealthy pitch-based triggers. We manipulate timbre features of victim audios to design the stealthy timbre-based attack and design a voiceprint selection module to facilitate the multi-backdoor attack. Our attacks can generate more `natural' poisoned samples and therefore are more stealthy. Extensive experiments are conducted on benchmark datasets, which verify the effectiveness of our attacks under different settings ($e.g.$, all-to-one, all-to-all, clean-label, physical, and multi-backdoor settings) and their stealthiness. The code for reproducing main experiments are available at \\url{https://github.com/HanboCai/BadSpeech_SoE}.","sentences":["Deep neural networks (DNNs) have been widely and successfully adopted and deployed in various applications of speech recognition.","Recently, a few works revealed that these models are vulnerable to backdoor attacks, where the adversaries can implant malicious prediction behaviors into victim models by poisoning their training process.","In this paper, we revisit poison-only backdoor attacks against speech recognition.","We reveal that existing methods are not stealthy since their trigger patterns are perceptible to humans or machine detection.","This limitation is mostly because their trigger patterns are simple noises or separable and distinctive clips.","Motivated by these findings, we propose to exploit elements of sound ($e.g.$, pitch and timbre) to design more stealthy yet effective poison-only backdoor attacks.","Specifically, we insert a short-duration high-pitched signal as the trigger and increase the pitch of remaining audio clips to `mask' it for designing stealthy pitch-based triggers.","We manipulate timbre features of victim audios to design the stealthy timbre-based attack and design a voiceprint selection module to facilitate the multi-backdoor attack.","Our attacks can generate more `natural' poisoned samples and therefore are more stealthy.","Extensive experiments are conducted on benchmark datasets, which verify the effectiveness of our attacks under different settings ($e.g.$, all-to-one, all-to-all, clean-label, physical, and multi-backdoor settings) and their stealthiness.","The code for reproducing main experiments are available at \\url{https://github.com/HanboCai/BadSpeech_SoE}."],"url":"http://arxiv.org/abs/2307.08208v1"}
{"created":"2023-07-17 02:54:07","title":"Identifying Vulnerable Third-Party Libraries from Textual Descriptions of Vulnerabilities and Libraries","abstract":"To avoid potential risks posed by vulnerabilities in third-party libraries, security researchers maintain databases containing vulnerability reports, e.g., the National Vulnerability Database (NVD). Application developers can identify vulnerable libraries by directly querying the databases with the name of each used library. However, the querying results of vulnerable libraries are not reliable due to the incompleteness of vulnerability reports. Thus, current approaches model the task of identifying vulnerable libraries as an extreme multi-label learning (XML) task. These approaches suffer from highly inaccurate results and cannot identify zero-shot libraries (i.e., those not appearing during model training). To address these limitations, in this paper, we propose the first entity-linking approach named VulLibMiner to identify vulnerable third-party libraries from textual descriptions of vulnerabilities and libraries, together with VulLib, a Java vulnerability dataset with vulnerability-affected libraries. VulLibMiner consists of a coarse-grained TF-IDF matcher to efficiently screen out a small set of candidate libraries and a fine-grained BERT-FNN model to identify vulnerable libraries from these candidates effectively. We evaluate VulLibMiner using two state-of-the-art/practice approaches of library identification (FastXML, LightXML) on both their dataset named VeraJava and our VulLib dataset. Our evaluation results show that VulLibMiner can effectively identify vulnerable libraries with an average F1 score of 0.542 while the state-of-the-art/practice approaches achieve only 0.377. We demonstrate VulLibMiner's high value of security practice by using VulLibMiner to identify 12,716 <vulnerability, library> pairs, and 7,936 of them do not appear in NVD.","sentences":["To avoid potential risks posed by vulnerabilities in third-party libraries, security researchers maintain databases containing vulnerability reports, e.g., the National Vulnerability Database (NVD).","Application developers can identify vulnerable libraries by directly querying the databases with the name of each used library.","However, the querying results of vulnerable libraries are not reliable due to the incompleteness of vulnerability reports.","Thus, current approaches model the task of identifying vulnerable libraries as an extreme multi-label learning (XML) task.","These approaches suffer from highly inaccurate results and cannot identify zero-shot libraries (i.e., those not appearing during model training).","To address these limitations, in this paper, we propose the first entity-linking approach named VulLibMiner to identify vulnerable third-party libraries from textual descriptions of vulnerabilities and libraries, together with VulLib, a Java vulnerability dataset with vulnerability-affected libraries.","VulLibMiner consists of a coarse-grained TF-IDF matcher to efficiently screen out a small set of candidate libraries and a fine-grained BERT-FNN model to identify vulnerable libraries from these candidates effectively.","We evaluate VulLibMiner using two state-of-the-art/practice approaches of library identification (FastXML, LightXML) on both their dataset named VeraJava and our VulLib dataset.","Our evaluation results show that VulLibMiner can effectively identify vulnerable libraries with an average F1 score of 0.542 while the state-of-the-art/practice approaches achieve only 0.377.","We demonstrate VulLibMiner's high value of security practice by using VulLibMiner to identify 12,716 <vulnerability, library> pairs, and 7,936 of them do not appear in NVD."],"url":"http://arxiv.org/abs/2307.08206v1"}
{"created":"2023-07-17 02:12:15","title":"Reducing Trust in Automated Certificate Authorities via Proofs-of-Authentication","abstract":"Automated certificate authorities (CAs) have expanded the reach of public key infrastructure on the web and for software signing. The certificates that these CAs issue attest to proof of control of some digital identity. Some of these automated CAs issue certificates in response to client authentication using OpenID Connect (OIDC, an extension of OAuth 2.0). This places these CAs in a position to impersonate any identity. Mitigations for this risk, like certificate transparency and signature thresholds, have emerged, but these mitigations only detect or raise the difficulty of compromise. Researchers have proposed alternatives to CAs in this setting, but many of these alternatives would require prohibitive changes to deployed authentication protocols.   In this work, we propose a cryptographic technique for reducing trust in these automated CAs. When issuing a certificate, the CAs embed a proof of authentication from the subject of the certificate -- but without enabling replay attacks. We explain multiple methods for achieving this with tradeoffs between user privacy, performance, and changes to existing infrastructure. We implement a proof of concept for a method using Guillou-Quisquater signatures that works out-of-the-box with existing OIDC deployments for the open-source Sigstore CA, finding that minimal modifications are required.","sentences":["Automated certificate authorities (CAs) have expanded the reach of public key infrastructure on the web and for software signing.","The certificates that these CAs issue attest to proof of control of some digital identity.","Some of these automated CAs issue certificates in response to client authentication using OpenID Connect (OIDC, an extension of OAuth 2.0).","This places these CAs in a position to impersonate any identity.","Mitigations for this risk, like certificate transparency and signature thresholds, have emerged, but these mitigations only detect or raise the difficulty of compromise.","Researchers have proposed alternatives to CAs in this setting, but many of these alternatives would require prohibitive changes to deployed authentication protocols.   ","In this work, we propose a cryptographic technique for reducing trust in these automated CAs.","When issuing a certificate, the CAs embed a proof of authentication from the subject of the certificate -- but without enabling replay attacks.","We explain multiple methods for achieving this with tradeoffs between user privacy, performance, and changes to existing infrastructure.","We implement a proof of concept for a method using Guillou-Quisquater signatures that works out-of-the-box with existing OIDC deployments for the open-source Sigstore CA, finding that minimal modifications are required."],"url":"http://arxiv.org/abs/2307.08201v1"}
{"created":"2023-07-17 02:08:50","title":"Ternary Stochastic Geometry Theory for Performance Analysis of RIS-Assisted UDN","abstract":"With the fast development of reconfigurable intelligent surface (RIS), the network topology becomes more complex and varied, which makes the network design and analysis extremely challenging. Most of the current works adopt the binary system stochastic geometric, missing the coupling relationships between the direct and reflected paths caused by RISs. In this paper, we first define the typical triangle which consists of a base station (BS), a RIS and a user equipment (UE) as the basic ternary network unit in a RIS-assisted ultra-dense network (UDN). In addition, we extend the Campbell's theorem to the ternary system and present the ternary probability generating functional (PGFL) of the stochastic geometry. Based on the ternary stochastic geometry theory, we derive and analyze the coverage probability, area spectral efficiency (ASE), area energy efficiency (AEE) and energy coverage efficiency (ECE) of the RIS-assisted UDN system. Simulation results show that the RISs can improve the system performances, especially for the UE who has a high signal to interference plus noise ratio (SINR), as if the introduced RIS brings in Matthew effect. This phenomenon of RIS is appealing for guiding the design of complex networks.","sentences":["With the fast development of reconfigurable intelligent surface (RIS), the network topology becomes more complex and varied, which makes the network design and analysis extremely challenging.","Most of the current works adopt the binary system stochastic geometric, missing the coupling relationships between the direct and reflected paths caused by RISs.","In this paper, we first define the typical triangle which consists of a base station (BS), a RIS and a user equipment (UE) as the basic ternary network unit in a RIS-assisted ultra-dense network (UDN).","In addition, we extend the Campbell's theorem to the ternary system and present the ternary probability generating functional (PGFL) of the stochastic geometry.","Based on the ternary stochastic geometry theory, we derive and analyze the coverage probability, area spectral efficiency (ASE), area energy efficiency (AEE) and energy coverage efficiency (ECE) of the RIS-assisted UDN system.","Simulation results show that the RISs can improve the system performances, especially for the UE who has a high signal to interference plus noise ratio (SINR), as if the introduced RIS brings in Matthew effect.","This phenomenon of RIS is appealing for guiding the design of complex networks."],"url":"http://arxiv.org/abs/2307.08200v1"}
{"created":"2023-07-17 02:03:17","title":"Manifold-Guided Sampling in Diffusion Models for Unbiased Image Generation","abstract":"Diffusion models are a powerful class of generative models that can produce high-quality images, but they may suffer from data bias. Data bias occurs when the training data does not reflect the true distribution of the data domain, but rather exhibits some skewed or imbalanced patterns. For example, the CelebA dataset contains more female images than male images, which can lead to biased generation results and affect downstream applications. In this paper, we propose a novel method to mitigate data bias in diffusion models by applying manifold guidance. Our key idea is to estimate the manifold of the training data using a learnable information-theoretic approach, and then use it to guide the sampling process of diffusion models. In this way, we can encourage the generated images to be uniformly distributed on the data manifold, without changing the model architecture or requiring labels or retraining. We provide theoretical analysis and empirical evidence to show that our method can improve the quality and unbiasedness of image generation compared to standard diffusion models.","sentences":["Diffusion models are a powerful class of generative models that can produce high-quality images, but they may suffer from data bias.","Data bias occurs when the training data does not reflect the true distribution of the data domain, but rather exhibits some skewed or imbalanced patterns.","For example, the CelebA dataset contains more female images than male images, which can lead to biased generation results and affect downstream applications.","In this paper, we propose a novel method to mitigate data bias in diffusion models by applying manifold guidance.","Our key idea is to estimate the manifold of the training data using a learnable information-theoretic approach, and then use it to guide the sampling process of diffusion models.","In this way, we can encourage the generated images to be uniformly distributed on the data manifold, without changing the model architecture or requiring labels or retraining.","We provide theoretical analysis and empirical evidence to show that our method can improve the quality and unbiasedness of image generation compared to standard diffusion models."],"url":"http://arxiv.org/abs/2307.08199v1"}
{"created":"2023-07-17 01:59:14","title":"On Point Affiliation in Feature Upsampling","abstract":"We introduce the notion of point affiliation into feature upsampling. By abstracting a feature map into non-overlapped semantic clusters formed by points of identical semantic meaning, feature upsampling can be viewed as point affiliation -- designating a semantic cluster for each upsampled point. In the framework of kernel-based dynamic upsampling, we show that an upsampled point can resort to its low-res decoder neighbors and high-res encoder point to reason the affiliation, conditioned on the mutual similarity between them. We therefore present a generic formulation for generating similarity-aware upsampling kernels and prove that such kernels encourage not only semantic smoothness but also boundary sharpness. This formulation constitutes a novel, lightweight, and universal upsampling solution, Similarity-Aware Point Affiliation (SAPA). We show its working mechanism via our preliminary designs with window-shape kernel. After probing the limitations of the designs on object detection, we reveal additional insights for upsampling, leading to SAPA with the dynamic kernel shape. Extensive experiments demonstrate that SAPA outperforms prior upsamplers and invites consistent performance improvements on a number of dense prediction tasks, including semantic segmentation, object detection, instance segmentation, panoptic segmentation, image matting, and depth estimation. Code is made available at: https://github.com/tiny-smart/sapa","sentences":["We introduce the notion of point affiliation into feature upsampling.","By abstracting a feature map into non-overlapped semantic clusters formed by points of identical semantic meaning, feature upsampling can be viewed as point affiliation -- designating a semantic cluster for each upsampled point.","In the framework of kernel-based dynamic upsampling, we show that an upsampled point can resort to its low-res decoder neighbors and high-res encoder point to reason the affiliation, conditioned on the mutual similarity between them.","We therefore present a generic formulation for generating similarity-aware upsampling kernels and prove that such kernels encourage not only semantic smoothness but also boundary sharpness.","This formulation constitutes a novel, lightweight, and universal upsampling solution, Similarity-Aware Point Affiliation (SAPA).","We show its working mechanism via our preliminary designs with window-shape kernel.","After probing the limitations of the designs on object detection, we reveal additional insights for upsampling, leading to SAPA with the dynamic kernel shape.","Extensive experiments demonstrate that SAPA outperforms prior upsamplers and invites consistent performance improvements on a number of dense prediction tasks, including semantic segmentation, object detection, instance segmentation, panoptic segmentation, image matting, and depth estimation.","Code is made available at: https://github.com/tiny-smart/sapa"],"url":"http://arxiv.org/abs/2307.08198v1"}
{"created":"2023-07-17 01:58:52","title":"Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs","abstract":"Biological nervous systems are created in a fundamentally different way than current artificial neural networks. Despite its impressive results in a variety of different domains, deep learning often requires considerable engineering effort to design high-performing neural architectures. By contrast, biological nervous systems are grown through a dynamic self-organizing process. In this paper, we take initial steps toward neural networks that grow through a developmental process that mirrors key properties of embryonic development in biological organisms. The growth process is guided by another neural network, which we call a Neural Developmental Program (NDP) and which operates through local communication alone. We investigate the role of neural growth on different machine learning benchmarks and different optimization methods (evolutionary training, online RL, offline RL, and supervised learning). Additionally, we highlight future research directions and opportunities enabled by having self-organization driving the growth of neural networks.","sentences":["Biological nervous systems are created in a fundamentally different way than current artificial neural networks.","Despite its impressive results in a variety of different domains, deep learning often requires considerable engineering effort to design high-performing neural architectures.","By contrast, biological nervous systems are grown through a dynamic self-organizing process.","In this paper, we take initial steps toward neural networks that grow through a developmental process that mirrors key properties of embryonic development in biological organisms.","The growth process is guided by another neural network, which we call a Neural Developmental Program (NDP) and which operates through local communication alone.","We investigate the role of neural growth on different machine learning benchmarks and different optimization methods (evolutionary training, online RL, offline RL, and supervised learning).","Additionally, we highlight future research directions and opportunities enabled by having self-organization driving the growth of neural networks."],"url":"http://arxiv.org/abs/2307.08197v1"}
{"created":"2023-07-17 01:51:06","title":"Covert Communication in Autoencoder Wireless Systems","abstract":"Hiding the wireless communication by transmitter Alice to intended receiver Bob from a capable and attentive adversary Willie has been widely studied under the moniker \"covert communications\". However, when such covert communication is done in the presence of allowable system communications, there has been little study of both hiding the signal and preserving the performance of those allowable communications. Here, by treating Alice, Bob, and Willie as a generator, decoder, and discriminator neural network, we perform joint training in an adversarial setting to yield a covert communication scheme that can be added to any normal autoencoder. The method does not depend on the characteristics of the cover signal or the type of channel and it is developed for both single-user and multi-user systems. Numerical results indicate that we are able to establish a reliable undetectable channel between Alice and Bob, regardless of the cover signal or type of fading, and that the signal causes almost no disturbance to the ongoing normal operation of the system.","sentences":["Hiding the wireless communication by transmitter Alice to intended receiver Bob from a capable and attentive adversary Willie has been widely studied under the moniker \"covert communications\".","However, when such covert communication is done in the presence of allowable system communications, there has been little study of both hiding the signal and preserving the performance of those allowable communications.","Here, by treating Alice, Bob, and Willie as a generator, decoder, and discriminator neural network, we perform joint training in an adversarial setting to yield a covert communication scheme that can be added to any normal autoencoder.","The method does not depend on the characteristics of the cover signal or the type of channel and it is developed for both single-user and multi-user systems.","Numerical results indicate that we are able to establish a reliable undetectable channel between Alice and Bob, regardless of the cover signal or type of fading, and that the signal causes almost no disturbance to the ongoing normal operation of the system."],"url":"http://arxiv.org/abs/2307.08195v1"}
{"created":"2023-07-17 01:46:15","title":"HOPE: High-order Polynomial Expansion of Black-box Neural Networks","abstract":"Despite their remarkable performance, deep neural networks remain mostly ``black boxes'', suggesting inexplicability and hindering their wide applications in fields requiring making rational decisions. Here we introduce HOPE (High-order Polynomial Expansion), a method for expanding a network into a high-order Taylor polynomial on a reference input. Specifically, we derive the high-order derivative rule for composite functions and extend the rule to neural networks to obtain their high-order derivatives quickly and accurately. From these derivatives, we can then derive the Taylor polynomial of the neural network, which provides an explicit expression of the network's local interpretations. Numerical analysis confirms the high accuracy, low computational complexity, and good convergence of the proposed method. Moreover, we demonstrate HOPE's wide applications built on deep learning, including function discovery, fast inference, and feature selection. The code is available at https://github.com/HarryPotterXTX/HOPE.git.","sentences":["Despite their remarkable performance, deep neural networks remain mostly ``black boxes'', suggesting inexplicability and hindering their wide applications in fields requiring making rational decisions.","Here we introduce HOPE (High-order Polynomial Expansion), a method for expanding a network into a high-order Taylor polynomial on a reference input.","Specifically, we derive the high-order derivative rule for composite functions and extend the rule to neural networks to obtain their high-order derivatives quickly and accurately.","From these derivatives, we can then derive the Taylor polynomial of the neural network, which provides an explicit expression of the network's local interpretations.","Numerical analysis confirms the high accuracy, low computational complexity, and good convergence of the proposed method.","Moreover, we demonstrate HOPE's wide applications built on deep learning, including function discovery, fast inference, and feature selection.","The code is available at https://github.com/HarryPotterXTX/HOPE.git."],"url":"http://arxiv.org/abs/2307.08192v1"}
{"created":"2023-07-17 01:39:34","title":"A Novel Reversible Data Hiding Scheme Based on Asymmetric Numeral Systems","abstract":"Reversible data hiding (RDH) has been extensively studied in the field of information security. In our previous work [1], an explicit implementation approaching the rate-distortion bound of RDH has been proposed. However, there are two challenges left in our previous method. Firstly, this method suffers from computing precision problem due to the use of arithmetic coding, which may cause the further embedding impossible. Secondly, it had to transmit the probability distribution of the host signals during the embedding/extraction process, yielding quite additional overhead and application limitations. In this paper, we first propose an RDH scheme that employs our recent asymmetric numeral systems (ANS) variant as the underlying coding framework to avoid the computing precision problem. Then, we give a dynamic implementation that does not require transmitting the host distribution in advance. The simulation results show that the proposed static method provides slightly higher peak signal-to-noise ratio (PSNR) values than our previous work, and larger embedding capacity than some state-of-the-art methods on gray-scale images. In addition, the proposed dynamic method totally saves the explicit transmission of the host distribution and achieve data embedding at the cost of a small image quality loss.","sentences":["Reversible data hiding (RDH) has been extensively studied in the field of information security.","In our previous work [1], an explicit implementation approaching the rate-distortion bound of RDH has been proposed.","However, there are two challenges left in our previous method.","Firstly, this method suffers from computing precision problem due to the use of arithmetic coding, which may cause the further embedding impossible.","Secondly, it had to transmit the probability distribution of the host signals during the embedding/extraction process, yielding quite additional overhead and application limitations.","In this paper, we first propose an RDH scheme that employs our recent asymmetric numeral systems (ANS) variant as the underlying coding framework to avoid the computing precision problem.","Then, we give a dynamic implementation that does not require transmitting the host distribution in advance.","The simulation results show that the proposed static method provides slightly higher peak signal-to-noise ratio (PSNR) values than our previous work, and larger embedding capacity than some state-of-the-art methods on gray-scale images.","In addition, the proposed dynamic method totally saves the explicit transmission of the host distribution and achieve data embedding at the cost of a small image quality loss."],"url":"http://arxiv.org/abs/2307.08190v1"}
{"created":"2023-07-17 01:35:56","title":"Mini-Giants: \"Small\" Language Models and Open Source Win-Win","abstract":"ChatGPT is phenomenal. However, it is prohibitively expensive to train and refine such giant models. Fortunately, small language models are flourishing and becoming more and more competent. We call them \"mini-giants\". We argue that open source community like Kaggle and mini-giants will win-win in many ways, technically, ethically and socially. In this article, we present a brief yet rich background, discuss how to attain small language models, present a comparative study of small language models and a brief discussion of evaluation methods, discuss the application scenarios where small language models are most needed in the real world, and conclude with discussion and outlook.","sentences":["ChatGPT is phenomenal.","However, it is prohibitively expensive to train and refine such giant models.","Fortunately, small language models are flourishing and becoming more and more competent.","We call them \"mini-giants\".","We argue that open source community like Kaggle and mini-giants will win-win in many ways, technically, ethically and socially.","In this article, we present a brief yet rich background, discuss how to attain small language models, present a comparative study of small language models and a brief discussion of evaluation methods, discuss the application scenarios where small language models are most needed in the real world, and conclude with discussion and outlook."],"url":"http://arxiv.org/abs/2307.08189v1"}
{"created":"2023-07-17 01:27:10","title":"An Empirical Investigation of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration","abstract":"In the realm of out-of-distribution generalization tasks, finetuning has risen as a key strategy. While the most focus has been on optimizing learning algorithms, our research highlights the influence of pre-trained model selection in finetuning on out-of-distribution performance and inference uncertainty. Balancing model size constraints of a single GPU, we examined the impact of varying pre-trained datasets and model parameters on performance metrics like accuracy and expected calibration error. Our findings underscore the significant influence of pre-trained model selection, showing marked performance improvements over algorithm choice. Larger models outperformed others, though the balance between memorization and true generalization merits further investigation. Ultimately, our research emphasizes the importance of pre-trained model selection for enhancing out-of-distribution generalization.","sentences":["In the realm of out-of-distribution generalization tasks, finetuning has risen as a key strategy.","While the most focus has been on optimizing learning algorithms, our research highlights the influence of pre-trained model selection in finetuning on out-of-distribution performance and inference uncertainty.","Balancing model size constraints of a single GPU, we examined the impact of varying pre-trained datasets and model parameters on performance metrics like accuracy and expected calibration error.","Our findings underscore the significant influence of pre-trained model selection, showing marked performance improvements over algorithm choice.","Larger models outperformed others, though the balance between memorization and true generalization merits further investigation.","Ultimately, our research emphasizes the importance of pre-trained model selection for enhancing out-of-distribution generalization."],"url":"http://arxiv.org/abs/2307.08187v1"}
{"created":"2023-07-17 00:56:21","title":"Zero-Shot Image Harmonization with Generative Model Prior","abstract":"Recent image harmonization methods have demonstrated promising results. However, due to their heavy reliance on a large number of composite images, these works are expensive in the training phase and often fail to generalize to unseen images. In this paper, we draw lessons from human behavior and come up with a zero-shot image harmonization method. Specifically, in the harmonization process, a human mainly utilizes his long-term prior on harmonious images and makes a composite image close to that prior. To imitate that, we resort to pretrained generative models for the prior of natural images. For the guidance of the harmonization direction, we propose an Attention-Constraint Text which is optimized to well illustrate the image environments. Some further designs are introduced for preserving the foreground content structure. The resulting framework, highly consistent with human behavior, can achieve harmonious results without burdensome training. Extensive experiments have demonstrated the effectiveness of our approach, and we have also explored some interesting applications.","sentences":["Recent image harmonization methods have demonstrated promising results.","However, due to their heavy reliance on a large number of composite images, these works are expensive in the training phase and often fail to generalize to unseen images.","In this paper, we draw lessons from human behavior and come up with a zero-shot image harmonization method.","Specifically, in the harmonization process, a human mainly utilizes his long-term prior on harmonious images and makes a composite image close to that prior.","To imitate that, we resort to pretrained generative models for the prior of natural images.","For the guidance of the harmonization direction, we propose an Attention-Constraint Text which is optimized to well illustrate the image environments.","Some further designs are introduced for preserving the foreground content structure.","The resulting framework, highly consistent with human behavior, can achieve harmonious results without burdensome training.","Extensive experiments have demonstrated the effectiveness of our approach, and we have also explored some interesting applications."],"url":"http://arxiv.org/abs/2307.08182v1"}
{"created":"2023-07-17 00:49:18","title":"Robot motor learning shows emergence of frequency-modulated, robust swimming with an invariant Strouhal-number","abstract":"Fish locomotion emerges from a diversity of interactions among deformable structures, surrounding fluids and neuromuscular activations, i.e., fluid-structure interactions (FSI) controlled by fish's motor systems. Previous studies suggested that such motor-controlled FSI may possess embodied traits. However, their implications in motor learning, neuromuscular control, gait generation, and swimming performance remain to be uncovered. Using robot models, we studied how swimming behaviours emerged from the FSI and the embodied traits. We developed modular robots with various designs and used Central Pattern Generators (CPGs) to control the torque acting on robot body. We used reinforcement learning to learn CPG parameters to maximize the swimming speed. The results showed that motor frequency converged faster than other parameters, and the emergent swimming gaits were robust against disruptions applied to motor control. For all robots and frequencies tested, swimming speed was proportional to the mean undulation velocity of body and caudal-fin combined, yielding an invariant, undulation-based Strouhal number. The Strouhal number also revealed two fundamental classes of undulatory swimming in both biological and robotic fishes. The robot actuators also demonstrated diverse functions as motors, virtual springs, and virtual masses. These results provide novel insights into the embodied traits of motor-controlled FSI for fish-inspired locomotion.","sentences":["Fish locomotion emerges from a diversity of interactions among deformable structures, surrounding fluids and neuromuscular activations, i.e., fluid-structure interactions (FSI) controlled by fish's motor systems.","Previous studies suggested that such motor-controlled FSI may possess embodied traits.","However, their implications in motor learning, neuromuscular control, gait generation, and swimming performance remain to be uncovered.","Using robot models, we studied how swimming behaviours emerged from the FSI and the embodied traits.","We developed modular robots with various designs and used Central Pattern Generators (CPGs) to control the torque acting on robot body.","We used reinforcement learning to learn CPG parameters to maximize the swimming speed.","The results showed that motor frequency converged faster than other parameters, and the emergent swimming gaits were robust against disruptions applied to motor control.","For all robots and frequencies tested, swimming speed was proportional to the mean undulation velocity of body and caudal-fin combined, yielding an invariant, undulation-based Strouhal number.","The Strouhal number also revealed two fundamental classes of undulatory swimming in both biological and robotic fishes.","The robot actuators also demonstrated diverse functions as motors, virtual springs, and virtual masses.","These results provide novel insights into the embodied traits of motor-controlled FSI for fish-inspired locomotion."],"url":"http://arxiv.org/abs/2307.08178v1"}
{"created":"2023-07-17 00:49:06","title":"In-IDE Generation-based Information Support with a Large Language Model","abstract":"Developers often face challenges in code understanding, which is crucial for building and maintaining high-quality software systems. Code comments and documentation can provide some context for the code, but are often scarce or missing. This challenge has become even more pressing with the rise of large language model (LLM) based code generation tools. To understand unfamiliar code, most software developers rely on general-purpose search engines to search through various programming information resources, which often requires multiple iterations of query rewriting and information foraging. More recently, developers have turned to online chatbots powered by LLMs, such as ChatGPT, which can provide more customized responses but also incur more overhead as developers need to communicate a significant amount of context to the LLM via a textual interface. In this study, we provide the investigation of an LLM-based conversational UI in the IDE. We aim to understand the promises and obstacles for tools powered by LLMs that are contextually aware, in that they automatically leverage the developer's programming context to answer queries. To this end, we develop an IDE Plugin that allows users to query back-ends such as OpenAI's GPT-3.5 and GPT-4 with high-level requests, like: explaining a highlighted section of code, explaining key domain-specific terms, or providing usage examples for an API. We conduct an exploratory user study with 32 participants to understand the usefulness and effectiveness, as well as individual preferences in the usage of, this LLM-powered information support tool. The study confirms that this approach can aid code understanding more effectively than web search, but the degree of the benefit differed by participants' experience levels.","sentences":["Developers often face challenges in code understanding, which is crucial for building and maintaining high-quality software systems.","Code comments and documentation can provide some context for the code, but are often scarce or missing.","This challenge has become even more pressing with the rise of large language model (LLM) based code generation tools.","To understand unfamiliar code, most software developers rely on general-purpose search engines to search through various programming information resources, which often requires multiple iterations of query rewriting and information foraging.","More recently, developers have turned to online chatbots powered by LLMs, such as ChatGPT, which can provide more customized responses but also incur more overhead as developers need to communicate a significant amount of context to the LLM via a textual interface.","In this study, we provide the investigation of an LLM-based conversational UI in the IDE.","We aim to understand the promises and obstacles for tools powered by LLMs that are contextually aware, in that they automatically leverage the developer's programming context to answer queries.","To this end, we develop an IDE Plugin that allows users to query back-ends such as OpenAI's GPT-3.5 and GPT-4 with high-level requests, like: explaining a highlighted section of code, explaining key domain-specific terms, or providing usage examples for an API.","We conduct an exploratory user study with 32 participants to understand the usefulness and effectiveness, as well as individual preferences in the usage of, this LLM-powered information support tool.","The study confirms that this approach can aid code understanding more effectively than web search, but the degree of the benefit differed by participants' experience levels."],"url":"http://arxiv.org/abs/2307.08177v1"}
{"created":"2023-07-17 00:07:52","title":"Multi-Objective Optimization of Performance and Interpretability of Tabular Supervised Machine Learning Models","abstract":"We present a model-agnostic framework for jointly optimizing the predictive performance and interpretability of supervised machine learning models for tabular data. Interpretability is quantified via three measures: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects. By treating hyperparameter optimization of a machine learning algorithm as a multi-objective optimization problem, our framework allows for generating diverse models that trade off high performance and ease of interpretability in a single optimization run. Efficient optimization is achieved via augmentation of the search space of the learning algorithm by incorporating feature selection, interaction and monotonicity constraints into the hyperparameter search space. We demonstrate that the optimization problem effectively translates to finding the Pareto optimal set of groups of selected features that are allowed to interact in a model, along with finding their optimal monotonicity constraints and optimal hyperparameters of the learning algorithm itself. We then introduce a novel evolutionary algorithm that can operate efficiently on this augmented search space. In benchmark experiments, we show that our framework is capable of finding diverse models that are highly competitive or outperform state-of-the-art XGBoost or Explainable Boosting Machine models, both with respect to performance and interpretability.","sentences":["We present a model-agnostic framework for jointly optimizing the predictive performance and interpretability of supervised machine learning models for tabular data.","Interpretability is quantified via three measures: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects.","By treating hyperparameter optimization of a machine learning algorithm as a multi-objective optimization problem, our framework allows for generating diverse models that trade off high performance and ease of interpretability in a single optimization run.","Efficient optimization is achieved via augmentation of the search space of the learning algorithm by incorporating feature selection, interaction and monotonicity constraints into the hyperparameter search space.","We demonstrate that the optimization problem effectively translates to finding the Pareto optimal set of groups of selected features that are allowed to interact in a model, along with finding their optimal monotonicity constraints and optimal hyperparameters of the learning algorithm itself.","We then introduce a novel evolutionary algorithm that can operate efficiently on this augmented search space.","In benchmark experiments, we show that our framework is capable of finding diverse models that are highly competitive or outperform state-of-the-art XGBoost or Explainable Boosting Machine models, both with respect to performance and interpretability."],"url":"http://arxiv.org/abs/2307.08175v1"}
{"created":"2023-07-16 23:11:26","title":"Credit Assignment: Challenges and Opportunities in Developing Human-like AI Agents","abstract":"Temporal credit assignment is crucial for learning and skill development in natural and artificial intelligence. While computational methods like the TD approach in reinforcement learning have been proposed, it's unclear if they accurately represent how humans handle feedback delays. Cognitive models intend to represent the mental steps by which humans solve problems and perform a number of tasks, but limited research in cognitive science has addressed the credit assignment problem in humans and cognitive models. Our research uses a cognitive model based on a theory of decisions from experience, Instance-Based Learning Theory (IBLT), to test different credit assignment mechanisms in a goal-seeking navigation task with varying levels of decision complexity. Instance-Based Learning (IBL) models simulate the process of making sequential choices with different credit assignment mechanisms, including a new IBL-TD model that combines the IBL decision mechanism with the TD approach. We found that (1) An IBL model that gives equal credit assignment to all decisions is able to match human performance better than other models, including IBL-TD and Q-learning; (2) IBL-TD and Q-learning models underperform compared to humans initially, but eventually, they outperform humans; (3) humans are influenced by decision complexity, while models are not. Our study provides insights into the challenges of capturing human behavior and the potential opportunities to use these models in future AI systems to support human activities.","sentences":["Temporal credit assignment is crucial for learning and skill development in natural and artificial intelligence.","While computational methods like the TD approach in reinforcement learning have been proposed, it's unclear if they accurately represent how humans handle feedback delays.","Cognitive models intend to represent the mental steps by which humans solve problems and perform a number of tasks, but limited research in cognitive science has addressed the credit assignment problem in humans and cognitive models.","Our research uses a cognitive model based on a theory of decisions from experience, Instance-Based Learning Theory (IBLT), to test different credit assignment mechanisms in a goal-seeking navigation task with varying levels of decision complexity.","Instance-Based Learning (IBL) models simulate the process of making sequential choices with different credit assignment mechanisms, including a new IBL-TD model that combines the IBL decision mechanism with the TD approach.","We found that (1) An IBL model that gives equal credit assignment to all decisions is able to match human performance better than other models, including IBL-TD and Q-learning; (2) IBL-TD and Q-learning models underperform compared to humans initially, but eventually, they outperform humans; (3) humans are influenced by decision complexity, while models are not.","Our study provides insights into the challenges of capturing human behavior and the potential opportunities to use these models in future AI systems to support human activities."],"url":"http://arxiv.org/abs/2307.08171v1"}
{"created":"2023-07-16 22:41:17","title":"Discovering User Types: Mapping User Traits by Task-Specific Behaviors in Reinforcement Learning","abstract":"When assisting human users in reinforcement learning (RL), we can represent users as RL agents and study key parameters, called \\emph{user traits}, to inform intervention design. We study the relationship between user behaviors (policy classes) and user traits. Given an environment, we introduce an intuitive tool for studying the breakdown of \"user types\": broad sets of traits that result in the same behavior. We show that seemingly different real-world environments admit the same set of user types and formalize this observation as an equivalence relation defined on environments. By transferring intervention design between environments within the same equivalence class, we can help rapidly personalize interventions.","sentences":["When assisting human users in reinforcement learning (RL), we can represent users as RL agents and study key parameters, called \\emph{user traits}, to inform intervention design.","We study the relationship between user behaviors (policy classes) and user traits.","Given an environment, we introduce an intuitive tool for studying the breakdown of \"user types\": broad sets of traits that result in the same behavior.","We show that seemingly different real-world environments admit the same set of user types and formalize this observation as an equivalence relation defined on environments.","By transferring intervention design between environments within the same equivalence class, we can help rapidly personalize interventions."],"url":"http://arxiv.org/abs/2307.08169v1"}
{"created":"2023-07-16 22:36:36","title":"Feedback is All You Need: Real-World Reinforcement Learning with Approximate Physics-Based Models","abstract":"We focus on developing efficient and reliable policy optimization strategies for robot learning with real-world data. In recent years, policy gradient methods have emerged as a promising paradigm for training control policies in simulation. However, these approaches often remain too data inefficient or unreliable to train on real robotic hardware. In this paper we introduce a novel policy gradient-based policy optimization framework which systematically leverages a (possibly highly simplified) first-principles model and enables learning precise control policies with limited amounts of real-world data. Our approach $1)$ uses the derivatives of the model to produce sample-efficient estimates of the policy gradient and $2)$ uses the model to design a low-level tracking controller, which is embedded in the policy class. Theoretical analysis provides insight into how the presence of this feedback controller addresses overcomes key limitations of stand-alone policy gradient methods, while hardware experiments with a small car and quadruped demonstrate that our approach can learn precise control strategies reliably and with only minutes of real-world data.","sentences":["We focus on developing efficient and reliable policy optimization strategies for robot learning with real-world data.","In recent years, policy gradient methods have emerged as a promising paradigm for training control policies in simulation.","However, these approaches often remain too data inefficient or unreliable to train on real robotic hardware.","In this paper we introduce a novel policy gradient-based policy optimization framework which systematically leverages a (possibly highly simplified) first-principles model and enables learning precise control policies with limited amounts of real-world data.","Our approach $1)$ uses the derivatives of the model to produce sample-efficient estimates of the policy gradient and $2)$ uses the model to design a low-level tracking controller, which is embedded in the policy class.","Theoretical analysis provides insight into how the presence of this feedback controller addresses overcomes key limitations of stand-alone policy gradient methods, while hardware experiments with a small car and quadruped demonstrate that our approach can learn precise control strategies reliably and with only minutes of real-world data."],"url":"http://arxiv.org/abs/2307.08168v1"}
