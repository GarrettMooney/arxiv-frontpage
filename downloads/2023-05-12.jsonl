{"created":"2023-05-11","title":"Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns","abstract":"Recent progress in artificial intelligence (AI), particularly in the domain of large language models (LLMs), has resulted in powerful and versatile dual-use systems. Indeed, cognition can be put towards a wide variety of tasks, some of which can result in harm. This study investigates how LLMs can be used for spear phishing, a prevalent form of cybercrime that involves manipulating targets into divulging sensitive information. I first explore LLMs' ability to assist with the reconnaissance and message generation stages of a successful spear phishing attack, where I find that advanced LLMs are capable of meaningfully improving cybercriminals' efficiency during these stages. Next, I conduct an empirical test by creating unique spear phishing messages for over 600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models. My findings reveal that these messages are not only realistic but also remarkably cost-effective, as each email cost only a fraction of a cent to generate. Next, I demonstrate how basic prompt engineering can circumvent safeguards installed in LLMs by the reinforcement learning from human feedback fine-tuning process, highlighting the need for more robust governance interventions aimed at mitigating misuse. To address these evolving risks, I propose two potential solutions: structured access schemes, such as application programming interfaces, and LLM-based defensive systems.","sentences":["Recent progress in artificial intelligence (AI), particularly in the domain of large language models (LLMs), has resulted in powerful and versatile dual-use systems.","Indeed, cognition can be put towards a wide variety of tasks, some of which can result in harm.","This study investigates how LLMs can be used for spear phishing, a prevalent form of cybercrime that involves manipulating targets into divulging sensitive information.","I first explore LLMs' ability to assist with the reconnaissance and message generation stages of a successful spear phishing attack, where I find that advanced LLMs are capable of meaningfully improving cybercriminals' efficiency during these stages.","Next, I conduct an empirical test by creating unique spear phishing messages for over 600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models.","My findings reveal that these messages are not only realistic but also remarkably cost-effective, as each email cost only a fraction of a cent to generate.","Next, I demonstrate how basic prompt engineering can circumvent safeguards installed in LLMs by the reinforcement learning from human feedback fine-tuning process, highlighting the need for more robust governance interventions aimed at mitigating misuse.","To address these evolving risks, I propose two potential solutions: structured access schemes, such as application programming interfaces, and LLM-based defensive systems."],"url":"http://arxiv.org/abs/2305.06972v1"}
{"created":"2023-05-11","title":"Enabling Programming Thinking in Large Language Models Toward Code Generation","abstract":"Large Language Models (LLMs) (e.g., ChatGPT) have shown impressive performance in code generation. A large-scale study released that writing programs requires programming thinking, i.e., analyzing and implementing requirements in programming logic (e.g., sequence, branch, loop). Existing studies use LLMs to generate programs from requirements directly and do not explicitly introduce the programming thinking.   This paper explores how to unlock the programming thinking of LLMs in code generation and proposes an approach named TiP. Our idea is to decompose code generation into two steps and progressively lead LLMs to analyze&implement requirements in programming logic. Specifically, TiP first generates a code sketch, which provides a high-level solving process using programming logic but omits implementation details (e.g., APIs). Then, TiP implements the sketch into a program using specific programming languages. We conduct extensive experiments on three public benchmarks (i.e., HumanEval, MBPP, and MBCPP). (1) TiP outperforms the state-of-the-art baseline - ChatGPT by up to 17.5% in Pass@1, 11.02% in Pass@3, and 9.84% in Pass@5. (2) Human evaluation shows that TiP outperforms ChatGPT in three aspects (i.e., correctness, code quality, and maintainability). (3) TiP is effective for different LLMs. (4) We explore multiple choices (e.g., chain-of-thought) for the code sketch and validate the superiority of our design. (5) We discuss the complementarity between TiP and post-processing approaches (e.g., CodeT).","sentences":["Large Language Models (LLMs) (e.g., ChatGPT) have shown impressive performance in code generation.","A large-scale study released that writing programs requires programming thinking, i.e., analyzing and implementing requirements in programming logic (e.g., sequence, branch, loop).","Existing studies use LLMs to generate programs from requirements directly and do not explicitly introduce the programming thinking.   ","This paper explores how to unlock the programming thinking of LLMs in code generation and proposes an approach named TiP. Our idea is to decompose code generation into two steps and progressively lead LLMs to analyze&implement requirements in programming logic.","Specifically, TiP first generates a code sketch, which provides a high-level solving process using programming logic but omits implementation details (e.g., APIs).","Then, TiP implements the sketch into a program using specific programming languages.","We conduct extensive experiments on three public benchmarks (i.e., HumanEval, MBPP, and MBCPP).","(1) TiP outperforms the state-of-the-art baseline - ChatGPT by up to 17.5% in Pass@1, 11.02% in Pass@3, and 9.84% in Pass@5.","(2) Human evaluation shows that TiP outperforms ChatGPT in three aspects (i.e., correctness, code quality, and maintainability).","(3) TiP is effective for different LLMs.","(4) We explore multiple choices (e.g., chain-of-thought) for the code sketch and validate the superiority of our design.","(5) We discuss the complementarity between TiP and post-processing approaches (e.g., CodeT)."],"url":"http://arxiv.org/abs/2305.06599v1"}
{"created":"2023-05-11","title":"Chain-of-Dictionary Prompting Elicits Translation in Large Language Models","abstract":"Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even when trained without parallel data. Yet, despite the fact that the amount of training data is gigantic, they still struggle with translating rare words, particularly for low-resource languages. Even worse, it is usually unrealistic to retrieve relevant demonstrations for in-context learning with low-resource languages on LLMs, which restricts the practical use of LLMs for translation -- how should we mitigate this problem? To this end, we present a novel method, CoD, which augments LLMs with prior knowledge with the chains of multilingual dictionaries for a subset of input words to elicit translation abilities for LLMs. Extensive experiments indicate that augmenting ChatGPT with CoD elicits large gains by up to 13x ChrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in Cyrillic script) on FLORES-200 full devtest set. We further demonstrate the importance of chaining the multilingual dictionaries, as well as the superiority of CoD to few-shot demonstration for low-resource languages.","sentences":["Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even when trained without parallel data.","Yet, despite the fact that the amount of training data is gigantic, they still struggle with translating rare words, particularly for low-resource languages.","Even worse, it is usually unrealistic to retrieve relevant demonstrations for in-context learning with low-resource languages on LLMs, which restricts the practical use of LLMs for translation -- how should we mitigate this problem?","To this end, we present a novel method, CoD, which augments LLMs with prior knowledge with the chains of multilingual dictionaries for a subset of input words to elicit translation abilities for LLMs.","Extensive experiments indicate that augmenting ChatGPT with CoD elicits large gains by up to 13x ChrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in Cyrillic script) on FLORES-200 full devtest set.","We further demonstrate the importance of chaining the multilingual dictionaries, as well as the superiority of CoD to few-shot demonstration for low-resource languages."],"url":"http://arxiv.org/abs/2305.06575v1"}
{"created":"2023-05-11","title":"Decentralization and Acceleration Enables Large-Scale Bundle Adjustment","abstract":"Scaling to arbitrarily large bundle adjustment problems requires data and compute to be distributed across multiple devices. Centralized methods in prior works are only able to solve small or medium size problems due to overhead in computation and communication. In this paper, we present a fully decentralized method that alleviates computation and communication bottlenecks to solve arbitrarily large bundle adjustment problems. We achieve this by reformulating the reprojection error and deriving a novel surrogate function that decouples optimization variables from different devices. This function makes it possible to use majorization minimization techniques and reduces bundle adjustment to independent optimization subproblems that can be solved in parallel. We further apply Nesterov's acceleration and adaptive restart to improve convergence while maintaining its theoretical guarantees. Despite limited peer-to-peer communication, our method has provable convergence to first-order critical points under mild conditions. On extensive benchmarks with public datasets, our method converges much faster than decentralized baselines with similar memory usage and communication load. Compared to centralized baselines using a single device, our method, while being decentralized, yields more accurate solutions with significant speedups of up to 940.7x over Ceres and 175.2x over DeepLM. Code: https://github.com/facebookresearch/DBA.","sentences":["Scaling to arbitrarily large bundle adjustment problems requires data and compute to be distributed across multiple devices.","Centralized methods in prior works are only able to solve small or medium size problems due to overhead in computation and communication.","In this paper, we present a fully decentralized method that alleviates computation and communication bottlenecks to solve arbitrarily large bundle adjustment problems.","We achieve this by reformulating the reprojection error and deriving a novel surrogate function that decouples optimization variables from different devices.","This function makes it possible to use majorization minimization techniques and reduces bundle adjustment to independent optimization subproblems that can be solved in parallel.","We further apply Nesterov's acceleration and adaptive restart to improve convergence while maintaining its theoretical guarantees.","Despite limited peer-to-peer communication, our method has provable convergence to first-order critical points under mild conditions.","On extensive benchmarks with public datasets, our method converges much faster than decentralized baselines with similar memory usage and communication load.","Compared to centralized baselines using a single device, our method, while being decentralized, yields more accurate solutions with significant speedups of up to 940.7x over Ceres and 175.2x over DeepLM.","Code: https://github.com/facebookresearch/DBA."],"url":"http://arxiv.org/abs/2305.07026v1"}
{"created":"2023-05-11","title":"SparseGNV: Generating Novel Views of Indoor Scenes with Sparse Input Views","abstract":"We study to generate novel views of indoor scenes given sparse input views. The challenge is to achieve both photorealism and view consistency. We present SparseGNV: a learning framework that incorporates 3D structures and image generative models to generate novel views with three modules. The first module builds a neural point cloud as underlying geometry, providing contextual information and guidance for the target novel view. The second module utilizes a transformer-based network to map the scene context and the guidance into a shared latent space and autoregressively decodes the target view in the form of discrete image tokens. The third module reconstructs the tokens into the image of the target view. SparseGNV is trained across a large indoor scene dataset to learn generalizable priors. Once trained, it can efficiently generate novel views of an unseen indoor scene in a feed-forward manner. We evaluate SparseGNV on both real-world and synthetic indoor scenes and demonstrate that it outperforms state-of-the-art methods based on either neural radiance fields or conditional image generation.","sentences":["We study to generate novel views of indoor scenes given sparse input views.","The challenge is to achieve both photorealism and view consistency.","We present SparseGNV: a learning framework that incorporates 3D structures and image generative models to generate novel views with three modules.","The first module builds a neural point cloud as underlying geometry, providing contextual information and guidance for the target novel view.","The second module utilizes a transformer-based network to map the scene context and the guidance into a shared latent space and autoregressively decodes the target view in the form of discrete image tokens.","The third module reconstructs the tokens into the image of the target view.","SparseGNV is trained across a large indoor scene dataset to learn generalizable priors.","Once trained, it can efficiently generate novel views of an unseen indoor scene in a feed-forward manner.","We evaluate SparseGNV on both real-world and synthetic indoor scenes and demonstrate that it outperforms state-of-the-art methods based on either neural radiance fields or conditional image generation."],"url":"http://arxiv.org/abs/2305.07024v1"}
{"created":"2023-05-11","title":"Virtual Occlusions Through Implicit Depth","abstract":"For augmented reality (AR), it is important that virtual assets appear to `sit among' real world objects. The virtual element should variously occlude and be occluded by real matter, based on a plausible depth ordering. This occlusion should be consistent over time as the viewer's camera moves. Unfortunately, small mistakes in the estimated scene depth can ruin the downstream occlusion mask, and thereby the AR illusion. Especially in real-time settings, depths inferred near boundaries or across time can be inconsistent. In this paper, we challenge the need for depth-regression as an intermediate step.   We instead propose an implicit model for depth and use that to predict the occlusion mask directly. The inputs to our network are one or more color images, plus the known depths of any virtual geometry. We show how our occlusion predictions are more accurate and more temporally stable than predictions derived from traditional depth-estimation models. We obtain state-of-the-art occlusion results on the challenging ScanNetv2 dataset and superior qualitative results on real scenes.","sentences":["For augmented reality (AR), it is important that virtual assets appear to `sit among' real world objects.","The virtual element should variously occlude and be occluded by real matter, based on a plausible depth ordering.","This occlusion should be consistent over time as the viewer's camera moves.","Unfortunately, small mistakes in the estimated scene depth can ruin the downstream occlusion mask, and thereby the AR illusion.","Especially in real-time settings, depths inferred near boundaries or across time can be inconsistent.","In this paper, we challenge the need for depth-regression as an intermediate step.   ","We instead propose an implicit model for depth and use that to predict the occlusion mask directly.","The inputs to our network are one or more color images, plus the known depths of any virtual geometry.","We show how our occlusion predictions are more accurate and more temporally stable than predictions derived from traditional depth-estimation models.","We obtain state-of-the-art occlusion results on the challenging ScanNetv2 dataset and superior qualitative results on real scenes."],"url":"http://arxiv.org/abs/2305.07014v1"}
{"created":"2023-05-11","title":"Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation","abstract":"Subword segmenters like BPE operate as a preprocessing step in neural machine translation and other (conditional) language models. They are applied to datasets before training, so translation or text generation quality relies on the quality of segmentations. We propose a departure from this paradigm, called subword segmental machine translation (SSMT). SSMT unifies subword segmentation and MT in a single trainable model. It learns to segment target sentence words while jointly learning to generate target sentences. To use SSMT during inference we propose dynamic decoding, a text generation algorithm that adapts segmentations as it generates translations. Experiments across 6 translation directions show that SSMT improves chrF scores for morphologically rich agglutinative languages. Gains are strongest in the very low-resource scenario. SSMT also learns subwords that are closer to morphemes compared to baselines and proves more robust on a test set constructed for evaluating morphological compositional generalisation.","sentences":["Subword segmenters like BPE operate as a preprocessing step in neural machine translation and other (conditional) language models.","They are applied to datasets before training, so translation or text generation quality relies on the quality of segmentations.","We propose a departure from this paradigm, called subword segmental machine translation (SSMT).","SSMT unifies subword segmentation and MT in a single trainable model.","It learns to segment target sentence words while jointly learning to generate target sentences.","To use SSMT during inference we propose dynamic decoding, a text generation algorithm that adapts segmentations as it generates translations.","Experiments across 6 translation directions show that SSMT improves chrF scores for morphologically rich agglutinative languages.","Gains are strongest in the very low-resource scenario.","SSMT also learns subwords that are closer to morphemes compared to baselines and proves more robust on a test set constructed for evaluating morphological compositional generalisation."],"url":"http://arxiv.org/abs/2305.07005v1"}
{"created":"2023-05-11","title":"Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach","abstract":"In the past decades, recommender systems have attracted much attention in both research and industry communities, and a large number of studies have been devoted to developing effective recommendation models. Basically speaking, these models mainly learn the underlying user preference from historical behavior data, and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we take a different approach to developing the recommendation models, considering recommendation as instruction following by LLMs. The key idea is that the preferences or needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation task. Instead of using public APIs of LLMs, we instruction tune an open-source LLM (3B Flan-T5-XL), in order to better adapt LLMs to recommender systems. For this purpose, we first design a general instruction format for describing the preference, intention, task form and context of a user in natural language. Then we manually design 39 instruction templates and automatically generate a large amount of user-personalized instruction data (252K instructions) with varying types of preferences and intentions. To demonstrate the effectiveness of our approach, we instantiate the instruction templates into several widely-studied recommendation (or search) tasks, and conduct extensive experiments on these tasks with real-world datasets. Experiment results show that the proposed approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks. Our approach sheds light on developing more user-friendly recommender systems, in which users can freely communicate with the system and obtain more accurate recommendations via natural language instructions.","sentences":["In the past decades, recommender systems have attracted much attention in both research and industry communities, and a large number of studies have been devoted to developing effective recommendation models.","Basically speaking, these models mainly learn the underlying user preference from historical behavior data, and then estimate the user-item matching relationships for recommendations.","Inspired by the recent progress on large language models (LLMs), we take a different approach to developing the recommendation models, considering recommendation as instruction following by LLMs.","The key idea is that the preferences or needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation task.","Instead of using public APIs of LLMs, we instruction tune an open-source LLM (3B Flan-T5-XL), in order to better adapt LLMs to recommender systems.","For this purpose, we first design a general instruction format for describing the preference, intention, task form and context of a user in natural language.","Then we manually design 39 instruction templates and automatically generate a large amount of user-personalized instruction data (252K instructions) with varying types of preferences and intentions.","To demonstrate the effectiveness of our approach, we instantiate the instruction templates into several widely-studied recommendation (or search) tasks, and conduct extensive experiments on these tasks with real-world datasets.","Experiment results show that the proposed approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks.","Our approach sheds light on developing more user-friendly recommender systems, in which users can freely communicate with the system and obtain more accurate recommendations via natural language instructions."],"url":"http://arxiv.org/abs/2305.07001v1"}
{"created":"2023-05-11","title":"Active Retrieval Augmented Generation","abstract":"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout the generation process is essential. There have been some past efforts to retrieve information multiple times while generating outputs, which mostly retrieve documents at fixed intervals using the previous context as queries. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic retrieval-augmented generation method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.","sentences":["Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output.","Augmenting LMs by retrieving information from external knowledge resources is one promising solution.","Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input.","This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout the generation process is essential.","There have been some past efforts to retrieve information multiple times while generating outputs, which mostly retrieve documents at fixed intervals using the previous context as queries.","In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation.","We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic retrieval-augmented generation method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.","We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets.","FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method.","Code and datasets are available at https://github.com/jzbjyb/FLARE."],"url":"http://arxiv.org/abs/2305.06983v1"}
{"created":"2023-05-11","title":"Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation","abstract":"Domain shift and label scarcity heavily limit deep learning applications to various medical image analysis tasks. Unsupervised domain adaptation (UDA) techniques have recently achieved promising cross-modality medical image segmentation by transferring knowledge from a label-rich source domain to an unlabeled target domain. However, it is also difficult to collect annotations from the source domain in many clinical applications, rendering most prior works suboptimal with the label-scarce source domain, particularly for few-shot scenarios, where only a few source labels are accessible. To achieve efficient few-shot cross-modality segmentation, we propose a novel transformation-consistent meta-hallucination framework, meta-hallucinator, with the goal of learning to diversify data distributions and generate useful examples for enhancing cross-modality performance. In our framework, hallucination and segmentation models are jointly trained with the gradient-based meta-learning strategy to synthesize examples that lead to good segmentation performance on the target domain. To further facilitate data hallucination and cross-domain knowledge transfer, we develop a self-ensembling model with a hallucination-consistent property. Our meta-hallucinator can seamlessly collaborate with the meta-segmenter for learning to hallucinate with mutual benefits from a combined view of meta-learning and self-ensembling learning. Extensive studies on MM-WHS 2017 dataset for cross-modality cardiac segmentation demonstrate that our method performs favorably against various approaches by a lot in the few-shot UDA scenario.","sentences":["Domain shift and label scarcity heavily limit deep learning applications to various medical image analysis tasks.","Unsupervised domain adaptation (UDA) techniques have recently achieved promising cross-modality medical image segmentation by transferring knowledge from a label-rich source domain to an unlabeled target domain.","However, it is also difficult to collect annotations from the source domain in many clinical applications, rendering most prior works suboptimal with the label-scarce source domain, particularly for few-shot scenarios, where only a few source labels are accessible.","To achieve efficient few-shot cross-modality segmentation, we propose a novel transformation-consistent meta-hallucination framework, meta-hallucinator, with the goal of learning to diversify data distributions and generate useful examples for enhancing cross-modality performance.","In our framework, hallucination and segmentation models are jointly trained with the gradient-based meta-learning strategy to synthesize examples that lead to good segmentation performance on the target domain.","To further facilitate data hallucination and cross-domain knowledge transfer, we develop a self-ensembling model with a hallucination-consistent property.","Our meta-hallucinator can seamlessly collaborate with the meta-segmenter for learning to hallucinate with mutual benefits from a combined view of meta-learning and self-ensembling learning.","Extensive studies on MM-WHS 2017 dataset for cross-modality cardiac segmentation demonstrate that our method performs favorably against various approaches by a lot in the few-shot UDA scenario."],"url":"http://arxiv.org/abs/2305.06978v1"}
{"created":"2023-05-11","title":"A method for automated regression test in scientific computing libraries: illustration with SPHinXsys","abstract":"Scientific computing libraries, either being in-house or open-source, have experienced enormous progress in both engineering and scientific research. It is therefore essential to ensure that the modifications in the source code aroused by bug fixing or new feature development wouldn't compromise the accuracy and functionality that has already been validated and verified. With this in mind, this paper introduces a method for developing and implementing an automatic regression test environment and takes the open-source multi-physics library SPHinXsys \\cite{zhang2021sphinxsys} as an example. Firstly, the reference database for each benchmark test is generated from monitored data by multiple executions. This database contains the maximum variation range of metrics for different types of strategies, i.e., time-averaged method, ensemble-averaged method as well as the dynamic time warping method, covering the uncertainty arising from parallel computing, particle relaxation, physical instabilities, etc. Then, new results obtained after source code modification will be tested with them according to a curve-similarity based comparison. Whenever the source code is updated, the regression test will be carried out automatically for all test cases and used to report the validity of the current results. This regression test environment has already been implemented in all dynamics test cases released in SPHinXsys, including fluid dynamics, solid mechanics, fluid-structure interaction, thermal and mass diffusion, reaction-diffusion, and their multi-physics coupling, and shows good capability for testing various problems. It's worth noting that while the present test environment is built and implemented for a specific scientific computing library, its underlying principle is generic and can be applied to many others.","sentences":["Scientific computing libraries, either being in-house or open-source, have experienced enormous progress in both engineering and scientific research.","It is therefore essential to ensure that the modifications in the source code aroused by bug fixing or new feature development wouldn't compromise the accuracy and functionality that has already been validated and verified.","With this in mind, this paper introduces a method for developing and implementing an automatic regression test environment and takes the open-source multi-physics library SPHinXsys \\cite{zhang2021sphinxsys} as an example.","Firstly, the reference database for each benchmark test is generated from monitored data by multiple executions.","This database contains the maximum variation range of metrics for different types of strategies, i.e., time-averaged method, ensemble-averaged method as well as the dynamic time warping method, covering the uncertainty arising from parallel computing, particle relaxation, physical instabilities, etc.","Then, new results obtained after source code modification will be tested with them according to a curve-similarity based comparison.","Whenever the source code is updated, the regression test will be carried out automatically for all test cases and used to report the validity of the current results.","This regression test environment has already been implemented in all dynamics test cases released in SPHinXsys, including fluid dynamics, solid mechanics, fluid-structure interaction, thermal and mass diffusion, reaction-diffusion, and their multi-physics coupling, and shows good capability for testing various problems.","It's worth noting that while the present test environment is built and implemented for a specific scientific computing library, its underlying principle is generic and can be applied to many others."],"url":"http://arxiv.org/abs/2305.06970v1"}
{"created":"2023-05-11","title":"Cascaded Cross-Attention Networks for Data-Efficient Whole-Slide Image Classification Using Transformers","abstract":"Whole-Slide Imaging allows for the capturing and digitization of high-resolution images of histological specimen. An automated analysis of such images using deep learning models is therefore of high demand. The transformer architecture has been proposed as a possible candidate for effectively leveraging the high-resolution information. Here, the whole-slide image is partitioned into smaller image patches and feature tokens are extracted from these image patches. However, while the conventional transformer allows for a simultaneous processing of a large set of input tokens, the computational demand scales quadratically with the number of input tokens and thus quadratically with the number of image patches. To address this problem we propose a novel cascaded cross-attention network (CCAN) based on the cross-attention mechanism that scales linearly with the number of extracted patches. Our experiments demonstrate that this architecture is at least on-par with and even outperforms other attention-based state-of-the-art methods on two public datasets: On the use-case of lung cancer (TCGA NSCLC) our model reaches a mean area under the receiver operating characteristic (AUC) of 0.970 $\\pm$ 0.008 and on renal cancer (TCGA RCC) reaches a mean AUC of 0.985 $\\pm$ 0.004. Furthermore, we show that our proposed model is efficient in low-data regimes, making it a promising approach for analyzing whole-slide images in resource-limited settings. To foster research in this direction, we make our code publicly available on GitHub: XXX.","sentences":["Whole-Slide Imaging allows for the capturing and digitization of high-resolution images of histological specimen.","An automated analysis of such images using deep learning models is therefore of high demand.","The transformer architecture has been proposed as a possible candidate for effectively leveraging the high-resolution information.","Here, the whole-slide image is partitioned into smaller image patches and feature tokens are extracted from these image patches.","However, while the conventional transformer allows for a simultaneous processing of a large set of input tokens, the computational demand scales quadratically with the number of input tokens and thus quadratically with the number of image patches.","To address this problem we propose a novel cascaded cross-attention network (CCAN) based on the cross-attention mechanism that scales linearly with the number of extracted patches.","Our experiments demonstrate that this architecture is at least on-par with and even outperforms other attention-based state-of-the-art methods on two public datasets: On the use-case of lung cancer (TCGA NSCLC) our model reaches a mean area under the receiver operating characteristic (AUC) of 0.970 $\\pm$ 0.008 and on renal cancer (TCGA RCC) reaches a mean AUC of 0.985 $\\pm$ 0.004.","Furthermore, we show that our proposed model is efficient in low-data regimes, making it a promising approach for analyzing whole-slide images in resource-limited settings.","To foster research in this direction, we make our code publicly available on GitHub: XXX."],"url":"http://arxiv.org/abs/2305.06963v1"}
{"created":"2023-05-11","title":"SalienDet: A Saliency-based Feature Enhancement Algorithm for Object Detection for Autonomous Driving","abstract":"Object detection (OD) is crucial to autonomous driving. Unknown objects are one of the reasons that hinder autonomous vehicles from driving beyond the operational domain. We propose a saliency-based OD algorithm (SalienDet) to detect objects that do not appear in the training sample set. SalienDet utilizes a saliency-based algorithm to enhance image features for object proposal generation. Then, we design a dataset relabeling approach to differentiate the unknown objects from all objects to achieve open-world detection. We evaluate SalienDet on KITTI, NuScenes, and BDD datasets, and the result indicates that it outperforms existing algorithms for unknown object detection. Additionally, SalienDet can be easily adapted for incremental learning in open-world detection tasks.","sentences":["Object detection (OD) is crucial to autonomous driving.","Unknown objects are one of the reasons that hinder autonomous vehicles from driving beyond the operational domain.","We propose a saliency-based OD algorithm (SalienDet) to detect objects that do not appear in the training sample set.","SalienDet utilizes a saliency-based algorithm to enhance image features for object proposal generation.","Then, we design a dataset relabeling approach to differentiate the unknown objects from all objects to achieve open-world detection.","We evaluate SalienDet on KITTI, NuScenes, and BDD datasets, and the result indicates that it outperforms existing algorithms for unknown object detection.","Additionally, SalienDet can be easily adapted for incremental learning in open-world detection tasks."],"url":"http://arxiv.org/abs/2305.06940v1"}
{"created":"2023-05-11","title":"Active Learning in the Predict-then-Optimize Framework: A Margin-Based Approach","abstract":"We develop the first active learning method in the predict-then-optimize framework. Specifically, we develop a learning method that sequentially decides whether to request the \"labels\" of feature samples from an unlabeled data stream, where the labels correspond to the parameters of an optimization model for decision-making. Our active learning method is the first to be directly informed by the decision error induced by the predicted parameters, which is referred to as the Smart Predict-then-Optimize (SPO) loss. Motivated by the structure of the SPO loss, our algorithm adopts a margin-based criterion utilizing the concept of distance to degeneracy and minimizes a tractable surrogate of the SPO loss on the collected data. In particular, we develop an efficient active learning algorithm with both hard and soft rejection variants, each with theoretical excess risk (i.e., generalization) guarantees. We further derive bounds on the label complexity, which refers to the number of samples whose labels are acquired to achieve a desired small level of SPO risk. Under some natural low-noise conditions, we show that these bounds can be better than the naive supervised learning approach that labels all samples. Furthermore, when using the SPO+ loss function, a specialized surrogate of the SPO loss, we derive a significantly smaller label complexity under separability conditions. We also present numerical evidence showing the practical value of our proposed algorithms in the settings of personalized pricing and the shortest path problem.","sentences":["We develop the first active learning method in the predict-then-optimize framework.","Specifically, we develop a learning method that sequentially decides whether to request the \"labels\" of feature samples from an unlabeled data stream, where the labels correspond to the parameters of an optimization model for decision-making.","Our active learning method is the first to be directly informed by the decision error induced by the predicted parameters, which is referred to as the Smart Predict-then-Optimize (SPO) loss.","Motivated by the structure of the SPO loss, our algorithm adopts a margin-based criterion utilizing the concept of distance to degeneracy and minimizes a tractable surrogate of the SPO loss on the collected data.","In particular, we develop an efficient active learning algorithm with both hard and soft rejection variants, each with theoretical excess risk (i.e., generalization) guarantees.","We further derive bounds on the label complexity, which refers to the number of samples whose labels are acquired to achieve a desired small level of SPO risk.","Under some natural low-noise conditions, we show that these bounds can be better than the naive supervised learning approach that labels all samples.","Furthermore, when using the SPO+ loss function, a specialized surrogate of the SPO loss, we derive a significantly smaller label complexity under separability conditions.","We also present numerical evidence showing the practical value of our proposed algorithms in the settings of personalized pricing and the shortest path problem."],"url":"http://arxiv.org/abs/2305.06584v1"}
{"created":"2023-05-11","title":"Occam's razor for AI: Coarse-graining Hammett Inspired Product Ansatz in Chemical Space","abstract":"Data-hungry machine learning methods have become a new standard to efficiently navigate chemical compound space for molecular and materials design and discovery. Due to the severe scarcity and cost of high-quality experimental or synthetic simulated training data, however, data-acquisition costs can be considerable. Relying on reasonably accurate approximate baseline labels with low computational complexity represents one of the most effective strategies to curb data-needs, e.g.~through $\\Delta$-, transfer-, or multi-fidelity learning. We introduce baseline labels in the form of a generic coarse-graining Hammett Inspired Product (HIP) {\\em Ansatz} which generalizes the empirical Hammett equation towards arbitrary systems and properties. Numerical evidence for the applicability of HIP includes solvation free energies of molecules, formation energies of quaternary elpasolite crystals, carbon adsorption energies on heterogeneous catalytic surfaces, HOMO-LUMO gaps of metallorganic complexes, and activation energies for S$_\\text{N}$2 reactions. After calibration on the same training sets, HIP yields an effective baseline for improved $\\Delta$-quantum machine learning models with superior data-efficiency when compared to previously introduced specialised domain-specific models.","sentences":["Data-hungry machine learning methods have become a new standard to efficiently navigate chemical compound space for molecular and materials design and discovery.","Due to the severe scarcity and cost of high-quality experimental or synthetic simulated training data, however, data-acquisition costs can be considerable.","Relying on reasonably accurate approximate baseline labels with low computational complexity represents one of the most effective strategies to curb data-needs, e.g.~through $\\Delta$-, transfer-, or multi-fidelity learning.","We introduce baseline labels in the form of a generic coarse-graining Hammett Inspired Product (HIP) {\\em Ansatz} which generalizes the empirical Hammett equation towards arbitrary systems and properties.","Numerical evidence for the applicability of HIP includes solvation free energies of molecules, formation energies of quaternary elpasolite crystals, carbon adsorption energies on heterogeneous catalytic surfaces, HOMO-LUMO gaps of metallorganic complexes, and activation energies for S$_\\text{N}$2 reactions.","After calibration on the same training sets, HIP yields an effective baseline for improved $\\Delta$-quantum machine learning models with superior data-efficiency when compared to previously introduced specialised domain-specific models."],"url":"http://arxiv.org/abs/2305.07010v1"}
{"created":"2023-05-11","title":"Data quality dimensions for fair AI","abstract":"AI systems are not intrinsically neutral and biases trickle in any type of technological tool. In particular when dealing with people, AI algorithms reflect technical errors originating with mislabeled data. As they feed wrong and discriminatory classifications, perpetuating structural racism and marginalization, these systems are not systematically guarded against bias. In this article we consider the problem of bias in AI systems from the point of view of Information Quality dimensions. We illustrate potential improvements of a bias mitigation tool in gender classification errors, referring to two typically difficult contexts: the classification of non-binary individuals and the classification of transgender individuals. The identification of data quality dimensions to implement in bias mitigation tool may help achieve more fairness. Hence, we propose to consider this issue in terms of completeness, consistency, timeliness and reliability, and offer some theoretical results.","sentences":["AI systems are not intrinsically neutral and biases trickle in any type of technological tool.","In particular when dealing with people, AI algorithms reflect technical errors originating with mislabeled data.","As they feed wrong and discriminatory classifications, perpetuating structural racism and marginalization, these systems are not systematically guarded against bias.","In this article we consider the problem of bias in AI systems from the point of view of Information Quality dimensions.","We illustrate potential improvements of a bias mitigation tool in gender classification errors, referring to two typically difficult contexts: the classification of non-binary individuals and the classification of transgender individuals.","The identification of data quality dimensions to implement in bias mitigation tool may help achieve more fairness.","Hence, we propose to consider this issue in terms of completeness, consistency, timeliness and reliability, and offer some theoretical results."],"url":"http://arxiv.org/abs/2305.06967v1"}
{"created":"2023-05-11","title":"The NetMob23 Dataset: A High-resolution Multi-region Service-level Mobile Data Traffic Cartography","abstract":"Digital sources have been enabling unprecedented data-driven and large-scale investigations across a wide range of domains, including demography, sociology, geography, urbanism, criminology, and engineering. A major barrier to innovation is represented by the limited availability of dependable digital datasets, especially in the context of data gathered by mobile network operators or service providers, due to concerns about user privacy and industrial competition. The resulting lack of reference datasets curbs the production of new research methods and results, and prevents verifiability and reproducibility of research outcomes. The NetMob23 dataset offers a rare opportunity to the multidisciplinary research community to access rich data about the spatio-temporal consumption of mobile applications in a developed country. The generation process of the dataset sets a new quality standard, leading to information about the demands generated by 68 popular mobile services, geo-referenced at a high resolution of $100\\times100$ $m^2$ over 20 metropolitan areas in France, and monitored during 77 consecutive days in 2019.","sentences":["Digital sources have been enabling unprecedented data-driven and large-scale investigations across a wide range of domains, including demography, sociology, geography, urbanism, criminology, and engineering.","A major barrier to innovation is represented by the limited availability of dependable digital datasets, especially in the context of data gathered by mobile network operators or service providers, due to concerns about user privacy and industrial competition.","The resulting lack of reference datasets curbs the production of new research methods and results, and prevents verifiability and reproducibility of research outcomes.","The NetMob23 dataset offers a rare opportunity to the multidisciplinary research community to access rich data about the spatio-temporal consumption of mobile applications in a developed country.","The generation process of the dataset sets a new quality standard, leading to information about the demands generated by 68 popular mobile services, geo-referenced at a high resolution of $100\\times100$ $m^2$ over 20 metropolitan areas in France, and monitored during 77 consecutive days in 2019."],"url":"http://arxiv.org/abs/2305.06933v1"}
{"created":"2023-05-11","title":"ns-O-RAN: Simulating O-RAN 5G Systems in ns-3","abstract":"O-RAN is radically shifting how cellular networks are designed, deployed and optimized through network programmability, disaggregation, and virtualization. Specifically, RAN Intelligent Controllers (RICs) can orchestrate and optimize the Radio Access Network (RAN) operations, allowing fine-grained control over the network. RICs provide new approaches and solutions for classical use cases such as on-demand traffic steering, anomaly detection, and Quality of Service (QoS) management, with an optimization that can target single User Equipments (UEs), slices, cells, or entire base stations. While this comes with the potential to enable intelligent, programmable RANs, there are still significant challenges to be faced, primarily related to data collection at scale, development and testing of custom control logic for the RICs, and availability of Open RAN simulation and experimental tools for the research and development communities. To address this, we introduce ns-O-RAN, a software integration between a real-world near-real-time RIC and an ns-3 simulated RAN which provides a platform for researchers and telco operators to build, test and integrate xApps. ns-O-RAN extends a popular Open RAN experimental framework (OpenRAN Gym) with simulation capabilities that enable the generation of realistic datasets without the need for experimental infrastructure. We implement it as a new open-source ns-3 module that uses the E2 interface to connect different simulated 5G base stations with the RIC, enabling the exchange of E2 messages and RAN KPMs to be consumed by standard xApps. Furthermore, we test ns-O-RAN with the OSC and OpenRAN Gym RICs, simplifying the onboarding from a test environment to production with real telecom hardware controlled without major reconfigurations required. ns-O-RAN is open source and publicly available, together with quick-start tutorials and documentation.","sentences":["O-RAN is radically shifting how cellular networks are designed, deployed and optimized through network programmability, disaggregation, and virtualization.","Specifically, RAN Intelligent Controllers (RICs) can orchestrate and optimize the Radio Access Network (RAN) operations, allowing fine-grained control over the network.","RICs provide new approaches and solutions for classical use cases such as on-demand traffic steering, anomaly detection, and Quality of Service (QoS) management, with an optimization that can target single User Equipments (UEs), slices, cells, or entire base stations.","While this comes with the potential to enable intelligent, programmable RANs, there are still significant challenges to be faced, primarily related to data collection at scale, development and testing of custom control logic for the RICs, and availability of Open RAN simulation and experimental tools for the research and development communities.","To address this, we introduce ns-O-RAN, a software integration between a real-world near-real-time RIC and an ns-3 simulated RAN which provides a platform for researchers and telco operators to build, test and integrate xApps.","ns-O-RAN extends a popular Open RAN experimental framework (OpenRAN Gym) with simulation capabilities that enable the generation of realistic datasets without the need for experimental infrastructure.","We implement it as a new open-source ns-3 module that uses the E2 interface to connect different simulated 5G base stations with the RIC, enabling the exchange of E2 messages and RAN KPMs to be consumed by standard xApps.","Furthermore, we test ns-O-RAN with the OSC and OpenRAN Gym RICs, simplifying the onboarding from a test environment to production with real telecom hardware controlled without major reconfigurations required.","ns-O-RAN is open source and publicly available, together with quick-start tutorials and documentation."],"url":"http://arxiv.org/abs/2305.06906v1"}
{"created":"2023-05-11","title":"Using a Bayesian-Inference Approach to Calibrating Models for Simulation in Robotics","abstract":"In robotics, simulation has the potential to reduce design time and costs, and lead to a more robust engineered solution and a safer development process. However, the use of simulators is predicated on the availability of good models. This contribution is concerned with improving the quality of these models via calibration, which is cast herein in a Bayesian framework. First, we discuss the Bayesian machinery involved in model calibration. Then, we demonstrate it in one example: calibration of a vehicle dynamics model that has low degree of freedom count and can be used for state estimation, model predictive control, or path planning. A high fidelity simulator is used to emulate the ``experiments'' and generate the data for the calibration. The merit of this work is not tied to a new Bayesian methodology for calibration, but to the demonstration of how the Bayesian machinery can establish connections among models in computational dynamics, even when the data in use is noisy. The software used to generate the results reported herein is available in a public repository for unfettered use and distribution.","sentences":["In robotics, simulation has the potential to reduce design time and costs, and lead to a more robust engineered solution and a safer development process.","However, the use of simulators is predicated on the availability of good models.","This contribution is concerned with improving the quality of these models via calibration, which is cast herein in a Bayesian framework.","First, we discuss the Bayesian machinery involved in model calibration.","Then, we demonstrate it in one example: calibration of a vehicle dynamics model that has low degree of freedom count and can be used for state estimation, model predictive control, or path planning.","A high fidelity simulator is used to emulate the ``experiments'' and generate the data for the calibration.","The merit of this work is not tied to a new Bayesian methodology for calibration, but to the demonstration of how the Bayesian machinery can establish connections among models in computational dynamics, even when the data in use is noisy.","The software used to generate the results reported herein is available in a public repository for unfettered use and distribution."],"url":"http://arxiv.org/abs/2305.06900v1"}
{"created":"2023-05-11","title":"Multi-Tier Client Selection for Mobile Federated Learning Networks","abstract":"Federated learning (FL), which addresses data privacy issues by training models on resource-constrained mobile devices in a distributed manner, has attracted significant research attention. However, the problem of optimizing FL client selection in mobile federated learning networks (MFLNs), where devices move in and out of each others' coverage and no FL server knows all the data owners, remains open. To bridge this gap, we propose a first-of-its-kind \\underline{Soc}ially-aware \\underline{Fed}erated \\underline{C}lient \\underline{S}election (SocFedCS) approach to minimize costs and train high-quality FL models. SocFedCS enriches the candidate FL client pool by enabling data owners to propagate FL task information through their local networks of trust, even as devices are moving into and out of each others' coverage. Based on Lyapunov optimization, we first transform this time-coupled problem into a step-by-step optimization problem. Then, we design a method based on alternating minimization and self-adaptive global best harmony search to solve this mixed-integer optimization problem. Extensive experiments comparing SocFedCS against five state-of-the-art approaches based on four real-world multimedia datasets demonstrate that it achieves 2.06\\% higher test accuracy and 12.24\\% lower cost on average than the best-performing baseline.","sentences":["Federated learning (FL), which addresses data privacy issues by training models on resource-constrained mobile devices in a distributed manner, has attracted significant research attention.","However, the problem of optimizing FL client selection in mobile federated learning networks (MFLNs), where devices move in and out of each others' coverage and no FL server knows all the data owners, remains open.","To bridge this gap, we propose a first-of-its-kind \\underline{Soc}ially-aware \\underline{Fed}erated \\underline{C}lient \\underline{S}election (SocFedCS) approach to minimize costs and train high-quality FL models.","SocFedCS enriches the candidate FL client pool by enabling data owners to propagate FL task information through their local networks of trust, even as devices are moving into and out of each others' coverage.","Based on Lyapunov optimization, we first transform this time-coupled problem into a step-by-step optimization problem.","Then, we design a method based on alternating minimization and self-adaptive global best harmony search to solve this mixed-integer optimization problem.","Extensive experiments comparing SocFedCS against five state-of-the-art approaches based on four real-world multimedia datasets demonstrate that it achieves 2.06\\% higher test accuracy and 12.24\\% lower cost on average than the best-performing baseline."],"url":"http://arxiv.org/abs/2305.06865v1"}
{"created":"2023-05-11","title":"A Causal Roadmap for Generating High-Quality Real-World Evidence","abstract":"Increasing emphasis on the use of real-world evidence (RWE) to support clinical policy and regulatory decision-making has led to a proliferation of guidance, advice, and frameworks from regulatory agencies, academia, professional societies, and industry. A broad spectrum of studies use real-world data (RWD) to produce RWE, ranging from randomized controlled trials with outcomes assessed using RWD to fully observational studies. Yet many RWE study proposals lack sufficient detail to evaluate adequacy, and many analyses of RWD suffer from implausible assumptions, other methodological flaws, or inappropriate interpretations. The Causal Roadmap is an explicit, itemized, iterative process that guides investigators to pre-specify analytic study designs; it addresses a wide range of guidance within a single framework. By requiring transparent evaluation of causal assumptions and facilitating objective comparisons of design and analysis choices based on pre-specified criteria, the Roadmap can help investigators to evaluate the quality of evidence that a given study is likely to produce, specify a study to generate high-quality RWE, and communicate effectively with regulatory agencies and other stakeholders. This paper aims to disseminate and extend the Causal Roadmap framework for use by clinical and translational researchers, with companion papers demonstrating application of the Causal Roadmap for specific use cases.","sentences":["Increasing emphasis on the use of real-world evidence (RWE) to support clinical policy and regulatory decision-making has led to a proliferation of guidance, advice, and frameworks from regulatory agencies, academia, professional societies, and industry.","A broad spectrum of studies use real-world data (RWD) to produce RWE, ranging from randomized controlled trials with outcomes assessed using RWD to fully observational studies.","Yet many RWE study proposals lack sufficient detail to evaluate adequacy, and many analyses of RWD suffer from implausible assumptions, other methodological flaws, or inappropriate interpretations.","The Causal Roadmap is an explicit, itemized, iterative process that guides investigators to pre-specify analytic study designs; it addresses a wide range of guidance within a single framework.","By requiring transparent evaluation of causal assumptions and facilitating objective comparisons of design and analysis choices based on pre-specified criteria, the Roadmap can help investigators to evaluate the quality of evidence that a given study is likely to produce, specify a study to generate high-quality RWE, and communicate effectively with regulatory agencies and other stakeholders.","This paper aims to disseminate and extend the Causal Roadmap framework for use by clinical and translational researchers, with companion papers demonstrating application of the Causal Roadmap for specific use cases."],"url":"http://arxiv.org/abs/2305.06850v1"}
{"created":"2023-05-11","title":"Implicit Neural Networks with Fourier-Feature Inputs for Free-breathing Cardiac MRI Reconstruction","abstract":"In this paper, we propose an approach for cardiac magnetic resonance imaging (MRI), which aims to reconstruct a real-time video of a beating heart from continuous highly under-sampled measurements. This task is challenging since the object to be reconstructed (the heart) is continuously changing during signal acquisition. To address this challenge, we represent the beating heart with an implicit neural network and fit the network so that the representation of the heart is consistent with the measurements. The network in the form of a multi-layer perceptron with Fourier-feature inputs acts as an effective signal prior and enables adjusting the regularization strength in both the spatial and temporal dimensions of the signal. We examine the proposed approach for 2D free-breathing cardiac real-time MRI in different operating regimes, i.e., for different image resolutions, slice thicknesses, and acquisition lengths. Our method achieves reconstruction quality on par with or slightly better than state-of-the-art untrained convolutional neural networks and superior image quality compared to a recent method that fits an implicit representation directly to Fourier-domain measurements. However, this comes at a higher computational cost. Our approach does not require any additional patient data or biosensors including electrocardiography, making it potentially applicable in a wide range of clinical scenarios.","sentences":["In this paper, we propose an approach for cardiac magnetic resonance imaging (MRI), which aims to reconstruct a real-time video of a beating heart from continuous highly under-sampled measurements.","This task is challenging since the object to be reconstructed (the heart) is continuously changing during signal acquisition.","To address this challenge, we represent the beating heart with an implicit neural network and fit the network so that the representation of the heart is consistent with the measurements.","The network in the form of a multi-layer perceptron with Fourier-feature inputs acts as an effective signal prior and enables adjusting the regularization strength in both the spatial and temporal dimensions of the signal.","We examine the proposed approach for 2D free-breathing cardiac real-time MRI in different operating regimes, i.e., for different image resolutions, slice thicknesses, and acquisition lengths.","Our method achieves reconstruction quality on par with or slightly better than state-of-the-art untrained convolutional neural networks and superior image quality compared to a recent method that fits an implicit representation directly to Fourier-domain measurements.","However, this comes at a higher computational cost.","Our approach does not require any additional patient data or biosensors including electrocardiography, making it potentially applicable in a wide range of clinical scenarios."],"url":"http://arxiv.org/abs/2305.06822v1"}
{"created":"2023-05-11","title":"Generation of Structurally Realistic Retinal Fundus Images with Diffusion Models","abstract":"We introduce a new technique for generating retinal fundus images that have anatomically accurate vascular structures, using diffusion models. We generate artery/vein masks to create the vascular structure, which we then condition to produce retinal fundus images. The proposed method can generate high-quality images with more realistic vascular structures and can create a diverse range of images based on the strengths of the diffusion model. We present quantitative evaluations that demonstrate the performance improvement using our method for data augmentation on vessel segmentation and artery/vein classification. We also present Turing test results by clinical experts, showing that our generated images are difficult to distinguish with real images. We believe that our method can be applied to construct stand-alone datasets that are irrelevant of patient privacy.","sentences":["We introduce a new technique for generating retinal fundus images that have anatomically accurate vascular structures, using diffusion models.","We generate artery/vein masks to create the vascular structure, which we then condition to produce retinal fundus images.","The proposed method can generate high-quality images with more realistic vascular structures and can create a diverse range of images based on the strengths of the diffusion model.","We present quantitative evaluations that demonstrate the performance improvement using our method for data augmentation on vessel segmentation and artery/vein classification.","We also present Turing test results by clinical experts, showing that our generated images are difficult to distinguish with real images.","We believe that our method can be applied to construct stand-alone datasets that are irrelevant of patient privacy."],"url":"http://arxiv.org/abs/2305.06813v1"}
{"created":"2023-05-11","title":"Quality Competition Among Internet Service Providers in a Path-Aware Internet","abstract":"Internet service providers (ISPs) have a variety of quality attributes that determine their attractiveness for data transmission, ranging from quality-of-service metrics such as jitter to security properties such as the presence of DDoS defense systems. ISPs improve these attributes in line with their profit objective, i.e., up to the level that maximizes revenue from attracted traffic while minimizing attribute-related cost, all in the context of alternative offers by competing ISPs. In today's Internet, this quality competition mostly takes place between ISPs that are next-hop options for a given destination. In contrast, emerging path-aware networks enable end-points to select entire inter-domain forwarding paths, and thus intensify ISP competition.   In this paper, we analyze how path-aware networking changes the competition dynamics in the Internet, and how path quality and ISP profits are affected as a result. To that end, we develop a game-theoretic model in which ISPs (i) affect path quality via multiple attributes that entail costs, (ii) constitute paths together with other selfish ISPs, and (iii) are in competition with alternative paths when attracting traffic. The model enables an extensive theoretical analysis, surprisingly showing that end-point path selection can have both positive and negative effects on path quality and ISP profits, depending on the network topology and the cost structure of ISPs. However, a large-scale simulation, which draws on real-world data to set model parameters, shows that the positive effects will likely prevail in practice: Compared to a single-path scenario, the prevalence of quality attributes increases by at least 50%, and 75% of ISPs improve their profit if the end-points can choose among 5 paths towards any destination.","sentences":["Internet service providers (ISPs) have a variety of quality attributes that determine their attractiveness for data transmission, ranging from quality-of-service metrics such as jitter to security properties such as the presence of DDoS defense systems.","ISPs improve these attributes in line with their profit objective, i.e., up to the level that maximizes revenue from attracted traffic while minimizing attribute-related cost, all in the context of alternative offers by competing ISPs.","In today's Internet, this quality competition mostly takes place between ISPs that are next-hop options for a given destination.","In contrast, emerging path-aware networks enable end-points to select entire inter-domain forwarding paths, and thus intensify ISP competition.   ","In this paper, we analyze how path-aware networking changes the competition dynamics in the Internet, and how path quality and ISP profits are affected as a result.","To that end, we develop a game-theoretic model in which ISPs (i) affect path quality via multiple attributes that entail costs, (ii) constitute paths together with other selfish ISPs, and (iii) are in competition with alternative paths when attracting traffic.","The model enables an extensive theoretical analysis, surprisingly showing that end-point path selection can have both positive and negative effects on path quality and ISP profits, depending on the network topology and the cost structure of ISPs.","However, a large-scale simulation, which draws on real-world data to set model parameters, shows that the positive effects will likely prevail in practice: Compared to a single-path scenario, the prevalence of quality attributes increases by at least 50%, and 75% of ISPs improve their profit if the end-points can choose among 5 paths towards any destination."],"url":"http://arxiv.org/abs/2305.06811v1"}
{"created":"2023-05-11","title":"Adaptive Privacy-Preserving Coded Computing With Hierarchical Task Partitioning","abstract":"Distributed computing is known as an emerging and efficient technique to support various intelligent services, such as large-scale machine learning. However, privacy leakage and random delays from straggling servers pose significant challenges. To address these issues, coded computing, a promising solution that combines coding theory with distributed computing, recovers computation tasks with results from a subset of workers. In this paper, we propose the adaptive privacy-preserving coded computing (APCC) strategy, which can adaptively provide accurate or approximated results according to the form of computation functions, so as to suit diverse types of computation tasks. We prove that APCC achieves complete data privacy preservation and demonstrate its optimality in terms of encoding rate, defined as the ratio between the computation loads of tasks before and after encoding. To further alleviate the straggling effect and reduce delay, we integrate hierarchical task partitioning and task cancellation into the coding design of APCC. The corresponding partitioning problems are formulated as mixed-integer nonlinear programming (MINLP) problems with the objective of minimizing task completion delay. We propose a low-complexity maximum value descent (MVD) algorithm to optimally solve these problems. Simulation results show that APCC can reduce task completion delay by at least 42.9% compared to other state-of-the-art benchmarks.","sentences":["Distributed computing is known as an emerging and efficient technique to support various intelligent services, such as large-scale machine learning.","However, privacy leakage and random delays from straggling servers pose significant challenges.","To address these issues, coded computing, a promising solution that combines coding theory with distributed computing, recovers computation tasks with results from a subset of workers.","In this paper, we propose the adaptive privacy-preserving coded computing (APCC) strategy, which can adaptively provide accurate or approximated results according to the form of computation functions, so as to suit diverse types of computation tasks.","We prove that APCC achieves complete data privacy preservation and demonstrate its optimality in terms of encoding rate, defined as the ratio between the computation loads of tasks before and after encoding.","To further alleviate the straggling effect and reduce delay, we integrate hierarchical task partitioning and task cancellation into the coding design of APCC.","The corresponding partitioning problems are formulated as mixed-integer nonlinear programming (MINLP) problems with the objective of minimizing task completion delay.","We propose a low-complexity maximum value descent (MVD) algorithm to optimally solve these problems.","Simulation results show that APCC can reduce task completion delay by at least 42.9% compared to other state-of-the-art benchmarks."],"url":"http://arxiv.org/abs/2305.06654v1"}
