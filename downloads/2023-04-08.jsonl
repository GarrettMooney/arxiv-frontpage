{"created":"2023-04-06","title":"$\\text{DC}^2$: Dual-Camera Defocus Control by Learning to Refocus","abstract":"Smartphone cameras today are increasingly approaching the versatility and quality of professional cameras through a combination of hardware and software advancements. However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images. At the same time, many smartphones now have multiple cameras with different fixed apertures -- specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF. In this work, we propose $\\text{DC}^2$, a system for defocus control for synthetically varying camera aperture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system. Our key insight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to control defocus. Quantitative and qualitative evaluations on real-world data demonstrate our system's efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus. Finally, we demonstrate creative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects.","sentences":["Smartphone cameras today are increasingly approaching the versatility and quality of professional cameras through a combination of hardware and software advancements.","However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images.","At the same time, many smartphones now have multiple cameras with different fixed apertures -- specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF.","In this work, we propose $\\text{DC}^2$, a system for defocus control for synthetically varying camera aperture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system.","Our key insight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to control defocus.","Quantitative and qualitative evaluations on real-world data demonstrate our system's efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus.","Finally, we demonstrate creative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects."],"url":"http://arxiv.org/abs/2304.03285v1"}
{"created":"2023-04-06","title":"Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention","abstract":"Humans possess a versatile mechanism for extracting structured representations of our visual world. When looking at an image, we can decompose the scene into entities and their parts as well as obtain the dependencies between them. To mimic such capability, we propose Visual Dependency Transformers (DependencyViT) that can induce visual dependencies without any labels. We achieve that with a novel neural operator called \\emph{reversed attention} that can naturally capture long-range visual dependencies between image patches. Specifically, we formulate it as a dependency graph where a child token in reversed attention is trained to attend to its parent tokens and send information following a normalized probability distribution rather than gathering information in conventional self-attention. With such a design, hierarchies naturally emerge from reversed attention layers, and a dependency tree is progressively induced from leaf nodes to the root node unsupervisedly.   DependencyViT offers several appealing benefits. (i) Entities and their parts in an image are represented by different subtrees, enabling part partitioning from dependencies; (ii) Dynamic visual pooling is made possible. The leaf nodes which rarely send messages can be pruned without hindering the model performance, based on which we propose the lightweight DependencyViT-Lite to reduce the computational and memory footprints; (iii) DependencyViT works well on both self- and weakly-supervised pretraining paradigms on ImageNet, and demonstrates its effectiveness on 8 datasets and 5 tasks, such as unsupervised part and saliency segmentation, recognition, and detection.","sentences":["Humans possess a versatile mechanism for extracting structured representations of our visual world.","When looking at an image, we can decompose the scene into entities and their parts as well as obtain the dependencies between them.","To mimic such capability, we propose Visual Dependency Transformers (DependencyViT) that can induce visual dependencies without any labels.","We achieve that with a novel neural operator called \\emph{reversed attention} that can naturally capture long-range visual dependencies between image patches.","Specifically, we formulate it as a dependency graph where a child token in reversed attention is trained to attend to its parent tokens and send information following a normalized probability distribution rather than gathering information in conventional self-attention.","With such a design, hierarchies naturally emerge from reversed attention layers, and a dependency tree is progressively induced from leaf nodes to the root node unsupervisedly.   ","DependencyViT offers several appealing benefits.","(i) Entities and their parts in an image are represented by different subtrees, enabling part partitioning from dependencies; (ii) Dynamic visual pooling is made possible.","The leaf nodes which rarely send messages can be pruned without hindering the model performance, based on which we propose the lightweight DependencyViT-Lite to reduce the computational and memory footprints; (iii) DependencyViT works well on both self- and weakly-supervised pretraining paradigms on ImageNet, and demonstrates its effectiveness on 8 datasets and 5 tasks, such as unsupervised part and saliency segmentation, recognition, and detection."],"url":"http://arxiv.org/abs/2304.03282v1"}
{"created":"2023-04-06","title":"LANe: Lighting-Aware Neural Fields for Compositional Scene Synthesis","abstract":"Neural fields have recently enjoyed great success in representing and rendering 3D scenes. However, most state-of-the-art implicit representations model static or dynamic scenes as a whole, with minor variations. Existing work on learning disentangled world and object neural fields do not consider the problem of composing objects into different world neural fields in a lighting-aware manner. We present Lighting-Aware Neural Field (LANe) for the compositional synthesis of driving scenes in a physically consistent manner. Specifically, we learn a scene representation that disentangles the static background and transient elements into a world-NeRF and class-specific object-NeRFs to allow compositional synthesis of multiple objects in the scene. Furthermore, we explicitly designed both the world and object models to handle lighting variation, which allows us to compose objects into scenes with spatially varying lighting. This is achieved by constructing a light field of the scene and using it in conjunction with a learned shader to modulate the appearance of the object NeRFs. We demonstrate the performance of our model on a synthetic dataset of diverse lighting conditions rendered with the CARLA simulator, as well as a novel real-world dataset of cars collected at different times of the day. Our approach shows that it outperforms state-of-the-art compositional scene synthesis on the challenging dataset setup, via composing object-NeRFs learned from one scene into an entirely different scene whilst still respecting the lighting variations in the novel scene. For more results, please visit our project website https://lane-composition.github.io/.","sentences":["Neural fields have recently enjoyed great success in representing and rendering 3D scenes.","However, most state-of-the-art implicit representations model static or dynamic scenes as a whole, with minor variations.","Existing work on learning disentangled world and object neural fields do not consider the problem of composing objects into different world neural fields in a lighting-aware manner.","We present Lighting-Aware Neural Field (LANe) for the compositional synthesis of driving scenes in a physically consistent manner.","Specifically, we learn a scene representation that disentangles the static background and transient elements into a world-NeRF and class-specific object-NeRFs to allow compositional synthesis of multiple objects in the scene.","Furthermore, we explicitly designed both the world and object models to handle lighting variation, which allows us to compose objects into scenes with spatially varying lighting.","This is achieved by constructing a light field of the scene and using it in conjunction with a learned shader to modulate the appearance of the object NeRFs.","We demonstrate the performance of our model on a synthetic dataset of diverse lighting conditions rendered with the CARLA simulator, as well as a novel real-world dataset of cars collected at different times of the day.","Our approach shows that it outperforms state-of-the-art compositional scene synthesis on the challenging dataset setup, via composing object-NeRFs learned from one scene into an entirely different scene whilst still respecting the lighting variations in the novel scene.","For more results, please visit our project website https://lane-composition.github.io/."],"url":"http://arxiv.org/abs/2304.03280v1"}
{"created":"2023-04-06","title":"Neural Fields meet Explicit Geometric Representation for Inverse Rendering of Urban Scenes","abstract":"Reconstruction and intrinsic decomposition of scenes from captured imagery would enable many applications such as relighting and virtual object insertion. Recent NeRF based methods achieve impressive fidelity of 3D reconstruction, but bake the lighting and shadows into the radiance field, while mesh-based methods that facilitate intrinsic decomposition through differentiable rendering have not yet scaled to the complexity and scale of outdoor scenes. We present a novel inverse rendering framework for large urban scenes capable of jointly reconstructing the scene geometry, spatially-varying materials, and HDR lighting from a set of posed RGB images with optional depth. Specifically, we use a neural field to account for the primary rays, and use an explicit mesh (reconstructed from the underlying neural field) for modeling secondary rays that produce higher-order lighting effects such as cast shadows. By faithfully disentangling complex geometry and materials from lighting effects, our method enables photorealistic relighting with specular and shadow effects on several outdoor datasets. Moreover, it supports physics-based scene manipulations such as virtual object insertion with ray-traced shadow casting.","sentences":["Reconstruction and intrinsic decomposition of scenes from captured imagery would enable many applications such as relighting and virtual object insertion.","Recent NeRF based methods achieve impressive fidelity of 3D reconstruction, but bake the lighting and shadows into the radiance field, while mesh-based methods that facilitate intrinsic decomposition through differentiable rendering have not yet scaled to the complexity and scale of outdoor scenes.","We present a novel inverse rendering framework for large urban scenes capable of jointly reconstructing the scene geometry, spatially-varying materials, and HDR lighting from a set of posed RGB images with optional depth.","Specifically, we use a neural field to account for the primary rays, and use an explicit mesh (reconstructed from the underlying neural field) for modeling secondary rays that produce higher-order lighting effects such as cast shadows.","By faithfully disentangling complex geometry and materials from lighting effects, our method enables photorealistic relighting with specular and shadow effects on several outdoor datasets.","Moreover, it supports physics-based scene manipulations such as virtual object insertion with ray-traced shadow casting."],"url":"http://arxiv.org/abs/2304.03266v1"}
{"created":"2023-04-06","title":"When do you need Chain-of-Thought Prompting for ChatGPT?","abstract":"Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs). For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%. However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks. Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so. Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs. In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT. Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage.","sentences":["Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs).","For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%.","However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT.","Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks.","Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so.","Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs.","In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT.","Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage."],"url":"http://arxiv.org/abs/2304.03262v1"}
{"created":"2023-04-06","title":"SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation","abstract":"Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains. This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions. This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation. To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data. As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data. This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques. Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios.","sentences":["Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains.","This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions.","This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation.","To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data.","As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data.","This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques.","Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios."],"url":"http://arxiv.org/abs/2304.03251v1"}
{"created":"2023-04-06","title":"Inst-Inpaint: Instructing to Remove Objects with Diffusion Models","abstract":"Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way. Traditionally, the pixels that are wished to be erased are defined with binary masks. From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors. In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously. For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon. Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts. We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets. We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements.","sentences":["Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way.","Traditionally, the pixels that are wished to be erased are defined with binary masks.","From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors.","In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously.","For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon.","Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts.","We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets.","We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements."],"url":"http://arxiv.org/abs/2304.03246v1"}
{"created":"2023-04-06","title":"Large language models effectively leverage document-level context for literary translation, but critical errors persist","abstract":"Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches. With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact. We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation.","sentences":["Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets.","However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult.","We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003)","LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English).","Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better.","We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches.","With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact.","We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation."],"url":"http://arxiv.org/abs/2304.03245v1"}
{"created":"2023-04-06","title":"Synthetic Data in Healthcare","abstract":"Synthetic data are becoming a critical tool for building artificially intelligent systems. Simulators provide a way of generating data systematically and at scale. These data can then be used either exclusively, or in conjunction with real data, for training and testing systems. Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck. While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial. Furthermore, these data are highly sensitive and often patient specific. Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists. In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases.","sentences":["Synthetic data are becoming a critical tool for building artificially intelligent systems.","Simulators provide a way of generating data systematically and at scale.","These data can then be used either exclusively, or in conjunction with real data, for training and testing systems.","Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck.","While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial.","Furthermore, these data are highly sensitive and often patient specific.","Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists.","In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine.","We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases."],"url":"http://arxiv.org/abs/2304.03243v1"}
{"created":"2023-04-06","title":"Assessing the Reproducibility of Machine-learning-based Biomarker Discovery in Parkinson's Disease","abstract":"Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease. Thus, GWAS data can be used to identify genetic variations associated with the disease. Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers. However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped. To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies. We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers. Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies. However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers. These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before. These findings open up new potential avenues of investigation.","sentences":["Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease.","Thus, GWAS data can be used to identify genetic variations associated with the disease.","Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers.","However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped.","To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies.","We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers.","Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies.","However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers.","These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before.","These findings open up new potential avenues of investigation."],"url":"http://arxiv.org/abs/2304.03239v1"}
{"created":"2023-04-06","title":"Anomaly Detection via Gumbel Noise Score Matching","abstract":"We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data. GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions. We test our method on a suite of anomaly detection tabular datasets. GNSM achieves a consistently high performance across all experiments. We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions. Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth. We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work.","sentences":["We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data.","GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions.","We test our method on a suite of anomaly detection tabular datasets.","GNSM achieves a consistently high performance across all experiments.","We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions.","Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth.","We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work."],"url":"http://arxiv.org/abs/2304.03220v1"}
{"created":"2023-04-06","title":"Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models","abstract":"To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable. Towards that goal, algorithmic auditing has received substantial attention. To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race). However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences. To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets. Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label). To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples. Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts. Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success. Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models.","sentences":["To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable.","Towards that goal, algorithmic auditing has received substantial attention.","To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race).","However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences.","To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets.","Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label).","To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples.","Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts.","Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success.","Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models."],"url":"http://arxiv.org/abs/2304.03218v1"}
{"created":"2023-04-06","title":"On the Pareto Front of Multilingual Neural Machine Translation","abstract":"In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better performance than temperature searching and gradient manipulation methods using up to half of the total training budget in our experiments.","sentences":["In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT).","By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus.","That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions.","Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks.","Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better performance than temperature searching and gradient manipulation methods using up to half of the total training budget in our experiments."],"url":"http://arxiv.org/abs/2304.03216v1"}
{"created":"2023-04-06","title":"Causal Discovery and Optimal Experimental Design for Genome-Scale Biological Network Recovery","abstract":"Causal discovery of genome-scale networks is important for identifying pathways from genes to observable traits - e.g. differences in cell function, disease, drug resistance and others. Causal learners based on graphical models rely on interventional samples to orient edges in the network. However, these models have not been shown to scale up the size of the genome, which are on the order of 1e3-1e4 genes. We introduce a new learner, SP-GIES, that jointly learns from interventional and observational datasets and achieves almost 4x speedup against an existing learner for 1,000 node networks. SP-GIES achieves an AUC-PR score of 0.91 on 1,000 node networks, and scales up to 2,000 node networks - this is 4x larger than existing works. We also show how SP-GIES improves downstream optimal experimental design strategies for selecting interventional experiments to perform on the system. This is an important step forward in realizing causal discovery at scale via autonomous experimental design.","sentences":["Causal discovery of genome-scale networks is important for identifying pathways from genes to observable traits - e.g. differences in cell function, disease, drug resistance and others.","Causal learners based on graphical models rely on interventional samples to orient edges in the network.","However, these models have not been shown to scale up the size of the genome, which are on the order of 1e3-1e4 genes.","We introduce a new learner, SP-GIES, that jointly learns from interventional and observational datasets and achieves almost 4x speedup against an existing learner for 1,000 node networks.","SP-GIES achieves an AUC-PR score of 0.91 on 1,000 node networks, and scales up to 2,000 node networks - this is 4x larger than existing works.","We also show how SP-GIES improves downstream optimal experimental design strategies for selecting interventional experiments to perform on the system.","This is an important step forward in realizing causal discovery at scale via autonomous experimental design."],"url":"http://arxiv.org/abs/2304.03210v1"}
{"created":"2023-04-06","title":"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster","abstract":"We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools. We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters. We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget). We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives. We describe our learnings including how Maximal Update Parameterization ($\\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale. We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal model scaling to models trained on fixed dataset sizes. Cerebras-GPT models are available on HuggingFace: https://huggingface.co/cerebras.","sentences":["We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools.","We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters.","We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget).","We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives.","We describe our learnings including how Maximal Update Parameterization ($\\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale.","We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal model scaling to models trained on fixed dataset sizes.","Cerebras-GPT models are available on HuggingFace: https://huggingface.co/cerebras."],"url":"http://arxiv.org/abs/2304.03208v1"}
{"created":"2023-04-06","title":"SLM: End-to-end Feature Selection via Sparse Learnable Masks","abstract":"Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability. We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples. At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles. In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax. This allows for more effective learning as demonstrated in ablation studies. Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance.","sentences":["Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability.","We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples.","At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles.","In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax.","This allows for more effective learning as demonstrated in ablation studies.","Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance."],"url":"http://arxiv.org/abs/2304.03202v1"}
{"created":"2023-04-06","title":"Micron-BERT: BERT-based Facial Micro-Expression Recognition","abstract":"Micro-expression recognition is one of the most challenging topics in affective computing. It aims to recognize tiny facial movements difficult for humans to perceive in a brief period, i.e., 0.25 to 0.5 seconds. Recent advances in pre-training deep Bidirectional Transformers (BERT) have significantly improved self-supervised learning tasks in computer vision. However, the standard BERT in vision problems is designed to learn only from full images or videos, and the architecture cannot accurately detect details of facial micro-expressions. This paper presents Micron-BERT ($\\mu$-BERT), a novel approach to facial micro-expression recognition. The proposed method can automatically capture these movements in an unsupervised manner based on two key ideas. First, we employ Diagonal Micro-Attention (DMA) to detect tiny differences between two frames. Second, we introduce a new Patch of Interest (PoI) module to localize and highlight micro-expression interest regions and simultaneously reduce noisy backgrounds and distractions. By incorporating these components into an end-to-end deep network, the proposed $\\mu$-BERT significantly outperforms all previous work in various micro-expression tasks. $\\mu$-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8 million images, and achieves high accuracy on new unseen facial micro-expression datasets. Empirical experiments show $\\mu$-BERT consistently outperforms state-of-the-art performance on four micro-expression benchmarks, including SAMM, CASME II, SMIC, and CASME3, by significant margins. Code will be available at \\url{https://github.com/uark-cviu/Micron-BERT}","sentences":["Micro-expression recognition is one of the most challenging topics in affective computing.","It aims to recognize tiny facial movements difficult for humans to perceive in a brief period, i.e., 0.25 to 0.5 seconds.","Recent advances in pre-training deep Bidirectional Transformers (BERT) have significantly improved self-supervised learning tasks in computer vision.","However, the standard BERT in vision problems is designed to learn only from full images or videos, and the architecture cannot accurately detect details of facial micro-expressions.","This paper presents Micron-BERT ($\\mu$-BERT), a novel approach to facial micro-expression recognition.","The proposed method can automatically capture these movements in an unsupervised manner based on two key ideas.","First, we employ Diagonal Micro-Attention (DMA) to detect tiny differences between two frames.","Second, we introduce a new Patch of Interest (PoI) module to localize and highlight micro-expression interest regions and simultaneously reduce noisy backgrounds and distractions.","By incorporating these components into an end-to-end deep network, the proposed $\\mu$-BERT significantly outperforms all previous work in various micro-expression tasks.","$\\mu$-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8 million images, and achieves high accuracy on new unseen facial micro-expression datasets.","Empirical experiments show $\\mu$-BERT consistently outperforms state-of-the-art performance on four micro-expression benchmarks, including SAMM, CASME II, SMIC, and CASME3, by significant margins.","Code will be available at \\url{https://github.com/uark-cviu/Micron-BERT}"],"url":"http://arxiv.org/abs/2304.03195v1"}
{"created":"2023-04-06","title":"Advances in Data-Driven Analysis and Synthesis of 3D Indoor Scenes","abstract":"This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes. We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations. Specifically, we focus on the analysis and synthesis of 3D indoor scenes. With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity. And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis. We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general. For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature. Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse.","sentences":["This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes.","We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations.","Specifically, we focus on the analysis and synthesis of 3D indoor scenes.","With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity.","And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis.","We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general.","For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature.","Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse."],"url":"http://arxiv.org/abs/2304.03188v1"}
{"created":"2023-04-06","title":"CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition","abstract":"Creating animatable avatars from static scans requires the modeling of clothing deformations in different poses. Existing learning-based methods typically add pose-dependent deformations upon a minimally-clothed mesh template or a learned implicit template, which have limitations in capturing details or hinder end-to-end learning. In this paper, we revisit point-based solutions and propose to decompose explicit garment-related templates and then add pose-dependent wrinkles to them. In this way, the clothing deformations are disentangled such that the pose-dependent wrinkles can be better learned and applied to unseen poses. Additionally, to tackle the seam artifact issues in recent state-of-the-art point-based methods, we propose to learn point features on a body surface, which establishes a continuous and compact feature space to capture the fine-grained and pose-dependent clothing geometry. To facilitate the research in this field, we also introduce a high-quality scan dataset of humans in real-world clothing. Our approach is validated on two existing datasets and our newly introduced dataset, showing better clothing deformation results in unseen poses. The project page with code and dataset can be found at https://www.liuyebin.com/closet.","sentences":["Creating animatable avatars from static scans requires the modeling of clothing deformations in different poses.","Existing learning-based methods typically add pose-dependent deformations upon a minimally-clothed mesh template or a learned implicit template, which have limitations in capturing details or hinder end-to-end learning.","In this paper, we revisit point-based solutions and propose to decompose explicit garment-related templates and then add pose-dependent wrinkles to them.","In this way, the clothing deformations are disentangled such that the pose-dependent wrinkles can be better learned and applied to unseen poses.","Additionally, to tackle the seam artifact issues in recent state-of-the-art point-based methods, we propose to learn point features on a body surface, which establishes a continuous and compact feature space to capture the fine-grained and pose-dependent clothing geometry.","To facilitate the research in this field, we also introduce a high-quality scan dataset of humans in real-world clothing.","Our approach is validated on two existing datasets and our newly introduced dataset, showing better clothing deformation results in unseen poses.","The project page with code and dataset can be found at https://www.liuyebin.com/closet."],"url":"http://arxiv.org/abs/2304.03167v1"}
{"created":"2023-04-06","title":"Bridging the Language Gap: Knowledge Injected Multilingual Question Answering","abstract":"Question Answering (QA) is the task of automatically answering questions posed by humans in natural languages. There are different settings to answer a question, such as abstractive, extractive, boolean, and multiple-choice QA. As a popular topic in natural language processing tasks, extractive question answering task (extractive QA) has gained extensive attention in the past few years. With the continuous evolvement of the world, generalized cross-lingual transfer (G-XLT), where question and answer context are in different languages, poses some unique challenges over cross-lingual transfer (XLT), where question and answer context are in the same language. With the boost of corresponding development of related benchmarks, many works have been done to improve the performance of various language QA tasks. However, only a few works are dedicated to the G-XLT task. In this work, we propose a generalized cross-lingual transfer framework to enhance the model's ability to understand different languages. Specifically, we first assemble triples from different languages to form multilingual knowledge. Since the lack of knowledge between different languages greatly limits models' reasoning ability, we further design a knowledge injection strategy via leveraging link prediction techniques to enrich the model storage of multilingual knowledge. In this way, we can profoundly exploit rich semantic knowledge. Experiment results on real-world datasets MLQA demonstrate that the proposed method can improve the performance by a large margin, outperforming the baseline method by 13.18%/12.00% F1/EM on average.","sentences":["Question Answering (QA) is the task of automatically answering questions posed by humans in natural languages.","There are different settings to answer a question, such as abstractive, extractive, boolean, and multiple-choice QA.","As a popular topic in natural language processing tasks, extractive question answering task (extractive QA) has gained extensive attention in the past few years.","With the continuous evolvement of the world, generalized cross-lingual transfer (G-XLT), where question and answer context are in different languages, poses some unique challenges over cross-lingual transfer (XLT), where question and answer context are in the same language.","With the boost of corresponding development of related benchmarks, many works have been done to improve the performance of various language QA tasks.","However, only a few works are dedicated to the G-XLT task.","In this work, we propose a generalized cross-lingual transfer framework to enhance the model's ability to understand different languages.","Specifically, we first assemble triples from different languages to form multilingual knowledge.","Since the lack of knowledge between different languages greatly limits models' reasoning ability, we further design a knowledge injection strategy via leveraging link prediction techniques to enrich the model storage of multilingual knowledge.","In this way, we can profoundly exploit rich semantic knowledge.","Experiment results on real-world datasets MLQA demonstrate that the proposed method can improve the performance by a large margin, outperforming the baseline method by 13.18%/12.00% F1/EM on average."],"url":"http://arxiv.org/abs/2304.03159v1"}
{"created":"2023-04-06","title":"Patch-wise Features for Blur Image Classification","abstract":"Images captured through smartphone cameras often suffer from degradation, blur being one of the major ones, posing a challenge in processing these images for downstream tasks. In this paper we propose low-compute lightweight patch-wise features for image quality assessment. Using our method we can discriminate between blur vs sharp image degradation. To this end, we train a decision-tree based XGBoost model on various intuitive image features like gray level variance, first and second order gradients, texture features like local binary patterns. Experiments conducted on an open dataset show that the proposed low compute method results in 90.1% mean accuracy on the validation set, which is comparable to the accuracy of a compute-intensive VGG16 network with 94% mean accuracy fine-tuned to this task. To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively. The proposed method is 10x faster than the VGG16 based model on CPU and scales linearly to the input image size making it suitable to be implemented on low compute edge devices.","sentences":["Images captured through smartphone cameras often suffer from degradation, blur being one of the major ones, posing a challenge in processing these images for downstream tasks.","In this paper we propose low-compute lightweight patch-wise features for image quality assessment.","Using our method we can discriminate between blur vs sharp image degradation.","To this end, we train a decision-tree based XGBoost model on various intuitive image features like gray level variance, first and second order gradients, texture features like local binary patterns.","Experiments conducted on an open dataset show that the proposed low compute method results in 90.1% mean accuracy on the validation set, which is comparable to the accuracy of a compute-intensive VGG16 network with 94% mean accuracy fine-tuned to this task.","To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively.","The proposed method is 10x faster than the VGG16 based model on CPU and scales linearly to the input image size making it suitable to be implemented on low compute edge devices."],"url":"http://arxiv.org/abs/2304.03156v1"}
{"created":"2023-04-06","title":"Zero-Shot Next-Item Recommendation using Large Pretrained Language Models","abstract":"Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples. Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting. We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders. First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences. To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations. Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that capture the user's preferences, select representative previously watched movies, and recommend a ranked list of 10 movies. We evaluate the proposed approach using GPT-3 on MovieLens 100K dataset and show that it achieves strong zero-shot performance, even outperforming some strong sequential recommendation models trained on the entire training dataset. These promising results highlight the ample research opportunities to use LLMs as recommenders. The code can be found at https://github.com/AGI-Edgerunners/LLM-Next-Item-Rec.","sentences":["Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples.","Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting.","We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders.","First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences.","To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations.","Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering.","Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that capture the user's preferences, select representative previously watched movies, and recommend a ranked list of 10 movies.","We evaluate the proposed approach using GPT-3 on MovieLens 100K dataset and show that it achieves strong zero-shot performance, even outperforming some strong sequential recommendation models trained on the entire training dataset.","These promising results highlight the ample research opportunities to use LLMs as recommenders.","The code can be found at https://github.com/AGI-Edgerunners/LLM-Next-Item-Rec."],"url":"http://arxiv.org/abs/2304.03153v1"}
{"created":"2023-04-06","title":"The Eyes Have It!: Using Human-Selected Features for Predicting Athletes' Performance","abstract":"Predicting athletes' performance has relied mostly on statistical data. Besides the traditional data, various types of data, including video, have become available. However, it is challenging to use them for deep learning, especially when the size of the athletes' dataset is small. This research proposes a feature-selection strategy based on the criteria used by insightful people, which could improve ML performance. Our ML model employs features selected by people who correctly evaluated the athletes' future performance. We tested out a strategy to predict the LPGA players' next day performance using their interview video. We asked study participants to predict the players' next day score after watching the interviews and asked why. Using combined features of the facial landmarks' movements, derived from the participants, and meta-data showed a better F1-score than using each feature separately. This study suggests that the human-in-the-loop model could improve algorithms' performance with small-dataset.","sentences":["Predicting athletes' performance has relied mostly on statistical data.","Besides the traditional data, various types of data, including video, have become available.","However, it is challenging to use them for deep learning, especially when the size of the athletes' dataset is small.","This research proposes a feature-selection strategy based on the criteria used by insightful people, which could improve ML performance.","Our ML model employs features selected by people who correctly evaluated the athletes' future performance.","We tested out a strategy to predict the LPGA players' next day performance using their interview video.","We asked study participants to predict the players' next day score after watching the interviews and asked why.","Using combined features of the facial landmarks' movements, derived from the participants, and meta-data showed a better F1-score than using each feature separately.","This study suggests that the human-in-the-loop model could improve algorithms' performance with small-dataset."],"url":"http://arxiv.org/abs/2304.03148v1"}
{"created":"2023-04-06","title":"Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions","abstract":"Deep neural networks have been critical in the task of Visual Question Answering (VQA), with research traditionally focused on improving model accuracy. Recently, however, there has been a trend towards evaluating the robustness of these models against adversarial attacks. This involves assessing the accuracy of VQA models under increasing levels of noise in the input, which can target either the image or the proposed query question, dubbed the main question. However, there is currently a lack of proper analysis of this aspect of VQA. This work proposes a new method that utilizes semantically related questions, referred to as basic questions, acting as noise to evaluate the robustness of VQA models. It is hypothesized that as the similarity of a basic question to the main question decreases, the level of noise increases. To generate a reasonable noise level for a given main question, a pool of basic questions is ranked based on their similarity to the main question, and this ranking problem is cast as a LASSO optimization problem. Additionally, this work proposes a novel robustness measure, R_score, and two basic question datasets to standardize the analysis of VQA model robustness. The experimental results demonstrate that the proposed evaluation method effectively analyzes the robustness of VQA models. Moreover, the experiments show that in-context learning with a chain of basic questions can enhance model accuracy.","sentences":["Deep neural networks have been critical in the task of Visual Question Answering (VQA), with research traditionally focused on improving model accuracy.","Recently, however, there has been a trend towards evaluating the robustness of these models against adversarial attacks.","This involves assessing the accuracy of VQA models under increasing levels of noise in the input, which can target either the image or the proposed query question, dubbed the main question.","However, there is currently a lack of proper analysis of this aspect of VQA.","This work proposes a new method that utilizes semantically related questions, referred to as basic questions, acting as noise to evaluate the robustness of VQA models.","It is hypothesized that as the similarity of a basic question to the main question decreases, the level of noise increases.","To generate a reasonable noise level for a given main question, a pool of basic questions is ranked based on their similarity to the main question, and this ranking problem is cast as a LASSO optimization problem.","Additionally, this work proposes a novel robustness measure, R_score, and two basic question datasets to standardize the analysis of VQA model robustness.","The experimental results demonstrate that the proposed evaluation method effectively analyzes the robustness of VQA models.","Moreover, the experiments show that in-context learning with a chain of basic questions can enhance model accuracy."],"url":"http://arxiv.org/abs/2304.03147v1"}
{"created":"2023-04-06","title":"Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming","abstract":"Question answering (QA) models have shown compelling results in the task of Machine Reading Comprehension (MRC). Recently these systems have proved to perform better than humans on held-out test sets of datasets e.g. SQuAD, but their robustness is not guaranteed. The QA model's brittleness is exposed when evaluated on adversarial generated examples by a performance drop. In this study, we explore the robustness of MRC models to entity renaming, with entities from low-resource regions such as Africa. We propose EntSwap, a method for test-time perturbations, to create a test set whose entities have been renamed. In particular, we rename entities of type: country, person, nationality, location, organization, and city, to create AfriSQuAD2. Using the perturbed test set, we evaluate the robustness of three popular MRC models. We find that compared to base models, large models perform well comparatively on novel entities. Furthermore, our analysis indicates that entity type person highly challenges the MRC models' performance.","sentences":["Question answering (QA) models have shown compelling results in the task of Machine Reading Comprehension (MRC).","Recently these systems have proved to perform better than humans on held-out test sets of datasets e.g. SQuAD, but their robustness is not guaranteed.","The QA model's brittleness is exposed when evaluated on adversarial generated examples by a performance drop.","In this study, we explore the robustness of MRC models to entity renaming, with entities from low-resource regions such as Africa.","We propose EntSwap, a method for test-time perturbations, to create a test set whose entities have been renamed.","In particular, we rename entities of type: country, person, nationality, location, organization, and city, to create AfriSQuAD2.","Using the perturbed test set, we evaluate the robustness of three popular MRC models.","We find that compared to base models, large models perform well comparatively on novel entities.","Furthermore, our analysis indicates that entity type person highly challenges the MRC models' performance."],"url":"http://arxiv.org/abs/2304.03145v1"}
{"created":"2023-04-06","title":"BotTriNet: A Unified and Efficient Embedding for Social Bots Detection via Metric Learning","abstract":"A persistently popular topic in online social networks is the rapid and accurate discovery of bot accounts to prevent their invasion and harassment of genuine users. We propose a unified embedding framework called BOTTRINET, which utilizes textual content posted by accounts for bot detection based on the assumption that contexts naturally reveal account personalities and habits. Content is abundant and valuable if the system efficiently extracts bot-related information using embedding techniques. Beyond the general embedding framework that generates word, sentence, and account embeddings, we design a triplet network to tune the raw embeddings (produced by traditional natural language processing techniques) for better classification performance. We evaluate detection accuracy and f1score on a real-world dataset CRESCI2017, comprising three bot account categories and five bot sample sets. Our system achieves the highest average accuracy of 98.34% and f1score of 97.99% on two content-intensive bot sets, outperforming previous work and becoming state-of-the-art. It also makes a breakthrough on four content-less bot sets, with an average accuracy improvement of 11.52% and an average f1score increase of 16.70%.","sentences":["A persistently popular topic in online social networks is the rapid and accurate discovery of bot accounts to prevent their invasion and harassment of genuine users.","We propose a unified embedding framework called BOTTRINET, which utilizes textual content posted by accounts for bot detection based on the assumption that contexts naturally reveal account personalities and habits.","Content is abundant and valuable if the system efficiently extracts bot-related information using embedding techniques.","Beyond the general embedding framework that generates word, sentence, and account embeddings, we design a triplet network to tune the raw embeddings (produced by traditional natural language processing techniques) for better classification performance.","We evaluate detection accuracy and f1score on a real-world dataset CRESCI2017, comprising three bot account categories and five bot sample sets.","Our system achieves the highest average accuracy of 98.34% and f1score of 97.99% on two content-intensive bot sets, outperforming previous work and becoming state-of-the-art.","It also makes a breakthrough on four content-less bot sets, with an average accuracy improvement of 11.52% and an average f1score increase of 16.70%."],"url":"http://arxiv.org/abs/2304.03144v1"}
{"created":"2023-04-06","title":"From Saliency to DINO: Saliency-guided Vision Transformer for Few-shot Keypoint Detection","abstract":"Unlike current deep keypoint detectors that are trained to recognize limited number of body parts, few-shot keypoint detection (FSKD) attempts to localize any keypoints, including novel or base keypoints, depending on the reference samples. FSKD requires the semantically meaningful relations for keypoint similarity learning to overcome the ubiquitous noise and ambiguous local patterns. One rescue comes with vision transformer (ViT) as it captures long-range relations well. However, ViT may model irrelevant features outside of the region of interest due to the global attention matrix, thus degrading similarity learning between support and query features. In this paper, we present a novel saliency-guided vision transformer, dubbed SalViT, for few-shot keypoint detection. Our SalViT enjoys a uniquely designed masked self-attention and a morphology learner, where the former introduces saliency map as a soft mask to constrain the self-attention on foregrounds, while the latter leverages the so-called power normalization to adjust morphology of saliency map, realizing ``dynamically changing receptive field''. Moreover, as salinecy detectors add computations, we show that attentive masks of DINO transformer can replace saliency. On top of SalViT, we also investigate i) transductive FSKD that enhances keypoint representations with unlabelled data and ii) FSKD under occlusions. We show that our model performs well on five public datasets and achieves ~10% PCK higher than the normally trained model under severe occlusions.","sentences":["Unlike current deep keypoint detectors that are trained to recognize limited number of body parts, few-shot keypoint detection (FSKD) attempts to localize any keypoints, including novel or base keypoints, depending on the reference samples.","FSKD requires the semantically meaningful relations for keypoint similarity learning to overcome the ubiquitous noise and ambiguous local patterns.","One rescue comes with vision transformer (ViT) as it captures long-range relations well.","However, ViT may model irrelevant features outside of the region of interest due to the global attention matrix, thus degrading similarity learning between support and query features.","In this paper, we present a novel saliency-guided vision transformer, dubbed SalViT, for few-shot keypoint detection.","Our SalViT enjoys a uniquely designed masked self-attention and a morphology learner, where the former introduces saliency map as a soft mask to constrain the self-attention on foregrounds, while the latter leverages the so-called power normalization to adjust morphology of saliency map, realizing ``dynamically changing receptive field''.","Moreover, as salinecy detectors add computations, we show that attentive masks of DINO transformer can replace saliency.","On top of SalViT, we also investigate i) transductive FSKD that enhances keypoint representations with unlabelled data and ii) FSKD under occlusions.","We show that our model performs well on five public datasets and achieves ~10% PCK higher than the normally trained model under severe occlusions."],"url":"http://arxiv.org/abs/2304.03140v1"}
{"created":"2023-04-06","title":"Simplifying Content-Based Neural News Recommendation: On User Modeling and Training Objectives","abstract":"The advent of personalized news recommendation has given rise to increasingly complex recommender architectures. Most neural news recommenders rely on user click behavior and typically introduce dedicated user encoders that aggregate the content of clicked news into user embeddings (early fusion). These models are predominantly trained with standard point-wise classification objectives. The existing body of work exhibits two main shortcomings: (1) despite general design homogeneity, direct comparisons between models are hindered by varying evaluation datasets and protocols; (2) it leaves alternative model designs and training objectives vastly unexplored. In this work, we present a unified framework for news recommendation, allowing for a systematic and fair comparison of news recommenders across several crucial design dimensions: (i) candidate-awareness in user modeling, (ii) click behavior fusion, and (iii) training objectives. Our findings challenge the status quo in neural news recommendation. We show that replacing sizable user encoders with parameter-efficient dot products between candidate and clicked news embeddings (late fusion) often yields substantial performance gains. Moreover, our results render contrastive training a viable alternative to point-wise classification objectives.","sentences":["The advent of personalized news recommendation has given rise to increasingly complex recommender architectures.","Most neural news recommenders rely on user click behavior and typically introduce dedicated user encoders that aggregate the content of clicked news into user embeddings (early fusion).","These models are predominantly trained with standard point-wise classification objectives.","The existing body of work exhibits two main shortcomings: (1) despite general design homogeneity, direct comparisons between models are hindered by varying evaluation datasets and protocols; (2) it leaves alternative model designs and training objectives vastly unexplored.","In this work, we present a unified framework for news recommendation, allowing for a systematic and fair comparison of news recommenders across several crucial design dimensions: (i) candidate-awareness in user modeling, (ii) click behavior fusion, and (iii) training objectives.","Our findings challenge the status quo in neural news recommendation.","We show that replacing sizable user encoders with parameter-efficient dot products between candidate and clicked news embeddings (late fusion) often yields substantial performance gains.","Moreover, our results render contrastive training a viable alternative to point-wise classification objectives."],"url":"http://arxiv.org/abs/2304.03112v1"}
{"created":"2023-04-06","title":"Unraveling the Crystallization Kinetics of the Ge$_2$Sb$_2$Te$_5$ Phase Change Compound with a Machine-Learned Interatomic Potential","abstract":"The phase change compound Ge$_2$Sb$_2$Te$_5$ (GST225) is exploited in advanced non-volatile electronic memories and in neuromorphic devices which both rely on a fast and reversible transition between the crystalline and amorphous phases induced by Joule heating. The crystallization kinetics of GST225 is a key functional feature for the operation of these devices. We report here on the development of a machine-learned interatomic potential for GST225 that allowed us to perform large scale molecular dynamics simulations (over 10000 atoms for over 100 ns) to uncover the details of the crystallization kinetics in a wide range of temperatures of interest for the programming of the devices. The potential is obtained by fitting with a deep neural network (NN) scheme a large quantum-mechanical database generated within Density Functional Theory. The availability of a highly efficient and yet highly accurate NN potential opens the possibility to simulate phase change materials at the length and time scales of the real devices.","sentences":["The phase change compound Ge$_2$Sb$_2$Te$_5$ (GST225) is exploited in advanced non-volatile electronic memories and in neuromorphic devices which both rely on a fast and reversible transition between the crystalline and amorphous phases induced by Joule heating.","The crystallization kinetics of GST225 is a key functional feature for the operation of these devices.","We report here on the development of a machine-learned interatomic potential for GST225 that allowed us to perform large scale molecular dynamics simulations (over 10000 atoms for over 100 ns) to uncover the details of the crystallization kinetics in a wide range of temperatures of interest for the programming of the devices.","The potential is obtained by fitting with a deep neural network (NN) scheme a large quantum-mechanical database generated within Density Functional Theory.","The availability of a highly efficient and yet highly accurate NN potential opens the possibility to simulate phase change materials at the length and time scales of the real devices."],"url":"http://arxiv.org/abs/2304.03109v1"}
{"created":"2023-04-06","title":"Multi-task learning for tissue segmentation and tumor detection in colorectal cancer histology slides","abstract":"Automating tissue segmentation and tumor detection in histopathology images of colorectal cancer (CRC) is an enabler for faster diagnostic pathology workflows. At the same time it is a challenging task due to low availability of public annotated datasets and high variability of image appearance. The semi-supervised learning for CRC detection (SemiCOL) challenge 2023 provides partially annotated data to encourage the development of automated solutions for tissue segmentation and tumor detection. We propose a U-Net based multi-task model combined with channel-wise and image-statistics-based color augmentations, as well as test-time augmentation, as a candidate solution to the SemiCOL challenge. Our approach achieved a multi-task Dice score of .8655 (Arm 1) and .8515 (Arm 2) for tissue segmentation and AUROC of .9725 (Arm 1) and 0.9750 (Arm 2) for tumor detection on the challenge validation set. The source code for our approach is made publicly available at https://github.com/lely475/CTPLab_SemiCOL2023.","sentences":["Automating tissue segmentation and tumor detection in histopathology images of colorectal cancer (CRC) is an enabler for faster diagnostic pathology workflows.","At the same time it is a challenging task due to low availability of public annotated datasets and high variability of image appearance.","The semi-supervised learning for CRC detection (SemiCOL) challenge 2023 provides partially annotated data to encourage the development of automated solutions for tissue segmentation and tumor detection.","We propose a U-Net based multi-task model combined with channel-wise and image-statistics-based color augmentations, as well as test-time augmentation, as a candidate solution to the SemiCOL challenge.","Our approach achieved a multi-task Dice score of .8655 (Arm 1) and .8515 (Arm 2) for tissue segmentation and AUROC of .9725 (Arm 1) and 0.9750 (Arm 2) for tumor detection on the challenge validation set.","The source code for our approach is made publicly available at https://github.com/lely475/CTPLab_SemiCOL2023."],"url":"http://arxiv.org/abs/2304.03101v1"}
{"created":"2023-04-06","title":"Spectral Gap Regularization of Neural Networks","abstract":"We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information. Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical motivation for this approach via spectral graph theory. We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool. We provide an approximate, variational approach for faster computation during training. We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction. We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis. We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay. Results demonstrate the efficacy of Fiedler regularization. This is a journal extension of the conference paper by Tam and Dunson (2020).","sentences":["We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information.","Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network.","We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization.","We provide theoretical motivation for this approach via spectral graph theory.","We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool.","We provide an approximate, variational approach for faster computation during training.","We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction.","We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis.","We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay.","Results demonstrate the efficacy of Fiedler regularization.","This is a journal extension of the conference paper by Tam and Dunson (2020)."],"url":"http://arxiv.org/abs/2304.03096v1"}
{"created":"2023-04-06","title":"An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset","abstract":"Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification. The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems. The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger. Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN. The results show a noticeable improvement in generalization on the 3RL dataset. Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%).","sentences":["Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification.","The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger.","Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN.","The results show a noticeable improvement in generalization on the 3RL dataset.","Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%)."],"url":"http://arxiv.org/abs/2304.03064v1"}
{"created":"2023-04-06","title":"Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures","abstract":"Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data. Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients. However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness. To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge. Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products. We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets. The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks. In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs. Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks. The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs.","sentences":["Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data.","Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients.","However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness.","To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge.","Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products.","We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets.","The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks.","In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs.","Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks.","The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs."],"url":"http://arxiv.org/abs/2304.03054v1"}
{"created":"2023-04-06","title":"ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments","abstract":"Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ETPNav utilizes a transformer-based cross-modal planner to generate navigation plans based on topological maps and instructions. The plan is then performed through an obstacle-avoiding controller that leverages a trial-and-error heuristic to prevent navigation from getting stuck in obstacles. Experimental results demonstrate the effectiveness of the proposed method. ETPNav yields more than 10% and 20% improvements over prior state-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code is available at https://github.com/MarSaKi/ETPNav.","sentences":["Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments.","It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction.","In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE).","To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments.","ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience.","It privileges the agent to break down the navigation procedure into high-level planning and low-level control.","Concurrently, ETPNav utilizes a transformer-based cross-modal planner to generate navigation plans based on topological maps and instructions.","The plan is then performed through an obstacle-avoiding controller that leverages a trial-and-error heuristic to prevent navigation from getting stuck in obstacles.","Experimental results demonstrate the effectiveness of the proposed method.","ETPNav yields more than 10% and 20% improvements over prior state-of-the-art on R2R-CE and RxR-CE datasets, respectively.","Our code is available at https://github.com/MarSaKi/ETPNav."],"url":"http://arxiv.org/abs/2304.03047v1"}
{"created":"2023-04-06","title":"Data Processing with FPGAs on Modern Architectures","abstract":"Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale. These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression). In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks. We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers. The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs. The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints.","sentences":["Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale.","These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression).","In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   ","In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks.","We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers.","The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs.","The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints."],"url":"http://arxiv.org/abs/2304.03044v1"}
{"created":"2023-04-06","title":"Revisiting Dense Retrieval with Unanswerable Counterfactuals","abstract":"The retriever-reader framework is popular for open-domain question answering (ODQA), where a retriever samples for the reader a set of relevant candidate passages from a large corpus. A key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question. In this work, we empirically dispel this belief and observe that recent dense retrieval models based on DPR often rank unanswerable counterfactual passages higher than their answerable original passages. To address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of DPR with the answerability of question-passage pairs. Specifically, we present counterfactually-Pivoting Contrastive Learning (PiCL), a novel representation learning approach for passage retrieval that leverages counterfactual samples as pivots between positive and negative samples in their learned embedding space. We incorporate PiCL into the retriever training to show the effectiveness of PiCL on ODQA benchmarks and the robustness of the learned models.","sentences":["The retriever-reader framework is popular for open-domain question answering (ODQA), where a retriever samples for the reader a set of relevant candidate passages from a large corpus.","A key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question.","In this work, we empirically dispel this belief and observe that recent dense retrieval models based on DPR often rank unanswerable counterfactual passages higher than their answerable original passages.","To address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of DPR with the answerability of question-passage pairs.","Specifically, we present counterfactually-Pivoting Contrastive Learning (PiCL), a novel representation learning approach for passage retrieval that leverages counterfactual samples as pivots between positive and negative samples in their learned embedding space.","We incorporate PiCL into the retriever training to show the effectiveness of PiCL on ODQA benchmarks and the robustness of the learned models."],"url":"http://arxiv.org/abs/2304.03031v1"}
{"created":"2023-04-06","title":"TagGPT: Large Language Models are Zero-shot Multimodal Taggers","abstract":"Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.","sentences":["Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems.","Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks.","In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion.","Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc.","Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics.","Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts.","It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want.","TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications.","We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers.","Project page: https://github.com/TencentARC/TagGPT."],"url":"http://arxiv.org/abs/2304.03022v1"}
{"created":"2023-04-06","title":"Optimal subsampling designs","abstract":"Subsampling is commonly used to overcome computational and economical bottlenecks in the analysis of finite populations and massive datasets. Existing methods are often limited in scope and use optimality criteria (e.g., A-optimality) with well-known deficiencies, such as lack of invariance to the measurement-scale of the data and parameterisation of the model. A unified theory of optimal subsampling design is still lacking. We present a theory of optimal design for general data subsampling problems, including finite population inference, parametric density estimation, and regression modelling. Our theory encompasses and generalises most existing methods in the field of optimal subdata selection based on unequal probability sampling and inverse probability weighting. We derive optimality conditions for a general class of optimality criteria, and present corresponding algorithms for finding optimal sampling schemes under Poisson and multinomial sampling designs. We present a novel class of transformation- and parameterisation-invariant linear optimality criteria which enjoy the best of two worlds: the computational tractability of A-optimality and invariance properties similar to D-optimality. The methodology is illustrated on an application in the traffic safety domain. In our experiments, the proposed invariant linear optimality criteria achieve 92-99% D-efficiency with 90-95% lower computational demand. In contrast, the A-optimality criterion has only 46% and 60% D-efficiency on two of the examples.","sentences":["Subsampling is commonly used to overcome computational and economical bottlenecks in the analysis of finite populations and massive datasets.","Existing methods are often limited in scope and use optimality criteria (e.g., A-optimality) with well-known deficiencies, such as lack of invariance to the measurement-scale of the data and parameterisation of the model.","A unified theory of optimal subsampling design is still lacking.","We present a theory of optimal design for general data subsampling problems, including finite population inference, parametric density estimation, and regression modelling.","Our theory encompasses and generalises most existing methods in the field of optimal subdata selection based on unequal probability sampling and inverse probability weighting.","We derive optimality conditions for a general class of optimality criteria, and present corresponding algorithms for finding optimal sampling schemes under Poisson and multinomial sampling designs.","We present a novel class of transformation- and parameterisation-invariant linear optimality criteria which enjoy the best of two worlds: the computational tractability of A-optimality and invariance properties similar to D-optimality.","The methodology is illustrated on an application in the traffic safety domain.","In our experiments, the proposed invariant linear optimality criteria achieve 92-99% D-efficiency with 90-95% lower computational demand.","In contrast, the A-optimality criterion has only 46% and 60% D-efficiency on two of the examples."],"url":"http://arxiv.org/abs/2304.03019v1"}
{"created":"2023-04-06","title":"IoT Federated Blockchain Learning at the Edge","abstract":"IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits. IoT devices are low-cost, energy-efficient, small and intelligent devices. In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge. The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy. Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained. 2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists. 3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models.","sentences":["IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits.","IoT devices are low-cost, energy-efficient, small and intelligent devices.","In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge.","The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy.","Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained.","2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists.","3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models."],"url":"http://arxiv.org/abs/2304.03006v1"}
{"created":"2023-04-06","title":"Natural Language Robot Programming: NLP integrated with autonomous robotic grasping","abstract":"In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks. Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database. We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone. Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot. Our results indicate that our approach has a high system usability score. The framework's dictionary can be easily extended without relying on transfer learning or large data sets. In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study.","sentences":["In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks.","Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database.","We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone.","Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot.","Our results indicate that our approach has a high system usability score.","The framework's dictionary can be easily extended without relying on transfer learning or large data sets.","In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study."],"url":"http://arxiv.org/abs/2304.02993v1"}
{"created":"2023-04-06","title":"Spritz-PS: Validation of Synthetic Face Images Using a Large Dataset of Printed Documents","abstract":"The capability of doing effective forensic analysis on printed and scanned (PS) images is essential in many applications. PS documents may be used to conceal the artifacts of images which is due to the synthetic nature of images since these artifacts are typically present in manipulated images and the main artifacts in the synthetic images can be removed after the PS. Due to the appeal of Generative Adversarial Networks (GANs), synthetic face images generated with GANs models are difficult to differentiate from genuine human faces and may be used to create counterfeit identities. Additionally, since GANs models do not account for physiological constraints for generating human faces and their impact on human IRISes, distinguishing genuine from synthetic IRISes in the PS scenario becomes extremely difficult. As a result of the lack of large-scale reference IRIS datasets in the PS scenario, we aim at developing a novel dataset to become a standard for Multimedia Forensics (MFs) investigation which is available at [45]. In this paper, we provide a novel dataset made up of a large number of synthetic and natural printed IRISes taken from VIPPrint Printed and Scanned face images. We extracted irises from face images and it is possible that the model due to eyelid occlusion captured the incomplete irises. To fill the missing pixels of extracted iris, we applied techniques to discover the complex link between the iris images. To highlight the problems involved with the evaluation of the dataset's IRIS images, we conducted a large number of analyses employing Siamese Neural Networks to assess the similarities between genuine and synthetic human IRISes, such as ResNet50, Xception, VGG16, and MobileNet-v2. For instance, using the Xception network, we achieved 56.76\\% similarity of IRISes for synthetic images and 92.77% similarity of IRISes for real images.","sentences":["The capability of doing effective forensic analysis on printed and scanned (PS) images is essential in many applications.","PS documents may be used to conceal the artifacts of images which is due to the synthetic nature of images since these artifacts are typically present in manipulated images and the main artifacts in the synthetic images can be removed after the PS.","Due to the appeal of Generative Adversarial Networks (GANs), synthetic face images generated with GANs models are difficult to differentiate from genuine human faces and may be used to create counterfeit identities.","Additionally, since GANs models do not account for physiological constraints for generating human faces and their impact on human IRISes, distinguishing genuine from synthetic IRISes in the PS scenario becomes extremely difficult.","As a result of the lack of large-scale reference IRIS datasets in the PS scenario, we aim at developing a novel dataset to become a standard for Multimedia Forensics (MFs) investigation which is available at [45].","In this paper, we provide a novel dataset made up of a large number of synthetic and natural printed IRISes taken from VIPPrint Printed and Scanned face images.","We extracted irises from face images and it is possible that the model due to eyelid occlusion captured the incomplete irises.","To fill the missing pixels of extracted iris, we applied techniques to discover the complex link between the iris images.","To highlight the problems involved with the evaluation of the dataset's IRIS images, we conducted a large number of analyses employing Siamese Neural Networks to assess the similarities between genuine and synthetic human IRISes, such as ResNet50, Xception, VGG16, and MobileNet-v2.","For instance, using the Xception network, we achieved 56.76\\% similarity of IRISes for synthetic images and 92.77% similarity of IRISes for real images."],"url":"http://arxiv.org/abs/2304.02982v1"}
{"created":"2023-04-06","title":"Smart Contract and DeFi Security: Insights from Tool Evaluations and Practitioner Surveys","abstract":"The growth of the decentralized finance (DeFi) ecosystem built on blockchain technology and smart contracts has led to an increased demand for secure and reliable smart contract development. However, attacks targeting smart contracts are increasing, causing an estimated \\$6.45 billion in financial losses. Researchers have proposed various automated security tools to detect vulnerabilities, but their real-world impact remains uncertain.   In this paper, we aim to shed light on the effectiveness of automated security tools in identifying vulnerabilities that can lead to high-profile attacks, and their overall usage within the industry. Our comprehensive study encompasses an evaluation of five SoTA automated security tools, an analysis of 127 high-impact real-world attacks resulting in \\$2.3 billion in losses, and a survey of 49 developers and auditors working in leading DeFi protocols. Our findings reveal a stark reality: the tools could have prevented a mere 8% of the attacks in our dataset, amounting to \\$149 million out of the \\$2.3 billion in losses. Notably, all preventable attacks were related to reentrancy vulnerabilities. Furthermore, practitioners distinguish logic-related bugs and protocol layer vulnerabilities as significant threats that are not adequately addressed by existing security tools. Our results emphasize the need to develop specialized tools catering to the distinct demands and expectations of developers and auditors. Further, our study highlights the necessity for continuous advancements in security tools to effectively tackle the ever-evolving challenges confronting the DeFi ecosystem.","sentences":["The growth of the decentralized finance (DeFi) ecosystem built on blockchain technology and smart contracts has led to an increased demand for secure and reliable smart contract development.","However, attacks targeting smart contracts are increasing, causing an estimated \\$6.45 billion in financial losses.","Researchers have proposed various automated security tools to detect vulnerabilities, but their real-world impact remains uncertain.   ","In this paper, we aim to shed light on the effectiveness of automated security tools in identifying vulnerabilities that can lead to high-profile attacks, and their overall usage within the industry.","Our comprehensive study encompasses an evaluation of five SoTA automated security tools, an analysis of 127 high-impact real-world attacks resulting in \\$2.3 billion in losses, and a survey of 49 developers and auditors working in leading DeFi protocols.","Our findings reveal a stark reality: the tools could have prevented a mere 8% of the attacks in our dataset, amounting to \\$149 million out of the \\$2.3 billion in losses.","Notably, all preventable attacks were related to reentrancy vulnerabilities.","Furthermore, practitioners distinguish logic-related bugs and protocol layer vulnerabilities as significant threats that are not adequately addressed by existing security tools.","Our results emphasize the need to develop specialized tools catering to the distinct demands and expectations of developers and auditors.","Further, our study highlights the necessity for continuous advancements in security tools to effectively tackle the ever-evolving challenges confronting the DeFi ecosystem."],"url":"http://arxiv.org/abs/2304.02981v1"}
{"created":"2023-04-06","title":"On the Limits of Cross-Authentication Checks for GNSS Signals","abstract":"Global navigation satellite systems (GNSSs) are implementing security mechanisms: examples are Galileo open service navigation message authentication (OS-NMA) and GPS chips-message robust authentication (CHIMERA). Each of these mechanisms operates in a single band. However, nowadays, even commercial GNSS receivers typically compute the position, velocity, and time (PVT) solution using multiple constellations and signals from multiple bands at once, significantly improving both accuracy and availability. Hence, cross-authentication checks have been proposed, based on the PVT obtained from the mixture of authenticated and non-authenticated signals.   In this paper, first, we formalize the models for the cross-authentication checks. Next, we describe, for each check, a spoofing attack to generate a fake signal leading the victim to a target PVT without notice. We analytically relate the degrees of the freedom of the attacker in manipulating the victim's solution to both the employed security checks and the number of open signals that can be tampered with by the attacker. We test the performance of the considered attack strategies on an experimental dataset. Lastly, we show the limits of the PVT-based GNSS cross-authentication checks, where both authenticated and non-authenticated signals are used.","sentences":["Global navigation satellite systems (GNSSs) are implementing security mechanisms: examples are Galileo open service navigation message authentication (OS-NMA) and GPS chips-message robust authentication (CHIMERA).","Each of these mechanisms operates in a single band.","However, nowadays, even commercial GNSS receivers typically compute the position, velocity, and time (PVT) solution using multiple constellations and signals from multiple bands at once, significantly improving both accuracy and availability.","Hence, cross-authentication checks have been proposed, based on the PVT obtained from the mixture of authenticated and non-authenticated signals.   ","In this paper, first, we formalize the models for the cross-authentication checks.","Next, we describe, for each check, a spoofing attack to generate a fake signal leading the victim to a target PVT without notice.","We analytically relate the degrees of the freedom of the attacker in manipulating the victim's solution to both the employed security checks and the number of open signals that can be tampered with by the attacker.","We test the performance of the considered attack strategies on an experimental dataset.","Lastly, we show the limits of the PVT-based GNSS cross-authentication checks, where both authenticated and non-authenticated signals are used."],"url":"http://arxiv.org/abs/2304.02977v1"}
{"created":"2023-04-06","title":"Training a Two Layer ReLU Network Analytically","abstract":"Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer. Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima. However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed. Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated. Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters.","sentences":["Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer.","Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima.","However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed.","Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated.","Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters."],"url":"http://arxiv.org/abs/2304.02972v1"}
{"created":"2023-04-06","title":"Synthetic Hard Negative Samples for Contrastive Learning","abstract":"Contrastive learning has emerged as an essential approach for self-supervised learning in computer vision. The central objective of contrastive learning is to maximize the similarities between two augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs). Recent studies have demonstrated that harder negative samples, i.e., those that are difficult to distinguish from anchor sample, play a more critical role in contrastive learning. In this paper, we propose a novel featurelevel method, namely sampling synthetic hard negative samples for contrastive learning (SSCL), to exploit harder negative samples more effectively. Specifically, 1) we generate more and harder negative samples by mixing negative samples, and then sample them by controlling the contrast of anchor sample with the other negative samples. 2) Considering that the negative samples obtained by sampling may have the problem of false negative samples, we further debias the negative samples. Our proposed method improves the classification performance on different image datasets and can be readily applied to existing methods.","sentences":["Contrastive learning has emerged as an essential approach for self-supervised learning in computer vision.","The central objective of contrastive learning is to maximize the similarities between two augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs).","Recent studies have demonstrated that harder negative samples, i.e., those that are difficult to distinguish from anchor sample, play a more critical role in contrastive learning.","In this paper, we propose a novel featurelevel method, namely sampling synthetic hard negative samples for contrastive learning (SSCL), to exploit harder negative samples more effectively.","Specifically, 1) we generate more and harder negative samples by mixing negative samples, and then sample them by controlling the contrast of anchor sample with the other negative samples.","2) Considering that the negative samples obtained by sampling may have the problem of false negative samples, we further debias the negative samples.","Our proposed method improves the classification performance on different image datasets and can be readily applied to existing methods."],"url":"http://arxiv.org/abs/2304.02971v1"}
{"created":"2023-04-06","title":"A Closer Look at Audio-Visual Semantic Segmentation","abstract":"Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries. Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object. However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set. In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks. Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks. We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+. Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set. We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy. Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models. Code and dataset will be available.","sentences":["Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries.","Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object.","However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set.","In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks.","Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks.","We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+.","Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set.","We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy.","Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models.","Code and dataset will be available."],"url":"http://arxiv.org/abs/2304.02970v1"}
{"created":"2023-04-06","title":"HGCC: Enhancing Hyperbolic Graph Convolution Networks on Heterogeneous Collaborative Graph for Recommendation","abstract":"Due to the naturally power-law distributed nature of user-item interaction data in recommendation tasks, hyperbolic space modeling has recently been introduced into collaborative filtering methods. Among them, hyperbolic GCN combines the advantages of GCN and hyperbolic space and achieves a surprising performance. However, these methods only partially exploit the nature of hyperbolic space in their designs due to completely random embedding initialization and an inaccurate tangent space aggregation. In addition, the data used in these works mainly focus on user-item interaction data only, which further limits the performance of the models. In this paper, we propose a hyperbolic GCN collaborative filtering model, HGCC, which improves the existing hyperbolic GCN structure for collaborative filtering and incorporates side information. It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically. Experimental results on four real datasets show that our model is highly competitive and outperforms leading baselines, including hyperbolic GCNs. Further experiments validate the efficacy of our proposed approach and give a further explanation by the learned embedding.","sentences":["Due to the naturally power-law distributed nature of user-item interaction data in recommendation tasks, hyperbolic space modeling has recently been introduced into collaborative filtering methods.","Among them, hyperbolic GCN combines the advantages of GCN and hyperbolic space and achieves a surprising performance.","However, these methods only partially exploit the nature of hyperbolic space in their designs due to completely random embedding initialization and an inaccurate tangent space aggregation.","In addition, the data used in these works mainly focus on user-item interaction data only, which further limits the performance of the models.","In this paper, we propose a hyperbolic GCN collaborative filtering model, HGCC, which improves the existing hyperbolic GCN structure for collaborative filtering and incorporates side information.","It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically.","Experimental results on four real datasets show that our model is highly competitive and outperforms leading baselines, including hyperbolic GCNs.","Further experiments validate the efficacy of our proposed approach and give a further explanation by the learned embedding."],"url":"http://arxiv.org/abs/2304.02961v1"}
{"created":"2023-04-06","title":"InterFormer: Real-time Interactive Image Segmentation","abstract":"Interactive image segmentation enables annotators to efficiently perform pixel-level annotation for segmentation tasks. However, the existing interactive segmentation pipeline suffers from inefficient computations of interactive models because of the following two issues. First, annotators' later click is based on models' feedback of annotators' former click. This serial interaction is unable to utilize model's parallelism capabilities. Second, the model has to repeatedly process the image, the annotator's current click, and the model's feedback of the annotator's former clicks at each step of interaction, resulting in redundant computations. For efficient computation, we propose a method named InterFormer that follows a new pipeline to address these issues. InterFormer extracts and preprocesses the computationally time-consuming part i.e. image processing from the existing process. Specifically, InterFormer employs a large vision transformer (ViT) on high-performance devices to preprocess images in parallel, and then uses a lightweight module called interactive multi-head self attention (I-MSA) for interactive segmentation. Furthermore, the I-MSA module's deployment on low-power devices extends the practical application of interactive segmentation. The I-MSA module utilizes the preprocessed features to efficiently response to the annotator inputs in real-time. The experiments on several datasets demonstrate the effectiveness of InterFormer, which outperforms previous interactive segmentation models in terms of computational efficiency and segmentation quality, achieve real-time high-quality interactive segmentation on CPU-only devices.","sentences":["Interactive image segmentation enables annotators to efficiently perform pixel-level annotation for segmentation tasks.","However, the existing interactive segmentation pipeline suffers from inefficient computations of interactive models because of the following two issues.","First, annotators' later click is based on models' feedback of annotators' former click.","This serial interaction is unable to utilize model's parallelism capabilities.","Second, the model has to repeatedly process the image, the annotator's current click, and the model's feedback of the annotator's former clicks at each step of interaction, resulting in redundant computations.","For efficient computation, we propose a method named InterFormer that follows a new pipeline to address these issues.","InterFormer extracts and preprocesses the computationally time-consuming part i.e. image processing from the existing process.","Specifically, InterFormer employs a large vision transformer (ViT) on high-performance devices to preprocess images in parallel, and then uses a lightweight module called interactive multi-head self attention (I-MSA) for interactive segmentation.","Furthermore, the I-MSA module's deployment on low-power devices extends the practical application of interactive segmentation.","The I-MSA module utilizes the preprocessed features to efficiently response to the annotator inputs in real-time.","The experiments on several datasets demonstrate the effectiveness of InterFormer, which outperforms previous interactive segmentation models in terms of computational efficiency and segmentation quality, achieve real-time high-quality interactive segmentation on CPU-only devices."],"url":"http://arxiv.org/abs/2304.02942v1"}
{"created":"2023-04-06","title":"All Keypoints You Need: Detecting Arbitrary Keypoints on the Body of Triple, High, and Long Jump Athletes","abstract":"Performance analyses based on videos are commonly used by coaches of athletes in various sports disciplines. In individual sports, these analyses mainly comprise the body posture. This paper focuses on the disciplines of triple, high, and long jump, which require fine-grained locations of the athlete's body. Typical human pose estimation datasets provide only a very limited set of keypoints, which is not sufficient in this case. Therefore, we propose a method to detect arbitrary keypoints on the whole body of the athlete by leveraging the limited set of annotated keypoints and auto-generated segmentation masks of body parts. Evaluations show that our model is capable of detecting keypoints on the head, torso, hands, feet, arms, and legs, including also bent elbows and knees. We analyze and compare different techniques to encode desired keypoints as the model's input and their embedding for the Transformer backbone.","sentences":["Performance analyses based on videos are commonly used by coaches of athletes in various sports disciplines.","In individual sports, these analyses mainly comprise the body posture.","This paper focuses on the disciplines of triple, high, and long jump, which require fine-grained locations of the athlete's body.","Typical human pose estimation datasets provide only a very limited set of keypoints, which is not sufficient in this case.","Therefore, we propose a method to detect arbitrary keypoints on the whole body of the athlete by leveraging the limited set of annotated keypoints and auto-generated segmentation masks of body parts.","Evaluations show that our model is capable of detecting keypoints on the head, torso, hands, feet, arms, and legs, including also bent elbows and knees.","We analyze and compare different techniques to encode desired keypoints as the model's input and their embedding for the Transformer backbone."],"url":"http://arxiv.org/abs/2304.02939v1"}
{"created":"2023-04-06","title":"Boundary-Denoising for Video Activity Localization","abstract":"Video activity localization aims at understanding the semantic content in long untrimmed videos and retrieving actions of interest. The retrieved action with its start and end locations can be used for highlight generation, temporal action detection, etc. Unfortunately, learning the exact boundary location of activities is highly challenging because temporal activities are continuous in time, and there are often no clear-cut transitions between actions. Moreover, the definition of the start and end of events is subjective, which may confuse the model. To alleviate the boundary ambiguity, we propose to study the video activity localization problem from a denoising perspective. Specifically, we propose an encoder-decoder model named DenoiseLoc. During training, a set of action spans is randomly generated from the ground truth with a controlled noise scale. Then we attempt to reverse this process by boundary denoising, allowing the localizer to predict activities with precise boundaries and resulting in faster convergence speed. Experiments show that DenoiseLoc advances %in several video activity understanding tasks. For example, we observe a gain of +12.36% average mAP on QV-Highlights dataset and +1.64% mAP@0.5 on THUMOS'14 dataset over the baseline. Moreover, DenoiseLoc achieves state-of-the-art performance on TACoS and MAD datasets, but with much fewer predictions compared to other current methods.","sentences":["Video activity localization aims at understanding the semantic content in long untrimmed videos and retrieving actions of interest.","The retrieved action with its start and end locations can be used for highlight generation, temporal action detection, etc.","Unfortunately, learning the exact boundary location of activities is highly challenging because temporal activities are continuous in time, and there are often no clear-cut transitions between actions.","Moreover, the definition of the start and end of events is subjective, which may confuse the model.","To alleviate the boundary ambiguity, we propose to study the video activity localization problem from a denoising perspective.","Specifically, we propose an encoder-decoder model named DenoiseLoc.","During training, a set of action spans is randomly generated from the ground truth with a controlled noise scale.","Then we attempt to reverse this process by boundary denoising, allowing the localizer to predict activities with precise boundaries and resulting in faster convergence speed.","Experiments show that DenoiseLoc advances %in several video activity understanding tasks.","For example, we observe a gain of +12.36% average mAP on QV-Highlights dataset and +1.64% mAP@0.5 on THUMOS'14 dataset over the baseline.","Moreover, DenoiseLoc achieves state-of-the-art performance on TACoS and MAD datasets, but with much fewer predictions compared to other current methods."],"url":"http://arxiv.org/abs/2304.02934v1"}
{"created":"2023-04-06","title":"Convolutional neural networks for crack detection on flexible road pavements","abstract":"Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions. Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards. In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying. However, surveying is still a tedious manual process. Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error. This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection. The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples. The effects of dataset augmentation are also investigated. Of the six models trained, five achieved accuracy above 97%. The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models. The dataset is available at the following URL: https://zenodo.org/record/7795975","sentences":["Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions.","Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards.","In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying.","However, surveying is still a tedious manual process.","Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error.","This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection.","The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples.","The effects of dataset augmentation are also investigated.","Of the six models trained, five achieved accuracy above 97%.","The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models.","The dataset is available at the following URL: https://zenodo.org/record/7795975"],"url":"http://arxiv.org/abs/2304.02933v1"}
{"created":"2023-04-06","title":"Mask Detection and Classification in Thermal Face Images","abstract":"Face masks are recommended to reduce the transmission of many viruses, especially SARS-CoV-2. Therefore, the automatic detection of whether there is a mask on the face, what type of mask is worn, and how it is worn is an important research topic. In this work, the use of thermal imaging was considered to analyze the possibility of detecting (localizing) a mask on the face, as well as to check whether it is possible to classify the type of mask on the face. The previously proposed dataset of thermal images was extended and annotated with the description of a type of mask and a location of a mask within a face. Different deep learning models were adapted. The best model for face mask detection turned out to be the Yolov5 model in the \"nano\" version, reaching mAP higher than 97% and precision of about 95%. High accuracy was also obtained for mask type classification. The best results were obtained for the convolutional neural network model built on an autoencoder initially trained in the thermal image reconstruction problem. The pretrained encoder was used to train a classifier which achieved an accuracy of 91%.","sentences":["Face masks are recommended to reduce the transmission of many viruses, especially SARS-CoV-2.","Therefore, the automatic detection of whether there is a mask on the face, what type of mask is worn, and how it is worn is an important research topic.","In this work, the use of thermal imaging was considered to analyze the possibility of detecting (localizing) a mask on the face, as well as to check whether it is possible to classify the type of mask on the face.","The previously proposed dataset of thermal images was extended and annotated with the description of a type of mask and a location of a mask within a face.","Different deep learning models were adapted.","The best model for face mask detection turned out to be the Yolov5 model in the \"nano\" version, reaching mAP higher than 97% and precision of about 95%.","High accuracy was also obtained for mask type classification.","The best results were obtained for the convolutional neural network model built on an autoencoder initially trained in the thermal image reconstruction problem.","The pretrained encoder was used to train a classifier which achieved an accuracy of 91%."],"url":"http://arxiv.org/abs/2304.02931v1"}
{"created":"2023-04-06","title":"Computer-aided Diagnosis of Malaria through Transfer Learning using the ResNet50 Backbone","abstract":"According to the World Malaria Report of 2022, 247 million cases of malaria and 619,000 related deaths were reported in 2021. This highlights the predominance of the disease, especially in the tropical and sub-tropical regions of Africa, parts of South-east Asia, Central and Southern America. Malaria is caused due to the Plasmodium parasite which is circulated through the bites of the female Anopheles mosquito. Hence, the detection of the parasite in human blood smears could confirm malarial infestation. Since the manual identification of Plasmodium is a lengthy and time-consuming task subject to variability in accuracy, we propose an automated, computer-aided diagnostic method to classify malarial thin smear blood cell images as parasitized and uninfected by using the ResNet50 Deep Neural Network. In this paper, we have used the pre-trained ResNet50 model on the open-access database provided by the National Library of Medicine's Lister Hill National Center for Biomedical Communication for 150 epochs. The results obtained showed accuracy, precision, and recall values of 98.75%, 99.3% and 99.5% on the ResNet50(proposed) model. We have compared these metrics with similar models such as VGG16, Watershed Segmentation and Random Forest, which showed better performance than traditional techniques as well.","sentences":["According to the World Malaria Report of 2022, 247 million cases of malaria and 619,000 related deaths were reported in 2021.","This highlights the predominance of the disease, especially in the tropical and sub-tropical regions of Africa, parts of South-east Asia, Central and Southern America.","Malaria is caused due to the Plasmodium parasite which is circulated through the bites of the female Anopheles mosquito.","Hence, the detection of the parasite in human blood smears could confirm malarial infestation.","Since the manual identification of Plasmodium is a lengthy and time-consuming task subject to variability in accuracy, we propose an automated, computer-aided diagnostic method to classify malarial thin smear blood cell images as parasitized and uninfected by using the ResNet50 Deep Neural Network.","In this paper, we have used the pre-trained ResNet50 model on the open-access database provided by the National Library of Medicine's Lister Hill National Center for Biomedical Communication for 150 epochs.","The results obtained showed accuracy, precision, and recall values of 98.75%, 99.3% and 99.5% on the ResNet50(proposed) model.","We have compared these metrics with similar models such as VGG16, Watershed Segmentation and Random Forest, which showed better performance than traditional techniques as well."],"url":"http://arxiv.org/abs/2304.02925v1"}
{"created":"2023-04-06","title":"Efficient Audio Captioning Transformer with Patchout and Text Guidance","abstract":"Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity. Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022.","sentences":["Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip.","In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting.","The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions.","To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset.","Moreover, we propose a method to apply Mixup augmentation for AAC.","Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance.","The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity.","Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022."],"url":"http://arxiv.org/abs/2304.02916v1"}
{"created":"2023-04-06","title":"SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention","abstract":"Extracting entities and relations is an essential task of information extraction. Triplets extracted from a sentence might overlap with each other. Previous methods either did not address the overlapping issues or solved overlapping issues partially. To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism. Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects. Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations. We test our method on two public datasets, our method achieves the best performances on these two datasets.","sentences":["Extracting entities and relations is an essential task of information extraction.","Triplets extracted from a sentence might overlap with each other.","Previous methods either did not address the overlapping issues or solved overlapping issues partially.","To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism.","Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects.","Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations.","We test our method on two public datasets, our method achieves the best performances on these two datasets."],"url":"http://arxiv.org/abs/2304.02901v1"}
{"created":"2023-04-06","title":"Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection","abstract":"Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential. However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large. In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension. Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration. We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\\big(\\big(\\frac{P}{S}\\big)^2 \\frac{\\log T}{T}\\big)$ for a given dataset where $S$ is the expected number of conditional PIP computations per MCMC iteration. Experiments show that our Rao-Blackwellized estimator can have a smaller variance than its counterpart associated with the subset wTGS.","sentences":["Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential.","However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large.","In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension.","Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration.","We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\\big(\\big(\\frac{P}{S}\\big)^2 \\frac{\\log T}{T}\\big)$ for a given dataset where $S$ is the expected number of conditional PIP computations per MCMC iteration.","Experiments show that our Rao-Blackwellized estimator can have a smaller variance than its counterpart associated with the subset wTGS."],"url":"http://arxiv.org/abs/2304.02899v1"}
{"created":"2023-04-06","title":"LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries","abstract":"Graph streams represent data interactions in real applications. The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others. However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them. Current studies apply sketches to summarize graph streams. We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches. In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance. Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically. LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy. We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency.","sentences":["Graph streams represent data interactions in real applications.","The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others.","However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them.","Current studies apply sketches to summarize graph streams.","We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches.","In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance.","Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically.","LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy.","We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency."],"url":"http://arxiv.org/abs/2304.02897v1"}
{"created":"2023-04-06","title":"Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients","abstract":"Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees. In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise). The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective. To address the challenges, we propose FedCNI without using an additional clean proxy dataset. It includes a noise-resilient local solver and a robust global aggregator. For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples. Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy. For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods. Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments.","sentences":["Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees.","In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise).","The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective.","To address the challenges, we propose FedCNI without using an additional clean proxy dataset.","It includes a noise-resilient local solver and a robust global aggregator.","For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples.","Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy.","For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods.","Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments."],"url":"http://arxiv.org/abs/2304.02892v1"}
{"created":"2023-04-06","title":"Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts","abstract":"Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research. NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language. This paper adapts these models to automatically associate the ICD codes. Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed. In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association. Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results.","sentences":["Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research.","NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language.","This paper adapts these models to automatically associate the ICD codes.","Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed.","In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association.","Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results."],"url":"http://arxiv.org/abs/2304.02886v1"}
{"created":"2023-04-06","title":"Protecting User Privacy in Online Settings via Supervised Learning","abstract":"Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit. Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money. However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics. The problem is the sale of user data to third parties. In this work, we design an intelligent approach to online privacy protection that leverages supervised learning. By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user. In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm. The results of our evaluation demonstrate the feasibility and potential of our approach.","sentences":["Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit.","Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money.","However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics.","The problem is the sale of user data to third parties.","In this work, we design an intelligent approach to online privacy protection that leverages supervised learning.","By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user.","In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm.","The results of our evaluation demonstrate the feasibility and potential of our approach."],"url":"http://arxiv.org/abs/2304.02870v1"}
{"created":"2023-04-06","title":"VPFusion: Towards Robust Vertical Representation Learning for 3D Object Detection","abstract":"Efficient point cloud representation is a fundamental element of Lidar-based 3D object detection. Recent grid-based detectors usually divide point clouds into voxels or pillars and construct single-stream networks in Bird's Eye View. However, these point cloud encoding paradigms underestimate the point representation in the vertical direction, which cause the loss of semantic or fine-grained information, especially for vertical sensitive objects like pedestrian and cyclists. In this paper, we propose an explicit vertical multi-scale representation learning framework, VPFusion, to combine the complementary information from both voxel and pillar streams. Specifically, VPFusion first builds upon a sparse voxel-pillar-based backbone. The backbone divides point clouds into voxels and pillars, then encodes features with 3D and 2D sparse convolution simultaneously. Next, we introduce the Sparse Fusion Layer (SFL), which establishes a bidirectional pathway for sparse voxel and pillar features to enable the interaction between them. Additionally, we present the Dense Fusion Neck (DFN) to effectively combine the dense feature maps from voxel and pillar branches with multi-scale. Extensive experiments on the large-scale Waymo Open Dataset and nuScenes Dataset demonstrate that VPFusion surpasses the single-stream baselines by a large margin and achieves state-of-the-art performance with real-time inference speed.","sentences":["Efficient point cloud representation is a fundamental element of Lidar-based 3D object detection.","Recent grid-based detectors usually divide point clouds into voxels or pillars and construct single-stream networks in Bird's Eye View.","However, these point cloud encoding paradigms underestimate the point representation in the vertical direction, which cause the loss of semantic or fine-grained information, especially for vertical sensitive objects like pedestrian and cyclists.","In this paper, we propose an explicit vertical multi-scale representation learning framework, VPFusion, to combine the complementary information from both voxel and pillar streams.","Specifically, VPFusion first builds upon a sparse voxel-pillar-based backbone.","The backbone divides point clouds into voxels and pillars, then encodes features with 3D and 2D sparse convolution simultaneously.","Next, we introduce the Sparse Fusion Layer (SFL), which establishes a bidirectional pathway for sparse voxel and pillar features to enable the interaction between them.","Additionally, we present the Dense Fusion Neck (DFN) to effectively combine the dense feature maps from voxel and pillar branches with multi-scale.","Extensive experiments on the large-scale Waymo Open Dataset and nuScenes Dataset demonstrate that VPFusion surpasses the single-stream baselines by a large margin and achieves state-of-the-art performance with real-time inference speed."],"url":"http://arxiv.org/abs/2304.02867v1"}
{"created":"2023-04-06","title":"Learning to Learn with Indispensable Connections","abstract":"Meta-learning aims to solve unseen tasks with few labelled instances. Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws. Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network. Because of this, meta-testing observes unnecessary computations and extra memory overhead. To overcome such flaws. We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections. We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem. We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase. Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets. Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset.","sentences":["Meta-learning aims to solve unseen tasks with few labelled instances.","Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws.","Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network.","Because of this, meta-testing observes unnecessary computations and extra memory overhead.","To overcome such flaws.","We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections.","We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem.","We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase.","Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets.","Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset."],"url":"http://arxiv.org/abs/2304.02862v1"}
{"created":"2023-04-06","title":"Replicability and Transparency for the Creation of Public Human User Video Game Datasets","abstract":"Replicability is absent in games research; a lack of transparency in protocol detail hinders scientific consensus and willingness to publish public datasets, impacting the application of these techniques in video games research. To combat this, we propose and give an example of the use of a set of experimental considerations, such as games and materials choice. This work promotes the communication of research protocols when publishing datasets, benefiting researchers when designing experiments.","sentences":["Replicability is absent in games research; a lack of transparency in protocol detail hinders scientific consensus and willingness to publish public datasets, impacting the application of these techniques in video games research.","To combat this, we propose and give an example of the use of a set of experimental considerations, such as games and materials choice.","This work promotes the communication of research protocols when publishing datasets, benefiting researchers when designing experiments."],"url":"http://arxiv.org/abs/2304.02861v1"}
{"created":"2023-04-06","title":"Towards an Effective and Efficient Transformer for Rain-by-snow Weather Removal","abstract":"Rain-by-snow weather removal is a specialized task in weather-degraded image restoration aiming to eliminate coexisting rain streaks and snow particles. In this paper, we propose RSFormer, an efficient and effective Transformer that addresses this challenge. Initially, we explore the proximity of convolution networks (ConvNets) and vision Transformers (ViTs) in hierarchical architectures and experimentally find they perform approximately at intra-stage feature learning. On this basis, we utilize a Transformer-like convolution block (TCB) that replaces the computationally expensive self-attention while preserving attention characteristics for adapting to input content. We also demonstrate that cross-stage progression is critical for performance improvement, and propose a global-local self-attention sampling mechanism (GLASM) that down-/up-samples features while capturing both global and local dependencies. Finally, we synthesize two novel rain-by-snow datasets, RSCityScape and RS100K, to evaluate our proposed RSFormer. Extensive experiments verify that RSFormer achieves the best trade-off between performance and time-consumption compared to other restoration methods. For instance, it outperforms Restormer with a 1.53% reduction in the number of parameters and a 15.6% reduction in inference time. Datasets, source code and pre-trained models are available at \\url{https://github.com/chdwyb/RSFormer}.","sentences":["Rain-by-snow weather removal is a specialized task in weather-degraded image restoration aiming to eliminate coexisting rain streaks and snow particles.","In this paper, we propose RSFormer, an efficient and effective Transformer that addresses this challenge.","Initially, we explore the proximity of convolution networks (ConvNets) and vision Transformers (ViTs) in hierarchical architectures and experimentally find they perform approximately at intra-stage feature learning.","On this basis, we utilize a Transformer-like convolution block (TCB) that replaces the computationally expensive self-attention while preserving attention characteristics for adapting to input content.","We also demonstrate that cross-stage progression is critical for performance improvement, and propose a global-local self-attention sampling mechanism (GLASM) that down-/up-samples features while capturing both global and local dependencies.","Finally, we synthesize two novel rain-by-snow datasets, RSCityScape and RS100K, to evaluate our proposed RSFormer.","Extensive experiments verify that RSFormer achieves the best trade-off between performance and time-consumption compared to other restoration methods.","For instance, it outperforms Restormer with a 1.53% reduction in the number of parameters and a 15.6% reduction in inference time.","Datasets, source code and pre-trained models are available at \\url{https://github.com/chdwyb/RSFormer}."],"url":"http://arxiv.org/abs/2304.02860v1"}
{"created":"2023-04-06","title":"A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation","abstract":"Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets. The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets. These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications.","sentences":["Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes.","Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems.","In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs).","A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review.","In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems.","We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems.","Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets.","The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets.","These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications."],"url":"http://arxiv.org/abs/2304.02858v1"}
{"created":"2023-04-06","title":"Optimization of probabilistic quantum search algorithm with a priori information","abstract":"A quantum computer encodes information in quantum states and runs quantum algorithms to surpass the classical counterparts by exploiting quantum superposition and quantum correlation. Grover's quantum search algorithm is a typical quantum algorithm that proves the superiority of quantum computing over classical computing. It has a quadratic reduction in the query complexity of database search, and is known to be optimal when no a priori information about the elements of the database is provided. In this work, we consider a probabilistic Grover's search algorithm allowing nonzero probability of failure for a database with general a priori probability distribution of the elements, and minimize the number of oracle calls by optimizing the initial state of the quantum system and the reflection axis of the diffusion operator. The initial state and the reflection axis are allowed not to coincide, and thus the quantum search algorithm rotates the quantum system in a three-dimensional subspace spanned by the initial state, the reflection axis and the search target state. The number of oracle calls is minimized by a variational method, and formal analytical results are obtained with the assumption of low failure probability. The results show that for nonuniform a priori distribution of the oracle elements, the number of oracle calls can be significantly reduced given a small decrease in the success probability of the quantum search algorithm, leading to a lower average number of oracle calls to find the solution of the search problem. The result is applied to a simple but nontrivial database model which has $N$ elements with nonuniform two-valued a priori probabilities to show the effect of the optimized search algorithm. The paper is concluded with a discussion about the generalization to higher-order results that allows a larger failure probability for the quantum search algorithm.","sentences":["A quantum computer encodes information in quantum states and runs quantum algorithms to surpass the classical counterparts by exploiting quantum superposition and quantum correlation.","Grover's quantum search algorithm is a typical quantum algorithm that proves the superiority of quantum computing over classical computing.","It has a quadratic reduction in the query complexity of database search, and is known to be optimal when no a priori information about the elements of the database is provided.","In this work, we consider a probabilistic Grover's search algorithm allowing nonzero probability of failure for a database with general a priori probability distribution of the elements, and minimize the number of oracle calls by optimizing the initial state of the quantum system and the reflection axis of the diffusion operator.","The initial state and the reflection axis are allowed not to coincide, and thus the quantum search algorithm rotates the quantum system in a three-dimensional subspace spanned by the initial state, the reflection axis and the search target state.","The number of oracle calls is minimized by a variational method, and formal analytical results are obtained with the assumption of low failure probability.","The results show that for nonuniform a priori distribution of the oracle elements, the number of oracle calls can be significantly reduced given a small decrease in the success probability of the quantum search algorithm, leading to a lower average number of oracle calls to find the solution of the search problem.","The result is applied to a simple but nontrivial database model which has $N$ elements with nonuniform two-valued a priori probabilities to show the effect of the optimized search algorithm.","The paper is concluded with a discussion about the generalization to higher-order results that allows a larger failure probability for the quantum search algorithm."],"url":"http://arxiv.org/abs/2304.02856v1"}
{"created":"2023-04-06","title":"Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets","abstract":"Deep networks have achieved impressive results on a range of well-curated benchmark datasets. Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance. In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features. We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet. It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations. We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline.","sentences":["Deep networks have achieved impressive results on a range of well-curated benchmark datasets.","Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance.","In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features.","We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet.","It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations.","We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline."],"url":"http://arxiv.org/abs/2304.02847v1"}
{"created":"2023-04-06","title":"NTK-SAP: Improving neural network pruning by aligning training dynamics","abstract":"Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent. In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well. We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP). Empirically, our method achieves better performance than all baselines on multiple datasets.","sentences":["Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory.","One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice.","Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK.","Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK.","This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart.","However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase.","We further propose to sample multiple realizations of random weights to estimate the NTK spectrum.","Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent.","In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well.","We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP).","Empirically, our method achieves better performance than all baselines on multiple datasets."],"url":"http://arxiv.org/abs/2304.02840v1"}
{"created":"2023-04-06","title":"TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph","abstract":"APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.","sentences":["APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT).","To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection.","Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks.","Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score.","To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline.","Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method."],"url":"http://arxiv.org/abs/2304.02838v1"}
{"created":"2023-04-06","title":"Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification","abstract":"The accuracy of predictive models for solitary pulmonary nodule (SPN) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (EHRs). However, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning. In this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected EHRs for SPN classification. We perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (CT) scans. Our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest CTs, billing codes, medications, and laboratory tests from EHRs of our home institution. Evaluation on 227 subjects with challenging SPNs revealed a significant AUC improvement over a longitudinal multimodal baseline (0.824 vs 0.752 AUC), as well as improvements over a single cross-section multimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741 AUC). This work demonstrates significant advantages with a novel approach for co-learning longitudinal imaging and non-imaging phenotypes with transformers.","sentences":["The accuracy of predictive models for solitary pulmonary nodule (SPN) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (EHRs).","However, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning.","In this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected EHRs for SPN classification.","We perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (CT) scans.","Our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest CTs, billing codes, medications, and laboratory tests from EHRs of our home institution.","Evaluation on 227 subjects with challenging SPNs revealed a significant AUC improvement over a longitudinal multimodal baseline (0.824 vs 0.752 AUC), as well as improvements over a single cross-section multimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741 AUC).","This work demonstrates significant advantages with a novel approach for co-learning longitudinal imaging and non-imaging phenotypes with transformers."],"url":"http://arxiv.org/abs/2304.02836v1"}
{"created":"2023-04-06","title":"GIF: A General Graph Unlearning Strategy via Influence Function","abstract":"With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention. However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning. We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature. Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data. The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency. Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism. We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency. Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}.","sentences":["With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention.","However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   ","In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning.","We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature.","Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data.","The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency.","Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism.","We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency.","Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}."],"url":"http://arxiv.org/abs/2304.02835v1"}
{"created":"2023-04-06","title":"DoUnseen: Zero-Shot Object Detection for Robotic Grasping","abstract":"How can we segment varying numbers of objects where each specific object represents its own separate class? To make the problem even more realistic, how can we add and delete classes on the fly without retraining? This is the case of robotic applications where no datasets of the objects exist or application that includes thousands of objects (E.g., in logistics) where it is impossible to train a single model to learn all of the objects. Most current research on object segmentation for robotic grasping focuses on class-level object segmentation (E.g., box, cup, bottle), closed sets (specific objects of a dataset; for example, YCB dataset), or deep learning-based template matching. In this work, we are interested in open sets where the number of classes is unknown, varying, and without pre-knowledge about the objects' types. We consider each specific object as its own separate class. Our goal is to develop a zero-shot object detector that requires no training and can add any object as a class just by capturing a few images of the object. Our main idea is to break the segmentation pipelines into two steps by combining unseen object segmentation networks cascaded by zero-shot classifiers. We evaluate our zero-shot object detector on unseen datasets and compare it to a trained Mask R-CNN on those datasets. The results show that the performance varies from practical to unsuitable depending on the environment setup and the objects being handled. The code is available in our DoUnseen library repository.","sentences":["How can we segment varying numbers of objects where each specific object represents its own separate class?","To make the problem even more realistic, how can we add and delete classes on the fly without retraining?","This is the case of robotic applications where no datasets of the objects exist or application that includes thousands of objects (E.g., in logistics) where it is impossible to train a single model to learn all of the objects.","Most current research on object segmentation for robotic grasping focuses on class-level object segmentation (E.g., box, cup, bottle), closed sets (specific objects of a dataset; for example, YCB dataset), or deep learning-based template matching.","In this work, we are interested in open sets where the number of classes is unknown, varying, and without pre-knowledge about the objects' types.","We consider each specific object as its own separate class.","Our goal is to develop a zero-shot object detector that requires no training and can add any object as a class just by capturing a few images of the object.","Our main idea is to break the segmentation pipelines into two steps by combining unseen object segmentation networks cascaded by zero-shot classifiers.","We evaluate our zero-shot object detector on unseen datasets and compare it to a trained Mask R-CNN on those datasets.","The results show that the performance varies from practical to unsuitable depending on the environment setup and the objects being handled.","The code is available in our DoUnseen library repository."],"url":"http://arxiv.org/abs/2304.02833v1"}
{"created":"2023-04-06","title":"Uncurated Image-Text Datasets: Shedding Light on Demographic Bias","abstract":"The increasing tendency to collect large and uncurated datasets to train vision-and-language models has raised concerns about fair representations. It is known that even small but manually annotated datasets, such as MSCOCO, are affected by societal bias. This problem, far from being solved, may be getting worse with data crawled from the Internet without much control. In addition, the lack of tools to analyze societal bias in big collections of images makes addressing the problem extremely challenging. Our first contribution is to annotate part of the Google Conceptual Captions dataset, widely used for training vision-and-language models, with four demographic and two contextual attributes. Our second contribution is to conduct a comprehensive analysis of the annotations, focusing on how different demographic groups are represented. Our last contribution lies in evaluating three prevailing vision-and-language tasks: image captioning, text-image CLIP embeddings, and text-to-image generation, showing that societal bias is a persistent problem in all of them.","sentences":["The increasing tendency to collect large and uncurated datasets to train vision-and-language models has raised concerns about fair representations.","It is known that even small but manually annotated datasets, such as MSCOCO, are affected by societal bias.","This problem, far from being solved, may be getting worse with data crawled from the Internet without much control.","In addition, the lack of tools to analyze societal bias in big collections of images makes addressing the problem extremely challenging.","Our first contribution is to annotate part of the Google Conceptual Captions dataset, widely used for training vision-and-language models, with four demographic and two contextual attributes.","Our second contribution is to conduct a comprehensive analysis of the annotations, focusing on how different demographic groups are represented.","Our last contribution lies in evaluating three prevailing vision-and-language tasks: image captioning, text-image CLIP embeddings, and text-to-image generation, showing that societal bias is a persistent problem in all of them."],"url":"http://arxiv.org/abs/2304.02828v1"}
{"created":"2023-04-06","title":"Pragmatically Appropriate Diversity for Dialogue Evaluation","abstract":"Linguistic pragmatics state that a conversation's underlying speech acts can constrain the type of response which is appropriate at each turn in the conversation. When generating dialogue responses, neural dialogue agents struggle to produce diverse responses. Currently, dialogue diversity is assessed using automatic metrics, but the underlying speech acts do not inform these metrics.   To remedy this, we propose the notion of Pragmatically Appropriate Diversity, defined as the extent to which a conversation creates and constrains the creation of multiple diverse responses. Using a human-created multi-response dataset, we find significant support for the hypothesis that speech acts provide a signal for the diversity of the set of next responses. Building on this result, we propose a new human evaluation task where creative writers predict the extent to which conversations inspire the creation of multiple diverse responses. Our studies find that writers' judgments align with the Pragmatically Appropriate Diversity of conversations. Our work suggests that expectations for diversity metric scores should vary depending on the speech act.","sentences":["Linguistic pragmatics state that a conversation's underlying speech acts can constrain the type of response which is appropriate at each turn in the conversation.","When generating dialogue responses, neural dialogue agents struggle to produce diverse responses.","Currently, dialogue diversity is assessed using automatic metrics, but the underlying speech acts do not inform these metrics.   ","To remedy this, we propose the notion of Pragmatically Appropriate Diversity, defined as the extent to which a conversation creates and constrains the creation of multiple diverse responses.","Using a human-created multi-response dataset, we find significant support for the hypothesis that speech acts provide a signal for the diversity of the set of next responses.","Building on this result, we propose a new human evaluation task where creative writers predict the extent to which conversations inspire the creation of multiple diverse responses.","Our studies find that writers' judgments align with the Pragmatically Appropriate Diversity of conversations.","Our work suggests that expectations for diversity metric scores should vary depending on the speech act."],"url":"http://arxiv.org/abs/2304.02812v1"}
{"created":"2023-04-06","title":"End-to-end Manipulator Calligraphy Planning via Variational Imitation Learning","abstract":"Planning from demonstrations has shown promising results with the advances of deep neural networks. One of the most popular real-world applications is automated handwriting using a robotic manipulator. Classically it is simplified as a two-dimension problem. This representation is suitable for elementary drawings, but it is not sufficient for Japanese calligraphy or complex work of art where the orientation of a pen is part of the user expression. In this study, we focus on automated planning of Japanese calligraphy using a three-dimension representation of the trajectory as well as the rotation of the pen tip, and propose a novel deep imitation learning neural network that learns from expert demonstrations through a combination of images and pose data. The network consists of a combination of variational auto-encoder, bi-directional LSTM, and Multi-Layer Perceptron (MLP). Experiments are conducted in a progressive way, and results demonstrate that the proposed approach is successful in completion of tasks for real-world robots, overcoming the distribution shift problem in imitation learning. The source code and dataset will be public.","sentences":["Planning from demonstrations has shown promising results with the advances of deep neural networks.","One of the most popular real-world applications is automated handwriting using a robotic manipulator.","Classically it is simplified as a two-dimension problem.","This representation is suitable for elementary drawings, but it is not sufficient for Japanese calligraphy or complex work of art where the orientation of a pen is part of the user expression.","In this study, we focus on automated planning of Japanese calligraphy using a three-dimension representation of the trajectory as well as the rotation of the pen tip, and propose a novel deep imitation learning neural network that learns from expert demonstrations through a combination of images and pose data.","The network consists of a combination of variational auto-encoder, bi-directional LSTM, and Multi-Layer Perceptron (MLP).","Experiments are conducted in a progressive way, and results demonstrate that the proposed approach is successful in completion of tasks for real-world robots, overcoming the distribution shift problem in imitation learning.","The source code and dataset will be public."],"url":"http://arxiv.org/abs/2304.02801v1"}
{"created":"2023-04-06","title":"Source-free Domain Adaptation Requires Penalized Diversity","abstract":"While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset. Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy. Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains. In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor. Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA). Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses. Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy. Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift. In addition, PD is augmented with a weighted MI maximization objective for label distribution shift. Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts.","sentences":["While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset.","Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy.","Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains.","In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor.","Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA).","Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses.","Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy.","Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift.","In addition, PD is augmented with a weighted MI maximization objective for label distribution shift.","Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts."],"url":"http://arxiv.org/abs/2304.02798v1"}
{"created":"2023-04-05","title":"Context-Aware Classification of Legal Document Pages","abstract":"For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand. Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently. Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length. In this paper, we present a simple but effective approach that overcomes the above limitation. Specifically, we enhance the input with extra tokens carrying sequential information about previous pages - introducing recurrence - which enables the usage of pre-trained Transformer models like BERT for context-aware page classification. Our experiments conducted on two legal datasets in English and Portuguese respectively show that the proposed approach can significantly improve the performance of document page classification compared to the non-recurrent setup as well as the other context-aware baselines.","sentences":["For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand.","Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently.","Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length.","In this paper, we present a simple but effective approach that overcomes the above limitation.","Specifically, we enhance the input with extra tokens carrying sequential information about previous pages - introducing recurrence - which enables the usage of pre-trained Transformer models like BERT for context-aware page classification.","Our experiments conducted on two legal datasets in English and Portuguese respectively show that the proposed approach can significantly improve the performance of document page classification compared to the non-recurrent setup as well as the other context-aware baselines."],"url":"http://arxiv.org/abs/2304.02787v1"}
{"created":"2023-04-05","title":"FACE-AUDITOR: Data Auditing in Facial Recognition Systems","abstract":"Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase. However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent. To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks. Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed.   In this paper, we formulate the auditing process as a user-level membership inference problem and propose a complete toolkit FACE-AUDITOR that can carefully choose the probing set to query the few-shot-based facial recognition model and determine whether any of a user's face images is used in training the model. We further propose to use the similarity scores between the original face images as reference information to improve the auditing performance. Extensive experiments on multiple real-world face image datasets show that FACE-AUDITOR can achieve auditing accuracy of up to $99\\%$. Finally, we show that FACE-AUDITOR is robust in the presence of several perturbation mechanisms to the training images or the target models. The source code of our experiments can be found at \\url{https://github.com/MinChen00/Face-Auditor}.","sentences":["Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase.","However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent.","To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks.","Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed.   ","In this paper, we formulate the auditing process as a user-level membership inference problem and propose a complete toolkit FACE-AUDITOR that can carefully choose the probing set to query the few-shot-based facial recognition model and determine whether any of a user's face images is used in training the model.","We further propose to use the similarity scores between the original face images as reference information to improve the auditing performance.","Extensive experiments on multiple real-world face image datasets show that FACE-AUDITOR can achieve auditing accuracy of up to $99\\%$. Finally, we show that FACE-AUDITOR is robust in the presence of several perturbation mechanisms to the training images or the target models.","The source code of our experiments can be found at \\url{https://github.com/MinChen00/Face-Auditor}."],"url":"http://arxiv.org/abs/2304.02782v1"}
{"created":"2023-04-05","title":"Low-Shot Learning for Fictional Claim Verification","abstract":"In this paper, we study the problem of claim verification in the context of claims about fictional stories in a low-shot learning setting. To this end, we generate two synthetic datasets and then develop an end-to-end pipeline and model that is tested on both benchmarks. To test the efficacy of our pipeline and the difficulty of benchmarks, we compare our models' results against human and random assignment results. Our code is available at https://github.com/Derposoft/plot_hole_detection.","sentences":["In this paper, we study the problem of claim verification in the context of claims about fictional stories in a low-shot learning setting.","To this end, we generate two synthetic datasets and then develop an end-to-end pipeline and model that is tested on both benchmarks.","To test the efficacy of our pipeline and the difficulty of benchmarks, we compare our models' results against human and random assignment results.","Our code is available at https://github.com/Derposoft/plot_hole_detection."],"url":"http://arxiv.org/abs/2304.02769v1"}
{"created":"2023-04-05","title":"Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review","abstract":"The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis. This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks. To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field. In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis. The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format. The paper presents some limitations of current research and some recommendations for further research.","sentences":["The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis.","This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks.","To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field.","In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis.","The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format.","The paper presents some limitations of current research and some recommendations for further research."],"url":"http://arxiv.org/abs/2304.02768v1"}
{"created":"2023-04-05","title":"MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection","abstract":"Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methane plume sites. Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact. Dataset and source code are public","sentences":["Methane (CH$_4$) is the chief contributor to global climate change.","Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions.","Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable.","To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions.","MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately.","Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art.","In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022.","It contains over 4000 methane plume sites.","Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact.","Dataset and source code are public"],"url":"http://arxiv.org/abs/2304.02767v1"}
{"created":"2023-04-05","title":"The Saudi Privacy Policy Dataset","abstract":"This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide. Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia. The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB. The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations. By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia.","sentences":["This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide.","Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia.","The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB.","The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations.","By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia."],"url":"http://arxiv.org/abs/2304.02757v1"}
{"created":"2023-04-05","title":"Hybrid Zonotopes Exactly Represent ReLU Neural Networks","abstract":"We show that hybrid zonotopes offer an equivalent representation of feed-forward fully connected neural networks with ReLU activation functions. Our approach demonstrates that the complexity of binary variables is equal to the total number of neurons in the network and hence grows linearly in the size of the network. We demonstrate the utility of the hybrid zonotope formulation through three case studies including nonlinear function approximation, MPC closed-loop reachability and verification, and robustness of classification on the MNIST dataset.","sentences":["We show that hybrid zonotopes offer an equivalent representation of feed-forward fully connected neural networks with ReLU activation functions.","Our approach demonstrates that the complexity of binary variables is equal to the total number of neurons in the network and hence grows linearly in the size of the network.","We demonstrate the utility of the hybrid zonotope formulation through three case studies including nonlinear function approximation, MPC closed-loop reachability and verification, and robustness of classification on the MNIST dataset."],"url":"http://arxiv.org/abs/2304.02755v1"}
{"created":"2023-04-05","title":"Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks","abstract":"This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy. The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups. Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology.","sentences":["This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data.","With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information.","Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali.","We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy.","The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups.","Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology."],"url":"http://arxiv.org/abs/2304.02739v1"}
{"created":"2023-04-05","title":"Core Challenges in Embodied Vision-Language Planning","abstract":"Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks. Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment.","sentences":["Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics.","Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three.","Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field.","In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments.","We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.","Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment."],"url":"http://arxiv.org/abs/2304.02738v1"}
{"created":"2023-04-05","title":"A Quantum-Chemical Bonding Database for Solid-State Materials","abstract":"An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials. Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties. Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis. With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data. We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database. The database structure of the bonding analysis database, which allows easy data retrieval, is also explained. The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively. Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features.","sentences":["An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials.","Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties.","Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis.","With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data.","We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database.","The database structure of the bonding analysis database, which allows easy data retrieval, is also explained.","The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively.","Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features."],"url":"http://arxiv.org/abs/2304.02726v1"}
{"created":"2023-04-05","title":"FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation","abstract":"Accurate medical imaging segmentation is critical for precise and effective medical interventions. However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales. These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge. In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors. Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges. Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency. These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation.","sentences":["Accurate medical imaging segmentation is critical for precise and effective medical interventions.","However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales.","These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge.","In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors.","Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges.","Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency.","These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation."],"url":"http://arxiv.org/abs/2304.02725v1"}
{"created":"2023-04-05","title":"Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound","abstract":"Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging. This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images. We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound. The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights. Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation. To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound.","sentences":["Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging.","This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images.","We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound.","The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights.","Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation.","To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound."],"url":"http://arxiv.org/abs/2304.02724v1"}
{"created":"2023-04-05","title":"To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency","abstract":"Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.","sentences":["Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise.","Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult.","This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets.","We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder.","Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2.","Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets."],"url":"http://arxiv.org/abs/2304.02721v1"}
{"created":"2023-04-05","title":"Domain Generalization with Adversarial Intensity Attack for Medical Image Segmentation","abstract":"Most statistical learning algorithms rely on an over-simplified assumption, that is, the train and test data are independent and identically distributed. In real-world scenarios, however, it is common for models to encounter data from new and different domains to which they were not exposed to during training. This is often the case in medical imaging applications due to differences in acquisition devices, imaging protocols, and patient characteristics. To address this problem, domain generalization (DG) is a promising direction as it enables models to handle data from previously unseen domains by learning domain-invariant features robust to variations across different domains. To this end, we introduce a novel DG method called Adversarial Intensity Attack (AdverIN), which leverages adversarial training to generate training data with an infinite number of styles and increase data diversity while preserving essential content information. We conduct extensive evaluation experiments on various multi-domain segmentation datasets, including 2D retinal fundus optic disc/cup and 3D prostate MRI. Our results demonstrate that AdverIN significantly improves the generalization ability of the segmentation models, achieving significant improvement on these challenging datasets. Code is available upon publication.","sentences":["Most statistical learning algorithms rely on an over-simplified assumption, that is, the train and test data are independent and identically distributed.","In real-world scenarios, however, it is common for models to encounter data from new and different domains to which they were not exposed to during training.","This is often the case in medical imaging applications due to differences in acquisition devices, imaging protocols, and patient characteristics.","To address this problem, domain generalization (DG) is a promising direction as it enables models to handle data from previously unseen domains by learning domain-invariant features robust to variations across different domains.","To this end, we introduce a novel DG method called Adversarial Intensity Attack (AdverIN), which leverages adversarial training to generate training data with an infinite number of styles and increase data diversity while preserving essential content information.","We conduct extensive evaluation experiments on various multi-domain segmentation datasets, including 2D retinal fundus optic disc/cup and 3D prostate MRI.","Our results demonstrate that AdverIN significantly improves the generalization ability of the segmentation models, achieving significant improvement on these challenging datasets.","Code is available upon publication."],"url":"http://arxiv.org/abs/2304.02720v1"}
{"created":"2023-04-05","title":"Learning Knowledge-Rich Sequential Model for Planar Homography Estimation in Aerial Video","abstract":"This paper presents an unsupervised approach that leverages raw aerial videos to learn to estimate planar homographic transformation between consecutive video frames. Previous learning-based estimators work on pairs of images to estimate their planar homographic transformations but suffer from severe over-fitting issues, especially when applying over aerial videos. To address this concern, we develop a sequential estimator that directly processes a sequence of video frames and estimates their pairwise planar homographic transformations in batches. We also incorporate a set of spatial-temporal knowledge to regularize the learning of such a sequence-to-sequence model. We collect a set of challenging aerial videos and compare the proposed method to the alternative algorithms. Empirical studies suggest that our sequential model achieves significant improvement over alternative image-based methods and the knowledge-rich regularization further boosts our system performance. Our codes and dataset could be found at https://github.com/Paul-LiPu/DeepVideoHomography","sentences":["This paper presents an unsupervised approach that leverages raw aerial videos to learn to estimate planar homographic transformation between consecutive video frames.","Previous learning-based estimators work on pairs of images to estimate their planar homographic transformations but suffer from severe over-fitting issues, especially when applying over aerial videos.","To address this concern, we develop a sequential estimator that directly processes a sequence of video frames and estimates their pairwise planar homographic transformations in batches.","We also incorporate a set of spatial-temporal knowledge to regularize the learning of such a sequence-to-sequence model.","We collect a set of challenging aerial videos and compare the proposed method to the alternative algorithms.","Empirical studies suggest that our sequential model achieves significant improvement over alternative image-based methods and the knowledge-rich regularization further boosts our system performance.","Our codes and dataset could be found at https://github.com/Paul-LiPu/DeepVideoHomography"],"url":"http://arxiv.org/abs/2304.02715v1"}
{"created":"2023-04-05","title":"NUMSnet: Nested-U Multi-class Segmentation network for 3D Medical Image Stacks","abstract":"Semantic segmentation for medical 3D image stacks enables accurate volumetric reconstructions, computer-aided diagnostics and follow up treatment planning. In this work, we present a novel variant of the Unet model called the NUMSnet that transmits pixel neighborhood features across scans through nested layers to achieve accurate multi-class semantic segmentations with minimal training data. We analyze the semantic segmentation performance of the NUMSnet model in comparison with several Unet model variants to segment 3-7 regions of interest using only 10% of images for training per Lung-CT and Heart-CT volumetric image stacks. The proposed NUMSnet model achieves up to 20% improvement in segmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and 2.5-10% improvement in Dice scores for Heart-CT stacks when compared to the Unet++ model. The NUMSnet model needs to be trained by ordered images around the central scan of each volumetric stack. Propagation of image feature information from the 6 nested layers of the Unet++ model are found to have better computation and segmentation performances than propagation of all up-sampling layers in a Unet++ model. The NUMSnet model achieves comparable segmentation performances to existing works, while being trained on as low as 5\\% of the training images. Also, transfer learning allows faster convergence of the NUMSnet model for multi-class semantic segmentation from pathology in Lung-CT images to cardiac segmentations in Heart-CT stacks. Thus, the proposed model can standardize multi-class semantic segmentation on a variety of volumetric image stacks with minimal training dataset. This can significantly reduce the cost, time and inter-observer variabilities associated with computer-aided detections and treatment.","sentences":["Semantic segmentation for medical 3D image stacks enables accurate volumetric reconstructions, computer-aided diagnostics and follow up treatment planning.","In this work, we present a novel variant of the Unet model called the NUMSnet that transmits pixel neighborhood features across scans through nested layers to achieve accurate multi-class semantic segmentations with minimal training data.","We analyze the semantic segmentation performance of the NUMSnet model in comparison with several Unet model variants to segment 3-7 regions of interest using only 10% of images for training per Lung-CT and Heart-CT volumetric image stacks.","The proposed NUMSnet model achieves up to 20% improvement in segmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and 2.5-10% improvement in Dice scores for Heart-CT stacks when compared to the Unet++ model.","The NUMSnet model needs to be trained by ordered images around the central scan of each volumetric stack.","Propagation of image feature information from the 6 nested layers of the Unet++ model are found to have better computation and segmentation performances than propagation of all up-sampling layers in a Unet++ model.","The NUMSnet model achieves comparable segmentation performances to existing works, while being trained on as low as 5\\% of the training images.","Also, transfer learning allows faster convergence of the NUMSnet model for multi-class semantic segmentation from pathology in Lung-CT images to cardiac segmentations in Heart-CT stacks.","Thus, the proposed model can standardize multi-class semantic segmentation on a variety of volumetric image stacks with minimal training dataset.","This can significantly reduce the cost, time and inter-observer variabilities associated with computer-aided detections and treatment."],"url":"http://arxiv.org/abs/2304.02713v1"}
{"created":"2023-04-05","title":"Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning","abstract":"Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt.","sentences":["Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation.","AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   ","Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema.","Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema.","SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   ","We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs.","Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data.","This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   ","SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt."],"url":"http://arxiv.org/abs/2304.02711v1"}
{"created":"2023-04-05","title":"Real-Time Dense 3D Mapping of Underwater Environments","abstract":"This paper addresses real-time dense 3D reconstruction for a resource-constrained Autonomous Underwater Vehicle (AUV). Underwater vision-guided operations are among the most challenging as they combine 3D motion in the presence of external forces, limited visibility, and absence of global positioning. Obstacle avoidance and effective path planning require online dense reconstructions of the environment. Autonomous operation is central to environmental monitoring, marine archaeology, resource utilization, and underwater cave exploration. To address this problem, we propose to use SVIn2, a robust VIO method, together with a real-time 3D reconstruction pipeline. We provide extensive evaluation on four challenging underwater datasets. Our pipeline produces comparable reconstruction with that of COLMAP, the state-of-the-art offline 3D reconstruction method, at high frame rates on a single CPU.","sentences":["This paper addresses real-time dense 3D reconstruction for a resource-constrained Autonomous Underwater Vehicle (AUV).","Underwater vision-guided operations are among the most challenging as they combine 3D motion in the presence of external forces, limited visibility, and absence of global positioning.","Obstacle avoidance and effective path planning require online dense reconstructions of the environment.","Autonomous operation is central to environmental monitoring, marine archaeology, resource utilization, and underwater cave exploration.","To address this problem, we propose to use SVIn2, a robust VIO method, together with a real-time 3D reconstruction pipeline.","We provide extensive evaluation on four challenging underwater datasets.","Our pipeline produces comparable reconstruction with that of COLMAP, the state-of-the-art offline 3D reconstruction method, at high frame rates on a single CPU."],"url":"http://arxiv.org/abs/2304.02704v1"}
{"created":"2023-04-05","title":"Recovering Continuous Scene Dynamics from A Single Blurry Image with Events","abstract":"This paper aims at demystifying a single motion-blurred image with events and revealing temporally continuous scene dynamics encrypted behind motion blurs. To achieve this end, an Implicit Video Function (IVF) is learned to represent a single motion blurred image with concurrent events, enabling the latent sharp image restoration of arbitrary timestamps in the range of imaging exposures. Specifically, a dual attention transformer is proposed to efficiently leverage merits from both modalities, i.e., the high temporal resolution of event features and the smoothness of image features, alleviating temporal ambiguities while suppressing the event noise. The proposed network is trained only with the supervision of ground-truth images of limited referenced timestamps. Motion- and texture-guided supervisions are employed simultaneously to enhance restorations of the non-referenced timestamps and improve the overall sharpness. Experiments on synthetic, semi-synthetic, and real-world datasets demonstrate that our proposed method outperforms state-of-the-art methods by a large margin in terms of both objective PSNR and SSIM measurements and subjective evaluations.","sentences":["This paper aims at demystifying a single motion-blurred image with events and revealing temporally continuous scene dynamics encrypted behind motion blurs.","To achieve this end, an Implicit Video Function (IVF) is learned to represent a single motion blurred image with concurrent events, enabling the latent sharp image restoration of arbitrary timestamps in the range of imaging exposures.","Specifically, a dual attention transformer is proposed to efficiently leverage merits from both modalities, i.e., the high temporal resolution of event features and the smoothness of image features, alleviating temporal ambiguities while suppressing the event noise.","The proposed network is trained only with the supervision of ground-truth images of limited referenced timestamps.","Motion- and texture-guided supervisions are employed simultaneously to enhance restorations of the non-referenced timestamps and improve the overall sharpness.","Experiments on synthetic, semi-synthetic, and real-world datasets demonstrate that our proposed method outperforms state-of-the-art methods by a large margin in terms of both objective PSNR and SSIM measurements and subjective evaluations."],"url":"http://arxiv.org/abs/2304.02695v1"}
{"created":"2023-04-05","title":"A Certified Radius-Guided Attack Framework to Image Segmentation Models","abstract":"Image segmentation is an important problem in many safety-critical applications. Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models. We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models. Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models. We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models. Specifically, we first adapt randomized smoothing, the state-of-the-art certification method for classification models, to derive the pixel's certified radius. We then focus more on disrupting pixels with relatively smaller certified radii and design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack. Next, we propose the first black-box attack to image segmentation models via bandit. We design a novel gradient estimator, based on bandit feedback, which is query-efficient and provably unbiased and stable. We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack, as well as a certified radius-guided PBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate. We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets. Our results validate the effectiveness of our certified radius-guided attack framework.","sentences":["Image segmentation is an important problem in many safety-critical applications.","Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models.","We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models.","Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models.","We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models.","Specifically, we first adapt randomized smoothing, the state-of-the-art certification method for classification models, to derive the pixel's certified radius.","We then focus more on disrupting pixels with relatively smaller certified radii and design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack.","Next, we propose the first black-box attack to image segmentation models via bandit.","We design a novel gradient estimator, based on bandit feedback, which is query-efficient and provably unbiased and stable.","We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack, as well as a certified radius-guided PBGD (CR-PBGD) attack.","We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate.","We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets.","Our results validate the effectiveness of our certified radius-guided attack framework."],"url":"http://arxiv.org/abs/2304.02693v1"}
{"created":"2023-04-05","title":"Chebyshev approximation of exponential data","abstract":"In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm. We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset.","sentences":["In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm.","We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset."],"url":"http://arxiv.org/abs/2304.02686v1"}
{"created":"2023-04-05","title":"Segment Anything","abstract":"We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.","sentences":["We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation.","Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images.","The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.","We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results.","We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision."],"url":"http://arxiv.org/abs/2304.02643v1"}
{"created":"2023-04-05","title":"High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation","abstract":"The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior. As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines. This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset. Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting. Our code is available at https://github.com/arvijj/hfpl.","sentences":["The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models.","The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps.","This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions.","The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth.","In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images.","In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior.","As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines.","This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset.","Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting.","Our code is available at https://github.com/arvijj/hfpl."],"url":"http://arxiv.org/abs/2304.02621v1"}
{"created":"2023-04-05","title":"An atlas of the heterogeneous viscoelastic brain with local power-law attenuation synthesised using Prony-series","abstract":"This review addresses the acute need to acknowledge the mechanical heterogeneity of brain matter and to accurately calibrate its local viscoelastic material properties accordingly. Specifically, it is important to compile the existing and disparate literature on attenuation power laws and dispersion to make progress in wave physics of brain matter, a field of research that has the potential to explain the mechanisms at play in diffuse axonal injury and mild traumatic brain injury in general. Currently, viscous effects in the brain are modelled using Prony-series, i.e., a sum of decaying exponentials at different relaxation times. Here we collect and synthesise the Prony-series coefficients appearing in the literature for twelve regions: brainstem, basal ganglia, cerebellum, corona radiata, corpus callosum, cortex, dentate gyrus, hippocampus, thalamus, grey matter, white matter, homogeneous brain, and for eight different mammals: pig, rat, human, mouse, cow, sheep, monkey and dog. Using this data, we compute the fractional-exponent attenuation power laws for different tissues of the brain, the corresponding dispersion laws resulting from causality, and the averaged Prony-series coefficients.","sentences":["This review addresses the acute need to acknowledge the mechanical heterogeneity of brain matter and to accurately calibrate its local viscoelastic material properties accordingly.","Specifically, it is important to compile the existing and disparate literature on attenuation power laws and dispersion to make progress in wave physics of brain matter, a field of research that has the potential to explain the mechanisms at play in diffuse axonal injury and mild traumatic brain injury in general.","Currently, viscous effects in the brain are modelled using Prony-series, i.e., a sum of decaying exponentials at different relaxation times.","Here we collect and synthesise the Prony-series coefficients appearing in the literature for twelve regions: brainstem, basal ganglia, cerebellum, corona radiata, corpus callosum, cortex, dentate gyrus, hippocampus, thalamus, grey matter, white matter, homogeneous brain, and for eight different mammals: pig, rat, human, mouse, cow, sheep, monkey and dog.","Using this data, we compute the fractional-exponent attenuation power laws for different tissues of the brain, the corresponding dispersion laws resulting from causality, and the averaged Prony-series coefficients."],"url":"http://arxiv.org/abs/2304.02610v1"}
{"created":"2023-04-05","title":"A Checklist to Publish Collections as Data in GLAM Institutions","abstract":"Large-scale digitization in Galleries, Libraries, Archives and Museums (GLAM) created the conditions for providing access to collections as data. It opened new opportunities to explore, use and reuse digital collections. Strong proponents of collections as data are the Innovation Labs which provided numerous examples of publishing datasets under open licenses in order to reuse digital content in novel and creative ways. Within the current transition to the emerging data spaces, clouds for cultural heritage and open science, the need to identify practices which support more GLAM institutions to offer datasets becomes a priority, especially within the smaller and medium-sized institutions.   This paper answers the need to support GLAM institutions in facilitating the transition into publishing their digital content and to introduce collections as data services; this will also help their future efficient contribution to data spaces and cultural heritage clouds. It offers a checklist that can be used for both creating and evaluating digital collections suitable for computational use. The main contributions of this paper are i) a methodology for devising a checklist to create and assess digital collections for computational use; ii) a checklist to create and assess digital collections suitable for use with computational methods; iii) the assessment of the checklist against the practice of institutions innovating in the Collections as data field; and iv) the results obtained after the application and recommendations for the use of the checklist in GLAM institutions.","sentences":["Large-scale digitization in Galleries, Libraries, Archives and Museums (GLAM) created the conditions for providing access to collections as data.","It opened new opportunities to explore, use and reuse digital collections.","Strong proponents of collections as data are the Innovation Labs which provided numerous examples of publishing datasets under open licenses in order to reuse digital content in novel and creative ways.","Within the current transition to the emerging data spaces, clouds for cultural heritage and open science, the need to identify practices which support more GLAM institutions to offer datasets becomes a priority, especially within the smaller and medium-sized institutions.   ","This paper answers the need to support GLAM institutions in facilitating the transition into publishing their digital content and to introduce collections as data services; this will also help their future efficient contribution to data spaces and cultural heritage clouds.","It offers a checklist that can be used for both creating and evaluating digital collections suitable for computational use.","The main contributions of this paper are i) a methodology for devising a checklist to create and assess digital collections for computational use; ii) a checklist to create and assess digital collections suitable for use with computational methods; iii) the assessment of the checklist against the practice of institutions innovating in the Collections as data field; and iv) the results obtained after the application and recommendations for the use of the checklist in GLAM institutions."],"url":"http://arxiv.org/abs/2304.02603v1"}
{"created":"2023-04-05","title":"ECG Feature Importance Rankings: Cardiologists vs. Algorithms","abstract":"Feature importance methods promise to provide a ranking of features according to importance for a given classification task. A wide range of methods exist but their rankings often disagree and they are inherently difficult to evaluate due to a lack of ground truth beyond synthetic datasets. In this work, we put feature importance methods to the test on real-world data in the domain of cardiology, where we try to distinguish three specific pathologies from healthy subjects based on ECG features comparing to features used in cardiologists' decision rules as ground truth. Some methods generally performed well and others performed poorly, while some methods did well on some but not all of the problems considered.","sentences":["Feature importance methods promise to provide a ranking of features according to importance for a given classification task.","A wide range of methods exist but their rankings often disagree and they are inherently difficult to evaluate due to a lack of ground truth beyond synthetic datasets.","In this work, we put feature importance methods to the test on real-world data in the domain of cardiology, where we try to distinguish three specific pathologies from healthy subjects based on ECG features comparing to features used in cardiologists' decision rules as ground truth.","Some methods generally performed well and others performed poorly, while some methods did well on some but not all of the problems considered."],"url":"http://arxiv.org/abs/2304.02577v1"}
{"created":"2023-04-05","title":"DEFLOW: Self-supervised 3D Motion Estimation of Debris Flow","abstract":"Existing work on scene flow estimation focuses on autonomous driving and mobile robotics, while automated solutions are lacking for motion in nature, such as that exhibited by debris flows. We propose DEFLOW, a model for 3D motion estimation of debris flows, together with a newly captured dataset. We adopt a novel multi-level sensor fusion architecture and self-supervision to incorporate the inductive biases of the scene. We further adopt a multi-frame temporal processing module to enable flow speed estimation over time. Our model achieves state-of-the-art optical flow and depth estimation on our dataset, and fully automates the motion estimation for debris flows. The source code and dataset are available at project page.","sentences":["Existing work on scene flow estimation focuses on autonomous driving and mobile robotics, while automated solutions are lacking for motion in nature, such as that exhibited by debris flows.","We propose DEFLOW, a model for 3D motion estimation of debris flows, together with a newly captured dataset.","We adopt a novel multi-level sensor fusion architecture and self-supervision to incorporate the inductive biases of the scene.","We further adopt a multi-frame temporal processing module to enable flow speed estimation over time.","Our model achieves state-of-the-art optical flow and depth estimation on our dataset, and fully automates the motion estimation for debris flows.","The source code and dataset are available at project page."],"url":"http://arxiv.org/abs/2304.02569v1"}
{"created":"2023-04-05","title":"Detecting and Grounding Multi-Modal Media Manipulation","abstract":"Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various deepfake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM^4). DGM^4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content (i.e., image bounding boxes and text tokens), which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER performs 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of our model; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation.","sentences":["Misinformation has become a pressing issue.","Fake media, in both visual and textual forms, is widespread on the web.","While various deepfake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities.","In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM^4).","DGM^4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content (i.e., image bounding boxes and text tokens), which requires deeper reasoning of multi-modal media manipulation.","To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations.","Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities.","HAMMER performs 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning.","Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information.","Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem.","Comprehensive experiments demonstrate the superiority of our model; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation."],"url":"http://arxiv.org/abs/2304.02556v1"}
{"created":"2023-04-05","title":"Human-like Summarization Evaluation with ChatGPT","abstract":"Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory. In this study, we explored ChatGPT's ability to perform human-like summarization evaluation using four human evaluation methods on five datasets. We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation. Additionally, it outperformed commonly used automatic evaluation metrics on some datasets. Furthermore, we discussed the impact of different prompts, compared its performance with that of human evaluation, and analyzed the generated explanations and invalid responses.","sentences":["Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory.","In this study, we explored ChatGPT's ability to perform human-like summarization evaluation using four human evaluation methods on five datasets.","We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation.","Additionally, it outperformed commonly used automatic evaluation metrics on some datasets.","Furthermore, we discussed the impact of different prompts, compared its performance with that of human evaluation, and analyzed the generated explanations and invalid responses."],"url":"http://arxiv.org/abs/2304.02554v1"}
{"created":"2023-04-05","title":"Goal-Conditioned Imitation Learning using Score-based Diffusion Policies","abstract":"We propose a new policy representation based on score-based diffusion models (SDMs). We apply our new policy representation in the domain of Goal-Conditioned Imitation Learning (GCIL) to learn general-purpose goal-specified policies from large uncurated datasets without rewards. Our new goal-conditioned policy architecture \"$\\textbf{BE}$havior generation with $\\textbf{S}$c$\\textbf{O}$re-based Diffusion Policies\" (BESO) leverages a generative, score-based diffusion model as its policy. BESO decouples the learning of the score model from the inference sampling process, and, hence allows for fast sampling strategies to generate goal-specified behavior in just 3 denoising steps, compared to 30+ steps of other diffusion based policies. Furthermore, BESO is highly expressive and can effectively capture multi-modality present in the solution space of the play data. Unlike previous methods such as Latent Plans or C-Bet, BESO does not rely on complex hierarchical policies or additional clustering for effective goal-conditioned behavior learning. Finally, we show how BESO can even be used to learn a goal-independent policy from play-data using classifier-free guidance. To the best of our knowledge this is the first work that a) represents a behavior policy based on such a decoupled SDM b) learns an SDM based policy in the domain of GCIL and c) provides a way to simultaneously learn a goal-dependent and a goal-independent policy from play-data. We evaluate BESO through detailed simulation and show that it consistently outperforms several state-of-the-art goal-conditioned imitation learning methods on challenging benchmarks. We additionally provide extensive ablation studies and experiments to demonstrate the effectiveness of our method for effective goal-conditioned behavior generation.","sentences":["We propose a new policy representation based on score-based diffusion models (SDMs).","We apply our new policy representation in the domain of Goal-Conditioned Imitation Learning (GCIL) to learn general-purpose goal-specified policies from large uncurated datasets without rewards.","Our new goal-conditioned policy architecture \"$\\textbf{BE}$havior generation with $\\textbf{S}$c$\\textbf{O}$re-based Diffusion Policies\" (BESO) leverages a generative, score-based diffusion model as its policy.","BESO decouples the learning of the score model from the inference sampling process, and, hence allows for fast sampling strategies to generate goal-specified behavior in just 3 denoising steps, compared to 30+ steps of other diffusion based policies.","Furthermore, BESO is highly expressive and can effectively capture multi-modality present in the solution space of the play data.","Unlike previous methods such as Latent Plans or C-Bet, BESO does not rely on complex hierarchical policies or additional clustering for effective goal-conditioned behavior learning.","Finally, we show how BESO can even be used to learn a goal-independent policy from play-data using classifier-free guidance.","To the best of our knowledge this is the first work that a) represents a behavior policy based on such a decoupled SDM b) learns an SDM based policy in the domain of GCIL and c) provides a way to simultaneously learn a goal-dependent and a goal-independent policy from play-data.","We evaluate BESO through detailed simulation and show that it consistently outperforms several state-of-the-art goal-conditioned imitation learning methods on challenging benchmarks.","We additionally provide extensive ablation studies and experiments to demonstrate the effectiveness of our method for effective goal-conditioned behavior generation."],"url":"http://arxiv.org/abs/2304.02532v1"}
{"created":"2023-04-05","title":"Learning to Compare Longitudinal Images","abstract":"Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications. The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing. Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level. This classical approach can suffer from pre-processing issues and limitations of the statistical modeling. For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes. In this paper, we present a simple machine learning-based approach that can alleviate these issues. In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or without supervision. In the self-supervised setup, for instance, the model is trained to temporally order the images, which requires learning to recognize time-irreversible changes. Our results from four datasets demonstrate that PaIRNet can be very effective in localizing and quantifying meaningful longitudinal changes while discounting nuisance variation. Our code is available at \\url{https://github.com/heejong-kim/learning-to-compare-longitudinal-images.git}","sentences":["Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications.","The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing.","Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level.","This classical approach can suffer from pre-processing issues and limitations of the statistical modeling.","For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes.","In this paper, we present a simple machine learning-based approach that can alleviate these issues.","In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or without supervision.","In the self-supervised setup, for instance, the model is trained to temporally order the images, which requires learning to recognize time-irreversible changes.","Our results from four datasets demonstrate that PaIRNet can be very effective in localizing and quantifying meaningful longitudinal changes while discounting nuisance variation.","Our code is available at \\url{https://github.com/heejong-kim/learning-to-compare-longitudinal-images.git}"],"url":"http://arxiv.org/abs/2304.02531v1"}
{"created":"2023-04-05","title":"SCB-dataset: A Dataset for Detecting Student Classroom Behavior","abstract":"The use of deep learning methods for automatic detection of students' classroom behavior is a promising approach to analyze their class performance and enhance teaching effectiveness. However, the lack of publicly available datasets on student behavior poses a challenge for researchers in this field. To address this issue, we propose a Student Classroom Behavior dataset (SCB-dataset) that reflects real-life scenarios. Our dataset includes 11,248 labels and 4,003 images, with a focus on hand-raising behavior. We evaluated the dataset using the YOLOv7 algorithm, achieving a mean average precision (map) of up to 85.3%. We believe that our dataset can serve as a robust foundation for future research in the field of student behavior detection and promote further advancements in this area.Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset","sentences":["The use of deep learning methods for automatic detection of students' classroom behavior is a promising approach to analyze their class performance and enhance teaching effectiveness.","However, the lack of publicly available datasets on student behavior poses a challenge for researchers in this field.","To address this issue, we propose a Student Classroom Behavior dataset (SCB-dataset) that reflects real-life scenarios.","Our dataset includes 11,248 labels and 4,003 images, with a focus on hand-raising behavior.","We evaluated the dataset using the YOLOv7 algorithm, achieving a mean average precision (map) of up to 85.3%.","We believe that our dataset can serve as a robust foundation for future research in the field of student behavior detection and promote further advancements in this area.","Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset"],"url":"http://arxiv.org/abs/2304.02488v1"}
{"created":"2023-04-05","title":"Checking the reliability of opacity databases","abstract":"Mathematical inequalities, combined with atomic-physics sum rules, enable one to derive lower and upper bounds for the Rosseland and/or Planck mean opacities. The resulting constraints must be satisfied, either for pure elements or mixtures. The intriguing law of anomalous numbers, also named Benford's law, is of great interest to detect errors in line-strength collections required for fine-structure calculations. Testing regularities may reveal hidden properties, such as the fractal nature of complex atomic spectra. The aforementioned constraints can also be useful to assess the reliability of experimental measurements. Finally, we recall that it is important to quantify the uncertainties due to interpolations in density-temperature opacity (or more generally atomic-data) tables, and that convergence studies are of course unavoidable in order to address the issue of completeness in terms of levels, configurations or superconfigurations, which is a cornerstone of opacity calculations.","sentences":["Mathematical inequalities, combined with atomic-physics sum rules, enable one to derive lower and upper bounds for the Rosseland and/or Planck mean opacities.","The resulting constraints must be satisfied, either for pure elements or mixtures.","The intriguing law of anomalous numbers, also named Benford's law, is of great interest to detect errors in line-strength collections required for fine-structure calculations.","Testing regularities may reveal hidden properties, such as the fractal nature of complex atomic spectra.","The aforementioned constraints can also be useful to assess the reliability of experimental measurements.","Finally, we recall that it is important to quantify the uncertainties due to interpolations in density-temperature opacity (or more generally atomic-data) tables, and that convergence studies are of course unavoidable in order to address the issue of completeness in terms of levels, configurations or superconfigurations, which is a cornerstone of opacity calculations."],"url":"http://arxiv.org/abs/2304.02469v1"}
{"created":"2023-04-05","title":"Selecting Features by their Resilience to the Curse of Dimensionality","abstract":"Real-world datasets are often of high dimension and effected by the curse of dimensionality. This hinders their comprehensibility and interpretability. To reduce the complexity feature selection aims to identify features that are crucial to learn from said data. While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features. Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes. By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality. Our experiments show that our method is competitive and commonly outperforms established feature selection methods. Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points. Our findings suggest that features that discriminate data and are connected to a low intrinsic dimensionality are meaningful for learning procedures.","sentences":["Real-world datasets are often of high dimension and effected by the curse of dimensionality.","This hinders their comprehensibility and interpretability.","To reduce the complexity feature selection aims to identify features that are crucial to learn from said data.","While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features.","Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes.","By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality.","Our experiments show that our method is competitive and commonly outperforms established feature selection methods.","Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points.","Our findings suggest that features that discriminate data and are connected to a low intrinsic dimensionality are meaningful for learning procedures."],"url":"http://arxiv.org/abs/2304.02455v1"}
{"created":"2023-04-05","title":"MS3D: Leveraging Multiple Detectors for Unsupervised Domain Adaptation in 3D Object Detection","abstract":"We introduce Multi-Source 3D (MS3D), a new self-training pipeline for unsupervised domain adaptation in 3D object detection. Despite the remarkable accuracy of 3D detectors, they often overfit to specific domain biases, leading to suboptimal performance in various sensor setups and environments. Existing methods typically focus on adapting a single detector to the target domain, overlooking the fact that different detectors possess distinct expertise on different unseen domains. MS3D leverages this by combining different pre-trained detectors from multiple source domains and incorporating temporal information to produce high-quality pseudo-labels for fine-tuning. Our proposed Kernel-Density Estimation (KDE) Box Fusion method fuses box proposals from multiple domains to obtain pseudo-labels that surpass the performance of the best source domain detectors. MS3D exhibits greater robustness to domain shifts and produces accurate pseudo-labels over greater distances, making it well-suited for high-to-low beam domain adaptation and vice versa. Our method achieved state-of-the-art performance on all evaluated datasets, and we demonstrate that the choice of pre-trained source detectors has minimal impact on the self-training result, making MS3D suitable for real-world applications.","sentences":["We introduce Multi-Source 3D (MS3D), a new self-training pipeline for unsupervised domain adaptation in 3D object detection.","Despite the remarkable accuracy of 3D detectors, they often overfit to specific domain biases, leading to suboptimal performance in various sensor setups and environments.","Existing methods typically focus on adapting a single detector to the target domain, overlooking the fact that different detectors possess distinct expertise on different unseen domains.","MS3D leverages this by combining different pre-trained detectors from multiple source domains and incorporating temporal information to produce high-quality pseudo-labels for fine-tuning.","Our proposed Kernel-Density Estimation (KDE) Box Fusion method fuses box proposals from multiple domains to obtain pseudo-labels that surpass the performance of the best source domain detectors.","MS3D exhibits greater robustness to domain shifts and produces accurate pseudo-labels over greater distances, making it well-suited for high-to-low beam domain adaptation and vice versa.","Our method achieved state-of-the-art performance on all evaluated datasets, and we demonstrate that the choice of pre-trained source detectors has minimal impact on the self-training result, making MS3D suitable for real-world applications."],"url":"http://arxiv.org/abs/2304.02431v1"}
{"created":"2023-04-05","title":"ParroT: Translating During Chat Using Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human. Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning. Codes: https://github.com/wxjiao/ParroT","sentences":["Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat.","However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field.","Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data.","Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process.","Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction.","Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human.","Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning.","Codes: https://github.com/wxjiao/ParroT"],"url":"http://arxiv.org/abs/2304.02426v2"}
{"created":"2023-04-05","title":"TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration","abstract":"We propose a novel task for generating 3D dance movements that simultaneously incorporate both text and music modalities. Unlike existing works that generate dance movements using a single modality such as music, our goal is to produce richer dance movements guided by the instructive information provided by the text. However, the lack of paired motion data with both music and text modalities limits the ability to generate dance movements that integrate both. To alleviate this challenge, we propose to utilize a 3D human motion VQ-VAE to project the motions of the two datasets into a latent space consisting of quantized vectors, which effectively mix the motion tokens from the two datasets with different distributions for training. Additionally, we propose a cross-modal transformer to integrate text instructions into motion generation architecture for generating 3D dance movements without degrading the performance of music-conditioned dance generation. To better evaluate the quality of the generated motion, we introduce two novel metrics, namely Motion Prediction Distance (MPD) and Freezing Score, to measure the coherence and freezing percentage of the generated motion. Extensive experiments show that our approach can generate realistic and coherent dance movements conditioned on both text and music while maintaining comparable performance with the two single modalities. Code will be available at: https://garfield-kh.github.io/TM2D/.","sentences":["We propose a novel task for generating 3D dance movements that simultaneously incorporate both text and music modalities.","Unlike existing works that generate dance movements using a single modality such as music, our goal is to produce richer dance movements guided by the instructive information provided by the text.","However, the lack of paired motion data with both music and text modalities limits the ability to generate dance movements that integrate both.","To alleviate this challenge, we propose to utilize a 3D human motion VQ-VAE to project the motions of the two datasets into a latent space consisting of quantized vectors, which effectively mix the motion tokens from the two datasets with different distributions for training.","Additionally, we propose a cross-modal transformer to integrate text instructions into motion generation architecture for generating 3D dance movements without degrading the performance of music-conditioned dance generation.","To better evaluate the quality of the generated motion, we introduce two novel metrics, namely Motion Prediction Distance (MPD) and Freezing Score, to measure the coherence and freezing percentage of the generated motion.","Extensive experiments show that our approach can generate realistic and coherent dance movements conditioned on both text and music while maintaining comparable performance with the two single modalities.","Code will be available at: https://garfield-kh.github.io/TM2D/."],"url":"http://arxiv.org/abs/2304.02419v1"}
{"created":"2023-04-05","title":"Quiz-based Knowledge Tracing","abstract":"Knowledge tracing (KT) aims to assess individuals' evolving knowledge states according to their learning interactions with different exercises in online learning systems (OIS), which is critical in supporting decision-making for subsequent intelligent services, such as personalized learning source recommendation. Existing researchers have broadly studied KT and developed many effective methods. However, most of them assume that students' historical interactions are uniformly distributed in a continuous sequence, ignoring the fact that actual interaction sequences are organized based on a series of quizzes with clear boundaries, where interactions within a quiz are consecutively completed, but interactions across different quizzes are discrete and may be spaced over days. In this paper, we present the Quiz-based Knowledge Tracing (QKT) model to monitor students' knowledge states according to their quiz-based learning interactions. Specifically, as students' interactions within a quiz are continuous and have the same or similar knowledge concepts, we design the adjacent gate followed by a global average pooling layer to capture the intra-quiz short-term knowledge influence. Then, as various quizzes tend to focus on different knowledge concepts, we respectively measure the inter-quiz knowledge substitution by the gated recurrent unit and the inter-quiz knowledge complementarity by the self-attentive encoder with a novel recency-aware attention mechanism. Finally, we integrate the inter-quiz long-term knowledge substitution and complementarity across different quizzes to output students' evolving knowledge states. Extensive experimental results on three public real-world datasets demonstrate that QKT achieves state-of-the-art performance compared to existing methods. Further analyses confirm that QKT is promising in designing more effective quizzes.","sentences":["Knowledge tracing (KT) aims to assess individuals' evolving knowledge states according to their learning interactions with different exercises in online learning systems (OIS), which is critical in supporting decision-making for subsequent intelligent services, such as personalized learning source recommendation.","Existing researchers have broadly studied KT and developed many effective methods.","However, most of them assume that students' historical interactions are uniformly distributed in a continuous sequence, ignoring the fact that actual interaction sequences are organized based on a series of quizzes with clear boundaries, where interactions within a quiz are consecutively completed, but interactions across different quizzes are discrete and may be spaced over days.","In this paper, we present the Quiz-based Knowledge Tracing (QKT) model to monitor students' knowledge states according to their quiz-based learning interactions.","Specifically, as students' interactions within a quiz are continuous and have the same or similar knowledge concepts, we design the adjacent gate followed by a global average pooling layer to capture the intra-quiz short-term knowledge influence.","Then, as various quizzes tend to focus on different knowledge concepts, we respectively measure the inter-quiz knowledge substitution by the gated recurrent unit and the inter-quiz knowledge complementarity by the self-attentive encoder with a novel recency-aware attention mechanism.","Finally, we integrate the inter-quiz long-term knowledge substitution and complementarity across different quizzes to output students' evolving knowledge states.","Extensive experimental results on three public real-world datasets demonstrate that QKT achieves state-of-the-art performance compared to existing methods.","Further analyses confirm that QKT is promising in designing more effective quizzes."],"url":"http://arxiv.org/abs/2304.02413v2"}
{"created":"2023-04-05","title":"PrivGraph: Differentially Private Graph Data Publication by Exploiting Community Information","abstract":"Graph data is used in a wide range of applications, while analyzing graph data without protection is prone to privacy breach risks. To mitigate the privacy risks, we resort to the standard technique of differential privacy to publish a synthetic graph. However, existing differentially private graph synthesis approaches either introduce excessive noise by directly perturbing the adjacency matrix, or suffer significant information loss during the graph encoding process. In this paper, we propose an effective graph synthesis algorithm PrivGraph by exploiting the community information. Concretely, PrivGraph differentially privately partitions the private graph into communities, extracts intra-community and inter-community information, and reconstructs the graph from the extracted graph information. We validate the effectiveness of PrivGraph on six real-world graph datasets and seven commonly used graph metrics.","sentences":["Graph data is used in a wide range of applications, while analyzing graph data without protection is prone to privacy breach risks.","To mitigate the privacy risks, we resort to the standard technique of differential privacy to publish a synthetic graph.","However, existing differentially private graph synthesis approaches either introduce excessive noise by directly perturbing the adjacency matrix, or suffer significant information loss during the graph encoding process.","In this paper, we propose an effective graph synthesis algorithm PrivGraph by exploiting the community information.","Concretely, PrivGraph differentially privately partitions the private graph into communities, extracts intra-community and inter-community information, and reconstructs the graph from the extracted graph information.","We validate the effectiveness of PrivGraph on six real-world graph datasets and seven commonly used graph metrics."],"url":"http://arxiv.org/abs/2304.02401v1"}
{"created":"2023-04-05","title":"How good Neural Networks interpretation methods really are? A quantitative benchmark","abstract":"Saliency Maps (SMs) have been extensively used to interpret deep learning models decision by highlighting the features deemed relevant by the model. They are used on highly nonlinear problems, where linear feature selection (FS) methods fail at highlighting relevant explanatory variables. However, the reliability of gradient-based feature attribution methods such as SM has mostly been only qualitatively (visually) assessed, and quantitative benchmarks are currently missing, partially due to the lack of a definite ground truth on image data. Concerned about the apophenic biases introduced by visual assessment of these methods, in this paper we propose a synthetic quantitative benchmark for Neural Networks (NNs) interpretation methods. For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings. We also compare these methods to conventional approaches such as mRMR or Random Forests. Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods. TreeShap, mRMR and LassoNet are the best performing FS methods. We also show that, when quantifying the relevance of a few non linearly-entangled predictive features diluted in a large number of irrelevant noisy variables, neural network-based FS and interpretation methods are still far from being reliable.","sentences":["Saliency Maps (SMs) have been extensively used to interpret deep learning models decision by highlighting the features deemed relevant by the model.","They are used on highly nonlinear problems, where linear feature selection (FS) methods fail at highlighting relevant explanatory variables.","However, the reliability of gradient-based feature attribution methods such as SM has mostly been only qualitatively (visually) assessed, and quantitative benchmarks are currently missing, partially due to the lack of a definite ground truth on image data.","Concerned about the apophenic biases introduced by visual assessment of these methods, in this paper we propose a synthetic quantitative benchmark for Neural Networks (NNs) interpretation methods.","For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings.","We also compare these methods to conventional approaches such as mRMR or Random Forests.","Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods.","TreeShap, mRMR and LassoNet are the best performing FS methods.","We also show that, when quantifying the relevance of a few non linearly-entangled predictive features diluted in a large number of irrelevant noisy variables, neural network-based FS and interpretation methods are still far from being reliable."],"url":"http://arxiv.org/abs/2304.02383v1"}
{"created":"2023-04-05","title":"What's in a Name? Beyond Class Indices for Image Recognition","abstract":"Existing machine learning models demonstrate excellent performance in image object recognition after training on a large-scale dataset under full supervision. However, these models only learn to map an image to a predefined class index, without revealing the actual semantic meaning of the object in the image. In contrast, vision-language models like CLIP are able to assign semantic class names to unseen objects in a `zero-shot' manner, although they still rely on a predefined set of candidate names at test time. In this paper, we reconsider the recognition problem and task a vision-language model to assign class names to images given only a large and essentially unconstrained vocabulary of categories as prior information. We use non-parametric methods to establish relationships between images which allow the model to automatically narrow down the set of possible candidate names. Specifically, we propose iteratively clustering the data and voting on class names within them, showing that this enables a roughly 50\\% improvement over the baseline on ImageNet. Furthermore, we tackle this problem both in unsupervised and partially supervised settings, as well as with a coarse-grained and fine-grained search space as the unconstrained dictionary.","sentences":["Existing machine learning models demonstrate excellent performance in image object recognition after training on a large-scale dataset under full supervision.","However, these models only learn to map an image to a predefined class index, without revealing the actual semantic meaning of the object in the image.","In contrast, vision-language models like CLIP are able to assign semantic class names to unseen objects in a `zero-shot' manner, although they still rely on a predefined set of candidate names at test time.","In this paper, we reconsider the recognition problem and task a vision-language model to assign class names to images given only a large and essentially unconstrained vocabulary of categories as prior information.","We use non-parametric methods to establish relationships between images which allow the model to automatically narrow down the set of possible candidate names.","Specifically, we propose iteratively clustering the data and voting on class names within them, showing that this enables a roughly 50\\% improvement over the baseline on ImageNet.","Furthermore, we tackle this problem both in unsupervised and partially supervised settings, as well as with a coarse-grained and fine-grained search space as the unconstrained dictionary."],"url":"http://arxiv.org/abs/2304.02364v1"}
{"created":"2023-04-05","title":"Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net","abstract":"Radiotherapy (RT) is a key component in the treatment of various cancers, including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia (AML). Precise delineation of organs at risk (OARs) and target areas is essential for effective treatment planning. Intensity Modulated Radiotherapy (IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow and Lymph node Irradiation (TMLI), provide more precise radiation delivery compared to Total Body Irradiation (TBI). However, these techniques require time-consuming manual segmentation of structures in Computerized Tomography (CT) scans by the Radiation Oncologist (RO). In this paper, we present a deep learning-based auto-contouring method for segmenting Planning Target Volume (PTV) for TMLI treatment using the U-Net architecture. We trained and compared two segmentation models with two different loss functions on a dataset of 100 patients treated with TMLI at the Humanitas Research Hospital between 2011 and 2021. Despite challenges in lymph node areas, the best model achieved an average Dice score of 0.816 for PTV segmentation. Our findings are a preliminary but significant step towards developing a segmentation model that has the potential to save radiation oncologists a considerable amount of time. This could allow for the treatment of more patients, resulting in improved clinical practice efficiency and more reproducible contours.","sentences":["Radiotherapy (RT) is a key component in the treatment of various cancers, including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia (AML).","Precise delineation of organs at risk (OARs) and target areas is essential for effective treatment planning.","Intensity Modulated Radiotherapy (IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow and Lymph node Irradiation (TMLI), provide more precise radiation delivery compared to Total Body Irradiation (TBI).","However, these techniques require time-consuming manual segmentation of structures in Computerized Tomography (CT) scans by the Radiation Oncologist (RO).","In this paper, we present a deep learning-based auto-contouring method for segmenting Planning Target Volume (PTV) for TMLI treatment using the U-Net architecture.","We trained and compared two segmentation models with two different loss functions on a dataset of 100 patients treated with TMLI at the Humanitas Research Hospital between 2011 and 2021.","Despite challenges in lymph node areas, the best model achieved an average Dice score of 0.816 for PTV segmentation.","Our findings are a preliminary but significant step towards developing a segmentation model that has the potential to save radiation oncologists a considerable amount of time.","This could allow for the treatment of more patients, resulting in improved clinical practice efficiency and more reproducible contours."],"url":"http://arxiv.org/abs/2304.02353v1"}
{"created":"2023-04-05","title":"Self-supervised 3D Human Pose Estimation from a Single Image","abstract":"We propose a new self-supervised method for predicting 3D human body pose from a single image. The prediction network is trained from a dataset of unlabelled images depicting people in typical poses and a set of unpaired 2D poses. By minimising the need for annotated data, the method has the potential for rapid application to pose estimation of other articulated structures (e.g. animals). The self-supervision comes from an earlier idea exploiting consistency between predicted pose under 3D rotation. Our method is a substantial advance on state-of-the-art self-supervised methods in training a mapping directly from images, without limb articulation constraints or any 3D empirical pose prior. We compare performance with state-of-the-art self-supervised methods using benchmark datasets that provide images and ground-truth 3D pose (Human3.6M, MPI-INF-3DHP). Despite the reduced requirement for annotated data, we show that the method outperforms on Human3.6M and matches performance on MPI-INF-3DHP. Qualitative results on a dataset of human hands show the potential for rapidly learning to predict 3D pose for articulated structures other than the human body.","sentences":["We propose a new self-supervised method for predicting 3D human body pose from a single image.","The prediction network is trained from a dataset of unlabelled images depicting people in typical poses and a set of unpaired 2D poses.","By minimising the need for annotated data, the method has the potential for rapid application to pose estimation of other articulated structures (e.g. animals).","The self-supervision comes from an earlier idea exploiting consistency between predicted pose under 3D rotation.","Our method is a substantial advance on state-of-the-art self-supervised methods in training a mapping directly from images, without limb articulation constraints or any 3D empirical pose prior.","We compare performance with state-of-the-art self-supervised methods using benchmark datasets that provide images and ground-truth 3D pose (Human3.6M, MPI-INF-3DHP).","Despite the reduced requirement for annotated data, we show that the method outperforms on Human3.6M and matches performance on MPI-INF-3DHP.","Qualitative results on a dataset of human hands show the potential for rapidly learning to predict 3D pose for articulated structures other than the human body."],"url":"http://arxiv.org/abs/2304.02349v1"}
{"created":"2023-04-05","title":"FASTAGEDS: Fast Approximate Graph Entity Dependency Discovery","abstract":"This paper studies the discovery of approximate rules in property graphs. We propose a semantically meaningful measure of error for mining graph entity dependencies (GEDs) at almost hold, to tolerate errors and inconsistencies that exist in real-world graphs. We present a new characterisation of GED satisfaction, and devise a depth-first search strategy to traverse the search space of candidate rules efficiently. Further, we perform experiments to demonstrate the feasibility and scalability of our solution, FASTAGEDS, with three real-world graphs.","sentences":["This paper studies the discovery of approximate rules in property graphs.","We propose a semantically meaningful measure of error for mining graph entity dependencies (GEDs) at almost hold, to tolerate errors and inconsistencies that exist in real-world graphs.","We present a new characterisation of GED satisfaction, and devise a depth-first search strategy to traverse the search space of candidate rules efficiently.","Further, we perform experiments to demonstrate the feasibility and scalability of our solution, FASTAGEDS, with three real-world graphs."],"url":"http://arxiv.org/abs/2304.02323v1"}
{"created":"2023-04-05","title":"Few-shot Semantic Image Synthesis with Class Affinity Transfer","abstract":"Semantic image synthesis aims to generate photo realistic images given a semantic segmentation map. Despite much recent progress, training them still requires large datasets of images annotated with per-pixel label maps that are extremely tedious to obtain. To alleviate the high annotation cost, we propose a transfer method that leverages a model trained on a large source dataset to improve the learning ability on small target datasets via estimated pairwise relations between source and target classes. The class affinity matrix is introduced as a first layer to the source model to make it compatible with the target label maps, and the source model is then further finetuned for the target domain. To estimate the class affinities we consider different approaches to leverage prior knowledge: semantic segmentation on the source domain, textual label embeddings, and self-supervised vision features. We apply our approach to GAN-based and diffusion-based architectures for semantic synthesis. Our experiments show that the different ways to estimate class affinity can be effectively combined, and that our approach significantly improves over existing state-of-the-art transfer approaches for generative image models.","sentences":["Semantic image synthesis aims to generate photo realistic images given a semantic segmentation map.","Despite much recent progress, training them still requires large datasets of images annotated with per-pixel label maps that are extremely tedious to obtain.","To alleviate the high annotation cost, we propose a transfer method that leverages a model trained on a large source dataset to improve the learning ability on small target datasets via estimated pairwise relations between source and target classes.","The class affinity matrix is introduced as a first layer to the source model to make it compatible with the target label maps, and the source model is then further finetuned for the target domain.","To estimate the class affinities we consider different approaches to leverage prior knowledge: semantic segmentation on the source domain, textual label embeddings, and self-supervised vision features.","We apply our approach to GAN-based and diffusion-based architectures for semantic synthesis.","Our experiments show that the different ways to estimate class affinity can be effectively combined, and that our approach significantly improves over existing state-of-the-art transfer approaches for generative image models."],"url":"http://arxiv.org/abs/2304.02321v1"}
{"created":"2023-04-05","title":"Efficient CNNs via Passive Filter Pruning","abstract":"Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications. However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage. Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters. The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data. Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance. To address this, we present a passive filter pruning method where the filters are pruned based on their contribution in producing output by considering the operator norm of the filters. The proposed pruning method generalizes better across various CNNs compared to that of the entry-wise norm-based pruning methods. In comparison to the existing active filter pruning methods, the proposed pruning method is at least 4.5 times faster in computing filter importance and is able to achieve similar performance compared to that of the active filter pruning methods. The efficacy of the proposed pruning method is evaluated on audio scene classification and image classification using various CNNs architecture such as VGGish, DCASE21_Net, VGG-16 and ResNet-50.","sentences":["Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications.","However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage.","Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters.","The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data.","Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance.","To address this, we present a passive filter pruning method where the filters are pruned based on their contribution in producing output by considering the operator norm of the filters.","The proposed pruning method generalizes better across various CNNs compared to that of the entry-wise norm-based pruning methods.","In comparison to the existing active filter pruning methods, the proposed pruning method is at least 4.5 times faster in computing filter importance and is able to achieve similar performance compared to that of the active filter pruning methods.","The efficacy of the proposed pruning method is evaluated on audio scene classification and image classification using various CNNs architecture such as VGGish, DCASE21_Net, VGG-16 and ResNet-50."],"url":"http://arxiv.org/abs/2304.02319v1"}
{"created":"2023-04-05","title":"Personality-aware Human-centric Multimodal Reasoning: A New Task","abstract":"Multimodal reasoning, an area of artificial intelligence that aims at make inferences from multimodal signals such as vision, language and speech, has drawn more and more attention in recent years. People with different personalities may respond differently to the same situation. However, such individual personalities were ignored in the previous studies. In this work, we introduce a new Personality-aware Human-centric Multimodal Reasoning (Personality-aware HMR) task, and accordingly construct a new dataset based on The Big Bang Theory television shows, to predict the behavior of a specific person at a specific moment, given the multimodal information of its past and future moments. The Myers-Briggs Type Indicator (MBTI) was annotated and utilized in the task to represent individuals' personalities. We benchmark the task by proposing three baseline methods, two were adapted from the related tasks and one was newly proposed for our task. The experimental results demonstrate that personality can effectively improve the performance of human-centric multimodal reasoning. To further solve the lack of personality annotation in real-life scenes, we introduce an extended task called Personality-predicted HMR, and propose the corresponding methods, to predict the MBTI personality at first, and then use the predicted personality to help multimodal reasoning. The experimental results show that our method can accurately predict personality and achieves satisfactory multimodal reasoning performance without relying on personality annotations.","sentences":["Multimodal reasoning, an area of artificial intelligence that aims at make inferences from multimodal signals such as vision, language and speech, has drawn more and more attention in recent years.","People with different personalities may respond differently to the same situation.","However, such individual personalities were ignored in the previous studies.","In this work, we introduce a new Personality-aware Human-centric Multimodal Reasoning (Personality-aware HMR) task, and accordingly construct a new dataset based on The Big Bang Theory television shows, to predict the behavior of a specific person at a specific moment, given the multimodal information of its past and future moments.","The Myers-Briggs Type Indicator (MBTI) was annotated and utilized in the task to represent individuals' personalities.","We benchmark the task by proposing three baseline methods, two were adapted from the related tasks and one was newly proposed for our task.","The experimental results demonstrate that personality can effectively improve the performance of human-centric multimodal reasoning.","To further solve the lack of personality annotation in real-life scenes, we introduce an extended task called Personality-predicted HMR, and propose the corresponding methods, to predict the MBTI personality at first, and then use the predicted personality to help multimodal reasoning.","The experimental results show that our method can accurately predict personality and achieves satisfactory multimodal reasoning performance without relying on personality annotations."],"url":"http://arxiv.org/abs/2304.02313v1"}
{"created":"2023-04-05","title":"Milky Way globular clusters on cosmological timescales. II. Interaction with the Galactic centre","abstract":"Aims. We estimate the dynamical evolution of the Globular Clusters interaction with the Galactic centre that dynamically changed in the past.   Methods. We simulated the orbits of 147 globular clusters over 10 Gyr lookback time using the parallel N-body code phi-GPU. For each globular cluster, we generated 1000 sets of initial data with random proper motions and radial velocities based on the observed values. To distinguish globular clusters interacting with the galactic centre, we used the criterion of a relative distance of less than 100 pc. We used four external potentials from the IllustrisTNG-100 database, which were selected for their similarity to the present-day Milky Way, to simulate the structure of the Galaxy at different times.   Results. We obtained 3-4 globular cluster interactions per Gyr at distances of less than 50 pc and 5-6 interactions per Gyr at distances of less than 80 pc among the studied 147 globular clusters that had close passages near the Galactic centre. We selected 10 of them for detailed study and found almost 100% probability of interaction with the Galactic centre for six of them.   Conclusions. According to our results, the maximum interaction frequency of globular clusters with the Galactic centre in the Milky Way is likely to be a few dozens of passages per Gyr within a central zone of 100 pc. This low frequency may not be sufficient to fully explain the relatively high mass (of order 10^7 Msol) of the nuclear star cluster in the Milky Way, if we consider only the periodic capture of stars from globular clusters during close encounters. Therefore, we must also consider the possibility that some early globular clusters were completely tidally disrupted during interactions with the forming nuclear star cluster and the Galactic centre.","sentences":["Aims.","We estimate the dynamical evolution of the Globular Clusters interaction with the Galactic centre that dynamically changed in the past.   Methods.","We simulated the orbits of 147 globular clusters over 10 Gyr lookback time using the parallel N-body code phi-GPU.","For each globular cluster, we generated 1000 sets of initial data with random proper motions and radial velocities based on the observed values.","To distinguish globular clusters interacting with the galactic centre, we used the criterion of a relative distance of less than 100 pc.","We used four external potentials from the IllustrisTNG-100 database, which were selected for their similarity to the present-day Milky Way, to simulate the structure of the Galaxy at different times.   Results.","We obtained 3-4 globular cluster interactions per Gyr at distances of less than 50 pc and 5-6 interactions per Gyr at distances of less than 80 pc among the studied 147 globular clusters that had close passages near the Galactic centre.","We selected 10 of them for detailed study and found almost 100% probability of interaction with the Galactic centre for six of them.   Conclusions.","According to our results, the maximum interaction frequency of globular clusters with the Galactic centre in the Milky Way is likely to be a few dozens of passages per Gyr within a central zone of 100 pc.","This low frequency may not be sufficient to fully explain the relatively high mass (of order 10^7 Msol) of the nuclear star cluster in the Milky Way, if we consider only the periodic capture of stars from globular clusters during close encounters.","Therefore, we must also consider the possibility that some early globular clusters were completely tidally disrupted during interactions with the forming nuclear star cluster and the Galactic centre."],"url":"http://arxiv.org/abs/2304.02311v1"}
{"created":"2023-04-05","title":"Extended atomic data for oxygen abundance analyses","abstract":"As the most abundant element in the universe after hydrogen and helium, oxygen plays a key role in planetary, stellar, and galactic astrophysics. Its abundance is especially influential on stellar structure and evolution, and as the dominant opacity contributor at the base of the Sun's convection zone it is central to the discussion around the solar modelling problem. However, abundance analyses require complete and reliable sets of atomic data. We present extensive atomic data for O I, by using the multiconfiguration Dirac-Hartree-Fock and relativistic configuration interaction methods. Lifetimes and transition probabilities for radiative electric dipole transitions are given and compared with results from previous calculations and available measurements. The accuracy of the computed transition rates is evaluated by the differences between the transition rates in Babushkin and Coulomb gauges, as well as by a cancellation factor analysis. Out of the 989 computed transitions in this work, 205 are assigned to the accuracy classes AA-B, that is, with uncertainties less than 10%, following the criteria defined by the National Institute of Standards and Technology Atomic Spectra Database. We discuss the influence of the new log(gf) values on the solar oxygen abundance and ultimately advocate $\\log\\epsilon_{\\mathrm{O}}=8.70\\pm0.04$.","sentences":["As the most abundant element in the universe after hydrogen and helium, oxygen plays a key role in planetary, stellar, and galactic astrophysics.","Its abundance is especially influential on stellar structure and evolution, and as the dominant opacity contributor at the base of the Sun's convection zone it is central to the discussion around the solar modelling problem.","However, abundance analyses require complete and reliable sets of atomic data.","We present extensive atomic data for O I, by using the multiconfiguration Dirac-Hartree-Fock and relativistic configuration interaction methods.","Lifetimes and transition probabilities for radiative electric dipole transitions are given and compared with results from previous calculations and available measurements.","The accuracy of the computed transition rates is evaluated by the differences between the transition rates in Babushkin and Coulomb gauges, as well as by a cancellation factor analysis.","Out of the 989 computed transitions in this work, 205 are assigned to the accuracy classes AA-B, that is, with uncertainties less than 10%, following the criteria defined by the National Institute of Standards and Technology Atomic Spectra Database.","We discuss the influence of the new log(gf) values on the solar oxygen abundance and ultimately advocate $\\log\\epsilon_{\\mathrm{O}}=8.70\\pm0.04$."],"url":"http://arxiv.org/abs/2304.02310v1"}
{"created":"2023-04-05","title":"Multi-Domain Norm-referenced Encoding Enables Data Efficient Transfer Learning of Facial Expression Recognition","abstract":"People can innately recognize human facial expressions in unnatural forms, such as when depicted on the unusual faces drawn in cartoons or when applied to an animal's features. However, current machine learning algorithms struggle with out-of-domain transfer in facial expression recognition (FER). We propose a biologically-inspired mechanism for such transfer learning, which is based on norm-referenced encoding, where patterns are encoded in terms of difference vectors relative to a domain-specific reference vector. By incorporating domain-specific reference frames, we demonstrate high data efficiency in transfer learning across multiple domains. Our proposed architecture provides an explanation for how the human brain might innately recognize facial expressions on varying head shapes (humans, monkeys, and cartoon avatars) without extensive training. Norm-referenced encoding also allows the intensity of the expression to be read out directly from neural unit activity, similar to face-selective neurons in the brain. Our model achieves a classification accuracy of 92.15\\% on the FERG dataset with extreme data efficiency. We train our proposed mechanism with only 12 images, including a single image of each class (facial expression) and one image per domain (avatar). In comparison, the authors of the FERG dataset achieved a classification accuracy of 89.02\\% with their FaceExpr model, which was trained on 43,000 images.","sentences":["People can innately recognize human facial expressions in unnatural forms, such as when depicted on the unusual faces drawn in cartoons or when applied to an animal's features.","However, current machine learning algorithms struggle with out-of-domain transfer in facial expression recognition (FER).","We propose a biologically-inspired mechanism for such transfer learning, which is based on norm-referenced encoding, where patterns are encoded in terms of difference vectors relative to a domain-specific reference vector.","By incorporating domain-specific reference frames, we demonstrate high data efficiency in transfer learning across multiple domains.","Our proposed architecture provides an explanation for how the human brain might innately recognize facial expressions on varying head shapes (humans, monkeys, and cartoon avatars) without extensive training.","Norm-referenced encoding also allows the intensity of the expression to be read out directly from neural unit activity, similar to face-selective neurons in the brain.","Our model achieves a classification accuracy of 92.15\\% on the FERG dataset with extreme data efficiency.","We train our proposed mechanism with only 12 images, including a single image of each class (facial expression) and one image per domain (avatar).","In comparison, the authors of the FERG dataset achieved a classification accuracy of 89.02\\% with their FaceExpr model, which was trained on 43,000 images."],"url":"http://arxiv.org/abs/2304.02309v1"}
{"created":"2023-04-05","title":"Influence of Dataset Parameters on the Performance of Direct UE Positioning via Deep Learning","abstract":"User equipment (UE) positioning accuracy is of paramount importance in current and future communications standard. However, traditional methods tend to perform poorly in non line of sight (NLoS) scenarios. As a result, deep learning is a candidate to enhance the UE positioning accuracy in NLoS environments. In this paper, we study the efficiency of deep learning on the 3GPP indoor factory (InF) statistical channel. More specifically, we analyse the impacts of several key elements on the positioning accuracy: the type of radio data used, the number of base stations (BS), the size of the training dataset, and the generalization ability of a trained model.","sentences":["User equipment (UE) positioning accuracy is of paramount importance in current and future communications standard.","However, traditional methods tend to perform poorly in non line of sight (NLoS) scenarios.","As a result, deep learning is a candidate to enhance the UE positioning accuracy in NLoS environments.","In this paper, we study the efficiency of deep learning on the 3GPP indoor factory (InF) statistical channel.","More specifically, we analyse the impacts of several key elements on the positioning accuracy: the type of radio data used, the number of base stations (BS), the size of the training dataset, and the generalization ability of a trained model."],"url":"http://arxiv.org/abs/2304.02308v1"}
{"created":"2023-04-05","title":"Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset","abstract":"Recent advancements in deep learning and computer vision have led to widespread use of deep neural networks to extract building footprints from remote-sensing imagery. The success of such methods relies on the availability of large databases of high-resolution remote sensing images with high-quality annotations. The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks. This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images. However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset. Therefore, it is an imperative pre-condition to adopt a data validation pipeline that evaluates the quality of the dataset prior to its use. To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits. In our experiments, we demonstrate that nearly 250k($ \\sim\\ $90%) images in the training split were identical. Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%. The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search .","sentences":["Recent advancements in deep learning and computer vision have led to widespread use of deep neural networks to extract building footprints from remote-sensing imagery.","The success of such methods relies on the availability of large databases of high-resolution remote sensing images with high-quality annotations.","The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks.","This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images.","However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset.","Therefore, it is an imperative pre-condition to adopt a data validation pipeline that evaluates the quality of the dataset prior to its use.","To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits.","In our experiments, we demonstrate that nearly 250k($ \\sim\\ $90%) images in the training split were identical.","Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%.","The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search ."],"url":"http://arxiv.org/abs/2304.02296v1"}
{"created":"2023-04-05","title":"A step towards the applicability of algorithms based on invariant causal learning on observational data","abstract":"Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization. In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships. Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM). This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context. Those environments are not normally available when working with observational data and real-world applications. Here we propose a method to generate them in an efficient way. We assess the performance of this unsupervised learning problem by implementing ICP on simulated data. We also show how to apply ICP efficiently integrated with our method for causal discovery. Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance.","sentences":["Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization.","In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships.","Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM).","This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context.","Those environments are not normally available when working with observational data and real-world applications.","Here we propose a method to generate them in an efficient way.","We assess the performance of this unsupervised learning problem by implementing ICP on simulated data.","We also show how to apply ICP efficiently integrated with our method for causal discovery.","Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance."],"url":"http://arxiv.org/abs/2304.02286v1"}
{"created":"2023-04-05","title":"MMVC: Learned Multi-Mode Video Compression with Block-based Prediction Mode Selection and Density-Adaptive Entropy Coding","abstract":"Learning-based video compression has been extensively studied over the past years, but it still has limitations in adapting to various motion patterns and entropy models. In this paper, we propose multi-mode video compression (MMVC), a block wise mode ensemble deep video compression framework that selects the optimal mode for feature domain prediction adapting to different motion patterns. Proposed multi-modes include ConvLSTM-based feature domain prediction, optical flow conditioned feature domain prediction, and feature propagation to address a wide range of cases from static scenes without apparent motions to dynamic scenes with a moving camera. We partition the feature space into blocks for temporal prediction in spatial block-based representations. For entropy coding, we consider both dense and sparse post-quantization residual blocks, and apply optional run-length coding to sparse residuals to improve the compression rate. In this sense, our method uses a dual-mode entropy coding scheme guided by a binary density map, which offers significant rate reduction surpassing the extra cost of transmitting the binary selection map. We validate our scheme with some of the most popular benchmarking datasets. Compared with state-of-the-art video compression schemes and standard codecs, our method yields better or competitive results measured with PSNR and MS-SSIM.","sentences":["Learning-based video compression has been extensively studied over the past years, but it still has limitations in adapting to various motion patterns and entropy models.","In this paper, we propose multi-mode video compression (MMVC), a block wise mode ensemble deep video compression framework that selects the optimal mode for feature domain prediction adapting to different motion patterns.","Proposed multi-modes include ConvLSTM-based feature domain prediction, optical flow conditioned feature domain prediction, and feature propagation to address a wide range of cases from static scenes without apparent motions to dynamic scenes with a moving camera.","We partition the feature space into blocks for temporal prediction in spatial block-based representations.","For entropy coding, we consider both dense and sparse post-quantization residual blocks, and apply optional run-length coding to sparse residuals to improve the compression rate.","In this sense, our method uses a dual-mode entropy coding scheme guided by a binary density map, which offers significant rate reduction surpassing the extra cost of transmitting the binary selection map.","We validate our scheme with some of the most popular benchmarking datasets.","Compared with state-of-the-art video compression schemes and standard codecs, our method yields better or competitive results measured with PSNR and MS-SSIM."],"url":"http://arxiv.org/abs/2304.02273v1"}
{"created":"2023-04-05","title":"Distributed Logistic Regression for Massive Data with Rare Events","abstract":"Large-scale rare events data are commonly encountered in practice. To tackle the massive rare events data, we propose a novel distributed estimation method for logistic regression in a distributed system. For a distributed framework, we face the following two challenges. The first challenge is how to distribute the data. In this regard, two different distribution strategies (i.e., the RANDOM strategy and the COPY strategy) are investigated. The second challenge is how to select an appropriate type of objective function so that the best asymptotic efficiency can be achieved. Then, the under-sampled (US) and inverse probability weighted (IPW) types of objective functions are considered. Our results suggest that the COPY strategy together with the IPW objective function is the best solution for distributed logistic regression with rare events. The finite sample performance of the distributed methods is demonstrated by simulation studies and a real-world Sweden Traffic Sign dataset.","sentences":["Large-scale rare events data are commonly encountered in practice.","To tackle the massive rare events data, we propose a novel distributed estimation method for logistic regression in a distributed system.","For a distributed framework, we face the following two challenges.","The first challenge is how to distribute the data.","In this regard, two different distribution strategies (i.e., the RANDOM strategy and the COPY strategy) are investigated.","The second challenge is how to select an appropriate type of objective function so that the best asymptotic efficiency can be achieved.","Then, the under-sampled (US) and inverse probability weighted (IPW) types of objective functions are considered.","Our results suggest that the COPY strategy together with the IPW objective function is the best solution for distributed logistic regression with rare events.","The finite sample performance of the distributed methods is demonstrated by simulation studies and a real-world Sweden Traffic Sign dataset."],"url":"http://arxiv.org/abs/2304.02269v1"}
{"created":"2023-04-05","title":"Deep Perceptual Similarity is Adaptable to Ambiguous Contexts","abstract":"The concept of image similarity is ambiguous, meaning that images that are considered similar in one context might not be in another. This ambiguity motivates the creation of metrics for specific contexts. This work explores the ability of the successful deep perceptual similarity (DPS) metrics to adapt to a given context. Recently, DPS metrics have emerged using the deep features of neural networks for comparing images. These metrics have been successful on datasets that leverage the average human perception in limited settings. But the question remains if they could be adapted to specific contexts of similarity. No single metric can suit all definitions of similarity and previous metrics have been rule-based which are labor intensive to rewrite for new contexts. DPS metrics, on the other hand, use neural networks which might be retrained for each context. However, retraining networks takes resources and might ruin performance on previous tasks. This work examines the adaptability of DPS metrics by training positive scalars for the deep features of pretrained CNNs to correctly measure similarity for different contexts. Evaluation is performed on contexts defined by randomly ordering six image distortions (e.g. rotation) by which should be considered more similar when applied to an image. This also gives insight into whether the features in the CNN is enough to discern different distortions without retraining. Finally, the trained metrics are evaluated on a perceptual similarity dataset to evaluate if adapting to an ordering affects their performance on established scenarios. The findings show that DPS metrics can be adapted with high performance. While the adapted metrics have difficulties with the same contexts as baselines, performance is improved in 99% of cases. Finally, it is shown that the adaption is not significantly detrimental to prior performance on perceptual similarity.","sentences":["The concept of image similarity is ambiguous, meaning that images that are considered similar in one context might not be in another.","This ambiguity motivates the creation of metrics for specific contexts.","This work explores the ability of the successful deep perceptual similarity (DPS) metrics to adapt to a given context.","Recently, DPS metrics have emerged using the deep features of neural networks for comparing images.","These metrics have been successful on datasets that leverage the average human perception in limited settings.","But the question remains if they could be adapted to specific contexts of similarity.","No single metric can suit all definitions of similarity and previous metrics have been rule-based which are labor intensive to rewrite for new contexts.","DPS metrics, on the other hand, use neural networks which might be retrained for each context.","However, retraining networks takes resources and might ruin performance on previous tasks.","This work examines the adaptability of DPS metrics by training positive scalars for the deep features of pretrained CNNs to correctly measure similarity for different contexts.","Evaluation is performed on contexts defined by randomly ordering six image distortions (e.g. rotation) by which should be considered more similar when applied to an image.","This also gives insight into whether the features in the CNN is enough to discern different distortions without retraining.","Finally, the trained metrics are evaluated on a perceptual similarity dataset to evaluate if adapting to an ordering affects their performance on established scenarios.","The findings show that DPS metrics can be adapted with high performance.","While the adapted metrics have difficulties with the same contexts as baselines, performance is improved in 99% of cases.","Finally, it is shown that the adaption is not significantly detrimental to prior performance on perceptual similarity."],"url":"http://arxiv.org/abs/2304.02265v1"}
{"created":"2023-04-05","title":"Persuading to Prepare for Quitting Smoking with a Virtual Coach: Using States and User Characteristics to Predict Behavior","abstract":"Despite their prevalence in eHealth applications for behavior change, persuasive messages tend to have small effects on behavior. Conditions or states (e.g., confidence, knowledge, motivation) and characteristics (e.g., gender, age, personality) of persuadees are two promising components for more effective algorithms for choosing persuasive messages. However, it is not yet sufficiently clear how well considering these components allows one to predict behavior after persuasive attempts, especially in the long run. Since collecting data for many algorithm components is costly and places a burden on users, a better understanding of the impact of individual components in practice is welcome. This can help to make an informed decision on which components to use. We thus conducted a longitudinal study in which a virtual coach persuaded 671 daily smokers to do preparatory activities for quitting smoking and becoming more physically active, such as envisioning one's desired future self. Based on the collected data, we designed a Reinforcement Learning (RL)-approach that considers current and future states to maximize the effort people spend on their activities. Using this RL-approach, we found, based on leave-one-out cross-validation, that considering states helps to predict both behavior and future states. User characteristics and especially involvement in the activities, on the other hand, only help to predict behavior if used in combination with states rather than alone. We see these results as supporting the use of states and involvement in persuasion algorithms. Our dataset is available online.","sentences":["Despite their prevalence in eHealth applications for behavior change, persuasive messages tend to have small effects on behavior.","Conditions or states (e.g., confidence, knowledge, motivation) and characteristics (e.g., gender, age, personality) of persuadees are two promising components for more effective algorithms for choosing persuasive messages.","However, it is not yet sufficiently clear how well considering these components allows one to predict behavior after persuasive attempts, especially in the long run.","Since collecting data for many algorithm components is costly and places a burden on users, a better understanding of the impact of individual components in practice is welcome.","This can help to make an informed decision on which components to use.","We thus conducted a longitudinal study in which a virtual coach persuaded 671 daily smokers to do preparatory activities for quitting smoking and becoming more physically active, such as envisioning one's desired future self.","Based on the collected data, we designed a Reinforcement Learning (RL)-approach that considers current and future states to maximize the effort people spend on their activities.","Using this RL-approach, we found, based on leave-one-out cross-validation, that considering states helps to predict both behavior and future states.","User characteristics and especially involvement in the activities, on the other hand, only help to predict behavior if used in combination with states rather than alone.","We see these results as supporting the use of states and involvement in persuasion algorithms.","Our dataset is available online."],"url":"http://arxiv.org/abs/2304.02264v1"}
{"created":"2023-04-05","title":"Low Latency Computing for Time Stretch Instruments","abstract":"Time stretch instruments have been exceptionally successful in discovering single-shot ultrafast phenomena such as optical rogue waves and have led to record-speed microscopy, spectroscopy, lidar, etc. These instruments encode the ultrafast events into the spectrum of a femtosecond pulse and then dilate the time scale of the data using group velocity dispersion. Generating as much as Tbit per second of data, they are ideal partners for deep learning networks which by their inherent complexity, require large datasets for training. However, the inference time scale of neural networks in the millisecond regime is orders of magnitude longer than the data acquisition rate of time stretch instruments. This underscores the need to explore means where some of the lower-level computational tasks can be done while the data is still in the optical domain. The Nonlinear Schr\\\"{o}dinger Kernel computing addresses this predicament. It utilizes optical nonlinearities to map the data onto a new domain in which classification accuracy is enhanced, without increasing the data dimensions. One limitation of this technique is the fixed optical transfer function, which prevents training and generalizability. Here we show that the optical kernel can be effectively tuned and trained by utilizing digital phase encoding of the femtosecond laser pulse leading to a reduction of the error rate in data classification.","sentences":["Time stretch instruments have been exceptionally successful in discovering single-shot ultrafast phenomena such as optical rogue waves and have led to record-speed microscopy, spectroscopy, lidar, etc.","These instruments encode the ultrafast events into the spectrum of a femtosecond pulse and then dilate the time scale of the data using group velocity dispersion.","Generating as much as Tbit per second of data, they are ideal partners for deep learning networks which by their inherent complexity, require large datasets for training.","However, the inference time scale of neural networks in the millisecond regime is orders of magnitude longer than the data acquisition rate of time stretch instruments.","This underscores the need to explore means where some of the lower-level computational tasks can be done while the data is still in the optical domain.","The Nonlinear Schr\\\"{o}dinger Kernel computing addresses this predicament.","It utilizes optical nonlinearities to map the data onto a new domain in which classification accuracy is enhanced, without increasing the data dimensions.","One limitation of this technique is the fixed optical transfer function, which prevents training and generalizability.","Here we show that the optical kernel can be effectively tuned and trained by utilizing digital phase encoding of the femtosecond laser pulse leading to a reduction of the error rate in data classification."],"url":"http://arxiv.org/abs/2304.02249v1"}
{"created":"2023-04-05","title":"BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation","abstract":"A novel 4K video frame interpolator based on bilateral transformer (BiFormer) is proposed in this paper, which performs three steps: global motion estimation, local motion refinement, and frame synthesis. First, in global motion estimation, we predict symmetric bilateral motion fields at a coarse scale. To this end, we propose BiFormer, the first transformer-based bilateral motion estimator. Second, we refine the global motion fields efficiently using blockwise bilateral cost volumes (BBCVs). Third, we warp the input frames using the refined motion fields and blend them to synthesize an intermediate frame. Extensive experiments demonstrate that the proposed BiFormer algorithm achieves excellent interpolation performance on 4K datasets. The source codes are available at https://github.com/JunHeum/BiFormer.","sentences":["A novel 4K video frame interpolator based on bilateral transformer (BiFormer) is proposed in this paper, which performs three steps: global motion estimation, local motion refinement, and frame synthesis.","First, in global motion estimation, we predict symmetric bilateral motion fields at a coarse scale.","To this end, we propose BiFormer, the first transformer-based bilateral motion estimator.","Second, we refine the global motion fields efficiently using blockwise bilateral cost volumes (BBCVs).","Third, we warp the input frames using the refined motion fields and blend them to synthesize an intermediate frame.","Extensive experiments demonstrate that the proposed BiFormer algorithm achieves excellent interpolation performance on 4K datasets.","The source codes are available at https://github.com/JunHeum/BiFormer."],"url":"http://arxiv.org/abs/2304.02225v1"}
{"created":"2023-04-05","title":"Identification of high-reliability regions of machine learning predictions in materials science using transparent conducting oxides and perovskites as examples","abstract":"Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science. Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML. We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials. Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science.","sentences":["Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science.","Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML.","We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials.","Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science."],"url":"http://arxiv.org/abs/2304.02218v1"}
{"created":"2023-04-05","title":"Industrial Anomaly Detection with Domain Shift: A Real-world Dataset and Masked Multi-scale Reconstruction","abstract":"Industrial anomaly detection (IAD) is crucial for automating industrial quality inspection. The diversity of the datasets is the foundation for developing comprehensive IAD algorithms. Existing IAD datasets focus on the diversity of data categories, overlooking the diversity of domains within the same data category. In this paper, to bridge this gap, we propose the Aero-engine Blade Anomaly Detection (AeBAD) dataset, consisting of two sub-datasets: the single-blade dataset and the video anomaly detection dataset of blades. Compared to existing datasets, AeBAD has the following two characteristics: 1.) The target samples are not aligned and at different scales. 2.) There is a domain shift between the distribution of normal samples in the test set and the training set, where the domain shifts are mainly caused by the changes in illumination and view. Based on this dataset, we observe that current state-of-the-art (SOTA) IAD methods exhibit limitations when the domain of normal samples in the test set undergoes a shift. To address this issue, we propose a novel method called masked multi-scale reconstruction (MMR), which enhances the model's capacity to deduce causality among patches in normal samples by a masked reconstruction task. MMR achieves superior performance compared to SOTA methods on the AeBAD dataset. Furthermore, MMR achieves competitive performance with SOTA methods to detect the anomalies of different types on the MVTec AD dataset. Code and dataset are available at https://github.com/zhangzilongc/MMR.","sentences":["Industrial anomaly detection (IAD) is crucial for automating industrial quality inspection.","The diversity of the datasets is the foundation for developing comprehensive IAD algorithms.","Existing IAD datasets focus on the diversity of data categories, overlooking the diversity of domains within the same data category.","In this paper, to bridge this gap, we propose the Aero-engine Blade Anomaly Detection (AeBAD) dataset, consisting of two sub-datasets: the single-blade dataset and the video anomaly detection dataset of blades.","Compared to existing datasets, AeBAD has the following two characteristics: 1.)","The target samples are not aligned and at different scales.","2.)","There is a domain shift between the distribution of normal samples in the test set and the training set, where the domain shifts are mainly caused by the changes in illumination and view.","Based on this dataset, we observe that current state-of-the-art (SOTA) IAD methods exhibit limitations when the domain of normal samples in the test set undergoes a shift.","To address this issue, we propose a novel method called masked multi-scale reconstruction (MMR), which enhances the model's capacity to deduce causality among patches in normal samples by a masked reconstruction task.","MMR achieves superior performance compared to SOTA methods on the AeBAD dataset.","Furthermore, MMR achieves competitive performance with SOTA methods to detect the anomalies of different types on the MVTec AD dataset.","Code and dataset are available at https://github.com/zhangzilongc/MMR."],"url":"http://arxiv.org/abs/2304.02216v1"}
{"created":"2023-04-05","title":"LogoNet: a fine-grained network for instance-level logo sketch retrieval","abstract":"Sketch-based image retrieval, which aims to use sketches as queries to retrieve images containing the same query instance, receives increasing attention in recent years. Although dramatic progress has been made in sketch retrieval, few efforts are devoted to logo sketch retrieval which is still hindered by the following challenges: Firstly, logo sketch retrieval is more difficult than typical sketch retrieval problem, since a logo sketch usually contains much less visual contents with only irregular strokes and lines. Secondly, instance-specific sketches demonstrate dramatic appearance variances, making them less identifiable when querying the same logo instance. Thirdly, there exist several sketch retrieval benchmarking datasets nowadays, whereas an instance-level logo sketch dataset is still publicly unavailable. To address the above-mentioned limitations, we make twofold contributions in this study for instance-level logo sketch retrieval. To begin with, we construct an instance-level logo sketch dataset containing 2k logo instances and exceeding 9k sketches. To our knowledge, this is the first publicly available instance-level logo sketch dataset. Next, we develop a fine-grained triple-branch CNN architecture based on hybrid attention mechanism termed LogoNet for accurate logo sketch retrieval. More specifically, we embed the hybrid attention mechanism into the triple-branch architecture for capturing the key query-specific information from the limited visual cues in the logo sketches. Experimental evaluations both on our assembled dataset and public benchmark datasets demonstrate the effectiveness of our proposed network.","sentences":["Sketch-based image retrieval, which aims to use sketches as queries to retrieve images containing the same query instance, receives increasing attention in recent years.","Although dramatic progress has been made in sketch retrieval, few efforts are devoted to logo sketch retrieval which is still hindered by the following challenges: Firstly, logo sketch retrieval is more difficult than typical sketch retrieval problem, since a logo sketch usually contains much less visual contents with only irregular strokes and lines.","Secondly, instance-specific sketches demonstrate dramatic appearance variances, making them less identifiable when querying the same logo instance.","Thirdly, there exist several sketch retrieval benchmarking datasets nowadays, whereas an instance-level logo sketch dataset is still publicly unavailable.","To address the above-mentioned limitations, we make twofold contributions in this study for instance-level logo sketch retrieval.","To begin with, we construct an instance-level logo sketch dataset containing 2k logo instances and exceeding 9k sketches.","To our knowledge, this is the first publicly available instance-level logo sketch dataset.","Next, we develop a fine-grained triple-branch CNN architecture based on hybrid attention mechanism termed LogoNet for accurate logo sketch retrieval.","More specifically, we embed the hybrid attention mechanism into the triple-branch architecture for capturing the key query-specific information from the limited visual cues in the logo sketches.","Experimental evaluations both on our assembled dataset and public benchmark datasets demonstrate the effectiveness of our proposed network."],"url":"http://arxiv.org/abs/2304.02214v1"}
{"created":"2023-04-05","title":"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT","abstract":"This article presents a new NLP task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existed perovskite solar cell FAIR(Findable, Accessible, Interoperable, Reusable) dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict solar cells' electrical performance and reverse-predict parameters on both material gene and FAIR datesets through LLM. We obtained comparable performance with traditional machine learning methods without feature selection, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.","sentences":["This article presents a new NLP task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science.","We accomplished this task by tuning GPT-3 on an existed perovskite solar cell FAIR(Findable, Accessible, Interoperable, Reusable) dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now.","The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis.","This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain.","Furthermore, we designed experiments to predict solar cells' electrical performance and reverse-predict parameters on both material gene and FAIR datesets through LLM.","We obtained comparable performance with traditional machine learning methods without feature selection, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist."],"url":"http://arxiv.org/abs/2304.02213v2"}
{"created":"2023-04-05","title":"PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data","abstract":"With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare. The efficient exploratory analysis of healthcare data constitutes a significant challenge. Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers. This allows policies to be rapidly adapted to changing circumstances. We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan. We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development. We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests and feature bagging. We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester. We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder. However, the auto-encoder needs to be trained, which requires several parameters to be tuned. In comparison, the PIKS technique has far fewer parameters to tune. This makes it advantageous for fast, \"out-of-the-box\" data exploration. The PIKS technique is scalable and can readily ingest new datasets. Hence, it can provide valuable, up-to-date insights to citizens, patients and policy-makers. We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work. This will help promote a deeper understanding of healthcare policies and public health issues.","sentences":["With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare.","The efficient exploratory analysis of healthcare data constitutes a significant challenge.","Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers.","This allows policies to be rapidly adapted to changing circumstances.","We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan.","We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development.","We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests and feature bagging.","We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester.","We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder.","However, the auto-encoder needs to be trained, which requires several parameters to be tuned.","In comparison, the PIKS technique has far fewer parameters to tune.","This makes it advantageous for fast, \"out-of-the-box\" data exploration.","The PIKS technique is scalable and can readily ingest new datasets.","Hence, it can provide valuable, up-to-date insights to citizens, patients and policy-makers.","We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work.","This will help promote a deeper understanding of healthcare policies and public health issues."],"url":"http://arxiv.org/abs/2304.02208v1"}
{"created":"2023-04-05","title":"MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs","abstract":"Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods. Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar.","sentences":["Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education.","Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels.","In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records.","Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels.","The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods.","Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar."],"url":"http://arxiv.org/abs/2304.02205v1"}
{"created":"2023-04-05","title":"Knowledge Combination to Learn Rotated Detection Without Rotated Annotation","abstract":"Rotated bounding boxes drastically reduce output ambiguity of elongated objects, making it superior to axis-aligned bounding boxes. Despite the effectiveness, rotated detectors are not widely employed. Annotating rotated bounding boxes is such a laborious process that they are not provided in many detection datasets where axis-aligned annotations are used instead. In this paper, we propose a framework that allows the model to predict precise rotated boxes only requiring cheaper axis-aligned annotation of the target dataset 1. To achieve this, we leverage the fact that neural networks are capable of learning richer representation of the target domain than what is utilized by the task. The under-utilized representation can be exploited to address a more detailed task. Our framework combines task knowledge of an out-of-domain source dataset with stronger annotation and domain knowledge of the target dataset with weaker annotation. A novel assignment process and projection loss are used to enable the co-training on the source and target datasets. As a result, the model is able to solve the more detailed task in the target domain, without additional computation overhead during inference. We extensively evaluate the method on various target datasets including fresh-produce dataset, HRSC2016 and SSDD. Results show that the proposed method consistently performs on par with the fully supervised approach.","sentences":["Rotated bounding boxes drastically reduce output ambiguity of elongated objects, making it superior to axis-aligned bounding boxes.","Despite the effectiveness, rotated detectors are not widely employed.","Annotating rotated bounding boxes is such a laborious process that they are not provided in many detection datasets where axis-aligned annotations are used instead.","In this paper, we propose a framework that allows the model to predict precise rotated boxes only requiring cheaper axis-aligned annotation of the target dataset 1.","To achieve this, we leverage the fact that neural networks are capable of learning richer representation of the target domain than what is utilized by the task.","The under-utilized representation can be exploited to address a more detailed task.","Our framework combines task knowledge of an out-of-domain source dataset with stronger annotation and domain knowledge of the target dataset with weaker annotation.","A novel assignment process and projection loss are used to enable the co-training on the source and target datasets.","As a result, the model is able to solve the more detailed task in the target domain, without additional computation overhead during inference.","We extensively evaluate the method on various target datasets including fresh-produce dataset, HRSC2016 and SSDD.","Results show that the proposed method consistently performs on par with the fully supervised approach."],"url":"http://arxiv.org/abs/2304.02199v1"}
{"created":"2023-04-05","title":"A Diffusion-based Method for Multi-turn Compositional Image Generation","abstract":"Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework. Additionally, we also perform ICM guidance and classifier-free guidance to improve performance. Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR.","sentences":["Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text.","While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs.","In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM).","We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG.","We introduce a conditioning scheme to generate the target image based on the fusion results.","To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework.","Additionally, we also perform ICM guidance and classifier-free guidance to improve performance.","Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR."],"url":"http://arxiv.org/abs/2304.02192v1"}
{"created":"2023-04-05","title":"A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data","abstract":"The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood. There may be hidden trends and patterns in the data that are worthy of further exploration and analysis. We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers. An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature. Outliers are identified as singleton or small clusters. This algorithm is swept across the dataset in a searchlight manner. The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers. We illustrate this system by anaylzing open health care data released by New York State. We apply our iterative k-means searchlight followed by subset scanning. Several anomalous trends in the data are identified, including cost overruns at specific hospitals, and increases in diagnoses such as suicides. These constitute novel findings in the literature, and are of potential use to regulatory agencies, policy makers and concerned citizens.","sentences":["The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood.","There may be hidden trends and patterns in the data that are worthy of further exploration and analysis.","We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers.","An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature.","Outliers are identified as singleton or small clusters.","This algorithm is swept across the dataset in a searchlight manner.","The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers.","We illustrate this system by anaylzing open health care data released by New York State.","We apply our iterative k-means searchlight followed by subset scanning.","Several anomalous trends in the data are identified, including cost overruns at specific hospitals, and increases in diagnoses such as suicides.","These constitute novel findings in the literature, and are of potential use to regulatory agencies, policy makers and concerned citizens."],"url":"http://arxiv.org/abs/2304.02189v1"}
{"created":"2023-04-05","title":"Bodily expressed emotion understanding through integrating Laban movement analysis","abstract":"Body movements carry important information about a person's emotions or mental state and are essential in daily communication. Enhancing the ability of machines to understand emotions expressed through body language can improve the communication of assistive robots with children and elderly users, provide psychiatric professionals with quantitative diagnostic and prognostic assistance, and aid law enforcement in identifying deception. This study develops a high-quality human motor element dataset based on the Laban Movement Analysis movement coding system and utilizes that to jointly learn about motor elements and emotions. Our long-term ambition is to integrate knowledge from computing, psychology, and performing arts to enable automated understanding and analysis of emotion and mental state through body language. This work serves as a launchpad for further research into recognizing emotions through analysis of human movement.","sentences":["Body movements carry important information about a person's emotions or mental state and are essential in daily communication.","Enhancing the ability of machines to understand emotions expressed through body language can improve the communication of assistive robots with children and elderly users, provide psychiatric professionals with quantitative diagnostic and prognostic assistance, and aid law enforcement in identifying deception.","This study develops a high-quality human motor element dataset based on the Laban Movement Analysis movement coding system and utilizes that to jointly learn about motor elements and emotions.","Our long-term ambition is to integrate knowledge from computing, psychology, and performing arts to enable automated understanding and analysis of emotion and mental state through body language.","This work serves as a launchpad for further research into recognizing emotions through analysis of human movement."],"url":"http://arxiv.org/abs/2304.02187v1"}
{"created":"2023-04-05","title":"On the Impact of Voice Anonymization on Speech-Based COVID-19 Detection","abstract":"With advances seen in deep learning, voice-based applications are burgeoning, ranging from personal assistants, affective computing, to remote disease diagnostics. As the voice contains both linguistic and paralinguistic information (e.g., vocal pitch, intonation, speech rate, loudness), there is growing interest in voice anonymization to preserve speaker privacy and identity. Voice privacy challenges have emerged over the last few years and focus has been placed on removing speaker identity while keeping linguistic content intact. For affective computing and disease monitoring applications, however, the paralinguistic content may be more critical. Unfortunately, the effects that anonymization may have on these systems are still largely unknown. In this paper, we fill this gap and focus on one particular health monitoring application: speech-based COVID-19 diagnosis. We test two popular anonymization methods and their impact on five different state-of-the-art COVID-19 diagnostic systems using three public datasets. We validate the effectiveness of the anonymization methods, compare their computational complexity, and quantify the impact across different testing scenarios for both within- and across-dataset conditions. Lastly, we show the benefits of anonymization as a data augmentation tool to help recover some of the COVID-19 diagnostic accuracy loss seen with anonymized data.","sentences":["With advances seen in deep learning, voice-based applications are burgeoning, ranging from personal assistants, affective computing, to remote disease diagnostics.","As the voice contains both linguistic and paralinguistic information (e.g., vocal pitch, intonation, speech rate, loudness), there is growing interest in voice anonymization to preserve speaker privacy and identity.","Voice privacy challenges have emerged over the last few years and focus has been placed on removing speaker identity while keeping linguistic content intact.","For affective computing and disease monitoring applications, however, the paralinguistic content may be more critical.","Unfortunately, the effects that anonymization may have on these systems are still largely unknown.","In this paper, we fill this gap and focus on one particular health monitoring application: speech-based COVID-19 diagnosis.","We test two popular anonymization methods and their impact on five different state-of-the-art COVID-19 diagnostic systems using three public datasets.","We validate the effectiveness of the anonymization methods, compare their computational complexity, and quantify the impact across different testing scenarios for both within- and across-dataset conditions.","Lastly, we show the benefits of anonymization as a data augmentation tool to help recover some of the COVID-19 diagnostic accuracy loss seen with anonymized data."],"url":"http://arxiv.org/abs/2304.02181v1"}
{"created":"2023-04-05","title":"ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules","abstract":"Charts are a powerful tool for visually conveying complex data, but their comprehension poses a challenge due to the diverse chart types and intricate components. Existing chart comprehension methods suffer from either heuristic rules or an over-reliance on OCR systems, resulting in suboptimal performance. To address these issues, we present ChartReader, a unified framework that seamlessly integrates chart derendering and comprehension tasks. Our approach includes a transformer-based chart component detection module and an extended pre-trained vision-language model for chart-to-X tasks. By learning the rules of charts automatically from annotated datasets, our approach eliminates the need for manual rule-making, reducing effort and enhancing accuracy.~We also introduce a data variable replacement technique and extend the input and position embeddings of the pre-trained model for cross-task training. We evaluate ChartReader on Chart-to-Table, ChartQA, and Chart-to-Text tasks, demonstrating its superiority over existing methods. Our proposed framework can significantly reduce the manual effort involved in chart analysis, providing a step towards a universal chart understanding model. Moreover, our approach offers opportunities for plug-and-play integration with mainstream LLMs such as T5 and TaPas, extending their capability to chart comprehension tasks. The code is available at https://github.com/zhiqic/ChartReader.","sentences":["Charts are a powerful tool for visually conveying complex data, but their comprehension poses a challenge due to the diverse chart types and intricate components.","Existing chart comprehension methods suffer from either heuristic rules or an over-reliance on OCR systems, resulting in suboptimal performance.","To address these issues, we present ChartReader, a unified framework that seamlessly integrates chart derendering and comprehension tasks.","Our approach includes a transformer-based chart component detection module and an extended pre-trained vision-language model for chart-to-X tasks.","By learning the rules of charts automatically from annotated datasets, our approach eliminates the need for manual rule-making, reducing effort and enhancing accuracy.~We also introduce a data variable replacement technique and extend the input and position embeddings of the pre-trained model for cross-task training.","We evaluate ChartReader on Chart-to-Table, ChartQA, and Chart-to-Text tasks, demonstrating its superiority over existing methods.","Our proposed framework can significantly reduce the manual effort involved in chart analysis, providing a step towards a universal chart understanding model.","Moreover, our approach offers opportunities for plug-and-play integration with mainstream LLMs such as T5 and TaPas, extending their capability to chart comprehension tasks.","The code is available at https://github.com/zhiqic/ChartReader."],"url":"http://arxiv.org/abs/2304.02173v1"}
{"created":"2023-04-04","title":"GINA-3D: Learning to Generate Implicit Neural Assets in the Wild","abstract":"Modeling the 3D world from sensor data for simulation is a scalable way of developing testing and validation environments for robotic learning problems such as autonomous driving. However, manually creating or re-creating real-world-like environments is difficult, expensive, and not scalable. Recent generative model techniques have shown promising progress to address such challenges by learning 3D assets using only plentiful 2D images -- but still suffer limitations as they leverage either human-curated image datasets or renderings from manually-created synthetic 3D environments. In this paper, we introduce GINA-3D, a generative model that uses real-world driving data from camera and LiDAR sensors to create realistic 3D implicit neural assets of diverse vehicles and pedestrians. Compared to the existing image datasets, the real-world driving setting poses new challenges due to occlusions, lighting-variations and long-tail distributions. GINA-3D tackles these challenges by decoupling representation learning and generative modeling into two stages with a learned tri-plane latent structure, inspired by recent advances in generative modeling of images. To evaluate our approach, we construct a large-scale object-centric dataset containing over 520K images of vehicles and pedestrians from the Waymo Open Dataset, and a new set of 80K images of long-tail instances such as construction equipment, garbage trucks, and cable cars. We compare our model with existing approaches and demonstrate that it achieves state-of-the-art performance in quality and diversity for both generated images and geometries.","sentences":["Modeling the 3D world from sensor data for simulation is a scalable way of developing testing and validation environments for robotic learning problems such as autonomous driving.","However, manually creating or re-creating real-world-like environments is difficult, expensive, and not scalable.","Recent generative model techniques have shown promising progress to address such challenges by learning 3D assets using only plentiful 2D images -- but still suffer limitations as they leverage either human-curated image datasets or renderings from manually-created synthetic 3D environments.","In this paper, we introduce GINA-3D, a generative model that uses real-world driving data from camera and LiDAR sensors to create realistic 3D implicit neural assets of diverse vehicles and pedestrians.","Compared to the existing image datasets, the real-world driving setting poses new challenges due to occlusions, lighting-variations and long-tail distributions.","GINA-3D tackles these challenges by decoupling representation learning and generative modeling into two stages with a learned tri-plane latent structure, inspired by recent advances in generative modeling of images.","To evaluate our approach, we construct a large-scale object-centric dataset containing over 520K images of vehicles and pedestrians from the Waymo Open Dataset, and a new set of 80K images of long-tail instances such as construction equipment, garbage trucks, and cable cars.","We compare our model with existing approaches and demonstrate that it achieves state-of-the-art performance in quality and diversity for both generated images and geometries."],"url":"http://arxiv.org/abs/2304.02163v1"}
{"created":"2023-04-04","title":"Pac-HuBERT: Self-Supervised Music Source Separation via Primitive Auditory Clustering and Hidden-Unit BERT","abstract":"In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance. Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data. In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model. We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture. We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation. Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset. The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models. We further demonstrate that it can boost performance with small amounts of supervised data. Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation.","sentences":["In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance.","Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data.","In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model.","We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture.","We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation.","Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset.","The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models.","We further demonstrate that it can boost performance with small amounts of supervised data.","Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation."],"url":"http://arxiv.org/abs/2304.02160v1"}
{"created":"2023-04-04","title":"Re-Evaluating LiDAR Scene Flow for Autonomous Driving","abstract":"Current methods for self-supervised LiDAR scene flow estimation work poorly on real data. A variety of flaws in common evaluation protocols have caused leading approaches to focus on problems that do not exist in real data. We analyze a suite of recent works and find that despite their focus on deep learning, the main challenges of the LiDAR scene flow problem -- removing the dominant rigid motion and robustly estimating the simple motions that remain -- can be more effectively solved with classical techniques such as ICP motion compensation and enforcing piecewise rigid assumptions. We combine these steps with a test-time optimization method to form a state-of-the-art system that does not require any training data. Because our final approach is dataless, it can be applied on different datasets with diverse LiDAR rigs without retraining. Our proposed approach outperforms all existing methods on Argoverse 2.0, halves the error rate on NuScenes, and even rivals the performance of supervised networks on Waymo and lidarKITTI.","sentences":["Current methods for self-supervised LiDAR scene flow estimation work poorly on real data.","A variety of flaws in common evaluation protocols have caused leading approaches to focus on problems that do not exist in real data.","We analyze a suite of recent works and find that despite their focus on deep learning, the main challenges of the LiDAR scene flow problem -- removing the dominant rigid motion and robustly estimating the simple motions that remain -- can be more effectively solved with classical techniques such as ICP motion compensation and enforcing piecewise rigid assumptions.","We combine these steps with a test-time optimization method to form a state-of-the-art system that does not require any training data.","Because our final approach is dataless, it can be applied on different datasets with diverse LiDAR rigs without retraining.","Our proposed approach outperforms all existing methods on Argoverse 2.0, halves the error rate on NuScenes, and even rivals the performance of supervised networks on Waymo and lidarKITTI."],"url":"http://arxiv.org/abs/2304.02150v1"}
{"created":"2023-04-04","title":"ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention","abstract":"Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task. In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation. We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence. Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features. We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments have been conducted to identify the optimal hyper-parameter set. These experiments demonstrated that we achieved a \\textbf{significant parameter reduction relative to prior transformer models} while attaining State-of-the-Art (SOTA) or near SOTA on all three datasets. Additionally, we achieved SOTA for Protocol III on H36M for both GT and CPN detection inputs. Finally, we obtained SOTA on all three metrics for the MPI-INF-3DHP dataset and for all three subjects on HumanEva under Protocol II.","sentences":["Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task.","In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation.","We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence.","Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features.","We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva.","Extensive experiments have been conducted to identify the optimal hyper-parameter set.","These experiments demonstrated that we achieved a \\textbf{significant parameter reduction relative to prior transformer models} while attaining State-of-the-Art (SOTA) or near SOTA on all three datasets.","Additionally, we achieved SOTA for Protocol III on H36M for both GT and CPN detection inputs.","Finally, we obtained SOTA on all three metrics for the MPI-INF-3DHP dataset and for all three subjects on HumanEva under Protocol II."],"url":"http://arxiv.org/abs/2304.02147v1"}
{"created":"2023-04-04","title":"A Data Fusion Framework for Multi-Domain Morality Learning","abstract":"Language models can be trained to recognize the moral sentiment of text, creating new opportunities to study the role of morality in human life. As interest in language and morality has grown, several ground truth datasets with moral annotations have been released. However, these datasets vary in the method of data collection, domain, topics, instructions for annotators, etc. Simply aggregating such heterogeneous datasets during training can yield models that fail to generalize well. We describe a data fusion framework for training on multiple heterogeneous datasets that improve performance and generalizability. The model uses domain adversarial training to align the datasets in feature space and a weighted loss function to deal with label shift. We show that the proposed framework achieves state-of-the-art performance in different datasets compared to prior works in morality inference.","sentences":["Language models can be trained to recognize the moral sentiment of text, creating new opportunities to study the role of morality in human life.","As interest in language and morality has grown, several ground truth datasets with moral annotations have been released.","However, these datasets vary in the method of data collection, domain, topics, instructions for annotators, etc.","Simply aggregating such heterogeneous datasets during training can yield models that fail to generalize well.","We describe a data fusion framework for training on multiple heterogeneous datasets that improve performance and generalizability.","The model uses domain adversarial training to align the datasets in feature space and a weighted loss function to deal with label shift.","We show that the proposed framework achieves state-of-the-art performance in different datasets compared to prior works in morality inference."],"url":"http://arxiv.org/abs/2304.02144v1"}
{"created":"2023-04-04","title":"Adaptive Ensemble Learning: Boosting Model Performance through Intelligent Feature Fusion in Deep Neural Networks","abstract":"In this paper, we present an Adaptive Ensemble Learning framework that aims to boost the performance of deep neural networks by intelligently fusing features through ensemble learning techniques. The proposed framework integrates ensemble learning strategies with deep learning architectures to create a more robust and adaptable model capable of handling complex tasks across various domains. By leveraging intelligent feature fusion methods, the Adaptive Ensemble Learning framework generates more discriminative and effective feature representations, leading to improved model performance and generalization capabilities.   We conducted extensive experiments and evaluations on several benchmark datasets, including image classification, object detection, natural language processing, and graph-based learning tasks. The results demonstrate that the proposed framework consistently outperforms baseline models and traditional feature fusion techniques, highlighting its effectiveness in enhancing deep learning models' performance. Furthermore, we provide insights into the impact of intelligent feature fusion on model performance and discuss the potential applications of the Adaptive Ensemble Learning framework in real-world scenarios.   The paper also explores the design and implementation of adaptive ensemble models, ensemble training strategies, and meta-learning techniques, which contribute to the framework's versatility and adaptability. In conclusion, the Adaptive Ensemble Learning framework represents a significant advancement in the field of feature fusion and ensemble learning for deep neural networks, with the potential to transform a wide range of applications across multiple domains.","sentences":["In this paper, we present an Adaptive Ensemble Learning framework that aims to boost the performance of deep neural networks by intelligently fusing features through ensemble learning techniques.","The proposed framework integrates ensemble learning strategies with deep learning architectures to create a more robust and adaptable model capable of handling complex tasks across various domains.","By leveraging intelligent feature fusion methods, the Adaptive Ensemble Learning framework generates more discriminative and effective feature representations, leading to improved model performance and generalization capabilities.   ","We conducted extensive experiments and evaluations on several benchmark datasets, including image classification, object detection, natural language processing, and graph-based learning tasks.","The results demonstrate that the proposed framework consistently outperforms baseline models and traditional feature fusion techniques, highlighting its effectiveness in enhancing deep learning models' performance.","Furthermore, we provide insights into the impact of intelligent feature fusion on model performance and discuss the potential applications of the Adaptive Ensemble Learning framework in real-world scenarios.   ","The paper also explores the design and implementation of adaptive ensemble models, ensemble training strategies, and meta-learning techniques, which contribute to the framework's versatility and adaptability.","In conclusion, the Adaptive Ensemble Learning framework represents a significant advancement in the field of feature fusion and ensemble learning for deep neural networks, with the potential to transform a wide range of applications across multiple domains."],"url":"http://arxiv.org/abs/2304.02653v1"}
{"created":"2023-04-04","title":"OpenContrails: Benchmarking Contrail Detection on GOES-16 ABI","abstract":"Contrails (condensation trails) are line-shaped ice clouds caused by aircraft and are likely the largest contributor of aviation-induced climate change. Contrail avoidance is potentially an inexpensive way to significantly reduce the climate impact of aviation. An automated contrail detection system is an essential tool to develop and evaluate contrail avoidance systems. In this paper, we present a human-labeled dataset named OpenContrails to train and evaluate contrail detection models based on GOES-16 Advanced Baseline Imager (ABI) data. We propose and evaluate a contrail detection model that incorporates temporal context for improved detection accuracy. The human labeled dataset and the contrail detection outputs are publicly available on Google Cloud Storage at gs://goes_contrails_dataset.","sentences":["Contrails (condensation trails) are line-shaped ice clouds caused by aircraft and are likely the largest contributor of aviation-induced climate change.","Contrail avoidance is potentially an inexpensive way to significantly reduce the climate impact of aviation.","An automated contrail detection system is an essential tool to develop and evaluate contrail avoidance systems.","In this paper, we present a human-labeled dataset named OpenContrails to train and evaluate contrail detection models based on GOES-16 Advanced Baseline Imager (ABI) data.","We propose and evaluate a contrail detection model that incorporates temporal context for improved detection accuracy.","The human labeled dataset and the contrail detection outputs are publicly available on Google Cloud Storage at gs://goes_contrails_dataset."],"url":"http://arxiv.org/abs/2304.02122v1"}
{"created":"2023-04-04","title":"Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach","abstract":"The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data. To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as a neural network. The encoder function is introduced to reconstruct the current state from past input-output data. Hence it enables the forward simulation of the rolled-out state-space model. While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process. This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA). Using the BLA provided state-space matrices and its associated reconstructability map both the state-transition part of the network and the encoder are initialized. The performance of the improved initialisation scheme is evaluated on a Wiener-Hammerstein simulation example and a benchmark dataset. The results show that for a weakly nonlinear system, the proposed initialisation based on the linear reconstructability map results in a faster convergence and a better model quality.","sentences":["The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data.","To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as a neural network.","The encoder function is introduced to reconstruct the current state from past input-output data.","Hence it enables the forward simulation of the rolled-out state-space model.","While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process.","This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA).","Using the BLA provided state-space matrices and its associated reconstructability map both the state-transition part of the network and the encoder are initialized.","The performance of the improved initialisation scheme is evaluated on a Wiener-Hammerstein simulation example and a benchmark dataset.","The results show that for a weakly nonlinear system, the proposed initialisation based on the linear reconstructability map results in a faster convergence and a better model quality."],"url":"http://arxiv.org/abs/2304.02119v1"}
{"created":"2023-04-04","title":"Statistics of extreme events in coarse-scale climate simulations via machine learning correction operators trained on nudged datasets","abstract":"This work presents a systematic framework for improving the predictions of statistical quantities for turbulent systems, with a focus on correcting climate simulations obtained by coarse-scale models. While high resolution simulations or reanalysis data are available, they cannot be directly used as training datasets to machine learn a correction for the coarse-scale climate model outputs, since chaotic divergence, inherent in the climate dynamics, makes datasets from different resolutions incompatible. To overcome this fundamental limitation we employ coarse-resolution model simulations nudged towards high quality climate realizations, here in the form of ERA5 reanalysis data. The nudging term is sufficiently small to not pollute the coarse-scale dynamics over short time scales, but also sufficiently large to keep the coarse-scale simulations close to the ERA5 trajectory over larger time scales. The result is a compatible pair of the ERA5 trajectory and the weakly nudged coarse-resolution E3SM output that is used as input training data to machine learn a correction operator. Once training is complete, we perform free-running coarse-scale E3SM simulations without nudging and use those as input to the machine-learned correction operator to obtain high-quality (corrected) outputs. The model is applied to atmospheric climate data with the purpose of predicting global and local statistics of various quantities of a time-period of a decade. Using datasets that are not employed for training, we demonstrate that the produced datasets from the ML-corrected coarse E3SM model have statistical properties that closely resemble the observations. Furthermore, the corrected coarse-scale E3SM output for the frequency of occurrence of extreme events, such as tropical cyclones and atmospheric rivers are presented. We present thorough comparisons and discuss limitations of the approach.","sentences":["This work presents a systematic framework for improving the predictions of statistical quantities for turbulent systems, with a focus on correcting climate simulations obtained by coarse-scale models.","While high resolution simulations or reanalysis data are available, they cannot be directly used as training datasets to machine learn a correction for the coarse-scale climate model outputs, since chaotic divergence, inherent in the climate dynamics, makes datasets from different resolutions incompatible.","To overcome this fundamental limitation we employ coarse-resolution model simulations nudged towards high quality climate realizations, here in the form of ERA5 reanalysis data.","The nudging term is sufficiently small to not pollute the coarse-scale dynamics over short time scales, but also sufficiently large to keep the coarse-scale simulations close to the ERA5 trajectory over larger time scales.","The result is a compatible pair of the ERA5 trajectory and the weakly nudged coarse-resolution E3SM output that is used as input training data to machine learn a correction operator.","Once training is complete, we perform free-running coarse-scale E3SM simulations without nudging and use those as input to the machine-learned correction operator to obtain high-quality (corrected) outputs.","The model is applied to atmospheric climate data with the purpose of predicting global and local statistics of various quantities of a time-period of a decade.","Using datasets that are not employed for training, we demonstrate that the produced datasets from the ML-corrected coarse E3SM model have statistical properties that closely resemble the observations.","Furthermore, the corrected coarse-scale E3SM output for the frequency of occurrence of extreme events, such as tropical cyclones and atmospheric rivers are presented.","We present thorough comparisons and discuss limitations of the approach."],"url":"http://arxiv.org/abs/2304.02117v1"}
{"created":"2023-04-04","title":"Model-independent study for a quintessence model of dark energy: Analysis and Observational constraints","abstract":"In this paper, a well motivated parametrization of the Hubble parameter ($H$% ) is revisited that renders two models of dark energy showing some intriguing features of Late-time accelerating universe. A general quintessence field is considered as a source of dark energy. We have obtained tighter constraints using recently updated cosmic observational datasets for the considered models. The two models described here show a nice fit to the considered uncorrelated Hubble datasets, Standard candles, Gamma Ray Bursts, Quasars, and uncorrelated Baryonic Acoustic Oscillations datasets. Using the constrained values of the model parameters, we have discussed some features of the late-time accelerating models and obtained the present value of the deceleration parameter ($q_{0}$), the present value of the Hubble parameter ($H_{0}$) and the transition redshift ($z_{t}$) from deceleration to acceleration. The $q_{0}$ values for both models are consistent with the Planck 2018 results. The evolution of the geometrical and physical parameters is discussed through some graphical representations for both models with some diagnostic analysis. The statistical analysis performed here shows more significant results, and overall, the outcomes of this investigation are superior to those previously found.","sentences":["In this paper, a well motivated parametrization of the Hubble parameter ($H$% ) is revisited that renders two models of dark energy showing some intriguing features of Late-time accelerating universe.","A general quintessence field is considered as a source of dark energy.","We have obtained tighter constraints using recently updated cosmic observational datasets for the considered models.","The two models described here show a nice fit to the considered uncorrelated Hubble datasets, Standard candles, Gamma Ray Bursts, Quasars, and uncorrelated Baryonic Acoustic Oscillations datasets.","Using the constrained values of the model parameters, we have discussed some features of the late-time accelerating models and obtained the present value of the deceleration parameter ($q_{0}$), the present value of the Hubble parameter ($H_{0}$) and the transition redshift ($z_{t}$) from deceleration to acceleration.","The $q_{0}$ values for both models are consistent with the Planck 2018 results.","The evolution of the geometrical and physical parameters is discussed through some graphical representations for both models with some diagnostic analysis.","The statistical analysis performed here shows more significant results, and overall, the outcomes of this investigation are superior to those previously found."],"url":"http://arxiv.org/abs/2304.02652v1"}
{"created":"2023-04-04","title":"Uncertainty estimation in Deep Learning for Panoptic segmentation","abstract":"As deep learning-based computer vision algorithms continue to improve and advance the state of the art, their robustness to real-world data continues to lag their performance on datasets. This makes it difficult to bring an algorithm from the lab to the real world. Ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout have been successfully used in many applications in an attempt to address this robustness issue. Unfortunately, it is not always clear if such ensemble-based approaches can be applied to a new problem domain. This is the case with panoptic segmentation, where the structure of the problem and architectures designed to solve it means that unlike image classification or even semantic segmentation, the typical solution of using a mean across samples cannot be directly applied. In this paper, we demonstrate how ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout can be used in the panoptic segmentation domain with no changes to an existing network, providing both improved performance and more importantly a better measure of uncertainty for predictions made by the network. Results are demonstrated quantitatively and qualitatively on the COCO, KITTI-STEP and VIPER datasets.","sentences":["As deep learning-based computer vision algorithms continue to improve and advance the state of the art, their robustness to real-world data continues to lag their performance on datasets.","This makes it difficult to bring an algorithm from the lab to the real world.","Ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout have been successfully used in many applications in an attempt to address this robustness issue.","Unfortunately, it is not always clear if such ensemble-based approaches can be applied to a new problem domain.","This is the case with panoptic segmentation, where the structure of the problem and architectures designed to solve it means that unlike image classification or even semantic segmentation, the typical solution of using a mean across samples cannot be directly applied.","In this paper, we demonstrate how ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout can be used in the panoptic segmentation domain with no changes to an existing network, providing both improved performance and more importantly a better measure of uncertainty for predictions made by the network.","Results are demonstrated quantitatively and qualitatively on the COCO, KITTI-STEP and VIPER datasets."],"url":"http://arxiv.org/abs/2304.02098v1"}
{"created":"2023-04-04","title":"EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT","abstract":"We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images. This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images. We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem. EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls. The dataset also contains 2D image labels that are used in the supervised training of an ink detection model. Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers. To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain. Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth. Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review. EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here. We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues.","sentences":["We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images.","This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images.","We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem.","EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls.","The dataset also contains 2D image labels that are used in the supervised training of an ink detection model.","Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities.","This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers.","To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth.","Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review.","EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here.","We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues."],"url":"http://arxiv.org/abs/2304.02084v1"}
{"created":"2023-04-04","title":"Scalable and Accurate Self-supervised Multimodal Representation Learning without Aligned Video and Text Data","abstract":"Scaling up weakly-supervised datasets has shown to be highly effective in the image-text domain and has contributed to most of the recent state-of-the-art computer vision and multimodal neural networks. However, existing large-scale video-text datasets and mining techniques suffer from several limitations, such as the scarcity of aligned data, the lack of diversity in the data, and the difficulty of collecting aligned data. Currently popular video-text data mining approach via automatic speech recognition (ASR) used in HowTo100M provides low-quality captions that often do not refer to the video content. Other mining approaches do not provide proper language descriptions (video tags) and are biased toward short clips (alt text). In this work, we show how recent advances in image captioning allow us to pre-train high-quality video models without any parallel video-text data. We pre-train several video captioning models that are based on an OPT language model and a TimeSformer visual backbone. We fine-tune these networks on several video captioning datasets. First, we demonstrate that image captioning pseudolabels work better for pre-training than the existing HowTo100M ASR captions. Second, we show that pre-training on both images and videos produces a significantly better network (+4 CIDER on MSR-VTT) than pre-training on a single modality. Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings. Given the efficacy of the pseudolabeling method, we are planning to publicly release the generated captions.","sentences":["Scaling up weakly-supervised datasets has shown to be highly effective in the image-text domain and has contributed to most of the recent state-of-the-art computer vision and multimodal neural networks.","However, existing large-scale video-text datasets and mining techniques suffer from several limitations, such as the scarcity of aligned data, the lack of diversity in the data, and the difficulty of collecting aligned data.","Currently popular video-text data mining approach via automatic speech recognition (ASR) used in HowTo100M provides low-quality captions that often do not refer to the video content.","Other mining approaches do not provide proper language descriptions (video tags) and are biased toward short clips (alt text).","In this work, we show how recent advances in image captioning allow us to pre-train high-quality video models without any parallel video-text data.","We pre-train several video captioning models that are based on an OPT language model and a TimeSformer visual backbone.","We fine-tune these networks on several video captioning datasets.","First, we demonstrate that image captioning pseudolabels work better for pre-training than the existing HowTo100M ASR captions.","Second, we show that pre-training on both images and videos produces a significantly better network (+4 CIDER on MSR-VTT) than pre-training on a single modality.","Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings.","Given the efficacy of the pseudolabeling method, we are planning to publicly release the generated captions."],"url":"http://arxiv.org/abs/2304.02080v1"}
{"created":"2023-04-04","title":"Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing","abstract":"Fashion illustration is used by designers to communicate their vision and to bring the design idea from conceptualization to realization, showing how clothes interact with the human body. In this context, computer vision can thus be used to improve the fashion design process. Differently from previous works that mainly focused on the virtual try-on of garments, we propose the task of multimodal-conditioned fashion image editing, guiding the generation of human-centric fashion images by following multimodal prompts, such as text, human body poses, and garment sketches. We tackle this problem by proposing a new architecture based on latent diffusion models, an approach that has not been used before in the fashion domain. Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner. Experimental results on these new datasets demonstrate the effectiveness of our proposal, both in terms of realism and coherence with the given multimodal inputs. Source code and collected multimodal annotations will be publicly released at: https://github.com/aimagelab/multimodal-garment-designer.","sentences":["Fashion illustration is used by designers to communicate their vision and to bring the design idea from conceptualization to realization, showing how clothes interact with the human body.","In this context, computer vision can thus be used to improve the fashion design process.","Differently from previous works that mainly focused on the virtual try-on of garments, we propose the task of multimodal-conditioned fashion image editing, guiding the generation of human-centric fashion images by following multimodal prompts, such as text, human body poses, and garment sketches.","We tackle this problem by proposing a new architecture based on latent diffusion models, an approach that has not been used before in the fashion domain.","Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner.","Experimental results on these new datasets demonstrate the effectiveness of our proposal, both in terms of realism and coherence with the given multimodal inputs.","Source code and collected multimodal annotations will be publicly released at: https://github.com/aimagelab/multimodal-garment-designer."],"url":"http://arxiv.org/abs/2304.02051v1"}
{"created":"2023-04-04","title":"Multi-Class Explainable Unlearning for Image Classification via Weight Filtering","abstract":"Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work provides interesting insights in the development of explainable solutions for unlearning and could be easily extended to other vision tasks.","sentences":["Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network.","While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round.","Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes.","By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design.","We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones.","Our work provides interesting insights in the development of explainable solutions for unlearning and could be easily extended to other vision tasks."],"url":"http://arxiv.org/abs/2304.02049v1"}
{"created":"2023-04-04","title":"Multi-Level Contrastive Learning for Dense Prediction Task","abstract":"In this work, we present Multi-Level Contrastive Learning for Dense Prediction Task (MCL), an efficient self-supervised method for learning region-level feature representation for dense prediction tasks. Our method is motivated by the three key factors in detection: localization, scale consistency and recognition. To explicitly encode absolute position and scale information, we propose a novel pretext task that assembles multi-scale images in a montage manner to mimic multi-object scenarios. Unlike the existing image-level self-supervised methods, our method constructs a multi-level contrastive loss that considers each sub-region of the montage image as a singleton. Our method enables the neural network to learn regional semantic representations for translation and scale consistency while reducing pre-training epochs to the same as supervised pre-training. Extensive experiments demonstrate that MCL consistently outperforms the recent state-of-the-art methods on various datasets with significant margins. In particular, MCL obtains 42.5 AP$^\\mathrm{bb}$ and 38.3 AP$^\\mathrm{mk}$ on COCO with the 1x schedule fintuning, when using Mask R-CNN with R50-FPN backbone pre-trained with 100 epochs. In comparison to MoCo, our method surpasses their performance by 4.0 AP$^\\mathrm{bb}$ and 3.1 AP$^\\mathrm{mk}$. Furthermore, we explore the alignment between pretext task and downstream tasks. We extend our pretext task to supervised pre-training, which achieves a similar performance to self-supervised learning. This result demonstrates the importance of the alignment between pretext task and downstream tasks, indicating the potential for wider applicability of our method beyond self-supervised settings.","sentences":["In this work, we present Multi-Level Contrastive Learning for Dense Prediction Task (MCL), an efficient self-supervised method for learning region-level feature representation for dense prediction tasks.","Our method is motivated by the three key factors in detection: localization, scale consistency and recognition.","To explicitly encode absolute position and scale information, we propose a novel pretext task that assembles multi-scale images in a montage manner to mimic multi-object scenarios.","Unlike the existing image-level self-supervised methods, our method constructs a multi-level contrastive loss that considers each sub-region of the montage image as a singleton.","Our method enables the neural network to learn regional semantic representations for translation and scale consistency while reducing pre-training epochs to the same as supervised pre-training.","Extensive experiments demonstrate that MCL consistently outperforms the recent state-of-the-art methods on various datasets with significant margins.","In particular, MCL obtains 42.5 AP$^\\mathrm{bb}$ and 38.3 AP$^\\mathrm{mk}$ on COCO with the 1x schedule fintuning, when using Mask R-CNN with R50-FPN backbone pre-trained with 100 epochs.","In comparison to MoCo, our method surpasses their performance by 4.0 AP$^\\mathrm{bb}$ and","3.1 AP$^\\mathrm{mk}$.","Furthermore, we explore the alignment between pretext task and downstream tasks.","We extend our pretext task to supervised pre-training, which achieves a similar performance to self-supervised learning.","This result demonstrates the importance of the alignment between pretext task and downstream tasks, indicating the potential for wider applicability of our method beyond self-supervised settings."],"url":"http://arxiv.org/abs/2304.02010v1"}
{"created":"2023-04-04","title":"OrienterNet: Visual Localization in 2D Public Maps with Neural Matching","abstract":"Humans can orient themselves in their 3D environments using simple 2D maps. Differently, algorithms for visual localization mostly rely on complex 3D point clouds that are expensive to build, store, and maintain over time. We bridge this gap by introducing OrienterNet, the first deep neural network that can localize an image with sub-meter accuracy using the same 2D semantic maps that humans use. OrienterNet estimates the location and orientation of a query image by matching a neural Bird's-Eye View with open and globally available maps from OpenStreetMap, enabling anyone to localize anywhere such maps are available. OrienterNet is supervised only by camera poses but learns to perform semantic matching with a wide range of map elements in an end-to-end manner. To enable this, we introduce a large crowd-sourced dataset of images captured across 12 cities from the diverse viewpoints of cars, bikes, and pedestrians. OrienterNet generalizes to new datasets and pushes the state of the art in both robotics and AR scenarios. The code and trained model will be released publicly.","sentences":["Humans can orient themselves in their 3D environments using simple 2D maps.","Differently, algorithms for visual localization mostly rely on complex 3D point clouds that are expensive to build, store, and maintain over time.","We bridge this gap by introducing OrienterNet, the first deep neural network that can localize an image with sub-meter accuracy using the same 2D semantic maps that humans use.","OrienterNet estimates the location and orientation of a query image by matching a neural Bird's-Eye View with open and globally available maps from OpenStreetMap, enabling anyone to localize anywhere such maps are available.","OrienterNet is supervised only by camera poses but learns to perform semantic matching with a wide range of map elements in an end-to-end manner.","To enable this, we introduce a large crowd-sourced dataset of images captured across 12 cities from the diverse viewpoints of cars, bikes, and pedestrians.","OrienterNet generalizes to new datasets and pushes the state of the art in both robotics and AR scenarios.","The code and trained model will be released publicly."],"url":"http://arxiv.org/abs/2304.02009v1"}
{"created":"2023-04-04","title":"GlueStick: Robust Image Matching by Sticking Points and Lines Together","abstract":"Line segments are powerful features complementary to points. They offer structural cues, robust to drastic viewpoint and illumination changes, and can be present even in texture-less areas. However, describing and matching them is more challenging compared to points due to partial occlusions, lack of texture, or repetitiveness. This paper introduces a new matching paradigm, where points, lines, and their descriptors are unified into a single wireframe structure. We propose GlueStick, a deep matching Graph Neural Network (GNN) that takes two wireframes from different images and leverages the connectivity information between nodes to better glue them together. In addition to the increased efficiency brought by the joint matching, we also demonstrate a large boost of performance when leveraging the complementary nature of these two features in a single architecture. We show that our matching strategy outperforms the state-of-the-art approaches independently matching line segments and points for a wide variety of datasets and tasks. The code is available at https://github.com/cvg/GlueStick.","sentences":["Line segments are powerful features complementary to points.","They offer structural cues, robust to drastic viewpoint and illumination changes, and can be present even in texture-less areas.","However, describing and matching them is more challenging compared to points due to partial occlusions, lack of texture, or repetitiveness.","This paper introduces a new matching paradigm, where points, lines, and their descriptors are unified into a single wireframe structure.","We propose GlueStick, a deep matching Graph Neural Network (GNN) that takes two wireframes from different images and leverages the connectivity information between nodes to better glue them together.","In addition to the increased efficiency brought by the joint matching, we also demonstrate a large boost of performance when leveraging the complementary nature of these two features in a single architecture.","We show that our matching strategy outperforms the state-of-the-art approaches independently matching line segments and points for a wide variety of datasets and tasks.","The code is available at https://github.com/cvg/GlueStick."],"url":"http://arxiv.org/abs/2304.02008v1"}
{"created":"2023-04-04","title":"Inference of the low-energy constants in delta-full chiral effective field theory including a correlated truncation error","abstract":"We sample the posterior probability distributions of the low-energy constants (LECs) in delta-full chiral effective field theory ($\\chi$EFT) up to third order. We use eigenvector continuation for fast and accurate emulation of the likelihood and Hamiltonian Monte Carlo to draw effectively independent samples from the posteriors. Our Bayesian inference is conditioned on the Granada database of neutron-proton ($np$) cross sections and polarizations. We use priors grounded in $\\chi$EFT assumptions and a Roy-Steiner analysis of pion-nucleon scattering data. We model correlated EFT truncation errors using a two-feature Gaussian process, and find correlation lengths for $np$ scattering energies and angles in the ranges 40--120 MeV and 25--45 degrees, respectively. These correlations yield a non-diagonal covariance matrix and reduce the number of independent scattering data with a factor of eight and four at the second and third chiral orders, respectively. The relatively small difference between the second and third order predictions in delta-full $\\chi$EFT suppresses the marginal variance of the truncation error and the effects of its correlation structure. Our results are particularly important for analyzing the predictive capabilities in \\textit{ab initio} nuclear theory.","sentences":["We sample the posterior probability distributions of the low-energy constants (LECs) in delta-full chiral effective field theory ($\\chi$EFT) up to third order.","We use eigenvector continuation for fast and accurate emulation of the likelihood and Hamiltonian Monte Carlo to draw effectively independent samples from the posteriors.","Our Bayesian inference is conditioned on the Granada database of neutron-proton ($np$) cross sections and polarizations.","We use priors grounded in $\\chi$EFT assumptions and a Roy-Steiner analysis of pion-nucleon scattering data.","We model correlated EFT truncation errors using a two-feature Gaussian process, and find correlation lengths for $np$ scattering energies and angles in the ranges 40--120 MeV and 25--45 degrees, respectively.","These correlations yield a non-diagonal covariance matrix and reduce the number of independent scattering data with a factor of eight and four at the second and third chiral orders, respectively.","The relatively small difference between the second and third order predictions in delta-full $\\chi$EFT suppresses the marginal variance of the truncation error and the effects of its correlation structure.","Our results are particularly important for analyzing the predictive capabilities in \\textit{ab initio} nuclear theory."],"url":"http://arxiv.org/abs/2304.02004v1"}
{"created":"2023-04-04","title":"Revisiting the Evaluation of Image Synthesis with GANs","abstract":"A good metric, which promises a reliable comparison between solutions, is essential to a well-defined task. Unlike most vision tasks that have per-sample ground-truth, image synthesis targets generating \\emph{unseen} data and hence is usually evaluated with a distributional distance between one set of real samples and another set of generated samples. This work provides an empirical study on the evaluation of synthesis performance by taking the popular generative adversarial networks (GANs) as a representative of generative models. In particular, we make in-depth analyses on how to represent a data point in the feature space, how to calculate a fair distance using selected samples, and how many instances to use from each set. Experiments on multiple datasets and settings suggest that (1) a group of models including both CNN-based and ViT-based architectures serve as reliable and robust feature extractors, (2) Centered Kernel Alignment (CKA) enables better comparison across various extractors and hierarchical layers in one model, and (3) CKA shows satisfactory sample efficiency and complements existing metrics (\\textit{e.g.}, FID) in characterizing the similarity between two internal data correlations. These findings help us design a new measurement system, based on which we re-evaluate the state-of-the-art generative models in a consistent and reliable way.","sentences":["A good metric, which promises a reliable comparison between solutions, is essential to a well-defined task.","Unlike most vision tasks that have per-sample ground-truth, image synthesis targets generating \\emph{unseen} data and hence is usually evaluated with a distributional distance between one set of real samples and another set of generated samples.","This work provides an empirical study on the evaluation of synthesis performance by taking the popular generative adversarial networks (GANs) as a representative of generative models.","In particular, we make in-depth analyses on how to represent a data point in the feature space, how to calculate a fair distance using selected samples, and how many instances to use from each set.","Experiments on multiple datasets and settings suggest that (1) a group of models including both CNN-based and ViT-based architectures serve as reliable and robust feature extractors, (2) Centered Kernel Alignment (CKA) enables better comparison across various extractors and hierarchical layers in one model, and (3) CKA shows satisfactory sample efficiency and complements existing metrics (\\textit{e.g.}, FID) in characterizing the similarity between two internal data correlations.","These findings help us design a new measurement system, based on which we re-evaluate the state-of-the-art generative models in a consistent and reliable way."],"url":"http://arxiv.org/abs/2304.01999v1"}
{"created":"2023-04-04","title":"Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution","abstract":"This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR). It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT). By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space. Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff. Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time. Finally, our work highlights its potential for various applications.","sentences":["This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR).","It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT).","By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space.","Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks.","Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff.","Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time.","Finally, our work highlights its potential for various applications."],"url":"http://arxiv.org/abs/2304.01994v2"}
{"created":"2023-04-04","title":"USTC FLICAR: A Multisensor Fusion Dataset of LiDAR-Inertial-Camera for Heavy-duty Autonomous Aerial Work Robots","abstract":"In this paper, we present the USTC FLICAR Dataset, which is dedicated to the development of simultaneous localization and mapping and precise 3D reconstruction of the workspace for heavy-duty autonomous aerial work robots. In recent years, numerous public datasets have played significant roles in the advancement of autonomous cars and unmanned aerial vehicles (UAVs). However, these two platforms differ from aerial work robots: UAVs are limited in their payload capacity, while cars are restricted to two-dimensional movements. To fill this gap, we create the Giraffe mapping robot based on a bucket truck, which is equipped with a variety of well-calibrated and synchronized sensors: four 3D LiDARs, two stereo cameras, two monocular cameras, Inertial Measurement Units (IMUs), and a GNSS/INS system. A laser tracker is used to record the millimeter-level ground truth positions. We also make its ground twin, the Okapi mapping robot, to gather data for comparison. The proposed dataset extends the typical autonomous driving sensing suite to aerial scenes. Therefore, the dataset is named FLICAR to denote flying cars. We believe this dataset can also represent the flying car scenarios, specifically the takeoff and landing of VTOL (Vertical Takeoff and Landing) flying cars. The dataset is available for download at: https://ustc-flicar.github.io.","sentences":["In this paper, we present the USTC FLICAR Dataset, which is dedicated to the development of simultaneous localization and mapping and precise 3D reconstruction of the workspace for heavy-duty autonomous aerial work robots.","In recent years, numerous public datasets have played significant roles in the advancement of autonomous cars and unmanned aerial vehicles (UAVs).","However, these two platforms differ from aerial work robots: UAVs are limited in their payload capacity, while cars are restricted to two-dimensional movements.","To fill this gap, we create the Giraffe mapping robot based on a bucket truck, which is equipped with a variety of well-calibrated and synchronized sensors: four 3D LiDARs, two stereo cameras, two monocular cameras, Inertial Measurement Units (IMUs), and a GNSS/INS system.","A laser tracker is used to record the millimeter-level ground truth positions.","We also make its ground twin, the Okapi mapping robot, to gather data for comparison.","The proposed dataset extends the typical autonomous driving sensing suite to aerial scenes.","Therefore, the dataset is named FLICAR to denote flying cars.","We believe this dataset can also represent the flying car scenarios, specifically the takeoff and landing of VTOL (Vertical Takeoff and Landing) flying cars.","The dataset is available for download at: https://ustc-flicar.github.io."],"url":"http://arxiv.org/abs/2304.01986v1"}
{"created":"2023-04-04","title":"ERM++: An Improved Baseline for Domain Generalization","abstract":"Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains. While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels. Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods. We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization. We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive. Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark. We hope that ERM++ becomes a strong baseline for future DG research. Code is released at https://github.com/piotr-teterwak/erm_plusplus.","sentences":["Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains.","While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels.","Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods.","We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization.","We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive.","Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark.","We hope that ERM++ becomes a strong baseline for future DG research.","Code is released at https://github.com/piotr-teterwak/erm_plusplus."],"url":"http://arxiv.org/abs/2304.01973v1"}
{"created":"2023-04-04","title":"MEGClass: Text Classification with Extremely Weak Supervision via Mutually-Enhancing Text Granularities","abstract":"Text classification typically requires a substantial amount of human-annotated data to serve as supervision, which is costly to obtain in dynamic emerging domains. Certain methods seek to address this problem by solely relying on the surface text of class names to serve as extremely weak supervision. However, existing methods fail to account for single-class documents discussing multiple topics. Both topic diversity and vague sentences may introduce noise into the document's underlying representation and consequently the precision of the predicted class. Furthermore, current work focuses on text granularities (documents, sentences, or words) independently, which limits the degree of coarse- or fine-grained context that we can jointly extract from all three to identify significant subtext for classification. In order to address this problem, we propose MEGClass, an extremely weakly-supervised text classification method to exploit Mutually-Enhancing Text Granularities. Specifically, MEGClass constructs class-oriented sentence and class representations based on keywords for performing a sentence-level confidence-weighted label ensemble in order to estimate a document's initial class distribution. This serves as the target distribution for a multi-head attention network with a class-weighted contrastive loss. This network learns contextualized sentence representations and weights to form document representations that reflect its original document and sentence-level topic diversity. Retaining this heterogeneity allows MEGClass to select the most class-indicative documents to serve as iterative feedback for enhancing the class representations. Finally, these top documents are used to fine-tune a pre-trained text classifier. As demonstrated through extensive experiments on six benchmark datasets, MEGClass outperforms other weakly and extremely weakly supervised methods.","sentences":["Text classification typically requires a substantial amount of human-annotated data to serve as supervision, which is costly to obtain in dynamic emerging domains.","Certain methods seek to address this problem by solely relying on the surface text of class names to serve as extremely weak supervision.","However, existing methods fail to account for single-class documents discussing multiple topics.","Both topic diversity and vague sentences may introduce noise into the document's underlying representation and consequently the precision of the predicted class.","Furthermore, current work focuses on text granularities (documents, sentences, or words) independently, which limits the degree of coarse- or fine-grained context that we can jointly extract from all three to identify significant subtext for classification.","In order to address this problem, we propose MEGClass, an extremely weakly-supervised text classification method to exploit Mutually-Enhancing Text Granularities.","Specifically, MEGClass constructs class-oriented sentence and class representations based on keywords for performing a sentence-level confidence-weighted label ensemble in order to estimate a document's initial class distribution.","This serves as the target distribution for a multi-head attention network with a class-weighted contrastive loss.","This network learns contextualized sentence representations and weights to form document representations that reflect its original document and sentence-level topic diversity.","Retaining this heterogeneity allows MEGClass to select the most class-indicative documents to serve as iterative feedback for enhancing the class representations.","Finally, these top documents are used to fine-tune a pre-trained text classifier.","As demonstrated through extensive experiments on six benchmark datasets, MEGClass outperforms other weakly and extremely weakly supervised methods."],"url":"http://arxiv.org/abs/2304.01969v1"}
{"created":"2023-04-04","title":"Ethylene Leak Detection Based on Infrared Imaging: A Benchmark","abstract":"Ethylene leakage detection has become one of the most important research directions in the field of target detection due to the fact that ethylene leakage in the petrochemical industry is closely related to production safety and environmental pollution. Under infrared conditions, there are many factors that affect the texture characteristics of ethylene, such as ethylene concentration, background, and so on. We find that the detection criteria used in infrared imaging ethylene leakage detection research cannot fully reflect real-world production conditions, which is not conducive to evaluate the performance of current image-based target detection methods. Therefore, we create a new infrared image dataset of ethylene leakage with different concentrations and backgrounds, including 54275 images. We use the proposed dataset benchmark to evaluate seven advanced image-based target detection algorithms. Experimental results demonstrate the performance and limitations of existing algorithms, and the dataset benchmark has good versatility and effectiveness.","sentences":["Ethylene leakage detection has become one of the most important research directions in the field of target detection due to the fact that ethylene leakage in the petrochemical industry is closely related to production safety and environmental pollution.","Under infrared conditions, there are many factors that affect the texture characteristics of ethylene, such as ethylene concentration, background, and so on.","We find that the detection criteria used in infrared imaging ethylene leakage detection research cannot fully reflect real-world production conditions, which is not conducive to evaluate the performance of current image-based target detection methods.","Therefore, we create a new infrared image dataset of ethylene leakage with different concentrations and backgrounds, including 54275 images.","We use the proposed dataset benchmark to evaluate seven advanced image-based target detection algorithms.","Experimental results demonstrate the performance and limitations of existing algorithms, and the dataset benchmark has good versatility and effectiveness."],"url":"http://arxiv.org/abs/2304.01962v1"}
{"created":"2023-04-04","title":"AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation","abstract":"This paper presents the AToMiC (Authoring Tools for Multimedia Content) dataset, designed to advance research in image/text cross-modal retrieval. While vision-language pretrained transformers have led to significant improvements in retrieval effectiveness, existing research has relied on image-caption datasets that feature only simplistic image-text relationships and underspecified user models of retrieval tasks. To address the gap between these oversimplified settings and real-world applications for multimedia content creation, we introduce a new approach for building retrieval test collections. We leverage hierarchical structures and diverse domains of texts, styles, and types of images, as well as large-scale image-document associations embedded in Wikipedia. We formulate two tasks based on a realistic user model and validate our dataset through retrieval experiments using baseline models. AToMiC offers a testbed for scalable, diverse, and reproducible multimedia retrieval research. Finally, the dataset provides the basis for a dedicated track at the 2023 Text Retrieval Conference (TREC), and is publicly available at https://github.com/TREC-AToMiC/AToMiC.","sentences":["This paper presents the AToMiC (Authoring Tools for Multimedia Content) dataset, designed to advance research in image/text cross-modal retrieval.","While vision-language pretrained transformers have led to significant improvements in retrieval effectiveness, existing research has relied on image-caption datasets that feature only simplistic image-text relationships and underspecified user models of retrieval tasks.","To address the gap between these oversimplified settings and real-world applications for multimedia content creation, we introduce a new approach for building retrieval test collections.","We leverage hierarchical structures and diverse domains of texts, styles, and types of images, as well as large-scale image-document associations embedded in Wikipedia.","We formulate two tasks based on a realistic user model and validate our dataset through retrieval experiments using baseline models.","AToMiC offers a testbed for scalable, diverse, and reproducible multimedia retrieval research.","Finally, the dataset provides the basis for a dedicated track at the 2023 Text Retrieval Conference (TREC), and is publicly available at https://github.com/TREC-AToMiC/AToMiC."],"url":"http://arxiv.org/abs/2304.01961v1"}
{"created":"2023-04-04","title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models","abstract":"The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance. To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks. The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA. The framework is designed to be research-friendly, efficient, modular, and extendable, allowing the integration of new adapters and the evaluation of them with new and larger-scale LLMs. Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we conduct experiments on six math reasoning datasets. The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning datasets. Overall, we provide a promising framework for fine-tuning large LLMs on downstream tasks. We believe the proposed LLMs-Adapters will advance adapter-based PEFT research, facilitate the deployment of research pipelines, and enable practical applications to real-world systems.","sentences":["The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca).","Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance.","To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks.","The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA.","The framework is designed to be research-friendly, efficient, modular, and extendable, allowing the integration of new adapters and the evaluation of them with new and larger-scale LLMs.","Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we conduct experiments on six math reasoning datasets.","The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning datasets.","Overall, we provide a promising framework for fine-tuning large LLMs on downstream tasks.","We believe the proposed LLMs-Adapters will advance adapter-based PEFT research, facilitate the deployment of research pipelines, and enable practical applications to real-world systems."],"url":"http://arxiv.org/abs/2304.01933v1"}
{"created":"2023-04-04","title":"High-Throughput Vector Similarity Search in Knowledge Graphs","abstract":"There is an increasing adoption of machine learning for encoding data into vectors to serve online recommendation and search use cases. As a result, recent data management systems propose augmenting query processing with online vector similarity search. In this work, we explore vector similarity search in the context of Knowledge Graphs (KGs). Motivated by the tasks of finding related KG queries and entities for past KG query workloads, we focus on hybrid vector similarity search (hybrid queries for short) where part of the query corresponds to vector similarity search and part of the query corresponds to predicates over relational attributes associated with the underlying data vectors. For example, given past KG queries for a song entity, we want to construct new queries for new song entities whose vector representations are close to the vector representation of the entity in the past KG query. But entities in a KG also have non-vector attributes such as a song associated with an artist, a genre, and a release date. Therefore, suggested entities must also satisfy query predicates over non-vector attributes beyond a vector-based similarity predicate. While these tasks are central to KGs, our contributions are generally applicable to hybrid queries. In contrast to prior works that optimize online queries, we focus on enabling efficient batch processing of past hybrid query workloads. We present our system, HQI, for high-throughput batch processing of hybrid queries. We introduce a workload-aware vector data partitioning scheme to tailor the vector index layout to the given workload and describe a multi-query optimization technique to reduce the overhead of vector similarity computations. We evaluate our methods on industrial workloads and demonstrate that HQI yields a 31x improvement in throughput for finding related KG queries compared to existing hybrid query processing approaches.","sentences":["There is an increasing adoption of machine learning for encoding data into vectors to serve online recommendation and search use cases.","As a result, recent data management systems propose augmenting query processing with online vector similarity search.","In this work, we explore vector similarity search in the context of Knowledge Graphs (KGs).","Motivated by the tasks of finding related KG queries and entities for past KG query workloads, we focus on hybrid vector similarity search (hybrid queries for short) where part of the query corresponds to vector similarity search and part of the query corresponds to predicates over relational attributes associated with the underlying data vectors.","For example, given past KG queries for a song entity, we want to construct new queries for new song entities whose vector representations are close to the vector representation of the entity in the past KG query.","But entities in a KG also have non-vector attributes such as a song associated with an artist, a genre, and a release date.","Therefore, suggested entities must also satisfy query predicates over non-vector attributes beyond a vector-based similarity predicate.","While these tasks are central to KGs, our contributions are generally applicable to hybrid queries.","In contrast to prior works that optimize online queries, we focus on enabling efficient batch processing of past hybrid query workloads.","We present our system, HQI, for high-throughput batch processing of hybrid queries.","We introduce a workload-aware vector data partitioning scheme to tailor the vector index layout to the given workload and describe a multi-query optimization technique to reduce the overhead of vector similarity computations.","We evaluate our methods on industrial workloads and demonstrate that HQI yields a 31x improvement in throughput for finding related KG queries compared to existing hybrid query processing approaches."],"url":"http://arxiv.org/abs/2304.01926v1"}
{"created":"2023-04-04","title":"Resources and Few-shot Learners for In-context Learning in Slavic Languages","abstract":"Despite the rapid recent progress in creating accurate and compact in-context learners, most recent work focuses on in-context learning (ICL) for tasks in English. However, the ability to interact with users of languages outside English presents a great potential for broadening the applicability of language technologies to non-English speakers.   In this work, we collect the infrastructure necessary for training and evaluation of ICL in a selection of Slavic languages: Czech, Polish, and Russian. We link a diverse set of datasets and cast these into a unified instructional format through a set of transformations and newly-crafted templates written purely in target languages. Using the newly-curated dataset, we evaluate a set of the most recent in-context learners and compare their results to the supervised baselines. Finally, we train, evaluate and publish a set of in-context learning models that we train on the collected resources and compare their performance to previous work.   We find that ICL models tuned in English are also able to learn some tasks from non-English contexts, but multilingual instruction fine-tuning consistently improves the ICL ability. We also find that the massive multitask training can be outperformed by single-task training in the target language, uncovering the potential for specializing in-context learners to the language(s) of their application.","sentences":["Despite the rapid recent progress in creating accurate and compact in-context learners, most recent work focuses on in-context learning (ICL) for tasks in English.","However, the ability to interact with users of languages outside English presents a great potential for broadening the applicability of language technologies to non-English speakers.   ","In this work, we collect the infrastructure necessary for training and evaluation of ICL in a selection of Slavic languages: Czech, Polish, and Russian.","We link a diverse set of datasets and cast these into a unified instructional format through a set of transformations and newly-crafted templates written purely in target languages.","Using the newly-curated dataset, we evaluate a set of the most recent in-context learners and compare their results to the supervised baselines.","Finally, we train, evaluate and publish a set of in-context learning models that we train on the collected resources and compare their performance to previous work.   ","We find that ICL models tuned in English are also able to learn some tasks from non-English contexts, but multilingual instruction fine-tuning consistently improves the ICL ability.","We also find that the massive multitask training can be outperformed by single-task training in the target language, uncovering the potential for specializing in-context learners to the language(s) of their application."],"url":"http://arxiv.org/abs/2304.01922v1"}
{"created":"2023-04-04","title":"viz2viz: Prompt-driven stylized visualization generation using a diffusion model","abstract":"Creating stylized visualization requires going beyond the limited, abstract, geometric marks produced by most tools. Rather, the designer builds stylized idioms where the marks are both transformed (e.g., photographs of candles instead of bars) and also synthesized into a 'scene' that pushes the boundaries of traditional visualizations. To support this, we introduce viz2viz, a system for transforming visualizations with a textual prompt to a stylized form. The system follows a high-level recipe that leverages various generative methods to produce new visualizations that retain the properties of the original dataset. While the base recipe is consistent across many visualization types, we demonstrate how it can be specifically adapted to the creation of different visualization types (bar charts, area charts, pie charts, and network visualizations). Our approach introduces techniques for using different prompts for different marks (i.e., each bar can be something completely different) while still retaining image \"coherence.\" We conclude with an evaluation of the approach and discussion on extensions and limitations.","sentences":["Creating stylized visualization requires going beyond the limited, abstract, geometric marks produced by most tools.","Rather, the designer builds stylized idioms where the marks are both transformed (e.g., photographs of candles instead of bars) and also synthesized into a 'scene' that pushes the boundaries of traditional visualizations.","To support this, we introduce viz2viz, a system for transforming visualizations with a textual prompt to a stylized form.","The system follows a high-level recipe that leverages various generative methods to produce new visualizations that retain the properties of the original dataset.","While the base recipe is consistent across many visualization types, we demonstrate how it can be specifically adapted to the creation of different visualization types (bar charts, area charts, pie charts, and network visualizations).","Our approach introduces techniques for using different prompts for different marks (i.e., each bar can be something completely different) while still retaining image \"coherence.\"","We conclude with an evaluation of the approach and discussion on extensions and limitations."],"url":"http://arxiv.org/abs/2304.01919v1"}
{"created":"2023-04-04","title":"Strong Baselines for Parameter Efficient Few-Shot Fine-tuning","abstract":"Few-shot classification (FSC) entails learning novel classes given only a few examples per class after a pre-training (or meta-training) phase on a set of base classes. Recent works have shown that simply fine-tuning a pre-trained Vision Transformer (ViT) on new test classes is a strong approach for FSC. Fine-tuning ViTs, however, is expensive in time, compute and storage. This has motivated the design of parameter efficient fine-tuning (PEFT) methods which fine-tune only a fraction of the Transformer's parameters. While these methods have shown promise, inconsistencies in experimental conditions make it difficult to disentangle their advantage from other experimental factors including the feature extractor architecture, pre-trained initialization and fine-tuning algorithm, amongst others. In our paper, we conduct a large-scale, experimentally consistent, empirical analysis to study PEFTs for few-shot image classification. Through a battery of over 1.8k controlled experiments on large-scale few-shot benchmarks including Meta-Dataset (MD) and ORBIT, we uncover novel insights on PEFTs that cast light on their efficacy in fine-tuning ViTs for few-shot classification. Through our controlled empirical study, we have two main findings: (i) Fine-tuning just the LayerNorm parameters (which we call LN-Tune) during few-shot adaptation is an extremely strong baseline across ViTs pre-trained with both self-supervised and supervised objectives, (ii) For self-supervised ViTs, we find that simply learning a set of scaling parameters for each attention matrix (which we call AttnScale) along with a domain-residual adapter (DRA) module leads to state-of-the-art performance (while being $\\sim\\!$ 9$\\times$ more parameter-efficient) on MD. Our extensive empirical findings set strong baselines and call for rethinking the current design of PEFT methods for FSC.","sentences":["Few-shot classification (FSC) entails learning novel classes given only a few examples per class after a pre-training (or meta-training) phase on a set of base classes.","Recent works have shown that simply fine-tuning a pre-trained Vision Transformer (ViT) on new test classes is a strong approach for FSC.","Fine-tuning ViTs, however, is expensive in time, compute and storage.","This has motivated the design of parameter efficient fine-tuning (PEFT) methods which fine-tune only a fraction of the Transformer's parameters.","While these methods have shown promise, inconsistencies in experimental conditions make it difficult to disentangle their advantage from other experimental factors including the feature extractor architecture, pre-trained initialization and fine-tuning algorithm, amongst others.","In our paper, we conduct a large-scale, experimentally consistent, empirical analysis to study PEFTs for few-shot image classification.","Through a battery of over 1.8k controlled experiments on large-scale few-shot benchmarks including Meta-Dataset (MD) and ORBIT, we uncover novel insights on PEFTs that cast light on their efficacy in fine-tuning ViTs for few-shot classification.","Through our controlled empirical study, we have two main findings: (i) Fine-tuning just the LayerNorm parameters (which we call LN-Tune) during few-shot adaptation is an extremely strong baseline across ViTs pre-trained with both self-supervised and supervised objectives, (ii) For self-supervised ViTs, we find that simply learning a set of scaling parameters for each attention matrix (which we call AttnScale) along with a domain-residual adapter (DRA) module leads to state-of-the-art performance (while being $\\sim\\!$ 9$\\times$ more parameter-efficient) on MD.","Our extensive empirical findings set strong baselines and call for rethinking the current design of PEFT methods for FSC."],"url":"http://arxiv.org/abs/2304.01917v1"}
{"created":"2023-04-04","title":"Leveraging Deep Learning Approaches for Deepfake Detection: A Review","abstract":"Conspicuous progression in the field of machine learning and deep learning have led the jump of highly realistic fake media, these media oftentimes referred as deepfakes. Deepfakes are fabricated media which are generated by sophisticated AI that are at times very difficult to set apart from the real media. So far, this media can be uploaded to the various social media platforms, hence advertising it to the world got easy, calling for an efficacious countermeasure. Thus, one of the optimistic counter steps against deepfake would be deepfake detection. To undertake this threat, researchers in the past have created models to detect deepfakes based on ML/DL techniques like Convolutional Neural Networks. This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset.","sentences":["Conspicuous progression in the field of machine learning and deep learning have led the jump of highly realistic fake media, these media oftentimes referred as deepfakes.","Deepfakes are fabricated media which are generated by sophisticated AI that are at times very difficult to set apart from the real media.","So far, this media can be uploaded to the various social media platforms, hence advertising it to the world got easy, calling for an efficacious countermeasure.","Thus, one of the optimistic counter steps against deepfake would be deepfake detection.","To undertake this threat, researchers in the past have created models to detect deepfakes based on ML/DL techniques like Convolutional Neural Networks.","This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset."],"url":"http://arxiv.org/abs/2304.01908v1"}
{"created":"2023-04-04","title":"Torch-Choice: A PyTorch Package for Large-Scale Choice Modelling with Python","abstract":"The $\\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch. $\\texttt{torch-choice}$ provides a $\\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a $\\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of $\\texttt{torch-choice}$ and $\\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) the expansion of item sets. Finally, we demonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets.","sentences":["The $\\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch.","$\\texttt{torch-choice}$ provides a $\\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently.","The paper demonstrates constructing a $\\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation.","The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient.","Models can be initialized using either R-style formula strings or Python dictionaries.","We conclude with a comparison of the computational efficiencies of $\\texttt{torch-choice}$ and $\\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) the expansion of item sets.","Finally, we demonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets."],"url":"http://arxiv.org/abs/2304.01906v1"}
{"created":"2023-04-04","title":"InfluencerRank: Discovering Effective Influencers via Graph Convolutional Attentive Recurrent Neural Networks","abstract":"As influencers play considerable roles in social media marketing, companies increase the budget for influencer marketing. Hiring effective influencers is crucial in social influencer marketing, but it is challenging to find the right influencers among hundreds of millions of social media users. In this paper, we propose InfluencerRank that ranks influencers by their effectiveness based on their posting behaviors and social relations over time. To represent the posting behaviors and social relations, the graph convolutional neural networks are applied to model influencers with heterogeneous networks during different historical periods. By learning the network structure with the embedded node features, InfluencerRank can derive informative representations for influencers at each period. An attentive recurrent neural network finally distinguishes highly effective influencers from other influencers by capturing the knowledge of the dynamics of influencer representations over time. Extensive experiments have been conducted on an Instagram dataset that consists of 18,397 influencers with their 2,952,075 posts published within 12 months. The experimental results demonstrate that InfluencerRank outperforms existing baseline methods. An in-depth analysis further reveals that all of our proposed features and model components are beneficial to discover effective influencers.","sentences":["As influencers play considerable roles in social media marketing, companies increase the budget for influencer marketing.","Hiring effective influencers is crucial in social influencer marketing, but it is challenging to find the right influencers among hundreds of millions of social media users.","In this paper, we propose InfluencerRank that ranks influencers by their effectiveness based on their posting behaviors and social relations over time.","To represent the posting behaviors and social relations, the graph convolutional neural networks are applied to model influencers with heterogeneous networks during different historical periods.","By learning the network structure with the embedded node features, InfluencerRank can derive informative representations for influencers at each period.","An attentive recurrent neural network finally distinguishes highly effective influencers from other influencers by capturing the knowledge of the dynamics of influencer representations over time.","Extensive experiments have been conducted on an Instagram dataset that consists of 18,397 influencers with their 2,952,075 posts published within 12 months.","The experimental results demonstrate that InfluencerRank outperforms existing baseline methods.","An in-depth analysis further reveals that all of our proposed features and model components are beneficial to discover effective influencers."],"url":"http://arxiv.org/abs/2304.01897v1"}
{"created":"2023-04-04","title":"San-BERT: Extractive Summarization for Sanskrit Documents using BERT and it's variants","abstract":"In this work, we develop language models for the Sanskrit language, namely Bidirectional Encoder Representations from Transformers (BERT) and its variants: A Lite BERT (ALBERT), and Robustly Optimized BERT (RoBERTa) using Devanagari Sanskrit text corpus. Then we extracted the features for the given text from these models. We applied the dimensional reduction and clustering techniques on the features to generate an extractive summary for a given Sanskrit document. Along with the extractive text summarization techniques, we have also created and released a Sanskrit Devanagari text corpus publicly.","sentences":["In this work, we develop language models for the Sanskrit language, namely Bidirectional Encoder Representations from Transformers (BERT) and its variants: A Lite BERT (ALBERT), and Robustly Optimized BERT (RoBERTa) using Devanagari Sanskrit text corpus.","Then we extracted the features for the given text from these models.","We applied the dimensional reduction and clustering techniques on the features to generate an extractive summary for a given Sanskrit document.","Along with the extractive text summarization techniques, we have also created and released a Sanskrit Devanagari text corpus publicly."],"url":"http://arxiv.org/abs/2304.01894v1"}
{"created":"2023-04-04","title":"SportsPose -- A Dynamic 3D sports pose dataset","abstract":"Accurate 3D human pose estimation is essential for sports analytics, coaching, and injury prevention. However, existing datasets for monocular pose estimation do not adequately capture the challenging and dynamic nature of sports movements. In response, we introduce SportsPose, a large-scale 3D human pose dataset consisting of highly dynamic sports movements. With more than 176,000 3D poses from 24 different subjects performing 5 different sports activities, SportsPose provides a diverse and comprehensive set of 3D poses that reflect the complex and dynamic nature of sports movements. Contrary to other markerless datasets we have quantitatively evaluated the precision of SportsPose by comparing our poses with a commercial marker-based system and achieve a mean error of 34.5 mm across all evaluation sequences. This is comparable to the error reported on the commonly used 3DPW dataset. We further introduce a new metric, local movement, which describes the movement of the wrist and ankle joints in relation to the body. With this, we show that SportsPose contains more movement than the Human3.6M and 3DPW datasets in these extremum joints, indicating that our movements are more dynamic. The dataset with accompanying code can be downloaded from our website. We hope that SportsPose will allow researchers and practitioners to develop and evaluate more effective models for the analysis of sports performance and injury prevention. With its realistic and diverse dataset, SportsPose provides a valuable resource for advancing the state-of-the-art in pose estimation in sports.","sentences":["Accurate 3D human pose estimation is essential for sports analytics, coaching, and injury prevention.","However, existing datasets for monocular pose estimation do not adequately capture the challenging and dynamic nature of sports movements.","In response, we introduce SportsPose, a large-scale 3D human pose dataset consisting of highly dynamic sports movements.","With more than 176,000 3D poses from 24 different subjects performing 5 different sports activities, SportsPose provides a diverse and comprehensive set of 3D poses that reflect the complex and dynamic nature of sports movements.","Contrary to other markerless datasets we have quantitatively evaluated the precision of SportsPose by comparing our poses with a commercial marker-based system and achieve a mean error of 34.5 mm across all evaluation sequences.","This is comparable to the error reported on the commonly used 3DPW dataset.","We further introduce a new metric, local movement, which describes the movement of the wrist and ankle joints in relation to the body.","With this, we show that SportsPose contains more movement than the Human3.6M and 3DPW datasets in these extremum joints, indicating that our movements are more dynamic.","The dataset with accompanying code can be downloaded from our website.","We hope that SportsPose will allow researchers and practitioners to develop and evaluate more effective models for the analysis of sports performance and injury prevention.","With its realistic and diverse dataset, SportsPose provides a valuable resource for advancing the state-of-the-art in pose estimation in sports."],"url":"http://arxiv.org/abs/2304.01865v1"}
{"created":"2023-04-04","title":"A Practical Framework for Unsupervised Structure Preservation Medical Image Enhancement","abstract":"Medical images are extremely valuable for supporting medical diagnoses. However, in practice, low-quality (LQ) medical images, such as images that are hazy/blurry, have uneven illumination, or are out of focus, among others, are often obtained during data acquisition. This leads to difficulties in the screening and diagnosis of medical diseases. Several generative adversarial networks (GAN)-based image enhancement methods have been proposed and have shown promising results. However, there is a quality-originality trade-off among these methods in the sense that they produce visually pleasing results but lose the ability to preserve originality, especially the structural inputs. Moreover, to our knowledge, there is no objective metric in evaluating the structure preservation of medical image enhancement methods in unsupervised settings due to the unavailability of paired ground-truth data. In this study, we propose a framework for practical unsupervised medical image enhancement that includes (1) a non-reference objective evaluation of structure preservation for medical image enhancement tasks called Laplacian structural similarity index measure (LaSSIM), which is based on SSIM and the Laplacian pyramid, and (2) a novel unsupervised GAN-based method called Laplacian medical image enhancement (LaMEGAN) to support the improvement of both originality and quality from LQ images. The LaSSIM metric does not require clean reference images and has been shown to be superior to SSIM in capturing image structural changes under image degradations, such as strong blurring on different datasets. The experiments demonstrated that our LaMEGAN achieves a satisfactory balance between quality and originality, with robust structure preservation performance while generating compelling visual results with very high image quality scores. The code will be made available at https://github.com/AillisInc/USPMIE.","sentences":["Medical images are extremely valuable for supporting medical diagnoses.","However, in practice, low-quality (LQ) medical images, such as images that are hazy/blurry, have uneven illumination, or are out of focus, among others, are often obtained during data acquisition.","This leads to difficulties in the screening and diagnosis of medical diseases.","Several generative adversarial networks (GAN)-based image enhancement methods have been proposed and have shown promising results.","However, there is a quality-originality trade-off among these methods in the sense that they produce visually pleasing results but lose the ability to preserve originality, especially the structural inputs.","Moreover, to our knowledge, there is no objective metric in evaluating the structure preservation of medical image enhancement methods in unsupervised settings due to the unavailability of paired ground-truth data.","In this study, we propose a framework for practical unsupervised medical image enhancement that includes (1) a non-reference objective evaluation of structure preservation for medical image enhancement tasks called Laplacian structural similarity index measure (LaSSIM), which is based on SSIM and the Laplacian pyramid, and (2) a novel unsupervised GAN-based method called Laplacian medical image enhancement (LaMEGAN) to support the improvement of both originality and quality from LQ images.","The LaSSIM metric does not require clean reference images and has been shown to be superior to SSIM in capturing image structural changes under image degradations, such as strong blurring on different datasets.","The experiments demonstrated that our LaMEGAN achieves a satisfactory balance between quality and originality, with robust structure preservation performance while generating compelling visual results with very high image quality scores.","The code will be made available at https://github.com/AillisInc/USPMIE."],"url":"http://arxiv.org/abs/2304.01864v1"}
{"created":"2023-04-04","title":"Evaluating Synthetic Pre-Training for Handwriting Processing Tasks","abstract":"In this work, we explore massive pre-training on synthetic word images for enhancing the performance on four benchmark downstream handwriting analysis tasks. To this end, we build a large synthetic dataset of word images rendered in several handwriting fonts, which offers a complete supervision signal. We use it to train a simple convolutional neural network (ConvNet) with a fully supervised objective. The vector representations of the images obtained from the pre-trained ConvNet can then be considered as encodings of the handwriting style. We exploit such representations for Writer Retrieval, Writer Identification, Writer Verification, and Writer Classification and demonstrate that our pre-training strategy allows extracting rich representations of the writers' style that enable the aforementioned tasks with competitive results with respect to task-specific State-of-the-Art approaches.","sentences":["In this work, we explore massive pre-training on synthetic word images for enhancing the performance on four benchmark downstream handwriting analysis tasks.","To this end, we build a large synthetic dataset of word images rendered in several handwriting fonts, which offers a complete supervision signal.","We use it to train a simple convolutional neural network (ConvNet) with a fully supervised objective.","The vector representations of the images obtained from the pre-trained ConvNet can then be considered as encodings of the handwriting style.","We exploit such representations for Writer Retrieval, Writer Identification, Writer Verification, and Writer Classification and demonstrate that our pre-training strategy allows extracting rich representations of the writers' style that enable the aforementioned tasks with competitive results with respect to task-specific State-of-the-Art approaches."],"url":"http://arxiv.org/abs/2304.01842v1"}
{"created":"2023-04-04","title":"BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection","abstract":"Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resemble the characteristics of other volumetric images such as micro-CT. To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available. BugNIST is an extensive dataset of micro-CT scans of 12 types of bugs, such as insects and larvae. BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material. The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures. Models capable of solving this task will be independent of the context, i.e., the surrounding material. This is a great advantage if the context is unknown or changing, as is often the case in micro-CT. Our initial baseline analysis shows that current state-of-the-art deep learning methods classify individual bugs very well, but has great difficulty with the detection challenge. Hereby, BugNIST enables research in image analysis areas that until now have missed relevant data - both classification, detection, and hopefully more.","sentences":["Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data.","However, medical data do not necessarily resemble the characteristics of other volumetric images such as micro-CT.","To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available.","BugNIST is an extensive dataset of micro-CT scans of 12 types of bugs, such as insects and larvae.","BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material.","The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures.","Models capable of solving this task will be independent of the context, i.e., the surrounding material.","This is a great advantage if the context is unknown or changing, as is often the case in micro-CT.","Our initial baseline analysis shows that current state-of-the-art deep learning methods classify individual bugs very well, but has great difficulty with the detection challenge.","Hereby, BugNIST enables research in image analysis areas that until now have missed relevant data - both classification, detection, and hopefully more."],"url":"http://arxiv.org/abs/2304.01838v1"}
{"created":"2023-04-04","title":"Sibling Rivalry: SNeIa Diversity and the Hubble Tension","abstract":"Thermonuclear supernovae, or Type-Ia supernovae (SNeIa), are an essential tool of cosmology. Precise cosmological constraints are extracted from a Hubble diagram defined by homogeneous distance indicators, but supernova homogeneity is not guaranteed. The degree of heterogeneity within the SNeIa parent population is unknown. In addition, event selections and standardization procedures are based on empirical, optically-measured observables rather than fundamental thermonuclear properties. Systematics are a natural consequence of event selection from a diverse parent population. Quantifying the impact of diversity-driven systematics is crucial to optimizing SNeIa as cosmic probes. In this work, the empirical observables are used to calibrate previously unidentified diversity-driven systematic uncertainties. The foundation of this approach is the concept of \"supernova siblings'', two or more supernovae hosted by the same parent galaxy. Sibling-based calibrations isolate intrinsic differences between supernovae; they control for source distance and host galaxy dependencies that can conceal systematics or lead to their underestimation. Newly calibrated distance modulus uncertainties are approximately an order of magnitude larger than previously reported. The physical origin of these uncertainties is plausibly attributed to the diverse thermonuclear scenarios responsible for SNeIa and the inhomogeneous apparent magnitudes induced by this diversity. Systematics mitigation strategies are discussed. Cosmological parameter constraints extracted from a re-analysis of the Pantheon+ SNeIa dataset are weaker than previously reported. Agreement with early-Universe parameter estimates is achieved for a $\\Lambda$CDM cosmology, including a reduction of the Hubble Tension from $\\sim$5$\\sigma$ to <1$\\sigma$.","sentences":["Thermonuclear supernovae, or Type-Ia supernovae (SNeIa), are an essential tool of cosmology.","Precise cosmological constraints are extracted from a Hubble diagram defined by homogeneous distance indicators, but supernova homogeneity is not guaranteed.","The degree of heterogeneity within the SNeIa parent population is unknown.","In addition, event selections and standardization procedures are based on empirical, optically-measured observables rather than fundamental thermonuclear properties.","Systematics are a natural consequence of event selection from a diverse parent population.","Quantifying the impact of diversity-driven systematics is crucial to optimizing SNeIa as cosmic probes.","In this work, the empirical observables are used to calibrate previously unidentified diversity-driven systematic uncertainties.","The foundation of this approach is the concept of \"supernova siblings'', two or more supernovae hosted by the same parent galaxy.","Sibling-based calibrations isolate intrinsic differences between supernovae; they control for source distance and host galaxy dependencies that can conceal systematics or lead to their underestimation.","Newly calibrated distance modulus uncertainties are approximately an order of magnitude larger than previously reported.","The physical origin of these uncertainties is plausibly attributed to the diverse thermonuclear scenarios responsible for SNeIa and the inhomogeneous apparent magnitudes induced by this diversity.","Systematics mitigation strategies are discussed.","Cosmological parameter constraints extracted from a re-analysis of the Pantheon+ SNeIa dataset are weaker than previously reported.","Agreement with early-Universe parameter estimates is achieved for a $\\Lambda$CDM cosmology, including a reduction of the Hubble Tension from $\\sim$5$\\sigma$ to <1$\\sigma$."],"url":"http://arxiv.org/abs/2304.01831v1"}
{"created":"2023-04-04","title":"Learning to Name Classes for Vision and Language Models","abstract":"Large scale vision and language models can achieve impressive zero-shot recognition performance by mapping class specific text queries to image content. Two distinct challenges that remain however, are high sensitivity to the choice of handcrafted class names that define queries, and the difficulty of adaptation to new, smaller datasets. Towards addressing these problems, we propose to leverage available data to learn, for each class, an optimal word embedding as a function of the visual content. By learning new word embeddings on an otherwise frozen model, we are able to retain zero-shot capabilities for new classes, easily adapt models to new datasets, and adjust potentially erroneous, non-descriptive or ambiguous class names. We show that our solution can easily be integrated in image classification and object detection pipelines, yields significant performance gains in multiple scenarios and provides insights into model biases and labelling errors.","sentences":["Large scale vision and language models can achieve impressive zero-shot recognition performance by mapping class specific text queries to image content.","Two distinct challenges that remain however, are high sensitivity to the choice of handcrafted class names that define queries, and the difficulty of adaptation to new, smaller datasets.","Towards addressing these problems, we propose to leverage available data to learn, for each class, an optimal word embedding as a function of the visual content.","By learning new word embeddings on an otherwise frozen model, we are able to retain zero-shot capabilities for new classes, easily adapt models to new datasets, and adjust potentially erroneous, non-descriptive or ambiguous class names.","We show that our solution can easily be integrated in image classification and object detection pipelines, yields significant performance gains in multiple scenarios and provides insights into model biases and labelling errors."],"url":"http://arxiv.org/abs/2304.01830v1"}
{"created":"2023-04-04","title":"CoreDiff: Contextual Error-Modulated Generalized Diffusion Model for Low-Dose CT Denoising and Generalization","abstract":"Low-dose computed tomography (CT) images suffer from noise and artifacts due to photon starvation and electronic noise. Recently, some works have attempted to use diffusion models to address the over-smoothness and training instability encountered by previous deep-learning-based denoising models. However, diffusion models suffer from long inference times due to the large number of sampling steps involved. Very recently, cold diffusion model generalizes classical diffusion models and has greater flexibility. Inspired by the cold diffusion, this paper presents a novel COntextual eRror-modulated gEneralized Diffusion model for low-dose CT (LDCT) denoising, termed CoreDiff. First, CoreDiff utilizes LDCT images to displace the random Gaussian noise and employs a novel mean-preserving degradation operator to mimic the physical process of CT degradation, significantly reducing sampling steps thanks to the informative LDCT images as the starting point of the sampling process. Second, to alleviate the error accumulation problem caused by the imperfect restoration operator in the sampling process, we propose a novel ContextuaL Error-modulAted Restoration Network (CLEAR-Net), which can leverage contextual information to constrain the sampling process from structural distortion and modulate time step embedding features for better alignment with the input at the next time step. Third, to rapidly generalize to a new, unseen dose level with as few resources as possible, we devise a one-shot learning framework to make CoreDiff generalize faster and better using only a single LDCT image (un)paired with NDCT. Extensive experimental results on two datasets demonstrate that our CoreDiff outperforms competing methods in denoising and generalization performance, with a clinically acceptable inference time.","sentences":["Low-dose computed tomography (CT) images suffer from noise and artifacts due to photon starvation and electronic noise.","Recently, some works have attempted to use diffusion models to address the over-smoothness and training instability encountered by previous deep-learning-based denoising models.","However, diffusion models suffer from long inference times due to the large number of sampling steps involved.","Very recently, cold diffusion model generalizes classical diffusion models and has greater flexibility.","Inspired by the cold diffusion, this paper presents a novel COntextual eRror-modulated gEneralized Diffusion model for low-dose CT (LDCT) denoising, termed CoreDiff.","First, CoreDiff utilizes LDCT images to displace the random Gaussian noise and employs a novel mean-preserving degradation operator to mimic the physical process of CT degradation, significantly reducing sampling steps thanks to the informative LDCT images as the starting point of the sampling process.","Second, to alleviate the error accumulation problem caused by the imperfect restoration operator in the sampling process, we propose a novel ContextuaL","Error-modulAted Restoration Network (CLEAR-Net), which can leverage contextual information to constrain the sampling process from structural distortion and modulate time step embedding features for better alignment with the input at the next time step.","Third, to rapidly generalize to a new, unseen dose level with as few resources as possible, we devise a one-shot learning framework to make CoreDiff generalize faster and better using only a single LDCT image (un)paired with NDCT.","Extensive experimental results on two datasets demonstrate that our CoreDiff outperforms competing methods in denoising and generalization performance, with a clinically acceptable inference time."],"url":"http://arxiv.org/abs/2304.01814v1"}
{"created":"2023-04-04","title":"Bridging the Gap between Model Explanations in Partially Annotated Multi-label Classification","abstract":"Due to the expensive costs of collecting labels in multi-label classification datasets, partially annotated multi-label classification has become an emerging field in computer vision. One baseline approach to this task is to assume unobserved labels as negative labels, but this assumption induces label noise as a form of false negative. To understand the negative impact caused by false negative labels, we study how these labels affect the model's explanation. We observe that the explanation of two models, trained with full and partial labels each, highlights similar regions but with different scaling, where the latter tends to have lower attribution scores. Based on these findings, we propose to boost the attribution scores of the model trained with partial labels to make its explanation resemble that of the model trained with full labels. Even with the conceptually simple approach, the multi-label classification performance improves by a large margin in three different datasets on a single positive label setting and one on a large-scale partial label setting. Code is available at https://github.com/youngwk/BridgeGapExplanationPAMC.","sentences":["Due to the expensive costs of collecting labels in multi-label classification datasets, partially annotated multi-label classification has become an emerging field in computer vision.","One baseline approach to this task is to assume unobserved labels as negative labels, but this assumption induces label noise as a form of false negative.","To understand the negative impact caused by false negative labels, we study how these labels affect the model's explanation.","We observe that the explanation of two models, trained with full and partial labels each, highlights similar regions but with different scaling, where the latter tends to have lower attribution scores.","Based on these findings, we propose to boost the attribution scores of the model trained with partial labels to make its explanation resemble that of the model trained with full labels.","Even with the conceptually simple approach, the multi-label classification performance improves by a large margin in three different datasets on a single positive label setting and one on a large-scale partial label setting.","Code is available at https://github.com/youngwk/BridgeGapExplanationPAMC."],"url":"http://arxiv.org/abs/2304.01804v1"}
{"created":"2023-04-04","title":"A User-Centered, Interactive, Human-in-the-Loop Topic Modelling System","abstract":"Human-in-the-loop topic modelling incorporates users' knowledge into the modelling process, enabling them to refine the model iteratively. Recent research has demonstrated the value of user feedback, but there are still issues to consider, such as the difficulty in tracking changes, comparing different models and the lack of evaluation based on real-world examples of use. We developed a novel, interactive human-in-the-loop topic modeling system with a user-friendly interface that enables users compare and record every step they take, and a novel topic words suggestion feature to help users provide feedback that is faithful to the ground truth. Our system also supports not only what traditional topic models can do, i.e., learning the topics from the whole corpus, but also targeted topic modelling, i.e., learning topics for specific aspects of the corpus. In this article, we provide an overview of the system and present the results of a series of user studies designed to assess the value of the system in progressively more realistic applications of topic modelling.","sentences":["Human-in-the-loop topic modelling incorporates users' knowledge into the modelling process, enabling them to refine the model iteratively.","Recent research has demonstrated the value of user feedback, but there are still issues to consider, such as the difficulty in tracking changes, comparing different models and the lack of evaluation based on real-world examples of use.","We developed a novel, interactive human-in-the-loop topic modeling system with a user-friendly interface that enables users compare and record every step they take, and a novel topic words suggestion feature to help users provide feedback that is faithful to the ground truth.","Our system also supports not only what traditional topic models can do, i.e., learning the topics from the whole corpus, but also targeted topic modelling, i.e., learning topics for specific aspects of the corpus.","In this article, we provide an overview of the system and present the results of a series of user studies designed to assess the value of the system in progressively more realistic applications of topic modelling."],"url":"http://arxiv.org/abs/2304.01774v1"}
{"created":"2023-04-04","title":"Black Box Few-Shot Adaptation for Vision-Language models","abstract":"Vision-Language (V-L) models trained with contrastive learning to align the visual and language modalities have been shown to be strong few-shot learners. Soft prompt learning is the method of choice for few-shot downstream adaption aiming to bridge the modality gap caused by the distribution shift induced by the new domain. While parameter-efficient, prompt learning still requires access to the model weights and can be computationally infeasible for large models with billions of parameters. To address these shortcomings, in this work, we describe a black-box method for V-L few-shot adaptation that (a) operates on pre-computed image and text features and hence works without access to the model's weights, (b) it is orders of magnitude faster at training time, (c) it is amenable to both supervised and unsupervised training, and (d) it can be even used to align image and text features computed from uni-modal models. To achieve this, we propose Linear Feature Alignment (LFA), a simple linear approach for V-L re-alignment in the target domain. LFA is initialized from a closed-form solution to a least-squares problem and then it is iteratively updated by minimizing a re-ranking loss. Despite its simplicity, our approach can even surpass soft-prompt learning methods as shown by extensive experiments on 11 image and 2 video datasets.","sentences":["Vision-Language (V-L) models trained with contrastive learning to align the visual and language modalities have been shown to be strong few-shot learners.","Soft prompt learning is the method of choice for few-shot downstream adaption aiming to bridge the modality gap caused by the distribution shift induced by the new domain.","While parameter-efficient, prompt learning still requires access to the model weights and can be computationally infeasible for large models with billions of parameters.","To address these shortcomings, in this work, we describe a black-box method for V-L few-shot adaptation that (a) operates on pre-computed image and text features and hence works without access to the model's weights, (b) it is orders of magnitude faster at training time, (c) it is amenable to both supervised and unsupervised training, and (d) it can be even used to align image and text features computed from uni-modal models.","To achieve this, we propose Linear Feature Alignment (LFA), a simple linear approach for V-L re-alignment in the target domain.","LFA is initialized from a closed-form solution to a least-squares problem and then it is iteratively updated by minimizing a re-ranking loss.","Despite its simplicity, our approach can even surpass soft-prompt learning methods as shown by extensive experiments on 11 image and 2 video datasets."],"url":"http://arxiv.org/abs/2304.01752v1"}
{"created":"2023-04-04","title":"Learning Invariant Representation via Contrastive Feature Alignment for Clutter Robust SAR Target Recognition","abstract":"The deep neural networks (DNNs) have freed the synthetic aperture radar automatic target recognition (SAR ATR) from expertise-based feature designing and demonstrated superiority over conventional solutions. There has been shown the unique deficiency of ground vehicle benchmarks in shapes of strong background correlation results in DNNs overfitting the clutter and being non-robust to unfamiliar surroundings. However, the gap between fixed background model training and varying background application remains underexplored. Inspired by contrastive learning, this letter proposes a solution called Contrastive Feature Alignment (CFA) aiming to learn invariant representation for robust recognition. The proposed method contributes a mixed clutter variants generation strategy and a new inference branch equipped with channel-weighted mean square error (CWMSE) loss for invariant representation learning. In specific, the generation strategy is delicately designed to better attract clutter-sensitive deviation in feature space. The CWMSE loss is further devised to better contrast this deviation and align the deep features activated by the original images and corresponding clutter variants. The proposed CFA combines both classification and CWMSE losses to train the model jointly, which allows for the progressive learning of invariant target representation. Extensive evaluations on the MSTAR dataset and six DNN models prove the effectiveness of our proposal. The results demonstrated that the CFA-trained models are capable of recognizing targets among unfamiliar surroundings that are not included in the dataset, and are robust to varying signal-to-clutter ratios.","sentences":["The deep neural networks (DNNs) have freed the synthetic aperture radar automatic target recognition (SAR ATR) from expertise-based feature designing and demonstrated superiority over conventional solutions.","There has been shown the unique deficiency of ground vehicle benchmarks in shapes of strong background correlation results in DNNs overfitting the clutter and being non-robust to unfamiliar surroundings.","However, the gap between fixed background model training and varying background application remains underexplored.","Inspired by contrastive learning, this letter proposes a solution called Contrastive Feature Alignment (CFA) aiming to learn invariant representation for robust recognition.","The proposed method contributes a mixed clutter variants generation strategy and a new inference branch equipped with channel-weighted mean square error (CWMSE) loss for invariant representation learning.","In specific, the generation strategy is delicately designed to better attract clutter-sensitive deviation in feature space.","The CWMSE loss is further devised to better contrast this deviation and align the deep features activated by the original images and corresponding clutter variants.","The proposed CFA combines both classification and CWMSE losses to train the model jointly, which allows for the progressive learning of invariant target representation.","Extensive evaluations on the MSTAR dataset and six DNN models prove the effectiveness of our proposal.","The results demonstrated that the CFA-trained models are capable of recognizing targets among unfamiliar surroundings that are not included in the dataset, and are robust to varying signal-to-clutter ratios."],"url":"http://arxiv.org/abs/2304.01747v1"}
{"created":"2023-04-04","title":"Bounding probabilities of causation through the causal marginal problem","abstract":"Probabilities of Causation play a fundamental role in decision making in law, health care and public policy. Nevertheless, their point identification is challenging, requiring strong assumptions such as monotonicity. In the absence of such assumptions, existing work requires multiple observations of datasets that contain the same treatment and outcome variables, in order to establish bounds on these probabilities. However, in many clinical trials and public policy evaluation cases, there exist independent datasets that examine the effect of a different treatment each on the same outcome variable. Here, we outline how to significantly tighten existing bounds on the probabilities of causation, by imposing counterfactual consistency between SCMs constructed from such independent datasets ('causal marginal problem'). Next, we describe a new information theoretic approach on falsification of counterfactual probabilities, using conditional mutual information to quantify counterfactual influence. The latter generalises to arbitrary discrete variables and number of treatments, and renders the causal marginal problem more interpretable. Since the question of 'tight enough' is left to the user, we provide an additional method of inference when the bounds are unsatisfactory: A maximum entropy based method that defines a metric for the space of plausible SCMs and proposes the entropy maximising SCM for inferring counterfactuals in the absence of more information.","sentences":["Probabilities of Causation play a fundamental role in decision making in law, health care and public policy.","Nevertheless, their point identification is challenging, requiring strong assumptions such as monotonicity.","In the absence of such assumptions, existing work requires multiple observations of datasets that contain the same treatment and outcome variables, in order to establish bounds on these probabilities.","However, in many clinical trials and public policy evaluation cases, there exist independent datasets that examine the effect of a different treatment each on the same outcome variable.","Here, we outline how to significantly tighten existing bounds on the probabilities of causation, by imposing counterfactual consistency between SCMs constructed from such independent datasets ('causal marginal problem').","Next, we describe a new information theoretic approach on falsification of counterfactual probabilities, using conditional mutual information to quantify counterfactual influence.","The latter generalises to arbitrary discrete variables and number of treatments, and renders the causal marginal problem more interpretable.","Since the question of 'tight enough' is left to the user, we provide an additional method of inference when the bounds are unsatisfactory: A maximum entropy based method that defines a metric for the space of plausible SCMs and proposes the entropy maximising SCM for inferring counterfactuals in the absence of more information."],"url":"http://arxiv.org/abs/2304.02023v1"}
{"created":"2023-04-04","title":"A Static Analysis Platform for Investigating Security Trends in Repositories","abstract":"Static analysis tools come in many forms andconfigurations, allowing them to handle various tasks in a (secure) development process: code style linting, bug/vulnerability detection, verification, etc., and adapt to the specific requirements of a software project, thus reducing the number of false positives.The wide range of configuration options poses a hurdle in their use for software developers, as the tools cannot be deployed out-of-the-box. However, static analysis tools only develop their full benefit if they are integrated into the software development workflow and used on regular. Vulnerability management should be integrated via version history to identify hotspots, for example. We present an analysis platform that integrates several static analysis tools that enable Git-based repositories to continuously monitor warnings across their version history. The framework is easily extensible with other tools and programming languages. We provide a visualization component in the form of a dashboard to display security trends and hotspots. Our tool can also be used to create a database of security alerts at a scale well-suited for machine learning applications such as bug or vulnerability detection.","sentences":["Static analysis tools come in many forms andconfigurations, allowing them to handle various tasks in a (secure) development process: code style linting, bug/vulnerability detection, verification, etc., and adapt to the specific requirements of a software project, thus reducing the number of false positives.","The wide range of configuration options poses a hurdle in their use for software developers, as the tools cannot be deployed out-of-the-box.","However, static analysis tools only develop their full benefit if they are integrated into the software development workflow and used on regular.","Vulnerability management should be integrated via version history to identify hotspots, for example.","We present an analysis platform that integrates several static analysis tools that enable Git-based repositories to continuously monitor warnings across their version history.","The framework is easily extensible with other tools and programming languages.","We provide a visualization component in the form of a dashboard to display security trends and hotspots.","Our tool can also be used to create a database of security alerts at a scale well-suited for machine learning applications such as bug or vulnerability detection."],"url":"http://arxiv.org/abs/2304.01725v1"}
{"created":"2023-04-04","title":"Towards Open-Vocabulary Video Instance Segmentation","abstract":"Video Instance Segmentation(VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories, lacking the generalization ability to handle novel categories in real-world videos. To address this limitation, we make the following three contributions. First, we introduce the novel task of Open-Vocabulary Video Instance Segmentation, which aims to simultaneously segment, track, and classify objects in videos from open-set categories, including novel categories unseen during training. Second, to benchmark Open-Vocabulary VIS, we collect a Large-Vocabulary Video Instance Segmentation dataset(LV-VIS), that contains well-annotated objects from 1,212 diverse categories, significantly surpassing the category size of existing datasets by more than one order of magnitude. Third, we propose an efficient Memory-Induced Vision-Language Transformer, MindVLT, to first achieve Open-Vocabulary VIS in an end-to-end manner with near real-time inference speed. Extensive experiments on LV-VIS and four existing VIS datasets demonstrate the strong zero-shot generalization ability of MindVLT on novel categories. We will release the dataset and code to facilitate future endeavors.","sentences":["Video Instance Segmentation(VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories, lacking the generalization ability to handle novel categories in real-world videos.","To address this limitation, we make the following three contributions.","First, we introduce the novel task of Open-Vocabulary Video Instance Segmentation, which aims to simultaneously segment, track, and classify objects in videos from open-set categories, including novel categories unseen during training.","Second, to benchmark Open-Vocabulary VIS, we collect a Large-Vocabulary Video Instance Segmentation dataset(LV-VIS), that contains well-annotated objects from 1,212 diverse categories, significantly surpassing the category size of existing datasets by more than one order of magnitude.","Third, we propose an efficient Memory-Induced Vision-Language Transformer, MindVLT, to first achieve Open-Vocabulary VIS in an end-to-end manner with near real-time inference speed.","Extensive experiments on LV-VIS and four existing VIS datasets demonstrate the strong zero-shot generalization ability of MindVLT on novel categories.","We will release the dataset and code to facilitate future endeavors."],"url":"http://arxiv.org/abs/2304.01715v1"}
{"created":"2023-04-04","title":"Privacy-Preserving Federated Discovery of DNA Motifs with Differential Privacy","abstract":"DNA motif discovery is an important issue in gene research, which aims to identify transcription factor binding sites (i.e., motifs) in DNA sequences to reveal the mechanisms that regulate gene expression. However, the phenomenon of data silos and the problem of privacy leakage have seriously hindered the development of DNA motif discovery. On the one hand, the phenomenon of data silos makes data collection difficult. On the other hand, the collection and use of DNA data become complicated and difficult because DNA is sensitive private information. In this context, how discovering DNA motifs under the premise of ensuring privacy and security and alleviating data silos has become a very important issue. Therefore, this paper proposes a novel method, namely DP-FLMD, to address this problem. Note that this is the first application of federated learning to the field of genetics research. The federated learning technique is used to solve the problem of data silos. It has the advantage of enabling multiple participants to train models together and providing privacy protection services. To address the challenges of federated learning in terms of communication costs, this paper applies a sampling method and a strategy for reducing communication costs to DP-FLMD. In addition, differential privacy, a privacy protection technique with rigorous mathematical proof, is also applied to DP-FLMD. Experiments on the DNA datasets show that DP-FLMD has high mining accuracy and runtime efficiency, and the performance of the algorithm is affected by some parameters.","sentences":["DNA motif discovery is an important issue in gene research, which aims to identify transcription factor binding sites (i.e., motifs) in DNA sequences to reveal the mechanisms that regulate gene expression.","However, the phenomenon of data silos and the problem of privacy leakage have seriously hindered the development of DNA motif discovery.","On the one hand, the phenomenon of data silos makes data collection difficult.","On the other hand, the collection and use of DNA data become complicated and difficult because DNA is sensitive private information.","In this context, how discovering DNA motifs under the premise of ensuring privacy and security and alleviating data silos has become a very important issue.","Therefore, this paper proposes a novel method, namely DP-FLMD, to address this problem.","Note that this is the first application of federated learning to the field of genetics research.","The federated learning technique is used to solve the problem of data silos.","It has the advantage of enabling multiple participants to train models together and providing privacy protection services.","To address the challenges of federated learning in terms of communication costs, this paper applies a sampling method and a strategy for reducing communication costs to DP-FLMD.","In addition, differential privacy, a privacy protection technique with rigorous mathematical proof, is also applied to DP-FLMD.","Experiments on the DNA datasets show that DP-FLMD has high mining accuracy and runtime efficiency, and the performance of the algorithm is affected by some parameters."],"url":"http://arxiv.org/abs/2304.01689v1"}
{"created":"2023-04-04","title":"HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering","abstract":"We consider the challenging task of training models for image-to-video deblurring, which aims to recover a sequence of sharp images corresponding to a given blurry image input. A critical issue disturbing the training of an image-to-video model is the ambiguity of the frame ordering since both the forward and backward sequences are plausible solutions. This paper proposes an effective self-supervised ordering scheme that allows training high-quality image-to-video deblurring models. Unlike previous methods that rely on order-invariant losses, we assign an explicit order for each video sequence, thus avoiding the order-ambiguity issue. Specifically, we map each video sequence to a vector in a latent high-dimensional space so that there exists a hyperplane such that for every video sequence, the vectors extracted from it and its reversed sequence are on different sides of the hyperplane. The side of the vectors will be used to define the order of the corresponding sequence. Last but not least, we propose a real-image dataset for the image-to-video deblurring problem that covers a variety of popular domains, including face, hand, and street. Extensive experimental results confirm the effectiveness of our method. Code and data are available at https://github.com/VinAIResearch/HyperCUT.git","sentences":["We consider the challenging task of training models for image-to-video deblurring, which aims to recover a sequence of sharp images corresponding to a given blurry image input.","A critical issue disturbing the training of an image-to-video model is the ambiguity of the frame ordering since both the forward and backward sequences are plausible solutions.","This paper proposes an effective self-supervised ordering scheme that allows training high-quality image-to-video deblurring models.","Unlike previous methods that rely on order-invariant losses, we assign an explicit order for each video sequence, thus avoiding the order-ambiguity issue.","Specifically, we map each video sequence to a vector in a latent high-dimensional space so that there exists a hyperplane such that for every video sequence, the vectors extracted from it and its reversed sequence are on different sides of the hyperplane.","The side of the vectors will be used to define the order of the corresponding sequence.","Last but not least, we propose a real-image dataset for the image-to-video deblurring problem that covers a variety of popular domains, including face, hand, and street.","Extensive experimental results confirm the effectiveness of our method.","Code and data are available at https://github.com/VinAIResearch/HyperCUT.git"],"url":"http://arxiv.org/abs/2304.01686v2"}
{"created":"2023-04-04","title":"Can BERT eat RuCoLA? Topological Data Analysis to Explain","abstract":"This paper investigates how Transformer language models (LMs) fine-tuned for acceptability classification capture linguistic features. Our approach uses the best practices of topological data analysis (TDA) in NLP: we construct directed attention graphs from attention matrices, derive topological features from them, and feed them to linear classifiers. We introduce two novel features, chordality, and the matching number, and show that TDA-based classifiers outperform fine-tuning baselines. We experiment with two datasets, CoLA and RuCoLA in English and Russian, typologically different languages. On top of that, we propose several black-box introspection techniques aimed at detecting changes in the attention mode of the LMs during fine-tuning, defining the LM's prediction confidences, and associating individual heads with fine-grained grammar phenomena. Our results contribute to understanding the behavior of monolingual LMs in the acceptability classification task, provide insights into the functional roles of attention heads, and highlight the advantages of TDA-based approaches for analyzing LMs. We release the code and the experimental results for further uptake.","sentences":["This paper investigates how Transformer language models (LMs) fine-tuned for acceptability classification capture linguistic features.","Our approach uses the best practices of topological data analysis (TDA) in NLP: we construct directed attention graphs from attention matrices, derive topological features from them, and feed them to linear classifiers.","We introduce two novel features, chordality, and the matching number, and show that TDA-based classifiers outperform fine-tuning baselines.","We experiment with two datasets, CoLA and RuCoLA in English and Russian, typologically different languages.","On top of that, we propose several black-box introspection techniques aimed at detecting changes in the attention mode of the LMs during fine-tuning, defining the LM's prediction confidences, and associating individual heads with fine-grained grammar phenomena.","Our results contribute to understanding the behavior of monolingual LMs in the acceptability classification task, provide insights into the functional roles of attention heads, and highlight the advantages of TDA-based approaches for analyzing LMs.","We release the code and the experimental results for further uptake."],"url":"http://arxiv.org/abs/2304.01680v1"}
{"created":"2023-04-04","title":"Motion-R3: Fast and Accurate Motion Annotation via Representation-based Representativeness Ranking","abstract":"In this paper, we follow a data-centric philosophy and propose a novel motion annotation method based on the inherent representativeness of motion data in a given dataset. Specifically, we propose a Representation-based Representativeness Ranking R3 method that ranks all motion data in a given dataset according to their representativeness in a learned motion representation space. We further propose a novel dual-level motion constrastive learning method to learn the motion representation space in a more informative way. Thanks to its high efficiency, our method is particularly responsive to frequent requirements change and enables agile development of motion annotation models. Experimental results on the HDM05 dataset against state-of-the-art methods demonstrate the superiority of our method.","sentences":["In this paper, we follow a data-centric philosophy and propose a novel motion annotation method based on the inherent representativeness of motion data in a given dataset.","Specifically, we propose a Representation-based Representativeness Ranking R3 method that ranks all motion data in a given dataset according to their representativeness in a learned motion representation space.","We further propose a novel dual-level motion constrastive learning method to learn the motion representation space in a more informative way.","Thanks to its high efficiency, our method is particularly responsive to frequent requirements change and enables agile development of motion annotation models.","Experimental results on the HDM05 dataset against state-of-the-art methods demonstrate the superiority of our method."],"url":"http://arxiv.org/abs/2304.01672v1"}
{"created":"2023-04-06","title":"Natural Language Robot Programming: NLP integrated with autonomous robotic grasping","abstract":"In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks. Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database. We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone. Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot. Our results indicate that our approach has a high system usability score. The framework's dictionary can be easily extended without relying on transfer learning or large data sets. In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study.","sentences":["In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks.","Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database.","We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone.","Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot.","Our results indicate that our approach has a high system usability score.","The framework's dictionary can be easily extended without relying on transfer learning or large data sets.","In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study."],"url":"http://arxiv.org/abs/2304.02993v1"}
{"created":"2023-04-02","title":"SEENN: Towards Temporal Spiking Early-Exit Neural Networks","abstract":"Spiking Neural Networks (SNNs) have recently become more popular as a biologically plausible substitute for traditional Artificial Neural Networks (ANNs). SNNs are cost-efficient and deployment-friendly because they process input in both spatial and temporal manners using binary spikes. However, we observe that the information capacity in SNNs is affected by the number of timesteps, leading to an accuracy-efficiency tradeoff. In this work, we study a fine-grained adjustment of the number of timesteps in SNNs. Specifically, we treat the number of timesteps as a variable conditioned on different input samples to reduce redundant timesteps for certain data. We call our method Spiking Early-Exit Neural Networks (SEENNs). To determine the appropriate number of timesteps, we propose SEENN-I which uses a confidence score thresholding to filter out the uncertain predictions, and SEENN-II which determines the number of timesteps by reinforcement learning. Moreover, we demonstrate that SEENN is compatible with both the directly trained SNN and the ANN-SNN conversion. By dynamically adjusting the number of timesteps, our SEENN achieves a remarkable reduction in the average number of timesteps during inference. For example, our SEENN-II ResNet-19 can achieve 96.1% accuracy with an average of 1.08 timesteps on the CIFAR-10 test dataset.","sentences":["Spiking Neural Networks (SNNs) have recently become more popular as a biologically plausible substitute for traditional Artificial Neural Networks (ANNs).","SNNs are cost-efficient and deployment-friendly because they process input in both spatial and temporal manners using binary spikes.","However, we observe that the information capacity in SNNs is affected by the number of timesteps, leading to an accuracy-efficiency tradeoff.","In this work, we study a fine-grained adjustment of the number of timesteps in SNNs.","Specifically, we treat the number of timesteps as a variable conditioned on different input samples to reduce redundant timesteps for certain data.","We call our method Spiking Early-Exit Neural Networks (SEENNs).","To determine the appropriate number of timesteps, we propose SEENN-I which uses a confidence score thresholding to filter out the uncertain predictions, and SEENN-II which determines the number of timesteps by reinforcement learning.","Moreover, we demonstrate that SEENN is compatible with both the directly trained SNN and the ANN-SNN conversion.","By dynamically adjusting the number of timesteps, our SEENN achieves a remarkable reduction in the average number of timesteps during inference.","For example, our SEENN-II ResNet-19 can achieve 96.1% accuracy with an average of 1.08 timesteps on the CIFAR-10 test dataset."],"url":"http://arxiv.org/abs/2304.01230v1"}
{"created":"2023-04-02","title":"Mini-batch $k$-means terminates within $O(d/\u03b5)$ iterations","abstract":"We answer the question: \"Does local progress (on batches) imply global progress (on the entire dataset) for mini-batch $k$-means?\". Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below some threshold.   Although at first glance it appears that this algorithm might execute forever, we answer the above question in the affirmative and show that if the batch is of size $\\tilde{\\Omega}((d/\\epsilon)^2)$, it must terminate within $O(d/\\epsilon)$ iterations with high probability, where $d$ is the dimension of the input, and $\\epsilon$ is a threshold parameter for termination. This is true regardless of how the centers are initialized. When the algorithm is initialized with the $k$-means++ initialization scheme, it achieves an approximation ratio of $O(\\log k)$ (the same as the full-batch version).   Finally, we show the applicability of our results to the mini-batch $k$-means algorithm implemented in the scikit-learn (sklearn) python library.","sentences":["We answer the question: \"Does local progress (on batches) imply global progress (on the entire dataset) for mini-batch $k$-means?\".","Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below some threshold.   ","Although at first glance it appears that this algorithm might execute forever, we answer the above question in the affirmative and show that if the batch is of size $\\tilde{\\Omega}((d/\\epsilon)^2)$, it must terminate within $O(d/\\epsilon)$ iterations with high probability, where $d$ is the dimension of the input, and $\\epsilon$ is a threshold parameter for termination.","This is true regardless of how the centers are initialized.","When the algorithm is initialized with the $k$-means++ initialization scheme, it achieves an approximation ratio of $O(\\log k)$ (the same as the full-batch version).   ","Finally, we show the applicability of our results to the mini-batch $k$-means algorithm implemented in the scikit-learn (sklearn) python library."],"url":"http://arxiv.org/abs/2304.00419v1"}
{"created":"2023-03-30","title":"XPert: Peripheral Circuit & Neural Architecture Co-search for Area and Energy-efficient Xbar-based Computing","abstract":"The hardware-efficiency and accuracy of Deep Neural Networks (DNNs) implemented on In-memory Computing (IMC) architectures primarily depend on the DNN architecture and the peripheral circuit parameters. It is therefore essential to holistically co-search the network and peripheral parameters to achieve optimal performance. To this end, we propose XPert, which co-searches network architecture in tandem with peripheral parameters such as the type and precision of analog-to-digital converters, crossbar column sharing and the layer-specific input precision using an optimization-based design space exploration. Compared to VGG16 baselines, XPert achieves 10.24x (4.7x) lower EDAP, 1.72x (1.62x) higher TOPS/W,1.93x (3x) higher TOPS/mm2 at 92.46% (56.7%) accuracy for CIFAR10 (TinyImagenet) datasets. The code for this paper is available at https://github.com/Intelligent-Computing-Lab-Yale/XPert.","sentences":["The hardware-efficiency and accuracy of Deep Neural Networks (DNNs) implemented on In-memory Computing (IMC) architectures primarily depend on the DNN architecture and the peripheral circuit parameters.","It is therefore essential to holistically co-search the network and peripheral parameters to achieve optimal performance.","To this end, we propose XPert, which co-searches network architecture in tandem with peripheral parameters such as the type and precision of analog-to-digital converters, crossbar column sharing and the layer-specific input precision using an optimization-based design space exploration.","Compared to VGG16 baselines, XPert achieves 10.24x (4.7x) lower EDAP, 1.72x (1.62x) higher TOPS/W,1.93x (3x) higher TOPS/mm2 at 92.46% (56.7%) accuracy for CIFAR10 (TinyImagenet) datasets.","The code for this paper is available at https://github.com/Intelligent-Computing-Lab-Yale/XPert."],"url":"http://arxiv.org/abs/2303.17646v1"}
{"created":"2023-03-30","title":"Going Beyond Nouns With Vision & Language Models Using Synthetic Data","abstract":"Large-scale pre-trained Vision & Language (VL) models have shown remarkable performance in many applications, enabling replacing a fixed set of supported classes with zero-shot open vocabulary reasoning over (almost arbitrary) natural language prompts. However, recent works have uncovered a fundamental weakness of these models. For example, their difficulty to understand Visual Language Concepts (VLC) that go 'beyond nouns' such as the meaning of non-object words (e.g., attributes, actions, relations, states, etc.), or difficulty in performing compositional reasoning such as understanding the significance of the order of the words in a sentence. In this work, we investigate to which extent purely synthetic data could be leveraged to teach these models to overcome such shortcomings without compromising their zero-shot capabilities. We contribute Synthetic Visual Concepts (SyViC) - a million-scale synthetic dataset and data generation codebase allowing to generate additional suitable data to improve VLC understanding and compositional reasoning of VL models. Additionally, we propose a general VL finetuning strategy for effectively leveraging SyViC towards achieving these improvements. Our extensive experiments and ablations on VL-Checklist, Winoground, and ARO benchmarks demonstrate that it is possible to adapt strong pre-trained VL models with synthetic data significantly enhancing their VLC understanding (e.g. by 9.9% on ARO and 4.3% on VL-Checklist) with under 1% drop in their zero-shot accuracy.","sentences":["Large-scale pre-trained Vision & Language (VL) models have shown remarkable performance in many applications, enabling replacing a fixed set of supported classes with zero-shot open vocabulary reasoning over (almost arbitrary) natural language prompts.","However, recent works have uncovered a fundamental weakness of these models.","For example, their difficulty to understand Visual Language Concepts (VLC) that go 'beyond nouns' such as the meaning of non-object words (e.g., attributes, actions, relations, states, etc.), or difficulty in performing compositional reasoning such as understanding the significance of the order of the words in a sentence.","In this work, we investigate to which extent purely synthetic data could be leveraged to teach these models to overcome such shortcomings without compromising their zero-shot capabilities.","We contribute Synthetic Visual Concepts (SyViC) - a million-scale synthetic dataset and data generation codebase allowing to generate additional suitable data to improve VLC understanding and compositional reasoning of VL models.","Additionally, we propose a general VL finetuning strategy for effectively leveraging SyViC towards achieving these improvements.","Our extensive experiments and ablations on VL-Checklist, Winoground, and ARO benchmarks demonstrate that it is possible to adapt strong pre-trained VL models with synthetic data significantly enhancing their VLC understanding (e.g. by 9.9% on ARO and 4.3% on VL-Checklist) with under 1% drop in their zero-shot accuracy."],"url":"http://arxiv.org/abs/2303.17590v1"}
{"created":"2023-03-30","title":"Mastering Complex Modes: A New Method for Real-Time Modal Identification of Vibrating Systems","abstract":"A novel algorithm for real-time modal identification in linear vibrating systems with complex modes is introduced, utilizing a combination of first order eigen-perturbation and second order separation techniques. In practical settings, structures with complex modes are frequently encountered and their presence often poses a challenge in accurately estimating the source signal in real-time. The proposed methodology addresses this issue by incorporating the right angle phase shift of the response in the sensor output and updating the second order statistics of the complex response through first order eigen-perturbation. Empirical evidence of the efficacy of the technique is demonstrated through numerical case studies and validation using various numerically modeled systems, as well as a standard ASCE-SHM benchmark problem with complex modes, highlighting the capability of the proposed method to achieve precise real-time modal property identification and online source separation with a minimal number of initially required batch data.","sentences":["A novel algorithm for real-time modal identification in linear vibrating systems with complex modes is introduced, utilizing a combination of first order eigen-perturbation and second order separation techniques.","In practical settings, structures with complex modes are frequently encountered and their presence often poses a challenge in accurately estimating the source signal in real-time.","The proposed methodology addresses this issue by incorporating the right angle phase shift of the response in the sensor output and updating the second order statistics of the complex response through first order eigen-perturbation.","Empirical evidence of the efficacy of the technique is demonstrated through numerical case studies and validation using various numerically modeled systems, as well as a standard ASCE-SHM benchmark problem with complex modes, highlighting the capability of the proposed method to achieve precise real-time modal property identification and online source separation with a minimal number of initially required batch data."],"url":"http://arxiv.org/abs/2303.17349v1"}
{"created":"2023-03-29","title":"An intelligent modular real-time vision-based system for environment perception","abstract":"A significant portion of driving hazards is caused by human error and disregard for local driving regulations; Consequently, an intelligent assistance system can be beneficial. This paper proposes a novel vision-based modular package to ensure drivers' safety by perceiving the environment. Each module is designed based on accuracy and inference time to deliver real-time performance. As a result, the proposed system can be implemented on a wide range of vehicles with minimum hardware requirements. Our modular package comprises four main sections: lane detection, object detection, segmentation, and monocular depth estimation. Each section is accompanied by novel techniques to improve the accuracy of others along with the entire system. Furthermore, a GUI is developed to display perceived information to the driver. In addition to using public datasets, like BDD100K, we have also collected and annotated a local dataset that we utilize to fine-tune and evaluate our system. We show that the accuracy of our system is above 80% in all the sections. Our code and data are available at https://github.com/Pandas-Team/Autonomous-Vehicle-Environment-Perception","sentences":["A significant portion of driving hazards is caused by human error and disregard for local driving regulations; Consequently, an intelligent assistance system can be beneficial.","This paper proposes a novel vision-based modular package to ensure drivers' safety by perceiving the environment.","Each module is designed based on accuracy and inference time to deliver real-time performance.","As a result, the proposed system can be implemented on a wide range of vehicles with minimum hardware requirements.","Our modular package comprises four main sections: lane detection, object detection, segmentation, and monocular depth estimation.","Each section is accompanied by novel techniques to improve the accuracy of others along with the entire system.","Furthermore, a GUI is developed to display perceived information to the driver.","In addition to using public datasets, like BDD100K, we have also collected and annotated a local dataset that we utilize to fine-tune and evaluate our system.","We show that the accuracy of our system is above 80% in all the sections.","Our code and data are available at https://github.com/Pandas-Team/Autonomous-Vehicle-Environment-Perception"],"url":"http://arxiv.org/abs/2303.16710v1"}
{"created":"2023-03-28","title":"Dias: Dynamic Rewriting of Pandas Code","abstract":"In recent years, dataframe libraries, such as pandas have exploded in popularity. Due to their flexibility, they are increasingly used in ad-hoc exploratory data analysis (EDA) workloads. These workloads are diverse, including custom functions which can span libraries or be written in pure Python. The majority of systems available to accelerate EDA workloads focus on bulk-parallel workloads, which contain vastly different computational patterns, typically within a single library. As a result, they can introduce excessive overheads for ad-hoc EDA workloads due to their expensive optimization techniques. Instead, we identify program rewriting as a lightweight technique which can offer substantial speedups while also avoiding slowdowns. We implemented our techniques in Dias, which rewrites notebook cells to be more efficient for ad-hoc EDA workloads. We develop techniques for efficient rewrites in Dias, including dynamic checking of preconditions under which rewrites are correct and just-in-time rewrites for notebook environments. We show that Dias can rewrite individual cells to be 57$\\times$ faster compared to pandas and 1909$\\times$ faster compared to optimized systems such as modin. Furthermore, Dias can accelerate whole notebooks by up to 3.6$\\times$ compared to pandas and 26.4$\\times$ compared to modin.","sentences":["In recent years, dataframe libraries, such as pandas have exploded in popularity.","Due to their flexibility, they are increasingly used in ad-hoc exploratory data analysis (EDA) workloads.","These workloads are diverse, including custom functions which can span libraries or be written in pure Python.","The majority of systems available to accelerate EDA workloads focus on bulk-parallel workloads, which contain vastly different computational patterns, typically within a single library.","As a result, they can introduce excessive overheads for ad-hoc EDA workloads due to their expensive optimization techniques.","Instead, we identify program rewriting as a lightweight technique which can offer substantial speedups while also avoiding slowdowns.","We implemented our techniques in Dias, which rewrites notebook cells to be more efficient for ad-hoc EDA workloads.","We develop techniques for efficient rewrites in Dias, including dynamic checking of preconditions under which rewrites are correct and just-in-time rewrites for notebook environments.","We show that Dias can rewrite individual cells to be 57$\\times$ faster compared to pandas and 1909$\\times$ faster compared to optimized systems such as modin.","Furthermore, Dias can accelerate whole notebooks by up to 3.6$\\times$ compared to pandas and 26.4$\\times$ compared to modin."],"url":"http://arxiv.org/abs/2303.16146v1"}
{"created":"2023-03-27","title":"Mass predictions of triply heavy hybrid baryons via QCD sum rules","abstract":"In this article, we study the mass spectrum of the low-lying triply heavy hybrid baryon, which consists of three valence heavy quarks in a color octet and one valence gluon, with spin-parity $J^P=(\\frac{1}{2})^+$ via QCD sum rules. This is the first study on the triply heavy hybrid baryons in the framework of QCD sum rules. After performing the QCD sum rule analysis, we find that the mass of $cccg$ hybrid baryon lies in $M_{cccg}= 5.91-6.13$ GeV. As a byproduct, the mass of the triply bottom hybrid baryon state is extracted to be around $M_{bbbg}=14.62-14.82$ GeV. The contributions up to dimension eight at the leading order of $\\alpha_s$ (LO) in the operator product expansion are taken into account in the calculation. The triply charmed hybrid baryon predicted in this work can decay into one doubly charmed baryon and one charmed meson. Especially, we propose to search for $cccg$ hybrid baryon with $J^{P}= (1/2)^+$ in the P-wave decay channels $\\Xi_{cc}^{++} D^0$, $\\Xi_{cc}^{+} D^+$, and $\\Xi_{ccs}^{+} D_s^+$, which may be accessible in future BelleII, Super-B, PANDA, and LHCb experiments.","sentences":["In this article, we study the mass spectrum of the low-lying triply heavy hybrid baryon, which consists of three valence heavy quarks in a color octet and one valence gluon, with spin-parity $J^P=(\\frac{1}{2})^+$ via QCD sum rules.","This is the first study on the triply heavy hybrid baryons in the framework of QCD sum rules.","After performing the QCD sum rule analysis, we find that the mass of $cccg$ hybrid baryon lies in $M_{cccg}= 5.91-6.13$ GeV. As a byproduct, the mass of the triply bottom hybrid baryon state is extracted to be around $M_{bbbg}=14.62-14.82$ GeV.","The contributions up to dimension eight at the leading order of $\\alpha_s$ (LO) in the operator product expansion are taken into account in the calculation.","The triply charmed hybrid baryon predicted in this work can decay into one doubly charmed baryon and one charmed meson.","Especially, we propose to search for $cccg$ hybrid baryon with $J^{P}= (1/2)^+$ in the P-wave decay channels $\\Xi_{cc}^{++} D^0$, $\\Xi_{cc}^{+} D^+$, and $\\Xi_{ccs}^{+} D_s^+$, which may be accessible in future BelleII, Super-B, PANDA, and LHCb experiments."],"url":"http://arxiv.org/abs/2303.15173v1"}
{"created":"2023-03-25","title":"Combining Contexts from Multiple Sources for Documentation-Specific Code Example Generation","abstract":"Code example is a crucial part of good documentation. It helps the developers to understand the documentation easily and use the corresponding code unit (e.g., method) properly. However, many official documentation still lacks (good) code example and it is one of the common documentation issues as found by several studies. Hence in this paper, we consider automatic code example generation for documentation, a direction less explored by the existing research. We employ Codex, a GPT-3 based model, pre-trained on both natural and programming languages to generate code examples from source code and documentation given as input. Our preliminary investigation on 40 scikit-learn methods reveals that this approach is able to generate good code examples where 72.5% code examples were executed without error (passability) and 82.5% properly dealt with the target method and documentation (relevance). We also find that incorporation of error logs (produced by the compiler while executing a failed code example) in the input further improves the passability from 72.5% to 87.5%. Thus, our investigation sets the base of documentation-specific code example generation and warrants in-depth future studies.","sentences":["Code example is a crucial part of good documentation.","It helps the developers to understand the documentation easily and use the corresponding code unit (e.g., method) properly.","However, many official documentation still lacks (good) code example and it is one of the common documentation issues as found by several studies.","Hence in this paper, we consider automatic code example generation for documentation, a direction less explored by the existing research.","We employ Codex, a GPT-3 based model, pre-trained on both natural and programming languages to generate code examples from source code and documentation given as input.","Our preliminary investigation on 40 scikit-learn methods reveals that this approach is able to generate good code examples where 72.5% code examples were executed without error (passability) and 82.5% properly dealt with the target method and documentation (relevance).","We also find that incorporation of error logs (produced by the compiler while executing a failed code example) in the input further improves the passability from 72.5% to 87.5%.","Thus, our investigation sets the base of documentation-specific code example generation and warrants in-depth future studies."],"url":"http://arxiv.org/abs/2303.14542v1"}
{"created":"2023-03-24","title":"SPONGE: Sequence Planning with Deformable-ON-Rigid Contact Prediction from Geometric Features","abstract":"Planning robotic manipulation tasks, especially those that involve interaction between deformable and rigid objects, is challenging due to the complexity in predicting such interactions. We introduce SPONGE, a sequence planning pipeline powered by a deep learning-based contact prediction model for contacts between deformable and rigid bodies under interactions. The contact prediction model is trained on synthetic data generated by a developed simulation environment to learn the mapping from point-cloud observation of a rigid target object and the pose of a deformable tool, to 3D representation of the contact points between the two bodies. We experimentally evaluated the proposed approach for a dish cleaning task both in simulation and on a real \\panda with real-world objects. The experimental results demonstrate that in both scenarios the proposed planning pipeline is capable of generating high-quality trajectories that can accomplish the task by achieving more than 90\\% area coverage on different objects of varying sizes and curvatures while minimizing travel distance. Code and video are available at: \\url{https://irobotics.aalto.fi/sponge/}.","sentences":["Planning robotic manipulation tasks, especially those that involve interaction between deformable and rigid objects, is challenging due to the complexity in predicting such interactions.","We introduce SPONGE, a sequence planning pipeline powered by a deep learning-based contact prediction model for contacts between deformable and rigid bodies under interactions.","The contact prediction model is trained on synthetic data generated by a developed simulation environment to learn the mapping from point-cloud observation of a rigid target object and the pose of a deformable tool, to 3D representation of the contact points between the two bodies.","We experimentally evaluated the proposed approach for a dish cleaning task both in simulation and on a real \\panda with real-world objects.","The experimental results demonstrate that in both scenarios the proposed planning pipeline is capable of generating high-quality trajectories that can accomplish the task by achieving more than 90\\% area coverage on different objects of varying sizes and curvatures while minimizing travel distance.","Code and video are available at: \\url{https://irobotics.aalto.fi/sponge/}."],"url":"http://arxiv.org/abs/2303.14012v1"}
{"created":"2023-03-24","title":"Two dimensional penetrative phototactic bioconvection with periodic sidewalls","abstract":"Light gradient can allow many motile photosynthetic microorganisms to bias their motion towards moderate light (positive phototaxis) or away from intense light (negative phototaxis). The proposed work presents the penetrative phototactic bioconvection in a non-scattering algal suspension. The suspension is confined by a stress-free top boundary, and rigid bottom and periodic lateral boundaries. The resulting bioconvective patterns of the problem strongly resemble to that of a spatially extended domain in the same vicinity. The bioconvection solution appears in the form of a two-rolls pattern (or any even number of rolls) due to the periodic lateral boundaries.","sentences":["Light gradient can allow many motile photosynthetic microorganisms to bias their motion towards moderate light (positive phototaxis) or away from intense light (negative phototaxis).","The proposed work presents the penetrative phototactic bioconvection in a non-scattering algal suspension.","The suspension is confined by a stress-free top boundary, and rigid bottom and periodic lateral boundaries.","The resulting bioconvective patterns of the problem strongly resemble to that of a spatially extended domain in the same vicinity.","The bioconvection solution appears in the form of a two-rolls pattern (or any even number of rolls) due to the periodic lateral boundaries."],"url":"http://arxiv.org/abs/2303.13837v1"}
{"created":"2023-03-23","title":"An infrared light-guide based target positioning system for operation in a harsh environment","abstract":"In the PANDA experiment's hypernuclear and hyperatom setup, a positioning system for the primary production target is required, which will be located in the center of the solenoid magnet, in ultra-high vacuum, and exposed to high radiation levels. In this work, a prototype for a positioning sensor was built using a bisected light guide for infrared light and a low-priced readout system based on microcontrollers. In contrast to many modern positioning systems that require electronics in direct proximity, this setup has no active electronic components close to the moving parts.   The prototype system was operated with a resolution of better than 5$\\micro$m, and with a repeatability of better than $\\pm$18$\\micro$m in a total of 14000 measurements. The demonstrated performance is by far satisfying the positioning requirement of $\\pm$300 $\\micro$m in the hypernuclear and hyperatom setup at PANDA.","sentences":["In the PANDA experiment's hypernuclear and hyperatom setup, a positioning system for the primary production target is required, which will be located in the center of the solenoid magnet, in ultra-high vacuum, and exposed to high radiation levels.","In this work, a prototype for a positioning sensor was built using a bisected light guide for infrared light and a low-priced readout system based on microcontrollers.","In contrast to many modern positioning systems that require electronics in direct proximity, this setup has no active electronic components close to the moving parts.   ","The prototype system was operated with a resolution of better than 5$\\micro$m, and with a repeatability of better than $\\pm$18$\\micro$m in a total of 14000 measurements.","The demonstrated performance is by far satisfying the positioning requirement of $\\pm$300 $\\micro$m in the hypernuclear and hyperatom setup at PANDA."],"url":"http://arxiv.org/abs/2303.13359v1"}
{"created":"2023-03-23","title":"Metal content of relativistically jetted and radio-quiet quasars in the main sequence context","abstract":"Optical and UV properties of radio-quiet (RQ) and radio-loud (RL, relativistically \"jetted\") active galactic nuclei (AGN) are known to differ markedly; however, it is still unclear what is due to a sample selection and what is associated with intrinsic differences in the inner workings of their emitting regions. Chemical composition is an important parameter related to the trends of the quasar main sequence. Recent works suggest that in addition to physical properties such as density, column density, and ionization level, strong FeII emitters require very high metal content. Little is known, however, about the chemical composition of jetted radio-loud sources. In this short note, we present a pilot analysis of the chemical composition of low-z radio-loud and radio-quiet quasars. Optical and UV spectra from ground and space were combined to allow for precise measurements of metallicity-sensitive diagnostic ratios. The comparison between radio-quiet and radio-loud was carried out for sources in the same domain of the Eigenvector 1 / main sequence parameter space. Arrays of dedicated photoionization simulations with the input of appropriate spectral energy distributions indicate that metallicity is sub-solar for RL AGN, and slightly sub-solar or around solar for RQ AGN. The metal content of the broad line emitting region likely reflects a similar enrichment story for both classes of AGN not involving recent circum-nuclear or nuclear starbursts.","sentences":["Optical and UV properties of radio-quiet (RQ) and radio-loud (RL, relativistically \"jetted\") active galactic nuclei (AGN) are known to differ markedly; however, it is still unclear what is due to a sample selection and what is associated with intrinsic differences in the inner workings of their emitting regions.","Chemical composition is an important parameter related to the trends of the quasar main sequence.","Recent works suggest that in addition to physical properties such as density, column density, and ionization level, strong FeII emitters require very high metal content.","Little is known, however, about the chemical composition of jetted radio-loud sources.","In this short note, we present a pilot analysis of the chemical composition of low-z radio-loud and radio-quiet quasars.","Optical and UV spectra from ground and space were combined to allow for precise measurements of metallicity-sensitive diagnostic ratios.","The comparison between radio-quiet and radio-loud was carried out for sources in the same domain of the Eigenvector 1 / main sequence parameter space.","Arrays of dedicated photoionization simulations with the input of appropriate spectral energy distributions indicate that metallicity is sub-solar for RL AGN, and slightly sub-solar or around solar for RQ AGN.","The metal content of the broad line emitting region likely reflects a similar enrichment story for both classes of AGN not involving recent circum-nuclear or nuclear starbursts."],"url":"http://arxiv.org/abs/2303.13250v1"}
{"created":"2023-03-22","title":"Selective Data Augmentation for Robust Speech Translation","abstract":"Speech translation (ST) systems translate speech in one language to text in another language. End-to-end ST systems (e2e-ST) have gained popularity over cascade systems because of their enhanced performance due to reduced latency and computational cost. Though resource intensive, e2e-ST systems have the inherent ability to retain para and non-linguistic characteristics of the speech unlike cascade systems. In this paper, we propose to use an e2e architecture for English-Hindi (en-hi) ST. We use two imperfect machine translation (MT) services to translate Libri-trans en text into hi text. While each service gives MT data individually to generate parallel ST data, we propose a data augmentation strategy of noisy MT data to aid robust ST. The main contribution of this paper is the proposal of a data augmentation strategy. We show that this results in better ST (BLEU score) compared to brute force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU score with our approach.","sentences":["Speech translation (ST) systems translate speech in one language to text in another language.","End-to-end ST systems (e2e-ST) have gained popularity over cascade systems because of their enhanced performance due to reduced latency and computational cost.","Though resource intensive, e2e-ST systems have the inherent ability to retain para and non-linguistic characteristics of the speech unlike cascade systems.","In this paper, we propose to use an e2e architecture for English-Hindi (en-hi) ST.","We use two imperfect machine translation (MT) services to translate Libri-trans en text into hi text.","While each service gives MT data individually to generate parallel ST data, we propose a data augmentation strategy of noisy MT data to aid robust ST.","The main contribution of this paper is the proposal of a data augmentation strategy.","We show that this results in better ST (BLEU score) compared to brute force augmentation of MT data.","We observed an absolute improvement of 1.59 BLEU score with our approach."],"url":"http://arxiv.org/abs/2304.03169v1"}
{"created":"2023-03-22","title":"Ghost Free Theory in Unitary Gauge: A New Candidate","abstract":"We propose an algebraic analysis using a 3+1 decomposition to identify conditions for a clever cancellation of the higher derivatives, which plagued the theory with Ostrogradsky ghosts, by exploiting some existing degeneracy in the Lagrangian. We obtain these conditions as linear equations (in terms of coefficients of the higher derivative terms) and demand that they vanish, such that the existence of nontrivial solutions implies that the theory is degenerate. We find that, for the theory under consideration, no such solutions exist for a general inhomogeneous scalar field, but that the theory is degenerate in the unitary gauge. We, then, find modified FLRW equations and narrow down conditions for which there could exist a de Sitter inflationary epoch. We further find constraints on the coefficients of the remaining higher-derivative interaction terms, based on power-counting renormalizability and tree-level unitarity up to the Planck scale.","sentences":["We propose an algebraic analysis using a 3+1 decomposition to identify conditions for a clever cancellation of the higher derivatives, which plagued the theory with Ostrogradsky ghosts, by exploiting some existing degeneracy in the Lagrangian.","We obtain these conditions as linear equations (in terms of coefficients of the higher derivative terms) and demand that they vanish, such that the existence of nontrivial solutions implies that the theory is degenerate.","We find that, for the theory under consideration, no such solutions exist for a general inhomogeneous scalar field, but that the theory is degenerate in the unitary gauge.","We, then, find modified FLRW equations and narrow down conditions for which there could exist a de Sitter inflationary epoch.","We further find constraints on the coefficients of the remaining higher-derivative interaction terms, based on power-counting renormalizability and tree-level unitarity up to the Planck scale."],"url":"http://arxiv.org/abs/2303.12464v1"}
{"created":"2023-03-17","title":"On the signless Laplacian spectrum of k-uniform hypergraphs","abstract":"Let $\\mathcal{H}$ be a connected $k$-uniform hypergraph on $n$ vertices and $m$ hyperedges. In [A.~Banerjee, On the spectrum of hypergraph, Linear Algebra and its Application, 614(2021), 82--110], Anirban Banerjee introduced a new adjacency matrix for hypergraphs. In this article we consider the corresponding signless Laplacian matrix $Q(\\mathcal{H})$ and discuss about its spectrum.","sentences":["Let $\\mathcal{H}$ be a connected $k$-uniform hypergraph on $n$ vertices and $m$ hyperedges.","In [A.~Banerjee, On the spectrum of hypergraph, Linear Algebra and its Application, 614(2021), 82--110], Anirban Banerjee introduced a new adjacency matrix for hypergraphs.","In this article we consider the corresponding signless Laplacian matrix $Q(\\mathcal{H})$ and discuss about its spectrum."],"url":"http://arxiv.org/abs/2303.09903v1"}
{"created":"2023-03-16","title":"Neural Architecture Search for Effective Teacher-Student Knowledge Transfer in Language Models","abstract":"Large pre-trained language models have achieved state-of-the-art results on a variety of downstream tasks. Knowledge Distillation (KD) of a smaller student model addresses their inefficiency, allowing for deployment in resource-constraint environments. KD however remains ineffective, as the student is manually selected from a set of existing options already pre-trained on large corpora, a sub-optimal choice within the space of all possible student architectures. This paper proposes KD-NAS, the use of Neural Architecture Search (NAS) guided by the Knowledge Distillation process to find the optimal student model for distillation from a teacher, for a given natural language task. In each episode of the search process, a NAS controller predicts a reward based on a combination of accuracy on the downstream task and latency of inference. The top candidate architectures are then distilled from the teacher on a small proxy set. Finally the architecture(s) with the highest reward is selected, and distilled on the full downstream task training set. When distilling on the MNLI task, our KD-NAS model produces a 2 point improvement in accuracy on GLUE tasks with equivalent GPU latency with respect to a hand-crafted student architecture available in the literature. Using Knowledge Distillation, this model also achieves a 1.4x speedup in GPU Latency (3.2x speedup on CPU) with respect to a BERT-Base Teacher, while maintaining 97% performance on GLUE Tasks (without CoLA). We also obtain an architecture with equivalent performance as the hand-crafted student model on the GLUE benchmark, but with a 15% speedup in GPU latency (20% speedup in CPU latency) and 0.8 times the number of parameters","sentences":["Large pre-trained language models have achieved state-of-the-art results on a variety of downstream tasks.","Knowledge Distillation (KD) of a smaller student model addresses their inefficiency, allowing for deployment in resource-constraint environments.","KD however remains ineffective, as the student is manually selected from a set of existing options already pre-trained on large corpora, a sub-optimal choice within the space of all possible student architectures.","This paper proposes KD-NAS, the use of Neural Architecture Search (NAS) guided by the Knowledge Distillation process to find the optimal student model for distillation from a teacher, for a given natural language task.","In each episode of the search process, a NAS controller predicts a reward based on a combination of accuracy on the downstream task and latency of inference.","The top candidate architectures are then distilled from the teacher on a small proxy set.","Finally the architecture(s) with the highest reward is selected, and distilled on the full downstream task training set.","When distilling on the MNLI task, our KD-NAS model produces a 2 point improvement in accuracy on GLUE tasks with equivalent GPU latency with respect to a hand-crafted student architecture available in the literature.","Using Knowledge Distillation, this model also achieves a 1.4x speedup in GPU Latency (3.2x speedup on CPU) with respect to a BERT-Base Teacher, while maintaining 97% performance on GLUE Tasks (without CoLA).","We also obtain an architecture with equivalent performance as the hand-crafted student model on the GLUE benchmark, but with a 15% speedup in GPU latency (20% speedup in CPU latency) and 0.8 times the number of parameters"],"url":"http://arxiv.org/abs/2303.09639v1"}
{"created":"2023-03-16","title":"Phototactic bioconvection in a forward scattering suspension illuminated by both diffuse and oblique collimated flux","abstract":"The onset of light-induced bioconvection via linear stability theory is investigated qualitatively for a suspension of phototactic algae. The forward scattering algal suspension is uniformly illuminated by both diffuse and oblique collimated flux. An unstable mode of disturbance at bioconvective instability transits from the stationary (overstable) to overstable (stationary) state at the variation in forward scattering coefficient for fixed parameters. Suspension becomes more stable as forward scattering coefficient increases.","sentences":["The onset of light-induced bioconvection via linear stability theory is investigated qualitatively for a suspension of phototactic algae.","The forward scattering algal suspension is uniformly illuminated by both diffuse and oblique collimated flux.","An unstable mode of disturbance at bioconvective instability transits from the stationary (overstable) to overstable (stationary) state at the variation in forward scattering coefficient for fixed parameters.","Suspension becomes more stable as forward scattering coefficient increases."],"url":"http://arxiv.org/abs/2303.09127v1"}
{"created":"2023-03-15","title":"MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge","abstract":"Large scale Vision-Language (VL) models have shown tremendous success in aligning representations between visual and text modalities. This enables remarkable progress in zero-shot recognition, image generation & editing, and many other exciting tasks. However, VL models tend to over-represent objects while paying much less attention to verbs, and require additional tuning on video data for best zero-shot action recognition performance. While previous work relied on large-scale, fully-annotated data, in this work we propose an unsupervised approach. We adapt a VL model for zero-shot and few-shot action recognition using a collection of unlabeled videos and an unpaired action dictionary. Based on that, we leverage Large Language Models and VL models to build a text bag for each unlabeled video via matching, text expansion and captioning. We use those bags in a Multiple Instance Learning setup to adapt an image-text backbone to video data. Although finetuned on unlabeled video data, our resulting models demonstrate high transferability to numerous unseen zero-shot downstream tasks, improving the base VL model performance by up to 14\\%, and even comparing favorably to fully-supervised baselines in both zero-shot and few-shot video recognition transfer. The code will be released later at \\url{https://github.com/wlin-at/MAXI}.","sentences":["Large scale Vision-Language (VL) models have shown tremendous success in aligning representations between visual and text modalities.","This enables remarkable progress in zero-shot recognition, image generation & editing, and many other exciting tasks.","However, VL models tend to over-represent objects while paying much less attention to verbs, and require additional tuning on video data for best zero-shot action recognition performance.","While previous work relied on large-scale, fully-annotated data, in this work we propose an unsupervised approach.","We adapt a VL model for zero-shot and few-shot action recognition using a collection of unlabeled videos and an unpaired action dictionary.","Based on that, we leverage Large Language Models and VL models to build a text bag for each unlabeled video via matching, text expansion and captioning.","We use those bags in a Multiple Instance Learning setup to adapt an image-text backbone to video data.","Although finetuned on unlabeled video data, our resulting models demonstrate high transferability to numerous unseen zero-shot downstream tasks, improving the base VL model performance by up to 14\\%, and even comparing favorably to fully-supervised baselines in both zero-shot and few-shot video recognition transfer.","The code will be released later at \\url{https://github.com/wlin-at/MAXI}."],"url":"http://arxiv.org/abs/2303.08914v1"}
{"created":"2023-03-15","title":"Building an Effective Email Spam Classification Model with spaCy","abstract":"Today, people use email services such as Gmail, Outlook, AOL Mail, etc. to communicate with each other as quickly as possible to send information and official letters. Spam or junk mail is a major challenge to this type of communication, usually sent by botnets with the aim of advertising, harming and stealing information in bulk to different people. Receiving unwanted spam emails on a daily basis fills up the inbox folder. Therefore, spam detection is a fundamental challenge, so far many works have been done to detect spam using clustering and text categorisation methods. In this article, the author has used the spaCy natural language processing library and 3 machine learning (ML) algorithms Naive Bayes (NB), Decision Tree C45 and Multilayer Perceptron (MLP) in the Python programming language to detect spam emails collected from the Gmail service. Observations show the accuracy rate (96%) of the Multilayer Perceptron (MLP) algorithm in spam detection.","sentences":["Today, people use email services such as Gmail, Outlook, AOL Mail, etc. to communicate with each other as quickly as possible to send information and official letters.","Spam or junk mail is a major challenge to this type of communication, usually sent by botnets with the aim of advertising, harming and stealing information in bulk to different people.","Receiving unwanted spam emails on a daily basis fills up the inbox folder.","Therefore, spam detection is a fundamental challenge, so far many works have been done to detect spam using clustering and text categorisation methods.","In this article, the author has used the spaCy natural language processing library and 3 machine learning (ML) algorithms Naive Bayes (NB), Decision Tree C45 and Multilayer Perceptron (MLP) in the Python programming language to detect spam emails collected from the Gmail service.","Observations show the accuracy rate (96%) of the Multilayer Perceptron (MLP) algorithm in spam detection."],"url":"http://arxiv.org/abs/2303.08792v1"}
{"created":"2023-03-15","title":"MCR-DL: Mix-and-Match Communication Runtime for Deep Learning","abstract":"In recent years, the training requirements of many state-of-the-art Deep Learning (DL) models have scaled beyond the compute and memory capabilities of a single processor, and necessitated distribution among processors. Training such massive models necessitates advanced parallelism strategies to maintain efficiency. However, such distributed DL parallelism strategies require a varied mixture of collective and point-to-point communication operations across a broad range of message sizes and scales. Examples of models using advanced parallelism strategies include Deep Learning Recommendation Models (DLRM) and Mixture-of-Experts (MoE). Communication libraries' performance varies wildly across different communication operations, scales, and message sizes. We propose MCR-DL: an extensible DL communication framework that supports all point-to-point and collective operations while enabling users to dynamically mix-and-match communication backends for a given operation without deadlocks. MCR-DL also comes packaged with a tuning suite for dynamically selecting the best communication backend for a given input tensor. We select DeepSpeed-MoE and DLRM as candidate DL models and demonstrate a 31% improvement in DS-MoE throughput on 256 V100 GPUs on the Lassen HPC system. Further, we achieve a 20% throughput improvement in a dense Megatron-DeepSpeed model and a 25% throughput improvement in DLRM on 32 A100 GPUs with the Theta-GPU HPC system.","sentences":["In recent years, the training requirements of many state-of-the-art Deep Learning (DL) models have scaled beyond the compute and memory capabilities of a single processor, and necessitated distribution among processors.","Training such massive models necessitates advanced parallelism strategies to maintain efficiency.","However, such distributed DL parallelism strategies require a varied mixture of collective and point-to-point communication operations across a broad range of message sizes and scales.","Examples of models using advanced parallelism strategies include Deep Learning Recommendation Models (DLRM) and Mixture-of-Experts (MoE).","Communication libraries' performance varies wildly across different communication operations, scales, and message sizes.","We propose MCR-DL: an extensible DL communication framework that supports all point-to-point and collective operations while enabling users to dynamically mix-and-match communication backends for a given operation without deadlocks.","MCR-DL also comes packaged with a tuning suite for dynamically selecting the best communication backend for a given input tensor.","We select DeepSpeed-MoE and DLRM as candidate DL models and demonstrate a 31% improvement in DS-MoE throughput on 256 V100 GPUs on the Lassen HPC system.","Further, we achieve a 20% throughput improvement in a dense Megatron-DeepSpeed model and a 25% throughput improvement in DLRM on 32 A100 GPUs with the Theta-GPU HPC system."],"url":"http://arxiv.org/abs/2303.08374v1"}
{"created":"2023-03-11","title":"FaaSched: A Jitter-Aware Serverless Scheduler","abstract":"Serverless computing systems are becoming very popular. Large corporations such as Netflix, Airbnb, and Coca-Cola use such systems for running their websites and IT systems. The advantages of such systems include superior support for auto-scaling, load balancing, and fast distributed processing. These are multi-QoS systems where different classes of applications have different latency and jitter (variation in the latency) requirements: we consider a mix of latency-sensitive (LS) and latency-desirable (LD) applications. Ensuring proper schedulability and QoS enforcement of LS applications is non-trivial. We need to minimize the jitter without increasing the response latency of LS applications, and we also need to keep the degradation of the response latency of LD applications in check.   This is the first paper in this domain that achieves a trade-off between the jitter suffered by LS applications and the response latency of LD applications. We minimize the former with a bound on the latter using a reinforcement learning (RL) based scheme. To design such an RL scheme, we performed detailed characterization studies to find the input variables of interest, defined novel state representations, and proposed a bespoke reward function that allows us to achieve this trade-off. For an aggressive use case comprising five popular LS and LD applications each, we show a reduction in response time variance and mean latency of 50.31% and 27.4%, respectively, for LS applications. The mean degradation in the execution latency of LD applications was limited to 19.88%.","sentences":["Serverless computing systems are becoming very popular.","Large corporations such as Netflix, Airbnb, and Coca-Cola use such systems for running their websites and IT systems.","The advantages of such systems include superior support for auto-scaling, load balancing, and fast distributed processing.","These are multi-QoS systems where different classes of applications have different latency and jitter (variation in the latency) requirements: we consider a mix of latency-sensitive (LS) and latency-desirable (LD) applications.","Ensuring proper schedulability and QoS enforcement of LS applications is non-trivial.","We need to minimize the jitter without increasing the response latency of LS applications, and we also need to keep the degradation of the response latency of LD applications in check.   ","This is the first paper in this domain that achieves a trade-off between the jitter suffered by LS applications and the response latency of LD applications.","We minimize the former with a bound on the latter using a reinforcement learning (RL) based scheme.","To design such an RL scheme, we performed detailed characterization studies to find the input variables of interest, defined novel state representations, and proposed a bespoke reward function that allows us to achieve this trade-off.","For an aggressive use case comprising five popular LS and LD applications each, we show a reduction in response time variance and mean latency of 50.31% and 27.4%, respectively, for LS applications.","The mean degradation in the execution latency of LD applications was limited to 19.88%."],"url":"http://arxiv.org/abs/2303.06473v1"}
{"created":"2023-03-10","title":"Quantum loop effects on the power spectrum and constraints on primordial black holes","abstract":"We present a detailed exposition on the prospects of formation of Primordial Black Holes (PBHs) during Slow Roll (SR) to Ultra Slow Roll (USR) transitions in the framework of single-field inflation. We use effective field theory (EFT) approach in order to keep the analysis model-independent and applicable to both the canonical and non-canonical cases. We show in detail how renormalizing the power spectrum to one loop order in $P(X,\\phi)$ theories severely limits the prospects for PBH formation in a single-field inflationary framework. We demonstrate that for the allowed range of effective sound speed, $1<c_s<1.17$, the consistency of one-loop corrected power spectrum leaves a small window for black hole masses, $M_{\\rm PBH}\\sim \\mathcal{O}(10^2-10^3)$gm to have sufficient e-foldings, $\\Delta {\\cal N}_{\\rm Total}\\sim {\\cal O}(54-59)$ for inflation. We confirm that adding a SR regime after USR before the end of inflation, does not significantly alter our conclusions. Our findings strictly rule out the possibility of generating large masses of PBHs from all possible models of single field inflation (canonical and non-canonical) and mature into a \"no-go theorem\" for the class of mentioned theories.","sentences":["We present a detailed exposition on the prospects of formation of Primordial Black Holes (PBHs) during Slow Roll (SR) to Ultra Slow Roll (USR) transitions in the framework of single-field inflation.","We use effective field theory (EFT) approach in order to keep the analysis model-independent and applicable to both the canonical and non-canonical cases.","We show in detail how renormalizing the power spectrum to one loop order in $P(X,\\phi)$ theories severely limits the prospects for PBH formation in a single-field inflationary framework.","We demonstrate that for the allowed range of effective sound speed, $1<c_s<1.17$, the consistency of one-loop corrected power spectrum leaves a small window for black hole masses, $M_{\\rm PBH}\\sim \\mathcal{O}(10^2-10^3)$gm to have sufficient e-foldings, $\\Delta {\\cal N}_{\\rm Total}\\sim {\\cal O}(54-59)$ for inflation.","We confirm that adding a SR regime after USR before the end of inflation, does not significantly alter our conclusions.","Our findings strictly rule out the possibility of generating large masses of PBHs from all possible models of single field inflation (canonical and non-canonical) and mature into a \"no-go theorem\" for the class of mentioned theories."],"url":"http://arxiv.org/abs/2303.06066v2"}
{"created":"2023-03-09","title":"Bipartite entanglement via distance between the states in a one dimensional spin 1/2 dimer copper acetate monohydrate","abstract":"In this paper, we used a theoretical measure known as distance between the states, $\\mathcal{E}(\\rho_e)$, to determine the bipartite entanglement of a one dimensional magnetic dimer system. The calculation was compared with the well-known entanglement measure, concurrence, and found to be the same. $\\mathcal{E}(\\rho_e)$ was, then, expressed in terms of two thermodynamic quantities, namely, magnetic susceptibility and specific heat. Experimental verification of temperature variation of the bipartite entanglement measure in terms of magnetic susceptibility and specific heat was done on single crystals of copper acetate-an excellent one dimensional dimer system. The results showed the existence of bipartite entanglement till temperatures as high as room temperature! Large sized single crystals of copper acetate were grown by a new evaporation technique and characterised by TGA, IR and Raman spectroscopy measurements.Density functional theory calculations were done to calculate the delocalisation index which showed much lower values of $\\delta(Cu,Cu)$ than other bonds, implying that the probability of direct Cu-Cu exchange in copper acetate is very small.","sentences":["In this paper, we used a theoretical measure known as distance between the states, $\\mathcal{E}(\\rho_e)$, to determine the bipartite entanglement of a one dimensional magnetic dimer system.","The calculation was compared with the well-known entanglement measure, concurrence, and found to be the same.","$\\mathcal{E}(\\rho_e)$ was, then, expressed in terms of two thermodynamic quantities, namely, magnetic susceptibility and specific heat.","Experimental verification of temperature variation of the bipartite entanglement measure in terms of magnetic susceptibility and specific heat was done on single crystals of copper acetate-an excellent one dimensional dimer system.","The results showed the existence of bipartite entanglement till temperatures as high as room temperature!","Large sized single crystals of copper acetate were grown by a new evaporation technique and characterised by TGA, IR and Raman spectroscopy measurements.","Density functional theory calculations were done to calculate the delocalisation index which showed much lower values of $\\delta(Cu,Cu)$ than other bonds, implying that the probability of direct Cu-Cu exchange in copper acetate is very small."],"url":"http://arxiv.org/abs/2303.05372v1"}
{"created":"2023-03-09","title":"Performance Characterization of using Quantization for DNN Inference on Edge Devices: Extended Version","abstract":"Quantization is a popular technique used in Deep Neural Networks (DNN) inference to reduce the size of models and improve the overall numerical performance by exploiting native hardware. This paper attempts to conduct an elaborate performance characterization of the benefits of using quantization techniques -- mainly FP16/INT8 variants with static and dynamic schemes -- using the MLPerf Edge Inference benchmarking methodology. The study is conducted on Intel x86 processors and Raspberry Pi device with ARM processor. The paper uses a number of DNN inference frameworks, including OpenVINO (for Intel CPUs only), TensorFlow Lite (TFLite), ONNX, and PyTorch with MobileNetV2, VGG-19, and DenseNet-121. The single-stream, multi-stream, and offline scenarios of the MLPerf Edge Inference benchmarks are used for measuring latency and throughput in our experiments. Our evaluation reveals that OpenVINO and TFLite are the most optimized frameworks for Intel CPUs and Raspberry Pi device, respectively. We observe no loss in accuracy except for the static quantization techniques. We also observed the benefits of using quantization for these optimized frameworks. For example, INT8-based quantized models deliver $3.3\\times$ and $4\\times$ better performance over FP32 using OpenVINO on Intel CPU and TFLite on Raspberry Pi device, respectively, for the MLPerf offline scenario. To the best of our knowledge, this paper is the first one that presents a unique characterization study characterizing the impact of quantization for a range of DNN inference frameworks -- including OpenVINO, TFLite, PyTorch, and ONNX -- on Intel x86 processors and Raspberry Pi device with ARM processor using the MLPerf Edge Inference benchmark methodology.","sentences":["Quantization is a popular technique used in Deep Neural Networks (DNN) inference to reduce the size of models and improve the overall numerical performance by exploiting native hardware.","This paper attempts to conduct an elaborate performance characterization of the benefits of using quantization techniques -- mainly FP16/INT8 variants with static and dynamic schemes -- using the MLPerf Edge Inference benchmarking methodology.","The study is conducted on Intel x86 processors and Raspberry Pi device with ARM processor.","The paper uses a number of DNN inference frameworks, including OpenVINO (for Intel CPUs only), TensorFlow Lite (TFLite), ONNX, and PyTorch with MobileNetV2, VGG-19, and DenseNet-121.","The single-stream, multi-stream, and offline scenarios of the MLPerf Edge Inference benchmarks are used for measuring latency and throughput in our experiments.","Our evaluation reveals that OpenVINO and TFLite are the most optimized frameworks for Intel CPUs and Raspberry Pi device, respectively.","We observe no loss in accuracy except for the static quantization techniques.","We also observed the benefits of using quantization for these optimized frameworks.","For example, INT8-based quantized models deliver $3.3\\times$ and $4\\times$ better performance over FP32 using OpenVINO on Intel CPU and TFLite on Raspberry Pi device, respectively, for the MLPerf offline scenario.","To the best of our knowledge, this paper is the first one that presents a unique characterization study characterizing the impact of quantization for a range of DNN inference frameworks -- including OpenVINO, TFLite, PyTorch, and ONNX -- on Intel x86 processors and Raspberry Pi device with ARM processor using the MLPerf Edge Inference benchmark methodology."],"url":"http://arxiv.org/abs/2303.05016v1"}
{"created":"2023-03-09","title":"Machine learning tools to improve nonlinear modeling parameters of RC columns","abstract":"Modeling parameters are essential to the fidelity of nonlinear models of concrete structures subjected to earthquake ground motions, especially when simulating seismic events strong enough to cause collapse. This paper addresses two of the most significant barriers to improving nonlinear modeling provisions in seismic evaluation standards using experimental data sets: identifying the most likely mode of failure of structural components, and implementing data fitting techniques capable of recognizing interdependencies between input parameters and nonlinear relationships between input parameters and model outputs. Machine learning tools in the Scikit-learn and Pytorch libraries were used to calibrate equations and black-box numerical models for nonlinear modeling parameters (MP) a and b of reinforced concrete columns defined in the ASCE 41 and ACI 369.1 standards, and to estimate their most likely mode of failure. It was found that machine learning regression models and machine learning black-boxes were more accurate than current provisions in the ACI 369.1/ASCE 41 Standards. Among the regression models, Regularized Linear Regression was the most accurate for estimating MP a, and Polynomial Regression was the most accurate for estimating MP b. The two black-box models evaluated, namely the Gaussian Process Regression and the Neural Network (NN), provided the most accurate estimates of MPs a and b. The NN model was the most accurate machine learning tool of all evaluated. A multi-class classification tool from the Scikit-learn machine learning library correctly identified column mode of failure with 79% accuracy for rectangular columns and with 81% accuracy for circular columns, a substantial improvement over the classification rules in ASCE 41-13.","sentences":["Modeling parameters are essential to the fidelity of nonlinear models of concrete structures subjected to earthquake ground motions, especially when simulating seismic events strong enough to cause collapse.","This paper addresses two of the most significant barriers to improving nonlinear modeling provisions in seismic evaluation standards using experimental data sets: identifying the most likely mode of failure of structural components, and implementing data fitting techniques capable of recognizing interdependencies between input parameters and nonlinear relationships between input parameters and model outputs.","Machine learning tools in the Scikit-learn and Pytorch libraries were used to calibrate equations and black-box numerical models for nonlinear modeling parameters (MP) a and b of reinforced concrete columns defined in the ASCE 41 and ACI 369.1 standards, and to estimate their most likely mode of failure.","It was found that machine learning regression models and machine learning black-boxes were more accurate than current provisions in the ACI 369.1/ASCE 41 Standards.","Among the regression models, Regularized Linear Regression was the most accurate for estimating MP a, and Polynomial Regression was the most accurate for estimating MP b.","The two black-box models evaluated, namely the Gaussian Process Regression and the Neural Network (NN), provided the most accurate estimates of MPs a and b.","The NN model was the most accurate machine learning tool of all evaluated.","A multi-class classification tool from the Scikit-learn machine learning library correctly identified column mode of failure with 79% accuracy for rectangular columns and with 81% accuracy for circular columns, a substantial improvement over the classification rules in ASCE 41-13."],"url":"http://arxiv.org/abs/2303.16140v1"}
{"created":"2023-03-08","title":"Communicating human intent to a robotic companion by multi-type gesture sentences","abstract":"Human-Robot collaboration in home and industrial workspaces is on the rise. However, the communication between robots and humans is a bottleneck. Although people use a combination of different types of gestures to complement speech, only a few robotic systems utilize gestures for communication. In this paper, we propose a gesture pseudo-language and show how multiple types of gestures can be combined to express human intent to a robot (i.e., expressing both the desired action and its parameters - e.g., pointing to an object and showing that the object should be emptied into a bowl). The demonstrated gestures and the perceived table-top scene (object poses detected by CosyPose) are processed in real-time) to extract the human's intent. We utilize behavior trees to generate reactive robot behavior that handles various possible states of the world (e.g., a drawer has to be opened before an object is placed into it) and recovers from errors (e.g., when the scene changes). Furthermore, our system enables switching between direct teleoperation of the end-effector and high-level operation using the proposed gesture sentences. The system is evaluated on increasingly complex tasks using a real 7-DoF Franka Emika Panda manipulator. Controlling the robot via action gestures lowered the execution time by up to 60%, compared to direct teleoperation.","sentences":["Human-Robot collaboration in home and industrial workspaces is on the rise.","However, the communication between robots and humans is a bottleneck.","Although people use a combination of different types of gestures to complement speech, only a few robotic systems utilize gestures for communication.","In this paper, we propose a gesture pseudo-language and show how multiple types of gestures can be combined to express human intent to a robot (i.e., expressing both the desired action and its parameters - e.g., pointing to an object and showing that the object should be emptied into a bowl).","The demonstrated gestures and the perceived table-top scene (object poses detected by CosyPose) are processed in real-time) to extract the human's intent.","We utilize behavior trees to generate reactive robot behavior that handles various possible states of the world (e.g., a drawer has to be opened before an object is placed into it) and recovers from errors (e.g., when the scene changes).","Furthermore, our system enables switching between direct teleoperation of the end-effector and high-level operation using the proposed gesture sentences.","The system is evaluated on increasingly complex tasks using a real 7-DoF Franka Emika Panda manipulator.","Controlling the robot via action gestures lowered the execution time by up to 60%, compared to direct teleoperation."],"url":"http://arxiv.org/abs/2303.04451v1"}
{"created":"2023-03-06","title":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","abstract":"Prompt tuning, in which a base pretrained model is adapted to each task via conditioning on learned prompt vectors, has emerged as a promising approach for efficiently adapting large language models to multiple downstream tasks. However, existing methods typically learn soft prompt vectors from scratch, and it has not been clear how to exploit the rich cross-task knowledge with prompt vectors in a multitask learning setting. We propose multitask prompt tuning (MPT), which first learns a single transferable prompt by distilling knowledge from multiple task-specific source prompts. We then learn multiplicative low rank updates to this shared prompt to efficiently adapt it to each downstream target task. Extensive experiments on 23 NLP datasets demonstrate that our proposed approach outperforms the state-of-the-art methods, including the full finetuning baseline in some cases, despite only tuning 0.035% as many task-specific parameters.","sentences":["Prompt tuning, in which a base pretrained model is adapted to each task via conditioning on learned prompt vectors, has emerged as a promising approach for efficiently adapting large language models to multiple downstream tasks.","However, existing methods typically learn soft prompt vectors from scratch, and it has not been clear how to exploit the rich cross-task knowledge with prompt vectors in a multitask learning setting.","We propose multitask prompt tuning (MPT), which first learns a single transferable prompt by distilling knowledge from multiple task-specific source prompts.","We then learn multiplicative low rank updates to this shared prompt to efficiently adapt it to each downstream target task.","Extensive experiments on 23 NLP datasets demonstrate that our proposed approach outperforms the state-of-the-art methods, including the full finetuning baseline in some cases, despite only tuning 0.035% as many task-specific parameters."],"url":"http://arxiv.org/abs/2303.02861v1"}
{"created":"2023-03-03","title":"The Awkward World of Python and C++","abstract":"There are undeniable benefits of binding Python and C++ to take advantage of the best features of both languages. This is especially relevant to the HEP and other scientific communities that have invested heavily in the C++ frameworks and are rapidly moving their data analyses to Python. Version 2 of Awkward Array, a Scikit-HEP Python library, introduces a set of header-only C++ libraries that do not depend on any application binary interface. Users can directly include these libraries in their compilation rather than linking against platform-specific libraries. This new development makes the integration of Awkward Arrays into other projects easier and more portable as the implementation is easily separable from the rest of the Awkward Array codebase. The code is minimal, it does not include all of the code needed to use Awkward Arrays in Python, nor does it include references to Python or pybind11. The C++ users can use it to make arrays and then copy them to Python without any specialized data types - only raw buffers, strings, and integers. This C++ code also simplifies the process of just-in-time (JIT) compilation in ROOT. This implementation approach solves some of the drawbacks, like packaging projects where native dependencies can be challenging. In this paper, we demonstrate the technique to integrate C++ and Python by using a header-only approach. We also describe the implementation of a new LayoutBuilder and a GrowableBuffer. Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing Awkward Arrays to C++ without copying them are discussed.","sentences":["There are undeniable benefits of binding Python and C++ to take advantage of the best features of both languages.","This is especially relevant to the HEP and other scientific communities that have invested heavily in the C++ frameworks and are rapidly moving their data analyses to Python.","Version 2 of Awkward Array, a Scikit-HEP Python library, introduces a set of header-only C++ libraries that do not depend on any application binary interface.","Users can directly include these libraries in their compilation rather than linking against platform-specific libraries.","This new development makes the integration of Awkward Arrays into other projects easier and more portable as the implementation is easily separable from the rest of the Awkward Array codebase.","The code is minimal, it does not include all of the code needed to use Awkward Arrays in Python, nor does it include references to Python or pybind11.","The C++ users can use it to make arrays and then copy them to Python without any specialized data types - only raw buffers, strings, and integers.","This C++ code also simplifies the process of just-in-time (JIT) compilation in ROOT.","This implementation approach solves some of the drawbacks, like packaging projects where native dependencies can be challenging.","In this paper, we demonstrate the technique to integrate C++ and Python by using a header-only approach.","We also describe the implementation of a new LayoutBuilder and a GrowableBuffer.","Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing Awkward Arrays to C++ without copying them are discussed."],"url":"http://arxiv.org/abs/2303.02205v1"}
{"created":"2023-03-02","title":"The PAndAS View of the Andromeda Satellite System. IV Global properties","abstract":"We build a statistical framework to infer the global properties of the satellite system of the Andromeda galaxy (M31) from the properties of individual dwarf galaxies located in the Pan-Andromeda Archaelogical Survey (PAndAS) and the previously determined completeness of the survey. Using forward modeling, we infer the slope of the luminosity function of the satellite system, the slope of its spatial density distribution, and the size-luminosity relation followed by the dwarf galaxies. We find that the slope of the luminosity function is $\\beta=-1.5\\pm0.1$. Combined with the spatial density profile, it implies that, when accounting for survey incompleteness, M31 hosts $92_{-26}^{+19}$ dwarf galaxies with $M_\\textrm{V}<-5.5$ and a sky-projected distance from M31 between 30 and 300kpc. We conclude that many faint or distant dwarf galaxies remain to be discovered around Andromeda, especially outside the PAndAS footprint. Finally, we use our model to test if the higher number of satellites situated in the hemisphere facing the Milky Way could be explained simply by the detection limits of dwarf galaxy searches. We rule this out at $>99.9\\%$ confidence and conclude that this anisotropy is an intrinsic feature of the M31 satellite system. The statistical framework we present here is a powerful tool to robustly constrain the properties of a satellite system and compare those across hosts, especially considering the upcoming start of the Euclid or Rubin large photometric surveys that are expected to uncover a large number of dwarf galaxies in the Local Volume.","sentences":["We build a statistical framework to infer the global properties of the satellite system of the Andromeda galaxy (M31) from the properties of individual dwarf galaxies located in the Pan-Andromeda Archaelogical Survey (PAndAS) and the previously determined completeness of the survey.","Using forward modeling, we infer the slope of the luminosity function of the satellite system, the slope of its spatial density distribution, and the size-luminosity relation followed by the dwarf galaxies.","We find that the slope of the luminosity function is $\\beta=-1.5\\pm0.1$. Combined with the spatial density profile, it implies that, when accounting for survey incompleteness, M31 hosts $92_{-26}^{+19}$ dwarf galaxies with $M_\\textrm{V}<-5.5$ and a sky-projected distance from M31 between 30 and 300kpc.","We conclude that many faint or distant dwarf galaxies remain to be discovered around Andromeda, especially outside the PAndAS footprint.","Finally, we use our model to test if the higher number of satellites situated in the hemisphere facing the Milky Way could be explained simply by the detection limits of dwarf galaxy searches.","We rule this out at $>99.9\\%$ confidence and conclude that this anisotropy is an intrinsic feature of the M31 satellite system.","The statistical framework we present here is a powerful tool to robustly constrain the properties of a satellite system and compare those across hosts, especially considering the upcoming start of the Euclid or Rubin large photometric surveys that are expected to uncover a large number of dwarf galaxies in the Local Volume."],"url":"http://arxiv.org/abs/2303.01528v1"}
{"created":"2023-03-02","title":"Learning to Grow Pretrained Models for Efficient Transformer Training","abstract":"Scaling transformers has led to significant breakthroughs in many domains, leading to a paradigm in which larger versions of existing models are trained and released on a periodic basis. New instances of such models are typically trained completely from scratch, despite the fact that they are often just scaled-up versions of their smaller counterparts. How can we use the implicit knowledge in the parameters of smaller, extant models to enable faster training of newer, larger models? This paper describes an approach for accelerating transformer training by learning to grow pretrained transformers, where we learn to linearly map the parameters of the smaller model to initialize the larger model. For tractable learning, we factorize the linear transformation as a composition of (linear) width- and depth-growth operators, and further employ a Kronecker factorization of these growth operators to encode architectural knowledge. Extensive experiments across both language and vision transformers demonstrate that our learned Linear Growth Operator (LiGO) can save up to 50% computational cost of training from scratch, while also consistently outperforming strong baselines that also reuse smaller pretrained models to initialize larger models.","sentences":["Scaling transformers has led to significant breakthroughs in many domains, leading to a paradigm in which larger versions of existing models are trained and released on a periodic basis.","New instances of such models are typically trained completely from scratch, despite the fact that they are often just scaled-up versions of their smaller counterparts.","How can we use the implicit knowledge in the parameters of smaller, extant models to enable faster training of newer, larger models?","This paper describes an approach for accelerating transformer training by learning to grow pretrained transformers, where we learn to linearly map the parameters of the smaller model to initialize the larger model.","For tractable learning, we factorize the linear transformation as a composition of (linear) width-","and depth-growth operators, and further employ a Kronecker factorization of these growth operators to encode architectural knowledge.","Extensive experiments across both language and vision transformers demonstrate that our learned Linear Growth Operator (LiGO) can save up to 50% computational cost of training from scratch, while also consistently outperforming strong baselines that also reuse smaller pretrained models to initialize larger models."],"url":"http://arxiv.org/abs/2303.00980v1"}
{"created":"2023-03-01","title":"Raychaudhuri equation in $k$-essence geometry: conditional singular and non-singular cosmological models","abstract":"We investigate how the Raychaudhuri equation behaves in the $k$-essence geometry. As far as we are concerned, both the early and current epochs of the universe are relevant to the $k$-essence theory. Here, we have studied the $k$-essence geometry using the Dirac-Born-Infeld (DBI) variety of non-standard action. The corresponding $k$-essence emergent spacetime is not conformally equivalent to the usual gravitational metric. We assume that the background gravitational metric is of the Friedmann-Lemaitre-Robertson-Walker (FLRW) type in this case. We have found that both the conditional singular and non-singular cosmological models of the universe through the modified Raychaudhuri equation are possible where we have used the spacetime as the flat $k$-essence emergent FLRW-type. We have also addressed to the Focusing theorem and conditional caustic universe construction. These conditional effects are caused by the additional interactions that arise as a result of the coupling that exists between the gravity and the $k$-essence scalar field.","sentences":["We investigate how the Raychaudhuri equation behaves in the $k$-essence geometry.","As far as we are concerned, both the early and current epochs of the universe are relevant to the $k$-essence theory.","Here, we have studied the $k$-essence geometry using the Dirac-Born-Infeld (DBI) variety of non-standard action.","The corresponding $k$-essence emergent spacetime is not conformally equivalent to the usual gravitational metric.","We assume that the background gravitational metric is of the Friedmann-Lemaitre-Robertson-Walker (FLRW) type in this case.","We have found that both the conditional singular and non-singular cosmological models of the universe through the modified Raychaudhuri equation are possible where we have used the spacetime as the flat $k$-essence emergent FLRW-type.","We have also addressed to the Focusing theorem and conditional caustic universe construction.","These conditional effects are caused by the additional interactions that arise as a result of the coupling that exists between the gravity and the $k$-essence scalar field."],"url":"http://arxiv.org/abs/2303.03118v1"}
{"created":"2023-02-28","title":"Learning Sparse Control Tasks from Pixels by Latent Nearest-Neighbor-Guided Explorations","abstract":"Recent progress in deep reinforcement learning (RL) and computer vision enables artificial agents to solve complex tasks, including locomotion, manipulation and video games from high-dimensional pixel observations. However, domain specific reward functions are often engineered to provide sufficient learning signals, requiring expert knowledge. While it is possible to train vision-based RL agents using only sparse rewards, additional challenges in exploration arise. We present a novel and efficient method to solve sparse-reward robot manipulation tasks from only image observations by utilizing a few demonstrations. First, we learn an embedded neural dynamics model from demonstration transitions and further fine-tune it with the replay buffer. Next, we reward the agents for staying close to the demonstrated trajectories using a distance metric defined in the embedding space. Finally, we use an off-policy, model-free vision RL algorithm to update the control policies. Our method achieves state-of-the-art sample efficiency in simulation and enables efficient training of a real Franka Emika Panda manipulator.","sentences":["Recent progress in deep reinforcement learning (RL) and computer vision enables artificial agents to solve complex tasks, including locomotion, manipulation and video games from high-dimensional pixel observations.","However, domain specific reward functions are often engineered to provide sufficient learning signals, requiring expert knowledge.","While it is possible to train vision-based RL agents using only sparse rewards, additional challenges in exploration arise.","We present a novel and efficient method to solve sparse-reward robot manipulation tasks from only image observations by utilizing a few demonstrations.","First, we learn an embedded neural dynamics model from demonstration transitions and further fine-tune it with the replay buffer.","Next, we reward the agents for staying close to the demonstrated trajectories using a distance metric defined in the embedding space.","Finally, we use an off-policy, model-free vision RL algorithm to update the control policies.","Our method achieves state-of-the-art sample efficiency in simulation and enables efficient training of a real Franka Emika Panda manipulator."],"url":"http://arxiv.org/abs/2302.14242v1"}
{"created":"2023-02-27","title":"Diversity matters: Robustness of bias measurements in Wikidata","abstract":"With the widespread use of knowledge graphs (KG) in various automated AI systems and applications, it is very important to ensure that information retrieval algorithms leveraging them are free from societal biases. Previous works have depicted biases that persist in KGs, as well as employed several metrics for measuring the biases. However, such studies lack the systematic exploration of the sensitivity of the bias measurements, through varying sources of data, or the embedding algorithms used. To address this research gap, in this work, we present a holistic analysis of bias measurement on the knowledge graph. First, we attempt to reveal data biases that surface in Wikidata for thirteen different demographics selected from seven continents. Next, we attempt to unfold the variance in the detection of biases by two different knowledge graph embedding algorithms - TransE and ComplEx. We conduct our extensive experiments on a large number of occupations sampled from the thirteen demographics with respect to the sensitive attribute, i.e., gender. Our results show that the inherent data bias that persists in KG can be altered by specific algorithm bias as incorporated by KG embedding learning algorithms. Further, we show that the choice of the state-of-the-art KG embedding algorithm has a strong impact on the ranking of biased occupations irrespective of gender. We observe that the similarity of the biased occupations across demographics is minimal which reflects the socio-cultural differences around the globe. We believe that this full-scale audit of the bias measurement pipeline will raise awareness among the community while deriving insights related to design choices of data and algorithms both and refrain from the popular dogma of ``one-size-fits-all''.","sentences":["With the widespread use of knowledge graphs (KG) in various automated AI systems and applications, it is very important to ensure that information retrieval algorithms leveraging them are free from societal biases.","Previous works have depicted biases that persist in KGs, as well as employed several metrics for measuring the biases.","However, such studies lack the systematic exploration of the sensitivity of the bias measurements, through varying sources of data, or the embedding algorithms used.","To address this research gap, in this work, we present a holistic analysis of bias measurement on the knowledge graph.","First, we attempt to reveal data biases that surface in Wikidata for thirteen different demographics selected from seven continents.","Next, we attempt to unfold the variance in the detection of biases by two different knowledge graph embedding algorithms - TransE and ComplEx.","We conduct our extensive experiments on a large number of occupations sampled from the thirteen demographics with respect to the sensitive attribute, i.e., gender.","Our results show that the inherent data bias that persists in KG can be altered by specific algorithm bias as incorporated by KG embedding learning algorithms.","Further, we show that the choice of the state-of-the-art KG embedding algorithm has a strong impact on the ranking of biased occupations irrespective of gender.","We observe that the similarity of the biased occupations across demographics is minimal which reflects the socio-cultural differences around the globe.","We believe that this full-scale audit of the bias measurement pipeline will raise awareness among the community while deriving insights related to design choices of data and algorithms both and refrain from the popular dogma of ``one-size-fits-all''."],"url":"http://arxiv.org/abs/2302.14027v1"}
{"created":"2023-02-27","title":"Fast Trajectory End-Point Prediction with Event Cameras for Reactive Robot Control","abstract":"Prediction skills can be crucial for the success of tasks where robots have limited time to act or joints actuation power. In such a scenario, a vision system with a fixed, possibly too low, sampling rate could lead to the loss of informative points, slowing down prediction convergence and reducing the accuracy. In this paper, we propose to exploit the low latency, motion-driven sampling, and data compression properties of event cameras to overcome these issues. As a use-case, we use a Panda robotic arm to intercept a ball bouncing on a table. To predict the interception point, we adopt a Stateful LSTM network, a specific LSTM variant without fixed input length, which perfectly suits the event-driven paradigm and the problem at hand, where the length of the trajectory is not defined. We train the network in simulation to speed up the dataset acquisition and then fine-tune the models on real trajectories. Experimental results demonstrate how using a dense spatial sampling (i.e. event cameras) significantly increases the number of intercepted trajectories as compared to a fixed temporal sampling (i.e. frame-based cameras).","sentences":["Prediction skills can be crucial for the success of tasks where robots have limited time to act or joints actuation power.","In such a scenario, a vision system with a fixed, possibly too low, sampling rate could lead to the loss of informative points, slowing down prediction convergence and reducing the accuracy.","In this paper, we propose to exploit the low latency, motion-driven sampling, and data compression properties of event cameras to overcome these issues.","As a use-case, we use a Panda robotic arm to intercept a ball bouncing on a table.","To predict the interception point, we adopt a Stateful LSTM network, a specific LSTM variant without fixed input length, which perfectly suits the event-driven paradigm and the problem at hand, where the length of the trajectory is not defined.","We train the network in simulation to speed up the dataset acquisition and then fine-tune the models on real trajectories.","Experimental results demonstrate how using a dense spatial sampling (i.e. event cameras) significantly increases the number of intercepted trajectories as compared to a fixed temporal sampling (i.e. frame-based cameras)."],"url":"http://arxiv.org/abs/2302.13796v1"}
{"created":"2023-02-26","title":"Verifiable Manufacturing Using Blockchain","abstract":"We propose a blockchain-based solution for enabling verifiability of manufacturing processes. We base our solution on the methodology of verifiable computing which, originally developed for cloud computing, enables clients to outsource computations to more powerful servers without the need to trust that the server correctly performed desired computation. Verifiable computing accomplishes this by enabling the client to generate cryptographic objects that the server must use to produce a cryptographic proof that verifies the correctness of results. The black box nature of servers in cloud computing is analogous to that of the manufacturing processes of an upstream manufacturer. In this work, we develop a one-to-one correspondence between physical processes and their digital representations as state sequences which is needed for the implementation of verifiable computing. Because direct application of verifiable computing in this case would be computationally prohibitive, we introduce a blockchain to provide a computationally feasible methodology for verifiable computing applied to physical processes. We implement and show the results of our implementation on a proof of concept, developed on Hyperledger Fabric.","sentences":["We propose a blockchain-based solution for enabling verifiability of manufacturing processes.","We base our solution on the methodology of verifiable computing which, originally developed for cloud computing, enables clients to outsource computations to more powerful servers without the need to trust that the server correctly performed desired computation.","Verifiable computing accomplishes this by enabling the client to generate cryptographic objects that the server must use to produce a cryptographic proof that verifies the correctness of results.","The black box nature of servers in cloud computing is analogous to that of the manufacturing processes of an upstream manufacturer.","In this work, we develop a one-to-one correspondence between physical processes and their digital representations as state sequences which is needed for the implementation of verifiable computing.","Because direct application of verifiable computing in this case would be computationally prohibitive, we introduce a blockchain to provide a computationally feasible methodology for verifiable computing applied to physical processes.","We implement and show the results of our implementation on a proof of concept, developed on Hyperledger Fabric."],"url":"http://arxiv.org/abs/2302.13353v1"}
{"created":"2023-02-25","title":"Absynthe: Abstract Interpretation-Guided Synthesis","abstract":"Synthesis tools have seen significant success in recent times. However, past approaches often require a complete and accurate embedding of the source language in the logic of the underlying solver, an approach difficult for industrial-grade languages. Other approaches couple the semantics of the source language with purpose-built synthesizers, necessarily tying the synthesis engine to a particular language model. In this paper, we propose Absynthe, an alternative approach based on user-defined abstract semantics that aims to be both lightweight and language agnostic, yet effective in guiding the search for programs. A synthesis goal in Absynthe is specified as an abstract specification in a lightweight user-defined abstract domain and concrete test cases. The synthesis engine is parameterized by the abstract semantics and independent of the source language. Absynthe validates candidate programs against test cases using the actual concrete language implementation to ensure correctness. We formalize the synthesis rules for Absynthe and describe how the key ideas are scaled-up in our implementation in Ruby. We evaluated Absynthe on SyGuS strings benchmark and found it competitive with other enumerative search solvers. Moreover, Absynthe's ability to combine abstract domains allows the user to move along a cost spectrum, i.e., expressive domains prune more programs but require more time. Finally, to verify Absynthe can act as a general purpose synthesis tool, we use Absynthe to synthesize Pandas data frame manipulating programs in Python using simple abstractions like types and column labels of a data frame. Absynthe reaches parity with AutoPandas, a deep learning based tool for the same benchmark suite. In summary, our results demonstrate Absynthe is a promising step forward towards a general-purpose approach to synthesis that may broaden the applicability of synthesis to more $\\ldots$","sentences":["Synthesis tools have seen significant success in recent times.","However, past approaches often require a complete and accurate embedding of the source language in the logic of the underlying solver, an approach difficult for industrial-grade languages.","Other approaches couple the semantics of the source language with purpose-built synthesizers, necessarily tying the synthesis engine to a particular language model.","In this paper, we propose Absynthe, an alternative approach based on user-defined abstract semantics that aims to be both lightweight and language agnostic, yet effective in guiding the search for programs.","A synthesis goal in Absynthe is specified as an abstract specification in a lightweight user-defined abstract domain and concrete test cases.","The synthesis engine is parameterized by the abstract semantics and independent of the source language.","Absynthe validates candidate programs against test cases using the actual concrete language implementation to ensure correctness.","We formalize the synthesis rules for Absynthe and describe how the key ideas are scaled-up in our implementation in Ruby.","We evaluated Absynthe on SyGuS strings benchmark and found it competitive with other enumerative search solvers.","Moreover, Absynthe's ability to combine abstract domains allows the user to move along a cost spectrum, i.e., expressive domains prune more programs but require more time.","Finally, to verify Absynthe can act as a general purpose synthesis tool, we use Absynthe to synthesize Pandas data frame manipulating programs in Python using simple abstractions like types and column labels of a data frame.","Absynthe reaches parity with AutoPandas, a deep learning based tool for the same benchmark suite.","In summary, our results demonstrate Absynthe is a promising step forward towards a general-purpose approach to synthesis that may broaden the applicability of synthesis to more $\\ldots$"],"url":"http://arxiv.org/abs/2302.13145v1"}
{"created":"2023-02-25","title":"Production and decay of polarized hyperon-antihyperon pairs","abstract":"Polarized hyperon-antihyperon pairs shed light on various unresolved puzzles in contemporary physics: How the strong interaction confines quarks into hadrons, how accurately the Standard Model describes microcosmos and even why our universe consists of so much more matter than antimatter. Thanks to their weak, parity violating decays, hyperons reveal their spin properties. This can be exploited e.g. the decomposition of the electromagnetic structure of hyperons, precision tests of flavour symmetry and searches for CP violation. At the BESIII experiment at BEPC-II, Beijing, China, hyperon-antihyperon pairs can be produced in abundance. Recently collected large data samples have triggered the development of new methods that provide unprecedented precision and a plethora of new results have emerged. When applied at future high-intensity facilities like PANDA and STCF, precision physics will be taken to a new level which can contribute to the solution to the aforementioned puzzles.","sentences":["Polarized hyperon-antihyperon pairs shed light on various unresolved puzzles in contemporary physics: How the strong interaction confines quarks into hadrons, how accurately the Standard Model describes microcosmos and even why our universe consists of so much more matter than antimatter.","Thanks to their weak, parity violating decays, hyperons reveal their spin properties.","This can be exploited e.g. the decomposition of the electromagnetic structure of hyperons, precision tests of flavour symmetry and searches for CP violation.","At the BESIII experiment at BEPC-II, Beijing, China, hyperon-antihyperon pairs can be produced in abundance.","Recently collected large data samples have triggered the development of new methods that provide unprecedented precision and a plethora of new results have emerged.","When applied at future high-intensity facilities like PANDA and STCF, precision physics will be taken to a new level which can contribute to the solution to the aforementioned puzzles."],"url":"http://arxiv.org/abs/2302.13071v1"}
{"created":"2023-02-21","title":"Experimental studies of superconducting gap structure and quantum fluctuations in novel superconductors and heavy fermion compounds","abstract":"Since its discovery more than a century ago, superconductivity has been at the epicentre of condensed matter physics research. The electron phonon coupling in conventional superconductors, which obeys BCS theory, causes an attractive interaction, resulting in a unique isotropic and fixed sign pairing symmetry ground state. Exotic pairing symmetries are hard to come by in this favourable interaction. While unconventional superconductivity is still a mystery, the potential for novel and exotic coupling symmetries due to the interplay of structural symmetries and Fermi surface (FS) topology makes it a fascinating research issue. In this thesis, we have investigated the magnetic, transport, and microscopic properties of the conventional superconductors HfIrSi, ZrIrSi, and novel superconductors ThCoC$_{2}$, CeIr$_{3}$, primarily through the use of a variety of complementary experimental techniques such as low temperature resistivity, magnetization, heat capacity, and muon spin rotation and relaxation measurements.","sentences":["Since its discovery more than a century ago, superconductivity has been at the epicentre of condensed matter physics research.","The electron phonon coupling in conventional superconductors, which obeys BCS theory, causes an attractive interaction, resulting in a unique isotropic and fixed sign pairing symmetry ground state.","Exotic pairing symmetries are hard to come by in this favourable interaction.","While unconventional superconductivity is still a mystery, the potential for novel and exotic coupling symmetries due to the interplay of structural symmetries and Fermi surface (FS) topology makes it a fascinating research issue.","In this thesis, we have investigated the magnetic, transport, and microscopic properties of the conventional superconductors HfIrSi, ZrIrSi, and novel superconductors ThCoC$_{2}$, CeIr$_{3}$, primarily through the use of a variety of complementary experimental techniques such as low temperature resistivity, magnetization, heat capacity, and muon spin rotation and relaxation measurements."],"url":"http://arxiv.org/abs/2302.10710v1"}
{"created":"2023-02-16","title":"PandA(Box) flies on Bluesky: maintainable and user-friendly fly scans with Mamba at HEPS","abstract":"At the High Energy Photon Source (HEPS), the upper-level control system for PandABox has been ported to Bluesky, enabling the combination of both components' flexibility in fly-scan applications. In less than 600 lines of easily customisable and extensible backend code, provided are full control of PandABox's TCP server in native ophyd, automated configuration (also including wiring) of \"PandA blocks\" for constant-speed mapping experiments of various dimensions, as well as generation of scans deliberately fragmented to deal with hardware limits in numbers of exposure frames or sequencer table entries. Based on this backend, a user-friendly Mamba frontend is developed for X-ray fluorescence (XRF) mapping experiments, which provides fully online visual feedback.","sentences":["At the High Energy Photon Source (HEPS), the upper-level control system for PandABox has been ported to Bluesky, enabling the combination of both components' flexibility in fly-scan applications.","In less than 600 lines of easily customisable and extensible backend code, provided are full control of PandABox's TCP server in native ophyd, automated configuration (also including wiring) of \"PandA blocks\" for constant-speed mapping experiments of various dimensions, as well as generation of scans deliberately fragmented to deal with hardware limits in numbers of exposure frames or sequencer table entries.","Based on this backend, a user-friendly Mamba frontend is developed for X-ray fluorescence (XRF) mapping experiments, which provides fully online visual feedback."],"url":"http://arxiv.org/abs/2302.08304v1"}
{"created":"2023-02-15","title":"XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars","abstract":"Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hardware-efficiency. Our experiments on crossbars with benchmark datasets (SVHN, CIFAR10 & CIFAR100) show upto ~8-16% improvement in the adversarial robustness of the searched Subnets against a baseline ResNet-18 model subjected to crossbar-aware adversarial training. We benchmark our robust Subnets for Energy-Delay-Area-Products (EDAPs) using the Neurosim tool and find that with additional hardware-efficiency driven optimizations, the Subnets attain ~1.5-1.6x lower EDAPs than ResNet-18 baseline.","sentences":["Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies.","However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs.","Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment.","Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge.","This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms.","We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hardware-efficiency.","Our experiments on crossbars with benchmark datasets (SVHN, CIFAR10 & CIFAR100) show upto ~8-16% improvement in the adversarial robustness of the searched Subnets against a baseline ResNet-18 model subjected to crossbar-aware adversarial training.","We benchmark our robust Subnets for Energy-Delay-Area-Products (EDAPs) using the Neurosim tool and find that with additional hardware-efficiency driven optimizations, the Subnets attain ~1.5-1.6x lower EDAPs than ResNet-18 baseline."],"url":"http://arxiv.org/abs/2302.07769v1"}
{"created":"2023-02-14","title":"Energy Transformer","abstract":"Transformers have become the de facto models of choice in machine learning, typically leading to impressive performance on many applications. At the same time, the architectural development in the transformer world is mostly driven by empirical findings, and the theoretical understanding of their architectural building blocks is rather limited. In contrast, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, but have not yet demonstrated truly impressive practical results. We propose a transformer architecture that replaces the sequence of feedforward transformer blocks with a single large Associative Memory model. Our novel architecture, called Energy Transformer (or ET for short), has many of the familiar architectural primitives that are often used in the current generation of transformers. However, it is not identical to the existing architectures. The sequence of transformer layers in ET is purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens. As a consequence of this computational principle, the attention in ET is different from the conventional attention mechanism. In this work, we introduce the theoretical foundations of ET, explore it's empirical capabilities using the image completion task, and obtain strong quantitative results on the graph anomaly detection task.","sentences":["Transformers have become the de facto models of choice in machine learning, typically leading to impressive performance on many applications.","At the same time, the architectural development in the transformer world is mostly driven by empirical findings, and the theoretical understanding of their architectural building blocks is rather limited.","In contrast, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, but have not yet demonstrated truly impressive practical results.","We propose a transformer architecture that replaces the sequence of feedforward transformer blocks with a single large Associative Memory model.","Our novel architecture, called Energy Transformer (or ET for short), has many of the familiar architectural primitives that are often used in the current generation of transformers.","However, it is not identical to the existing architectures.","The sequence of transformer layers in ET is purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens.","As a consequence of this computational principle, the attention in ET is different from the conventional attention mechanism.","In this work, we introduce the theoretical foundations of ET, explore it's empirical capabilities using the image completion task, and obtain strong quantitative results on the graph anomaly detection task."],"url":"http://arxiv.org/abs/2302.07253v1"}
{"created":"2023-02-14","title":"Enhancing Machine Learning Model Performance with Hyper Parameter Optimization: A Comparative Study","abstract":"One of the most critical issues in machine learning is the selection of appropriate hyper parameters for training models. Machine learning models may be able to reach the best training performance and may increase the ability to generalize using hyper parameter optimization (HPO) techniques. HPO is a popular topic that artificial intelligence studies have focused on recently and has attracted increasing interest. While the traditional methods developed for HPO include exhaustive search, grid search, random search, and Bayesian optimization; meta-heuristic algorithms are also employed as more advanced methods. Meta-heuristic algorithms search for the solution space where the solutions converge to the best combination to solve a specific problem. These algorithms test various scenarios and evaluate the results to select the best-performing combinations. In this study, classical methods, such as grid, random search and Bayesian optimization, and population-based algorithms, such as genetic algorithms and particle swarm optimization, are discussed in terms of the HPO. The use of related search algorithms is explained together with Python programming codes developed on packages such as Scikit-learn, Sklearn Genetic, and Optuna. The performance of the search algorithms is compared on a sample data set, and according to the results, the particle swarm optimization algorithm has outperformed the other algorithms.","sentences":["One of the most critical issues in machine learning is the selection of appropriate hyper parameters for training models.","Machine learning models may be able to reach the best training performance and may increase the ability to generalize using hyper parameter optimization (HPO) techniques.","HPO is a popular topic that artificial intelligence studies have focused on recently and has attracted increasing interest.","While the traditional methods developed for HPO include exhaustive search, grid search, random search, and Bayesian optimization; meta-heuristic algorithms are also employed as more advanced methods.","Meta-heuristic algorithms search for the solution space where the solutions converge to the best combination to solve a specific problem.","These algorithms test various scenarios and evaluate the results to select the best-performing combinations.","In this study, classical methods, such as grid, random search and Bayesian optimization, and population-based algorithms, such as genetic algorithms and particle swarm optimization, are discussed in terms of the HPO.","The use of related search algorithms is explained together with Python programming codes developed on packages such as Scikit-learn, Sklearn Genetic, and Optuna.","The performance of the search algorithms is compared on a sample data set, and according to the results, the particle swarm optimization algorithm has outperformed the other algorithms."],"url":"http://arxiv.org/abs/2302.11406v1"}
{"created":"2023-02-13","title":"Workload-Balanced Pruning for Sparse Spiking Neural Networks","abstract":"Pruning for Spiking Neural Networks (SNNs) has emerged as a fundamental methodology for deploying deep SNNs on resource-constrained edge devices. Though the existing pruning methods can provide extremely high weight sparsity for deep SNNs, the high weight sparsity brings a workload imbalance problem. Specifically, the workload imbalance happens when a different number of non-zero weights are assigned to hardware units running in parallel, which results in low hardware utilization and thus imposes longer latency and higher energy costs. In preliminary experiments, we show that sparse SNNs ($\\sim$98% weight sparsity) can suffer as low as $\\sim$59% utilization. To alleviate the workload imbalance problem, we propose u-Ticket, where we monitor and adjust the weight connections of the SNN during Lottery Ticket Hypothesis (LTH) based pruning, thus guaranteeing the final ticket gets optimal utilization when deployed onto the hardware. Experiments indicate that our u-Ticket can guarantee up to 100% hardware utilization, thus reducing up to 76.9% latency and 63.8% energy cost compared to the non-utilization-aware LTH method.","sentences":["Pruning for Spiking Neural Networks (SNNs) has emerged as a fundamental methodology for deploying deep SNNs on resource-constrained edge devices.","Though the existing pruning methods can provide extremely high weight sparsity for deep SNNs, the high weight sparsity brings a workload imbalance problem.","Specifically, the workload imbalance happens when a different number of non-zero weights are assigned to hardware units running in parallel, which results in low hardware utilization and thus imposes longer latency and higher energy costs.","In preliminary experiments, we show that sparse SNNs ($\\sim$98% weight sparsity) can suffer as low as $\\sim$59% utilization.","To alleviate the workload imbalance problem, we propose u-Ticket, where we monitor and adjust the weight connections of the SNN during Lottery Ticket Hypothesis (LTH) based pruning, thus guaranteeing the final ticket gets optimal utilization when deployed onto the hardware.","Experiments indicate that our u-Ticket can guarantee up to 100% hardware utilization, thus reducing up to 76.9% latency and 63.8% energy cost compared to the non-utilization-aware LTH method."],"url":"http://arxiv.org/abs/2302.06746v1"}
{"created":"2023-02-11","title":"No-go for PBH formation in EFT of single field inflation","abstract":"Using the Effective Field Theory (EFT) framework of single field inflation, we investigate the possibility of the formation of Primordial Black Holes (PBHs) in the Slow Roll (SR) to Ultra Slow Roll (USR) transition. We demonstrate that, due to one loop correction to the power spectrum, causality is violated ($c_s>1$) for the mass range of PBHs, $M_{\\rm PBH}>10^{2}{\\rm gm}$ created during the said transition. We find that non-canonical features with $c_s<1$ worsen the predictions of canonical framework of single field inflation.","sentences":["Using the Effective Field Theory (EFT) framework of single field inflation, we investigate the possibility of the formation of Primordial Black Holes (PBHs) in the Slow Roll (SR) to Ultra Slow Roll (USR) transition.","We demonstrate that, due to one loop correction to the power spectrum, causality is violated ($c_s>1$) for the mass range of PBHs, $M_{\\rm PBH}>10^{2}{\\rm gm}$ created during the said transition.","We find that non-canonical features with $c_s<1$ worsen the predictions of canonical framework of single field inflation."],"url":"http://arxiv.org/abs/2302.05655v2"}
{"created":"2023-02-09","title":"DeepCAM: A Fully CAM-based Inference Accelerator with Variable Hash Lengths for Energy-efficient Deep Neural Networks","abstract":"With ever increasing depth and width in deep neural networks to achieve state-of-the-art performance, deep learning computation has significantly grown, and dot-products remain dominant in overall computation time. Most prior works are built on conventional dot-product where weighted input summation is used to represent the neuron operation. However, another implementation of dot-product based on the notion of angles and magnitudes in the Euclidean space has attracted limited attention. This paper proposes DeepCAM, an inference accelerator built on two critical innovations to alleviate the computation time bottleneck of convolutional neural networks. The first innovation is an approximate dot-product built on computations in the Euclidean space that can replace addition and multiplication with simple bit-wise operations. The second innovation is a dynamic size content addressable memory-based (CAM-based) accelerator to perform bit-wise operations and accelerate the CNNs with a lower computation time. Our experiments on benchmark image recognition datasets demonstrate that DeepCAM is up to 523x and 3498x faster than Eyeriss and traditional CPUs like Intel Skylake, respectively. Furthermore, the energy consumed by our DeepCAM approach is 2.16x to 109x less compared to Eyeriss.","sentences":["With ever increasing depth and width in deep neural networks to achieve state-of-the-art performance, deep learning computation has significantly grown, and dot-products remain dominant in overall computation time.","Most prior works are built on conventional dot-product where weighted input summation is used to represent the neuron operation.","However, another implementation of dot-product based on the notion of angles and magnitudes in the Euclidean space has attracted limited attention.","This paper proposes DeepCAM, an inference accelerator built on two critical innovations to alleviate the computation time bottleneck of convolutional neural networks.","The first innovation is an approximate dot-product built on computations in the Euclidean space that can replace addition and multiplication with simple bit-wise operations.","The second innovation is a dynamic size content addressable memory-based (CAM-based) accelerator to perform bit-wise operations and accelerate the CNNs with a lower computation time.","Our experiments on benchmark image recognition datasets demonstrate that DeepCAM is up to 523x and 3498x faster than Eyeriss and traditional CPUs like Intel Skylake, respectively.","Furthermore, the energy consumed by our DeepCAM approach is 2.16x to 109x less compared to Eyeriss."],"url":"http://arxiv.org/abs/2302.04712v1"}
{"created":"2023-02-08","title":"Federated Minimax Optimization with Client Heterogeneity","abstract":"Minimax optimization has seen a surge in interest with the advent of modern applications such as GANs, and it is inherently more challenging than simple minimization. The difficulty is exacerbated by the training data residing at multiple edge devices or \\textit{clients}, especially when these clients can have heterogeneous datasets and local computation capabilities. We propose a general federated minimax optimization framework that subsumes such settings and several existing methods like Local SGDA. We show that naive aggregation of heterogeneous local progress results in optimizing a mismatched objective function -- a phenomenon previously observed in standard federated minimization. To fix this problem, we propose normalizing the client updates by the number of local steps undertaken between successive communication rounds. We analyze the convergence of the proposed algorithm for classes of nonconvex-concave and nonconvex-nonconcave functions and characterize the impact of heterogeneous client data, partial client participation, and heterogeneous local computations. Our analysis works under more general assumptions on the intra-client noise and inter-client heterogeneity than so far considered in the literature. For all the function classes considered, we significantly improve the existing computation and communication complexity results. Experimental results support our theoretical claims.","sentences":["Minimax optimization has seen a surge in interest with the advent of modern applications such as GANs, and it is inherently more challenging than simple minimization.","The difficulty is exacerbated by the training data residing at multiple edge devices or \\textit{clients}, especially when these clients can have heterogeneous datasets and local computation capabilities.","We propose a general federated minimax optimization framework that subsumes such settings and several existing methods like Local SGDA.","We show that naive aggregation of heterogeneous local progress results in optimizing a mismatched objective function -- a phenomenon previously observed in standard federated minimization.","To fix this problem, we propose normalizing the client updates by the number of local steps undertaken between successive communication rounds.","We analyze the convergence of the proposed algorithm for classes of nonconvex-concave and nonconvex-nonconcave functions and characterize the impact of heterogeneous client data, partial client participation, and heterogeneous local computations.","Our analysis works under more general assumptions on the intra-client noise and inter-client heterogeneity than so far considered in the literature.","For all the function classes considered, we significantly improve the existing computation and communication complexity results.","Experimental results support our theoretical claims."],"url":"http://arxiv.org/abs/2302.04249v2"}
{"created":"2023-02-08","title":"A Model for Forecasting Air Quality Index in Port Harcourt Nigeria Using Bi-LSTM Algorithm","abstract":"The release of toxic gases by industries, emissions from vehicles, and an increase in the concentration of harmful gases and particulate matter in the atmosphere are all contributing factors to the deterioration of the quality of the air. Factors such as industries, urbanization, population growth, and the increased use of vehicles contribute to the rapid increase in pollution levels, which can adversely impact human health. This paper presents a model for forecasting the air quality index in Nigeria using the Bi-directional LSTM model. The air pollution data was downloaded from an online database (UCL). The dataset was pre-processed using both pandas tools in python. The pre-processed result was used as input features in training a Bi-LSTM model in making future forecasts of the values of the particulate matter Pm2.5, and Pm10. The Bi-LSTM model was evaluated using some evaluation parameters such as mean square error, mean absolute error, absolute mean square, and R^2 square. The result of the Bi-LSTM shows a mean square error of 52.99%, relative mean square error of 7.28%, mean absolute error of 3.4%, and R^2 square of 97%. The model. This shows that the model follows a seamless trend in forecasting the air quality in Port Harcourt, Nigeria.","sentences":["The release of toxic gases by industries, emissions from vehicles, and an increase in the concentration of harmful gases and particulate matter in the atmosphere are all contributing factors to the deterioration of the quality of the air.","Factors such as industries, urbanization, population growth, and the increased use of vehicles contribute to the rapid increase in pollution levels, which can adversely impact human health.","This paper presents a model for forecasting the air quality index in Nigeria using the Bi-directional LSTM model.","The air pollution data was downloaded from an online database (UCL).","The dataset was pre-processed using both pandas tools in python.","The pre-processed result was used as input features in training a Bi-LSTM model in making future forecasts of the values of the particulate matter Pm2.5, and Pm10.","The Bi-LSTM model was evaluated using some evaluation parameters such as mean square error, mean absolute error, absolute mean square, and R^2 square.","The result of the Bi-LSTM shows a mean square error of 52.99%, relative mean square error of 7.28%, mean absolute error of 3.4%, and R^2 square of 97%.","The model.","This shows that the model follows a seamless trend in forecasting the air quality in Port Harcourt, Nigeria."],"url":"http://arxiv.org/abs/2302.03930v1"}
{"created":"2023-02-07","title":"WaveTrain: A Python Package for Numerical Quantum Mechanics of Chain-Like Systems Based on Tensor Trains","abstract":"WaveTrain is an open-source software for numerical simulations of chain-like quantum systems with nearest-neighbor (NN) interactions only. The Python package is centered around tensor train (TT, or matrix product) format representations of Hamiltonian operators and (stationary or time-evolving) state vectors. It builds on the Python tensor train toolbox Scikit-tt, which provides efficient construction methods and storage schemes for the TT format. Its solvers for eigenvalue problems and linear differential equations are used in WaveTrain for the time-independent and time-dependent Schroedinger equations, respectively. Employing efficient decompositions to construct low-rank representations, the tensor-train ranks of state vectors are often found to depend only marginally on the chain length N. This results in the computational effort growing only slightly more than linearly with N, thus mitigating the curse of dimensionality. As a complement to the classes for full quantum mechanics, WaveTrain also contains classes for fully classical and mixed quantum-classical (Ehrenfest or mean field) dynamics of bipartite systems. The graphical capabilities allow visualization of quantum dynamics on the fly, with a choice of several different representations based on reduced density matrices. Even though developed for treating quasi one-dimensional excitonic energy transport in molecular solids or conjugated organic polymers, including coupling to phonons, WaveTrain can be used for any kind of chain-like quantum systems, with or without periodic boundary conditions, and with NN interactions only.","sentences":["WaveTrain is an open-source software for numerical simulations of chain-like quantum systems with nearest-neighbor (NN) interactions only.","The Python package is centered around tensor train (TT, or matrix product) format representations of Hamiltonian operators and (stationary or time-evolving) state vectors.","It builds on the Python tensor train toolbox Scikit-tt, which provides efficient construction methods and storage schemes for the TT format.","Its solvers for eigenvalue problems and linear differential equations are used in WaveTrain for the time-independent and time-dependent Schroedinger equations, respectively.","Employing efficient decompositions to construct low-rank representations, the tensor-train ranks of state vectors are often found to depend only marginally on the chain length N.","This results in the computational effort growing only slightly more than linearly with N, thus mitigating the curse of dimensionality.","As a complement to the classes for full quantum mechanics, WaveTrain also contains classes for fully classical and mixed quantum-classical (Ehrenfest or mean field) dynamics of bipartite systems.","The graphical capabilities allow visualization of quantum dynamics on the fly, with a choice of several different representations based on reduced density matrices.","Even though developed for treating quasi one-dimensional excitonic energy transport in molecular solids or conjugated organic polymers, including coupling to phonons, WaveTrain can be used for any kind of chain-like quantum systems, with or without periodic boundary conditions, and with NN interactions only."],"url":"http://arxiv.org/abs/2302.03725v2"}
{"created":"2023-02-07","title":"Open data from the third observing run of LIGO, Virgo, KAGRA and GEO","abstract":"The global network of gravitational-wave observatories now includes five detectors, namely LIGO Hanford, LIGO Livingston, Virgo, KAGRA, and GEO 600. These detectors collected data during their third observing run, O3, composed of three phases: O3a starting in April of 2019 and lasting six months, O3b starting in November of 2019 and lasting five months, and O3GK starting in April of 2020 and lasting 2 weeks. In this paper we describe these data and various other science products that can be freely accessed through the Gravitational Wave Open Science Center at https://gwosc.org. The main dataset, consisting of the gravitational-wave strain time series that contains the astrophysical signals, is released together with supporting data useful for their analysis and documentation, tutorials, as well as analysis software packages.","sentences":["The global network of gravitational-wave observatories now includes five detectors, namely LIGO Hanford, LIGO Livingston, Virgo, KAGRA, and GEO 600.","These detectors collected data during their third observing run, O3, composed of three phases: O3a starting in April of 2019 and lasting six months, O3b starting in November of 2019 and lasting five months, and O3GK starting in April of 2020 and lasting 2 weeks.","In this paper we describe these data and various other science products that can be freely accessed through the Gravitational Wave Open Science Center at https://gwosc.org.","The main dataset, consisting of the gravitational-wave strain time series that contains the astrophysical signals, is released together with supporting data useful for their analysis and documentation, tutorials, as well as analysis software packages."],"url":"http://arxiv.org/abs/2302.03676v1"}
{"created":"2023-02-07","title":"Design of an Energy-Aware Cartesian Impedance Controller for Collaborative Disassembly","abstract":"Human-robot collaborative disassembly is an emerging trend in the sustainable recycling process of electronic and mechanical products. It requires the use of advanced technologies to assist workers in repetitive physical tasks and deal with creaky and potentially damaged components. Nevertheless, when disassembling worn-out or damaged components, unexpected robot behaviors may emerge, so harmless and symbiotic physical interaction with humans and the environment becomes paramount. This work addresses this challenge at the control level by ensuring safe and passive behaviors in unplanned interactions and contact losses. The proposed algorithm capitalizes on an energy-aware Cartesian impedance controller, which features energy scaling and damping injection, and an augmented energy tank, which limits the power flow from the controller to the robot. The controller is evaluated in a real-world flawed unscrewing task with a Franka Emika Panda and is compared to a standard impedance controller and a hybrid force-impedance controller. The results demonstrate the high potential of the algorithm in human-robot collaborative disassembly tasks.","sentences":["Human-robot collaborative disassembly is an emerging trend in the sustainable recycling process of electronic and mechanical products.","It requires the use of advanced technologies to assist workers in repetitive physical tasks and deal with creaky and potentially damaged components.","Nevertheless, when disassembling worn-out or damaged components, unexpected robot behaviors may emerge, so harmless and symbiotic physical interaction with humans and the environment becomes paramount.","This work addresses this challenge at the control level by ensuring safe and passive behaviors in unplanned interactions and contact losses.","The proposed algorithm capitalizes on an energy-aware Cartesian impedance controller, which features energy scaling and damping injection, and an augmented energy tank, which limits the power flow from the controller to the robot.","The controller is evaluated in a real-world flawed unscrewing task with a Franka Emika Panda and is compared to a standard impedance controller and a hybrid force-impedance controller.","The results demonstrate the high potential of the algorithm in human-robot collaborative disassembly tasks."],"url":"http://arxiv.org/abs/2302.03587v2"}
{"created":"2023-02-04","title":"The nonleptonic decays of $b$-flavored mesons to $S$-wave charmonium and charm meson states","abstract":"The detection of radially excited heavy meson \\\\states in recent years and measurement of heavy meson decays, particularly $B_c^+\\to J/\\psi D_s^+$ and $B_c^+\\to J/\\psi D_s^{*+}$, by the LHCb and ATLAS Collaborations, have aroused a lot of theoretical interest in the nonleptonic decays of $b$-flavored mesons. In this paper, we study the exclusive two-body nonleptonic $\\bar{B}^0$, $\\bar{B_s^0}$, $B^-$ and $B_c^-$-meson decays to two vector meson ($V_1(nS)V_2$) states. Assuming the factorization hypothesis, we calculate the weak-decay form factors from the overlapping integrals of meson wave functions, in the framework of the relativistic independent quark (RIQ) model. We find a few dominant decay modes: $B^-\\to D^{*0}\\rho^-$, $\\bar{B^0}\\to D^{*+}\\rho^-$, $\\bar{B_s^0}\\to D_s^{*+}\\rho^-$, $B^-\\to J/\\psi K^{*-}$ and $B_c^-\\to J/\\psi D_s^{*-}$ with predicted branching fractions of 1.54, 1.42, 1.17, 0.53 and 0.52 (in $\\%$), which are experimentally accessible. The predicted branching fractions for corresponding decay modes to excited ($2S$) states, obtained in the order ${\\cal O }(10^{-3}-10^{-4})$ lie within the detection accuracy of the current experiments at LHCb and Tevatron. The sizeable $CP$-odd fractions predicted for $B_c^-$-meson decay to two charmful states: $D^{*0}D^{*-}_{(s)}$ and $\\bar{D}^{*0}D^{*-}_{(s)}$ indicate significant $CP$-violation hinting at the so-called new physics beyond the standard model.","sentences":["The detection of radially excited heavy meson \\\\states in recent years and measurement of heavy meson decays, particularly $B_c^+\\to J/\\psi D_s^+$ and $B_c^+\\to J/\\psi D_s^{*+}$, by the LHCb and ATLAS Collaborations, have aroused a lot of theoretical interest in the nonleptonic decays of $b$-flavored mesons.","In this paper, we study the exclusive two-body nonleptonic $\\bar{B}^0$, $\\bar{B_s^0}$, $B^-$ and $B_c^-$-meson decays to two vector meson ($V_1(nS)V_2$) states.","Assuming the factorization hypothesis, we calculate the weak-decay form factors from the overlapping integrals of meson wave functions, in the framework of the relativistic independent quark (RIQ) model.","We find a few dominant decay modes: $B^-\\to D^{*0}\\rho^-$, $\\bar{B^0}\\to D^{*+}\\rho^-$, $\\bar{B_s^0}\\to D_s^{*+}\\rho^-$, $B^-\\to J/\\psi K^{*-}$ and $B_c^-\\to J/\\psi D_s^{*-}$ with predicted branching fractions of 1.54, 1.42, 1.17, 0.53 and 0.52 (in $\\%$), which are experimentally accessible.","The predicted branching fractions for corresponding decay modes to excited ($2S$) states, obtained in the order ${\\cal O }(10^{-3}-10^{-4})$ lie within the detection accuracy of the current experiments at LHCb and Tevatron.","The sizeable $CP$-odd fractions predicted for $B_c^-$-meson decay to two charmful states: $D^{*0}D^{*-}_{(s)}$ and $\\bar{D}^{*0}D^{*-}_{(s)}$ indicate significant $CP$-violation hinting at the so-called new physics beyond the standard model."],"url":"http://arxiv.org/abs/2302.02142v2"}
{"created":"2023-01-31","title":"Patch Gradient Descent: Training Neural Networks on Very Large Images","abstract":"Traditional CNN models are trained and tested on relatively low resolution images (<300 px), and cannot be directly operated on large-scale images due to compute and memory constraints. We propose Patch Gradient Descent (PatchGD), an effective learning strategy that allows to train the existing CNN architectures on large-scale images in an end-to-end manner. PatchGD is based on the hypothesis that instead of performing gradient-based updates on an entire image at once, it should be possible to achieve a good solution by performing model updates on only small parts of the image at a time, ensuring that the majority of it is covered over the course of iterations. PatchGD thus extensively enjoys better memory and compute efficiency when training models on large scale images. PatchGD is thoroughly evaluated on two datasets - PANDA and UltraMNIST with ResNet50 and MobileNetV2 models under different memory constraints. Our evaluation clearly shows that PatchGD is much more stable and efficient than the standard gradient-descent method in handling large images, and especially when the compute memory is limited.","sentences":["Traditional CNN models are trained and tested on relatively low resolution images (<300 px), and cannot be directly operated on large-scale images due to compute and memory constraints.","We propose Patch Gradient Descent (PatchGD), an effective learning strategy that allows to train the existing CNN architectures on large-scale images in an end-to-end manner.","PatchGD is based on the hypothesis that instead of performing gradient-based updates on an entire image at once, it should be possible to achieve a good solution by performing model updates on only small parts of the image at a time, ensuring that the majority of it is covered over the course of iterations.","PatchGD","thus extensively enjoys better memory and compute efficiency when training models on large scale images.","PatchGD is thoroughly evaluated on two datasets - PANDA and UltraMNIST with ResNet50 and MobileNetV2 models under different memory constraints.","Our evaluation clearly shows that PatchGD is much more stable and efficient than the standard gradient-descent method in handling large images, and especially when the compute memory is limited."],"url":"http://arxiv.org/abs/2301.13817v1"}
{"created":"2023-01-31","title":"CMLCompiler: A Unified Compiler for Classical Machine Learning","abstract":"Classical machine learning (CML) occupies nearly half of machine learning pipelines in production applications. Unfortunately, it fails to utilize the state-of-the-practice devices fully and performs poorly. Without a unified framework, the hybrid deployments of deep learning (DL) and CML also suffer from severe performance and portability issues. This paper presents the design of a unified compiler, called CMLCompiler, for CML inference. We propose two unified abstractions: operator representations and extended computational graphs. The CMLCompiler framework performs the conversion and graph optimization based on two unified abstractions, then outputs an optimized computational graph to DL compilers or frameworks. We implement CMLCompiler on TVM. The evaluation shows CMLCompiler's portability and superior performance. It achieves up to 4.38x speedup on CPU, 3.31x speedup on GPU, and 5.09x speedup on IoT devices, compared to the state-of-the-art solutions -- scikit-learn, intel sklearn, and hummingbird. Our performance of CML and DL mixed pipelines achieves up to 3.04x speedup compared with cross-framework implementations.","sentences":["Classical machine learning (CML) occupies nearly half of machine learning pipelines in production applications.","Unfortunately, it fails to utilize the state-of-the-practice devices fully and performs poorly.","Without a unified framework, the hybrid deployments of deep learning (DL) and CML also suffer from severe performance and portability issues.","This paper presents the design of a unified compiler, called CMLCompiler, for CML inference.","We propose two unified abstractions: operator representations and extended computational graphs.","The CMLCompiler framework performs the conversion and graph optimization based on two unified abstractions, then outputs an optimized computational graph to DL compilers or frameworks.","We implement CMLCompiler on TVM.","The evaluation shows CMLCompiler's portability and superior performance.","It achieves up to 4.38x speedup on CPU, 3.31x speedup on GPU, and 5.09x speedup on IoT devices, compared to the state-of-the-art solutions -- scikit-learn, intel sklearn, and hummingbird.","Our performance of CML and DL mixed pipelines achieves up to 3.04x speedup compared with cross-framework implementations."],"url":"http://arxiv.org/abs/2301.13441v2"}
{"created":"2023-01-30","title":"Probing Gravity for one Minute with an Optical-Lattice Atom Interferometer","abstract":"We have realized an atom interferometer that probes gravitational potentials by holding, rather than dropping, atoms. Up to one minute of coherence times are realized by suspending the spatially separated atomic wave packets in an optical lattice that is mode-filtered by an optical cavity. This trapped configuration suppresses phase variance due to vibrations by four to five orders of magnitude, overcoming the dominant noise source in atom-interferometric gravimeters. Recent progress in characterizing and reducing interferometer decoherence led to major increases in coherence and precision, paving the way to measurements of dark-energy candidates and probes of the quantum nature of gravity through measuring the gravity of source masses with record precision and spatial resolution.","sentences":["We have realized an atom interferometer that probes gravitational potentials by holding, rather than dropping, atoms.","Up to one minute of coherence times are realized by suspending the spatially separated atomic wave packets in an optical lattice that is mode-filtered by an optical cavity.","This trapped configuration suppresses phase variance due to vibrations by four to five orders of magnitude, overcoming the dominant noise source in atom-interferometric gravimeters.","Recent progress in characterizing and reducing interferometer decoherence led to major increases in coherence and precision, paving the way to measurements of dark-energy candidates and probes of the quantum nature of gravity through measuring the gravity of source masses with record precision and spatial resolution."],"url":"http://arxiv.org/abs/2301.13315v1"}
{"created":"2023-01-30","title":"Investigation of Ultrafast Demagnetization and Gilbert Damping and their Correlation in Different Ferromagnetic Thin Films Grown Under Identical Conditions","abstract":"Following the demonstration of laser-induced ultrafast demagnetization in ferromagnetic nickel, several theoretical and phenomenological propositions have sought to uncover its underlying physics. In this work we revisit the three temperature model (3TM) and the microscopic three temperature model (M3TM) to perform a comparative analysis of ultrafast demagnetization in 20-nm-thick cobalt, nickel and permalloy thin films measured using an all-optical pump-probe technique. In addition to the ultrafast dynamics at the femtosecond timescales, the nanosecond magnetization precession and damping are recorded at various pump excitation fluences revealing a fluence-dependent enhancement in both the demagnetization times and the damping factors. We confirm that the Curie temperature to magnetic moment ratio of a given system acts as a figure of merit for the demagnetization time, while the demagnetization times and damping factors show an apparent sensitivity to the density of states at the Fermi level for a given system. Further, from numerical simulations of the ultrafast demagnetization based on both the 3TM and the M3TM, we extract the reservoir coupling parameters that best reproduce the experimental data and estimate the value of the spin flip scattering probability for each system. We discuss how the fluence-dependence of inter-reservoir coupling parameters so extracted may reflect a role played by nonthermal electrons in the magnetization dynamics at low laser fluences.","sentences":["Following the demonstration of laser-induced ultrafast demagnetization in ferromagnetic nickel, several theoretical and phenomenological propositions have sought to uncover its underlying physics.","In this work we revisit the three temperature model (3TM) and the microscopic three temperature model (M3TM) to perform a comparative analysis of ultrafast demagnetization in 20-nm-thick cobalt, nickel and permalloy thin films measured using an all-optical pump-probe technique.","In addition to the ultrafast dynamics at the femtosecond timescales, the nanosecond magnetization precession and damping are recorded at various pump excitation fluences revealing a fluence-dependent enhancement in both the demagnetization times and the damping factors.","We confirm that the Curie temperature to magnetic moment ratio of a given system acts as a figure of merit for the demagnetization time, while the demagnetization times and damping factors show an apparent sensitivity to the density of states at the Fermi level for a given system.","Further, from numerical simulations of the ultrafast demagnetization based on both the 3TM and the M3TM, we extract the reservoir coupling parameters that best reproduce the experimental data and estimate the value of the spin flip scattering probability for each system.","We discuss how the fluence-dependence of inter-reservoir coupling parameters so extracted may reflect a role played by nonthermal electrons in the magnetization dynamics at low laser fluences."],"url":"http://arxiv.org/abs/2301.12797v1"}
{"created":"2023-01-30","title":"Dynamics of a buffer-gas-loaded, deep optical trap for molecules","abstract":"We describe an approach to optically trapping small, closed-shell molecules at cryogenic temperatures by buffer-gas loading a deep optical dipole trap. The ~10 K trap depth will be produced by a tightly-focused, 1064-nm cavity capable of reaching intensities of hundreds of GW/cm$^2$. Molecules will be directly buffer-gas loaded into the trap using a helium buffer gas at 1.5 K. The very far-off-resonant, quasi-electrostatic trapping mechanism is insensitive to a molecule's internal state, energy level structure, and its electric and magnetic dipole moment. Here, we theoretically investigate the trapping and loading dynamics, as well as the heating and loss rates, and conclude that $10^4$-$10^6$ molecules are likely to be trapped. Our trap would open new possibilities in molecular spectroscopy, studies of cold chemical reactions, and precision measurement, amongst other fields of physics.","sentences":["We describe an approach to optically trapping small, closed-shell molecules at cryogenic temperatures by buffer-gas loading a deep optical dipole trap.","The ~10 K trap depth will be produced by a tightly-focused, 1064-nm cavity capable of reaching intensities of hundreds of GW/cm$^2$. Molecules will be directly buffer-gas loaded into the trap using a helium buffer gas at 1.5 K.","The very far-off-resonant, quasi-electrostatic trapping mechanism is insensitive to a molecule's internal state, energy level structure, and its electric and magnetic dipole moment.","Here, we theoretically investigate the trapping and loading dynamics, as well as the heating and loss rates, and conclude that $10^4$-$10^6$ molecules are likely to be trapped.","Our trap would open new possibilities in molecular spectroscopy, studies of cold chemical reactions, and precision measurement, amongst other fields of physics."],"url":"http://arxiv.org/abs/2301.12620v1"}
{"created":"2023-01-24","title":"Reconstructing charged-particle trajectories in the PANDA Straw Tube Tracker using the LOcal Track Finder (LOTF) algorithm","abstract":"We present the LOcal Track Finder (LOTF) algorithm, a method that performs charged-particle trajectory reconstruction using the Straw Tube Tracker, one of the central trackers of the antiProton ANnihilation at DArmstadt (PANDA) detector. The algorithm builds upon the neighboring relations of the tubes to connect individual hits and form track candidates. In addition, it uses a local fitting procedure to handle regions where several tracks overlap and utilizes a system of virtual nodes to reconstruct the z-information of the particle trajectories. We generated 30,000 events to assess the performance of our approach and compared our results to two other track reconstruction methods. LOTF has (1) an average of 85\\% of found tracks, (2) the largest number of Fully Pure tracks, (3) the lowest amount of incorrect reconstructions, and (4) is significantly faster than the other two approaches. Further, we tested our method using 3,750 data sets composed of 4 events each, showing that our approach handles cases in which events are mixed. The raw (without parallelization) average reconstruction rate is about 68,000 hits/s, which makes the present algorithm promising for online data selection and processing.","sentences":["We present the LOcal Track Finder (LOTF) algorithm, a method that performs charged-particle trajectory reconstruction using the Straw Tube Tracker, one of the central trackers of the antiProton ANnihilation at DArmstadt (PANDA) detector.","The algorithm builds upon the neighboring relations of the tubes to connect individual hits and form track candidates.","In addition, it uses a local fitting procedure to handle regions where several tracks overlap and utilizes a system of virtual nodes to reconstruct the z-information of the particle trajectories.","We generated 30,000 events to assess the performance of our approach and compared our results to two other track reconstruction methods.","LOTF has (1) an average of 85\\% of found tracks, (2) the largest number of Fully Pure tracks, (3) the lowest amount of incorrect reconstructions, and (4) is significantly faster than the other two approaches.","Further, we tested our method using 3,750 data sets composed of 4 events each, showing that our approach handles cases in which events are mixed.","The raw (without parallelization) average reconstruction rate is about 68,000 hits/s, which makes the present algorithm promising for online data selection and processing."],"url":"http://arxiv.org/abs/2301.10055v1"}
{"created":"2023-01-24","title":"Effects of both diffuse and collimated incident radiation on phototactic bioconvection","abstract":"The linear stability of a finite-depth algal suspension is investigated numerically with particular emphasis on the effects of angle of incidence. The suspension of phototactic algae is uniformly illuminated by both diffuse and oblique collimated irradiation. The bioconvective solutions show a transition of the most unstable mode of disturbance from the stationary (overstable) to overstable (stationary) state at the variation in angle of incidence for fixed parameter ranges. Furthermore, a transition from mode 2 to mode 1 instability is noticed for some parameter values as the angle of incidence varies. Oscillatory modes of disturbance are also predicted at the increment in angle of incidence (or cell swimming speed)","sentences":["The linear stability of a finite-depth algal suspension is investigated numerically with particular emphasis on the effects of angle of incidence.","The suspension of phototactic algae is uniformly illuminated by both diffuse and oblique collimated irradiation.","The bioconvective solutions show a transition of the most unstable mode of disturbance from the stationary (overstable) to overstable (stationary) state at the variation in angle of incidence for fixed parameter ranges.","Furthermore, a transition from mode 2 to mode 1 instability is noticed for some parameter values as the angle of incidence varies.","Oscillatory modes of disturbance are also predicted at the increment in angle of incidence (or cell swimming speed)"],"url":"http://arxiv.org/abs/2301.09864v1"}
{"created":"2023-01-21","title":"Expectations for time-delay measurements in active galactic nuclei with the Vera Rubin Observatory","abstract":"The Vera Rubin Observatory will provide an unprecedented set of time-dependent observations of the sky. The planned Legacy Survey of Space and Time (LSST) operating for 10 years will provide dense lightcurves for thousands of active galactic nuclei (AGN) in Deep Drilling Fields (DDFs) and less dense lightcurves for millions of AGN. We model the prospects for measuring time delays for emission lines with respect to the continuum, using these data. We model the artificial lightcurves using Timmer-Koenig algorithm, we use the exemplary cadence to sample them, we supplement lightcurves with the expected contamination by the strong emission lines (Hbeta, Mg II and CIV as well as with Fe II pseudo-continuum and the starlight). We choose the suitable photometric bands appropriate for the redshift and compare the assumed line time delay with the recovered time delay for 100 statistical realizations of the light curves. We show that time delays for emission lines can be well measured from the Main Survey for the bright tail of the quasar distribution (about 15% of all sources) with the accuracy within 1 sigma error, for DDFs results for fainter quasars are also reliable when all 10 years of data are used. There are also some prospects to measure the time delays for the faintest quasars at the smallest redshifts from the first two years of data, and eventually even from the first season. The entire quasar population will allow obtaining results of apparently high accuracy but in our simulations, we see a systematic offset between the assumed and recovered time delay depending on the redshift and source luminosity which will not disappear even in the case of large statistics. Such a problem might affect the slope of the radius-luminosity relation and cosmological applications of quasars if simulations correcting for such effects are not performed.","sentences":["The Vera Rubin Observatory will provide an unprecedented set of time-dependent observations of the sky.","The planned Legacy Survey of Space and Time (LSST) operating for 10 years will provide dense lightcurves for thousands of active galactic nuclei (AGN) in Deep Drilling Fields (DDFs) and less dense lightcurves for millions of AGN.","We model the prospects for measuring time delays for emission lines with respect to the continuum, using these data.","We model the artificial lightcurves using Timmer-Koenig algorithm, we use the exemplary cadence to sample them, we supplement lightcurves with the expected contamination by the strong emission lines (Hbeta, Mg II and CIV as well as with Fe II pseudo-continuum and the starlight).","We choose the suitable photometric bands appropriate for the redshift and compare the assumed line time delay with the recovered time delay for 100 statistical realizations of the light curves.","We show that time delays for emission lines can be well measured from the Main Survey for the bright tail of the quasar distribution (about 15% of all sources) with the accuracy within 1 sigma error, for DDFs results for fainter quasars are also reliable when all 10 years of data are used.","There are also some prospects to measure the time delays for the faintest quasars at the smallest redshifts from the first two years of data, and eventually even from the first season.","The entire quasar population will allow obtaining results of apparently high accuracy but in our simulations, we see a systematic offset between the assumed and recovered time delay depending on the redshift and source luminosity which will not disappear even in the case of large statistics.","Such a problem might affect the slope of the radius-luminosity relation and cosmological applications of quasars if simulations correcting for such effects are not performed."],"url":"http://arxiv.org/abs/2301.08975v1"}
{"created":"2023-01-11","title":"Recurrent generation of maximally entangled single particle states via quantum walks on cyclic graphs","abstract":"Maximally entangled single particle states (MESPS) are opening new possibilities in quantum technologies as they have the potential to encode more information and are robust to decoherence compared to their non-local two-particle counterparts. Herein, using discrete-time quantum walks on $k$-cycles where $k\\in\\{3,4,5,8\\}$ and by using either a single coin or effective-single coin or two coins in various deterministic sequences, we generate MESPS for recurring time steps. These sequences beget ordered quantum walks and yield MESPS with periods 4, 6, 9, 12, and 15. For the first time, we reveal single coins such as Hadamard, which can generate periodic MESPS (with periods 4 and 12) on $4$ and $8$-cycles. This scheme is resource-saving with possibly the most straightforward experimental realization since the same coin is applied at each time step.","sentences":["Maximally entangled single particle states (MESPS) are opening new possibilities in quantum technologies as they have the potential to encode more information and are robust to decoherence compared to their non-local two-particle counterparts.","Herein, using discrete-time quantum walks on $k$-cycles where $k\\in\\{3,4,5,8\\}$ and by using either a single coin or effective-single coin or two coins in various deterministic sequences, we generate MESPS for recurring time steps.","These sequences beget ordered quantum walks and yield MESPS with periods 4, 6, 9, 12, and 15.","For the first time, we reveal single coins such as Hadamard, which can generate periodic MESPS (with periods 4 and 12) on $4$ and $8$-cycles.","This scheme is resource-saving with possibly the most straightforward experimental realization since the same coin is applied at each time step."],"url":"http://arxiv.org/abs/2301.04501v1"}
{"created":"2023-01-10","title":"Studying Logging Practice in Machine Learning-based Applications","abstract":"Logging is a common practice in traditional software development. Several research works have been done to investigate the different characteristics of logging practices in traditional software systems (e.g., Android applications, JAVA applications, C/C++ applications). Nowadays, we are witnessing more and more development of Machine Learning-based applications (ML-based applications). Today, there are many popular libraries that facilitate and contribute to the development of such applications, among which we can mention: Pytorch, Tensorflow, Theano, MXNet, Scikit-Learn, Caffe, and Keras. Despite the popularity of ML, we don't have a clear understanding of logging practices in ML applications. In this paper, we aim to fill this knowledge gap and help ML practitioners understand the characteristics of logging in ML-based applications. In particular, we conduct an empirical study on 110 open-source ML-based applications. Through a quantitative analysis, we find that logging practice in ML-based applications is less pervasive than in traditional applications including Android, JAVA, and C/C++ applications. Furthermore, the majority of logging statements in ML-based applications are in info and warn levels, compared to traditional applications where info is the majority of logging statement in C/C++ application and debug, error levels constitute the majority of logging statement in Android application. We also perform a quantitative and qualitative analysis of a random sample of logging statements to understand where ML developers put most of logging statements and examine why and how they are using logging. These analyses led to the following observations: (i) ML developers put most of the logging statements in model training, and in non-ML components. (ii) Data and model management appear to be the main reason behind the introduction of logging statements in ML-based applications.","sentences":["Logging is a common practice in traditional software development.","Several research works have been done to investigate the different characteristics of logging practices in traditional software systems (e.g., Android applications, JAVA applications, C/C++ applications).","Nowadays, we are witnessing more and more development of Machine Learning-based applications (ML-based applications).","Today, there are many popular libraries that facilitate and contribute to the development of such applications, among which we can mention: Pytorch, Tensorflow, Theano, MXNet, Scikit-Learn, Caffe, and Keras.","Despite the popularity of ML, we don't have a clear understanding of logging practices in ML applications.","In this paper, we aim to fill this knowledge gap and help ML practitioners understand the characteristics of logging in ML-based applications.","In particular, we conduct an empirical study on 110 open-source ML-based applications.","Through a quantitative analysis, we find that logging practice in ML-based applications is less pervasive than in traditional applications including Android, JAVA, and C/C++ applications.","Furthermore, the majority of logging statements in ML-based applications are in info and warn levels, compared to traditional applications where info is the majority of logging statement in C/C++ application and debug, error levels constitute the majority of logging statement in Android application.","We also perform a quantitative and qualitative analysis of a random sample of logging statements to understand where ML developers put most of logging statements and examine why and how they are using logging.","These analyses led to the following observations: (i) ML developers put most of the logging statements in model training, and in non-ML components.","(ii) Data and model management appear to be the main reason behind the introduction of logging statements in ML-based applications."],"url":"http://arxiv.org/abs/2301.04234v1"}
{"created":"2023-01-06","title":"\"No, to the Right\" -- Online Language Corrections for Robotic Manipulation via Shared Autonomy","abstract":"Systems for language-guided human-robot interaction must satisfy two key desiderata for broad adoption: adaptivity and learning efficiency. Unfortunately, existing instruction-following agents cannot adapt, lacking the ability to incorporate online natural language supervision, and even if they could, require hundreds of demonstrations to learn even simple policies. In this work, we address these problems by presenting Language-Informed Latent Actions with Corrections (LILAC), a framework for incorporating and adapting to natural language corrections - \"to the right,\" or \"no, towards the book\" - online, during execution. We explore rich manipulation domains within a shared autonomy paradigm. Instead of discrete turn-taking between a human and robot, LILAC splits agency between the human and robot: language is an input to a learned model that produces a meaningful, low-dimensional control space that the human can use to guide the robot. Each real-time correction refines the human's control space, enabling precise, extended behaviors - with the added benefit of requiring only a handful of demonstrations to learn. We evaluate our approach via a user study where users work with a Franka Emika Panda manipulator to complete complex manipulation tasks. Compared to existing learned baselines covering both open-loop instruction following and single-turn shared autonomy, we show that our corrections-aware approach obtains higher task completion rates, and is subjectively preferred by users because of its reliability, precision, and ease of use.","sentences":["Systems for language-guided human-robot interaction must satisfy two key desiderata for broad adoption: adaptivity and learning efficiency.","Unfortunately, existing instruction-following agents cannot adapt, lacking the ability to incorporate online natural language supervision, and even if they could, require hundreds of demonstrations to learn even simple policies.","In this work, we address these problems by presenting Language-Informed Latent Actions with Corrections (LILAC), a framework for incorporating and adapting to natural language corrections - \"to the right,\" or \"no, towards the book\" - online, during execution.","We explore rich manipulation domains within a shared autonomy paradigm.","Instead of discrete turn-taking between a human and robot, LILAC splits agency between the human and robot: language is an input to a learned model that produces a meaningful, low-dimensional control space that the human can use to guide the robot.","Each real-time correction refines the human's control space, enabling precise, extended behaviors - with the added benefit of requiring only a handful of demonstrations to learn.","We evaluate our approach via a user study where users work with a Franka Emika Panda manipulator to complete complex manipulation tasks.","Compared to existing learned baselines covering both open-loop instruction following and single-turn shared autonomy, we show that our corrections-aware approach obtains higher task completion rates, and is subjectively preferred by users because of its reliability, precision, and ease of use."],"url":"http://arxiv.org/abs/2301.02555v1"}
{"created":"2023-01-05","title":"TextDescriptives: A Python package for calculating a large variety of metrics from text","abstract":"TextDescriptives is a Python package for calculating a large variety of metrics from text. It is built on top of spaCy and can be easily integrated into existing workflows. The package has already been used for analysing the linguistic stability of clinical texts, creating features for predicting neuropsychiatric conditions, and analysing linguistic goals of primary school students. This paper describes the package and its features.","sentences":["TextDescriptives is a Python package for calculating a large variety of metrics from text.","It is built on top of spaCy and can be easily integrated into existing workflows.","The package has already been used for analysing the linguistic stability of clinical texts, creating features for predicting neuropsychiatric conditions, and analysing linguistic goals of primary school students.","This paper describes the package and its features."],"url":"http://arxiv.org/abs/2301.02057v3"}
{"created":"2023-01-05","title":"A Distance-Geometric Method for Recovering Robot Joint Angles From an RGB Image","abstract":"Autonomous manipulation systems operating in domains where human intervention is difficult or impossible (e.g., underwater, extraterrestrial or hazardous environments) require a high degree of robustness to sensing and communication failures. Crucially, motion planning and control algorithms require a stream of accurate joint angle data provided by joint encoders, the failure of which may result in an unrecoverable loss of functionality. In this paper, we present a novel method for retrieving the joint angles of a robot manipulator using only a single RGB image of its current configuration, opening up an avenue for recovering system functionality when conventional proprioceptive sensing is unavailable. Our approach, based on a distance-geometric representation of the configuration space, exploits the knowledge of a robot's kinematic model with the goal of training a shallow neural network that performs a 2D-to-3D regression of distances associated with detected structural keypoints. It is shown that the resulting Euclidean distance matrix uniquely corresponds to the observed configuration, where joint angles can be recovered via multidimensional scaling and a simple inverse kinematics procedure. We evaluate the performance of our approach on real RGB images of a Franka Emika Panda manipulator, showing that the proposed method is efficient and exhibits solid generalization ability. Furthermore, we show that our method can be easily combined with a dense refinement technique to obtain superior results.","sentences":["Autonomous manipulation systems operating in domains where human intervention is difficult or impossible (e.g., underwater, extraterrestrial or hazardous environments) require a high degree of robustness to sensing and communication failures.","Crucially, motion planning and control algorithms require a stream of accurate joint angle data provided by joint encoders, the failure of which may result in an unrecoverable loss of functionality.","In this paper, we present a novel method for retrieving the joint angles of a robot manipulator using only a single RGB image of its current configuration, opening up an avenue for recovering system functionality when conventional proprioceptive sensing is unavailable.","Our approach, based on a distance-geometric representation of the configuration space, exploits the knowledge of a robot's kinematic model with the goal of training a shallow neural network that performs a 2D-to-3D regression of distances associated with detected structural keypoints.","It is shown that the resulting Euclidean distance matrix uniquely corresponds to the observed configuration, where joint angles can be recovered via multidimensional scaling and a simple inverse kinematics procedure.","We evaluate the performance of our approach on real RGB images of a Franka Emika Panda manipulator, showing that the proposed method is efficient and exhibits solid generalization ability.","Furthermore, we show that our method can be easily combined with a dense refinement technique to obtain superior results."],"url":"http://arxiv.org/abs/2301.02051v1"}
{"created":"2023-01-04","title":"Augmenting data-driven models for energy systems through feature engineering: A Python framework for feature engineering","abstract":"Data-driven modeling is an approach in energy systems modeling that has been gaining popularity. In data-driven modeling, machine learning methods such as linear regression, neural networks or decision-tree based methods are being applied. While these methods do not require domain knowledge, they are sensitive to data quality. Therefore, improving data quality in a dataset is beneficial for creating machine learning-based models. The improvement of data quality can be implemented through preprocessing methods. A selected type of preprocessing is feature engineering, which focuses on evaluating and improving the quality of certain features inside the dataset. Feature engineering methods include methods such as feature creation, feature expansion, or feature selection. In this work, a Python framework containing different feature engineering methods is presented. This framework contains different methods for feature creation, expansion and selection; in addition, methods for transforming or filtering data are implemented. The implementation of the framework is based on the Python library scikit-learn. The framework is demonstrated on a case study of a use case from energy demand prediction. A data-driven model is created including selected feature engineering methods. The results show an improvement in prediction accuracy through the engineered features.","sentences":["Data-driven modeling is an approach in energy systems modeling that has been gaining popularity.","In data-driven modeling, machine learning methods such as linear regression, neural networks or decision-tree based methods are being applied.","While these methods do not require domain knowledge, they are sensitive to data quality.","Therefore, improving data quality in a dataset is beneficial for creating machine learning-based models.","The improvement of data quality can be implemented through preprocessing methods.","A selected type of preprocessing is feature engineering, which focuses on evaluating and improving the quality of certain features inside the dataset.","Feature engineering methods include methods such as feature creation, feature expansion, or feature selection.","In this work, a Python framework containing different feature engineering methods is presented.","This framework contains different methods for feature creation, expansion and selection; in addition, methods for transforming or filtering data are implemented.","The implementation of the framework is based on the Python library scikit-learn.","The framework is demonstrated on a case study of a use case from energy demand prediction.","A data-driven model is created including selected feature engineering methods.","The results show an improvement in prediction accuracy through the engineered features."],"url":"http://arxiv.org/abs/2301.01720v1"}
{"created":"2023-01-02","title":"Investigating the Role of Electric Fields on Flow Harmonics in Heavy-Ion Collisions","abstract":"Using the blast-wave model, we explore the effect of electric fields on spectra and flow harmonics (especially the elliptic flow) for charged pions and protons. We incorporate the first-order correction to the single-particle distribution function due to the electric fields and the dissipative effect while calculating the invariant yields of hadron in the Cooper-Frey prescription at the freezeout hypersurface. We find a noticeable correction to the directed and elliptic flow of pions and protons for unidirectional and azimuthal asymmetric electric fields in the transverse plane of magnitude $\\sim m_{\\pi}^{2}$. Further, we observe mass dependency of the directed flow generated due to the electric fields. The splitting of particle and antiparticle's elliptic flow is also discussed.","sentences":["Using the blast-wave model, we explore the effect of electric fields on spectra and flow harmonics (especially the elliptic flow) for charged pions and protons.","We incorporate the first-order correction to the single-particle distribution function due to the electric fields and the dissipative effect while calculating the invariant yields of hadron in the Cooper-Frey prescription at the freezeout hypersurface.","We find a noticeable correction to the directed and elliptic flow of pions and protons for unidirectional and azimuthal asymmetric electric fields in the transverse plane of magnitude $\\sim m_{\\pi}^{2}$.","Further, we observe mass dependency of the directed flow generated due to the electric fields.","The splitting of particle and antiparticle's elliptic flow is also discussed."],"url":"http://arxiv.org/abs/2301.00632v1"}
{"created":"2023-01-02","title":"Statistical Machine Translation for Indic Languages","abstract":"Machine Translation (MT) system generally aims at automatic representation of source language into target language retaining the originality of context using various Natural Language Processing (NLP) techniques. Among various NLP methods, Statistical Machine Translation(SMT). SMT uses probabilistic and statistical techniques to analyze information and conversion. This paper canvasses about the development of bilingual SMT models for translating English to fifteen low-resource Indian Languages (ILs) and vice versa. At the outset, all 15 languages are briefed with a short description related to our experimental need. Further, a detailed analysis of Samanantar and OPUS dataset for model building, along with standard benchmark dataset (Flores-200) for fine-tuning and testing, is done as a part of our experiment. Different preprocessing approaches are proposed in this paper to handle the noise of the dataset. To create the system, MOSES open-source SMT toolkit is explored. Distance reordering is utilized with the aim to understand the rules of grammar and context-dependent adjustments through a phrase reordering categorization framework. In our experiment, the quality of the translation is evaluated using standard metrics such as BLEU, METEOR, and RIBES","sentences":["Machine Translation (MT) system generally aims at automatic representation of source language into target language retaining the originality of context using various Natural Language Processing (NLP) techniques.","Among various NLP methods, Statistical Machine Translation(SMT).","SMT uses probabilistic and statistical techniques to analyze information and conversion.","This paper canvasses about the development of bilingual SMT models for translating English to fifteen low-resource Indian Languages (ILs) and vice versa.","At the outset, all 15 languages are briefed with a short description related to our experimental need.","Further, a detailed analysis of Samanantar and OPUS dataset for model building, along with standard benchmark dataset (Flores-200) for fine-tuning and testing, is done as a part of our experiment.","Different preprocessing approaches are proposed in this paper to handle the noise of the dataset.","To create the system, MOSES open-source SMT toolkit is explored.","Distance reordering is utilized with the aim to understand the rules of grammar and context-dependent adjustments through a phrase reordering categorization framework.","In our experiment, the quality of the translation is evaluated using standard metrics such as BLEU, METEOR, and RIBES"],"url":"http://arxiv.org/abs/2301.00539v1"}
{"created":"2023-04-06","title":"Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark","abstract":"Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results show that agents can both act competently and morally, so concrete progress can currently be made in machine ethics--designing agents that are Pareto improvements in both safety and capabilities.","sentences":["Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity.","So do agents naturally learn to be Machiavellian?","And how do we measure these behaviors in general-purpose models such as GPT-4?","Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making.","Scenario labeling is automated with LMs, which are more performant than human annotators.","We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations.","We observe some tension between maximizing reward and behaving ethically.","To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors.","Our results show that agents can both act competently and morally, so concrete progress can currently be made in machine ethics--designing agents that are Pareto improvements in both safety and capabilities."],"url":"http://arxiv.org/abs/2304.03279v1"}
{"created":"2023-04-06","title":"DiffMimic: Efficient Motion Mimicking with Differentiable Physics","abstract":"Motion mimicking is a foundational task in physics-based character animation. However, most existing motion mimicking methods are built upon reinforcement learning (RL) and suffer from heavy reward engineering, high variance, and slow convergence with hard explorations. Specifically, they usually take tens of hours or even days of training to mimic a simple motion sequence, resulting in poor scalability. In this work, we leverage differentiable physics simulators (DPS) and propose an efficient motion mimicking method dubbed DiffMimic. Our key insight is that DPS casts a complex policy learning task to a much simpler state matching problem. In particular, DPS learns a stable policy by analytical gradients with ground-truth physical priors hence leading to significantly faster and stabler convergence than RL-based methods. Moreover, to escape from local optima, we utilize a Demonstration Replay mechanism to enable stable gradient backpropagation in a long horizon. Extensive experiments on standard benchmarks show that DiffMimic has a better sample efficiency and time efficiency than existing methods (e.g., DeepMimic). Notably, DiffMimic allows a physically simulated character to learn Backflip after 10 minutes of training and be able to cycle it after 3 hours of training, while the existing approach may require about a day of training to cycle Backflip. More importantly, we hope DiffMimic can benefit more differentiable animation systems with techniques like differentiable clothes simulation in future research.","sentences":["Motion mimicking is a foundational task in physics-based character animation.","However, most existing motion mimicking methods are built upon reinforcement learning (RL) and suffer from heavy reward engineering, high variance, and slow convergence with hard explorations.","Specifically, they usually take tens of hours or even days of training to mimic a simple motion sequence, resulting in poor scalability.","In this work, we leverage differentiable physics simulators (DPS) and propose an efficient motion mimicking method dubbed DiffMimic.","Our key insight is that DPS casts a complex policy learning task to a much simpler state matching problem.","In particular, DPS learns a stable policy by analytical gradients with ground-truth physical priors hence leading to significantly faster and stabler convergence than RL-based methods.","Moreover, to escape from local optima, we utilize a Demonstration Replay mechanism to enable stable gradient backpropagation in a long horizon.","Extensive experiments on standard benchmarks show that DiffMimic has a better sample efficiency and time efficiency than existing methods (e.g., DeepMimic).","Notably, DiffMimic allows a physically simulated character to learn Backflip after 10 minutes of training and be able to cycle it after 3 hours of training, while the existing approach may require about a day of training to cycle Backflip.","More importantly, we hope DiffMimic can benefit more differentiable animation systems with techniques like differentiable clothes simulation in future research."],"url":"http://arxiv.org/abs/2304.03274v1"}
{"created":"2023-04-06","title":"Towards self-driving laboratories in chemistry and materials sciences: The central role of DFT in the era of AI","abstract":"Density functional theory plays a pivotal role for the chemical and materials science due to its relatively high predictive power, applicability, versatility and low computational cost. We review recent progress in machine learning model developments, which has relied heavily on density functional theory for synthetic data generation and model architecture, and provide some broader context for its general relevance to the chemical sciences. Resulting in models with high efficiency, accuracy, scalability, and transferability (EAST), these developments will pave the way for the routine use of successful experimental planning software within self-driving laboratories.","sentences":["Density functional theory plays a pivotal role for the chemical and materials science due to its relatively high predictive power, applicability, versatility and low computational cost.","We review recent progress in machine learning model developments, which has relied heavily on density functional theory for synthetic data generation and model architecture, and provide some broader context for its general relevance to the chemical sciences.","Resulting in models with high efficiency, accuracy, scalability, and transferability (EAST), these developments will pave the way for the routine use of successful experimental planning software within self-driving laboratories."],"url":"http://arxiv.org/abs/2304.03272v1"}
{"created":"2023-04-06","title":"Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models","abstract":"The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny. Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar. For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret. This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures. To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own water footprint. In this paper, we provide a principled methodology to estimate fine-grained water footprint of AI models, and also discuss the unique spatial-temporal diversities of AI models' runtime water efficiency. Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to enable truly sustainable AI.","sentences":["The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny.","Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar.","For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret.","This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures.","To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own water footprint.","In this paper, we provide a principled methodology to estimate fine-grained water footprint of AI models, and also discuss the unique spatial-temporal diversities of AI models' runtime water efficiency.","Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to enable truly sustainable AI."],"url":"http://arxiv.org/abs/2304.03271v1"}
{"created":"2023-04-06","title":"Causal Discovery with Score Matching on Additive Models with Arbitrary Noise","abstract":"Causal discovery methods are intrinsically constrained by the set of assumptions needed to ensure structure identifiability. Moreover additional restrictions are often imposed in order to simplify the inference task: this is the case for the Gaussian noise assumption on additive non-linear models, which is common to many causal discovery approaches. In this paper we show the shortcomings of inference under this hypothesis, analyzing the risk of edge inversion under violation of Gaussianity of the noise terms. Then, we propose a novel method for inferring the topological ordering of the variables in the causal graph, from data generated according to an additive non-linear model with a generic noise distribution. This leads to NoGAM (Not only Gaussian Additive noise Models), a causal discovery algorithm with a minimal set of assumptions and state of the art performance, experimentally benchmarked on synthetic data.","sentences":["Causal discovery methods are intrinsically constrained by the set of assumptions needed to ensure structure identifiability.","Moreover additional restrictions are often imposed in order to simplify the inference task: this is the case for the Gaussian noise assumption on additive non-linear models, which is common to many causal discovery approaches.","In this paper we show the shortcomings of inference under this hypothesis, analyzing the risk of edge inversion under violation of Gaussianity of the noise terms.","Then, we propose a novel method for inferring the topological ordering of the variables in the causal graph, from data generated according to an additive non-linear model with a generic noise distribution.","This leads to NoGAM (Not only Gaussian Additive noise Models), a causal discovery algorithm with a minimal set of assumptions and state of the art performance, experimentally benchmarked on synthetic data."],"url":"http://arxiv.org/abs/2304.03265v1"}
{"created":"2023-04-06","title":"Toward End-to-End MLOps Tools Map: A Preliminary Study based on a Multivocal Literature Review","abstract":"MLOps tools enable continuous development of machine learning, following the DevOps process. Different MLOps tools have been presented on the market, however, such a number of tools often create confusion on the most appropriate tool to be used in each DevOps phase. To overcome this issue, we conducted a multivocal literature review mapping 84 MLOps tools identified from 254 Primary Studies, on the DevOps phases, highlighting their purpose, and possible incompatibilities. The result of this work will be helpful to both practitioners and researchers, as a starting point for future investigations on MLOps tools, pipelines, and processes.","sentences":["MLOps tools enable continuous development of machine learning, following the DevOps process.","Different MLOps tools have been presented on the market, however, such a number of tools often create confusion on the most appropriate tool to be used in each DevOps phase.","To overcome this issue, we conducted a multivocal literature review mapping 84 MLOps tools identified from 254 Primary Studies, on the DevOps phases, highlighting their purpose, and possible incompatibilities.","The result of this work will be helpful to both practitioners and researchers, as a starting point for future investigations on MLOps tools, pipelines, and processes."],"url":"http://arxiv.org/abs/2304.03254v1"}
{"created":"2023-04-06","title":"A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk","abstract":"Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on treatment at eligibility while others are off treatment but may switch to treatment at a specified time - if they survive long enough. We define and identify an average causal effect of switching under specified causal assumptions. Estimation is done using a g-computation framework with a joint semiparametric Bayesian model for the death and recurrent event processes. Computing the estimand for various switching times allows us to assess the impact of treatment timing. We apply the method to contrast hospitalization rates under different opioid treatment strategies among patients with chronic back pain using Medicare claims data.","sentences":["Observational studies of recurrent event rates are common in biomedical statistics.","Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window.","Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility.","Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias.","Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest.","Both processes are also censored so that events are not observed over the entire followup window.","Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on treatment at eligibility while others are off treatment but may switch to treatment at a specified time - if they survive long enough.","We define and identify an average causal effect of switching under specified causal assumptions.","Estimation is done using a g-computation framework with a joint semiparametric Bayesian model for the death and recurrent event processes.","Computing the estimand for various switching times allows us to assess the impact of treatment timing.","We apply the method to contrast hospitalization rates under different opioid treatment strategies among patients with chronic back pain using Medicare claims data."],"url":"http://arxiv.org/abs/2304.03247v1"}
{"created":"2023-04-06","title":"Synthetic Data in Healthcare","abstract":"Synthetic data are becoming a critical tool for building artificially intelligent systems. Simulators provide a way of generating data systematically and at scale. These data can then be used either exclusively, or in conjunction with real data, for training and testing systems. Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck. While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial. Furthermore, these data are highly sensitive and often patient specific. Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists. In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases.","sentences":["Synthetic data are becoming a critical tool for building artificially intelligent systems.","Simulators provide a way of generating data systematically and at scale.","These data can then be used either exclusively, or in conjunction with real data, for training and testing systems.","Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck.","While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial.","Furthermore, these data are highly sensitive and often patient specific.","Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists.","In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine.","We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases."],"url":"http://arxiv.org/abs/2304.03243v1"}
{"created":"2023-04-06","title":"Assessing the Reproducibility of Machine-learning-based Biomarker Discovery in Parkinson's Disease","abstract":"Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease. Thus, GWAS data can be used to identify genetic variations associated with the disease. Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers. However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped. To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies. We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers. Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies. However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers. These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before. These findings open up new potential avenues of investigation.","sentences":["Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease.","Thus, GWAS data can be used to identify genetic variations associated with the disease.","Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers.","However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped.","To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies.","We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers.","Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies.","However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers.","These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before.","These findings open up new potential avenues of investigation."],"url":"http://arxiv.org/abs/2304.03239v1"}
{"created":"2023-04-06","title":"Probing Dark QCD Sector through the Higgs Portal with Machine Learning at the LHC","abstract":"The QCD-like dark sector with GeV-scale dark hadrons has the potential to generate new signatures at the Large Hadron Collider (LHC). In this paper, we consider a singlet scalar mediator in the tens of GeV-scale that connects the dark sector and the Standard Model (SM) sector via the Higgs portal. We focus on the Higgs-strahlung process, $q\\overline{q}'\\rightarrow W^{\\ast}\\rightarrow WH $, to produce a highly boosted Higgs boson. Our scenario predicts two different processes that can generate dark mesons: (1) the cascade decay from the Higgs boson to two light scalar mediators and then to four dark mesons; (2) the Higgs boson decaying to two dark quarks, which then undergo a QCD-like shower and hadronization to produce dark mesons. We apply machine learning techniques, such as Convolutional Neural Network (CNN) and Energy Flow Network (EFN), to the fat jet structure to distinguish these signal processes from large SM backgrounds. We find that the branching ratio of the Higgs boson to two light scalar mediators can be constrained to be less than $10\\%$ at 14 TeV LHC with $\\mathcal{L} = 3000 fb^{-1}$.","sentences":["The QCD-like dark sector with GeV-scale dark hadrons has the potential to generate new signatures at the Large Hadron Collider (LHC).","In this paper, we consider a singlet scalar mediator in the tens of GeV-scale that connects the dark sector and the Standard Model (SM) sector via the Higgs portal.","We focus on the Higgs-strahlung process, $q\\overline{q}'\\rightarrow W^{\\ast}\\rightarrow WH $, to produce a highly boosted Higgs boson.","Our scenario predicts two different processes that can generate dark mesons: (1) the cascade decay from the Higgs boson to two light scalar mediators and then to four dark mesons; (2) the Higgs boson decaying to two dark quarks, which then undergo a QCD-like shower and hadronization to produce dark mesons.","We apply machine learning techniques, such as Convolutional Neural Network (CNN) and Energy Flow Network (EFN), to the fat jet structure to distinguish these signal processes from large SM backgrounds.","We find that the branching ratio of the Higgs boson to two light scalar mediators can be constrained to be less than $10\\%$ at 14 TeV LHC with $\\mathcal{L} = 3000 fb^{-1}$."],"url":"http://arxiv.org/abs/2304.03237v1"}
{"created":"2023-04-06","title":"Mitigating Green's function Monte Carlo signal-to-noise problems using contour deformations","abstract":"The Green's function Monte Carlo (GFMC) method provides accurate solutions to the nuclear many-body problem and predicts properties of light nuclei starting from realistic two- and three-body interactions. Controlling the GFMC fermion-sign problem is crucial, as the signal-to-noise ratio decreases exponentially with Euclidean time, requiring significant computing resources. Inspired by similar scenarios in lattice quantum field theory and spin systems, in this work, we employ integration contour deformations to improve the GFMC signal-to-noise ratio. Machine learning techniques are used to select optimal contours with minimal variance from parameterized families of deformations. As a proof of principle, we consider the deuteron binding energies and Euclidean density response functions. We only observe mild signal-to-noise improvement for the binding energy case. On the other hand, we achieve an order of magnitude reduction of the variance for Euclidean density response functions, paving the way for computing electron- and neutrino-nucleus cross-sections of larger nuclei.","sentences":["The Green's function Monte Carlo (GFMC) method provides accurate solutions to the nuclear many-body problem and predicts properties of light nuclei starting from realistic two-","and three-body interactions.","Controlling the GFMC fermion-sign problem is crucial, as the signal-to-noise ratio decreases exponentially with Euclidean time, requiring significant computing resources.","Inspired by similar scenarios in lattice quantum field theory and spin systems, in this work, we employ integration contour deformations to improve the GFMC signal-to-noise ratio.","Machine learning techniques are used to select optimal contours with minimal variance from parameterized families of deformations.","As a proof of principle, we consider the deuteron binding energies and Euclidean density response functions.","We only observe mild signal-to-noise improvement for the binding energy case.","On the other hand, we achieve an order of magnitude reduction of the variance for Euclidean density response functions, paving the way for computing electron- and neutrino-nucleus cross-sections of larger nuclei."],"url":"http://arxiv.org/abs/2304.03229v1"}
{"created":"2023-04-06","title":"Anomaly Detection via Gumbel Noise Score Matching","abstract":"We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data. GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions. We test our method on a suite of anomaly detection tabular datasets. GNSM achieves a consistently high performance across all experiments. We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions. Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth. We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work.","sentences":["We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data.","GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions.","We test our method on a suite of anomaly detection tabular datasets.","GNSM achieves a consistently high performance across all experiments.","We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions.","Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth.","We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work."],"url":"http://arxiv.org/abs/2304.03220v1"}
{"created":"2023-04-06","title":"Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models","abstract":"To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable. Towards that goal, algorithmic auditing has received substantial attention. To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race). However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences. To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets. Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label). To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples. Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts. Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success. Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models.","sentences":["To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable.","Towards that goal, algorithmic auditing has received substantial attention.","To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race).","However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences.","To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets.","Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label).","To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples.","Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts.","Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success.","Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models."],"url":"http://arxiv.org/abs/2304.03218v1"}
{"created":"2023-04-06","title":"Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching","abstract":"Cross-device user matching is a critical problem in numerous domains, including advertising, recommender systems, and cybersecurity. It involves identifying and linking different devices belonging to the same person, utilizing sequence logs. Previous data mining techniques have struggled to address the long-range dependencies and higher-order connections between the logs. Recently, researchers have modeled this problem as a graph problem and proposed a two-tier graph contextual embedding (TGCE) neural network architecture, which outperforms previous methods. In this paper, we propose a novel hierarchical graph neural network architecture (HGNN), which has a more computationally efficient second level design than TGCE. Furthermore, we introduce a cross-attention (Cross-Att) mechanism in our model, which improves performance by 5% compared to the state-of-the-art TGCE method.","sentences":["Cross-device user matching is a critical problem in numerous domains, including advertising, recommender systems, and cybersecurity.","It involves identifying and linking different devices belonging to the same person, utilizing sequence logs.","Previous data mining techniques have struggled to address the long-range dependencies and higher-order connections between the logs.","Recently, researchers have modeled this problem as a graph problem and proposed a two-tier graph contextual embedding (TGCE) neural network architecture, which outperforms previous methods.","In this paper, we propose a novel hierarchical graph neural network architecture (HGNN), which has a more computationally efficient second level design than TGCE.","Furthermore, we introduce a cross-attention (Cross-Att) mechanism in our model, which improves performance by 5% compared to the state-of-the-art TGCE method."],"url":"http://arxiv.org/abs/2304.03215v1"}
{"created":"2023-04-06","title":"Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts","abstract":"Integrating high-level semantically correlated contents and low-level anatomical features is of central importance in medical image segmentation. Towards this end, recent deep learning-based medical segmentation methods have shown great promise in better modeling such information. However, convolution operators for medical segmentation typically operate on regular grids, which inherently blur the high-frequency regions, i.e., boundary regions. In this work, we propose MORSE, a generic implicit neural rendering framework designed at an anatomical level to assist learning in medical image segmentation. Our method is motivated by the fact that implicit neural representation has been shown to be more effective in fitting complex signals and solving computer graphics problems than discrete grid-based representation. The core of our approach is to formulate medical image segmentation as a rendering problem in an end-to-end manner. Specifically, we continuously align the coarse segmentation prediction with the ambiguous coordinate-based point representations and aggregate these features to adaptively refine the boundary region. To parallelly optimize multi-scale pixel-level features, we leverage the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a stochastic gating mechanism. Our experiments demonstrate that MORSE can work well with different medical segmentation backbones, consistently achieving competitive performance improvements in both 2D and 3D supervised medical segmentation methods. We also theoretically analyze the superiority of MORSE.","sentences":["Integrating high-level semantically correlated contents and low-level anatomical features is of central importance in medical image segmentation.","Towards this end, recent deep learning-based medical segmentation methods have shown great promise in better modeling such information.","However, convolution operators for medical segmentation typically operate on regular grids, which inherently blur the high-frequency regions, i.e., boundary regions.","In this work, we propose MORSE, a generic implicit neural rendering framework designed at an anatomical level to assist learning in medical image segmentation.","Our method is motivated by the fact that implicit neural representation has been shown to be more effective in fitting complex signals and solving computer graphics problems than discrete grid-based representation.","The core of our approach is to formulate medical image segmentation as a rendering problem in an end-to-end manner.","Specifically, we continuously align the coarse segmentation prediction with the ambiguous coordinate-based point representations and aggregate these features to adaptively refine the boundary region.","To parallelly optimize multi-scale pixel-level features, we leverage the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a stochastic gating mechanism.","Our experiments demonstrate that MORSE can work well with different medical segmentation backbones, consistently achieving competitive performance improvements in both 2D and 3D supervised medical segmentation methods.","We also theoretically analyze the superiority of MORSE."],"url":"http://arxiv.org/abs/2304.03209v1"}
{"created":"2023-04-06","title":"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster","abstract":"We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools. We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters. We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget). We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives. We describe our learnings including how Maximal Update Parameterization ($\\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale. We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal model scaling to models trained on fixed dataset sizes. Cerebras-GPT models are available on HuggingFace: https://huggingface.co/cerebras.","sentences":["We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools.","We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters.","We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget).","We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives.","We describe our learnings including how Maximal Update Parameterization ($\\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale.","We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal model scaling to models trained on fixed dataset sizes.","Cerebras-GPT models are available on HuggingFace: https://huggingface.co/cerebras."],"url":"http://arxiv.org/abs/2304.03208v1"}
{"created":"2023-04-06","title":"SLM: End-to-end Feature Selection via Sparse Learnable Masks","abstract":"Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability. We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples. At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles. In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax. This allows for more effective learning as demonstrated in ablation studies. Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance.","sentences":["Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability.","We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples.","At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles.","In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax.","This allows for more effective learning as demonstrated in ablation studies.","Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance."],"url":"http://arxiv.org/abs/2304.03202v1"}
{"created":"2023-04-06","title":"Improving automatic endoscopic stone recognition using a multi-view fusion approach enhanced with two-step transfer learning","abstract":"This contribution presents a deep-learning method for extracting and fusing image information acquired from different viewpoints, with the aim to produce more discriminant object features for the identification of the type of kidney stones seen in endoscopic images. The model was further improved with a two-step transfer learning approach and by attention blocks to refine the learned feature maps. Deep feature fusion strategies improved the results of single view extraction backbone models by more than 6% in terms of accuracy of the kidney stones classification.","sentences":["This contribution presents a deep-learning method for extracting and fusing image information acquired from different viewpoints, with the aim to produce more discriminant object features for the identification of the type of kidney stones seen in endoscopic images.","The model was further improved with a two-step transfer learning approach and by attention blocks to refine the learned feature maps.","Deep feature fusion strategies improved the results of single view extraction backbone models by more than 6% in terms of accuracy of the kidney stones classification."],"url":"http://arxiv.org/abs/2304.03193v1"}
{"created":"2023-04-06","title":"Krylov Methods are (nearly) Optimal for Low-Rank Approximation","abstract":"We consider the problem of rank-$1$ low-rank approximation (LRA) in the matrix-vector product model under various Schatten norms: $$   \\min_{\\|u\\|_2=1} \\|A (I - u u^\\top)\\|_{\\mathcal{S}_p} , $$ where $\\|M\\|_{\\mathcal{S}_p}$ denotes the $\\ell_p$ norm of the singular values of $M$. Given $\\varepsilon>0$, our goal is to output a unit vector $v$ such that $$   \\|A(I - vv^\\top)\\|_{\\mathcal{S}_p} \\leq (1+\\varepsilon) \\min_{\\|u\\|_2=1}\\|A(I - u u^\\top)\\|_{\\mathcal{S}_p}. $$ Our main result shows that Krylov methods (nearly) achieve the information-theoretically optimal number of matrix-vector products for Spectral ($p=\\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.   In particular, for Spectral LRA, we show that any algorithm requires $\\Omega\\left(\\log(n)/\\varepsilon^{1/2}\\right)$ matrix-vector products, exactly matching the upper bound obtained by Krylov methods [MM15, BCW22]. Our lower bound addresses Open Question 1 in [Woo14], providing evidence for the lack of progress on algorithms for Spectral LRA and resolves Open Question 1.2 in [BCW22]. Next, we show that for any fixed constant $p$, i.e. $1\\leq p =O(1)$, there is an upper bound of $O\\left(\\log(1/\\varepsilon)/\\varepsilon^{1/3}\\right)$ matrix-vector products, implying that the complexity does not grow as a function of input size. This improves the $O\\left(\\log(n/\\varepsilon)/\\varepsilon^{1/3}\\right)$ bound recently obtained in [BCW22], and matches their $\\Omega\\left(1/\\varepsilon^{1/3}\\right)$ lower bound, to a $\\log(1/\\varepsilon)$ factor.","sentences":["We consider the problem of rank-$1$ low-rank approximation (LRA) in the matrix-vector product model under various Schatten norms: $$   \\min_{\\|u\\|_2=1} \\|A (I - u u^\\top)\\|_{\\mathcal{S}_p} , $$ where $\\|M\\|_{\\mathcal{S}_p}$ denotes the $\\ell_p$ norm of the singular values of $M$. Given $\\varepsilon>0$, our goal is to output a unit vector $v$ such that $$   \\|A(I - vv^\\top)\\|_{\\mathcal{S}_p} \\leq (1+\\varepsilon) \\min_{\\|u\\|_2=1}\\|A(I - u u^\\top)\\|_{\\mathcal{S}_p}.","$$ Our main result shows that Krylov methods (nearly) achieve the information-theoretically optimal number of matrix-vector products for Spectral ($p=\\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.   ","In particular, for Spectral LRA, we show that any algorithm requires $\\Omega\\left(\\log(n)/\\varepsilon^{1/2}\\right)$ matrix-vector products, exactly matching the upper bound obtained by Krylov methods","[MM15, BCW22].","Our lower bound addresses Open Question 1 in [Woo14], providing evidence for the lack of progress on algorithms for Spectral LRA and resolves Open Question 1.2 in [BCW22].","Next, we show that for any fixed constant $p$, i.e. $1\\leq p =O(1)$, there is an upper bound of $O\\left(\\log(1/\\varepsilon)/\\varepsilon^{1/3}\\right)$ matrix-vector products, implying that the complexity does not grow as a function of input size.","This improves the $O\\left(\\log(n/\\varepsilon)/\\varepsilon^{1/3}\\right)$ bound recently obtained in [BCW22], and matches their $\\Omega\\left(1/\\varepsilon^{1/3}\\right)$ lower bound, to a $\\log(1/\\varepsilon)$ factor."],"url":"http://arxiv.org/abs/2304.03191v1"}
{"created":"2023-04-06","title":"The Concept of Forward-Forward Learning Applied to a Multi Output Perceptron","abstract":"The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification. The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples. Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries. Moreover, the overall performance is comparable to more complex neural networks with hidden layers. The benefit of the approach presented here is that it only involves a single matrix multiplication.","sentences":["The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification.","The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples.","Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries.","Moreover, the overall performance is comparable to more complex neural networks with hidden layers.","The benefit of the approach presented here is that it only involves a single matrix multiplication."],"url":"http://arxiv.org/abs/2304.03189v1"}
{"created":"2023-04-06","title":"Advances in Data-Driven Analysis and Synthesis of 3D Indoor Scenes","abstract":"This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes. We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations. Specifically, we focus on the analysis and synthesis of 3D indoor scenes. With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity. And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis. We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general. For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature. Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse.","sentences":["This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes.","We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations.","Specifically, we focus on the analysis and synthesis of 3D indoor scenes.","With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity.","And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis.","We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general.","For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature.","Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse."],"url":"http://arxiv.org/abs/2304.03188v1"}
{"created":"2023-04-06","title":"Pairwise Ranking with Gaussian Kernels","abstract":"Regularized pairwise ranking with Gaussian kernels is one of the cutting-edge learning algorithms. Despite a wide range of applications, a rigorous theoretical demonstration still lacks to support the performance of such ranking estimators. This work aims to fill this gap by developing novel oracle inequalities for regularized pairwise ranking. With the help of these oracle inequalities, we derive fast learning rates of Gaussian ranking estimators under a general box-counting dimension assumption on the input domain combined with the noise conditions or the standard smoothness condition. Our theoretical analysis improves the existing estimates and shows that a low intrinsic dimension of input space can help the rates circumvent the curse of dimensionality.","sentences":["Regularized pairwise ranking with Gaussian kernels is one of the cutting-edge learning algorithms.","Despite a wide range of applications, a rigorous theoretical demonstration still lacks to support the performance of such ranking estimators.","This work aims to fill this gap by developing novel oracle inequalities for regularized pairwise ranking.","With the help of these oracle inequalities, we derive fast learning rates of Gaussian ranking estimators under a general box-counting dimension assumption on the input domain combined with the noise conditions or the standard smoothness condition.","Our theoretical analysis improves the existing estimates and shows that a low intrinsic dimension of input space can help the rates circumvent the curse of dimensionality."],"url":"http://arxiv.org/abs/2304.03185v1"}
{"created":"2023-04-06","title":"Deep learning-based image exposure enhancement as a pre-processing for an accurate 3D colon surface reconstruction","abstract":"This contribution shows how an appropriate image pre-processing can improve a deep-learning based 3D reconstruction of colon parts. The assumption is that, rather than global image illumination corrections, local under- and over-exposures should be corrected in colonoscopy. An overview of the pipeline including the image exposure correction and a RNN-SLAM is first given. Then, this paper quantifies the reconstruction accuracy of the endoscope trajectory in the colon with and without appropriate illumination correction","sentences":["This contribution shows how an appropriate image pre-processing can improve a deep-learning based 3D reconstruction of colon parts.","The assumption is that, rather than global image illumination corrections, local under- and over-exposures should be corrected in colonoscopy.","An overview of the pipeline including the image exposure correction and a RNN-SLAM is first given.","Then, this paper quantifies the reconstruction accuracy of the endoscope trajectory in the colon with and without appropriate illumination correction"],"url":"http://arxiv.org/abs/2304.03171v1"}
{"created":"2023-04-06","title":"Parameterized Approximation Schemes for Clustering with General Norm Objectives","abstract":"This paper considers the well-studied algorithmic regime of designing a $(1+\\epsilon)$-approximation algorithm for a $k$-clustering problem that runs in time $f(k,\\epsilon)poly(n)$ (sometimes called an efficient parameterized approximation scheme or EPAS for short). Notable results of this kind include EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\\u{o}iu, Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means [Kumar, Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to the specific objective and metric space.   Our main contribution is a clean and simple EPAS that settles more than ten clustering problems (across multiple well-studied objectives as well as metric spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large variety of clustering objectives (for example, $k$-means, $k$-center, $k$-median, priority $k$-center, $\\ell$-centrum, ordered $k$-median, socially fair $k$-median aka robust $k$-median, or more generally monotone norm $k$-clustering) and metric spaces (for example, continuous high-dimensional Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth metrics, and planar metrics).   Key to our approach is a new concept that we call bounded $\\epsilon$-scatter dimension--an intrinsic complexity measure of a metric space that is a relaxation of the standard notion of bounded doubling dimension. Our main technical result shows that two conditions are essentially sufficient for our algorithm to yield an EPAS on the input metric $M$ for any clustering objective: (i) The objective is described by a monotone (not necessarily symmetric!) norm, and (ii) the $\\epsilon$-scatter dimension of $M$ is upper bounded by a function of $\\epsilon$.","sentences":["This paper considers the well-studied algorithmic regime of designing a $(1+\\epsilon)$-approximation algorithm for a $k$-clustering problem that runs in time $f(k,\\epsilon)poly(n)$ (sometimes called an efficient parameterized approximation scheme or EPAS for short).","Notable results of this kind include EPASes in the high-dimensional Euclidean setting for $k$-center","[Bad\\u{o}iu, Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means","[Kumar, Sabharwal, Sen; J. ACM 2010].","However, existing EPASes handle only basic objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to the specific objective and metric space.   ","Our main contribution is a clean and simple EPAS that settles more than ten clustering problems (across multiple well-studied objectives as well as metric spaces) and unifies well-known EPASes.","Our algorithm gives EPASes for a large variety of clustering objectives (for example, $k$-means, $k$-center, $k$-median, priority $k$-center, $\\ell$-centrum, ordered $k$-median, socially fair $k$-median aka robust $k$-median, or more generally monotone norm $k$-clustering) and metric spaces (for example, continuous high-dimensional Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth metrics, and planar metrics).   ","Key to our approach is a new concept that we call bounded $\\epsilon$-scatter dimension--an intrinsic complexity measure of a metric space that is a relaxation of the standard notion of bounded doubling dimension.","Our main technical result shows that two conditions are essentially sufficient for our algorithm to yield an EPAS on the input metric $M$ for any clustering objective: (i)","The objective is described by a monotone (not necessarily symmetric!)","norm, and (ii) the $\\epsilon$-scatter dimension of $M$ is upper bounded by a function of $\\epsilon$."],"url":"http://arxiv.org/abs/2304.03146v1"}
{"created":"2023-04-06","title":"Is it conceivable that neurogenesis, neural Darwinism, and species evolution could all serve as inspiration for the creation of evolutionary deep neural networks?","abstract":"Deep Neural Networks (DNNs) are built using artificial neural networks. They are part of machine learning methods that are capable of learning from data that have been used in a wide range of applications. DNNs are mainly handcrafted and they usually contain numerous layers. Research frontier has emerged that concerns automated construction of DNNs via evolutionary algorithms. This paper emphasizes the importance of what we call two-dimensional brain evolution and how it can inspire two dimensional DNN evolutionary modeling. We also highlight the connection between the dropout method which is widely-used in regularizing DNNs and neurogenesis of the brain, and how these concepts could benefit DNNs evolution.The paper concludes with several recommendations for enhancing the automatic construction of DNNs.","sentences":["Deep Neural Networks (DNNs) are built using artificial neural networks.","They are part of machine learning methods that are capable of learning from data that have been used in a wide range of applications.","DNNs are mainly handcrafted and they usually contain numerous layers.","Research frontier has emerged that concerns automated construction of DNNs via evolutionary algorithms.","This paper emphasizes the importance of what we call two-dimensional brain evolution and how it can inspire two dimensional DNN evolutionary modeling.","We also highlight the connection between the dropout method which is widely-used in regularizing DNNs and neurogenesis of the brain, and how these concepts could benefit DNNs evolution.","The paper concludes with several recommendations for enhancing the automatic construction of DNNs."],"url":"http://arxiv.org/abs/2304.03122v1"}
{"created":"2023-04-06","title":"Efficient SAGE Estimation via Causal Structure Learning","abstract":"The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features. However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose $d$-SAGE, a method that accelerates SAGE approximation. $d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations. This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations. Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values.","sentences":["The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features.","However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets.","This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions.","Thus, SAGE approximation algorithms only take a fraction of the feature sets into account.","We propose $d$-SAGE, a method that accelerates SAGE approximation.","$d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped.","To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations.","This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations.","Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values."],"url":"http://arxiv.org/abs/2304.03113v1"}
{"created":"2023-04-06","title":"Unraveling the Crystallization Kinetics of the Ge$_2$Sb$_2$Te$_5$ Phase Change Compound with a Machine-Learned Interatomic Potential","abstract":"The phase change compound Ge$_2$Sb$_2$Te$_5$ (GST225) is exploited in advanced non-volatile electronic memories and in neuromorphic devices which both rely on a fast and reversible transition between the crystalline and amorphous phases induced by Joule heating. The crystallization kinetics of GST225 is a key functional feature for the operation of these devices. We report here on the development of a machine-learned interatomic potential for GST225 that allowed us to perform large scale molecular dynamics simulations (over 10000 atoms for over 100 ns) to uncover the details of the crystallization kinetics in a wide range of temperatures of interest for the programming of the devices. The potential is obtained by fitting with a deep neural network (NN) scheme a large quantum-mechanical database generated within Density Functional Theory. The availability of a highly efficient and yet highly accurate NN potential opens the possibility to simulate phase change materials at the length and time scales of the real devices.","sentences":["The phase change compound Ge$_2$Sb$_2$Te$_5$ (GST225) is exploited in advanced non-volatile electronic memories and in neuromorphic devices which both rely on a fast and reversible transition between the crystalline and amorphous phases induced by Joule heating.","The crystallization kinetics of GST225 is a key functional feature for the operation of these devices.","We report here on the development of a machine-learned interatomic potential for GST225 that allowed us to perform large scale molecular dynamics simulations (over 10000 atoms for over 100 ns) to uncover the details of the crystallization kinetics in a wide range of temperatures of interest for the programming of the devices.","The potential is obtained by fitting with a deep neural network (NN) scheme a large quantum-mechanical database generated within Density Functional Theory.","The availability of a highly efficient and yet highly accurate NN potential opens the possibility to simulate phase change materials at the length and time scales of the real devices."],"url":"http://arxiv.org/abs/2304.03109v1"}
{"created":"2023-04-06","title":"Retention Is All You Need","abstract":"Skilled employees are usually seen as the most important pillar of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed for analyzing attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist human resource departments in interpreting the predictions provided by machine learning models. In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process. We optimize both the correctness and explanation of the results. Furthermore, using \"What-if-analysis\", we aim to observe plausible causes for attrition of an individual employee. The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions. Reducing attrition is not only a problem for any specific organization but also, in some countries, becomes a significant societal problem that impacts the well-being of both employers and employees.","sentences":["Skilled employees are usually seen as the most important pillar of an organization.","Despite this, most organizations face high attrition and turnover rates.","While several machine learning models have been developed for analyzing attrition and its causal factors, the interpretations of those models remain opaque.","In this paper, we propose the HR-DSS approach, which stands for Human Resource Decision Support System, and uses explainable AI for employee attrition problems.","The system is designed to assist human resource departments in interpreting the predictions provided by machine learning models.","In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process.","We optimize both the correctness and explanation of the results.","Furthermore, using \"What-if-analysis\", we aim to observe plausible causes for attrition of an individual employee.","The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions.","Reducing attrition is not only a problem for any specific organization but also, in some countries, becomes a significant societal problem that impacts the well-being of both employers and employees."],"url":"http://arxiv.org/abs/2304.03103v1"}
{"created":"2023-04-06","title":"Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm","abstract":"The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field. Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged. With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model. Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension. SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources.","sentences":["The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field.","Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged.","With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model.","Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension.","SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources."],"url":"http://arxiv.org/abs/2304.03098v1"}
{"created":"2023-04-06","title":"Spectral Gap Regularization of Neural Networks","abstract":"We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information. Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical motivation for this approach via spectral graph theory. We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool. We provide an approximate, variational approach for faster computation during training. We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction. We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis. We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay. Results demonstrate the efficacy of Fiedler regularization. This is a journal extension of the conference paper by Tam and Dunson (2020).","sentences":["We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information.","Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network.","We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization.","We provide theoretical motivation for this approach via spectral graph theory.","We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool.","We provide an approximate, variational approach for faster computation during training.","We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction.","We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis.","We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay.","Results demonstrate the efficacy of Fiedler regularization.","This is a journal extension of the conference paper by Tam and Dunson (2020)."],"url":"http://arxiv.org/abs/2304.03096v1"}
{"created":"2023-04-06","title":"PopulAtion Parameter Averaging (PAPA)","abstract":"Ensemble methods combine the predictions of multiple models to improve performance, but they require significantly higher computation costs at inference time. To avoid these costs, multiple neural networks can be combined into one by averaging their weights (model soups). However, this usually performs significantly worse than ensembling. Weight averaging is only beneficial when weights are similar enough (in weight or feature space) to average well but different enough to benefit from combining them. Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a method that combines the generality of ensembling with the efficiency of weight averaging. PAPA leverages a population of diverse models (trained on different data orders, augmentations, and regularizations) while occasionally (not too often, not too rarely) replacing the weights of the networks with the population average of the weights. PAPA reduces the performance gap between averaging and ensembling, increasing the average accuracy of a population of models by up to 1.1% on CIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to training independent (non-averaged) models.","sentences":["Ensemble methods combine the predictions of multiple models to improve performance, but they require significantly higher computation costs at inference time.","To avoid these costs, multiple neural networks can be combined into one by averaging their weights (model soups).","However, this usually performs significantly worse than ensembling.","Weight averaging is only beneficial when weights are similar enough (in weight or feature space) to average well but different enough to benefit from combining them.","Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a method that combines the generality of ensembling with the efficiency of weight averaging.","PAPA leverages a population of diverse models (trained on different data orders, augmentations, and regularizations) while occasionally (not too often, not too rarely) replacing the weights of the networks with the population average of the weights.","PAPA reduces the performance gap between averaging and ensembling, increasing the average accuracy of a population of models by up to 1.1% on CIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to training independent (non-averaged) models."],"url":"http://arxiv.org/abs/2304.03094v1"}
{"created":"2023-04-06","title":"Inductive Graph Unlearning","abstract":"As a way to implement the \"right to be forgotten\" in machine learning, \\textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples. Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data. To extend machine unlearning to graph data, \\textit{GraphEraser} has been proposed. However, a critical issue is that \\textit{GraphEraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training. It is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance. Such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks. To fill this gap, we propose the \\underline{{\\bf G}}\\underline{{\\bf U}}ided \\underline{{\\bf I}}n\\underline{{\\bf D}}uctiv\\underline{{\\bf E}} Graph Unlearning framework (GUIDE). GUIDE consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation. Empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs. Generally speaking, GUIDE can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information. The code will be available here: https://github.com/Happy2Git/GUIDE.","sentences":["As a way to implement the \"right to be forgotten\" in machine learning, \\textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples.","Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data.","To extend machine unlearning to graph data, \\textit{GraphEraser} has been proposed.","However, a critical issue is that \\textit{GraphEraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training.","It is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance.","Such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks.","To fill this gap, we propose the \\underline{{\\bf G}}\\underline{{\\bf U}}ided \\underline{{\\bf I}}n\\underline{{\\bf D}}uctiv\\underline{{\\bf E}} Graph Unlearning framework (GUIDE).","GUIDE consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation.","Empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs.","Generally speaking, GUIDE can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information.","The code will be available here: https://github.com/Happy2Git/GUIDE."],"url":"http://arxiv.org/abs/2304.03093v1"}
{"created":"2023-04-06","title":"Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media","abstract":"Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.","sentences":["Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media.","Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models.","However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges.","The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative.","This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges."],"url":"http://arxiv.org/abs/2304.03087v1"}
{"created":"2023-04-06","title":"Safe MDP Planning by Learning Temporal Patterns of Undesirable Trajectories and Averting Negative Side Effects","abstract":"In safe MDP planning, a cost function based on the current state and action is often used to specify safety aspects. In the real world, often the state representation used may lack sufficient fidelity to specify such safety constraints. Operating based on an incomplete model can often produce unintended negative side effects (NSEs). To address these challenges, first, we associate safety signals with state-action trajectories (rather than just an immediate state-action). This makes our safety model highly general. We also assume categorical safety labels are given for different trajectories, rather than a numerical cost function, which is harder to specify by the problem designer. We then employ a supervised learning model to learn such non-Markovian safety patterns. Second, we develop a Lagrange multiplier method, which incorporates the safety model and the underlying MDP model in a single computation graph to facilitate agent learning of safe behaviors. Finally, our empirical results on a variety of discrete and continuous domains show that this approach can satisfy complex non-Markovian safety constraints while optimizing an agent's total returns, is highly scalable, and is also better than the previous best approach for Markovian NSEs.","sentences":["In safe MDP planning, a cost function based on the current state and action is often used to specify safety aspects.","In the real world, often the state representation used may lack sufficient fidelity to specify such safety constraints.","Operating based on an incomplete model can often produce unintended negative side effects (NSEs).","To address these challenges, first, we associate safety signals with state-action trajectories (rather than just an immediate state-action).","This makes our safety model highly general.","We also assume categorical safety labels are given for different trajectories, rather than a numerical cost function, which is harder to specify by the problem designer.","We then employ a supervised learning model to learn such non-Markovian safety patterns.","Second, we develop a Lagrange multiplier method, which incorporates the safety model and the underlying MDP model in a single computation graph to facilitate agent learning of safe behaviors.","Finally, our empirical results on a variety of discrete and continuous domains show that this approach can satisfy complex non-Markovian safety constraints while optimizing an agent's total returns, is highly scalable, and is also better than the previous best approach for Markovian NSEs."],"url":"http://arxiv.org/abs/2304.03081v1"}
{"created":"2023-04-06","title":"Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series","abstract":"The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta (x_\\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$ for one or multiple powers $p\\in\\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.","sentences":["The real life time series are usually nonstationary, bringing a difficult question of model adaptation.","Classical approaches like GARCH assume arbitrary type of dependence.","To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta (x_\\tau))$ moving log-likelihood, evolving in time.","It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$ for one or multiple powers $p\\in\\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies."],"url":"http://arxiv.org/abs/2304.03069v1"}
{"created":"2023-04-06","title":"An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset","abstract":"Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification. The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems. The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger. Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN. The results show a noticeable improvement in generalization on the 3RL dataset. Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%).","sentences":["Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification.","The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger.","Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN.","The results show a noticeable improvement in generalization on the 3RL dataset.","Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%)."],"url":"http://arxiv.org/abs/2304.03064v1"}
{"created":"2023-04-06","title":"Sharp Deviations Bounds for Dirichlet Weighted Sums with Application to analysis of Bayesian algorithms","abstract":"In this work, we derive sharp non-asymptotic deviation bounds for weighted sums of Dirichlet random variables. These bounds are based on a novel integral representation of the density of a weighted Dirichlet sum. This representation allows us to obtain a Gaussian-like approximation for the sum distribution using geometry and complex analysis methods. Our results generalize similar bounds for the Beta distribution obtained in the seminal paper Alfers and Dinges [1984]. Additionally, our results can be considered a sharp non-asymptotic version of the inverse of Sanov's theorem studied by Ganesh and O'Connell [1999] in the Bayesian setting. Based on these results, we derive new deviation bounds for the Dirichlet process posterior means with application to Bayesian bootstrap. Finally, we apply our estimates to the analysis of the Multinomial Thompson Sampling (TS) algorithm in multi-armed bandits and significantly sharpen the existing regret bounds by making them independent of the size of the arms distribution support.","sentences":["In this work, we derive sharp non-asymptotic deviation bounds for weighted sums of Dirichlet random variables.","These bounds are based on a novel integral representation of the density of a weighted Dirichlet sum.","This representation allows us to obtain a Gaussian-like approximation for the sum distribution using geometry and complex analysis methods.","Our results generalize similar bounds for the Beta distribution obtained in the seminal paper Alfers and Dinges [1984].","Additionally, our results can be considered a sharp non-asymptotic version of the inverse of Sanov's theorem studied by Ganesh and O'Connell [1999] in the Bayesian setting.","Based on these results, we derive new deviation bounds for the Dirichlet process posterior means with application to Bayesian bootstrap.","Finally, we apply our estimates to the analysis of the Multinomial Thompson Sampling (TS) algorithm in multi-armed bandits and significantly sharpen the existing regret bounds by making them independent of the size of the arms distribution support."],"url":"http://arxiv.org/abs/2304.03056v1"}
{"created":"2023-04-06","title":"Expert-Independent Generalization of Well and Seismic Data Using Machine Learning Methods for Complex Reservoirs Predicting During Early-Stage Geological Exploration","abstract":"The aim of this study is to develop and apply an autonomous approach for predicting the probability of hydrocarbon reservoirs spreading in the studied area. Autonomy means that after preparing and inputting geological-geophysical information, the influence of an expert on the algorithms is minimized. The study was made based on the 3D seismic survey data and well information on the early exploration stage of the studied field. As a result, a forecast of the probability of spatial distribution of reservoirs was made for two sets of input data: the base set and the set after reverse-calibration, and three-dimensional cubes of calibrated probabilities of belonging of the studied space to the identified classes were obtained. The approach presented in the paper allows for expert-independent generalization of geological and geophysical data, and to use this generalization for hypothesis testing and creating geological models based on a probabilistic representation of the reservoir. The quality of the probabilistic representation depends on the quality and quantity of the input data. Depending on the input data, the approach can be a useful tool for exploration and prospecting of geological objects, identifying potential resources, optimizing and designing field development.","sentences":["The aim of this study is to develop and apply an autonomous approach for predicting the probability of hydrocarbon reservoirs spreading in the studied area.","Autonomy means that after preparing and inputting geological-geophysical information, the influence of an expert on the algorithms is minimized.","The study was made based on the 3D seismic survey data and well information on the early exploration stage of the studied field.","As a result, a forecast of the probability of spatial distribution of reservoirs was made for two sets of input data: the base set and the set after reverse-calibration, and three-dimensional cubes of calibrated probabilities of belonging of the studied space to the identified classes were obtained.","The approach presented in the paper allows for expert-independent generalization of geological and geophysical data, and to use this generalization for hypothesis testing and creating geological models based on a probabilistic representation of the reservoir.","The quality of the probabilistic representation depends on the quality and quantity of the input data.","Depending on the input data, the approach can be a useful tool for exploration and prospecting of geological objects, identifying potential resources, optimizing and designing field development."],"url":"http://arxiv.org/abs/2304.03048v1"}
{"created":"2023-04-06","title":"Data Processing with FPGAs on Modern Architectures","abstract":"Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale. These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression). In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks. We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers. The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs. The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints.","sentences":["Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale.","These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression).","In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   ","In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks.","We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers.","The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs.","The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints."],"url":"http://arxiv.org/abs/2304.03044v1"}
{"created":"2023-04-06","title":"Multi-Linear Kernel Regression and Imputation in Data Manifolds","abstract":"This paper introduces an efficient multi-linear nonparametric (kernel-based) approximation framework for data regression and imputation, and its application to dynamic magnetic-resonance imaging (dMRI). Data features are assumed to reside in or close to a smooth manifold embedded in a reproducing kernel Hilbert space. Landmark points are identified to describe concisely the point cloud of features by linear approximating patches which mimic the concept of tangent spaces to smooth manifolds. The multi-linear model effects dimensionality reduction, enables efficient computations, and extracts data patterns and their geometry without any training data or additional information. Numerical tests on dMRI data under severe under-sampling demonstrate remarkable improvements in efficiency and accuracy of the proposed approach over its predecessors, popular data modeling methods, as well as recent tensor-based and deep-image-prior schemes.","sentences":["This paper introduces an efficient multi-linear nonparametric (kernel-based) approximation framework for data regression and imputation, and its application to dynamic magnetic-resonance imaging (dMRI).","Data features are assumed to reside in or close to a smooth manifold embedded in a reproducing kernel Hilbert space.","Landmark points are identified to describe concisely the point cloud of features by linear approximating patches which mimic the concept of tangent spaces to smooth manifolds.","The multi-linear model effects dimensionality reduction, enables efficient computations, and extracts data patterns and their geometry without any training data or additional information.","Numerical tests on dMRI data under severe under-sampling demonstrate remarkable improvements in efficiency and accuracy of the proposed approach over its predecessors, popular data modeling methods, as well as recent tensor-based and deep-image-prior schemes."],"url":"http://arxiv.org/abs/2304.03041v1"}
{"created":"2023-04-06","title":"Modelling customer lifetime-value in the retail banking industry","abstract":"Understanding customer lifetime value is key to nurturing long-term customer relationships, however, estimating it is far from straightforward. In the retail banking industry, commonly used approaches rely on simple heuristics and do not take advantage of the high predictive ability of modern machine learning techniques. We present a general framework for modelling customer lifetime value which may be applied to industries with long-lasting contractual and product-centric customer relationships, of which retail banking is an example. This framework is novel in facilitating CLV predictions over arbitrary time horizons and product-based propensity models. We also detail an implementation of this model which is currently in production at a large UK lender. In testing, we estimate an 43% improvement in out-of-time CLV prediction error relative to a popular baseline approach. Propensity models derived from our CLV model have been used to support customer contact marketing campaigns. In testing, we saw that the top 10% of customers ranked by their propensity to take up investment products were 3.2 times more likely to take up an investment product in the next year than a customer chosen at random.","sentences":["Understanding customer lifetime value is key to nurturing long-term customer relationships, however, estimating it is far from straightforward.","In the retail banking industry, commonly used approaches rely on simple heuristics and do not take advantage of the high predictive ability of modern machine learning techniques.","We present a general framework for modelling customer lifetime value which may be applied to industries with long-lasting contractual and product-centric customer relationships, of which retail banking is an example.","This framework is novel in facilitating CLV predictions over arbitrary time horizons and product-based propensity models.","We also detail an implementation of this model which is currently in production at a large UK lender.","In testing, we estimate an 43% improvement in out-of-time CLV prediction error relative to a popular baseline approach.","Propensity models derived from our CLV model have been used to support customer contact marketing campaigns.","In testing, we saw that the top 10% of customers ranked by their propensity to take up investment products were 3.2 times more likely to take up an investment product in the next year than a customer chosen at random."],"url":"http://arxiv.org/abs/2304.03038v1"}
{"created":"2023-04-06","title":"Tensor Slicing and Optimization for Multicore NPUs","abstract":"Although code generation for Convolution Neural Network (CNN) models has been extensively studied, performing efficient data slicing and parallelization for highly-constrai\\-ned Multicore Neural Processor Units (NPUs) is still a challenging problem. Given the size of convolutions' input/output tensors and the small footprint of NPU on-chip memories, minimizing memory transactions while maximizing parallelism and MAC utilization are central to any effective solution. This paper proposes a TensorFlow XLA/LLVM compiler optimization pass for Multicore NPUs, called Tensor Slicing Optimization (TSO), which: (a) maximizes convolution parallelism and memory usage across NPU cores; and (b) reduces data transfers between host and NPU on-chip memories by using DRAM memory burst time estimates to guide tensor slicing. To evaluate the proposed approach, a set of experiments was performed using the NeuroMorphic Processor (NMP), a multicore NPU containing 32 RISC-V cores extended with novel CNN instructions. Experimental results show that TSO is capable of identifying the best tensor slicing that minimizes execution time for a set of CNN models. Speed-ups of up to 21.7\\% result when comparing the TSO burst-based technique to a no-burst data slicing approach. To validate the generality of the TSO approach, the algorithm was also ported to the Glow Machine Learning framework. The performance of the models were measured on both Glow and TensorFlow XLA/LLVM compilers, revealing similar results.","sentences":["Although code generation for Convolution Neural Network (CNN) models has been extensively studied, performing efficient data slicing and parallelization for highly-constrai\\-ned Multicore Neural Processor Units (NPUs) is still a challenging problem.","Given the size of convolutions' input/output tensors and the small footprint of NPU on-chip memories, minimizing memory transactions while maximizing parallelism and MAC utilization are central to any effective solution.","This paper proposes a TensorFlow XLA/LLVM compiler optimization pass for Multicore NPUs, called Tensor Slicing Optimization (TSO), which: (a) maximizes convolution parallelism and memory usage across NPU cores; and (b) reduces data transfers between host and NPU on-chip memories by using DRAM memory burst time estimates to guide tensor slicing.","To evaluate the proposed approach, a set of experiments was performed using the NeuroMorphic Processor (NMP), a multicore NPU containing 32 RISC-V cores extended with novel CNN instructions.","Experimental results show that TSO is capable of identifying the best tensor slicing that minimizes execution time for a set of CNN models.","Speed-ups of up to 21.7\\% result when comparing the TSO burst-based technique to a no-burst data slicing approach.","To validate the generality of the TSO approach, the algorithm was also ported to the Glow Machine Learning framework.","The performance of the models were measured on both Glow and TensorFlow XLA/LLVM compilers, revealing similar results."],"url":"http://arxiv.org/abs/2304.03013v1"}
{"created":"2023-04-06","title":"IoT Federated Blockchain Learning at the Edge","abstract":"IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits. IoT devices are low-cost, energy-efficient, small and intelligent devices. In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge. The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy. Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained. 2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists. 3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models.","sentences":["IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits.","IoT devices are low-cost, energy-efficient, small and intelligent devices.","In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge.","The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy.","Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained.","2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists.","3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models."],"url":"http://arxiv.org/abs/2304.03006v1"}
{"created":"2023-04-06","title":"Spritz-PS: Validation of Synthetic Face Images Using a Large Dataset of Printed Documents","abstract":"The capability of doing effective forensic analysis on printed and scanned (PS) images is essential in many applications. PS documents may be used to conceal the artifacts of images which is due to the synthetic nature of images since these artifacts are typically present in manipulated images and the main artifacts in the synthetic images can be removed after the PS. Due to the appeal of Generative Adversarial Networks (GANs), synthetic face images generated with GANs models are difficult to differentiate from genuine human faces and may be used to create counterfeit identities. Additionally, since GANs models do not account for physiological constraints for generating human faces and their impact on human IRISes, distinguishing genuine from synthetic IRISes in the PS scenario becomes extremely difficult. As a result of the lack of large-scale reference IRIS datasets in the PS scenario, we aim at developing a novel dataset to become a standard for Multimedia Forensics (MFs) investigation which is available at [45]. In this paper, we provide a novel dataset made up of a large number of synthetic and natural printed IRISes taken from VIPPrint Printed and Scanned face images. We extracted irises from face images and it is possible that the model due to eyelid occlusion captured the incomplete irises. To fill the missing pixels of extracted iris, we applied techniques to discover the complex link between the iris images. To highlight the problems involved with the evaluation of the dataset's IRIS images, we conducted a large number of analyses employing Siamese Neural Networks to assess the similarities between genuine and synthetic human IRISes, such as ResNet50, Xception, VGG16, and MobileNet-v2. For instance, using the Xception network, we achieved 56.76\\% similarity of IRISes for synthetic images and 92.77% similarity of IRISes for real images.","sentences":["The capability of doing effective forensic analysis on printed and scanned (PS) images is essential in many applications.","PS documents may be used to conceal the artifacts of images which is due to the synthetic nature of images since these artifacts are typically present in manipulated images and the main artifacts in the synthetic images can be removed after the PS.","Due to the appeal of Generative Adversarial Networks (GANs), synthetic face images generated with GANs models are difficult to differentiate from genuine human faces and may be used to create counterfeit identities.","Additionally, since GANs models do not account for physiological constraints for generating human faces and their impact on human IRISes, distinguishing genuine from synthetic IRISes in the PS scenario becomes extremely difficult.","As a result of the lack of large-scale reference IRIS datasets in the PS scenario, we aim at developing a novel dataset to become a standard for Multimedia Forensics (MFs) investigation which is available at [45].","In this paper, we provide a novel dataset made up of a large number of synthetic and natural printed IRISes taken from VIPPrint Printed and Scanned face images.","We extracted irises from face images and it is possible that the model due to eyelid occlusion captured the incomplete irises.","To fill the missing pixels of extracted iris, we applied techniques to discover the complex link between the iris images.","To highlight the problems involved with the evaluation of the dataset's IRIS images, we conducted a large number of analyses employing Siamese Neural Networks to assess the similarities between genuine and synthetic human IRISes, such as ResNet50, Xception, VGG16, and MobileNet-v2.","For instance, using the Xception network, we achieved 56.76\\% similarity of IRISes for synthetic images and 92.77% similarity of IRISes for real images."],"url":"http://arxiv.org/abs/2304.02982v1"}
{"created":"2023-04-06","title":"A Fast and Lightweight Network for Low-Light Image Enhancement","abstract":"Low-light images often suffer from severe noise, low brightness, low contrast, and color deviation. While several low-light image enhancement methods have been proposed, there remains a lack of efficient methods that can simultaneously solve all of these problems. In this paper, we introduce FLW-Net, a Fast and LightWeight Network for low-light image enhancement that significantly improves processing speed and overall effect. To achieve efficient low-light image enhancement, we recognize the challenges of the lack of an absolute reference and the need for a large receptive field to obtain global contrast. Therefore, we propose an efficient global feature information extraction component and design loss functions based on relative information to overcome these challenges. Finally, we conduct comparative experiments to demonstrate the effectiveness of the proposed method, and the results confirm that FLW-Net can significantly reduce the complexity of supervised low-light image enhancement networks while improving processing effect. Code is available at https://github.com/hitzhangyu/FLW-Net","sentences":["Low-light images often suffer from severe noise, low brightness, low contrast, and color deviation.","While several low-light image enhancement methods have been proposed, there remains a lack of efficient methods that can simultaneously solve all of these problems.","In this paper, we introduce FLW-Net, a Fast and LightWeight Network for low-light image enhancement that significantly improves processing speed and overall effect.","To achieve efficient low-light image enhancement, we recognize the challenges of the lack of an absolute reference and the need for a large receptive field to obtain global contrast.","Therefore, we propose an efficient global feature information extraction component and design loss functions based on relative information to overcome these challenges.","Finally, we conduct comparative experiments to demonstrate the effectiveness of the proposed method, and the results confirm that FLW-Net can significantly reduce the complexity of supervised low-light image enhancement networks while improving processing effect.","Code is available at https://github.com/hitzhangyu/FLW-Net"],"url":"http://arxiv.org/abs/2304.02978v1"}
{"created":"2023-04-06","title":"Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations","abstract":"In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time. The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs). We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control. Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters. We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification.","sentences":["In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time.","The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs).","We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control.","Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters.","We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification."],"url":"http://arxiv.org/abs/2304.02976v1"}
{"created":"2023-04-06","title":"Deep Long-Short Term Memory networks: Stability properties and Experimental validation","abstract":"The aim of this work is to investigate the use of Incrementally Input-to-State Stable ($\\delta$ISS) deep Long Short Term Memory networks (LSTMs) for the identification of nonlinear dynamical systems. We show that suitable sufficient conditions on the weights of the network can be leveraged to setup a training procedure able to learn provenly-$\\delta$ISS LSTM models from data. The proposed approach is tested on a real brake-by-wire apparatus to identify a model of the system from input-output experimentally collected data. Results show satisfactory modeling performances.","sentences":["The aim of this work is to investigate the use of Incrementally Input-to-State Stable ($\\delta$ISS) deep Long Short Term Memory networks (LSTMs) for the identification of nonlinear dynamical systems.","We show that suitable sufficient conditions on the weights of the network can be leveraged to setup a training procedure able to learn provenly-$\\delta$ISS LSTM models from data.","The proposed approach is tested on a real brake-by-wire apparatus to identify a model of the system from input-output experimentally collected data.","Results show satisfactory modeling performances."],"url":"http://arxiv.org/abs/2304.02975v1"}
{"created":"2023-04-06","title":"Training a Two Layer ReLU Network Analytically","abstract":"Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer. Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima. However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed. Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated. Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters.","sentences":["Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer.","Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima.","However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed.","Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated.","Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters."],"url":"http://arxiv.org/abs/2304.02972v1"}
{"created":"2023-04-06","title":"Synthetic Hard Negative Samples for Contrastive Learning","abstract":"Contrastive learning has emerged as an essential approach for self-supervised learning in computer vision. The central objective of contrastive learning is to maximize the similarities between two augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs). Recent studies have demonstrated that harder negative samples, i.e., those that are difficult to distinguish from anchor sample, play a more critical role in contrastive learning. In this paper, we propose a novel featurelevel method, namely sampling synthetic hard negative samples for contrastive learning (SSCL), to exploit harder negative samples more effectively. Specifically, 1) we generate more and harder negative samples by mixing negative samples, and then sample them by controlling the contrast of anchor sample with the other negative samples. 2) Considering that the negative samples obtained by sampling may have the problem of false negative samples, we further debias the negative samples. Our proposed method improves the classification performance on different image datasets and can be readily applied to existing methods.","sentences":["Contrastive learning has emerged as an essential approach for self-supervised learning in computer vision.","The central objective of contrastive learning is to maximize the similarities between two augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs).","Recent studies have demonstrated that harder negative samples, i.e., those that are difficult to distinguish from anchor sample, play a more critical role in contrastive learning.","In this paper, we propose a novel featurelevel method, namely sampling synthetic hard negative samples for contrastive learning (SSCL), to exploit harder negative samples more effectively.","Specifically, 1) we generate more and harder negative samples by mixing negative samples, and then sample them by controlling the contrast of anchor sample with the other negative samples.","2) Considering that the negative samples obtained by sampling may have the problem of false negative samples, we further debias the negative samples.","Our proposed method improves the classification performance on different image datasets and can be readily applied to existing methods."],"url":"http://arxiv.org/abs/2304.02971v1"}
{"created":"2023-04-06","title":"Benchmarking Robustness to Text-Guided Corruptions","abstract":"This study investigates the robustness of image classifiers to text-guided corruptions. We utilize diffusion models to edit images to different domains. Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content. Thus, the corruptions will be more realistic and the comparison will be more informative. Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort. We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains. As well as introducing a new benchmark we try to investigate the robustness of different vision models. The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains. We also observe that convolutional models are more robust than transformer architectures. Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images. The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems. The code for generating the benchmark will be made available online upon publication.","sentences":["This study investigates the robustness of image classifiers to text-guided corruptions.","We utilize diffusion models to edit images to different domains.","Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content.","Thus, the corruptions will be more realistic and the comparison will be more informative.","Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort.","We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains.","As well as introducing a new benchmark we try to investigate the robustness of different vision models.","The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains.","We also observe that convolutional models are more robust than transformer architectures.","Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images.","The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems.","The code for generating the benchmark will be made available online upon publication."],"url":"http://arxiv.org/abs/2304.02963v1"}
{"created":"2023-04-06","title":"When approximate design for fast homomorphic computation provides differential privacy guarantees","abstract":"While machine learning has become pervasive in as diversified fields as industry, healthcare, social networks, privacy concerns regarding the training data have gained a critical importance. In settings where several parties wish to collaboratively train a common model without jeopardizing their sensitive data, the need for a private training protocol is particularly stringent and implies to protect the data against both the model's end-users and the actors of the training phase. Differential privacy (DP) and cryptographic primitives are complementary popular countermeasures against privacy attacks. Among these cryptographic primitives, fully homomorphic encryption (FHE) offers ciphertext malleability at the cost of time-consuming operations in the homomorphic domain. In this paper, we design SHIELD, a probabilistic approximation algorithm for the argmax operator which is both fast when homomorphically executed and whose inaccuracy is used as a feature to ensure DP guarantees. Even if SHIELD could have other applications, we here focus on one setting and seamlessly integrate it in the SPEED collaborative training framework from \"SPEED: Secure, PrivatE, and Efficient Deep learning\" (Grivet S\\'ebert et al., 2021) to improve its computational efficiency. After thoroughly describing the FHE implementation of our algorithm and its DP analysis, we present experimental results. To the best of our knowledge, it is the first work in which relaxing the accuracy of an homomorphic calculation is constructively usable as a degree of freedom to achieve better FHE performances.","sentences":["While machine learning has become pervasive in as diversified fields as industry, healthcare, social networks, privacy concerns regarding the training data have gained a critical importance.","In settings where several parties wish to collaboratively train a common model without jeopardizing their sensitive data, the need for a private training protocol is particularly stringent and implies to protect the data against both the model's end-users and the actors of the training phase.","Differential privacy (DP) and cryptographic primitives are complementary popular countermeasures against privacy attacks.","Among these cryptographic primitives, fully homomorphic encryption (FHE) offers ciphertext malleability at the cost of time-consuming operations in the homomorphic domain.","In this paper, we design SHIELD, a probabilistic approximation algorithm for the argmax operator which is both fast when homomorphically executed and whose inaccuracy is used as a feature to ensure DP guarantees.","Even if SHIELD could have other applications, we here focus on one setting and seamlessly integrate it in the SPEED collaborative training framework from \"SPEED: Secure, PrivatE, and Efficient Deep learning\" (Grivet S\\'ebert et al., 2021) to improve its computational efficiency.","After thoroughly describing the FHE implementation of our algorithm and its DP analysis, we present experimental results.","To the best of our knowledge, it is the first work in which relaxing the accuracy of an homomorphic calculation is constructively usable as a degree of freedom to achieve better FHE performances."],"url":"http://arxiv.org/abs/2304.02959v1"}
{"created":"2023-04-06","title":"FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead","abstract":"We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI). Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective. Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner. Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance. With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution. Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware. The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time.","sentences":["We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI).","Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective.","Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner.","Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance.","With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution.","Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware.","The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time."],"url":"http://arxiv.org/abs/2304.02948v1"}
{"created":"2023-04-06","title":"Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems","abstract":"This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm. The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions. The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life. A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits. RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains. Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy.","sentences":["This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm.","The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions.","The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life.","A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits.","RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains.","Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy."],"url":"http://arxiv.org/abs/2304.02947v1"}
{"created":"2023-04-06","title":"Convolutional neural networks for crack detection on flexible road pavements","abstract":"Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions. Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards. In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying. However, surveying is still a tedious manual process. Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error. This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection. The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples. The effects of dataset augmentation are also investigated. Of the six models trained, five achieved accuracy above 97%. The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models. The dataset is available at the following URL: https://zenodo.org/record/7795975","sentences":["Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions.","Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards.","In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying.","However, surveying is still a tedious manual process.","Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error.","This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection.","The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples.","The effects of dataset augmentation are also investigated.","Of the six models trained, five achieved accuracy above 97%.","The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models.","The dataset is available at the following URL: https://zenodo.org/record/7795975"],"url":"http://arxiv.org/abs/2304.02933v1"}
{"created":"2023-04-06","title":"Mask Detection and Classification in Thermal Face Images","abstract":"Face masks are recommended to reduce the transmission of many viruses, especially SARS-CoV-2. Therefore, the automatic detection of whether there is a mask on the face, what type of mask is worn, and how it is worn is an important research topic. In this work, the use of thermal imaging was considered to analyze the possibility of detecting (localizing) a mask on the face, as well as to check whether it is possible to classify the type of mask on the face. The previously proposed dataset of thermal images was extended and annotated with the description of a type of mask and a location of a mask within a face. Different deep learning models were adapted. The best model for face mask detection turned out to be the Yolov5 model in the \"nano\" version, reaching mAP higher than 97% and precision of about 95%. High accuracy was also obtained for mask type classification. The best results were obtained for the convolutional neural network model built on an autoencoder initially trained in the thermal image reconstruction problem. The pretrained encoder was used to train a classifier which achieved an accuracy of 91%.","sentences":["Face masks are recommended to reduce the transmission of many viruses, especially SARS-CoV-2.","Therefore, the automatic detection of whether there is a mask on the face, what type of mask is worn, and how it is worn is an important research topic.","In this work, the use of thermal imaging was considered to analyze the possibility of detecting (localizing) a mask on the face, as well as to check whether it is possible to classify the type of mask on the face.","The previously proposed dataset of thermal images was extended and annotated with the description of a type of mask and a location of a mask within a face.","Different deep learning models were adapted.","The best model for face mask detection turned out to be the Yolov5 model in the \"nano\" version, reaching mAP higher than 97% and precision of about 95%.","High accuracy was also obtained for mask type classification.","The best results were obtained for the convolutional neural network model built on an autoencoder initially trained in the thermal image reconstruction problem.","The pretrained encoder was used to train a classifier which achieved an accuracy of 91%."],"url":"http://arxiv.org/abs/2304.02931v1"}
{"created":"2023-04-06","title":"Efficient Audio Captioning Transformer with Patchout and Text Guidance","abstract":"Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity. Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022.","sentences":["Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip.","In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting.","The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions.","To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset.","Moreover, we propose a method to apply Mixup augmentation for AAC.","Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance.","The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity.","Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022."],"url":"http://arxiv.org/abs/2304.02916v1"}
{"created":"2023-04-06","title":"Classification of Superstatistical Features in High Dimensions","abstract":"We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.","sentences":["We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation.","Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance.","We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters."],"url":"http://arxiv.org/abs/2304.02912v1"}
{"created":"2023-04-06","title":"Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks","abstract":"Unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge. Recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue. A key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices. To capitalize on this discovery, we introduce a novel regularization technique, termed Heavy-Tailed Regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization. Firstly, we employ the Weighted Alpha and Stable Rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients. To circumvent over-regularization, we introduce two variations of the penalty function. Then, adopting a Bayesian statistics perspective and leveraging knowledge from random matrices, we develop two novel heavy-tailed regularization methods, utilizing Powerlaw distribution and Frechet distribution as priors for the global spectrum and maximum eigenvalues, respectively. We empirically show that heavytailed regularization outperforms conventional regularization techniques in terms of generalization performance.","sentences":["Unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge.","Recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue.","A key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices.","To capitalize on this discovery, we introduce a novel regularization technique, termed Heavy-Tailed Regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization.","Firstly, we employ the Weighted Alpha and Stable Rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients.","To circumvent over-regularization, we introduce two variations of the penalty function.","Then, adopting a Bayesian statistics perspective and leveraging knowledge from random matrices, we develop two novel heavy-tailed regularization methods, utilizing Powerlaw distribution and Frechet distribution as priors for the global spectrum and maximum eigenvalues, respectively.","We empirically show that heavytailed regularization outperforms conventional regularization techniques in terms of generalization performance."],"url":"http://arxiv.org/abs/2304.02911v1"}
{"created":"2023-04-06","title":"A Context-Switching/Dual-Context ROM Augmented RAM using Standard 8T SRAM","abstract":"The landscape of emerging applications has been continually widening, encompassing various data-intensive applications like artificial intelligence, machine learning, secure encryption, Internet-of-Things, etc. A sustainable approach toward creating dedicated hardware platforms that can cater to multiple applications often requires the underlying hardware to context-switch or support more than one context simultaneously. This paper presents a context-switching and dual-context memory based on the standard 8T SRAM bit-cell. Specifically, we exploit the availability of multi-VT transistors by selectively choosing the read-port transistors of the 8T SRAM cell to be either high-VT or low-VT. The 8T SRAM cell is thus augmented to store ROM data (represented as the VT of the transistors constituting the read-port) while simultaneously storing RAM data. Further, we propose specific sensing methodologies such that the memory array can support RAM-only or ROM-only mode (context-switching (CS) mode) or RAM and ROM mode simultaneously (dual-context (DC) mode). Extensive Monte-Carlo simulations have verified the robustness of our proposed ROM-augmented CS/DC memory on the Globalfoundries 22nm-FDX technology node.","sentences":["The landscape of emerging applications has been continually widening, encompassing various data-intensive applications like artificial intelligence, machine learning, secure encryption, Internet-of-Things, etc.","A sustainable approach toward creating dedicated hardware platforms that can cater to multiple applications often requires the underlying hardware to context-switch or support more than one context simultaneously.","This paper presents a context-switching and dual-context memory based on the standard 8T SRAM bit-cell.","Specifically, we exploit the availability of multi-VT transistors by selectively choosing the read-port transistors of the 8T SRAM cell to be either high-VT or low-VT.","The 8T SRAM cell is thus augmented to store ROM data (represented as the VT of the transistors constituting the read-port) while simultaneously storing RAM data.","Further, we propose specific sensing methodologies such that the memory array can support RAM-only or ROM-only mode (context-switching (CS) mode) or RAM and ROM mode simultaneously (dual-context (DC) mode).","Extensive Monte-Carlo simulations have verified the robustness of our proposed ROM-augmented CS/DC memory on the Globalfoundries 22nm-FDX technology node."],"url":"http://arxiv.org/abs/2304.02908v1"}
{"created":"2023-04-06","title":"Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry","abstract":"Bayesian inference in deep neural networks is challenging due to the high-dimensional, strongly multi-modal parameter posterior density landscape. Markov chain Monte Carlo approaches asymptotically recover the true posterior but are considered prohibitively expensive for large modern architectures. Local methods, which have emerged as a popular alternative, focus on specific parameter regions that can be approximated by functions with tractable integrals. While these often yield satisfactory empirical results, they fail, by definition, to account for the multi-modality of the parameter posterior. In this work, we argue that the dilemma between exact-but-unaffordable and cheap-but-inexact approaches can be mitigated by exploiting symmetries in the posterior landscape. Such symmetries, induced by neuron interchangeability and certain activation functions, manifest in different parameter values leading to the same functional output value. We show theoretically that the posterior predictive density in Bayesian neural networks can be restricted to a symmetry-free parameter reference set. By further deriving an upper bound on the number of Monte Carlo chains required to capture the functional diversity, we propose a straightforward approach for feasible Bayesian inference. Our experiments suggest that efficient sampling is indeed possible, opening up a promising path to accurate uncertainty quantification in deep learning.","sentences":["Bayesian inference in deep neural networks is challenging due to the high-dimensional, strongly multi-modal parameter posterior density landscape.","Markov chain Monte Carlo approaches asymptotically recover the true posterior but are considered prohibitively expensive for large modern architectures.","Local methods, which have emerged as a popular alternative, focus on specific parameter regions that can be approximated by functions with tractable integrals.","While these often yield satisfactory empirical results, they fail, by definition, to account for the multi-modality of the parameter posterior.","In this work, we argue that the dilemma between exact-but-unaffordable and cheap-but-inexact approaches can be mitigated by exploiting symmetries in the posterior landscape.","Such symmetries, induced by neuron interchangeability and certain activation functions, manifest in different parameter values leading to the same functional output value.","We show theoretically that the posterior predictive density in Bayesian neural networks can be restricted to a symmetry-free parameter reference set.","By further deriving an upper bound on the number of Monte Carlo chains required to capture the functional diversity, we propose a straightforward approach for feasible Bayesian inference.","Our experiments suggest that efficient sampling is indeed possible, opening up a promising path to accurate uncertainty quantification in deep learning."],"url":"http://arxiv.org/abs/2304.02902v1"}
{"created":"2023-04-06","title":"Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection","abstract":"Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential. However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large. In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension. Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration. We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\\big(\\big(\\frac{P}{S}\\big)^2 \\frac{\\log T}{T}\\big)$ for a given dataset where $S$ is the expected number of conditional PIP computations per MCMC iteration. Experiments show that our Rao-Blackwellized estimator can have a smaller variance than its counterpart associated with the subset wTGS.","sentences":["Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential.","However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large.","In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension.","Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration.","We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\\big(\\big(\\frac{P}{S}\\big)^2 \\frac{\\log T}{T}\\big)$ for a given dataset where $S$ is the expected number of conditional PIP computations per MCMC iteration.","Experiments show that our Rao-Blackwellized estimator can have a smaller variance than its counterpart associated with the subset wTGS."],"url":"http://arxiv.org/abs/2304.02899v1"}
{"created":"2023-04-06","title":"Object-centric Inference for Language Conditioned Placement: A Foundation Model based Approach","abstract":"We focus on the task of language-conditioned object placement, in which a robot should generate placements that satisfy all the spatial relational constraints in language instructions. Previous works based on rule-based language parsing or scene-centric visual representation have restrictions on the form of instructions and reference objects or require large amounts of training data. We propose an object-centric framework that leverages foundation models to ground the reference objects and spatial relations for placement, which is more sample efficient and generalizable. Experiments indicate that our model can achieve a 97.75% success rate of placement with only ~0.26M trainable parameters. Besides, our method generalizes better to both unseen objects and instructions. Moreover, with only 25% training data, we still outperform the top competing approach.","sentences":["We focus on the task of language-conditioned object placement, in which a robot should generate placements that satisfy all the spatial relational constraints in language instructions.","Previous works based on rule-based language parsing or scene-centric visual representation have restrictions on the form of instructions and reference objects or require large amounts of training data.","We propose an object-centric framework that leverages foundation models to ground the reference objects and spatial relations for placement, which is more sample efficient and generalizable.","Experiments indicate that our model can achieve a 97.75% success rate of placement with only ~0.26M trainable parameters.","Besides, our method generalizes better to both unseen objects and instructions.","Moreover, with only 25% training data, we still outperform the top competing approach."],"url":"http://arxiv.org/abs/2304.02893v1"}
{"created":"2023-04-06","title":"Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients","abstract":"Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees. In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise). The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective. To address the challenges, we propose FedCNI without using an additional clean proxy dataset. It includes a noise-resilient local solver and a robust global aggregator. For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples. Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy. For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods. Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments.","sentences":["Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees.","In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise).","The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective.","To address the challenges, we propose FedCNI without using an additional clean proxy dataset.","It includes a noise-resilient local solver and a robust global aggregator.","For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples.","Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy.","For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods.","Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments."],"url":"http://arxiv.org/abs/2304.02892v1"}
{"created":"2023-04-06","title":"ViralVectors: Compact and Scalable Alignment-free Virome Feature Generation","abstract":"The amount of sequencing data for SARS-CoV-2 is several orders of magnitude larger than any virus. This will continue to grow geometrically for SARS-CoV-2, and other viruses, as many countries heavily finance genomic surveillance efforts. Hence, we need methods for processing large amounts of sequence data to allow for effective yet timely decision-making. Such data will come from heterogeneous sources: aligned, unaligned, or even unassembled raw nucleotide or amino acid sequencing reads pertaining to the whole genome or regions (e.g., spike) of interest. In this work, we propose \\emph{ViralVectors}, a compact feature vector generation from virome sequencing data that allows effective downstream analysis. Such generation is based on \\emph{minimizers}, a type of lightweight \"signature\" of a sequence, used traditionally in assembly and read mapping -- to our knowledge, the first use minimizers in this way. We validate our approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spike sequences (to show scalability); (b) 3K Coronaviridae spike sequences (to show robustness to more genomic variability); and (c) 4K raw WGS reads sets taken from nasal-swab PCR tests (to show the ability to process unassembled reads). Our results show that ViralVectors outperforms current benchmarks in most classification and clustering tasks.","sentences":["The amount of sequencing data for SARS-CoV-2 is several orders of magnitude larger than any virus.","This will continue to grow geometrically for SARS-CoV-2, and other viruses, as many countries heavily finance genomic surveillance efforts.","Hence, we need methods for processing large amounts of sequence data to allow for effective yet timely decision-making.","Such data will come from heterogeneous sources: aligned, unaligned, or even unassembled raw nucleotide or amino acid sequencing reads pertaining to the whole genome or regions (e.g., spike) of interest.","In this work, we propose \\emph{ViralVectors}, a compact feature vector generation from virome sequencing data that allows effective downstream analysis.","Such generation is based on \\emph{minimizers}, a type of lightweight \"signature\" of a sequence, used traditionally in assembly and read mapping -- to our knowledge, the first use minimizers in this way.","We validate our approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spike sequences (to show scalability); (b) 3K Coronaviridae spike sequences (to show robustness to more genomic variability); and (c) 4K raw WGS reads sets taken from nasal-swab PCR tests (to show the ability to process unassembled reads).","Our results show that ViralVectors outperforms current benchmarks in most classification and clustering tasks."],"url":"http://arxiv.org/abs/2304.02891v1"}
{"created":"2023-04-06","title":"Tag that issue: Applying API-domain labels in issue tracking systems","abstract":"Labeling issues with the skills required to complete them can help contributors to choose tasks in Open Source Software projects. However, manually labeling issues is time-consuming and error-prone, and current automated approaches are mostly limited to classifying issues as bugs/non-bugs. We investigate the feasibility and relevance of automatically labeling issues with what we call \"API-domains,\" which are high-level categories of APIs. Therefore, we posit that the APIs used in the source code affected by an issue can be a proxy for the type of skills (e.g., DB, security, UI) needed to work on the issue. We ran a user study (n=74) to assess API-domain labels' relevancy to potential contributors, leveraged the issues' descriptions and the project history to build prediction models, and validated the predictions with contributors (n=20) of the projects. Our results show that (i) newcomers to the project consider API-domain labels useful in choosing tasks, (ii) labels can be predicted with a precision of 84% and a recall of 78.6% on average, (iii) the results of the predictions reached up to 71.3% in precision and 52.5% in recall when training with a project and testing in another (transfer learning), and (iv) project contributors consider most of the predictions helpful in identifying needed skills. These findings suggest our approach can be applied in practice to automatically label issues, assisting developers in finding tasks that better match their skills.","sentences":["Labeling issues with the skills required to complete them can help contributors to choose tasks in Open Source Software projects.","However, manually labeling issues is time-consuming and error-prone, and current automated approaches are mostly limited to classifying issues as bugs/non-bugs.","We investigate the feasibility and relevance of automatically labeling issues with what we call \"API-domains,\" which are high-level categories of APIs.","Therefore, we posit that the APIs used in the source code affected by an issue can be a proxy for the type of skills (e.g., DB, security, UI) needed to work on the issue.","We ran a user study (n=74) to assess API-domain labels' relevancy to potential contributors, leveraged the issues' descriptions and the project history to build prediction models, and validated the predictions with contributors (n=20) of the projects.","Our results show that (i) newcomers to the project consider API-domain labels useful in choosing tasks, (ii) labels can be predicted with a precision of 84% and a recall of 78.6% on average, (iii) the results of the predictions reached up to 71.3% in precision and 52.5% in recall when training with a project and testing in another (transfer learning), and (iv) project contributors consider most of the predictions helpful in identifying needed skills.","These findings suggest our approach can be applied in practice to automatically label issues, assisting developers in finding tasks that better match their skills."],"url":"http://arxiv.org/abs/2304.02877v1"}
{"created":"2023-04-06","title":"Computational role of sleep in memory reorganization","abstract":"Sleep is considered to play an essential role in memory reorganization. Despite its importance, classical theoretical models did not focus on detailed sleep characteristics. Here, we review recent theoretical approaches to investigate their roles in learning. We first review the possibility that slow waves improve computation by preparing distinct neuronal states and by imposing traveling waves. Second, we consider how memory transfer between multiple regions at different speeds could improve generalization. Third, we suggest that dreaming might contribute to forming efficient representations analogous to state-of-art machine learning methods. We finally discuss how these points could be further developed, emphasizing the connections to experimental neuroscience and machine learning.","sentences":["Sleep is considered to play an essential role in memory reorganization.","Despite its importance, classical theoretical models did not focus on detailed sleep characteristics.","Here, we review recent theoretical approaches to investigate their roles in learning.","We first review the possibility that slow waves improve computation by preparing distinct neuronal states and by imposing traveling waves.","Second, we consider how memory transfer between multiple regions at different speeds could improve generalization.","Third, we suggest that dreaming might contribute to forming efficient representations analogous to state-of-art machine learning methods.","We finally discuss how these points could be further developed, emphasizing the connections to experimental neuroscience and machine learning."],"url":"http://arxiv.org/abs/2304.02873v1"}
{"created":"2023-04-06","title":"Protecting User Privacy in Online Settings via Supervised Learning","abstract":"Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit. Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money. However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics. The problem is the sale of user data to third parties. In this work, we design an intelligent approach to online privacy protection that leverages supervised learning. By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user. In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm. The results of our evaluation demonstrate the feasibility and potential of our approach.","sentences":["Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit.","Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money.","However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics.","The problem is the sale of user data to third parties.","In this work, we design an intelligent approach to online privacy protection that leverages supervised learning.","By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user.","In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm.","The results of our evaluation demonstrate the feasibility and potential of our approach."],"url":"http://arxiv.org/abs/2304.02870v1"}
{"created":"2023-04-06","title":"Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions","abstract":"Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.","sentences":["Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users.","In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world.","Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.","Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing."],"url":"http://arxiv.org/abs/2304.02868v1"}
{"created":"2023-04-06","title":"Learning to Learn with Indispensable Connections","abstract":"Meta-learning aims to solve unseen tasks with few labelled instances. Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws. Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network. Because of this, meta-testing observes unnecessary computations and extra memory overhead. To overcome such flaws. We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections. We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem. We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase. Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets. Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset.","sentences":["Meta-learning aims to solve unseen tasks with few labelled instances.","Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws.","Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network.","Because of this, meta-testing observes unnecessary computations and extra memory overhead.","To overcome such flaws.","We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections.","We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem.","We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase.","Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets.","Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset."],"url":"http://arxiv.org/abs/2304.02862v1"}
{"created":"2023-04-06","title":"A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation","abstract":"Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets. The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets. These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications.","sentences":["Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes.","Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems.","In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs).","A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review.","In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems.","We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems.","Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets.","The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets.","These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications."],"url":"http://arxiv.org/abs/2304.02858v1"}
{"created":"2023-04-06","title":"Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification","abstract":"A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.","sentences":["A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood.","This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples.","Intuitively, this behavior can improve robustness against label noise by reducing overfitting.","We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties.","We evaluate the effectiveness of the method by measuring its robustness against label noise in classification.","We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more."],"url":"http://arxiv.org/abs/2304.02849v1"}
{"created":"2023-04-06","title":"Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets","abstract":"Deep networks have achieved impressive results on a range of well-curated benchmark datasets. Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance. In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features. We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet. It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations. We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline.","sentences":["Deep networks have achieved impressive results on a range of well-curated benchmark datasets.","Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance.","In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features.","We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet.","It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations.","We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline."],"url":"http://arxiv.org/abs/2304.02847v1"}
{"created":"2023-04-06","title":"Robust Neural Architecture Search","abstract":"Neural Architectures Search (NAS) becomes more and more popular over these years. However, NAS-generated models tends to suffer greater vulnerability to various malicious attacks. Lots of robust NAS methods leverage adversarial training to enhance the robustness of NAS-generated models, however, they neglected the nature accuracy of NAS-generated models. In our paper, we propose a novel NAS method, Robust Neural Architecture Search (RNAS). To design a regularization term to balance accuracy and robustness, RNAS generates architectures with both high accuracy and good robustness. To reduce search cost, we further propose to use noise examples instead adversarial examples as input to search architectures. Extensive experiments show that RNAS achieves state-of-the-art (SOTA) performance on both image classification and adversarial attacks, which illustrates the proposed RNAS achieves a good tradeoff between robustness and accuracy.","sentences":["Neural Architectures Search (NAS) becomes more and more popular over these years.","However, NAS-generated models tends to suffer greater vulnerability to various malicious attacks.","Lots of robust NAS methods leverage adversarial training to enhance the robustness of NAS-generated models, however, they neglected the nature accuracy of NAS-generated models.","In our paper, we propose a novel NAS method, Robust Neural Architecture Search (RNAS).","To design a regularization term to balance accuracy and robustness, RNAS generates architectures with both high accuracy and good robustness.","To reduce search cost, we further propose to use noise examples instead adversarial examples as input to search architectures.","Extensive experiments show that RNAS achieves state-of-the-art (SOTA) performance on both image classification and adversarial attacks, which illustrates the proposed RNAS achieves a good tradeoff between robustness and accuracy."],"url":"http://arxiv.org/abs/2304.02845v1"}
{"created":"2023-04-06","title":"NTK-SAP: Improving neural network pruning by aligning training dynamics","abstract":"Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent. In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well. We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP). Empirically, our method achieves better performance than all baselines on multiple datasets.","sentences":["Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory.","One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice.","Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK.","Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK.","This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart.","However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase.","We further propose to sample multiple realizations of random weights to estimate the NTK spectrum.","Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent.","In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well.","We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP).","Empirically, our method achieves better performance than all baselines on multiple datasets."],"url":"http://arxiv.org/abs/2304.02840v1"}
{"created":"2023-04-06","title":"TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph","abstract":"APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.","sentences":["APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT).","To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection.","Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks.","Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score.","To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline.","Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method."],"url":"http://arxiv.org/abs/2304.02838v1"}
{"created":"2023-04-06","title":"Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification","abstract":"The accuracy of predictive models for solitary pulmonary nodule (SPN) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (EHRs). However, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning. In this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected EHRs for SPN classification. We perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (CT) scans. Our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest CTs, billing codes, medications, and laboratory tests from EHRs of our home institution. Evaluation on 227 subjects with challenging SPNs revealed a significant AUC improvement over a longitudinal multimodal baseline (0.824 vs 0.752 AUC), as well as improvements over a single cross-section multimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741 AUC). This work demonstrates significant advantages with a novel approach for co-learning longitudinal imaging and non-imaging phenotypes with transformers.","sentences":["The accuracy of predictive models for solitary pulmonary nodule (SPN) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (EHRs).","However, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning.","In this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected EHRs for SPN classification.","We perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (CT) scans.","Our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest CTs, billing codes, medications, and laboratory tests from EHRs of our home institution.","Evaluation on 227 subjects with challenging SPNs revealed a significant AUC improvement over a longitudinal multimodal baseline (0.824 vs 0.752 AUC), as well as improvements over a single cross-section multimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741 AUC).","This work demonstrates significant advantages with a novel approach for co-learning longitudinal imaging and non-imaging phenotypes with transformers."],"url":"http://arxiv.org/abs/2304.02836v1"}
{"created":"2023-04-06","title":"GIF: A General Graph Unlearning Strategy via Influence Function","abstract":"With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention. However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning. We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature. Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data. The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency. Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism. We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency. Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}.","sentences":["With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention.","However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   ","In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning.","We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature.","Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data.","The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency.","Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism.","We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency.","Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}."],"url":"http://arxiv.org/abs/2304.02835v1"}
{"created":"2023-04-06","title":"Probing the Purview of Neural Networks via Gradient Analysis","abstract":"We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference. The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data. We define purview as the additional capacity necessary to characterize inference samples that differ from the training data. To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately. To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels. We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features. We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples. Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.","sentences":["We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference.","The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data.","We define purview as the additional capacity necessary to characterize inference samples that differ from the training data.","To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately.","To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels.","We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features.","We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples.","Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively."],"url":"http://arxiv.org/abs/2304.02834v1"}
{"created":"2023-04-06","title":"Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing","abstract":"In the traditional vehicular network, computing tasks generated by the vehicles are usually uploaded to the cloud for processing. However, since task offloading toward the cloud will cause a large delay, vehicular edge computing (VEC) is introduced to avoid such a problem and improve the whole system performance, where a roadside unit (RSU) with certain computing capability is used to process the data of vehicles as an edge entity. Owing to the privacy and security issues, vehicles are reluctant to upload local data directly to the RSU, and thus federated learning (FL) becomes a promising technology for some machine learning tasks in VEC, where vehicles only need to upload the local model hyperparameters instead of transferring their local data to the nearby RSU. Furthermore, as vehicles have different local training time due to various sizes of local data and their different computing capabilities, asynchronous federated learning (AFL) is employed to facilitate the RSU to update the global model immediately after receiving a local model to reduce the aggregation delay. However, in AFL of VEC, different vehicles may have different impact on the global model updating because of their various local training delay, transmission delay and local data sizes. Also, if there are bad nodes among the vehicles, it will affect the global aggregation quality at the RSU. To solve the above problem, we shall propose a deep reinforcement learning (DRL) based vehicle selection scheme to improve the accuracy of the global model in AFL of vehicular network. In the scheme, we present the model including the state, action and reward in the DRL based to the specific problem. Simulation results demonstrate our scheme can effectively remove the bad nodes and improve the aggregation accuracy of the global model.","sentences":["In the traditional vehicular network, computing tasks generated by the vehicles are usually uploaded to the cloud for processing.","However, since task offloading toward the cloud will cause a large delay, vehicular edge computing (VEC) is introduced to avoid such a problem and improve the whole system performance, where a roadside unit (RSU) with certain computing capability is used to process the data of vehicles as an edge entity.","Owing to the privacy and security issues, vehicles are reluctant to upload local data directly to the RSU, and thus federated learning (FL) becomes a promising technology for some machine learning tasks in VEC, where vehicles only need to upload the local model hyperparameters instead of transferring their local data to the nearby RSU.","Furthermore, as vehicles have different local training time due to various sizes of local data and their different computing capabilities, asynchronous federated learning (AFL) is employed to facilitate the RSU to update the global model immediately after receiving a local model to reduce the aggregation delay.","However, in AFL of VEC, different vehicles may have different impact on the global model updating because of their various local training delay, transmission delay and local data sizes.","Also, if there are bad nodes among the vehicles, it will affect the global aggregation quality at the RSU.","To solve the above problem, we shall propose a deep reinforcement learning (DRL) based vehicle selection scheme to improve the accuracy of the global model in AFL of vehicular network.","In the scheme, we present the model including the state, action and reward in the DRL based to the specific problem.","Simulation results demonstrate our scheme can effectively remove the bad nodes and improve the aggregation accuracy of the global model."],"url":"http://arxiv.org/abs/2304.02832v1"}
{"created":"2023-04-06","title":"SoK: Machine Learning for Continuous Integration","abstract":"Continuous Integration (CI) has become a well-established software development practice for automatically and continuously integrating code changes during software development. An increasing number of Machine Learning (ML) based approaches for automation of CI phases are being reported in the literature. It is timely and relevant to provide a Systemization of Knowledge (SoK) of ML-based approaches for CI phases. This paper reports an SoK of different aspects of the use of ML for CI. Our systematic analysis also highlights the deficiencies of the existing ML-based solutions that can be improved for advancing the state-of-the-art.","sentences":["Continuous Integration (CI) has become a well-established software development practice for automatically and continuously integrating code changes during software development.","An increasing number of Machine Learning (ML) based approaches for automation of CI phases are being reported in the literature.","It is timely and relevant to provide a Systemization of Knowledge (SoK) of ML-based approaches for CI phases.","This paper reports an SoK of different aspects of the use of ML for CI.","Our systematic analysis also highlights the deficiencies of the existing ML-based solutions that can be improved for advancing the state-of-the-art."],"url":"http://arxiv.org/abs/2304.02829v1"}
{"created":"2023-04-06","title":"GPT detectors are biased against non-native English writers","abstract":"The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse.","sentences":["The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content.","Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored.","In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers.","Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified.","Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions.","Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse."],"url":"http://arxiv.org/abs/2304.02819v1"}
{"created":"2023-04-06","title":"Causal Repair of Learning-enabled Cyber-physical Systems","abstract":"Models of actual causality leverage domain knowledge to generate convincing diagnoses of events that caused an outcome. It is promising to apply these models to diagnose and repair run-time property violations in cyber-physical systems (CPS) with learning-enabled components (LEC). However, given the high diversity and complexity of LECs, it is challenging to encode domain knowledge (e.g., the CPS dynamics) in a scalable actual causality model that could generate useful repair suggestions. In this paper, we focus causal diagnosis on the input/output behaviors of LECs. Specifically, we aim to identify which subset of I/O behaviors of the LEC is an actual cause for a property violation. An important by-product is a counterfactual version of the LEC that repairs the run-time property by fixing the identified problematic behaviors. Based on this insights, we design a two-step diagnostic pipeline: (1) construct and Halpern-Pearl causality model that reflects the dependency of property outcome on the component's I/O behaviors, and (2) perform a search for an actual cause and corresponding repair on the model. We prove that our pipeline has the following guarantee: if an actual cause is found, the system is guaranteed to be repaired; otherwise, we have high probabilistic confidence that the LEC under analysis did not cause the property violation. We demonstrate that our approach successfully repairs learned controllers on a standard OpenAI Gym benchmark.","sentences":["Models of actual causality leverage domain knowledge to generate convincing diagnoses of events that caused an outcome.","It is promising to apply these models to diagnose and repair run-time property violations in cyber-physical systems (CPS) with learning-enabled components (LEC).","However, given the high diversity and complexity of LECs, it is challenging to encode domain knowledge (e.g., the CPS dynamics) in a scalable actual causality model that could generate useful repair suggestions.","In this paper, we focus causal diagnosis on the input/output behaviors of LECs.","Specifically, we aim to identify which subset of I/O behaviors of the LEC is an actual cause for a property violation.","An important by-product is a counterfactual version of the LEC that repairs the run-time property by fixing the identified problematic behaviors.","Based on this insights, we design a two-step diagnostic pipeline: (1) construct and Halpern-Pearl causality model that reflects the dependency of property outcome on the component's I/O behaviors, and (2) perform a search for an actual cause and corresponding repair on the model.","We prove that our pipeline has the following guarantee: if an actual cause is found, the system is guaranteed to be repaired; otherwise, we have high probabilistic confidence that the LEC under analysis did not cause the property violation.","We demonstrate that our approach successfully repairs learned controllers on a standard OpenAI Gym benchmark."],"url":"http://arxiv.org/abs/2304.02813v1"}
{"created":"2023-04-06","title":"HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions","abstract":"Due to the complex behavior arising from non-uniqueness, symmetry, and bifurcations in the solution space, solving inverse problems of nonlinear differential equations (DEs) with multiple solutions is a challenging task. To address this issue, we propose homotopy physics-informed neural networks (HomPINNs), a novel framework that leverages homotopy continuation and neural networks (NNs) to solve inverse problems. The proposed framework begins with the use of a NN to simultaneously approximate known observations and conform to the constraints of DEs. By utilizing the homotopy continuation method, the approximation traces the observations to identify multiple solutions and solve the inverse problem. The experiments involve testing the performance of the proposed method on one-dimensional DEs and applying it to solve a two-dimensional Gray-Scott simulation. Our findings demonstrate that the proposed method is scalable and adaptable, providing an effective solution for solving DEs with multiple solutions and unknown parameters. Moreover, it has significant potential for various applications in scientific computing, such as modeling complex systems and solving inverse problems in physics, chemistry, biology, etc.","sentences":["Due to the complex behavior arising from non-uniqueness, symmetry, and bifurcations in the solution space, solving inverse problems of nonlinear differential equations (DEs) with multiple solutions is a challenging task.","To address this issue, we propose homotopy physics-informed neural networks (HomPINNs), a novel framework that leverages homotopy continuation and neural networks (NNs) to solve inverse problems.","The proposed framework begins with the use of a NN to simultaneously approximate known observations and conform to the constraints of DEs.","By utilizing the homotopy continuation method, the approximation traces the observations to identify multiple solutions and solve the inverse problem.","The experiments involve testing the performance of the proposed method on one-dimensional DEs and applying it to solve a two-dimensional Gray-Scott simulation.","Our findings demonstrate that the proposed method is scalable and adaptable, providing an effective solution for solving DEs with multiple solutions and unknown parameters.","Moreover, it has significant potential for various applications in scientific computing, such as modeling complex systems and solving inverse problems in physics, chemistry, biology, etc."],"url":"http://arxiv.org/abs/2304.02811v1"}
{"created":"2023-04-06","title":"Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit Diversity Modeling","abstract":"Graph neural networks (GNNs) have been widely applied to learning over graph data. Yet, real-world graphs commonly exhibit diverse graph structures and contain heterogeneous nodes and edges. Moreover, to enhance the generalization ability of GNNs, it has become common practice to further increase the diversity of training graph structures by incorporating graph augmentations and/or performing large-scale pre-training on more graphs. Therefore, it becomes essential for a GNN to simultaneously model diverse graph structures. Yet, naively increasing the GNN model capacity will suffer from both higher inference costs and the notorious trainability issue of GNNs. This paper introduces the Mixture-of-Expert (MoE) idea to GNNs, aiming to enhance their ability to accommodate the diversity of training graph structures, without incurring computational overheads. Our new Graph Mixture of Expert (GMoE) model enables each node in the graph to dynamically select its own optimal \\textit{information aggregation experts}. These experts are trained to model different subgroups of graph structures in the training set. Additionally, GMoE includes information aggregation experts with varying aggregation hop sizes, where the experts with larger hop sizes are specialized in capturing information over longer ranges. The effectiveness of GMoE is verified through experimental results on a large variety of graph, node, and link prediction tasks in the OGB benchmark. For instance, it enhances ROC-AUC by $1.81\\%$ in ogbg-molhiv and by $1.40\\%$ in ogbg-molbbbp, as compared to the non-MoE baselines. Our code is available at https://github.com/VITA-Group/Graph-Mixture-of-Experts.","sentences":["Graph neural networks (GNNs) have been widely applied to learning over graph data.","Yet, real-world graphs commonly exhibit diverse graph structures and contain heterogeneous nodes and edges.","Moreover, to enhance the generalization ability of GNNs, it has become common practice to further increase the diversity of training graph structures by incorporating graph augmentations and/or performing large-scale pre-training on more graphs.","Therefore, it becomes essential for a GNN to simultaneously model diverse graph structures.","Yet, naively increasing the GNN model capacity will suffer from both higher inference costs and the notorious trainability issue of GNNs.","This paper introduces the Mixture-of-Expert (MoE) idea to GNNs, aiming to enhance their ability to accommodate the diversity of training graph structures, without incurring computational overheads.","Our new Graph Mixture of Expert (GMoE) model enables each node in the graph to dynamically select its own optimal \\textit{information aggregation experts}.","These experts are trained to model different subgroups of graph structures in the training set.","Additionally, GMoE includes information aggregation experts with varying aggregation hop sizes, where the experts with larger hop sizes are specialized in capturing information over longer ranges.","The effectiveness of GMoE is verified through experimental results on a large variety of graph, node, and link prediction tasks in the OGB benchmark.","For instance, it enhances ROC-AUC by $1.81\\%$ in ogbg-molhiv and by $1.40\\%$ in ogbg-molbbbp, as compared to the non-MoE baselines.","Our code is available at https://github.com/VITA-Group/Graph-Mixture-of-Experts."],"url":"http://arxiv.org/abs/2304.02806v1"}
{"created":"2023-04-06","title":"Source-free Domain Adaptation Requires Penalized Diversity","abstract":"While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset. Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy. Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains. In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor. Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA). Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses. Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy. Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift. In addition, PD is augmented with a weighted MI maximization objective for label distribution shift. Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts.","sentences":["While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset.","Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy.","Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains.","In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor.","Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA).","Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses.","Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy.","Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift.","In addition, PD is augmented with a weighted MI maximization objective for label distribution shift.","Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts."],"url":"http://arxiv.org/abs/2304.02798v1"}
{"created":"2023-04-05","title":"UNICORN: A Unified Backdoor Trigger Inversion Framework","abstract":"The backdoor attack, where the adversary uses inputs stamped with triggers (e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat to Deep Neural Network (DNN) models. Trigger inversion is an effective way of identifying backdoor models and understanding embedded adversarial behaviors. A challenge of trigger inversion is that there are many ways of constructing the trigger. Existing methods cannot generalize to various types of triggers by making certain assumptions or attack-specific constraints. The fundamental reason is that existing work does not consider the trigger's design space in their formulation of the inversion problem. This work formally defines and analyzes the triggers injected in different spaces and the inversion problem. Then, it proposes a unified framework to invert backdoor triggers based on the formalization of triggers and the identified inner behaviors of backdoor models from our analysis. Our prototype UNICORN is general and effective in inverting backdoor triggers in DNNs. The code can be found at https://github.com/RU-System-Software-and-Security/UNICORN.","sentences":["The backdoor attack, where the adversary uses inputs stamped with triggers (e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat to Deep Neural Network (DNN) models.","Trigger inversion is an effective way of identifying backdoor models and understanding embedded adversarial behaviors.","A challenge of trigger inversion is that there are many ways of constructing the trigger.","Existing methods cannot generalize to various types of triggers by making certain assumptions or attack-specific constraints.","The fundamental reason is that existing work does not consider the trigger's design space in their formulation of the inversion problem.","This work formally defines and analyzes the triggers injected in different spaces and the inversion problem.","Then, it proposes a unified framework to invert backdoor triggers based on the formalization of triggers and the identified inner behaviors of backdoor models from our analysis.","Our prototype UNICORN is general and effective in inverting backdoor triggers in DNNs.","The code can be found at https://github.com/RU-System-Software-and-Security/UNICORN."],"url":"http://arxiv.org/abs/2304.02786v1"}
{"created":"2023-04-05","title":"Performance of Data Augmentation Methods for Brazilian Portuguese Text Classification","abstract":"Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers. Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora. In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora. As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity.","sentences":["Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers.","Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora.","In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora.","As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity."],"url":"http://arxiv.org/abs/2304.02785v1"}
{"created":"2023-04-05","title":"A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors","abstract":"Liver transplantation is a life-saving procedure for patients with end-stage liver disease. There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations. The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days. However, the donor-patient matching should also take into consideration post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant. Accurate prediction of these risk scores remains a significant challenge. In this study, we will use predictive models to solve the above challenge. We propose a deep learning framework model to predict multiple risk factors after a liver transplant. By formulating it as a multi-task learning problem, the proposed deep neural network was trained on this data to simultaneously predict the five post-transplant risks and achieve equally good performance by leveraging task balancing techniques. We also propose a novel fairness achieving algorithm and to ensure prediction fairness across different subpopulations. We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018. The performance of the model was evaluated using various performance metrics such as AUROC, AURPC, and accuracy. The results of our experiments demonstrate that the proposed multitask prediction model achieved high accuracy and good balance in predicting all five post-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%. The fairness-achieving algorithm significantly reduced the fairness disparity compared to the baseline model.","sentences":["Liver transplantation is a life-saving procedure for patients with end-stage liver disease.","There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations.","The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days.","However, the donor-patient matching should also take into consideration post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant.","Accurate prediction of these risk scores remains a significant challenge.","In this study, we will use predictive models to solve the above challenge.","We propose a deep learning framework model to predict multiple risk factors after a liver transplant.","By formulating it as a multi-task learning problem, the proposed deep neural network was trained on this data to simultaneously predict the five post-transplant risks and achieve equally good performance by leveraging task balancing techniques.","We also propose a novel fairness achieving algorithm and to ensure prediction fairness across different subpopulations.","We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018.","The performance of the model was evaluated using various performance metrics such as AUROC, AURPC, and accuracy.","The results of our experiments demonstrate that the proposed multitask prediction model achieved high accuracy and good balance in predicting all five post-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%.","The fairness-achieving algorithm significantly reduced the fairness disparity compared to the baseline model."],"url":"http://arxiv.org/abs/2304.02780v1"}
{"created":"2023-04-05","title":"Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review","abstract":"The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis. This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks. To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field. In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis. The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format. The paper presents some limitations of current research and some recommendations for further research.","sentences":["The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis.","This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks.","To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field.","In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis.","The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format.","The paper presents some limitations of current research and some recommendations for further research."],"url":"http://arxiv.org/abs/2304.02768v1"}
{"created":"2023-04-05","title":"MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection","abstract":"Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methane plume sites. Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact. Dataset and source code are public","sentences":["Methane (CH$_4$) is the chief contributor to global climate change.","Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions.","Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable.","To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions.","MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately.","Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art.","In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022.","It contains over 4000 methane plume sites.","Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact.","Dataset and source code are public"],"url":"http://arxiv.org/abs/2304.02767v1"}
{"created":"2023-04-05","title":"The Saudi Privacy Policy Dataset","abstract":"This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide. Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia. The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB. The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations. By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia.","sentences":["This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide.","Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia.","The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB.","The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations.","By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia."],"url":"http://arxiv.org/abs/2304.02757v1"}
{"created":"2023-04-05","title":"Hybrid Zonotopes Exactly Represent ReLU Neural Networks","abstract":"We show that hybrid zonotopes offer an equivalent representation of feed-forward fully connected neural networks with ReLU activation functions. Our approach demonstrates that the complexity of binary variables is equal to the total number of neurons in the network and hence grows linearly in the size of the network. We demonstrate the utility of the hybrid zonotope formulation through three case studies including nonlinear function approximation, MPC closed-loop reachability and verification, and robustness of classification on the MNIST dataset.","sentences":["We show that hybrid zonotopes offer an equivalent representation of feed-forward fully connected neural networks with ReLU activation functions.","Our approach demonstrates that the complexity of binary variables is equal to the total number of neurons in the network and hence grows linearly in the size of the network.","We demonstrate the utility of the hybrid zonotope formulation through three case studies including nonlinear function approximation, MPC closed-loop reachability and verification, and robustness of classification on the MNIST dataset."],"url":"http://arxiv.org/abs/2304.02755v1"}
{"created":"2023-04-05","title":"Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models","abstract":"Neural network models of language have long been used as a tool for developing hypotheses about conceptual representation in the mind and brain. For many years, such use involved extracting vector-space representations of words and using distances among these to predict or understand human behavior in various semantic tasks. In contemporary language AIs, however, it is possible to interrogate the latent structure of conceptual representations using methods nearly identical to those commonly used with human participants. The current work uses two common techniques borrowed from cognitive psychology to estimate and compare lexical-semantic structure in both humans and a well-known AI, the DaVinci variant of GPT-3. In humans, we show that conceptual structure is robust to differences in culture, language, and method of estimation. Structures estimated from AI behavior, while individually fairly consistent with those estimated from human behavior, depend much more upon the particular task used to generate behavior responses--responses generated by the very same model in the two tasks yield estimates of conceptual structure that cohere less with one another than do human structure estimates. The results suggest one important way that knowledge inhering in contemporary AIs can differ from human cognition.","sentences":["Neural network models of language have long been used as a tool for developing hypotheses about conceptual representation in the mind and brain.","For many years, such use involved extracting vector-space representations of words and using distances among these to predict or understand human behavior in various semantic tasks.","In contemporary language AIs, however, it is possible to interrogate the latent structure of conceptual representations using methods nearly identical to those commonly used with human participants.","The current work uses two common techniques borrowed from cognitive psychology to estimate and compare lexical-semantic structure in both humans and a well-known AI, the DaVinci variant of GPT-3.","In humans, we show that conceptual structure is robust to differences in culture, language, and method of estimation.","Structures estimated from AI behavior, while individually fairly consistent with those estimated from human behavior, depend much more upon the particular task used to generate behavior responses--responses generated by the very same model in the two tasks yield estimates of conceptual structure that cohere less with one another than do human structure estimates.","The results suggest one important way that knowledge inhering in contemporary AIs can differ from human cognition."],"url":"http://arxiv.org/abs/2304.02754v1"}
{"created":"2023-04-05","title":"Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks","abstract":"This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy. The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups. Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology.","sentences":["This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data.","With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information.","Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali.","We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy.","The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups.","Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology."],"url":"http://arxiv.org/abs/2304.02739v1"}
{"created":"2023-04-05","title":"Core Challenges in Embodied Vision-Language Planning","abstract":"Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks. Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment.","sentences":["Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics.","Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three.","Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field.","In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments.","We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.","Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment."],"url":"http://arxiv.org/abs/2304.02738v1"}
{"created":"2023-04-05","title":"Learning Stability Attention in Vision-based End-to-end Driving Policies","abstract":"Modern end-to-end learning systems can learn to explicitly infer control from perception. However, it is difficult to guarantee stability and robustness for these systems since they are often exposed to unstructured, high-dimensional, and complex observation spaces (e.g., autonomous driving from a stream of pixel inputs). We propose to leverage control Lyapunov functions (CLFs) to equip end-to-end vision-based policies with stability properties and introduce stability attention in CLFs (att-CLFs) to tackle environmental changes and improve learning flexibility. We also present an uncertainty propagation technique that is tightly integrated into att-CLFs. We demonstrate the effectiveness of att-CLFs via comparison with classical CLFs, model predictive control, and vanilla end-to-end learning in a photo-realistic simulator and on a real full-scale autonomous vehicle.","sentences":["Modern end-to-end learning systems can learn to explicitly infer control from perception.","However, it is difficult to guarantee stability and robustness for these systems since they are often exposed to unstructured, high-dimensional, and complex observation spaces (e.g., autonomous driving from a stream of pixel inputs).","We propose to leverage control Lyapunov functions (CLFs) to equip end-to-end vision-based policies with stability properties and introduce stability attention in CLFs (att-CLFs) to tackle environmental changes and improve learning flexibility.","We also present an uncertainty propagation technique that is tightly integrated into att-CLFs.","We demonstrate the effectiveness of att-CLFs via comparison with classical CLFs, model predictive control, and vanilla end-to-end learning in a photo-realistic simulator and on a real full-scale autonomous vehicle."],"url":"http://arxiv.org/abs/2304.02733v1"}
{"created":"2023-04-05","title":"A Quantum-Chemical Bonding Database for Solid-State Materials","abstract":"An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials. Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties. Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis. With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data. We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database. The database structure of the bonding analysis database, which allows easy data retrieval, is also explained. The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively. Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features.","sentences":["An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials.","Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties.","Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis.","With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data.","We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database.","The database structure of the bonding analysis database, which allows easy data retrieval, is also explained.","The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively.","Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features."],"url":"http://arxiv.org/abs/2304.02726v1"}
{"created":"2023-04-05","title":"FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation","abstract":"Accurate medical imaging segmentation is critical for precise and effective medical interventions. However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales. These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge. In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors. Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges. Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency. These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation.","sentences":["Accurate medical imaging segmentation is critical for precise and effective medical interventions.","However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales.","These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge.","In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors.","Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges.","Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency.","These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation."],"url":"http://arxiv.org/abs/2304.02725v1"}
{"created":"2023-04-05","title":"Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound","abstract":"Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging. This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images. We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound. The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights. Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation. To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound.","sentences":["Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging.","This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images.","We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound.","The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights.","Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation.","To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound."],"url":"http://arxiv.org/abs/2304.02724v1"}
{"created":"2023-04-05","title":"Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning","abstract":"Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt.","sentences":["Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation.","AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   ","Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema.","Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema.","SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   ","We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs.","Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data.","This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   ","SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt."],"url":"http://arxiv.org/abs/2304.02711v1"}
{"created":"2023-04-05","title":"Agnostic proper learning of monotone functions: beyond the black-box correction barrier","abstract":"We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this gap in our knowledge between the run-time and sample complexity.   This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs. This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels.","sentences":["We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions.","Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function.","The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15).","We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient.","Our work thus closes this gap in our knowledge between the run-time and sample complexity.   ","This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs.","This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   ","Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels."],"url":"http://arxiv.org/abs/2304.02700v1"}
{"created":"2023-04-05","title":"Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data Work","abstract":"Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional. However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when. In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes. We present a rigorous methodology for its creation and discuss its transferability to the visual design process. We operationalize the taxonomy through the development of AutoMLTrace, a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work. Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team. Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work.","sentences":["Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional.","However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when.","In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes.","We present a rigorous methodology for its creation and discuss its transferability to the visual design process.","We operationalize the taxonomy through the development of AutoMLTrace, a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work.","Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team.","Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work."],"url":"http://arxiv.org/abs/2304.02699v1"}
{"created":"2023-04-05","title":"Revolutionizing Single Cell Analysis: The Power of Large Language Models for Cell Type Annotation","abstract":"In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function. However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function. The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types. This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation. By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked. This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences. Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis.","sentences":["In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function.","However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function.","The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types.","This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation.","By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked.","This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences.","Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis."],"url":"http://arxiv.org/abs/2304.02697v1"}
{"created":"2023-04-05","title":"A Certified Radius-Guided Attack Framework to Image Segmentation Models","abstract":"Image segmentation is an important problem in many safety-critical applications. Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models. We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models. Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models. We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models. Specifically, we first adapt randomized smoothing, the state-of-the-art certification method for classification models, to derive the pixel's certified radius. We then focus more on disrupting pixels with relatively smaller certified radii and design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack. Next, we propose the first black-box attack to image segmentation models via bandit. We design a novel gradient estimator, based on bandit feedback, which is query-efficient and provably unbiased and stable. We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack, as well as a certified radius-guided PBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate. We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets. Our results validate the effectiveness of our certified radius-guided attack framework.","sentences":["Image segmentation is an important problem in many safety-critical applications.","Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models.","We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models.","Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models.","We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models.","Specifically, we first adapt randomized smoothing, the state-of-the-art certification method for classification models, to derive the pixel's certified radius.","We then focus more on disrupting pixels with relatively smaller certified radii and design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack.","Next, we propose the first black-box attack to image segmentation models via bandit.","We design a novel gradient estimator, based on bandit feedback, which is query-efficient and provably unbiased and stable.","We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack, as well as a certified radius-guided PBGD (CR-PBGD) attack.","We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate.","We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets.","Our results validate the effectiveness of our certified radius-guided attack framework."],"url":"http://arxiv.org/abs/2304.02693v1"}
{"created":"2023-04-05","title":"ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast","abstract":"Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects). Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria. However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced. In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation. Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers. Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes. Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings. Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency.","sentences":["Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects).","Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria.","However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced.","In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation.","Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers.","Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes.","Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings.","Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency."],"url":"http://arxiv.org/abs/2304.02689v1"}
{"created":"2023-04-05","title":"Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability","abstract":"Transferability is the property of adversarial examples to be misclassified by other models than the surrogate model for which they were crafted. Previous research has shown that transferability is substantially increased when the training of the surrogate model has been early stopped. A common hypothesis to explain this is that the later training epochs are when models learn the non-robust features that adversarial attacks exploit. Hence, an early stopped model is more robust (hence, a better surrogate) than fully trained models. We demonstrate that the reasons why early stopping improves transferability lie in the side effects it has on the learning dynamics of the model. We first show that early stopping benefits transferability even on models learning from data with non-robust features. We then establish links between transferability and the exploration of the loss landscape in the parameter space, on which early stopping has an inherent effect. More precisely, we observe that transferability peaks when the learning rate decays, which is also the time at which the sharpness of the loss significantly drops. This leads us to propose RFN, a new approach for transferability that minimizes loss sharpness during training in order to maximize transferability. We show that by searching for large flat neighborhoods, RFN always improves over early stopping (by up to 47 points of transferability rate) and is competitive to (if not better than) strong state-of-the-art baselines.","sentences":["Transferability is the property of adversarial examples to be misclassified by other models than the surrogate model for which they were crafted.","Previous research has shown that transferability is substantially increased when the training of the surrogate model has been early stopped.","A common hypothesis to explain this is that the later training epochs are when models learn the non-robust features that adversarial attacks exploit.","Hence, an early stopped model is more robust (hence, a better surrogate) than fully trained models.","We demonstrate that the reasons why early stopping improves transferability lie in the side effects it has on the learning dynamics of the model.","We first show that early stopping benefits transferability even on models learning from data with non-robust features.","We then establish links between transferability and the exploration of the loss landscape in the parameter space, on which early stopping has an inherent effect.","More precisely, we observe that transferability peaks when the learning rate decays, which is also the time at which the sharpness of the loss significantly drops.","This leads us to propose RFN, a new approach for transferability that minimizes loss sharpness during training in order to maximize transferability.","We show that by searching for large flat neighborhoods, RFN always improves over early stopping (by up to 47 points of transferability rate) and is competitive to (if not better than) strong state-of-the-art baselines."],"url":"http://arxiv.org/abs/2304.02688v1"}
{"created":"2023-04-05","title":"Segment Anything","abstract":"We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.","sentences":["We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation.","Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images.","The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.","We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results.","We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision."],"url":"http://arxiv.org/abs/2304.02643v1"}
{"created":"2023-04-05","title":"Self-Distillation for Gaussian Process Regression and Classification","abstract":"We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric. The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration. By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters. Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the model from a Binomial likelihood to a continuous Bernoulli likelihood to be well-specified. To the best of our knowledge, our proposed approaches are the first to formulate knowledge distillation specifically for Gaussian Process models.","sentences":["We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric.","The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration.","By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters.","Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the model from a Binomial likelihood to a continuous Bernoulli likelihood to be well-specified.","To the best of our knowledge, our proposed approaches are the first to formulate knowledge distillation specifically for Gaussian Process models."],"url":"http://arxiv.org/abs/2304.02641v1"}
{"created":"2023-04-05","title":"GenPhys: From Physical Processes to Generative Models","abstract":"Since diffusion models (DM) and the more recent Poisson flow generative models (PFGM) are inspired by physical processes, it is reasonable to ask: Can physical processes offer additional new generative models? We show that the answer is yes. We introduce a general family, Generative Models from Physical Processes (GenPhys), where we translate partial differential equations (PDEs) describing physical processes to generative models. We show that generative models can be constructed from s-generative PDEs (s for smooth). GenPhys subsume the two existing generative models (DM and PFGM) and even give rise to new families of generative models, e.g., \"Yukawa Generative Models\" inspired from weak interactions. On the other hand, some physical processes by default do not belong to the GenPhys family, e.g., the wave equation and the Schr\\\"{o}dinger equation, but could be made into the GenPhys family with some modifications. Our goal with GenPhys is to explore and expand the design space of generative models.","sentences":["Since diffusion models (DM) and the more recent Poisson flow generative models (PFGM) are inspired by physical processes, it is reasonable to ask: Can physical processes offer additional new generative models?","We show that the answer is yes.","We introduce a general family, Generative Models from Physical Processes (GenPhys), where we translate partial differential equations (PDEs) describing physical processes to generative models.","We show that generative models can be constructed from s-generative PDEs (s for smooth).","GenPhys subsume the two existing generative models (DM and PFGM) and even give rise to new families of generative models, e.g., \"Yukawa Generative Models\" inspired from weak interactions.","On the other hand, some physical processes by default do not belong to the GenPhys family, e.g., the wave equation and the Schr\\\"{o}dinger equation, but could be made into the GenPhys family with some modifications.","Our goal with GenPhys is to explore and expand the design space of generative models."],"url":"http://arxiv.org/abs/2304.02637v1"}
{"created":"2023-04-05","title":"Mapping historical forest biomass for stock-change assessments at parcel to landscape scales","abstract":"Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios. Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time. Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.   Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches for mapping historical forest aboveground biomass (AGB): training on FIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps (indirect), and an ensemble averaging predictions from the direct and indirect models. Model prediction surfaces (maps) were tested against FIA estimates at multiple scales. All three approaches produced viable outputs, yet tradeoffs were evident in terms of model complexity, map accuracy, saturation, and fine-scale pattern representation. The resulting map products can help identify where, when, and how forest carbon stocks are changing as a result of both anthropogenic and natural drivers alike. These products can thus serve as inputs to a wide range of applications including stock-change assessments, monitoring reporting and verification frameworks, and prioritizing parcels for protection or enrollment in improved management programs.","sentences":["Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios.","Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time.","Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.   ","Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches for mapping historical forest aboveground biomass (AGB): training on FIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps (indirect), and an ensemble averaging predictions from the direct and indirect models.","Model prediction surfaces (maps) were tested against FIA estimates at multiple scales.","All three approaches produced viable outputs, yet tradeoffs were evident in terms of model complexity, map accuracy, saturation, and fine-scale pattern representation.","The resulting map products can help identify where, when, and how forest carbon stocks are changing as a result of both anthropogenic and natural drivers alike.","These products can thus serve as inputs to a wide range of applications including stock-change assessments, monitoring reporting and verification frameworks, and prioritizing parcels for protection or enrollment in improved management programs."],"url":"http://arxiv.org/abs/2304.02632v1"}
{"created":"2023-04-05","title":"High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation","abstract":"The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior. As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines. This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset. Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting. Our code is available at https://github.com/arvijj/hfpl.","sentences":["The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models.","The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps.","This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions.","The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth.","In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images.","In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior.","As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines.","This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset.","Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting.","Our code is available at https://github.com/arvijj/hfpl."],"url":"http://arxiv.org/abs/2304.02621v1"}
{"created":"2023-04-05","title":"Efficient Quantum Algorithms for Quantum Optimal Control","abstract":"In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem. This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schr\\\"odinger equation. This type of control problem also has an intricate relation with machine learning. Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm. We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schr\\\"odinger equation, the numerical quadrature, and optimization. Our quantum algorithms require fault-tolerant quantum computers.","sentences":["In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem.","This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schr\\\"odinger equation.","This type of control problem also has an intricate relation with machine learning.","Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm.","We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schr\\\"odinger equation, the numerical quadrature, and optimization.","Our quantum algorithms require fault-tolerant quantum computers."],"url":"http://arxiv.org/abs/2304.02613v1"}
{"created":"2023-04-05","title":"Query lower bounds for log-concave sampling","abstract":"Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\\ge 2$ requires $\\Omega(\\log \\kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\\widetilde \\Omega(\\min(\\sqrt\\kappa \\log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this problem, as well as connections to lower bound techniques based on Wishart matrices developed in the matrix-vector query literature.","sentences":["Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one.","In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\\ge 2$ requires $\\Omega(\\log \\kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\\widetilde \\Omega(\\min(\\sqrt\\kappa \\log d, d))$ queries, which is nearly sharp for the class of Gaussians.","Here $\\kappa$ denotes the condition number of the target distribution.","Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this problem, as well as connections to lower bound techniques based on Wishart matrices developed in the matrix-vector query literature."],"url":"http://arxiv.org/abs/2304.02599v1"}
{"created":"2023-04-05","title":"A force-sensing surgical drill for real-time force feedback in robotic mastoidectomy","abstract":"Purpose: Robotic assistance in otologic surgery can reduce the task load of operating surgeons during the removal of bone around the critical structures in the lateral skull base. However, safe deployment into the anatomical passageways necessitates the development of advanced sensing capabilities to actively limit the interaction forces between the surgical tools and critical anatomy.   Methods: We introduce a surgical drill equipped with a force sensor that is capable of measuring accurate tool-tissue interaction forces to enable force control and feedback to surgeons. The design, calibration and validation of the force-sensing surgical drill mounted on a cooperatively controlled surgical robot are described in this work.   Results: The force measurements on the tip of the surgical drill are validated with raw-egg drilling experiments, where a force sensor mounted below the egg serves as ground truth. The average root mean square error (RMSE) for points and path drilling experiments are 41.7 (pm 12.2) mN and 48.3 (pm 13.7) mN respectively.   Conclusions: The force-sensing prototype measures forces with sub-millinewton resolution and the results demonstrate that the calibrated force-sensing drill generates accurate force measurements with minimal error compared to the measured drill forces. The development of such sensing capabilities is crucial for the safe use of robotic systems in a clinical context.","sentences":["Purpose: Robotic assistance in otologic surgery can reduce the task load of operating surgeons during the removal of bone around the critical structures in the lateral skull base.","However, safe deployment into the anatomical passageways necessitates the development of advanced sensing capabilities to actively limit the interaction forces between the surgical tools and critical anatomy.   ","Methods: We introduce a surgical drill equipped with a force sensor that is capable of measuring accurate tool-tissue interaction forces to enable force control and feedback to surgeons.","The design, calibration and validation of the force-sensing surgical drill mounted on a cooperatively controlled surgical robot are described in this work.   ","Results:","The force measurements on the tip of the surgical drill are validated with raw-egg drilling experiments, where a force sensor mounted below the egg serves as ground truth.","The average root mean square error (RMSE) for points and path drilling experiments are 41.7 (pm 12.2) mN and 48.3 (pm 13.7) mN respectively.   ","Conclusions: The force-sensing prototype measures forces with sub-millinewton resolution and the results demonstrate that the calibrated force-sensing drill generates accurate force measurements with minimal error compared to the measured drill forces.","The development of such sensing capabilities is crucial for the safe use of robotic systems in a clinical context."],"url":"http://arxiv.org/abs/2304.02583v1"}
{"created":"2023-04-05","title":"ECG Feature Importance Rankings: Cardiologists vs. Algorithms","abstract":"Feature importance methods promise to provide a ranking of features according to importance for a given classification task. A wide range of methods exist but their rankings often disagree and they are inherently difficult to evaluate due to a lack of ground truth beyond synthetic datasets. In this work, we put feature importance methods to the test on real-world data in the domain of cardiology, where we try to distinguish three specific pathologies from healthy subjects based on ECG features comparing to features used in cardiologists' decision rules as ground truth. Some methods generally performed well and others performed poorly, while some methods did well on some but not all of the problems considered.","sentences":["Feature importance methods promise to provide a ranking of features according to importance for a given classification task.","A wide range of methods exist but their rankings often disagree and they are inherently difficult to evaluate due to a lack of ground truth beyond synthetic datasets.","In this work, we put feature importance methods to the test on real-world data in the domain of cardiology, where we try to distinguish three specific pathologies from healthy subjects based on ECG features comparing to features used in cardiologists' decision rules as ground truth.","Some methods generally performed well and others performed poorly, while some methods did well on some but not all of the problems considered."],"url":"http://arxiv.org/abs/2304.02577v1"}
{"created":"2023-04-05","title":"Conformal Off-Policy Evaluation in Markov Decision Processes","abstract":"Reinforcement Learning aims at identifying and evaluating efficient control policies from data. In many real-world applications, the learner is not allowed to experiment and cannot gather data in an online manner (this is the case when experimenting is expensive, risky or unethical). For such applications, the reward of a given policy (the target policy) must be estimated using historical data gathered under a different policy (the behavior policy). Most methods for this learning task, referred to as Off-Policy Evaluation (OPE), do not come with accuracy and certainty guarantees. We present a novel OPE method based on Conformal Prediction that outputs an interval containing the true reward of the target policy with a prescribed level of certainty. The main challenge in OPE stems from the distribution shift due to the discrepancies between the target and the behavior policies. We propose and empirically evaluate different ways to deal with this shift. Some of these methods yield conformalized intervals with reduced length compared to existing approaches, while maintaining the same certainty level.","sentences":["Reinforcement Learning aims at identifying and evaluating efficient control policies from data.","In many real-world applications, the learner is not allowed to experiment and cannot gather data in an online manner (this is the case when experimenting is expensive, risky or unethical).","For such applications, the reward of a given policy (the target policy) must be estimated using historical data gathered under a different policy (the behavior policy).","Most methods for this learning task, referred to as Off-Policy Evaluation (OPE), do not come with accuracy and certainty guarantees.","We present a novel OPE method based on Conformal Prediction that outputs an interval containing the true reward of the target policy with a prescribed level of certainty.","The main challenge in OPE stems from the distribution shift due to the discrepancies between the target and the behavior policies.","We propose and empirically evaluate different ways to deal with this shift.","Some of these methods yield conformalized intervals with reduced length compared to existing approaches, while maintaining the same certainty level."],"url":"http://arxiv.org/abs/2304.02574v1"}
{"created":"2023-04-05","title":"Optimism Based Exploration in Large-Scale Recommender Systems","abstract":"Bandit learning algorithms have been an increasingly popular design choice for recommender systems. Despite the strong interest in bandit learning from the community, there remains multiple bottlenecks that prevent many bandit learning approaches from productionalization. Two of the most important bottlenecks are scaling to multi-task and A/B testing. Classic bandit algorithms, especially those leveraging contextual information, often requires reward for uncertainty estimation, which hinders their adoptions in multi-task recommender systems. Moreover, different from supervised learning algorithms, bandit learning algorithms emphasize greatly on the data collection process through their explorative nature. Such explorative behavior induces unfair evaluation for bandit learning agents in a classic A/B test setting. In this work, we present a novel design of production bandit learning life-cycle for recommender systems, along with a novel set of metrics to measure their efficiency in user exploration. We show through large-scale production recommender system experiments and in-depth analysis that our bandit agent design improves personalization for the production recommender system and our experiment design fairly evaluates the performance of bandit learning algorithms.","sentences":["Bandit learning algorithms have been an increasingly popular design choice for recommender systems.","Despite the strong interest in bandit learning from the community, there remains multiple bottlenecks that prevent many bandit learning approaches from productionalization.","Two of the most important bottlenecks are scaling to multi-task and A/B testing.","Classic bandit algorithms, especially those leveraging contextual information, often requires reward for uncertainty estimation, which hinders their adoptions in multi-task recommender systems.","Moreover, different from supervised learning algorithms, bandit learning algorithms emphasize greatly on the data collection process through their explorative nature.","Such explorative behavior induces unfair evaluation for bandit learning agents in a classic A/B test setting.","In this work, we present a novel design of production bandit learning life-cycle for recommender systems, along with a novel set of metrics to measure their efficiency in user exploration.","We show through large-scale production recommender system experiments and in-depth analysis that our bandit agent design improves personalization for the production recommender system and our experiment design fairly evaluates the performance of bandit learning algorithms."],"url":"http://arxiv.org/abs/2304.02572v1"}
{"created":"2023-04-05","title":"Self-Supervised Siamese Autoencoders","abstract":"Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire. In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance. The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data. These features are then used as inputs in downstream tasks, such as image classification. Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks. Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set. In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders. We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two self-supervised baselines across multiple data sets, settings, and scenarios. Crucially, this includes conditions in which only a small amount of labeled data is available.","sentences":["Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire.","In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance.","The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data.","These features are then used as inputs in downstream tasks, such as image classification.","Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks.","Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set.","In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders.","We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two self-supervised baselines across multiple data sets, settings, and scenarios.","Crucially, this includes conditions in which only a small amount of labeled data is available."],"url":"http://arxiv.org/abs/2304.02549v1"}
{"created":"2023-04-05","title":"Multi-annotator Deep Learning: A Probabilistic Framework for Classification","abstract":"Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances. A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations. Together with a weighted loss function, we improve the learning from correlated annotation patterns. In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning. Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators.","sentences":["Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data.","However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings.","We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL).","A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach.","The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances.","A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency.","Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations.","Together with a weighted loss function, we improve the learning from correlated annotation patterns.","In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning.","Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators."],"url":"http://arxiv.org/abs/2304.02539v1"}
{"created":"2023-04-05","title":"Goal-Conditioned Imitation Learning using Score-based Diffusion Policies","abstract":"We propose a new policy representation based on score-based diffusion models (SDMs). We apply our new policy representation in the domain of Goal-Conditioned Imitation Learning (GCIL) to learn general-purpose goal-specified policies from large uncurated datasets without rewards. Our new goal-conditioned policy architecture \"$\\textbf{BE}$havior generation with $\\textbf{S}$c$\\textbf{O}$re-based Diffusion Policies\" (BESO) leverages a generative, score-based diffusion model as its policy. BESO decouples the learning of the score model from the inference sampling process, and, hence allows for fast sampling strategies to generate goal-specified behavior in just 3 denoising steps, compared to 30+ steps of other diffusion based policies. Furthermore, BESO is highly expressive and can effectively capture multi-modality present in the solution space of the play data. Unlike previous methods such as Latent Plans or C-Bet, BESO does not rely on complex hierarchical policies or additional clustering for effective goal-conditioned behavior learning. Finally, we show how BESO can even be used to learn a goal-independent policy from play-data using classifier-free guidance. To the best of our knowledge this is the first work that a) represents a behavior policy based on such a decoupled SDM b) learns an SDM based policy in the domain of GCIL and c) provides a way to simultaneously learn a goal-dependent and a goal-independent policy from play-data. We evaluate BESO through detailed simulation and show that it consistently outperforms several state-of-the-art goal-conditioned imitation learning methods on challenging benchmarks. We additionally provide extensive ablation studies and experiments to demonstrate the effectiveness of our method for effective goal-conditioned behavior generation.","sentences":["We propose a new policy representation based on score-based diffusion models (SDMs).","We apply our new policy representation in the domain of Goal-Conditioned Imitation Learning (GCIL) to learn general-purpose goal-specified policies from large uncurated datasets without rewards.","Our new goal-conditioned policy architecture \"$\\textbf{BE}$havior generation with $\\textbf{S}$c$\\textbf{O}$re-based Diffusion Policies\" (BESO) leverages a generative, score-based diffusion model as its policy.","BESO decouples the learning of the score model from the inference sampling process, and, hence allows for fast sampling strategies to generate goal-specified behavior in just 3 denoising steps, compared to 30+ steps of other diffusion based policies.","Furthermore, BESO is highly expressive and can effectively capture multi-modality present in the solution space of the play data.","Unlike previous methods such as Latent Plans or C-Bet, BESO does not rely on complex hierarchical policies or additional clustering for effective goal-conditioned behavior learning.","Finally, we show how BESO can even be used to learn a goal-independent policy from play-data using classifier-free guidance.","To the best of our knowledge this is the first work that a) represents a behavior policy based on such a decoupled SDM b) learns an SDM based policy in the domain of GCIL and c) provides a way to simultaneously learn a goal-dependent and a goal-independent policy from play-data.","We evaluate BESO through detailed simulation and show that it consistently outperforms several state-of-the-art goal-conditioned imitation learning methods on challenging benchmarks.","We additionally provide extensive ablation studies and experiments to demonstrate the effectiveness of our method for effective goal-conditioned behavior generation."],"url":"http://arxiv.org/abs/2304.02532v1"}
{"created":"2023-04-05","title":"Learning to Compare Longitudinal Images","abstract":"Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications. The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing. Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level. This classical approach can suffer from pre-processing issues and limitations of the statistical modeling. For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes. In this paper, we present a simple machine learning-based approach that can alleviate these issues. In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or without supervision. In the self-supervised setup, for instance, the model is trained to temporally order the images, which requires learning to recognize time-irreversible changes. Our results from four datasets demonstrate that PaIRNet can be very effective in localizing and quantifying meaningful longitudinal changes while discounting nuisance variation. Our code is available at \\url{https://github.com/heejong-kim/learning-to-compare-longitudinal-images.git}","sentences":["Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications.","The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing.","Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level.","This classical approach can suffer from pre-processing issues and limitations of the statistical modeling.","For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes.","In this paper, we present a simple machine learning-based approach that can alleviate these issues.","In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or without supervision.","In the self-supervised setup, for instance, the model is trained to temporally order the images, which requires learning to recognize time-irreversible changes.","Our results from four datasets demonstrate that PaIRNet can be very effective in localizing and quantifying meaningful longitudinal changes while discounting nuisance variation.","Our code is available at \\url{https://github.com/heejong-kim/learning-to-compare-longitudinal-images.git}"],"url":"http://arxiv.org/abs/2304.02531v1"}
{"created":"2023-04-05","title":"Constrained Exploration in Reinforcement Learning with Optimality Preservation","abstract":"We consider a class of reinforcement-learning systems in which the agent follows a behavior policy to explore a discrete state-action space to find an optimal policy while adhering to some restriction on its behavior. Such restriction may prevent the agent from visiting some state-action pairs, possibly leading to the agent finding only a sub-optimal policy. To address this problem we introduce the concept of constrained exploration with optimality preservation, whereby the exploration behavior of the agent is constrained to meet a specification while the optimality of the (original) unconstrained learning process is preserved. We first establish a feedback-control structure that models the dynamics of the unconstrained learning process. We then extend this structure by adding a supervisor to ensure that the behavior of the agent meets the specification, and establish (for a class of reinforcement-learning problems with a known deterministic environment) a necessary and sufficient condition under which optimality is preserved. This work demonstrates the utility and the prospect of studying reinforcement-learning problems in the context of the theories of discrete-event systems, automata and formal languages.","sentences":["We consider a class of reinforcement-learning systems in which the agent follows a behavior policy to explore a discrete state-action space to find an optimal policy while adhering to some restriction on its behavior.","Such restriction may prevent the agent from visiting some state-action pairs, possibly leading to the agent finding only a sub-optimal policy.","To address this problem we introduce the concept of constrained exploration with optimality preservation, whereby the exploration behavior of the agent is constrained to meet a specification while the optimality of the (original) unconstrained learning process is preserved.","We first establish a feedback-control structure that models the dynamics of the unconstrained learning process.","We then extend this structure by adding a supervisor to ensure that the behavior of the agent meets the specification, and establish (for a class of reinforcement-learning problems with a known deterministic environment) a necessary and sufficient condition under which optimality is preserved.","This work demonstrates the utility and the prospect of studying reinforcement-learning problems in the context of the theories of discrete-event systems, automata and formal languages."],"url":"http://arxiv.org/abs/2304.03104v1"}
{"created":"2023-04-05","title":"Supporting Energy-Based Learning With An Ising Machine Substrate: A Case Study on RBM","abstract":"Nature apparently does a lot of computation constantly. If we can harness some of that computation at an appropriate level, we can potentially perform certain type of computation (much) faster and more efficiently than we can do with a von Neumann computer. Indeed, many powerful algorithms are inspired by nature and are thus prime candidates for nature-based computation. One particular branch of this effort that has seen some recent rapid advances is Ising machines. Some Ising machines are already showing better performance and energy efficiency for optimization problems. Through design iterations and co-evolution between hardware and algorithm, we expect more benefits from nature-based computing systems. In this paper, we make a case for an augmented Ising machine suitable for both training and inference using an energy-based machine learning algorithm. We show that with a small change, the Ising substrate accelerate key parts of the algorithm and achieve non-trivial speedup and efficiency gain. With a more substantial change, we can turn the machine into a self-sufficient gradient follower to virtually complete training entirely in hardware. This can bring about 29x speedup and about 1000x reduction in energy compared to a Tensor Processing Unit (TPU) host.","sentences":["Nature apparently does a lot of computation constantly.","If we can harness some of that computation at an appropriate level, we can potentially perform certain type of computation (much) faster and more efficiently than we can do with a von Neumann computer.","Indeed, many powerful algorithms are inspired by nature and are thus prime candidates for nature-based computation.","One particular branch of this effort that has seen some recent rapid advances is Ising machines.","Some Ising machines are already showing better performance and energy efficiency for optimization problems.","Through design iterations and co-evolution between hardware and algorithm, we expect more benefits from nature-based computing systems.","In this paper, we make a case for an augmented Ising machine suitable for both training and inference using an energy-based machine learning algorithm.","We show that with a small change, the Ising substrate accelerate key parts of the algorithm and achieve non-trivial speedup and efficiency gain.","With a more substantial change, we can turn the machine into a self-sufficient gradient follower to virtually complete training entirely in hardware.","This can bring about 29x speedup and about 1000x reduction in energy compared to a Tensor Processing Unit (TPU) host."],"url":"http://arxiv.org/abs/2304.02525v1"}
{"created":"2023-04-05","title":"Hyper-parameter Tuning for Adversarially Robust Models","abstract":"This work focuses on the problem of hyper-parameter tuning (HPT) for robust (i.e., adversarially trained) models, with the twofold goal of i) establishing which additional HPs are relevant to tune in adversarial settings, and ii) reducing the cost of HPT for robust models. We pursue the first goal via an extensive experimental study based on 3 recent models widely adopted in the prior literature on adversarial robustness. Our findings show that the complexity of the HPT problem, already notoriously expensive, is exacerbated in adversarial settings due to two main reasons: i) the need of tuning additional HPs which balance standard and adversarial training; ii) the need of tuning the HPs of the standard and adversarial training phases independently. Fortunately, we also identify new opportunities to reduce the cost of HPT for robust models. Specifically, we propose to leverage cheap adversarial training methods to obtain inexpensive, yet highly correlated, estimations of the quality achievable using state-of-the-art methods (PGD). We show that, by exploiting this novel idea in conjunction with a recent multi-fidelity optimizer (taKG), the efficiency of the HPT process can be significantly enhanced.","sentences":["This work focuses on the problem of hyper-parameter tuning (HPT) for robust (i.e., adversarially trained) models, with the twofold goal of i) establishing which additional HPs are relevant to tune in adversarial settings, and ii) reducing the cost of HPT for robust models.","We pursue the first goal via an extensive experimental study based on 3 recent models widely adopted in the prior literature on adversarial robustness.","Our findings show that the complexity of the HPT problem, already notoriously expensive, is exacerbated in adversarial settings due to two main reasons: i) the need of tuning additional HPs which balance standard and adversarial training; ii) the need of tuning the HPs of the standard and adversarial training phases independently.","Fortunately, we also identify new opportunities to reduce the cost of HPT for robust models.","Specifically, we propose to leverage cheap adversarial training methods to obtain inexpensive, yet highly correlated, estimations of the quality achievable using state-of-the-art methods (PGD).","We show that, by exploiting this novel idea in conjunction with a recent multi-fidelity optimizer (taKG), the efficiency of the HPT process can be significantly enhanced."],"url":"http://arxiv.org/abs/2304.02497v1"}
{"created":"2023-04-05","title":"Quantifying the Roles of Visual, Linguistic, and Visual-Linguistic Complexity in Verb Acquisition","abstract":"Children typically learn the meanings of nouns earlier than the meanings of verbs. However, it is unclear whether this asymmetry is a result of complexity in the visual structure of categories in the world to which language refers, the structure of language itself, or the interplay between the two sources of information. We quantitatively test these three hypotheses regarding early verb learning by employing visual and linguistic representations of words sourced from large-scale pre-trained artificial neural networks. Examining the structure of both visual and linguistic embedding spaces, we find, first, that the representation of verbs is generally more variable and less discriminable within domain than the representation of nouns. Second, we find that if only one learning instance per category is available, visual and linguistic representations are less well aligned in the verb system than in the noun system. However, in parallel with the course of human language development, if multiple learning instances per category are available, visual and linguistic representations become almost as well aligned in the verb system as in the noun system. Third, we compare the relative contributions of factors that may predict learning difficulty for individual words. A regression analysis reveals that visual variability is the strongest factor that internally drives verb learning, followed by visual-linguistic alignment and linguistic variability. Based on these results, we conclude that verb acquisition is influenced by all three sources of complexity, but that the variability of visual structure poses the most significant challenge for verb learning.","sentences":["Children typically learn the meanings of nouns earlier than the meanings of verbs.","However, it is unclear whether this asymmetry is a result of complexity in the visual structure of categories in the world to which language refers, the structure of language itself, or the interplay between the two sources of information.","We quantitatively test these three hypotheses regarding early verb learning by employing visual and linguistic representations of words sourced from large-scale pre-trained artificial neural networks.","Examining the structure of both visual and linguistic embedding spaces, we find, first, that the representation of verbs is generally more variable and less discriminable within domain than the representation of nouns.","Second, we find that if only one learning instance per category is available, visual and linguistic representations are less well aligned in the verb system than in the noun system.","However, in parallel with the course of human language development, if multiple learning instances per category are available, visual and linguistic representations become almost as well aligned in the verb system as in the noun system.","Third, we compare the relative contributions of factors that may predict learning difficulty for individual words.","A regression analysis reveals that visual variability is the strongest factor that internally drives verb learning, followed by visual-linguistic alignment and linguistic variability.","Based on these results, we conclude that verb acquisition is influenced by all three sources of complexity, but that the variability of visual structure poses the most significant challenge for verb learning."],"url":"http://arxiv.org/abs/2304.02492v1"}
{"created":"2023-04-05","title":"Opening the random forest black box by the analysis of the mutual impact of features","abstract":"Random forest is a popular machine learning approach for the analysis of high-dimensional data because it is flexible and provides variable importance measures for the selection of relevant features. However, the complex relationships between the features are usually not considered for the selection and thus also neglected for the characterization of the analysed samples. Here we propose two novel approaches that focus on the mutual impact of features in random forests. Mutual forest impact (MFI) is a relation parameter that evaluates the mutual association of the featurs to the outcome and, hence, goes beyond the analysis of correlation coefficients. Mutual impurity reduction (MIR) is an importance measure that combines this relation parameter with the importance of the individual features. MIR and MFI are implemented together with testing procedures that generate p-values for the selection of related and important features. Applications to various simulated data sets and the comparison to other methods for feature selection and relation analysis show that MFI and MIR are very promising to shed light on the complex relationships between features and outcome. In addition, they are not affected by common biases, e.g. that features with many possible splits or high minor allele frequencies are prefered.","sentences":["Random forest is a popular machine learning approach for the analysis of high-dimensional data because it is flexible and provides variable importance measures for the selection of relevant features.","However, the complex relationships between the features are usually not considered for the selection and thus also neglected for the characterization of the analysed samples.","Here we propose two novel approaches that focus on the mutual impact of features in random forests.","Mutual forest impact (MFI) is a relation parameter that evaluates the mutual association of the featurs to the outcome and, hence, goes beyond the analysis of correlation coefficients.","Mutual impurity reduction (MIR) is an importance measure that combines this relation parameter with the importance of the individual features.","MIR and MFI are implemented together with testing procedures that generate p-values for the selection of related and important features.","Applications to various simulated data sets and the comparison to other methods for feature selection and relation analysis show that MFI and MIR are very promising to shed light on the complex relationships between features and outcome.","In addition, they are not affected by common biases, e.g. that features with many possible splits or high minor allele frequencies are prefered."],"url":"http://arxiv.org/abs/2304.02490v1"}
{"created":"2023-04-05","title":"A dynamic Bayesian optimized active recommender system for curiosity-driven Human-in-the-loop automated experiments","abstract":"Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined apriori with limited human feedback during operation. In contrast, here we present the development of a new type of human in the loop experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly, employing human feedback. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and then implement this in real time on an atomic force microscope, where the optimization proceeds to find symmetric piezoresponse amplitude hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human-augmented machine learning approaches for curiosity-driven exploration of systems across experimental domains. The analysis reported here is summarized in Colab Notebook for the purpose of tutorial and application to other data: https://github.com/arpanbiswas52/varTBO","sentences":["Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites.","In virtually all cases, the target property of interest for optimization is defined apriori with limited human feedback during operation.","In contrast, here we present the development of a new type of human in the loop experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly, employing human feedback.","We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and then implement this in real time on an atomic force microscope, where the optimization proceeds to find symmetric piezoresponse amplitude hysteresis loops.","It is found that such features appear more affected by subsurface defects than the local domain structure.","This work shows the utility of human-augmented machine learning approaches for curiosity-driven exploration of systems across experimental domains.","The analysis reported here is summarized in Colab Notebook for the purpose of tutorial and application to other data: https://github.com/arpanbiswas52/varTBO"],"url":"http://arxiv.org/abs/2304.02484v1"}
{"created":"2023-04-05","title":"Selecting Features by their Resilience to the Curse of Dimensionality","abstract":"Real-world datasets are often of high dimension and effected by the curse of dimensionality. This hinders their comprehensibility and interpretability. To reduce the complexity feature selection aims to identify features that are crucial to learn from said data. While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features. Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes. By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality. Our experiments show that our method is competitive and commonly outperforms established feature selection methods. Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points. Our findings suggest that features that discriminate data and are connected to a low intrinsic dimensionality are meaningful for learning procedures.","sentences":["Real-world datasets are often of high dimension and effected by the curse of dimensionality.","This hinders their comprehensibility and interpretability.","To reduce the complexity feature selection aims to identify features that are crucial to learn from said data.","While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features.","Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes.","By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality.","Our experiments show that our method is competitive and commonly outperforms established feature selection methods.","Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points.","Our findings suggest that features that discriminate data and are connected to a low intrinsic dimensionality are meaningful for learning procedures."],"url":"http://arxiv.org/abs/2304.02455v1"}
{"created":"2023-04-05","title":"Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems","abstract":"Minimax problems have recently attracted a lot of research interests. A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable. In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables. Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint. The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results. In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our reformulation creates a new way for interested researchers to design new (and possibly more efficient) decentralized methods on solving NCSC minimax problems. We show a global convergence result of the proposed algorithm and an iteration complexity result to produce a (near) stationary point of the reformulation. Moreover, a relation is established between the (near) stationarities of the reformulation and the original formulation. With this relation, we show that when the dual regularizer is smooth, our algorithm can have lower complexity results (with reduced dependence on a condition number) than existing ones to produce a near-stationary point of the original formulation. Numerical experiments are conducted on a distributionally robust logistic regression to demonstrate the performance of the proposed algorithm.","sentences":["Minimax problems have recently attracted a lot of research interests.","A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable.","In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables.","Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint.","The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results.","In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our reformulation creates a new way for interested researchers to design new (and possibly more efficient) decentralized methods on solving NCSC minimax problems.","We show a global convergence result of the proposed algorithm and an iteration complexity result to produce a (near) stationary point of the reformulation.","Moreover, a relation is established between the (near) stationarities of the reformulation and the original formulation.","With this relation, we show that when the dual regularizer is smooth, our algorithm can have lower complexity results (with reduced dependence on a condition number) than existing ones to produce a near-stationary point of the original formulation.","Numerical experiments are conducted on a distributionally robust logistic regression to demonstrate the performance of the proposed algorithm."],"url":"http://arxiv.org/abs/2304.02441v1"}
{"created":"2023-04-05","title":"Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping","abstract":"Jointly harnessing complementary features of multi-modal input data in a common latent space has been found to be beneficial long ago. However, the influence of each modality on the models decision remains a puzzle. This study proposes a deep learning framework for the modality-level interpretation of multimodal earth observation data in an end-to-end fashion. While leveraging an explainable machine learning method, namely Occlusion Sensitivity, the proposed framework investigates the influence of modalities under an early-fusion scenario in which the modalities are fused before the learning process. We show that the task of wilderness mapping largely benefits from auxiliary data such as land cover and night time light data.","sentences":["Jointly harnessing complementary features of multi-modal input data in a common latent space has been found to be beneficial long ago.","However, the influence of each modality on the models decision remains a puzzle.","This study proposes a deep learning framework for the modality-level interpretation of multimodal earth observation data in an end-to-end fashion.","While leveraging an explainable machine learning method, namely Occlusion Sensitivity, the proposed framework investigates the influence of modalities under an early-fusion scenario in which the modalities are fused before the learning process.","We show that the task of wilderness mapping largely benefits from auxiliary data such as land cover and night time light data."],"url":"http://arxiv.org/abs/2304.02407v1"}
{"created":"2023-04-05","title":"AutoRL Hyperparameter Landscapes","abstract":"Although Reinforcement Learning (RL) has shown to be capable of producing impressive results, its use is limited by the impact of its hyperparameters on performance. This often makes it difficult to achieve good results in practice. Automated RL (AutoRL) addresses this difficulty, yet little is known about the dynamics of the hyperparameter landscapes that hyperparameter optimization (HPO) methods traverse in search of optimal configurations. In view of existing AutoRL approaches dynamically adjusting hyperparameter configurations, we propose an approach to build and analyze these hyperparameter landscapes not just for one point in time but at multiple points in time throughout training. Addressing an important open question on the legitimacy of such dynamic AutoRL approaches, we provide thorough empirical evidence that the hyperparameter landscapes strongly vary over time across representative algorithms from RL literature (DQN and SAC) in different kinds of environments (Cartpole and Hopper). This supports the theory that hyperparameters should be dynamically adjusted during training and shows the potential for more insights on AutoRL problems that can be gained through landscape analyses.","sentences":["Although Reinforcement Learning (RL) has shown to be capable of producing impressive results, its use is limited by the impact of its hyperparameters on performance.","This often makes it difficult to achieve good results in practice.","Automated RL (AutoRL) addresses this difficulty, yet little is known about the dynamics of the hyperparameter landscapes that hyperparameter optimization (HPO) methods traverse in search of optimal configurations.","In view of existing AutoRL approaches dynamically adjusting hyperparameter configurations, we propose an approach to build and analyze these hyperparameter landscapes not just for one point in time but at multiple points in time throughout training.","Addressing an important open question on the legitimacy of such dynamic AutoRL approaches, we provide thorough empirical evidence that the hyperparameter landscapes strongly vary over time across representative algorithms from RL literature (DQN and SAC) in different kinds of environments (Cartpole and Hopper).","This supports the theory that hyperparameters should be dynamically adjusted during training and shows the potential for more insights on AutoRL problems that can be gained through landscape analyses."],"url":"http://arxiv.org/abs/2304.02396v1"}
{"created":"2023-04-05","title":"DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images","abstract":"Computer-assisted automatic analysis of diabetic retinopathy (DR) is of great importance in reducing the risks of vision loss and even blindness. Ultra-wide optical coherence tomography angiography (UW-OCTA) is a non-invasive and safe imaging modality in DR diagnosis system, but there is a lack of publicly available benchmarks for model development and evaluation. To promote further research and scientific benchmarking for diabetic retinopathy analysis using UW-OCTA images, we organized a challenge named \"DRAC - Diabetic Retinopathy Analysis Challenge\" in conjunction with the 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022). The challenge consists of three tasks: segmentation of DR lesions, image quality assessment and DR grading. The scientific community responded positively to the challenge, with 11, 12, and 13 teams from geographically diverse institutes submitting different solutions in these three tasks, respectively. This paper presents a summary and analysis of the top-performing solutions and results for each task of the challenge. The obtained results from top algorithms indicate the importance of data augmentation, model architecture and ensemble of networks in improving the performance of deep learning models. These findings have the potential to enable new developments in diabetic retinopathy analysis. The challenge remains open for post-challenge registrations and submissions for benchmarking future methodology developments.","sentences":["Computer-assisted automatic analysis of diabetic retinopathy (DR) is of great importance in reducing the risks of vision loss and even blindness.","Ultra-wide optical coherence tomography angiography (UW-OCTA) is a non-invasive and safe imaging modality in DR diagnosis system, but there is a lack of publicly available benchmarks for model development and evaluation.","To promote further research and scientific benchmarking for diabetic retinopathy analysis using UW-OCTA images, we organized a challenge named \"DRAC - Diabetic Retinopathy Analysis Challenge\" in conjunction with the 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022).","The challenge consists of three tasks: segmentation of DR lesions, image quality assessment and DR grading.","The scientific community responded positively to the challenge, with 11, 12, and 13 teams from geographically diverse institutes submitting different solutions in these three tasks, respectively.","This paper presents a summary and analysis of the top-performing solutions and results for each task of the challenge.","The obtained results from top algorithms indicate the importance of data augmentation, model architecture and ensemble of networks in improving the performance of deep learning models.","These findings have the potential to enable new developments in diabetic retinopathy analysis.","The challenge remains open for post-challenge registrations and submissions for benchmarking future methodology developments."],"url":"http://arxiv.org/abs/2304.02389v1"}
{"created":"2023-04-05","title":"Machine Learning of Public Sentiments toward Wind Energy in Norway","abstract":"Across Europe negative public opinion has and may continue to limit the deployment of renewable energy infrastructure required for the transition to net-zero energy systems. Understanding public sentiment and its spatio-temporal variations is as such important for decision-making and socially accepted energy systems. In this study, we apply a sentiment classification model based on a machine learning framework for natural language processing, NorBERT, on data collected from Twitter between 2006 and 2022 to analyse the case of wind power opposition in Norway. From the 68828 tweets with geospatial information, we show how discussions about wind power intensified in 2018/2019 together with a trend of more negative tweets up until 2020, both on a regional level and for Norway as a whole. Furthermore, we find weak geographical clustering in our data, indicating that discussions are country wide and not dominated by specific regional events or developments. Twitter data allows for detailed insight into the temporal nature of public sentiments and extending this research to additional case studies of technologies, countries and sources of data (e.g. newspapers, other social media) may prove important to complement traditional survey research and the understanding of public sentiment.","sentences":["Across Europe negative public opinion has and may continue to limit the deployment of renewable energy infrastructure required for the transition to net-zero energy systems.","Understanding public sentiment and its spatio-temporal variations is as such important for decision-making and socially accepted energy systems.","In this study, we apply a sentiment classification model based on a machine learning framework for natural language processing, NorBERT, on data collected from Twitter between 2006 and 2022 to analyse the case of wind power opposition in Norway.","From the 68828 tweets with geospatial information, we show how discussions about wind power intensified in 2018/2019 together with a trend of more negative tweets up until 2020, both on a regional level and for Norway as a whole.","Furthermore, we find weak geographical clustering in our data, indicating that discussions are country wide and not dominated by specific regional events or developments.","Twitter data allows for detailed insight into the temporal nature of public sentiments and extending this research to additional case studies of technologies, countries and sources of data (e.g. newspapers, other social media) may prove important to complement traditional survey research and the understanding of public sentiment."],"url":"http://arxiv.org/abs/2304.02388v1"}
{"created":"2023-04-05","title":"Predictive Coding as a Neuromorphic Alternative to Backpropagation: A Critical Evaluation","abstract":"Backpropagation has rapidly become the workhorse credit assignment algorithm for modern deep learning methods. Recently, modified forms of predictive coding (PC), an algorithm with origins in computational neuroscience, have been shown to result in approximately or exactly equal parameter updates to those under backpropagation. Due to this connection, it has been suggested that PC can act as an alternative to backpropagation with desirable properties that may facilitate implementation in neuromorphic systems. Here, we explore these claims using the different contemporary PC variants proposed in the literature. We obtain time complexity bounds for these PC variants which we show are lower-bounded by backpropagation. We also present key properties of these variants that have implications for neurobiological plausibility and their interpretations, particularly from the perspective of standard PC as a variational Bayes algorithm for latent probabilistic models. Our findings shed new light on the connection between the two learning frameworks and suggest that, in its current forms, PC may have more limited potential as a direct replacement of backpropagation than previously envisioned.","sentences":["Backpropagation has rapidly become the workhorse credit assignment algorithm for modern deep learning methods.","Recently, modified forms of predictive coding (PC), an algorithm with origins in computational neuroscience, have been shown to result in approximately or exactly equal parameter updates to those under backpropagation.","Due to this connection, it has been suggested that PC can act as an alternative to backpropagation with desirable properties that may facilitate implementation in neuromorphic systems.","Here, we explore these claims using the different contemporary PC variants proposed in the literature.","We obtain time complexity bounds for these PC variants which we show are lower-bounded by backpropagation.","We also present key properties of these variants that have implications for neurobiological plausibility and their interpretations, particularly from the perspective of standard PC as a variational Bayes algorithm for latent probabilistic models.","Our findings shed new light on the connection between the two learning frameworks and suggest that, in its current forms, PC may have more limited potential as a direct replacement of backpropagation than previously envisioned."],"url":"http://arxiv.org/abs/2304.02658v1"}
{"created":"2023-04-05","title":"How good Neural Networks interpretation methods really are? A quantitative benchmark","abstract":"Saliency Maps (SMs) have been extensively used to interpret deep learning models decision by highlighting the features deemed relevant by the model. They are used on highly nonlinear problems, where linear feature selection (FS) methods fail at highlighting relevant explanatory variables. However, the reliability of gradient-based feature attribution methods such as SM has mostly been only qualitatively (visually) assessed, and quantitative benchmarks are currently missing, partially due to the lack of a definite ground truth on image data. Concerned about the apophenic biases introduced by visual assessment of these methods, in this paper we propose a synthetic quantitative benchmark for Neural Networks (NNs) interpretation methods. For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings. We also compare these methods to conventional approaches such as mRMR or Random Forests. Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods. TreeShap, mRMR and LassoNet are the best performing FS methods. We also show that, when quantifying the relevance of a few non linearly-entangled predictive features diluted in a large number of irrelevant noisy variables, neural network-based FS and interpretation methods are still far from being reliable.","sentences":["Saliency Maps (SMs) have been extensively used to interpret deep learning models decision by highlighting the features deemed relevant by the model.","They are used on highly nonlinear problems, where linear feature selection (FS) methods fail at highlighting relevant explanatory variables.","However, the reliability of gradient-based feature attribution methods such as SM has mostly been only qualitatively (visually) assessed, and quantitative benchmarks are currently missing, partially due to the lack of a definite ground truth on image data.","Concerned about the apophenic biases introduced by visual assessment of these methods, in this paper we propose a synthetic quantitative benchmark for Neural Networks (NNs) interpretation methods.","For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings.","We also compare these methods to conventional approaches such as mRMR or Random Forests.","Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods.","TreeShap, mRMR and LassoNet are the best performing FS methods.","We also show that, when quantifying the relevance of a few non linearly-entangled predictive features diluted in a large number of irrelevant noisy variables, neural network-based FS and interpretation methods are still far from being reliable."],"url":"http://arxiv.org/abs/2304.02383v1"}
{"created":"2023-04-05","title":"Physics-Inspired Interpretability Of Machine Learning Models","abstract":"The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.","sentences":["The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving.","Great interest exists in understanding which features of the input data prompt model decision making.","In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences.","By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making.","Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule.","However, no such approach exists for machine learning loss landscapes.","We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable."],"url":"http://arxiv.org/abs/2304.02381v1"}
{"created":"2023-04-05","title":"Effective control of two-dimensional Rayleigh--B\u00e9nard convection: invariant multi-agent reinforcement learning is all you need","abstract":"Rayleigh-B\\'enard convection (RBC) is a recurrent phenomenon in several industrial and geoscience flows and a well-studied system from a fundamental fluid-mechanics viewpoint. However, controlling RBC, for example by modulating the spatial distribution of the bottom-plate heating in the canonical RBC configuration, remains a challenging topic for classical control-theory methods. In the present work, we apply deep reinforcement learning (DRL) for controlling RBC. We show that effective RBC control can be obtained by leveraging invariant multi-agent reinforcement learning (MARL), which takes advantage of the locality and translational invariance inherent to RBC flows inside wide channels. The MARL framework applied to RBC allows for an increase in the number of control segments without encountering the curse of dimensionality that would result from a naive increase in the DRL action-size dimension. This is made possible by the MARL ability for re-using the knowledge generated in different parts of the RBC domain. We show in a case study that MARL DRL is able to discover an advanced control strategy that destabilizes the spontaneous RBC double-cell pattern, changes the topology of RBC by coalescing adjacent convection cells, and actively controls the resulting coalesced cell to bring it to a new stable configuration. This modified flow configuration results in reduced convective heat transfer, which is beneficial in several industrial processes. Therefore, our work both shows the potential of MARL DRL for controlling large RBC systems, as well as demonstrates the possibility for DRL to discover strategies that move the RBC configuration between different topological configurations, yielding desirable heat-transfer characteristics. These results are useful for both gaining further understanding of the intrinsic properties of RBC, as well as for developing industrial applications.","sentences":["Rayleigh-B\\'enard convection (RBC) is a recurrent phenomenon in several industrial and geoscience flows and a well-studied system from a fundamental fluid-mechanics viewpoint.","However, controlling RBC, for example by modulating the spatial distribution of the bottom-plate heating in the canonical RBC configuration, remains a challenging topic for classical control-theory methods.","In the present work, we apply deep reinforcement learning (DRL) for controlling RBC.","We show that effective RBC control can be obtained by leveraging invariant multi-agent reinforcement learning (MARL), which takes advantage of the locality and translational invariance inherent to RBC flows inside wide channels.","The MARL framework applied to RBC allows for an increase in the number of control segments without encountering the curse of dimensionality that would result from a naive increase in the DRL action-size dimension.","This is made possible by the MARL ability for re-using the knowledge generated in different parts of the RBC domain.","We show in a case study that MARL DRL is able to discover an advanced control strategy that destabilizes the spontaneous RBC double-cell pattern, changes the topology of RBC by coalescing adjacent convection cells, and actively controls the resulting coalesced cell to bring it to a new stable configuration.","This modified flow configuration results in reduced convective heat transfer, which is beneficial in several industrial processes.","Therefore, our work both shows the potential of MARL DRL for controlling large RBC systems, as well as demonstrates the possibility for DRL to discover strategies that move the RBC configuration between different topological configurations, yielding desirable heat-transfer characteristics.","These results are useful for both gaining further understanding of the intrinsic properties of RBC, as well as for developing industrial applications."],"url":"http://arxiv.org/abs/2304.02370v1"}
{"created":"2023-04-05","title":"What's in a Name? Beyond Class Indices for Image Recognition","abstract":"Existing machine learning models demonstrate excellent performance in image object recognition after training on a large-scale dataset under full supervision. However, these models only learn to map an image to a predefined class index, without revealing the actual semantic meaning of the object in the image. In contrast, vision-language models like CLIP are able to assign semantic class names to unseen objects in a `zero-shot' manner, although they still rely on a predefined set of candidate names at test time. In this paper, we reconsider the recognition problem and task a vision-language model to assign class names to images given only a large and essentially unconstrained vocabulary of categories as prior information. We use non-parametric methods to establish relationships between images which allow the model to automatically narrow down the set of possible candidate names. Specifically, we propose iteratively clustering the data and voting on class names within them, showing that this enables a roughly 50\\% improvement over the baseline on ImageNet. Furthermore, we tackle this problem both in unsupervised and partially supervised settings, as well as with a coarse-grained and fine-grained search space as the unconstrained dictionary.","sentences":["Existing machine learning models demonstrate excellent performance in image object recognition after training on a large-scale dataset under full supervision.","However, these models only learn to map an image to a predefined class index, without revealing the actual semantic meaning of the object in the image.","In contrast, vision-language models like CLIP are able to assign semantic class names to unseen objects in a `zero-shot' manner, although they still rely on a predefined set of candidate names at test time.","In this paper, we reconsider the recognition problem and task a vision-language model to assign class names to images given only a large and essentially unconstrained vocabulary of categories as prior information.","We use non-parametric methods to establish relationships between images which allow the model to automatically narrow down the set of possible candidate names.","Specifically, we propose iteratively clustering the data and voting on class names within them, showing that this enables a roughly 50\\% improvement over the baseline on ImageNet.","Furthermore, we tackle this problem both in unsupervised and partially supervised settings, as well as with a coarse-grained and fine-grained search space as the unconstrained dictionary."],"url":"http://arxiv.org/abs/2304.02364v1"}
{"created":"2023-04-05","title":"Visualizing Quantum Circuit Probability -- estimating computational action for quantum program synthesis","abstract":"This research applies concepts from algorithmic probability to Boolean and quantum combinatorial logic circuits. A tutorial-style introduction to states and various notions of the complexity of states are presented. Thereafter, the probability of states in the circuit model of computation is defined. Classical and quantum gate sets are compared to select some characteristic sets. The reachability and expressibility in a space-time-bounded setting for these gate sets are enumerated and visualized. These results are studied in terms of computational resources, universality and quantum behavior. The article suggests how applications like geometric quantum machine learning, novel quantum algorithm synthesis and quantum artificial general intelligence can benefit by studying circuit probabilities.","sentences":["This research applies concepts from algorithmic probability to Boolean and quantum combinatorial logic circuits.","A tutorial-style introduction to states and various notions of the complexity of states are presented.","Thereafter, the probability of states in the circuit model of computation is defined.","Classical and quantum gate sets are compared to select some characteristic sets.","The reachability and expressibility in a space-time-bounded setting for these gate sets are enumerated and visualized.","These results are studied in terms of computational resources, universality and quantum behavior.","The article suggests how applications like geometric quantum machine learning, novel quantum algorithm synthesis and quantum artificial general intelligence can benefit by studying circuit probabilities."],"url":"http://arxiv.org/abs/2304.02358v1"}
{"created":"2023-04-05","title":"Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net","abstract":"Radiotherapy (RT) is a key component in the treatment of various cancers, including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia (AML). Precise delineation of organs at risk (OARs) and target areas is essential for effective treatment planning. Intensity Modulated Radiotherapy (IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow and Lymph node Irradiation (TMLI), provide more precise radiation delivery compared to Total Body Irradiation (TBI). However, these techniques require time-consuming manual segmentation of structures in Computerized Tomography (CT) scans by the Radiation Oncologist (RO). In this paper, we present a deep learning-based auto-contouring method for segmenting Planning Target Volume (PTV) for TMLI treatment using the U-Net architecture. We trained and compared two segmentation models with two different loss functions on a dataset of 100 patients treated with TMLI at the Humanitas Research Hospital between 2011 and 2021. Despite challenges in lymph node areas, the best model achieved an average Dice score of 0.816 for PTV segmentation. Our findings are a preliminary but significant step towards developing a segmentation model that has the potential to save radiation oncologists a considerable amount of time. This could allow for the treatment of more patients, resulting in improved clinical practice efficiency and more reproducible contours.","sentences":["Radiotherapy (RT) is a key component in the treatment of various cancers, including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia (AML).","Precise delineation of organs at risk (OARs) and target areas is essential for effective treatment planning.","Intensity Modulated Radiotherapy (IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow and Lymph node Irradiation (TMLI), provide more precise radiation delivery compared to Total Body Irradiation (TBI).","However, these techniques require time-consuming manual segmentation of structures in Computerized Tomography (CT) scans by the Radiation Oncologist (RO).","In this paper, we present a deep learning-based auto-contouring method for segmenting Planning Target Volume (PTV) for TMLI treatment using the U-Net architecture.","We trained and compared two segmentation models with two different loss functions on a dataset of 100 patients treated with TMLI at the Humanitas Research Hospital between 2011 and 2021.","Despite challenges in lymph node areas, the best model achieved an average Dice score of 0.816 for PTV segmentation.","Our findings are a preliminary but significant step towards developing a segmentation model that has the potential to save radiation oncologists a considerable amount of time.","This could allow for the treatment of more patients, resulting in improved clinical practice efficiency and more reproducible contours."],"url":"http://arxiv.org/abs/2304.02353v1"}
{"created":"2023-04-05","title":"Spectral Toolkit of Algorithms for Graphs: Technical Report (1)","abstract":"Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library for efficient spectral graph algorithms, and its development starts in September 2022. We have so far finished the component on local graph clustering, and this technical report presents a user's guide to STAG, showcase studies, and several technical considerations behind our development.","sentences":["Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library for efficient spectral graph algorithms, and its development starts in September 2022.","We have so far finished the component on local graph clustering, and this technical report presents a user's guide to STAG, showcase studies, and several technical considerations behind our development."],"url":"http://arxiv.org/abs/2304.03170v1"}
{"created":"2023-04-05","title":"Unfolded Self-Reconstruction LSH: Towards Machine Unlearning in Approximate Nearest Neighbour Search","abstract":"Approximate nearest neighbour (ANN) search is an essential component of search engines, recommendation systems, etc. Many recent works focus on learning-based data-distribution-dependent hashing and achieve good retrieval performance. However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements. This need requires the ANN search algorithm to support fast online data deletion and insertion. Current learning-based hashing methods need retraining the hash function, which is prohibitable due to the vast time-cost of large-scale data. To address this problem, we propose a novel data-dependent hashing method named unfolded self-reconstruction locality-sensitive hashing (USR-LSH). Our USR-LSH unfolded the optimization update for instance-wise data reconstruction, which is better for preserving data information than data-independent LSH. Moreover, our USR-LSH supports fast online data deletion and insertion without retraining. To the best of our knowledge, we are the first to address the machine unlearning of retrieval problems. Empirically, we demonstrate that USR-LSH outperforms the state-of-the-art data-distribution-independent LSH in ANN tasks in terms of precision and recall. We also show that USR-LSH has significantly faster data deletion and insertion time than learning-based data-dependent hashing.","sentences":["Approximate nearest neighbour (ANN) search is an essential component of search engines, recommendation systems, etc.","Many recent works focus on learning-based data-distribution-dependent hashing and achieve good retrieval performance.","However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements.","This need requires the ANN search algorithm to support fast online data deletion and insertion.","Current learning-based hashing methods need retraining the hash function, which is prohibitable due to the vast time-cost of large-scale data.","To address this problem, we propose a novel data-dependent hashing method named unfolded self-reconstruction locality-sensitive hashing (USR-LSH).","Our USR-LSH unfolded the optimization update for instance-wise data reconstruction, which is better for preserving data information than data-independent LSH.","Moreover, our USR-LSH supports fast online data deletion and insertion without retraining.","To the best of our knowledge, we are the first to address the machine unlearning of retrieval problems.","Empirically, we demonstrate that USR-LSH outperforms the state-of-the-art data-distribution-independent LSH in ANN tasks in terms of precision and recall.","We also show that USR-LSH has significantly faster data deletion and insertion time than learning-based data-dependent hashing."],"url":"http://arxiv.org/abs/2304.02350v2"}
{"created":"2023-04-05","title":"Correcting Flaws in Common Disentanglement Metrics","abstract":"Recent years have seen growing interest in learning disentangled representations, in which distinct features, such as size or shape, are represented by distinct neurons. Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed. In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems. We then consider the task of compositional generalization. Unlike prior works, we treat this as a classification problem, which allows us to use it to measure the disentanglement ability of the encoder, without depending on the decoder. We show that performance on this task is (a) generally quite poor, (b) correlated with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics.","sentences":["Recent years have seen growing interest in learning disentangled representations, in which distinct features, such as size or shape, are represented by distinct neurons.","Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed.","In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems.","We then consider the task of compositional generalization.","Unlike prior works, we treat this as a classification problem, which allows us to use it to measure the disentanglement ability of the encoder, without depending on the decoder.","We show that performance on this task is (a) generally quite poor, (b) correlated with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics."],"url":"http://arxiv.org/abs/2304.02335v1"}
{"created":"2023-04-05","title":"Efficient CNNs via Passive Filter Pruning","abstract":"Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications. However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage. Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters. The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data. Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance. To address this, we present a passive filter pruning method where the filters are pruned based on their contribution in producing output by considering the operator norm of the filters. The proposed pruning method generalizes better across various CNNs compared to that of the entry-wise norm-based pruning methods. In comparison to the existing active filter pruning methods, the proposed pruning method is at least 4.5 times faster in computing filter importance and is able to achieve similar performance compared to that of the active filter pruning methods. The efficacy of the proposed pruning method is evaluated on audio scene classification and image classification using various CNNs architecture such as VGGish, DCASE21_Net, VGG-16 and ResNet-50.","sentences":["Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications.","However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage.","Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters.","The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data.","Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance.","To address this, we present a passive filter pruning method where the filters are pruned based on their contribution in producing output by considering the operator norm of the filters.","The proposed pruning method generalizes better across various CNNs compared to that of the entry-wise norm-based pruning methods.","In comparison to the existing active filter pruning methods, the proposed pruning method is at least 4.5 times faster in computing filter importance and is able to achieve similar performance compared to that of the active filter pruning methods.","The efficacy of the proposed pruning method is evaluated on audio scene classification and image classification using various CNNs architecture such as VGGish, DCASE21_Net, VGG-16 and ResNet-50."],"url":"http://arxiv.org/abs/2304.02319v1"}
{"created":"2023-04-05","title":"Multi-Domain Norm-referenced Encoding Enables Data Efficient Transfer Learning of Facial Expression Recognition","abstract":"People can innately recognize human facial expressions in unnatural forms, such as when depicted on the unusual faces drawn in cartoons or when applied to an animal's features. However, current machine learning algorithms struggle with out-of-domain transfer in facial expression recognition (FER). We propose a biologically-inspired mechanism for such transfer learning, which is based on norm-referenced encoding, where patterns are encoded in terms of difference vectors relative to a domain-specific reference vector. By incorporating domain-specific reference frames, we demonstrate high data efficiency in transfer learning across multiple domains. Our proposed architecture provides an explanation for how the human brain might innately recognize facial expressions on varying head shapes (humans, monkeys, and cartoon avatars) without extensive training. Norm-referenced encoding also allows the intensity of the expression to be read out directly from neural unit activity, similar to face-selective neurons in the brain. Our model achieves a classification accuracy of 92.15\\% on the FERG dataset with extreme data efficiency. We train our proposed mechanism with only 12 images, including a single image of each class (facial expression) and one image per domain (avatar). In comparison, the authors of the FERG dataset achieved a classification accuracy of 89.02\\% with their FaceExpr model, which was trained on 43,000 images.","sentences":["People can innately recognize human facial expressions in unnatural forms, such as when depicted on the unusual faces drawn in cartoons or when applied to an animal's features.","However, current machine learning algorithms struggle with out-of-domain transfer in facial expression recognition (FER).","We propose a biologically-inspired mechanism for such transfer learning, which is based on norm-referenced encoding, where patterns are encoded in terms of difference vectors relative to a domain-specific reference vector.","By incorporating domain-specific reference frames, we demonstrate high data efficiency in transfer learning across multiple domains.","Our proposed architecture provides an explanation for how the human brain might innately recognize facial expressions on varying head shapes (humans, monkeys, and cartoon avatars) without extensive training.","Norm-referenced encoding also allows the intensity of the expression to be read out directly from neural unit activity, similar to face-selective neurons in the brain.","Our model achieves a classification accuracy of 92.15\\% on the FERG dataset with extreme data efficiency.","We train our proposed mechanism with only 12 images, including a single image of each class (facial expression) and one image per domain (avatar).","In comparison, the authors of the FERG dataset achieved a classification accuracy of 89.02\\% with their FaceExpr model, which was trained on 43,000 images."],"url":"http://arxiv.org/abs/2304.02309v1"}
{"created":"2023-04-05","title":"A step towards the applicability of algorithms based on invariant causal learning on observational data","abstract":"Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization. In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships. Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM). This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context. Those environments are not normally available when working with observational data and real-world applications. Here we propose a method to generate them in an efficient way. We assess the performance of this unsupervised learning problem by implementing ICP on simulated data. We also show how to apply ICP efficiently integrated with our method for causal discovery. Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance.","sentences":["Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization.","In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships.","Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM).","This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context.","Those environments are not normally available when working with observational data and real-world applications.","Here we propose a method to generate them in an efficient way.","We assess the performance of this unsupervised learning problem by implementing ICP on simulated data.","We also show how to apply ICP efficiently integrated with our method for causal discovery.","Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance."],"url":"http://arxiv.org/abs/2304.02286v1"}
{"created":"2023-04-05","title":"Graph Representation Learning for Interactive Biomolecule Systems","abstract":"Advances in deep learning models have revolutionized the study of biomolecule systems and their mechanisms. Graph representation learning, in particular, is important for accurately capturing the geometric information of biomolecules at different levels. This paper presents a comprehensive review of the methodologies used to represent biological molecules and systems as computer-recognizable objects, such as sequences, graphs, and surfaces. Moreover, it examines how geometric deep learning models, with an emphasis on graph-based techniques, can analyze biomolecule data to enable drug discovery, protein characterization, and biological system analysis. The study concludes with an overview of the current state of the field, highlighting the challenges that exist and the potential future research directions.","sentences":["Advances in deep learning models have revolutionized the study of biomolecule systems and their mechanisms.","Graph representation learning, in particular, is important for accurately capturing the geometric information of biomolecules at different levels.","This paper presents a comprehensive review of the methodologies used to represent biological molecules and systems as computer-recognizable objects, such as sequences, graphs, and surfaces.","Moreover, it examines how geometric deep learning models, with an emphasis on graph-based techniques, can analyze biomolecule data to enable drug discovery, protein characterization, and biological system analysis.","The study concludes with an overview of the current state of the field, highlighting the challenges that exist and the potential future research directions."],"url":"http://arxiv.org/abs/2304.02656v1"}
{"created":"2023-04-05","title":"CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval","abstract":"Growing techniques have been emerging to improve the performance of passage retrieval. As an effective representation bottleneck pretraining technique, the contextual masked auto-encoder utilizes contextual embedding to assist in the reconstruction of passages. However, it only uses a single auto-encoding pre-task for dense representation pre-training. This study brings multi-view modeling to the contextual masked auto-encoder. Firstly, multi-view representation utilizes both dense and sparse vectors as multi-view representations, aiming to capture sentence semantics from different aspects. Moreover, multiview decoding paradigm utilizes both autoencoding and auto-regressive decoders in representation bottleneck pre-training, aiming to provide both reconstructive and generative signals for better contextual representation pretraining. We refer to this multi-view pretraining method as CoT-MAE v2. Through extensive experiments, we show that CoT-MAE v2 is effective and robust on large-scale passage retrieval benchmarks and out-of-domain zero-shot benchmarks.","sentences":["Growing techniques have been emerging to improve the performance of passage retrieval.","As an effective representation bottleneck pretraining technique, the contextual masked auto-encoder utilizes contextual embedding to assist in the reconstruction of passages.","However, it only uses a single auto-encoding pre-task for dense representation pre-training.","This study brings multi-view modeling to the contextual masked auto-encoder.","Firstly, multi-view representation utilizes both dense and sparse vectors as multi-view representations, aiming to capture sentence semantics from different aspects.","Moreover, multiview decoding paradigm utilizes both autoencoding and auto-regressive decoders in representation bottleneck pre-training, aiming to provide both reconstructive and generative signals for better contextual representation pretraining.","We refer to this multi-view pretraining method as CoT-MAE v2.","Through extensive experiments, we show that CoT-MAE v2 is effective and robust on large-scale passage retrieval benchmarks and out-of-domain zero-shot benchmarks."],"url":"http://arxiv.org/abs/2304.03158v1"}
{"created":"2023-04-05","title":"Rethinking the Trigger-injecting Position in Graph Backdoor Attack","abstract":"Backdoor attacks have been demonstrated as a security threat for machine learning models. Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-of-the-art performance on the clean inputs. While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample. There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively. Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant. Furthermore, we explain these two strategies' similar (better) attack performance through explanation techniques, which results in a further understanding of backdoor attacks in GNNs.","sentences":["Backdoor attacks have been demonstrated as a security threat for machine learning models.","Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-of-the-art performance on the clean inputs.","While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample.","There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively.","Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant.","Furthermore, we explain these two strategies' similar (better) attack performance through explanation techniques, which results in a further understanding of backdoor attacks in GNNs."],"url":"http://arxiv.org/abs/2304.02277v1"}
{"created":"2023-04-05","title":"Optimal Sketching Bounds for Sparse Linear Regression","abstract":"We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression. For this problem, under the $\\ell_2$ norm, we observe an upper bound of $O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $o(d)$ rows showing that $O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions. We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight.","sentences":["We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses.","We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor.","This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound.","This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression.","For this problem, under the $\\ell_2$ norm, we observe an upper bound of $O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression.","For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $o(d)$ rows showing that $O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions.","We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight."],"url":"http://arxiv.org/abs/2304.02261v1"}
{"created":"2023-04-05","title":"Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy","abstract":"We address an important gap in detection of political bias in news articles. Previous works that perform supervised document classification can be biased towards the writing style of each news outlet, leading to overfitting and limited generalizability. Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles. We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads. While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet. We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy. Further analysis demonstrates the ability of our model to capture the discourse structures commonly used in the journalism domain.","sentences":["We address an important gap in detection of political bias in news articles.","Previous works that perform supervised document classification can be biased towards the writing style of each news outlet, leading to overfitting and limited generalizability.","Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles.","We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads.","While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet.","We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy.","Further analysis demonstrates the ability of our model to capture the discourse structures commonly used in the journalism domain."],"url":"http://arxiv.org/abs/2304.02247v1"}
{"created":"2023-04-05","title":"List and Certificate Complexities in Replicable Learning","abstract":"We investigate replicable learning algorithms. Ideally, we would like to design algorithms that output the same canonical model over multiple runs, even when different runs observe a different set of samples from the unknown data distribution. In general, such a strong notion of replicability is not achievable. Thus we consider two feasible notions of replicability called list replicability and certificate replicability. Intuitively, these notions capture the degree of (non) replicability. We design algorithms for certain learning problems that are optimal in list and certificate complexity. We establish matching impossibility results.","sentences":["We investigate replicable learning algorithms.","Ideally, we would like to design algorithms that output the same canonical model over multiple runs, even when different runs observe a different set of samples from the unknown data distribution.","In general, such a strong notion of replicability is not achievable.","Thus we consider two feasible notions of replicability called list replicability and certificate replicability.","Intuitively, these notions capture the degree of (non) replicability.","We design algorithms for certain learning problems that are optimal in list and certificate complexity.","We establish matching impossibility results."],"url":"http://arxiv.org/abs/2304.02240v1"}
{"created":"2023-04-05","title":"Optimal Energy Storage Scheduling for Wind Curtailment Reduction and Energy Arbitrage: A Deep Reinforcement Learning Approach","abstract":"Wind energy has been rapidly gaining popularity as a means for combating climate change. However, the variable nature of wind generation can undermine system reliability and lead to wind curtailment, causing substantial economic losses to wind power producers. Battery energy storage systems (BESS) that serve as onsite backup sources are among the solutions to mitigate wind curtailment. However, such an auxiliary role of the BESS might severely weaken its economic viability. This paper addresses the issue by proposing joint wind curtailment reduction and energy arbitrage for the BESS. We decouple the market participation of the co-located wind-battery system and develop a joint-bidding framework for the wind farm and BESS. It is challenging to optimize the joint-bidding because of the stochasticity of energy prices and wind generation. Therefore, we leverage deep reinforcement learning to maximize the overall revenue from the spot market while unlocking the BESS's potential in concurrently reducing wind curtailment and conducting energy arbitrage. We validate the proposed strategy using realistic wind farm data and demonstrate that our joint-bidding strategy responds better to wind curtailment and generates higher revenues than the optimization-based benchmark. Our simulations also reveal that the extra wind generation used to be curtailed can be an effective power source to charge the BESS, resulting in additional financial returns.","sentences":["Wind energy has been rapidly gaining popularity as a means for combating climate change.","However, the variable nature of wind generation can undermine system reliability and lead to wind curtailment, causing substantial economic losses to wind power producers.","Battery energy storage systems (BESS) that serve as onsite backup sources are among the solutions to mitigate wind curtailment.","However, such an auxiliary role of the BESS might severely weaken its economic viability.","This paper addresses the issue by proposing joint wind curtailment reduction and energy arbitrage for the BESS.","We decouple the market participation of the co-located wind-battery system and develop a joint-bidding framework for the wind farm and BESS.","It is challenging to optimize the joint-bidding because of the stochasticity of energy prices and wind generation.","Therefore, we leverage deep reinforcement learning to maximize the overall revenue from the spot market while unlocking the BESS's potential in concurrently reducing wind curtailment and conducting energy arbitrage.","We validate the proposed strategy using realistic wind farm data and demonstrate that our joint-bidding strategy responds better to wind curtailment and generates higher revenues than the optimization-based benchmark.","Our simulations also reveal that the extra wind generation used to be curtailed can be an effective power source to charge the BESS, resulting in additional financial returns."],"url":"http://arxiv.org/abs/2304.02239v1"}
{"created":"2023-04-05","title":"JPEG Compressed Images Can Bypass Protections Against AI Editing","abstract":"Recently developed text-to-image diffusion models make it easy to edit or create high-quality images. Their ease of use has raised concerns about the potential for malicious editing or deepfake creation. Imperceptible perturbations have been proposed as a means of protecting images from malicious editing by preventing diffusion models from generating realistic images. However, we find that the aforementioned perturbations are not robust to JPEG compression, which poses a major weakness because of the common usage and availability of JPEG. We discuss the importance of robustness for additive imperceptible perturbations and encourage alternative approaches to protect images against editing.","sentences":["Recently developed text-to-image diffusion models make it easy to edit or create high-quality images.","Their ease of use has raised concerns about the potential for malicious editing or deepfake creation.","Imperceptible perturbations have been proposed as a means of protecting images from malicious editing by preventing diffusion models from generating realistic images.","However, we find that the aforementioned perturbations are not robust to JPEG compression, which poses a major weakness because of the common usage and availability of JPEG.","We discuss the importance of robustness for additive imperceptible perturbations and encourage alternative approaches to protect images against editing."],"url":"http://arxiv.org/abs/2304.02234v1"}
{"created":"2023-04-05","title":"Mixed Regression via Approximate Message Passing","abstract":"We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error. The state evolution characterization can be used to tailor the AMP algorithm to take advantage of any structural information known about the signals. Using state evolution, we derive an optimal choice of AMP `denoising' functions that minimizes the estimation error in each iteration.   The theoretical results are validated by numerical simulations for mixed linear regression, max-affine regression, and mixture-of-experts. For max-affine regression, we propose an algorithm that combines AMP with expectation-maximization to estimate intercepts of the model along with the signals. The numerical results show that AMP significantly outperforms other estimators for mixed linear regression and max-affine regression in most parameter regimes.","sentences":["We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables.","This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts.","In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector.","The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations.","We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit.","This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error.","The state evolution characterization can be used to tailor the AMP algorithm to take advantage of any structural information known about the signals.","Using state evolution, we derive an optimal choice of AMP `denoising' functions that minimizes the estimation error in each iteration.   ","The theoretical results are validated by numerical simulations for mixed linear regression, max-affine regression, and mixture-of-experts.","For max-affine regression, we propose an algorithm that combines AMP with expectation-maximization to estimate intercepts of the model along with the signals.","The numerical results show that AMP significantly outperforms other estimators for mixed linear regression and max-affine regression in most parameter regimes."],"url":"http://arxiv.org/abs/2304.02229v1"}
{"created":"2023-04-05","title":"Local Intrinsic Dimensional Entropy","abstract":"Most entropy measures depend on the spread of the probability distribution over the sample space X, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimensionality. We find that ID-Entropy satisfies many desirable properties and can be extended to conditional entropy, joint entropy and mutual-information variants. ID-Entropy also yields new information bottleneck principles and also links to causality. In the context of deep learning, for feedforward architectures, we show, theoretically and empirically, that the ID-Entropy of a hidden layer directly controls the generalization gap for both classifiers and auto-encoders, when the target function is Lipschitz continuous. Our work primarily shows that, for continuous spaces, taking a structural rather than a statistical approach yields entropy measures which preserve intrinsic data dimensionality, while being relevant for studying various architectures.","sentences":["Most entropy measures depend on the spread of the probability distribution over the sample space X, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|.","For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity).","Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality.","In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks.","We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimensionality.","We find that ID-Entropy satisfies many desirable properties and can be extended to conditional entropy, joint entropy and mutual-information variants.","ID-Entropy also yields new information bottleneck principles and also links to causality.","In the context of deep learning, for feedforward architectures, we show, theoretically and empirically, that the ID-Entropy of a hidden layer directly controls the generalization gap for both classifiers and auto-encoders, when the target function is Lipschitz continuous.","Our work primarily shows that, for continuous spaces, taking a structural rather than a statistical approach yields entropy measures which preserve intrinsic data dimensionality, while being relevant for studying various architectures."],"url":"http://arxiv.org/abs/2304.02223v1"}
{"created":"2023-04-05","title":"Adopting Two Supervisors for Efficient Use of Large-Scale Remote Deep Neural Networks","abstract":"Recent decades have seen the rise of large-scale Deep Neural Networks (DNNs) to achieve human-competitive performance in a variety of artificial intelligence tasks. Often consisting of hundreds of millions, if not hundreds of billion parameters, these DNNs are too large to be deployed to, or efficiently run on resource-constrained devices such as mobile phones or IoT microcontrollers. Systems relying on large-scale DNNs thus have to call the corresponding model over the network, leading to substantial costs for hosting and running the large-scale remote model, costs which are often charged on a per-use basis. In this paper, we propose BiSupervised, a novel architecture, where, before relying on a large remote DNN, a system attempts to make a prediction on a small-scale local model. A DNN supervisor monitors said prediction process and identifies easy inputs for which the local prediction can be trusted. For these inputs, the remote model does not have to be invoked, thus saving costs, while only marginally impacting the overall system accuracy. Our architecture furthermore foresees a second supervisor to monitor the remote predictions and identify inputs for which not even these can be trusted, allowing to raise an exception or run a fallback strategy instead. We evaluate the cost savings, and the ability to detect incorrectly predicted inputs on four diverse case studies: IMDB movie review sentiment classification, Github issue triaging, Imagenet image classification, and SQuADv2 free-text question answering","sentences":["Recent decades have seen the rise of large-scale Deep Neural Networks (DNNs) to achieve human-competitive performance in a variety of artificial intelligence tasks.","Often consisting of hundreds of millions, if not hundreds of billion parameters, these DNNs are too large to be deployed to, or efficiently run on resource-constrained devices such as mobile phones or IoT microcontrollers.","Systems relying on large-scale DNNs thus have to call the corresponding model over the network, leading to substantial costs for hosting and running the large-scale remote model, costs which are often charged on a per-use basis.","In this paper, we propose BiSupervised, a novel architecture, where, before relying on a large remote DNN, a system attempts to make a prediction on a small-scale local model.","A DNN supervisor monitors said prediction process and identifies easy inputs for which the local prediction can be trusted.","For these inputs, the remote model does not have to be invoked, thus saving costs, while only marginally impacting the overall system accuracy.","Our architecture furthermore foresees a second supervisor to monitor the remote predictions and identify inputs for which not even these can be trusted, allowing to raise an exception or run a fallback strategy instead.","We evaluate the cost savings, and the ability to detect incorrectly predicted inputs on four diverse case studies: IMDB movie review sentiment classification, Github issue triaging, Imagenet image classification, and SQuADv2 free-text question answering"],"url":"http://arxiv.org/abs/2304.02654v1"}
{"created":"2023-04-05","title":"Zero-shot domain adaptation of anomalous samples for semi-supervised anomaly detection","abstract":"Semi-supervised anomaly detection~(SSAD) is a task where normal data and a limited number of anomalous data are available for training. In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase. To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain. First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables. Since the decoder cannot reconstruct the original data solely from domain-invariant latent variables, we conditioned the decoder on the domain label. To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function. Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain.","sentences":["Semi-supervised anomaly detection~(SSAD) is a task where normal data and a limited number of anomalous data are available for training.","In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase.","To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain.","First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables.","Since the decoder cannot reconstruct the original data solely from domain-invariant latent variables, we conditioned the decoder on the domain label.","To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function.","Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain."],"url":"http://arxiv.org/abs/2304.02221v1"}
{"created":"2023-04-05","title":"On the universal approximation property of radial basis function neural networks","abstract":"In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts. We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space. For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.","sentences":["In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts.","We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space.","For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision."],"url":"http://arxiv.org/abs/2304.02220v1"}
{"created":"2023-04-05","title":"Identification of high-reliability regions of machine learning predictions in materials science using transparent conducting oxides and perovskites as examples","abstract":"Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science. Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML. We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials. Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science.","sentences":["Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science.","Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML.","We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials.","Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science."],"url":"http://arxiv.org/abs/2304.02218v1"}
{"created":"2023-04-05","title":"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT","abstract":"This article presents a new NLP task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existed perovskite solar cell FAIR(Findable, Accessible, Interoperable, Reusable) dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict solar cells' electrical performance and reverse-predict parameters on both material gene and FAIR datesets through LLM. We obtained comparable performance with traditional machine learning methods without feature selection, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.","sentences":["This article presents a new NLP task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science.","We accomplished this task by tuning GPT-3 on an existed perovskite solar cell FAIR(Findable, Accessible, Interoperable, Reusable) dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now.","The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis.","This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain.","Furthermore, we designed experiments to predict solar cells' electrical performance and reverse-predict parameters on both material gene and FAIR datesets through LLM.","We obtained comparable performance with traditional machine learning methods without feature selection, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist."],"url":"http://arxiv.org/abs/2304.02213v2"}
{"created":"2023-04-05","title":"PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data","abstract":"With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare. The efficient exploratory analysis of healthcare data constitutes a significant challenge. Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers. This allows policies to be rapidly adapted to changing circumstances. We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan. We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development. We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests and feature bagging. We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester. We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder. However, the auto-encoder needs to be trained, which requires several parameters to be tuned. In comparison, the PIKS technique has far fewer parameters to tune. This makes it advantageous for fast, \"out-of-the-box\" data exploration. The PIKS technique is scalable and can readily ingest new datasets. Hence, it can provide valuable, up-to-date insights to citizens, patients and policy-makers. We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work. This will help promote a deeper understanding of healthcare policies and public health issues.","sentences":["With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare.","The efficient exploratory analysis of healthcare data constitutes a significant challenge.","Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers.","This allows policies to be rapidly adapted to changing circumstances.","We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan.","We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development.","We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests and feature bagging.","We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester.","We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder.","However, the auto-encoder needs to be trained, which requires several parameters to be tuned.","In comparison, the PIKS technique has far fewer parameters to tune.","This makes it advantageous for fast, \"out-of-the-box\" data exploration.","The PIKS technique is scalable and can readily ingest new datasets.","Hence, it can provide valuable, up-to-date insights to citizens, patients and policy-makers.","We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work.","This will help promote a deeper understanding of healthcare policies and public health issues."],"url":"http://arxiv.org/abs/2304.02208v1"}
{"created":"2023-04-05","title":"Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models","abstract":"Heatmaps are widely used to interpret deep neural networks, particularly for computer vision tasks, and the heatmap-based explainable AI (XAI) techniques are a well-researched topic. However, most studies concentrate on enhancing the quality of the generated heatmap or discovering alternate heatmap generation techniques, and little effort has been devoted to making heatmap-based XAI automatic, interactive, scalable, and accessible. To address this gap, we propose a framework that includes two modules: (1) context modelling and (2) reasoning. We proposed a template-based image captioning approach for context modelling to create text-based contextual information from the heatmap and input data. The reasoning module leverages a large language model to provide explanations in combination with specialised knowledge. Our qualitative experiments demonstrate the effectiveness of our framework and heatmap captioning approach. The code for the proposed template-based heatmap captioning approach will be publicly available.","sentences":["Heatmaps are widely used to interpret deep neural networks, particularly for computer vision tasks, and the heatmap-based explainable AI (XAI) techniques are a well-researched topic.","However, most studies concentrate on enhancing the quality of the generated heatmap or discovering alternate heatmap generation techniques, and little effort has been devoted to making heatmap-based XAI automatic, interactive, scalable, and accessible.","To address this gap, we propose a framework that includes two modules: (1) context modelling and (2) reasoning.","We proposed a template-based image captioning approach for context modelling to create text-based contextual information from the heatmap and input data.","The reasoning module leverages a large language model to provide explanations in combination with specialised knowledge.","Our qualitative experiments demonstrate the effectiveness of our framework and heatmap captioning approach.","The code for the proposed template-based heatmap captioning approach will be publicly available."],"url":"http://arxiv.org/abs/2304.02202v1"}
{"created":"2023-04-05","title":"Estimating Patterns of Classical and Quantum Skyrmion States","abstract":"In this review we discuss the latest results concerning development of the machine learning algorithms for characterization of the magnetic skyrmions that are topologically-protected magnetic textures originated from the Dzyaloshinskii-Moriya interaction that competes Heisenberg isotropic exchange in ferromagnets. We show that for classical spin systems there is a whole pool of machine approaches allowing their accurate phase classification and quantitative description on the basis of few magnetization snapshots. In turn, investigation of the quantum skyrmions is a less explored issue, since there are fundamental limitations on the simulation of such wave functions with classical supercomputers. One needs to find the ways to imitate quantum skyrmions on near-term quantum computers. In this respect, we discuss implementation of the method for estimating structural complexity of classical objects for characterization of the quantum skyrmion state on the basis of limited number of bitstrings obtained from the projective measurements.","sentences":["In this review we discuss the latest results concerning development of the machine learning algorithms for characterization of the magnetic skyrmions that are topologically-protected magnetic textures originated from the Dzyaloshinskii-Moriya interaction that competes Heisenberg isotropic exchange in ferromagnets.","We show that for classical spin systems there is a whole pool of machine approaches allowing their accurate phase classification and quantitative description on the basis of few magnetization snapshots.","In turn, investigation of the quantum skyrmions is a less explored issue, since there are fundamental limitations on the simulation of such wave functions with classical supercomputers.","One needs to find the ways to imitate quantum skyrmions on near-term quantum computers.","In this respect, we discuss implementation of the method for estimating structural complexity of classical objects for characterization of the quantum skyrmion state on the basis of limited number of bitstrings obtained from the projective measurements."],"url":"http://arxiv.org/abs/2304.02201v1"}
{"created":"2023-04-05","title":"EigenFold: Generative Protein Structure Prediction with Diffusion Models","abstract":"Protein structure prediction has reached revolutionary levels of accuracy on single structures, yet distributional modeling paradigms are needed to capture the conformational ensembles and flexibility that underlie biological function. Towards this goal, we develop EigenFold, a diffusion generative modeling framework for sampling a distribution of structures from a given protein sequence. We define a diffusion process that models the structure as a system of harmonic oscillators and which naturally induces a cascading-resolution generative process along the eigenmodes of the system. On recent CAMEO targets, EigenFold achieves a median TMScore of 0.84, while providing a more comprehensive picture of model uncertainty via the ensemble of sampled structures relative to existing methods. We then assess EigenFold's ability to model and predict conformational heterogeneity for fold-switching proteins and ligand-induced conformational change. Code is available at https://github.com/bjing2016/EigenFold.","sentences":["Protein structure prediction has reached revolutionary levels of accuracy on single structures, yet distributional modeling paradigms are needed to capture the conformational ensembles and flexibility that underlie biological function.","Towards this goal, we develop EigenFold, a diffusion generative modeling framework for sampling a distribution of structures from a given protein sequence.","We define a diffusion process that models the structure as a system of harmonic oscillators and which naturally induces a cascading-resolution generative process along the eigenmodes of the system.","On recent CAMEO targets, EigenFold achieves a median TMScore of 0.84, while providing a more comprehensive picture of model uncertainty via the ensemble of sampled structures relative to existing methods.","We then assess EigenFold's ability to model and predict conformational heterogeneity for fold-switching proteins and ligand-induced conformational change.","Code is available at https://github.com/bjing2016/EigenFold."],"url":"http://arxiv.org/abs/2304.02198v1"}
{"created":"2023-04-05","title":"A Diffusion-based Method for Multi-turn Compositional Image Generation","abstract":"Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework. Additionally, we also perform ICM guidance and classifier-free guidance to improve performance. Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR.","sentences":["Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text.","While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs.","In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM).","We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG.","We introduce a conditioning scheme to generate the target image based on the fusion results.","To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework.","Additionally, we also perform ICM guidance and classifier-free guidance to improve performance.","Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR."],"url":"http://arxiv.org/abs/2304.02192v1"}
{"created":"2023-04-05","title":"Building predictive models of healthcare costs with open healthcare data","abstract":"Due to rapidly rising healthcare costs worldwide, there is significant interest in controlling them. An important aspect concerns price transparency, as preliminary efforts have demonstrated that patients will shop for lower costs, driving efficiency. This requires the data to be made available, and models that can predict healthcare costs for a wide range of patient demographics and conditions. We present an approach to this problem by developing a predictive model using machine-learning techniques. We analyzed de-identified patient data from New York State SPARCS (statewide planning and research cooperative system), consisting of 2.3 million records in 2016. We built models to predict costs from patient diagnoses and demographics. We investigated two model classes consisting of sparse regression and decision trees. We obtained the best performance by using a decision tree with depth 10. We obtained an R-square value of 0.76 which is better than the values reported in the literature for similar problems.","sentences":["Due to rapidly rising healthcare costs worldwide, there is significant interest in controlling them.","An important aspect concerns price transparency, as preliminary efforts have demonstrated that patients will shop for lower costs, driving efficiency.","This requires the data to be made available, and models that can predict healthcare costs for a wide range of patient demographics and conditions.","We present an approach to this problem by developing a predictive model using machine-learning techniques.","We analyzed de-identified patient data from New York State SPARCS (statewide planning and research cooperative system), consisting of 2.3 million records in 2016.","We built models to predict costs from patient diagnoses and demographics.","We investigated two model classes consisting of sparse regression and decision trees.","We obtained the best performance by using a decision tree with depth 10.","We obtained an R-square value of 0.76 which is better than the values reported in the literature for similar problems."],"url":"http://arxiv.org/abs/2304.02191v1"}
{"created":"2023-04-05","title":"Globalizing Fairness Attributes in Machine Learning: A Case Study on Health in Africa","abstract":"With growing machine learning (ML) applications in healthcare, there have been calls for fairness in ML to understand and mitigate ethical concerns these systems may pose. Fairness has implications for global health in Africa, which already has inequitable power imbalances between the Global North and South. This paper seeks to explore fairness for global health, with Africa as a case study. We propose fairness attributes for consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. This work serves as a basis and call for action for furthering research into fairness in global health.","sentences":["With growing machine learning (ML) applications in healthcare, there have been calls for fairness in ML to understand and mitigate ethical concerns these systems may pose.","Fairness has implications for global health in Africa, which already has inequitable power imbalances between the Global North and South.","This paper seeks to explore fairness for global health, with Africa as a case study.","We propose fairness attributes for consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities.","This work serves as a basis and call for action for furthering research into fairness in global health."],"url":"http://arxiv.org/abs/2304.02190v1"}
{"created":"2023-04-05","title":"A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data","abstract":"The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood. There may be hidden trends and patterns in the data that are worthy of further exploration and analysis. We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers. An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature. Outliers are identified as singleton or small clusters. This algorithm is swept across the dataset in a searchlight manner. The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers. We illustrate this system by anaylzing open health care data released by New York State. We apply our iterative k-means searchlight followed by subset scanning. Several anomalous trends in the data are identified, including cost overruns at specific hospitals, and increases in diagnoses such as suicides. These constitute novel findings in the literature, and are of potential use to regulatory agencies, policy makers and concerned citizens.","sentences":["The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood.","There may be hidden trends and patterns in the data that are worthy of further exploration and analysis.","We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers.","An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature.","Outliers are identified as singleton or small clusters.","This algorithm is swept across the dataset in a searchlight manner.","The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers.","We illustrate this system by anaylzing open health care data released by New York State.","We apply our iterative k-means searchlight followed by subset scanning.","Several anomalous trends in the data are identified, including cost overruns at specific hospitals, and increases in diagnoses such as suicides.","These constitute novel findings in the literature, and are of potential use to regulatory agencies, policy makers and concerned citizens."],"url":"http://arxiv.org/abs/2304.02189v1"}
{"created":"2023-04-05","title":"Training Strategies for Vision Transformers for Object Detection","abstract":"Vision-based Transformer have shown huge application in the perception module of autonomous driving in terms of predicting accurate 3D bounding boxes, owing to their strong capability in modeling long-range dependencies between the visual features. However Transformers, initially designed for language models, have mostly focused on the performance accuracy, and not so much on the inference-time budget. For a safety critical system like autonomous driving, real-time inference at the on-board compute is an absolute necessity. This keeps our object detection algorithm under a very tight run-time budget. In this paper, we evaluated a variety of strategies to optimize on the inference-time of vision transformers based object detection methods keeping a close-watch on any performance variations. Our chosen metric for these strategies is accuracy-runtime joint optimization. Moreover, for actual inference-time analysis we profile our strategies with float32 and float16 precision with TensorRT module. This is the most common format used by the industry for deployment of their Machine Learning networks on the edge devices. We showed that our strategies are able to improve inference-time by 63% at the cost of performance drop of mere 3% for our problem-statement defined in evaluation section. These strategies brings down Vision Transformers detectors inference-time even less than traditional single-image based CNN detectors like FCOS. We recommend practitioners use these techniques to deploy Transformers based hefty multi-view networks on a budge-constrained robotic platform.","sentences":["Vision-based Transformer have shown huge application in the perception module of autonomous driving in terms of predicting accurate 3D bounding boxes, owing to their strong capability in modeling long-range dependencies between the visual features.","However Transformers, initially designed for language models, have mostly focused on the performance accuracy, and not so much on the inference-time budget.","For a safety critical system like autonomous driving, real-time inference at the on-board compute is an absolute necessity.","This keeps our object detection algorithm under a very tight run-time budget.","In this paper, we evaluated a variety of strategies to optimize on the inference-time of vision transformers based object detection methods keeping a close-watch on any performance variations.","Our chosen metric for these strategies is accuracy-runtime joint optimization.","Moreover, for actual inference-time analysis we profile our strategies with float32 and float16 precision with TensorRT module.","This is the most common format used by the industry for deployment of their Machine Learning networks on the edge devices.","We showed that our strategies are able to improve inference-time by 63% at the cost of performance drop of mere 3% for our problem-statement defined in evaluation section.","These strategies brings down Vision Transformers detectors inference-time even less than traditional single-image based CNN detectors like FCOS.","We recommend practitioners use these techniques to deploy Transformers based hefty multi-view networks on a budge-constrained robotic platform."],"url":"http://arxiv.org/abs/2304.02186v1"}
{"created":"2023-04-04","title":"Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model","abstract":"Synthetic electronic health records (EHRs) that are both realistic and preserve privacy can serve as an alternative to real EHRs for machine learning (ML) modeling and statistical analysis. However, generating high-fidelity and granular electronic health record (EHR) data in its original, highly-dimensional form poses challenges for existing methods due to the complexities inherent in high-dimensional data. In this paper, we propose Hierarchical Autoregressive Language mOdel (HALO) for generating longitudinal high-dimensional EHR, which preserve the statistical properties of real EHR and can be used to train accurate ML models without privacy concerns. Our HALO method, designed as a hierarchical autoregressive model, generates a probability density function of medical codes, clinical visits, and patient records, allowing for the generation of realistic EHR data in its original, unaggregated form without the need for variable selection or aggregation. Additionally, our model also produces high-quality continuous variables in a longitudinal and probabilistic manner. We conducted extensive experiments and demonstrate that HALO can generate high-fidelity EHR data with high-dimensional disease code probabilities (d > 10,000), disease co-occurrence probabilities within visits (d > 1,000,000), and conditional probabilities across consecutive visits (d > 5,000,000) and achieve above 0.9 R2 correlation in comparison to real EHR data. This performance then enables downstream ML models trained on its synthetic data to achieve comparable accuracy to models trained on real data (0.938 AUROC with HALO data vs. 0.943 with real data). Finally, using a combination of real and synthetic data enhances the accuracy of ML models beyond that achieved by using only real EHR data.","sentences":["Synthetic electronic health records (EHRs) that are both realistic and preserve privacy can serve as an alternative to real EHRs for machine learning (ML) modeling and statistical analysis.","However, generating high-fidelity and granular electronic health record (EHR) data in its original, highly-dimensional form poses challenges for existing methods due to the complexities inherent in high-dimensional data.","In this paper, we propose Hierarchical Autoregressive Language mOdel (HALO) for generating longitudinal high-dimensional EHR, which preserve the statistical properties of real EHR and can be used to train accurate ML models without privacy concerns.","Our HALO method, designed as a hierarchical autoregressive model, generates a probability density function of medical codes, clinical visits, and patient records, allowing for the generation of realistic EHR data in its original, unaggregated form without the need for variable selection or aggregation.","Additionally, our model also produces high-quality continuous variables in a longitudinal and probabilistic manner.","We conducted extensive experiments and demonstrate that HALO can generate high-fidelity EHR data with high-dimensional disease code probabilities (d > 10,000), disease co-occurrence probabilities within visits (d > 1,000,000), and conditional probabilities across consecutive visits (d > 5,000,000) and achieve above 0.9 R2 correlation in comparison to real EHR data.","This performance then enables downstream ML models trained on its synthetic data to achieve comparable accuracy to models trained on real data (0.938 AUROC with HALO data vs. 0.943 with real data).","Finally, using a combination of real and synthetic data enhances the accuracy of ML models beyond that achieved by using only real EHR data."],"url":"http://arxiv.org/abs/2304.02169v1"}
{"created":"2023-04-04","title":"I2I: Initializing Adapters with Improvised Knowledge","abstract":"Adapters present a promising solution to the catastrophic forgetting problem in continual learning. However, training independent Adapter modules for every new task misses an opportunity for cross-task knowledge transfer. We propose Improvise to Initialize (I2I), a continual learning algorithm that initializes Adapters for incoming tasks by distilling knowledge from previously-learned tasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning benchmark, by conducting experiments on sequences of visual question answering tasks. Adapters trained with I2I consistently achieve better task accuracy than independently-trained Adapters, demonstrating that our algorithm facilitates knowledge transfer between task Adapters. I2I also results in better cross-task knowledge transfer than the state-of-the-art AdapterFusion without incurring the associated parametric cost.","sentences":["Adapters present a promising solution to the catastrophic forgetting problem in continual learning.","However, training independent Adapter modules for every new task misses an opportunity for cross-task knowledge transfer.","We propose Improvise to Initialize (I2I), a continual learning algorithm that initializes Adapters for incoming tasks by distilling knowledge from previously-learned tasks' Adapters.","We evaluate I2I on CLiMB, a multimodal continual learning benchmark, by conducting experiments on sequences of visual question answering tasks.","Adapters trained with I2I consistently achieve better task accuracy than independently-trained Adapters, demonstrating that our algorithm facilitates knowledge transfer between task Adapters.","I2I also results in better cross-task knowledge transfer than the state-of-the-art AdapterFusion without incurring the associated parametric cost."],"url":"http://arxiv.org/abs/2304.02168v1"}
{"created":"2023-04-04","title":"Pac-HuBERT: Self-Supervised Music Source Separation via Primitive Auditory Clustering and Hidden-Unit BERT","abstract":"In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance. Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data. In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model. We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture. We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation. Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset. The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models. We further demonstrate that it can boost performance with small amounts of supervised data. Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation.","sentences":["In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance.","Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data.","In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model.","We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture.","We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation.","Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset.","The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models.","We further demonstrate that it can boost performance with small amounts of supervised data.","Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation."],"url":"http://arxiv.org/abs/2304.02160v1"}
{"created":"2023-04-04","title":"FedBot: Enhancing Privacy in Chatbots with Federated Learning","abstract":"Chatbots are mainly data-driven and usually based on utterances that might be sensitive. However, training deep learning models on shared data can violate user privacy. Such issues have commonly existed in chatbots since their inception. In the literature, there have been many approaches to deal with privacy, such as differential privacy and secure multi-party computation, but most of them need to have access to users' data. In this context, Federated Learning (FL) aims to protect data privacy through distributed learning methods that keep the data in its location. This paper presents Fedbot, a proof-of-concept (POC) privacy-preserving chatbot that leverages large-scale customer support data. The POC combines Deep Bidirectional Transformer models and federated learning algorithms to protect customer data privacy during collaborative model training. The results of the proof-of-concept showcase the potential for privacy-preserving chatbots to transform the customer support industry by delivering personalized and efficient customer service that meets data privacy regulations and legal requirements. Furthermore, the system is specifically designed to improve its performance and accuracy over time by leveraging its ability to learn from previous interactions.","sentences":["Chatbots are mainly data-driven and usually based on utterances that might be sensitive.","However, training deep learning models on shared data can violate user privacy.","Such issues have commonly existed in chatbots since their inception.","In the literature, there have been many approaches to deal with privacy, such as differential privacy and secure multi-party computation, but most of them need to have access to users' data.","In this context, Federated Learning (FL) aims to protect data privacy through distributed learning methods that keep the data in its location.","This paper presents Fedbot, a proof-of-concept (POC) privacy-preserving chatbot that leverages large-scale customer support data.","The POC combines Deep Bidirectional Transformer models and federated learning algorithms to protect customer data privacy during collaborative model training.","The results of the proof-of-concept showcase the potential for privacy-preserving chatbots to transform the customer support industry by delivering personalized and efficient customer service that meets data privacy regulations and legal requirements.","Furthermore, the system is specifically designed to improve its performance and accuracy over time by leveraging its ability to learn from previous interactions."],"url":"http://arxiv.org/abs/2304.03228v1"}
{"created":"2023-04-04","title":"ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention","abstract":"Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task. In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation. We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence. Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features. We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments have been conducted to identify the optimal hyper-parameter set. These experiments demonstrated that we achieved a \\textbf{significant parameter reduction relative to prior transformer models} while attaining State-of-the-Art (SOTA) or near SOTA on all three datasets. Additionally, we achieved SOTA for Protocol III on H36M for both GT and CPN detection inputs. Finally, we obtained SOTA on all three metrics for the MPI-INF-3DHP dataset and for all three subjects on HumanEva under Protocol II.","sentences":["Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task.","In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation.","We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence.","Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features.","We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva.","Extensive experiments have been conducted to identify the optimal hyper-parameter set.","These experiments demonstrated that we achieved a \\textbf{significant parameter reduction relative to prior transformer models} while attaining State-of-the-Art (SOTA) or near SOTA on all three datasets.","Additionally, we achieved SOTA for Protocol III on H36M for both GT and CPN detection inputs.","Finally, we obtained SOTA on all three metrics for the MPI-INF-3DHP dataset and for all three subjects on HumanEva under Protocol II."],"url":"http://arxiv.org/abs/2304.02147v1"}
{"created":"2023-04-04","title":"Structure Learning with Continuous Optimization: A Sober Look and Beyond","abstract":"This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable. Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization. We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations. We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve improvement in this case. Our findings suggest that future works should take into account the non-equal noise variances formulation to handle more general settings and for a more comprehensive empirical evaluation. Lastly, we provide insights into other aspects of the search procedure, including thresholding and sparsity, and show that they play an important role in the final solutions.","sentences":["This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable.","Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization.","We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations.","We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve improvement in this case.","Our findings suggest that future works should take into account the non-equal noise variances formulation to handle more general settings and for a more comprehensive empirical evaluation.","Lastly, we provide insights into other aspects of the search procedure, including thresholding and sparsity, and show that they play an important role in the final solutions."],"url":"http://arxiv.org/abs/2304.02146v1"}
{"created":"2023-04-04","title":"Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses","abstract":"This paper focuses on optimal unimodal transformation of the score outputs of a univariate learning model under linear loss functions. We demonstrate that the optimal mapping between score values and the target region is a rectangular function. To produce this optimal rectangular fit for the observed samples, we propose a sequential approach that can its estimation with each incoming new sample. Our approach has logarithmic time complexity per iteration and is optimally efficient.","sentences":["This paper focuses on optimal unimodal transformation of the score outputs of a univariate learning model under linear loss functions.","We demonstrate that the optimal mapping between score values and the target region is a rectangular function.","To produce this optimal rectangular fit for the observed samples, we propose a sequential approach that can its estimation with each incoming new sample.","Our approach has logarithmic time complexity per iteration and is optimally efficient."],"url":"http://arxiv.org/abs/2304.02141v1"}
{"created":"2023-04-04","title":"Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach","abstract":"The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data. To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as a neural network. The encoder function is introduced to reconstruct the current state from past input-output data. Hence it enables the forward simulation of the rolled-out state-space model. While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process. This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA). Using the BLA provided state-space matrices and its associated reconstructability map both the state-transition part of the network and the encoder are initialized. The performance of the improved initialisation scheme is evaluated on a Wiener-Hammerstein simulation example and a benchmark dataset. The results show that for a weakly nonlinear system, the proposed initialisation based on the linear reconstructability map results in a faster convergence and a better model quality.","sentences":["The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data.","To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as a neural network.","The encoder function is introduced to reconstruct the current state from past input-output data.","Hence it enables the forward simulation of the rolled-out state-space model.","While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process.","This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA).","Using the BLA provided state-space matrices and its associated reconstructability map both the state-transition part of the network and the encoder are initialized.","The performance of the improved initialisation scheme is evaluated on a Wiener-Hammerstein simulation example and a benchmark dataset.","The results show that for a weakly nonlinear system, the proposed initialisation based on the linear reconstructability map results in a faster convergence and a better model quality."],"url":"http://arxiv.org/abs/2304.02119v1"}
{"created":"2023-04-04","title":"Statistics of extreme events in coarse-scale climate simulations via machine learning correction operators trained on nudged datasets","abstract":"This work presents a systematic framework for improving the predictions of statistical quantities for turbulent systems, with a focus on correcting climate simulations obtained by coarse-scale models. While high resolution simulations or reanalysis data are available, they cannot be directly used as training datasets to machine learn a correction for the coarse-scale climate model outputs, since chaotic divergence, inherent in the climate dynamics, makes datasets from different resolutions incompatible. To overcome this fundamental limitation we employ coarse-resolution model simulations nudged towards high quality climate realizations, here in the form of ERA5 reanalysis data. The nudging term is sufficiently small to not pollute the coarse-scale dynamics over short time scales, but also sufficiently large to keep the coarse-scale simulations close to the ERA5 trajectory over larger time scales. The result is a compatible pair of the ERA5 trajectory and the weakly nudged coarse-resolution E3SM output that is used as input training data to machine learn a correction operator. Once training is complete, we perform free-running coarse-scale E3SM simulations without nudging and use those as input to the machine-learned correction operator to obtain high-quality (corrected) outputs. The model is applied to atmospheric climate data with the purpose of predicting global and local statistics of various quantities of a time-period of a decade. Using datasets that are not employed for training, we demonstrate that the produced datasets from the ML-corrected coarse E3SM model have statistical properties that closely resemble the observations. Furthermore, the corrected coarse-scale E3SM output for the frequency of occurrence of extreme events, such as tropical cyclones and atmospheric rivers are presented. We present thorough comparisons and discuss limitations of the approach.","sentences":["This work presents a systematic framework for improving the predictions of statistical quantities for turbulent systems, with a focus on correcting climate simulations obtained by coarse-scale models.","While high resolution simulations or reanalysis data are available, they cannot be directly used as training datasets to machine learn a correction for the coarse-scale climate model outputs, since chaotic divergence, inherent in the climate dynamics, makes datasets from different resolutions incompatible.","To overcome this fundamental limitation we employ coarse-resolution model simulations nudged towards high quality climate realizations, here in the form of ERA5 reanalysis data.","The nudging term is sufficiently small to not pollute the coarse-scale dynamics over short time scales, but also sufficiently large to keep the coarse-scale simulations close to the ERA5 trajectory over larger time scales.","The result is a compatible pair of the ERA5 trajectory and the weakly nudged coarse-resolution E3SM output that is used as input training data to machine learn a correction operator.","Once training is complete, we perform free-running coarse-scale E3SM simulations without nudging and use those as input to the machine-learned correction operator to obtain high-quality (corrected) outputs.","The model is applied to atmospheric climate data with the purpose of predicting global and local statistics of various quantities of a time-period of a decade.","Using datasets that are not employed for training, we demonstrate that the produced datasets from the ML-corrected coarse E3SM model have statistical properties that closely resemble the observations.","Furthermore, the corrected coarse-scale E3SM output for the frequency of occurrence of extreme events, such as tropical cyclones and atmospheric rivers are presented.","We present thorough comparisons and discuss limitations of the approach."],"url":"http://arxiv.org/abs/2304.02117v1"}
{"created":"2023-04-04","title":"Deep learning for diffusion in porous media","abstract":"We adopt convolutional neural networks (CNN) to predict the basic properties of the porous media. Two different media types are considered: one mimics the sandstone, and the other mimics the systems derived from the extracellular space of biological tissues. The Lattice Boltzmann Method is used to obtain the labeled data necessary for performing supervised learning. We distinguish two tasks. In the first, networks based on the analysis of the system's geometry predict porosity and effective diffusion coefficient. In the second, networks reconstruct the system's geometry and concentration map. In the first task, we propose two types of CNN models: the C-Net and the encoder part of the U-Net. Both networks are modified by adding a self-normalization module. The models predict with reasonable accuracy but only within the data type, they are trained on. For instance, the model trained on sandstone-like samples overshoots or undershoots for biological-like samples. In the second task, we propose the usage of the U-Net architecture. It accurately reconstructs the concentration fields. Moreover, the network trained on one data type works well for the other. For instance, the model trained on sandstone-like samples works perfectly on biological-like samples.","sentences":["We adopt convolutional neural networks (CNN) to predict the basic properties of the porous media.","Two different media types are considered: one mimics the sandstone, and the other mimics the systems derived from the extracellular space of biological tissues.","The Lattice Boltzmann Method is used to obtain the labeled data necessary for performing supervised learning.","We distinguish two tasks.","In the first, networks based on the analysis of the system's geometry predict porosity and effective diffusion coefficient.","In the second, networks reconstruct the system's geometry and concentration map.","In the first task, we propose two types of CNN models: the C-Net and the encoder part of the U-Net.","Both networks are modified by adding a self-normalization module.","The models predict with reasonable accuracy but only within the data type, they are trained on.","For instance, the model trained on sandstone-like samples overshoots or undershoots for biological-like samples.","In the second task, we propose the usage of the U-Net architecture.","It accurately reconstructs the concentration fields.","Moreover, the network trained on one data type works well for the other.","For instance, the model trained on sandstone-like samples works perfectly on biological-like samples."],"url":"http://arxiv.org/abs/2304.02104v1"}
{"created":"2023-04-04","title":"Performance Analysis of ML-based MTC Traffic Pattern Predictors","abstract":"Prolonging the lifetime of massive machine-type communication (MTC) networks is key to realizing a sustainable digitized society. Great energy savings can be achieved by accurately predicting MTC traffic followed by properly designed resource allocation mechanisms. However, selecting the proper MTC traffic predictor is not straightforward and depends on accuracy/complexity trade-offs and the specific MTC applications and network characteristics. Remarkably, the related state-of-the-art literature still lacks such debates. Herein, we assess the performance of several machine learning (ML) methods to predict Poisson and quasi-periodic MTC traffic in terms of accuracy and computational cost. Results show that the temporal convolutional network (TCN) outperforms the long-short term memory (LSTM), the gated recurrent units (GRU), and the recurrent neural network (RNN), in that order. For Poisson traffic, the accuracy gap between the predictors is larger than under quasi-periodic traffic. Finally, we show that running a TCN predictor is around three times more costly than other methods, while the training/inference time is the greatest/least.","sentences":["Prolonging the lifetime of massive machine-type communication (MTC) networks is key to realizing a sustainable digitized society.","Great energy savings can be achieved by accurately predicting MTC traffic followed by properly designed resource allocation mechanisms.","However, selecting the proper MTC traffic predictor is not straightforward and depends on accuracy/complexity trade-offs and the specific MTC applications and network characteristics.","Remarkably, the related state-of-the-art literature still lacks such debates.","Herein, we assess the performance of several machine learning (ML) methods to predict Poisson and quasi-periodic MTC traffic in terms of accuracy and computational cost.","Results show that the temporal convolutional network (TCN) outperforms the long-short term memory (LSTM), the gated recurrent units (GRU), and the recurrent neural network (RNN), in that order.","For Poisson traffic, the accuracy gap between the predictors is larger than under quasi-periodic traffic.","Finally, we show that running a TCN predictor is around three times more costly than other methods, while the training/inference time is the greatest/least."],"url":"http://arxiv.org/abs/2304.02100v1"}
{"created":"2023-04-04","title":"The CAMELS project: Expanding the galaxy formation model space with new ASTRID and 28-parameter TNG and SIMBA suites","abstract":"We present CAMELS-ASTRID, the third suite of hydrodynamical simulations in the Cosmology and Astrophysics with MachinE Learning (CAMELS) project, along with new simulation sets that extend the model parameter space based on the previous frameworks of CAMELS-TNG and CAMELS-SIMBA, to provide broader training sets and testing grounds for machine-learning algorithms designed for cosmological studies. CAMELS-ASTRID employs the galaxy formation model following the ASTRID simulation and contains 2,124 hydrodynamic simulation runs that vary 3 cosmological parameters ($\\Omega_m$, $\\sigma_8$, $\\Omega_b$) and 4 parameters controlling stellar and AGN feedback. Compared to the existing TNG and SIMBA simulation suites in CAMELS, the fiducial model of ASTRID features the mildest AGN feedback and predicts the least baryonic effect on the matter power spectrum. The training set of ASTRID covers a broader variation in the galaxy populations and the baryonic impact on the matter power spectrum compared to its TNG and SIMBA counterparts, which can make machine-learning models trained on the ASTRID suite exhibit better extrapolation performance when tested on other hydrodynamic simulation sets. We also introduce extension simulation sets in CAMELS that widely explore 28 parameters in the TNG and SIMBA models, demonstrating the enormity of the overall galaxy formation model parameter space and the complex non-linear interplay between cosmology and astrophysical processes. With the new simulation suites, we show that building robust machine-learning models favors training and testing on the largest possible diversity of galaxy formation models. We also demonstrate that it is possible to train accurate neural networks to infer cosmological parameters using the high-dimensional TNG-SB28 simulation set.","sentences":["We present CAMELS-ASTRID, the third suite of hydrodynamical simulations in the Cosmology and Astrophysics with MachinE Learning (CAMELS) project, along with new simulation sets that extend the model parameter space based on the previous frameworks of CAMELS-TNG and CAMELS-SIMBA, to provide broader training sets and testing grounds for machine-learning algorithms designed for cosmological studies.","CAMELS-ASTRID employs the galaxy formation model following the ASTRID simulation and contains 2,124 hydrodynamic simulation runs that vary 3 cosmological parameters ($\\Omega_m$, $\\sigma_8$, $\\Omega_b$) and 4 parameters controlling stellar and AGN feedback.","Compared to the existing TNG and SIMBA simulation suites in CAMELS, the fiducial model of ASTRID features the mildest AGN feedback and predicts the least baryonic effect on the matter power spectrum.","The training set of ASTRID covers a broader variation in the galaxy populations and the baryonic impact on the matter power spectrum compared to its TNG and SIMBA counterparts, which can make machine-learning models trained on the ASTRID suite exhibit better extrapolation performance when tested on other hydrodynamic simulation sets.","We also introduce extension simulation sets in CAMELS that widely explore 28 parameters in the TNG and SIMBA models, demonstrating the enormity of the overall galaxy formation model parameter space and the complex non-linear interplay between cosmology and astrophysical processes.","With the new simulation suites, we show that building robust machine-learning models favors training and testing on the largest possible diversity of galaxy formation models.","We also demonstrate that it is possible to train accurate neural networks to infer cosmological parameters using the high-dimensional TNG-SB28 simulation set."],"url":"http://arxiv.org/abs/2304.02096v1"}
{"created":"2023-04-04","title":"Hierarchically Fusing Long and Short-Term User Interests for Click-Through Rate Prediction in Product Search","abstract":"Estimating Click-Through Rate (CTR) is a vital yet challenging task in personalized product search. However, existing CTR methods still struggle in the product search settings due to the following three challenges including how to more effectively extract users' short-term interests with respect to multiple aspects, how to extract and fuse users' long-term interest with short-term interests, how to address the entangling characteristic of long and short-term interests. To resolve these challenges, in this paper, we propose a new approach named Hierarchical Interests Fusing Network (HIFN), which consists of four basic modules namely Short-term Interests Extractor (SIE), Long-term Interests Extractor (LIE), Interests Fusion Module (IFM) and Interests Disentanglement Module (IDM). Specifically, SIE is proposed to extract user's short-term interests by integrating three fundamental interests encoders within it namely query-dependent, target-dependent and causal-dependent interest encoder, respectively, followed by delivering the resultant representation to the module LIE, where it can effectively capture user long-term interests by devising an attention mechanism with respect to the short-term interests from SIE module. In IFM, the achieved long and short-term interests are further fused in an adaptive manner, followed by concatenating it with original raw context features for the final prediction result. Last but not least, considering the entangling characteristic of long and short-term interests, IDM further devises a self-supervised framework to disentangle long and short-term interests. Extensive offline and online evaluations on a real-world e-commerce platform demonstrate the superiority of HIFN over state-of-the-art methods.","sentences":["Estimating Click-Through Rate (CTR) is a vital yet challenging task in personalized product search.","However, existing CTR methods still struggle in the product search settings due to the following three challenges including how to more effectively extract users' short-term interests with respect to multiple aspects, how to extract and fuse users' long-term interest with short-term interests, how to address the entangling characteristic of long and short-term interests.","To resolve these challenges, in this paper, we propose a new approach named Hierarchical Interests Fusing Network (HIFN), which consists of four basic modules namely Short-term Interests Extractor (SIE), Long-term Interests Extractor (LIE), Interests Fusion Module (IFM) and Interests Disentanglement Module (IDM).","Specifically, SIE is proposed to extract user's short-term interests by integrating three fundamental interests encoders within it namely query-dependent, target-dependent and causal-dependent interest encoder, respectively, followed by delivering the resultant representation to the module LIE, where it can effectively capture user long-term interests by devising an attention mechanism with respect to the short-term interests from SIE module.","In IFM, the achieved long and short-term interests are further fused in an adaptive manner, followed by concatenating it with original raw context features for the final prediction result.","Last but not least, considering the entangling characteristic of long and short-term interests, IDM further devises a self-supervised framework to disentangle long and short-term interests.","Extensive offline and online evaluations on a real-world e-commerce platform demonstrate the superiority of HIFN over state-of-the-art methods."],"url":"http://arxiv.org/abs/2304.02089v1"}
{"created":"2023-04-04","title":"Scalable Online Learning of Approximate Stackelberg Solutions in Energy Trading Games with Demand Response Aggregators","abstract":"In this work, a Stackelberg game theoretic framework is proposed for trading energy bidirectionally between the demand-response (DR) aggregator and the prosumers. This formulation allows for flexible energy arbitrage and additional monetary rewards while ensuring that the prosumers' desired daily energy demand is met. Then, a scalable (with the number of prosumers) approach is proposed to find approximate equilibria based on online sampling and learning of the prosumers' cumulative best response. Moreover, bounds are provided on the quality of the approximate equilibrium solution. Last, real-world data from the California day-ahead energy market and the University of California at Davis building energy demands are utilized to demonstrate the efficacy of the proposed framework and the online scalable solution.","sentences":["In this work, a Stackelberg game theoretic framework is proposed for trading energy bidirectionally between the demand-response (DR) aggregator and the prosumers.","This formulation allows for flexible energy arbitrage and additional monetary rewards while ensuring that the prosumers' desired daily energy demand is met.","Then, a scalable (with the number of prosumers) approach is proposed to find approximate equilibria based on online sampling and learning of the prosumers' cumulative best response.","Moreover, bounds are provided on the quality of the approximate equilibrium solution.","Last, real-world data from the California day-ahead energy market and the University of California at Davis building energy demands are utilized to demonstrate the efficacy of the proposed framework and the online scalable solution."],"url":"http://arxiv.org/abs/2304.02086v1"}
{"created":"2023-04-04","title":"EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT","abstract":"We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images. This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images. We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem. EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls. The dataset also contains 2D image labels that are used in the supervised training of an ink detection model. Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers. To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain. Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth. Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review. EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here. We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues.","sentences":["We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images.","This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images.","We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem.","EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls.","The dataset also contains 2D image labels that are used in the supervised training of an ink detection model.","Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities.","This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers.","To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth.","Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review.","EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here.","We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues."],"url":"http://arxiv.org/abs/2304.02084v1"}
{"created":"2023-04-04","title":"Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation","abstract":"We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.","sentences":["We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective.","Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied.","We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data.","Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment.","Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation.","The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency."],"url":"http://arxiv.org/abs/2304.02064v1"}
{"created":"2023-04-04","title":"Multi-Class Explainable Unlearning for Image Classification via Weight Filtering","abstract":"Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work provides interesting insights in the development of explainable solutions for unlearning and could be easily extended to other vision tasks.","sentences":["Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network.","While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round.","Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes.","By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design.","We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones.","Our work provides interesting insights in the development of explainable solutions for unlearning and could be easily extended to other vision tasks."],"url":"http://arxiv.org/abs/2304.02049v1"}
{"created":"2023-04-04","title":"Deep Learning for Automated Experimentation in Scanning Transmission Electron Microscopy","abstract":"Machine learning (ML) has become critical for post-acquisition data analysis in (scanning) transmission electron microscopy, (S)TEM, imaging and spectroscopy. An emerging trend is the transition to real-time analysis and closed-loop microscope operation. The effective use of ML in electron microscopy now requires the development of strategies for microscopy-centered experiment workflow design and optimization. Here, we discuss the associated challenges with the transition to active ML, including sequential data analysis and out-of-distribution drift effects, the requirements for the edge operation, local and cloud data storage, and theory in the loop operations. Specifically, we discuss the relative contributions of human scientists and ML agents in the ideation, orchestration, and execution of experimental workflows and the need to develop universal hyper languages that can apply across multiple platforms. These considerations will collectively inform the operationalization of ML in next-generation experimentation.","sentences":["Machine learning (ML) has become critical for post-acquisition data analysis in (scanning) transmission electron microscopy, (S)TEM, imaging and spectroscopy.","An emerging trend is the transition to real-time analysis and closed-loop microscope operation.","The effective use of ML in electron microscopy now requires the development of strategies for microscopy-centered experiment workflow design and optimization.","Here, we discuss the associated challenges with the transition to active ML, including sequential data analysis and out-of-distribution drift effects, the requirements for the edge operation, local and cloud data storage, and theory in the loop operations.","Specifically, we discuss the relative contributions of human scientists and ML agents in the ideation, orchestration, and execution of experimental workflows and the need to develop universal hyper languages that can apply across multiple platforms.","These considerations will collectively inform the operationalization of ML in next-generation experimentation."],"url":"http://arxiv.org/abs/2304.02048v1"}
{"created":"2023-04-04","title":"Effective Theory of Transformers at Initialization","abstract":"We perform an effective-theory analysis of forward-backward signal propagation in wide and deep Transformers, i.e., residual neural networks with multi-head self-attention blocks and multilayer perceptron blocks. This analysis suggests particular width scalings of initialization and training hyperparameters for these models. We then take up such suggestions, training Vision and Language Transformers in practical setups.","sentences":["We perform an effective-theory analysis of forward-backward signal propagation in wide and deep Transformers, i.e., residual neural networks with multi-head self-attention blocks and multilayer perceptron blocks.","This analysis suggests particular width scalings of initialization and training hyperparameters for these models.","We then take up such suggestions, training Vision and Language Transformers in practical setups."],"url":"http://arxiv.org/abs/2304.02034v1"}
{"created":"2023-04-04","title":"EGC: Image Generation and Classification via a Single Energy-Based Model","abstract":"Learning image classification and image generation using the same set of network parameters is a challenging problem. Recent advanced approaches perform well in one task often exhibit poor performance in the other. This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network. Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10. This work represents the first successful attempt to simultaneously excel in both tasks using a single set of network parameters. We believe that EGC bridges the gap between discriminative and generative learning.","sentences":["Learning image classification and image generation using the same set of network parameters is a challenging problem.","Recent advanced approaches perform well in one task often exhibit poor performance in the other.","This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network.","Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass.","EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10.","This work represents the first successful attempt to simultaneously excel in both tasks using a single set of network parameters.","We believe that EGC bridges the gap between discriminative and generative learning."],"url":"http://arxiv.org/abs/2304.02012v1"}
{"created":"2023-04-04","title":"FakET: Simulating Cryo-Electron Tomograms with Neural Style Transfer","abstract":"Particle localization and -classification constitute two of the most fundamental problems in computational microscopy. In recent years, deep learning based approaches have been introduced for these tasks with great success. A key shortcoming of these supervised learning methods is their need for large training data sets, typically generated from particle models in conjunction with complex numerical forward models simulating the physics of transmission electron microscopes. Computer implementations of such forward models are computationally extremely demanding and limit the scope of their applicability. In this paper we propose a simple method for simulating the forward operator of an electron microscope based on additive noise and Neural Style Transfer techniques. We evaluate the method on localization and classification tasks using one of the established state-of-the-art architectures showing performance on par with the benchmark. In contrast to previous approaches, our method accelerates the data generation process by a factor of 750 while using 33 times less memory and scales well to typical transmission electron microscope detector sizes. It utilizes GPU acceleration and parallel processing. It can be used as a stand-alone method to adapt a training data set or as a data augmentation technique. The source code is available at https://gitlab.com/deepet/faket.","sentences":["Particle localization and -classification constitute two of the most fundamental problems in computational microscopy.","In recent years, deep learning based approaches have been introduced for these tasks with great success.","A key shortcoming of these supervised learning methods is their need for large training data sets, typically generated from particle models in conjunction with complex numerical forward models simulating the physics of transmission electron microscopes.","Computer implementations of such forward models are computationally extremely demanding and limit the scope of their applicability.","In this paper we propose a simple method for simulating the forward operator of an electron microscope based on additive noise and Neural Style Transfer techniques.","We evaluate the method on localization and classification tasks using one of the established state-of-the-art architectures showing performance on par with the benchmark.","In contrast to previous approaches, our method accelerates the data generation process by a factor of 750 while using 33 times less memory and scales well to typical transmission electron microscope detector sizes.","It utilizes GPU acceleration and parallel processing.","It can be used as a stand-alone method to adapt a training data set or as a data augmentation technique.","The source code is available at https://gitlab.com/deepet/faket."],"url":"http://arxiv.org/abs/2304.02011v1"}
{"created":"2023-04-04","title":"Autoregressive Neural TensorNet: Bridging Neural Networks and Tensor Networks for Quantum Many-Body Simulation","abstract":"Quantum many-body physics simulation has important impacts on understanding fundamental science and has applications to quantum materials design and quantum technology. However, due to the exponentially growing size of the Hilbert space with respect to the particle number, a direct simulation is intractable. While representing quantum states with tensor networks and neural networks are the two state-of-the-art methods for approximate simulations, each has its own limitations in terms of expressivity and optimization. To address these challenges, we develop a novel architecture, Autoregressive Neural TensorNet (ANTN), which bridges tensor networks and autoregressive neural networks. We show that Autoregressive Neural TensorNet parameterizes normalized wavefunctions with exact sampling, generalizes the expressivity of tensor networks and autoregressive neural networks, and inherits a variety of symmetries from autoregressive neural networks. We demonstrate our approach on the 2D $J_1$-$J_2$ Heisenberg model with different systems sizes and coupling parameters, outperforming both tensor networks and autoregressive neural networks. Our work opens up new opportunities for both scientific simulations and machine learning applications.","sentences":["Quantum many-body physics simulation has important impacts on understanding fundamental science and has applications to quantum materials design and quantum technology.","However, due to the exponentially growing size of the Hilbert space with respect to the particle number, a direct simulation is intractable.","While representing quantum states with tensor networks and neural networks are the two state-of-the-art methods for approximate simulations, each has its own limitations in terms of expressivity and optimization.","To address these challenges, we develop a novel architecture, Autoregressive Neural TensorNet (ANTN), which bridges tensor networks and autoregressive neural networks.","We show that Autoregressive Neural TensorNet parameterizes normalized wavefunctions with exact sampling, generalizes the expressivity of tensor networks and autoregressive neural networks, and inherits a variety of symmetries from autoregressive neural networks.","We demonstrate our approach on the 2D $J_1$-$J_2$ Heisenberg model with different systems sizes and coupling parameters, outperforming both tensor networks and autoregressive neural networks.","Our work opens up new opportunities for both scientific simulations and machine learning applications."],"url":"http://arxiv.org/abs/2304.01996v1"}
{"created":"2023-04-04","title":"Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution","abstract":"This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR). It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT). By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space. Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff. Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time. Finally, our work highlights its potential for various applications.","sentences":["This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR).","It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT).","By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space.","Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks.","Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff.","Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time.","Finally, our work highlights its potential for various applications."],"url":"http://arxiv.org/abs/2304.01994v2"}
{"created":"2023-04-04","title":"Side Channel-Assisted Inference Leakage from Machine Learning-based ECG Classification","abstract":"The Electrocardiogram (ECG) measures the electrical cardiac activity generated by the heart to detect abnormal heartbeat and heart attack. However, the irregular occurrence of the abnormalities demands continuous monitoring of heartbeats. Machine learning techniques are leveraged to automate the task to reduce labor work needed during monitoring. In recent years, many companies have launched products with ECG monitoring and irregular heartbeat alert. Among all classification algorithms, the time series-based algorithm dynamic time warping (DTW) is widely adopted to undertake the ECG classification task. Though progress has been achieved, the DTW-based ECG classification also brings a new attacking vector of leaking the patients' diagnosis results. This paper shows that the ECG input samples' labels can be stolen via a side-channel attack, Flush+Reload. In particular, we first identify the vulnerability of DTW for ECG classification, i.e., the correlation between warping path choice and prediction results. Then we implement an attack that leverages Flush+Reload to monitor the warping path selection with known ECG data and then build a predictor for constructing the relation between warping path selection and labels of input ECG samples. Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW.","sentences":["The Electrocardiogram (ECG) measures the electrical cardiac activity generated by the heart to detect abnormal heartbeat and heart attack.","However, the irregular occurrence of the abnormalities demands continuous monitoring of heartbeats.","Machine learning techniques are leveraged to automate the task to reduce labor work needed during monitoring.","In recent years, many companies have launched products with ECG monitoring and irregular heartbeat alert.","Among all classification algorithms, the time series-based algorithm dynamic time warping (DTW) is widely adopted to undertake the ECG classification task.","Though progress has been achieved, the DTW-based ECG classification also brings a new attacking vector of leaking the patients' diagnosis results.","This paper shows that the ECG input samples' labels can be stolen via a side-channel attack, Flush+Reload.","In particular, we first identify the vulnerability of DTW for ECG classification, i.e., the correlation between warping path choice and prediction results.","Then we implement an attack that leverages Flush+Reload to monitor the warping path selection with known ECG data and then build a predictor for constructing the relation between warping path selection and labels of input ECG samples.","Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW."],"url":"http://arxiv.org/abs/2304.01990v1"}
{"created":"2023-04-04","title":"Dialogue-Contextualized Re-ranking for Medical History-Taking","abstract":"AI-driven medical history-taking is an important component in symptom checking, automated patient intake, triage, and other AI virtual care applications. As history-taking is extremely varied, machine learning models require a significant amount of data to train. To overcome this challenge, existing systems are developed using indirect data or expert knowledge. This leads to a training-inference gap as models are trained on different kinds of data than what they observe at inference time. In this work, we present a two-stage re-ranking approach that helps close the training-inference gap by re-ranking the first-stage question candidates using a dialogue-contextualized model. For this, we propose a new model, global re-ranker, which cross-encodes the dialogue with all questions simultaneously, and compare it with several existing neural baselines. We test both transformer and S4-based language model backbones. We find that relative to the expert system, the best performance is achieved by our proposed global re-ranker with a transformer backbone, resulting in a 30% higher normalized discount cumulative gain (nDCG) and a 77% higher mean average precision (mAP).","sentences":["AI-driven medical history-taking is an important component in symptom checking, automated patient intake, triage, and other AI virtual care applications.","As history-taking is extremely varied, machine learning models require a significant amount of data to train.","To overcome this challenge, existing systems are developed using indirect data or expert knowledge.","This leads to a training-inference gap as models are trained on different kinds of data than what they observe at inference time.","In this work, we present a two-stage re-ranking approach that helps close the training-inference gap by re-ranking the first-stage question candidates using a dialogue-contextualized model.","For this, we propose a new model, global re-ranker, which cross-encodes the dialogue with all questions simultaneously, and compare it with several existing neural baselines.","We test both transformer and S4-based language model backbones.","We find that relative to the expert system, the best performance is achieved by our proposed global re-ranker with a transformer backbone, resulting in a 30% higher normalized discount cumulative gain (nDCG) and a 77% higher mean average precision (mAP)."],"url":"http://arxiv.org/abs/2304.01974v1"}
{"created":"2023-04-04","title":"ERM++: An Improved Baseline for Domain Generalization","abstract":"Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains. While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels. Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods. We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization. We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive. Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark. We hope that ERM++ becomes a strong baseline for future DG research. Code is released at https://github.com/piotr-teterwak/erm_plusplus.","sentences":["Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains.","While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels.","Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods.","We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization.","We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive.","Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark.","We hope that ERM++ becomes a strong baseline for future DG research.","Code is released at https://github.com/piotr-teterwak/erm_plusplus."],"url":"http://arxiv.org/abs/2304.01973v1"}
{"created":"2023-04-04","title":"Model-corrected learned primal-dual models for fast limited-view photoacoustic tomography","abstract":"Learned iterative reconstructions hold great promise to accelerate tomographic imaging with empirical robustness to model perturbations. Nevertheless, an adoption for photoacoustic tomography is hindered by the need to repeatedly evaluate the computational expensive forward model. Computational feasibility can be obtained by the use of fast approximate models, but a need to compensate model errors arises. In this work we advance the methodological and theoretical basis for model corrections in learned image reconstructions by embedding the model correction in a learned primal-dual framework. Here, the model correction is jointly learned in data space coupled with a learned updating operator in image space within an unrolled end-to-end learned iterative reconstruction approach. The proposed formulation allows an extension to a primal-dual deep equilibrium model providing fixed-point convergence as well as reduced memory requirements for training. We provide theoretical and empirical insights into the proposed models with numerical validation in a realistic 2D limited-view setting. The model-corrected learned primal-dual methods show excellent reconstruction quality with fast inference times and thus providing a methodological basis for real-time capable and scalable iterative reconstructions in photoacoustic tomography.","sentences":["Learned iterative reconstructions hold great promise to accelerate tomographic imaging with empirical robustness to model perturbations.","Nevertheless, an adoption for photoacoustic tomography is hindered by the need to repeatedly evaluate the computational expensive forward model.","Computational feasibility can be obtained by the use of fast approximate models, but a need to compensate model errors arises.","In this work we advance the methodological and theoretical basis for model corrections in learned image reconstructions by embedding the model correction in a learned primal-dual framework.","Here, the model correction is jointly learned in data space coupled with a learned updating operator in image space within an unrolled end-to-end learned iterative reconstruction approach.","The proposed formulation allows an extension to a primal-dual deep equilibrium model providing fixed-point convergence as well as reduced memory requirements for training.","We provide theoretical and empirical insights into the proposed models with numerical validation in a realistic 2D limited-view setting.","The model-corrected learned primal-dual methods show excellent reconstruction quality with fast inference times and thus providing a methodological basis for real-time capable and scalable iterative reconstructions in photoacoustic tomography."],"url":"http://arxiv.org/abs/2304.01963v1"}
{"created":"2023-04-04","title":"Randomized Adversarial Style Perturbations for Domain Generalization","abstract":"We propose a novel domain generalization technique, referred to as Randomized Adversarial Style Perturbation (RASP), which is motivated by the observation that the characteristics of each domain are captured by the feature statistics corresponding to style. The proposed algorithm perturbs the style of a feature in an adversarial direction towards a randomly selected class, and makes the model learn against being misled by the unexpected styles observed in unseen target domains. While RASP is effective to handle domain shifts, its naive integration into the training procedure might degrade the capability of learning knowledge from source domains because it has no restriction on the perturbations of representations. This challenge is alleviated by Normalized Feature Mixup (NFM), which facilitates the learning of the original features while achieving robustness to perturbed representations via their mixup during training. We evaluate the proposed algorithm via extensive experiments on various benchmarks and show that our approach improves domain generalization performance, especially in large-scale benchmarks.","sentences":["We propose a novel domain generalization technique, referred to as Randomized Adversarial Style Perturbation (RASP), which is motivated by the observation that the characteristics of each domain are captured by the feature statistics corresponding to style.","The proposed algorithm perturbs the style of a feature in an adversarial direction towards a randomly selected class, and makes the model learn against being misled by the unexpected styles observed in unseen target domains.","While RASP is effective to handle domain shifts, its naive integration into the training procedure might degrade the capability of learning knowledge from source domains because it has no restriction on the perturbations of representations.","This challenge is alleviated by Normalized Feature Mixup (NFM), which facilitates the learning of the original features while achieving robustness to perturbed representations via their mixup during training.","We evaluate the proposed algorithm via extensive experiments on various benchmarks and show that our approach improves domain generalization performance, especially in large-scale benchmarks."],"url":"http://arxiv.org/abs/2304.01959v1"}
{"created":"2023-04-04","title":"High-Throughput Vector Similarity Search in Knowledge Graphs","abstract":"There is an increasing adoption of machine learning for encoding data into vectors to serve online recommendation and search use cases. As a result, recent data management systems propose augmenting query processing with online vector similarity search. In this work, we explore vector similarity search in the context of Knowledge Graphs (KGs). Motivated by the tasks of finding related KG queries and entities for past KG query workloads, we focus on hybrid vector similarity search (hybrid queries for short) where part of the query corresponds to vector similarity search and part of the query corresponds to predicates over relational attributes associated with the underlying data vectors. For example, given past KG queries for a song entity, we want to construct new queries for new song entities whose vector representations are close to the vector representation of the entity in the past KG query. But entities in a KG also have non-vector attributes such as a song associated with an artist, a genre, and a release date. Therefore, suggested entities must also satisfy query predicates over non-vector attributes beyond a vector-based similarity predicate. While these tasks are central to KGs, our contributions are generally applicable to hybrid queries. In contrast to prior works that optimize online queries, we focus on enabling efficient batch processing of past hybrid query workloads. We present our system, HQI, for high-throughput batch processing of hybrid queries. We introduce a workload-aware vector data partitioning scheme to tailor the vector index layout to the given workload and describe a multi-query optimization technique to reduce the overhead of vector similarity computations. We evaluate our methods on industrial workloads and demonstrate that HQI yields a 31x improvement in throughput for finding related KG queries compared to existing hybrid query processing approaches.","sentences":["There is an increasing adoption of machine learning for encoding data into vectors to serve online recommendation and search use cases.","As a result, recent data management systems propose augmenting query processing with online vector similarity search.","In this work, we explore vector similarity search in the context of Knowledge Graphs (KGs).","Motivated by the tasks of finding related KG queries and entities for past KG query workloads, we focus on hybrid vector similarity search (hybrid queries for short) where part of the query corresponds to vector similarity search and part of the query corresponds to predicates over relational attributes associated with the underlying data vectors.","For example, given past KG queries for a song entity, we want to construct new queries for new song entities whose vector representations are close to the vector representation of the entity in the past KG query.","But entities in a KG also have non-vector attributes such as a song associated with an artist, a genre, and a release date.","Therefore, suggested entities must also satisfy query predicates over non-vector attributes beyond a vector-based similarity predicate.","While these tasks are central to KGs, our contributions are generally applicable to hybrid queries.","In contrast to prior works that optimize online queries, we focus on enabling efficient batch processing of past hybrid query workloads.","We present our system, HQI, for high-throughput batch processing of hybrid queries.","We introduce a workload-aware vector data partitioning scheme to tailor the vector index layout to the given workload and describe a multi-query optimization technique to reduce the overhead of vector similarity computations.","We evaluate our methods on industrial workloads and demonstrate that HQI yields a 31x improvement in throughput for finding related KG queries compared to existing hybrid query processing approaches."],"url":"http://arxiv.org/abs/2304.01926v1"}
{"created":"2023-04-04","title":"Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable","abstract":"Typical neural network trainings have substantial variance in test-set performance between repeated runs, impeding hyperparameter comparison and training reproducibility. We present the following results towards understanding this variation. (1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have very little variance in their performance on the test-distributions from which those test-sets are sampled, suggesting that variance is less of a practical issue than previously thought. (2) We present a simplifying statistical assumption which closely approximates the structure of the test-set accuracy distribution. (3) We argue that test-set variance is inevitable in the following two senses. First, we show that variance is largely caused by high sensitivity of the training process to initial conditions, rather than by specific sources of randomness like the data order and augmentations. Second, we prove that variance is unavoidable given the observation that ensembles of trained networks are well-calibrated. (4) We conduct preliminary studies of distribution-shift, fine-tuning, data augmentation and learning rate through the lens of variance between runs.","sentences":["Typical neural network trainings have substantial variance in test-set performance between repeated runs, impeding hyperparameter comparison and training reproducibility.","We present the following results towards understanding this variation.","(1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have very little variance in their performance on the test-distributions from which those test-sets are sampled, suggesting that variance is less of a practical issue than previously thought.","(2) We present a simplifying statistical assumption which closely approximates the structure of the test-set accuracy distribution.","(3) We argue that test-set variance is inevitable in the following two senses.","First, we show that variance is largely caused by high sensitivity of the training process to initial conditions, rather than by specific sources of randomness like the data order and augmentations.","Second, we prove that variance is unavoidable given the observation that ensembles of trained networks are well-calibrated.","(4) We conduct preliminary studies of distribution-shift, fine-tuning, data augmentation and learning rate through the lens of variance between runs."],"url":"http://arxiv.org/abs/2304.01910v1"}
{"created":"2023-04-06","title":"Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention","abstract":"Humans possess a versatile mechanism for extracting structured representations of our visual world. When looking at an image, we can decompose the scene into entities and their parts as well as obtain the dependencies between them. To mimic such capability, we propose Visual Dependency Transformers (DependencyViT) that can induce visual dependencies without any labels. We achieve that with a novel neural operator called \\emph{reversed attention} that can naturally capture long-range visual dependencies between image patches. Specifically, we formulate it as a dependency graph where a child token in reversed attention is trained to attend to its parent tokens and send information following a normalized probability distribution rather than gathering information in conventional self-attention. With such a design, hierarchies naturally emerge from reversed attention layers, and a dependency tree is progressively induced from leaf nodes to the root node unsupervisedly.   DependencyViT offers several appealing benefits. (i) Entities and their parts in an image are represented by different subtrees, enabling part partitioning from dependencies; (ii) Dynamic visual pooling is made possible. The leaf nodes which rarely send messages can be pruned without hindering the model performance, based on which we propose the lightweight DependencyViT-Lite to reduce the computational and memory footprints; (iii) DependencyViT works well on both self- and weakly-supervised pretraining paradigms on ImageNet, and demonstrates its effectiveness on 8 datasets and 5 tasks, such as unsupervised part and saliency segmentation, recognition, and detection.","sentences":["Humans possess a versatile mechanism for extracting structured representations of our visual world.","When looking at an image, we can decompose the scene into entities and their parts as well as obtain the dependencies between them.","To mimic such capability, we propose Visual Dependency Transformers (DependencyViT) that can induce visual dependencies without any labels.","We achieve that with a novel neural operator called \\emph{reversed attention} that can naturally capture long-range visual dependencies between image patches.","Specifically, we formulate it as a dependency graph where a child token in reversed attention is trained to attend to its parent tokens and send information following a normalized probability distribution rather than gathering information in conventional self-attention.","With such a design, hierarchies naturally emerge from reversed attention layers, and a dependency tree is progressively induced from leaf nodes to the root node unsupervisedly.   ","DependencyViT offers several appealing benefits.","(i) Entities and their parts in an image are represented by different subtrees, enabling part partitioning from dependencies; (ii) Dynamic visual pooling is made possible.","The leaf nodes which rarely send messages can be pruned without hindering the model performance, based on which we propose the lightweight DependencyViT-Lite to reduce the computational and memory footprints; (iii) DependencyViT works well on both self- and weakly-supervised pretraining paradigms on ImageNet, and demonstrates its effectiveness on 8 datasets and 5 tasks, such as unsupervised part and saliency segmentation, recognition, and detection."],"url":"http://arxiv.org/abs/2304.03282v1"}
{"created":"2023-04-06","title":"Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark","abstract":"Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results show that agents can both act competently and morally, so concrete progress can currently be made in machine ethics--designing agents that are Pareto improvements in both safety and capabilities.","sentences":["Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity.","So do agents naturally learn to be Machiavellian?","And how do we measure these behaviors in general-purpose models such as GPT-4?","Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making.","Scenario labeling is automated with LMs, which are more performant than human annotators.","We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations.","We observe some tension between maximizing reward and behaving ethically.","To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors.","Our results show that agents can both act competently and morally, so concrete progress can currently be made in machine ethics--designing agents that are Pareto improvements in both safety and capabilities."],"url":"http://arxiv.org/abs/2304.03279v1"}
{"created":"2023-04-06","title":"SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation","abstract":"Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains. This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions. This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation. To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data. As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data. This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques. Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios.","sentences":["Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains.","This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions.","This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation.","To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data.","As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data.","This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques.","Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios."],"url":"http://arxiv.org/abs/2304.03251v1"}
{"created":"2023-04-06","title":"Inst-Inpaint: Instructing to Remove Objects with Diffusion Models","abstract":"Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way. Traditionally, the pixels that are wished to be erased are defined with binary masks. From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors. In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously. For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon. Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts. We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets. We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements.","sentences":["Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way.","Traditionally, the pixels that are wished to be erased are defined with binary masks.","From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors.","In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously.","For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon.","Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts.","We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets.","We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements."],"url":"http://arxiv.org/abs/2304.03246v1"}
{"created":"2023-04-06","title":"Large language models effectively leverage document-level context for literary translation, but critical errors persist","abstract":"Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches. With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact. We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation.","sentences":["Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets.","However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult.","We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003)","LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English).","Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better.","We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches.","With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact.","We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation."],"url":"http://arxiv.org/abs/2304.03245v1"}
{"created":"2023-04-06","title":"Protecting information via probabilistic cellular automata","abstract":"Probabilistic cellular automata describe the dynamics of classical spin models, which, for sufficiently small temperature $T$, can serve as classical memory capable of storing information even in the presence of nonzero external magnetic field $h$. In this article, we study a recently-introduced probabilistic cellular automaton, the sweep rule, and map out a region of two coexisting stable phases in the $(T,h)$ plane. We also find that the sweep rule belongs to the weak two-dimensional Ising universality class. Our work is a step towards understanding how simple geometrically-local error-correction strategies can protect information encoded into complex noisy systems, such as topological quantum error-correcting codes.","sentences":["Probabilistic cellular automata describe the dynamics of classical spin models, which, for sufficiently small temperature $T$, can serve as classical memory capable of storing information even in the presence of nonzero external magnetic field $h$. In this article, we study a recently-introduced probabilistic cellular automaton, the sweep rule, and map out a region of two coexisting stable phases in the $(T,h)$ plane.","We also find that the sweep rule belongs to the weak two-dimensional Ising universality class.","Our work is a step towards understanding how simple geometrically-local error-correction strategies can protect information encoded into complex noisy systems, such as topological quantum error-correcting codes."],"url":"http://arxiv.org/abs/2304.03240v1"}
{"created":"2023-04-06","title":"On the renormalization group fixed point of the two-dimensional Ising model at criticality","abstract":"We analyze the renormalization group fixed point of the two-dimensional Ising model at criticality. In contrast with expectations from tensor network renormalization (TNR), we show that a simple, explicit analytic description of this fixed point using operator-algebraic renormalization (OAR) is possible. Specifically, the fixed point is characterized in terms of spin-spin correlation functions. Explicit error bounds for the approximation of continuum correlation functions are given.","sentences":["We analyze the renormalization group fixed point of the two-dimensional Ising model at criticality.","In contrast with expectations from tensor network renormalization (TNR), we show that a simple, explicit analytic description of this fixed point using operator-algebraic renormalization (OAR) is possible.","Specifically, the fixed point is characterized in terms of spin-spin correlation functions.","Explicit error bounds for the approximation of continuum correlation functions are given."],"url":"http://arxiv.org/abs/2304.03224v1"}
{"created":"2023-04-06","title":"A matrix algebra approach to approximate Hessians","abstract":"This work presents a novel matrix-based method for constructing an approximation Hessian using only function evaluations. The method requires less computational power than interpolation-based methods and is easy to implement in matrix-based programming languages such as MATLAB. As only function evaluations are required, the method is suitable for use in derivative-free algorithms. For reasonably structured sample sets, the method is proven to create an order-$1$ accurate approximation of the full Hessian. Under more specialized structures, the method is proved to yield order-$2$ accuracy. The undetermined case, where the number of sample points is less than required for full interpolation, is studied and error bounds are developed for the resulting partial Hessians.","sentences":["This work presents a novel matrix-based method for constructing an approximation Hessian using only function evaluations.","The method requires less computational power than interpolation-based methods and is easy to implement in matrix-based programming languages such as MATLAB.","As only function evaluations are required, the method is suitable for use in derivative-free algorithms.","For reasonably structured sample sets, the method is proven to create an order-$1$ accurate approximation of the full Hessian.","Under more specialized structures, the method is proved to yield order-$2$ accuracy.","The undetermined case, where the number of sample points is less than required for full interpolation, is studied and error bounds are developed for the resulting partial Hessians."],"url":"http://arxiv.org/abs/2304.03222v1"}
{"created":"2023-04-06","title":"Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models","abstract":"To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable. Towards that goal, algorithmic auditing has received substantial attention. To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race). However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences. To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets. Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label). To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples. Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts. Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success. Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models.","sentences":["To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable.","Towards that goal, algorithmic auditing has received substantial attention.","To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race).","However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences.","To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets.","Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label).","To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples.","Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts.","Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success.","Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models."],"url":"http://arxiv.org/abs/2304.03218v1"}
{"created":"2023-04-06","title":"On the approximation of vector-valued functions by samples","abstract":"Given a Hilbert space $\\mathcal H$ and a finite measure space $\\Omega$, the approximation of a vector-valued function $f: \\Omega \\to \\mathcal H$ by a $k$-dimensional subspace $\\mathcal U \\subset \\mathcal H$ plays an important role in dimension reduction techniques, such as reduced basis methods for solving parameter-dependent partial differential equations. For functions in the Lebesgue--Bochner space $L^2(\\Omega;\\mathcal H)$, the best possible subspace approximation error $d_k^{(2)}$ is characterized by the singular values of $f$. However, for practical reasons, $\\mathcal U$ is often restricted to be spanned by point samples of $f$. We show that this restriction only has a mild impact on the attainable error; there always exist $k$ samples such that the resulting error is not larger than $\\sqrt{k+1} \\cdot d_k^{(2)}$. Our work extends existing results by Binev at al. (SIAM J. Math. Anal., 43(3):1457--1472, 2011) on approximation in supremum norm and by Deshpande et al. (Theory Comput., 2:225--247, 2006) on column subset selection for matrices.","sentences":["Given a Hilbert space $\\mathcal H$ and a finite measure space $\\Omega$, the approximation of a vector-valued function $f: \\Omega \\to \\mathcal H$ by a $k$-dimensional subspace $\\mathcal U \\subset \\mathcal H$ plays an important role in dimension reduction techniques, such as reduced basis methods for solving parameter-dependent partial differential equations.","For functions in the Lebesgue--Bochner space $L^2(\\Omega;\\mathcal H)$, the best possible subspace approximation error $d_k^{(2)}$ is characterized by the singular values of $f$. However, for practical reasons, $\\mathcal U$ is often restricted to be spanned by point samples of $f$. We show that this restriction only has a mild impact on the attainable error; there always exist $k$ samples such that the resulting error is not larger than $\\sqrt{k+1} \\cdot d_k^{(2)}$.","Our work extends existing results by Binev at al.","(SIAM J. Math.","Anal., 43(3):1457--1472, 2011) on approximation in supremum norm and by Deshpande et al.","(Theory Comput., 2:225--247, 2006) on column subset selection for matrices."],"url":"http://arxiv.org/abs/2304.03212v1"}
{"created":"2023-04-06","title":"SLM: End-to-end Feature Selection via Sparse Learnable Masks","abstract":"Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability. We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples. At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles. In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax. This allows for more effective learning as demonstrated in ablation studies. Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance.","sentences":["Feature selection has been widely used to alleviate compute requirements during training, elucidate model interpretability, and improve model generalizability.","We propose SLM -- Sparse Learnable Masks -- a canonical approach for end-to-end feature selection that scales well with respect to both the feature dimension and the number of samples.","At the heart of SLM lies a simple but effective learnable sparse mask, which learns which features to select, and gives rise to a novel objective that provably maximizes the mutual information (MI) between the selected features and the labels, which can be derived from a quadratic relaxation of mutual information from first principles.","In addition, we derive a scaling mechanism that allows SLM to precisely control the number of features selected, through a novel use of sparsemax.","This allows for more effective learning as demonstrated in ablation studies.","Empirically, SLM achieves state-of-the-art results against a variety of competitive baselines on eight benchmark datasets, often by a significant margin, especially on those with real-world challenges such as class imbalance."],"url":"http://arxiv.org/abs/2304.03202v1"}
{"created":"2023-04-06","title":"The Concept of Forward-Forward Learning Applied to a Multi Output Perceptron","abstract":"The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification. The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples. Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries. Moreover, the overall performance is comparable to more complex neural networks with hidden layers. The benefit of the approach presented here is that it only involves a single matrix multiplication.","sentences":["The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification.","The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples.","Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries.","Moreover, the overall performance is comparable to more complex neural networks with hidden layers.","The benefit of the approach presented here is that it only involves a single matrix multiplication."],"url":"http://arxiv.org/abs/2304.03189v1"}
{"created":"2023-04-06","title":"Searching for Primordial Black Holes with the Einstein Telescope: impact of design and systematics","abstract":"Primordial Black Holes (PBHs) have recently attracted much attention as they may explain some of the LIGO/Virgo/KAGRA observations and significantly contribute to the dark matter in our universe. The next generation of Gravitational Wave (GW) detectors will have the unique opportunity to set stringent bounds on this putative population of objects. Focusing on the Einstein Telescope (ET), in this paper we analyse in detail the impact of systematics and different detector designs on our future capability of observing key quantities that would allow us to discover and/or constrain a population of PBH mergers. We also perform a population analysis, with a mass and redshift distribution compatible with the current observational bounds. Our results indicate that ET alone can reach an exquisite level of accuracy on the key observables considered, as well as detect up to tens of thousands of PBH binaries per year, but for some key signatures (in particular high--redshift sources) the cryogenic instrument optimised for low frequencies turns out to be crucial, both for the number of observations and the error on the parameters reconstruction. As far as the detector geometry is concerned, we find that a network consisting of two separated L--shaped interferometers of 15 (20)~km arm length, oriented at $45^{\\circ}$ with respect to each other performs better than a single triangular shaped instrument of 10 (15)~km arm length, for all the metrics considered.","sentences":["Primordial Black Holes (PBHs) have recently attracted much attention as they may explain some of the LIGO/Virgo/KAGRA observations and significantly contribute to the dark matter in our universe.","The next generation of Gravitational Wave (GW) detectors will have the unique opportunity to set stringent bounds on this putative population of objects.","Focusing on the Einstein Telescope (ET), in this paper we analyse in detail the impact of systematics and different detector designs on our future capability of observing key quantities that would allow us to discover and/or constrain a population of PBH mergers.","We also perform a population analysis, with a mass and redshift distribution compatible with the current observational bounds.","Our results indicate that ET alone can reach an exquisite level of accuracy on the key observables considered, as well as detect up to tens of thousands of PBH binaries per year, but for some key signatures (in particular high--redshift sources) the cryogenic instrument optimised for low frequencies turns out to be crucial, both for the number of observations and the error on the parameters reconstruction.","As far as the detector geometry is concerned, we find that a network consisting of two separated L--shaped interferometers of 15 (20)~km arm length, oriented at $45^{\\circ}$ with respect to each other performs better than a single triangular shaped instrument of 10 (15)~km arm length, for all the metrics considered."],"url":"http://arxiv.org/abs/2304.03160v1"}
{"created":"2023-04-06","title":"On the detectability of higher harmonics with LISA","abstract":"Supermassive black hole binaries (SMBHB) are expected to be detected by the future space-based gravitational-wave detector LISA with a large signal-to-noise ratio (SNR). This prospect enhances the possibility of differentiating higher harmonics in the inspiral-merger-ringdown (IMR) waveform. In this study, we test the ability of LISA to identify the presence of different modes in the IMR waveform from a SMBHB. We analyze the contribution of each mode to the total SNR for different sources. We show that higher modes, in particular, the mode $(3, 3)$ and $(4, 4)$, can dominate the signal observed through the LISA detector for SMBHB of the order of $10^8 M_\\odot$. With Bayesian analysis, we can discriminate models with different IMR modes. While higher modes are often considered to be orthogonal, it is no longer the case in the merger-ringdown phase. Therefore, omitting harmonics not only diminishes the SNR but can also lead to biases in the parameter estimation. We analyze the bias for each model for our example system and quantify the threshold SNR where we can expect the parameter bias to be comparable to the statistical error. Our work highlights the importance of higher modes to describe the gravitational waveform of events detected by LISA.","sentences":["Supermassive black hole binaries (SMBHB) are expected to be detected by the future space-based gravitational-wave detector LISA with a large signal-to-noise ratio (SNR).","This prospect enhances the possibility of differentiating higher harmonics in the inspiral-merger-ringdown (IMR) waveform.","In this study, we test the ability of LISA to identify the presence of different modes in the IMR waveform from a SMBHB.","We analyze the contribution of each mode to the total SNR for different sources.","We show that higher modes, in particular, the mode $(3, 3)$ and $(4, 4)$, can dominate the signal observed through the LISA detector for SMBHB of the order of $10^8 M_\\odot$. With Bayesian analysis, we can discriminate models with different IMR modes.","While higher modes are often considered to be orthogonal, it is no longer the case in the merger-ringdown phase.","Therefore, omitting harmonics not only diminishes the SNR but can also lead to biases in the parameter estimation.","We analyze the bias for each model for our example system and quantify the threshold SNR where we can expect the parameter bias to be comparable to the statistical error.","Our work highlights the importance of higher modes to describe the gravitational waveform of events detected by LISA."],"url":"http://arxiv.org/abs/2304.03142v1"}
{"created":"2023-04-06","title":"VLPD: Context-Aware Pedestrian Detection via Vision-Language Semantic Self-Supervision","abstract":"Detecting pedestrians accurately in urban scenes is significant for realistic applications like autonomous driving or video surveillance. However, confusing human-like objects often lead to wrong detections, and small scale or heavily occluded pedestrians are easily missed due to their unusual appearances. To address these challenges, only object regions are inadequate, thus how to fully utilize more explicit and semantic contexts becomes a key problem. Meanwhile, previous context-aware pedestrian detectors either only learn latent contexts with visual clues, or need laborious annotations to obtain explicit and semantic contexts. Therefore, we propose in this paper a novel approach via Vision-Language semantic self-supervision for context-aware Pedestrian Detection (VLPD) to model explicitly semantic contexts without any extra annotations. Firstly, we propose a self-supervised Vision-Language Semantic (VLS) segmentation method, which learns both fully-supervised pedestrian detection and contextual segmentation via self-generated explicit labels of semantic classes by vision-language models. Furthermore, a self-supervised Prototypical Semantic Contrastive (PSC) learning method is proposed to better discriminate pedestrians and other classes, based on more explicit and semantic contexts obtained from VLS. Extensive experiments on popular benchmarks show that our proposed VLPD achieves superior performances over the previous state-of-the-arts, particularly under challenging circumstances like small scale and heavy occlusion. Code is available at https://github.com/lmy98129/VLPD.","sentences":["Detecting pedestrians accurately in urban scenes is significant for realistic applications like autonomous driving or video surveillance.","However, confusing human-like objects often lead to wrong detections, and small scale or heavily occluded pedestrians are easily missed due to their unusual appearances.","To address these challenges, only object regions are inadequate, thus how to fully utilize more explicit and semantic contexts becomes a key problem.","Meanwhile, previous context-aware pedestrian detectors either only learn latent contexts with visual clues, or need laborious annotations to obtain explicit and semantic contexts.","Therefore, we propose in this paper a novel approach via Vision-Language semantic self-supervision for context-aware Pedestrian Detection (VLPD) to model explicitly semantic contexts without any extra annotations.","Firstly, we propose a self-supervised Vision-Language Semantic (VLS) segmentation method, which learns both fully-supervised pedestrian detection and contextual segmentation via self-generated explicit labels of semantic classes by vision-language models.","Furthermore, a self-supervised Prototypical Semantic Contrastive (PSC) learning method is proposed to better discriminate pedestrians and other classes, based on more explicit and semantic contexts obtained from VLS.","Extensive experiments on popular benchmarks show that our proposed VLPD achieves superior performances over the previous state-of-the-arts, particularly under challenging circumstances like small scale and heavy occlusion.","Code is available at https://github.com/lmy98129/VLPD."],"url":"http://arxiv.org/abs/2304.03135v1"}
{"created":"2023-04-06","title":"Risperidone response in patients with schizophrenia drives DNA methylation changes in immune and neuronal systems","abstract":"Background: The choice of efficient antipsychotic therapy for schizophrenia relies on a time-consuming trial-and-error approach, whereas the social and economic burdens of the disease call for faster alternatives. Material \\& methods: In a search for predictive biomarkers of antipsychotic response, blood methylomes of 28 patients were analyzed before and 4 weeks into risperidone therapy. Results: Several CpGs exhibiting response-specific temporal dynamics were identified in otherwise temporally stable methylomes and noticeable global response-related differences were observed between good and bad responders. These were associated with genes involved in immunity, neurotransmission and neuronal development. Polymorphisms in many of these genes were previously linked with schizophrenia etiology and antipsychotic response. Conclusion: Antipsychotic response seems to be shaped by both stable and medication-induced methylation differences.","sentences":["Background: The choice of efficient antipsychotic therapy for schizophrenia relies on a time-consuming trial-and-error approach, whereas the social and economic burdens of the disease call for faster alternatives.","Material \\& methods: In a search for predictive biomarkers of antipsychotic response, blood methylomes of 28 patients were analyzed before and 4 weeks into risperidone therapy.","Results: Several CpGs exhibiting response-specific temporal dynamics were identified in otherwise temporally stable methylomes and noticeable global response-related differences were observed between good and bad responders.","These were associated with genes involved in immunity, neurotransmission and neuronal development.","Polymorphisms in many of these genes were previously linked with schizophrenia etiology and antipsychotic response.","Conclusion: Antipsychotic response seems to be shaped by both stable and medication-induced methylation differences."],"url":"http://arxiv.org/abs/2304.03131v1"}
{"created":"2023-04-06","title":"Zero-shot Generative Model Adaptation via Image-specific Prompt Learning","abstract":"Recently, CLIP-guided image synthesis has shown appealing performance on adapting a pre-trained source-domain generator to an unseen target domain. It does not require any target-domain samples but only the textual domain labels. The training is highly efficient, e.g., a few minutes. However, existing methods still have some limitations in the quality of generated images and may suffer from the mode collapse issue. A key reason is that a fixed adaptation direction is applied for all cross-domain image pairs, which leads to identical supervision signals. To address this issue, we propose an Image-specific Prompt Learning (IPL) method, which learns specific prompt vectors for each source-domain image. This produces a more precise adaptation direction for every cross-domain image pair, endowing the target-domain generator with greatly enhanced flexibility. Qualitative and quantitative evaluations on various domains demonstrate that IPL effectively improves the quality and diversity of synthesized images and alleviates the mode collapse. Moreover, IPL is independent of the structure of the generative model, such as generative adversarial networks or diffusion models. Code is available at https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation.","sentences":["Recently, CLIP-guided image synthesis has shown appealing performance on adapting a pre-trained source-domain generator to an unseen target domain.","It does not require any target-domain samples but only the textual domain labels.","The training is highly efficient, e.g., a few minutes.","However, existing methods still have some limitations in the quality of generated images and may suffer from the mode collapse issue.","A key reason is that a fixed adaptation direction is applied for all cross-domain image pairs, which leads to identical supervision signals.","To address this issue, we propose an Image-specific Prompt Learning (IPL) method, which learns specific prompt vectors for each source-domain image.","This produces a more precise adaptation direction for every cross-domain image pair, endowing the target-domain generator with greatly enhanced flexibility.","Qualitative and quantitative evaluations on various domains demonstrate that IPL effectively improves the quality and diversity of synthesized images and alleviates the mode collapse.","Moreover, IPL is independent of the structure of the generative model, such as generative adversarial networks or diffusion models.","Code is available at https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation."],"url":"http://arxiv.org/abs/2304.03119v1"}
{"created":"2023-04-06","title":"Continual Detection Transformer for Incremental Object Detection","abstract":"Incremental object detection (IOD) aims to train an object detector in phases, each with annotations for new object categories. As other incremental settings, IOD is subject to catastrophic forgetting, which is often addressed by techniques such as knowledge distillation (KD) and exemplar replay (ER). However, KD and ER do not work well if applied directly to state-of-the-art transformer-based object detectors such as Deformable DETR and UP-DETR. In this paper, we solve these issues by proposing a ContinuaL DEtection TRansformer (CL-DETR), a new method for transformer-based IOD which enables effective usage of KD and ER in this context. First, we introduce a Detector Knowledge Distillation (DKD) loss, focusing on the most informative and reliable predictions from old versions of the model, ignoring redundant background predictions, and ensuring compatibility with the available ground-truth labels. We also improve ER by proposing a calibration strategy to preserve the label distribution of the training set, therefore better matching training and testing statistics. We conduct extensive experiments on COCO 2017 and demonstrate that CL-DETR achieves state-of-the-art results in the IOD setting.","sentences":["Incremental object detection (IOD) aims to train an object detector in phases, each with annotations for new object categories.","As other incremental settings, IOD is subject to catastrophic forgetting, which is often addressed by techniques such as knowledge distillation (KD) and exemplar replay (ER).","However, KD and ER do not work well if applied directly to state-of-the-art transformer-based object detectors such as Deformable DETR and UP-DETR.","In this paper, we solve these issues by proposing a ContinuaL DEtection TRansformer (CL-DETR), a new method for transformer-based IOD which enables effective usage of KD and ER in this context.","First, we introduce a Detector Knowledge Distillation (DKD) loss, focusing on the most informative and reliable predictions from old versions of the model, ignoring redundant background predictions, and ensuring compatibility with the available ground-truth labels.","We also improve ER by proposing a calibration strategy to preserve the label distribution of the training set, therefore better matching training and testing statistics.","We conduct extensive experiments on COCO 2017 and demonstrate that CL-DETR achieves state-of-the-art results in the IOD setting."],"url":"http://arxiv.org/abs/2304.03110v1"}
{"created":"2023-04-06","title":"Spectral Gap Regularization of Neural Networks","abstract":"We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information. Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical motivation for this approach via spectral graph theory. We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool. We provide an approximate, variational approach for faster computation during training. We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction. We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis. We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay. Results demonstrate the efficacy of Fiedler regularization. This is a journal extension of the conference paper by Tam and Dunson (2020).","sentences":["We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information.","Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network.","We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization.","We provide theoretical motivation for this approach via spectral graph theory.","We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool.","We provide an approximate, variational approach for faster computation during training.","We provide an alternative formulation of this framework in the form of a structurally weighted $\\text{L}_1$ penalty, thus linking our approach to sparsity induction.","We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis.","We performed experiments on datasets that compare Fiedler regularization with classical regularization methods such as dropout and weight decay.","Results demonstrate the efficacy of Fiedler regularization.","This is a journal extension of the conference paper by Tam and Dunson (2020)."],"url":"http://arxiv.org/abs/2304.03096v1"}
{"created":"2023-04-06","title":"Safe MDP Planning by Learning Temporal Patterns of Undesirable Trajectories and Averting Negative Side Effects","abstract":"In safe MDP planning, a cost function based on the current state and action is often used to specify safety aspects. In the real world, often the state representation used may lack sufficient fidelity to specify such safety constraints. Operating based on an incomplete model can often produce unintended negative side effects (NSEs). To address these challenges, first, we associate safety signals with state-action trajectories (rather than just an immediate state-action). This makes our safety model highly general. We also assume categorical safety labels are given for different trajectories, rather than a numerical cost function, which is harder to specify by the problem designer. We then employ a supervised learning model to learn such non-Markovian safety patterns. Second, we develop a Lagrange multiplier method, which incorporates the safety model and the underlying MDP model in a single computation graph to facilitate agent learning of safe behaviors. Finally, our empirical results on a variety of discrete and continuous domains show that this approach can satisfy complex non-Markovian safety constraints while optimizing an agent's total returns, is highly scalable, and is also better than the previous best approach for Markovian NSEs.","sentences":["In safe MDP planning, a cost function based on the current state and action is often used to specify safety aspects.","In the real world, often the state representation used may lack sufficient fidelity to specify such safety constraints.","Operating based on an incomplete model can often produce unintended negative side effects (NSEs).","To address these challenges, first, we associate safety signals with state-action trajectories (rather than just an immediate state-action).","This makes our safety model highly general.","We also assume categorical safety labels are given for different trajectories, rather than a numerical cost function, which is harder to specify by the problem designer.","We then employ a supervised learning model to learn such non-Markovian safety patterns.","Second, we develop a Lagrange multiplier method, which incorporates the safety model and the underlying MDP model in a single computation graph to facilitate agent learning of safe behaviors.","Finally, our empirical results on a variety of discrete and continuous domains show that this approach can satisfy complex non-Markovian safety constraints while optimizing an agent's total returns, is highly scalable, and is also better than the previous best approach for Markovian NSEs."],"url":"http://arxiv.org/abs/2304.03081v1"}
{"created":"2023-04-06","title":"An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset","abstract":"Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification. The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems. The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger. Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN. The results show a noticeable improvement in generalization on the 3RL dataset. Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%).","sentences":["Although real-time facial emotion recognition is a hot topic research domain in the field of human-computer interaction, state-of the-art available datasets still suffer from various problems, such as some unrelated photos such as document photos, unbalanced numbers of photos in each class, and misleading images that can negatively affect correct classification.","The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","The 3RL dataset is labelled with five basic emotions: happiness, fear, sadness, disgust, and anger.","Moreover, we compared the 3RL dataset with other famous state-of-the-art datasets (FER dataset, CK+ dataset), and we applied the most commonly used algorithms in previous works, SVM and CNN.","The results show a noticeable improvement in generalization on the 3RL dataset.","Experiments have shown an accuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+ are, respectively (approximately from 60% to 85%)."],"url":"http://arxiv.org/abs/2304.03064v1"}
{"created":"2023-04-06","title":"Intermediate-qudit assisted Improved quantum algorithm for string matching with an Advanced Decomposition of Fredkin gate","abstract":"The circuit-level implementation of a quantum string-matching algorithm, which matches a search string (pattern) of length $M$ inside a longer text of length $N$, has already been demonstrated in the literature to outperform its classical counterparts in terms of time complexity and space complexity. Higher-dimensional quantum computing is becoming more and more common as a result of its powerful storage and processing capabilities. In this article, we have shown an improved quantum circuit implementation for the string-matching problem with the help of higher-dimensional intermediate temporary qudits. It is also shown that with the help of intermediate qudits not only the complexity of depth can be reduced but also query complexity can be reduced for a quantum algorithm, for the first time to the best of our knowledge. Our algorithm has an improved query complexity of $O(\\sqrt{N-M+1})$ with overall time complexity $O\\left(\\sqrt{N-M+1}\\left((\\log {(N-M+1)} \\log N)+\\log (M)\\right)\\right)$ as compared to the state-of-the-art work which has a query complexity of $O(\\sqrt{N})$ with overall time complexity $O\\left(\\sqrt{N}\\left((\\log N)^{2}+\\log (M)\\right)\\right)$, while the ancilla count also reduces to $\\frac{N}{2}$ from $\\frac{N}{2}+M$. The cost of state-of-the-art quantum circuit for string-matching problem is colossal due to a huge number of Fredkin gates and multi-controlled Toffoli gates. We have exhibited an improved gate cost and depth over the circuit by applying a proposed Fredkin gate decomposition with intermediate qutrits (3-dimensional qudits or ternary systems) and already existing logarithmic-depth decomposition of $n$-qubit Toffoli or multi-controlled Toffoli gate (MCT) with intermediate ququarts (4-dimensional qudits or quaternary systems). We have also asserted that the quantum circuit cost is relevant instead of using higher dimensional qudits through error analysis.","sentences":["The circuit-level implementation of a quantum string-matching algorithm, which matches a search string (pattern) of length $M$ inside a longer text of length $N$, has already been demonstrated in the literature to outperform its classical counterparts in terms of time complexity and space complexity.","Higher-dimensional quantum computing is becoming more and more common as a result of its powerful storage and processing capabilities.","In this article, we have shown an improved quantum circuit implementation for the string-matching problem with the help of higher-dimensional intermediate temporary qudits.","It is also shown that with the help of intermediate qudits not only the complexity of depth can be reduced but also query complexity can be reduced for a quantum algorithm, for the first time to the best of our knowledge.","Our algorithm has an improved query complexity of $O(\\sqrt{N-M+1})$ with overall time complexity $O\\left(\\sqrt{N-M+1}\\left((\\log {(N-M+1)} \\log N)+\\log (M)\\right)\\right)$ as compared to the state-of-the-art work which has a query complexity of $O(\\sqrt{N})$ with overall time complexity $O\\left(\\sqrt{N}\\left((\\log N)^{2}+\\log (M)\\right)\\right)$, while the ancilla count also reduces to $\\frac{N}{2}$ from $\\frac{N}{2}+M$. The cost of state-of-the-art quantum circuit for string-matching problem is colossal due to a huge number of Fredkin gates and multi-controlled Toffoli gates.","We have exhibited an improved gate cost and depth over the circuit by applying a proposed Fredkin gate decomposition with intermediate qutrits (3-dimensional qudits or ternary systems) and already existing logarithmic-depth decomposition of $n$-qubit Toffoli or multi-controlled Toffoli gate (MCT) with intermediate ququarts (4-dimensional qudits or quaternary systems).","We have also asserted that the quantum circuit cost is relevant instead of using higher dimensional qudits through error analysis."],"url":"http://arxiv.org/abs/2304.03050v1"}
{"created":"2023-04-06","title":"ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments","abstract":"Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ETPNav utilizes a transformer-based cross-modal planner to generate navigation plans based on topological maps and instructions. The plan is then performed through an obstacle-avoiding controller that leverages a trial-and-error heuristic to prevent navigation from getting stuck in obstacles. Experimental results demonstrate the effectiveness of the proposed method. ETPNav yields more than 10% and 20% improvements over prior state-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code is available at https://github.com/MarSaKi/ETPNav.","sentences":["Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments.","It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction.","In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE).","To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments.","ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience.","It privileges the agent to break down the navigation procedure into high-level planning and low-level control.","Concurrently, ETPNav utilizes a transformer-based cross-modal planner to generate navigation plans based on topological maps and instructions.","The plan is then performed through an obstacle-avoiding controller that leverages a trial-and-error heuristic to prevent navigation from getting stuck in obstacles.","Experimental results demonstrate the effectiveness of the proposed method.","ETPNav yields more than 10% and 20% improvements over prior state-of-the-art on R2R-CE and RxR-CE datasets, respectively.","Our code is available at https://github.com/MarSaKi/ETPNav."],"url":"http://arxiv.org/abs/2304.03047v1"}
{"created":"2023-04-06","title":"Rough volatility, path-dependent PDEs and weak rates of convergence","abstract":"In the setting of stochastic Volterra equations, and in particular rough volatility models, we show that conditional expectations are the unique classical solutions to path-dependent PDEs. The latter arise from the functional It\\^o formula developed by [Viens, F., & Zhang, J. (2019). A martingale approach for fractional Brownian motions and related path dependent PDEs. Ann. Appl. Probab.]. We then leverage these tools to study weak rates of convergence for discretised stochastic integrals of smooth functions of a Riemann-Liouville fractional Brownian motion with Hurst parameter $H \\in (0,1/2)$. These integrals approximate log-stock prices in rough volatility models. We obtain weak error rates of order 1 if the test function is quadratic and of order $H+1/2$ for smooth test functions.","sentences":["In the setting of stochastic Volterra equations, and in particular rough volatility models, we show that conditional expectations are the unique classical solutions to path-dependent PDEs.","The latter arise from the functional It\\^o formula developed by [Viens, F., & Zhang, J. (2019).","A martingale approach for fractional Brownian motions and related path dependent PDEs.","Ann.","Appl.","Probab.].","We then leverage these tools to study weak rates of convergence for discretised stochastic integrals of smooth functions of a Riemann-Liouville fractional Brownian motion with Hurst parameter $H \\in (0,1/2)$. These integrals approximate log-stock prices in rough volatility models.","We obtain weak error rates of order 1 if the test function is quadratic and of order $H+1/2$ for smooth test functions."],"url":"http://arxiv.org/abs/2304.03042v1"}
{"created":"2023-04-06","title":"Modelling customer lifetime-value in the retail banking industry","abstract":"Understanding customer lifetime value is key to nurturing long-term customer relationships, however, estimating it is far from straightforward. In the retail banking industry, commonly used approaches rely on simple heuristics and do not take advantage of the high predictive ability of modern machine learning techniques. We present a general framework for modelling customer lifetime value which may be applied to industries with long-lasting contractual and product-centric customer relationships, of which retail banking is an example. This framework is novel in facilitating CLV predictions over arbitrary time horizons and product-based propensity models. We also detail an implementation of this model which is currently in production at a large UK lender. In testing, we estimate an 43% improvement in out-of-time CLV prediction error relative to a popular baseline approach. Propensity models derived from our CLV model have been used to support customer contact marketing campaigns. In testing, we saw that the top 10% of customers ranked by their propensity to take up investment products were 3.2 times more likely to take up an investment product in the next year than a customer chosen at random.","sentences":["Understanding customer lifetime value is key to nurturing long-term customer relationships, however, estimating it is far from straightforward.","In the retail banking industry, commonly used approaches rely on simple heuristics and do not take advantage of the high predictive ability of modern machine learning techniques.","We present a general framework for modelling customer lifetime value which may be applied to industries with long-lasting contractual and product-centric customer relationships, of which retail banking is an example.","This framework is novel in facilitating CLV predictions over arbitrary time horizons and product-based propensity models.","We also detail an implementation of this model which is currently in production at a large UK lender.","In testing, we estimate an 43% improvement in out-of-time CLV prediction error relative to a popular baseline approach.","Propensity models derived from our CLV model have been used to support customer contact marketing campaigns.","In testing, we saw that the top 10% of customers ranked by their propensity to take up investment products were 3.2 times more likely to take up an investment product in the next year than a customer chosen at random."],"url":"http://arxiv.org/abs/2304.03038v1"}
{"created":"2023-04-06","title":"Optimal allocation strategies in platform trials","abstract":"Platform trials are randomized clinical trials that allow simultaneous comparison of multiple interventions, usually against a common control. Arms to test experimental interventions may enter and leave the platform over time. This implies that the number of experimental intervention arms in the trial may change over time. Determining optimal allocation rates to allocate patients to the treatment and control arms in platform trials is challenging because the change in treatment arms implies that also the optimal allocation rates will change when treatments enter or leave the platform. In addition, the optimal allocation depends on the analysis strategy used. In this paper, we derive optimal treatment allocation rates for platform trials with shared controls, assuming that a stratified estimation and testing procedure based on a regression model, is used to adjust for time trends. We consider both, analysis using concurrent controls only as well as analysis methods based on also non-concurrent controls and assume that the total sample size is fixed. The objective function to be minimized is the maximum of the variances of the effect estimators. We show that the optimal solution depends on the entry time of the arms in the trial and, in general, does not correspond to the square root of $k$ allocation rule used in the classical multi-arm trials. We illustrate the optimal allocation and evaluate the power and type 1 error rate compared to trials using one-to-one and square root of $k$ allocations by means of a case study.","sentences":["Platform trials are randomized clinical trials that allow simultaneous comparison of multiple interventions, usually against a common control.","Arms to test experimental interventions may enter and leave the platform over time.","This implies that the number of experimental intervention arms in the trial may change over time.","Determining optimal allocation rates to allocate patients to the treatment and control arms in platform trials is challenging because the change in treatment arms implies that also the optimal allocation rates will change when treatments enter or leave the platform.","In addition, the optimal allocation depends on the analysis strategy used.","In this paper, we derive optimal treatment allocation rates for platform trials with shared controls, assuming that a stratified estimation and testing procedure based on a regression model, is used to adjust for time trends.","We consider both, analysis using concurrent controls only as well as analysis methods based on also non-concurrent controls and assume that the total sample size is fixed.","The objective function to be minimized is the maximum of the variances of the effect estimators.","We show that the optimal solution depends on the entry time of the arms in the trial and, in general, does not correspond to the square root of $k$ allocation rule used in the classical multi-arm trials.","We illustrate the optimal allocation and evaluate the power and type 1 error rate compared to trials using one-to-one and square root of $k$ allocations by means of a case study."],"url":"http://arxiv.org/abs/2304.03035v1"}
{"created":"2023-04-06","title":"Visualizing Skiers' Trajectories in Monocular Videos","abstract":"Trajectories are fundamental to winning in alpine skiing. Tools enabling the analysis of such curves can enhance the training activity and enrich broadcasting content. In this paper, we propose SkiTraVis, an algorithm to visualize the sequence of points traversed by a skier during its performance. SkiTraVis works on monocular videos and constitutes a pipeline of a visual tracker to model the skier's motion and of a frame correspondence module to estimate the camera's motion. The separation of the two motions enables the visualization of the trajectory according to the moving camera's perspective. We performed experiments on videos of real-world professional competitions to quantify the visualization error, the computational efficiency, as well as the applicability. Overall, the results achieved demonstrate the potential of our solution for broadcasting media enhancement and coach assistance.","sentences":["Trajectories are fundamental to winning in alpine skiing.","Tools enabling the analysis of such curves can enhance the training activity and enrich broadcasting content.","In this paper, we propose SkiTraVis, an algorithm to visualize the sequence of points traversed by a skier during its performance.","SkiTraVis works on monocular videos and constitutes a pipeline of a visual tracker to model the skier's motion and of a frame correspondence module to estimate the camera's motion.","The separation of the two motions enables the visualization of the trajectory according to the moving camera's perspective.","We performed experiments on videos of real-world professional competitions to quantify the visualization error, the computational efficiency, as well as the applicability.","Overall, the results achieved demonstrate the potential of our solution for broadcasting media enhancement and coach assistance."],"url":"http://arxiv.org/abs/2304.02994v1"}
{"created":"2023-04-06","title":"Leveraging Social Interactions to Detect Misinformation on Social Media","abstract":"Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-the-art models.","sentences":["Detecting misinformation threads is crucial to guarantee a healthy environment on social media.","We address the problem using the data set created during the COVID-19 pandemic.","It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source.","The models identifying unreliable threads usually rely on textual features.","But reliability is not just what is said, but by whom and to whom.","We additionally leverage on network information.","Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not.","We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework.","Keeping track of the sequence of the interactions during the time, we improve over previous state-of-the-art models."],"url":"http://arxiv.org/abs/2304.02983v1"}
{"created":"2023-04-06","title":"A Closer Look at Audio-Visual Semantic Segmentation","abstract":"Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries. Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object. However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set. In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks. Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks. We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+. Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set. We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy. Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models. Code and dataset will be available.","sentences":["Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries.","Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object.","However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set.","In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks.","Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks.","We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+.","Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set.","We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy.","Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models.","Code and dataset will be available."],"url":"http://arxiv.org/abs/2304.02970v1"}
{"created":"2023-04-06","title":"Benchmarking Robustness to Text-Guided Corruptions","abstract":"This study investigates the robustness of image classifiers to text-guided corruptions. We utilize diffusion models to edit images to different domains. Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content. Thus, the corruptions will be more realistic and the comparison will be more informative. Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort. We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains. As well as introducing a new benchmark we try to investigate the robustness of different vision models. The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains. We also observe that convolutional models are more robust than transformer architectures. Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images. The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems. The code for generating the benchmark will be made available online upon publication.","sentences":["This study investigates the robustness of image classifiers to text-guided corruptions.","We utilize diffusion models to edit images to different domains.","Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content.","Thus, the corruptions will be more realistic and the comparison will be more informative.","Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort.","We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains.","As well as introducing a new benchmark we try to investigate the robustness of different vision models.","The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains.","We also observe that convolutional models are more robust than transformer architectures.","Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images.","The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems.","The code for generating the benchmark will be made available online upon publication."],"url":"http://arxiv.org/abs/2304.02963v1"}
{"created":"2023-04-06","title":"SwarmGear: Heterogeneous Swarm of Drones with Reconfigurable Leader Drone and Virtual Impedance Links for Multi-Robot Inspection","abstract":"The continuous monitoring by drone swarms remains a challenging problem due to the lack of power supply and the inability of drones to land on uneven surfaces. Heterogeneous swarms, including ground and aerial vehicles, can support longer inspections and carry a higher number of sensors on board. However, their capabilities are limited by the mobility of wheeled and legged robots in a cluttered environment.   In this paper, we propose a novel concept for autonomous inspection that we call SwarmGear. SwarmGear utilizes a heterogeneous swarm that investigates the environment in a leader-follower formation. The leader drone is able to land on rough terrain and traverse it by four compliant robotic legs, possessing both the functionalities of an aerial and mobile robot. To preserve the formation of the swarm during its motion, virtual impedance links were developed between the leader and the follower drones.   We evaluated experimentally the accuracy of the hybrid leader drone's ground locomotion. By changing the step parameters, the optimal step configuration was found. Two types of gaits were evaluated. The experiments revealed low crosstrack error (mean of 2 cm and max of 4.8 cm) and the ability of the leader drone to move with a 190 mm step length and a 3 degree standard yaw deviation. Four types of drone formations were considered. The best formation was used for experiments with SwarmGear, and it showed low overall crosstrack error for the swarm (mean 7.9 cm for the type 1 gait and 5.1 cm for the type 2 gait).   The proposed system can potentially improve the performance of autonomous swarms in cluttered and unstructured environments by allowing all agents of the swarm to switch between aerial and ground formations to overcome various obstacles and perform missions over a large area.","sentences":["The continuous monitoring by drone swarms remains a challenging problem due to the lack of power supply and the inability of drones to land on uneven surfaces.","Heterogeneous swarms, including ground and aerial vehicles, can support longer inspections and carry a higher number of sensors on board.","However, their capabilities are limited by the mobility of wheeled and legged robots in a cluttered environment.   ","In this paper, we propose a novel concept for autonomous inspection that we call SwarmGear.","SwarmGear utilizes a heterogeneous swarm that investigates the environment in a leader-follower formation.","The leader drone is able to land on rough terrain and traverse it by four compliant robotic legs, possessing both the functionalities of an aerial and mobile robot.","To preserve the formation of the swarm during its motion, virtual impedance links were developed between the leader and the follower drones.   ","We evaluated experimentally the accuracy of the hybrid leader drone's ground locomotion.","By changing the step parameters, the optimal step configuration was found.","Two types of gaits were evaluated.","The experiments revealed low crosstrack error (mean of 2 cm and max of 4.8 cm) and the ability of the leader drone to move with a 190 mm step length and a 3 degree standard yaw deviation.","Four types of drone formations were considered.","The best formation was used for experiments with SwarmGear, and it showed low overall crosstrack error for the swarm (mean 7.9 cm for the type 1 gait and 5.1 cm for the type 2 gait).   ","The proposed system can potentially improve the performance of autonomous swarms in cluttered and unstructured environments by allowing all agents of the swarm to switch between aerial and ground formations to overcome various obstacles and perform missions over a large area."],"url":"http://arxiv.org/abs/2304.02956v1"}
{"created":"2023-04-06","title":"FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead","abstract":"We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI). Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective. Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner. Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance. With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution. Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware. The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time.","sentences":["We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI).","Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective.","Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner.","Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance.","With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution.","Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware.","The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time."],"url":"http://arxiv.org/abs/2304.02948v1"}
{"created":"2023-04-06","title":"Multi-label classification of open-ended questions with BERT","abstract":"Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases. However, answers to open-ended questions are text data which are harder to analyze. Traditionally, answers were manually classified as specified in the coding manual. Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code. However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently. This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys. We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels). We find that classification with BERT (forcing at least one label) has the smallest 0/1 loss (13.1%) among methods considered (18.9%-21.6%). As expected, it is much easier to correctly predict answer texts that correspond to a single label (7.1% loss) than those that correspond to multiple labels ($\\sim$50% loss). Because BERT predicts zero labels for only 1.5% of the answers, forcing at least one label, while recommended, ultimately does not lower the 0/1 loss by much. Our work has important implications for social scientists: 1) We have shown multi-label classification with BERT works in the German language for open-ends. 2) For mildly multi-label classification tasks, the loss now appears small enough to allow for fully automatic classification (as compared to semi-automatic approaches). 3) Multi-label classification with BERT requires only a single model. The leading competitor, ECC, iterates through individual single label predictions.","sentences":["Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases.","However, answers to open-ended questions are text data which are harder to analyze.","Traditionally, answers were manually classified as specified in the coding manual.","Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code.","However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently.","This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys.","We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels).","We find that classification with BERT (forcing at least one label) has the smallest 0/1 loss (13.1%) among methods considered (18.9%-21.6%).","As expected, it is much easier to correctly predict answer texts that correspond to a single label (7.1% loss) than those that correspond to multiple labels ($\\sim$50% loss).","Because BERT predicts zero labels for only 1.5% of the answers, forcing at least one label, while recommended, ultimately does not lower the 0/1 loss by much.","Our work has important implications for social scientists: 1) We have shown multi-label classification with BERT works in the German language for open-ends.","2) For mildly multi-label classification tasks, the loss now appears small enough to allow for fully automatic classification (as compared to semi-automatic approaches).","3) Multi-label classification with BERT requires only a single model.","The leading competitor, ECC, iterates through individual single label predictions."],"url":"http://arxiv.org/abs/2304.02945v1"}
{"created":"2023-04-06","title":"Improved Hardness of Approximating k-Clique under ETH","abstract":"In this paper, we prove that assuming the exponential time hypothesis (ETH), there is no $f(k)\\cdot n^{k^{o(1/\\log\\log k)}}$-time algorithm that can decide whether an $n$-vertex graph contains a clique of size $k$ or contains no clique of size $k/2$, and no FPT algorithm can decide whether an input graph has a clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function in $k^{1-o(1)}$. Our results significantly improve the previous works [Lin21, LRSW22]. The crux of our proof is a framework to construct gap-producing reductions for the \\kclique{} problem. More precisely, we show that given an error-correcting code $C:\\Sigma_1^k\\to\\Sigma_2^{k'}$ that is locally testable and smooth locally decodable in the parallel setting, one can construct a reduction which on input a graph $G$ outputs a graph $G'$ in $(k')^{O(1)}\\cdot n^{O(\\log|\\Sigma_2|/\\log|\\Sigma_1|)}$ time such that:   $\\bullet$ If $G$ has a clique of size $k$, then $G'$ has a clique of size $K$, where $K = (k')^{O(1)}$.   $\\bullet$ If $G$ has no clique of size $k$, then $G'$ has no clique of size $(1-\\varepsilon)\\cdot K$ for some constant $\\varepsilon\\in(0,1)$.   We then construct such a code with $k'=k^{\\Theta(\\log\\log k)}$ and $|\\Sigma_2|=|\\Sigma_1|^{k^{0.54}}$, establishing the hardness results above. Our code generalizes the derivative code [WY07] into the case with a super constant order of derivatives.","sentences":["In this paper, we prove that assuming the exponential time hypothesis (ETH), there is no $f(k)\\cdot n^{k^{o(1/\\log\\log k)}}$-time algorithm that can decide whether an $n$-vertex graph contains a clique of size $k$ or contains no clique of size $k/2$, and no FPT algorithm can decide whether an input graph has a clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function in $k^{1-o(1)}$. Our results significantly improve the previous works","[Lin21, LRSW22].","The crux of our proof is a framework to construct gap-producing reductions for the \\kclique{} problem.","More precisely, we show that given an error-correcting code $C:\\Sigma_1^k\\to\\Sigma_2^{k'}$ that is locally testable and smooth locally decodable in the parallel setting, one can construct a reduction which on input a graph $G$ outputs a graph $G'$ in $(k')^{O(1)}\\cdot n^{O(\\log|\\Sigma_2|/\\log|\\Sigma_1|)}$ time such that:   $\\bullet$ If $G$ has a clique of size $k$, then $G'$ has a clique of size $K$, where $K = (k')^{O(1)}$.   $\\bullet$ If $G$ has no clique of size $k$, then $G'$ has no clique of size $(1-\\varepsilon)\\cdot K$ for some constant $\\varepsilon\\in(0,1)$.   We then construct such a code with $k'=k^{\\Theta(\\log\\log k)}$ and $|\\Sigma_2|=|\\Sigma_1|^{k^{0.54}}$, establishing the hardness results above.","Our code generalizes the derivative code","[WY07] into the case with a super constant order of derivatives."],"url":"http://arxiv.org/abs/2304.02943v1"}
{"created":"2023-04-06","title":"On Disturbance-to-State Adaptive Stabilization without Parameter Bound by Nonlinear Feedback of Delayed State and Input","abstract":"We complete the first step towards the resolution of several decades-old challenges in disturbance-robust adaptive control. For a scalar linear system with an unknown parameter for which no a priori bound is given, with a disturbance that is of unlimited magnitude and possibly persistent (not square integrable), and without a persistency of excitation necessarily verified by the state, we consider the problems of (practical) gain assignment relative to the disturbance. We provide a solution to these heretofore unsolved feedback design problems with the aid of infinite-dimensional nonlinear feedback employing distributed delay of the state and input itself. Specifically, in addition to (0) the global boundedness of the infinite-dimensional state of the closed-loop system when the disturbance is present, we establish (1) practical input-to-output stability with assignable asymptotic gain from the disturbance to the plant state; (2) assignable exponential convergence rate; and (3) assignable radius of the residual set. The accompanying identifier in our adaptive controller guarantees (4) boundedness of the parameter estimate even when disturbances are present; (5) an ultimate estimation error which is proportional to the magnitude of the disturbance with assignable gain when there exists sufficient excitation of the state; and (6) exact parameter estimation in finite-time when the disturbance is absent and there is sufficient excitation. Among our results, one reveals a tradeoff between \"learning capacity\" and \"disturbance robustness:\" the less sensitive the identifier is to the disturbance, the less likely it is to learn the parameter.","sentences":["We complete the first step towards the resolution of several decades-old challenges in disturbance-robust adaptive control.","For a scalar linear system with an unknown parameter for which no a priori bound is given, with a disturbance that is of unlimited magnitude and possibly persistent (not square integrable), and without a persistency of excitation necessarily verified by the state, we consider the problems of (practical) gain assignment relative to the disturbance.","We provide a solution to these heretofore unsolved feedback design problems with the aid of infinite-dimensional nonlinear feedback employing distributed delay of the state and input itself.","Specifically, in addition to (0) the global boundedness of the infinite-dimensional state of the closed-loop system when the disturbance is present, we establish (1) practical input-to-output stability with assignable asymptotic gain from the disturbance to the plant state; (2) assignable exponential convergence rate; and (3) assignable radius of the residual set.","The accompanying identifier in our adaptive controller guarantees (4) boundedness of the parameter estimate even when disturbances are present; (5) an ultimate estimation error which is proportional to the magnitude of the disturbance with assignable gain when there exists sufficient excitation of the state; and (6) exact parameter estimation in finite-time when the disturbance is absent and there is sufficient excitation.","Among our results, one reveals a tradeoff between \"learning capacity\" and \"disturbance robustness:\" the less sensitive the identifier is to the disturbance, the less likely it is to learn the parameter."],"url":"http://arxiv.org/abs/2304.02938v1"}
{"created":"2023-04-06","title":"Convolutional neural networks for crack detection on flexible road pavements","abstract":"Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions. Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards. In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying. However, surveying is still a tedious manual process. Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error. This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection. The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples. The effects of dataset augmentation are also investigated. Of the six models trained, five achieved accuracy above 97%. The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models. The dataset is available at the following URL: https://zenodo.org/record/7795975","sentences":["Flexible road pavements deteriorate primarily due to traffic and adverse environmental conditions.","Cracking is the most common deterioration mechanism; the surveying thereof is typically conducted manually using internationally defined classification standards.","In South Africa, the use of high-definition video images has been introduced, which allows for safer road surveying.","However, surveying is still a tedious manual process.","Automation of the detection of defects such as cracks would allow for faster analysis of road networks and potentially reduce human bias and error.","This study performs a comparison of six state-of-the-art convolutional neural network models for the purpose of crack detection.","The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples.","The effects of dataset augmentation are also investigated.","Of the six models trained, five achieved accuracy above 97%.","The highest recorded accuracy was 98%, achieved by the ResNet and VGG16 models.","The dataset is available at the following URL: https://zenodo.org/record/7795975"],"url":"http://arxiv.org/abs/2304.02933v1"}
{"created":"2023-04-06","title":"Efficient Audio Captioning Transformer with Patchout and Text Guidance","abstract":"Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity. Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022.","sentences":["Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip.","In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting.","The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions.","To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset.","Moreover, we propose a method to apply Mixup augmentation for AAC.","Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance.","The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity.","Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022."],"url":"http://arxiv.org/abs/2304.02916v1"}
{"created":"2023-04-06","title":"The Wright function -- hypergeometric representation and symbolical evaluation","abstract":"The Wright function, which arises in the theory of the space-time fractional diffusion equation, is an interesting mathematical object which has diverse connections with other special and elementary functions. The Wright function provides a unified treatment of several classes of special functions, such as the Gaussian, Airy, Bessel, and Error functions, etc. The manuscript demonstrates an algorithm for symbolical representation in terms of finite sums of hypergeometric (HG) functions and polynomials. The HG functions are then represented by known elementary or other special functions, wherever possible. The algorithm is programmed in the open-source computer algebra system Maxima and can be used to for testing numerical algorithms for the evaluation of the Wright function.","sentences":["The Wright function, which arises in the theory of the space-time fractional diffusion equation, is an interesting mathematical object which has diverse connections with other special and elementary functions.","The Wright function provides a unified treatment of several classes of special functions, such as the Gaussian, Airy, Bessel, and Error functions, etc.","The manuscript demonstrates an algorithm for symbolical representation in terms of finite sums of hypergeometric (HG) functions and polynomials.","The HG functions are then represented by known elementary or other special functions, wherever possible.","The algorithm is programmed in the open-source computer algebra system Maxima and can be used to for testing numerical algorithms for the evaluation of the Wright function."],"url":"http://arxiv.org/abs/2304.02903v1"}
{"created":"2023-04-06","title":"SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention","abstract":"Extracting entities and relations is an essential task of information extraction. Triplets extracted from a sentence might overlap with each other. Previous methods either did not address the overlapping issues or solved overlapping issues partially. To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism. Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects. Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations. We test our method on two public datasets, our method achieves the best performances on these two datasets.","sentences":["Extracting entities and relations is an essential task of information extraction.","Triplets extracted from a sentence might overlap with each other.","Previous methods either did not address the overlapping issues or solved overlapping issues partially.","To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism.","Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects.","Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations.","We test our method on two public datasets, our method achieves the best performances on these two datasets."],"url":"http://arxiv.org/abs/2304.02901v1"}
{"created":"2023-04-06","title":"LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries","abstract":"Graph streams represent data interactions in real applications. The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others. However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them. Current studies apply sketches to summarize graph streams. We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches. In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance. Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically. LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy. We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency.","sentences":["Graph streams represent data interactions in real applications.","The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others.","However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them.","Current studies apply sketches to summarize graph streams.","We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches.","In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance.","Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically.","LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy.","We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency."],"url":"http://arxiv.org/abs/2304.02897v1"}
{"created":"2023-04-06","title":"Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients","abstract":"Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees. In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise). The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective. To address the challenges, we propose FedCNI without using an additional clean proxy dataset. It includes a noise-resilient local solver and a robust global aggregator. For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples. Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy. For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods. Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments.","sentences":["Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees.","In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise).","The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective.","To address the challenges, we propose FedCNI without using an additional clean proxy dataset.","It includes a noise-resilient local solver and a robust global aggregator.","For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples.","Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy.","For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods.","Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments."],"url":"http://arxiv.org/abs/2304.02892v1"}
{"created":"2023-04-06","title":"Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts","abstract":"Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research. NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language. This paper adapts these models to automatically associate the ICD codes. Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed. In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association. Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results.","sentences":["Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research.","NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language.","This paper adapts these models to automatically associate the ICD codes.","Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed.","In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association.","Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results."],"url":"http://arxiv.org/abs/2304.02886v1"}
{"created":"2023-04-06","title":"Tag that issue: Applying API-domain labels in issue tracking systems","abstract":"Labeling issues with the skills required to complete them can help contributors to choose tasks in Open Source Software projects. However, manually labeling issues is time-consuming and error-prone, and current automated approaches are mostly limited to classifying issues as bugs/non-bugs. We investigate the feasibility and relevance of automatically labeling issues with what we call \"API-domains,\" which are high-level categories of APIs. Therefore, we posit that the APIs used in the source code affected by an issue can be a proxy for the type of skills (e.g., DB, security, UI) needed to work on the issue. We ran a user study (n=74) to assess API-domain labels' relevancy to potential contributors, leveraged the issues' descriptions and the project history to build prediction models, and validated the predictions with contributors (n=20) of the projects. Our results show that (i) newcomers to the project consider API-domain labels useful in choosing tasks, (ii) labels can be predicted with a precision of 84% and a recall of 78.6% on average, (iii) the results of the predictions reached up to 71.3% in precision and 52.5% in recall when training with a project and testing in another (transfer learning), and (iv) project contributors consider most of the predictions helpful in identifying needed skills. These findings suggest our approach can be applied in practice to automatically label issues, assisting developers in finding tasks that better match their skills.","sentences":["Labeling issues with the skills required to complete them can help contributors to choose tasks in Open Source Software projects.","However, manually labeling issues is time-consuming and error-prone, and current automated approaches are mostly limited to classifying issues as bugs/non-bugs.","We investigate the feasibility and relevance of automatically labeling issues with what we call \"API-domains,\" which are high-level categories of APIs.","Therefore, we posit that the APIs used in the source code affected by an issue can be a proxy for the type of skills (e.g., DB, security, UI) needed to work on the issue.","We ran a user study (n=74) to assess API-domain labels' relevancy to potential contributors, leveraged the issues' descriptions and the project history to build prediction models, and validated the predictions with contributors (n=20) of the projects.","Our results show that (i) newcomers to the project consider API-domain labels useful in choosing tasks, (ii) labels can be predicted with a precision of 84% and a recall of 78.6% on average, (iii) the results of the predictions reached up to 71.3% in precision and 52.5% in recall when training with a project and testing in another (transfer learning), and (iv) project contributors consider most of the predictions helpful in identifying needed skills.","These findings suggest our approach can be applied in practice to automatically label issues, assisting developers in finding tasks that better match their skills."],"url":"http://arxiv.org/abs/2304.02877v1"}
{"created":"2023-04-06","title":"Learning to Learn with Indispensable Connections","abstract":"Meta-learning aims to solve unseen tasks with few labelled instances. Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws. Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network. Because of this, meta-testing observes unnecessary computations and extra memory overhead. To overcome such flaws. We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections. We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem. We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase. Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets. Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset.","sentences":["Meta-learning aims to solve unseen tasks with few labelled instances.","Nevertheless, despite its effectiveness for quick learning in existing optimization-based methods, it has several flaws.","Inconsequential connections are frequently seen during meta-training, which results in an over-parameterized neural network.","Because of this, meta-testing observes unnecessary computations and extra memory overhead.","To overcome such flaws.","We propose a novel meta-learning method called Meta-LTH that includes indispensible (necessary) connections.","We applied the lottery ticket hypothesis technique known as magnitude pruning to generate these crucial connections that can effectively solve few-shot learning problem.","We aim to perform two things: (a) to find a sub-network capable of more adaptive meta-learning and (b) to learn new low-level features of unseen tasks and recombine those features with the already learned features during the meta-test phase.","Experimental results show that our proposed Met-LTH method outperformed existing first-order MAML algorithm for three different classification datasets.","Our method improves the classification accuracy by approximately 2% (20-way 1-shot task setting) for omniglot dataset."],"url":"http://arxiv.org/abs/2304.02862v1"}
{"created":"2023-04-06","title":"Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification","abstract":"A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.","sentences":["A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood.","This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples.","Intuitively, this behavior can improve robustness against label noise by reducing overfitting.","We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties.","We evaluate the effectiveness of the method by measuring its robustness against label noise in classification.","We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more."],"url":"http://arxiv.org/abs/2304.02849v1"}
{"created":"2023-04-06","title":"Probing the Purview of Neural Networks via Gradient Analysis","abstract":"We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference. The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data. We define purview as the additional capacity necessary to characterize inference samples that differ from the training data. To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately. To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels. We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features. We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples. Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.","sentences":["We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference.","The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data.","We define purview as the additional capacity necessary to characterize inference samples that differ from the training data.","To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately.","To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels.","We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features.","We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples.","Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively."],"url":"http://arxiv.org/abs/2304.02834v1"}
{"created":"2023-04-06","title":"Source-free Domain Adaptation Requires Penalized Diversity","abstract":"While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset. Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy. Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains. In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor. Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA). Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses. Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy. Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift. In addition, PD is augmented with a weighted MI maximization objective for label distribution shift. Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts.","sentences":["While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset.","Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy.","Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains.","In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor.","Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA).","Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses.","Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy.","Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift.","In addition, PD is augmented with a weighted MI maximization objective for label distribution shift.","Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts."],"url":"http://arxiv.org/abs/2304.02798v1"}
{"created":"2023-04-05","title":"Improving pulsar-timing solutions through dynamic pulse fitting","abstract":"Precision pulsar timing is integral to the detection of the nanohertz stochastic gravitational-wave background as well as understanding the physics of neutron stars. Conventional pulsar timing often uses fixed time and frequency-averaged templates to determine the pulse times of arrival, which can lead to reduced accuracy when the pulse profile evolves over time. We illustrate a dynamic timing method that fits each observing epoch using basis functions. By fitting each epoch separately, we allow for the evolution of the pulse shape epoch to epoch. We apply our method to PSR J1103$-$5403 and demonstrate that it undergoes mode changing, making it the fourth millisecond pulsar to exhibit such behaviour. Our method, which is able to identify and time a single mode, yields a timing solution with a root-mean-square error of 1.343 $\\mu \\mathrm{s}$, a factor of 1.78 improvement over template fitting on both modes. In addition, the white-noise amplitude is reduced 4.3 times, suggesting that fitting the full data set causes the mode changing to be incorrectly classified as white noise. This reduction in white noise boosts the signal-to-noise ratio of a gravitational-wave background signal for this particular pulsar by 32%. We discuss the possible applications for this method of timing to study pulsar magnetospheres and further improve the sensitivity of searches for nanohertz gravitational waves.","sentences":["Precision pulsar timing is integral to the detection of the nanohertz stochastic gravitational-wave background as well as understanding the physics of neutron stars.","Conventional pulsar timing often uses fixed time and frequency-averaged templates to determine the pulse times of arrival, which can lead to reduced accuracy when the pulse profile evolves over time.","We illustrate a dynamic timing method that fits each observing epoch using basis functions.","By fitting each epoch separately, we allow for the evolution of the pulse shape epoch to epoch.","We apply our method to PSR J1103$-$5403 and demonstrate that it undergoes mode changing, making it the fourth millisecond pulsar to exhibit such behaviour.","Our method, which is able to identify and time a single mode, yields a timing solution with a root-mean-square error of 1.343 $\\mu \\mathrm{s}$, a factor of 1.78 improvement over template fitting on both modes.","In addition, the white-noise amplitude is reduced 4.3 times, suggesting that fitting the full data set causes the mode changing to be incorrectly classified as white noise.","This reduction in white noise boosts the signal-to-noise ratio of a gravitational-wave background signal for this particular pulsar by 32%.","We discuss the possible applications for this method of timing to study pulsar magnetospheres and further improve the sensitivity of searches for nanohertz gravitational waves."],"url":"http://arxiv.org/abs/2304.02793v1"}
{"created":"2023-04-05","title":"The Colorado Ultraviolet Transit Experiment (CUTE) signal to noise calculator","abstract":"We present here the signal-to-noise (S/N) calculator developed for the Colorado Ultraviolet Transit Experiment (CUTE) mission. CUTE is a 6U CubeSat operating in the near-ultraviolet (NUV) observing exoplanetary transits to study their upper atmospheres. CUTE was launched into a low-Earth orbit in September 2021 and it is currently gathering scientific data. As part of the S/N calculator, we also present the error propagation for computing transit depth uncertainties starting from the S/N of the original spectroscopic observations. The CUTE S/N calculator is currently extensively used for target selection and scheduling. The modular construction of the CUTE S/N calculator enables its adaptation and can be used also for other missions and instruments.","sentences":["We present here the signal-to-noise (S/N) calculator developed for the Colorado Ultraviolet Transit Experiment (CUTE) mission.","CUTE is a 6U CubeSat operating in the near-ultraviolet (NUV) observing exoplanetary transits to study their upper atmospheres.","CUTE was launched into a low-Earth orbit in September 2021 and it is currently gathering scientific data.","As part of the S/N calculator, we also present the error propagation for computing transit depth uncertainties starting from the S/N of the original spectroscopic observations.","The CUTE S/N calculator is currently extensively used for target selection and scheduling.","The modular construction of the CUTE S/N calculator enables its adaptation and can be used also for other missions and instruments."],"url":"http://arxiv.org/abs/2304.02776v1"}
{"created":"2023-04-05","title":"MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection","abstract":"Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methane plume sites. Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact. Dataset and source code are public","sentences":["Methane (CH$_4$) is the chief contributor to global climate change.","Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions.","Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable.","To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions.","MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately.","Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art.","In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022.","It contains over 4000 methane plume sites.","Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact.","Dataset and source code are public"],"url":"http://arxiv.org/abs/2304.02767v1"}
{"created":"2023-04-05","title":"A Robust Observer with Gyroscopic Bias Correction for Rotational Dynamics","abstract":"We propose an observer for rotational dynamics subject to directional and gyroscopic measurements, which simultaneously estimates the gyroscopic biases and attitude rates. We show uniform almost global asymptotic and local exponential stability of the resulting error dynamics, implying robustness against bounded disturbances. This robustness is quantified with respect to a popular nonlinear complementary filter in quantitative simulation studies, and we explore how the measurement noise propagates to the asymptotic errors as a function of tuning. This is an extended version of a paper with the same title (to appear at IFAC WC 2023). Additional mathematical details are provided in this extended version.","sentences":["We propose an observer for rotational dynamics subject to directional and gyroscopic measurements, which simultaneously estimates the gyroscopic biases and attitude rates.","We show uniform almost global asymptotic and local exponential stability of the resulting error dynamics, implying robustness against bounded disturbances.","This robustness is quantified with respect to a popular nonlinear complementary filter in quantitative simulation studies, and we explore how the measurement noise propagates to the asymptotic errors as a function of tuning.","This is an extended version of a paper with the same title (to appear at IFAC WC 2023).","Additional mathematical details are provided in this extended version."],"url":"http://arxiv.org/abs/2304.02763v1"}
{"created":"2023-04-05","title":"Integrating U-nets into a Multi-scale Waveform Inversion for Salt Body Building","abstract":"In salt provinces, full-waveform inversion (FWI) is most likely to fail when starting with a poor initial model that lacks the salt information. Conventionally, salt bodies are included in the FWI starting model by interpreting the salt boundaries from seismic images, which is time-consuming and prone to error. Studies show that FWI can improve the interpreted salt provided that the data are recorded using long offsets, and contain low frequencies, which are not always available. Thus, we develop an approach to invert for the salt body starting from a poor initial model, limited data offsets, and the absence of low frequencies. We leverage deep learning to apply multi-stage flooding and unflooding of the velocity model. Specifically, we apply a multi-scale FWI using three frequency bandwidths. We apply a network after each frequency scale. After the first two bandwidths, the networks are trained to flood the salt, while the network after the last frequency bandwidth is trained to unflood it. We verify the method on the synthetic BP 2004 salt model benchmark. We only use the synthetic data of short offsets up to 6 km and remove frequencies below 3 Hz. We also apply the method to real vintage data acquired in the Gulf of Mexico region. The real data lack frequencies below 6 Hz and the streamer length is only 4.8 km. With these limitations, we manage to recover the salt body and verify the result by using them to image the data and analyze the resulting angle gathers.","sentences":["In salt provinces, full-waveform inversion (FWI) is most likely to fail when starting with a poor initial model that lacks the salt information.","Conventionally, salt bodies are included in the FWI starting model by interpreting the salt boundaries from seismic images, which is time-consuming and prone to error.","Studies show that FWI can improve the interpreted salt provided that the data are recorded using long offsets, and contain low frequencies, which are not always available.","Thus, we develop an approach to invert for the salt body starting from a poor initial model, limited data offsets, and the absence of low frequencies.","We leverage deep learning to apply multi-stage flooding and unflooding of the velocity model.","Specifically, we apply a multi-scale FWI using three frequency bandwidths.","We apply a network after each frequency scale.","After the first two bandwidths, the networks are trained to flood the salt, while the network after the last frequency bandwidth is trained to unflood it.","We verify the method on the synthetic BP 2004 salt model benchmark.","We only use the synthetic data of short offsets up to 6 km and remove frequencies below 3 Hz.","We also apply the method to real vintage data acquired in the Gulf of Mexico region.","The real data lack frequencies below 6 Hz and the streamer length is only 4.8 km.","With these limitations, we manage to recover the salt body and verify the result by using them to image the data and analyze the resulting angle gathers."],"url":"http://arxiv.org/abs/2304.02758v1"}
{"created":"2023-04-05","title":"Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks","abstract":"This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy. The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups. Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology.","sentences":["This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data.","With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information.","Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali.","We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy.","The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups.","Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology."],"url":"http://arxiv.org/abs/2304.02739v1"}
{"created":"2023-04-05","title":"Core Challenges in Embodied Vision-Language Planning","abstract":"Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks. Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment.","sentences":["Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics.","Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three.","Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field.","In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments.","We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.","Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalisability and furthers real-world deployment."],"url":"http://arxiv.org/abs/2304.02738v1"}
{"created":"2023-04-05","title":"Efficient OCR for Building a Diverse Digital History","abstract":"Thousands of users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) - which jointly learns a vision and language model - is poorly extensible to low-resource document collections, as learning a language-vision model requires extensive labeled sequences and compute. This study models OCR as a character level image retrieval problem, using a contrastively trained vision encoder. Because the model only learns characters' visual features, it is more sample efficient and extensible than existing architectures, enabling accurate OCR in settings where existing solutions fail. Crucially, the model opens new avenues for community engagement in making digital history more representative of documentary history.","sentences":["Thousands of users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history.","The sequence-to-sequence architecture typically used for optical character recognition (OCR) - which jointly learns a vision and language model - is poorly extensible to low-resource document collections, as learning a language-vision model requires extensive labeled sequences and compute.","This study models OCR as a character level image retrieval problem, using a contrastively trained vision encoder.","Because the model only learns characters' visual features, it is more sample efficient and extensible than existing architectures, enabling accurate OCR in settings where existing solutions fail.","Crucially, the model opens new avenues for community engagement in making digital history more representative of documentary history."],"url":"http://arxiv.org/abs/2304.02737v1"}
{"created":"2023-04-05","title":"Holographic Codes from Hyperinvariant Tensor Networks","abstract":"Holographic quantum-error correcting codes are models of bulk/boundary dualities such as the anti-de Sitter/conformal field theory (AdS/CFT) correspondence, where a higher-dimensional bulk geometry is associated with the code's logical degrees of freedom. Previous discrete holographic codes based on tensor networks have reproduced the general code properties expected from continuum AdS/CFT, such as complementary recovery. However, the boundary states of such tensor networks typically do not exhibit the expected correlation functions of CFT boundary states. In this work, we show that a new class of exact holographic codes, extending the previously proposed hyperinvariant tensor networks into quantum codes, produce the correct boundary correlation functions. This approach yields a dictionary between logical states in the bulk and the critical renormalization group flow of boundary states. Furthermore, these codes exhibit a state-dependent breakdown of complementary recovery as expected from AdS/CFT under small quantum gravity corrections.","sentences":["Holographic quantum-error correcting codes are models of bulk/boundary dualities such as the anti-de Sitter/conformal field theory (AdS/CFT) correspondence, where a higher-dimensional bulk geometry is associated with the code's logical degrees of freedom.","Previous discrete holographic codes based on tensor networks have reproduced the general code properties expected from continuum AdS/CFT, such as complementary recovery.","However, the boundary states of such tensor networks typically do not exhibit the expected correlation functions of CFT boundary states.","In this work, we show that a new class of exact holographic codes, extending the previously proposed hyperinvariant tensor networks into quantum codes, produce the correct boundary correlation functions.","This approach yields a dictionary between logical states in the bulk and the critical renormalization group flow of boundary states.","Furthermore, these codes exhibit a state-dependent breakdown of complementary recovery as expected from AdS/CFT under small quantum gravity corrections."],"url":"http://arxiv.org/abs/2304.02732v1"}
{"created":"2023-04-05","title":"A Quantum-Chemical Bonding Database for Solid-State Materials","abstract":"An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials. Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties. Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis. With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data. We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database. The database structure of the bonding analysis database, which allows easy data retrieval, is also explained. The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively. Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features.","sentences":["An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials.","Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties.","Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis.","With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data.","We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database.","The database structure of the bonding analysis database, which allows easy data retrieval, is also explained.","The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively.","Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features."],"url":"http://arxiv.org/abs/2304.02726v1"}
{"created":"2023-04-05","title":"FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation","abstract":"Accurate medical imaging segmentation is critical for precise and effective medical interventions. However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales. These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge. In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors. Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges. Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency. These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation.","sentences":["Accurate medical imaging segmentation is critical for precise and effective medical interventions.","However, despite the success of convolutional neural networks (CNNs) in medical image segmentation, they still face challenges in handling fine-scale features and variations in image scales.","These challenges are particularly evident in complex and challenging segmentation tasks, such as the BraTS multi-label brain tumor segmentation challenge.","In this task, accurately segmenting the various tumor sub-components, which vary significantly in size and shape, remains a significant challenge, with even state-of-the-art methods producing substantial errors.","Therefore, we propose two architectures, FMG-Net and W-Net, that incorporate the principles of geometric multigrid methods for solving linear systems of equations into CNNs to address these challenges.","Our experiments on the BraTS 2020 dataset demonstrate that both FMG-Net and W-Net outperform the widely used U-Net architecture regarding tumor subcomponent segmentation accuracy and training efficiency.","These findings highlight the potential of incorporating the principles of multigrid methods into CNNs to improve the accuracy and efficiency of medical imaging segmentation."],"url":"http://arxiv.org/abs/2304.02725v1"}
{"created":"2023-04-05","title":"Anisotropic Hubble Expansion in Pantheon+ Supernovae","abstract":"We decompose the Pantheon+ Type Ia supernovae (SN) sample in hemispheres on the sky finding angular variations up to $4$ km/s/Mpc in the Hubble constant $H_0$ both in the SH0ES redshift range $0.0233 < z < 0.15$ and in the extended redshift range $0.01 < z < 0.7$. We assume the $\\Lambda$CDM model, so our findings become model dependent in extended redshift ranges. $H_0$ is larger in a hemisphere encompassing the CMB dipole direction. The variations we see exceed the errors on the recent SH0ES determination, $H_0 = 73.04 \\pm 1.04$ km/s/Mpc, but are not large enough to explain early versus late Universe discrepancies in the Hubble constant. The removal of low redshift SN leads to a weakening of angular $H_0$ variations, but we confirm that they persist beyond the influence of the Shapley supercluster $z > 0.06$","sentences":["We decompose the Pantheon+ Type Ia supernovae (SN) sample in hemispheres on the sky finding angular variations up to $4$ km/s/Mpc in the Hubble constant $H_0$ both in the SH0ES redshift range $0.0233 <","z < 0.15$ and in the extended redshift range $0.01 <","z < 0.7$. We assume the $\\Lambda$CDM model, so our findings become model dependent in extended redshift ranges.","$H_0$ is larger in a hemisphere encompassing the CMB dipole direction.","The variations we see exceed the errors on the recent SH0ES determination, $H_0 = 73.04 \\pm 1.04$ km/s/Mpc, but are not large enough to explain early versus late Universe discrepancies in the Hubble constant.","The removal of low redshift SN leads to a weakening of angular $H_0$ variations, but we confirm that they persist beyond the influence of the Shapley supercluster $z > 0.06$"],"url":"http://arxiv.org/abs/2304.02718v1"}
{"created":"2023-04-05","title":"Learning Stage-wise GANs for Whistle Extraction in Time-Frequency Spectrograms","abstract":"Whistle contour extraction aims to derive animal whistles from time-frequency spectrograms as polylines. For toothed whales, whistle extraction results can serve as the basis for analyzing animal abundance, species identity, and social activities. During the last few decades, as long-term recording systems have become affordable, automated whistle extraction algorithms were proposed to process large volumes of recording data. Recently, a deep learning-based method demonstrated superior performance in extracting whistles under varying noise conditions. However, training such networks requires a large amount of labor-intensive annotation, which is not available for many species. To overcome this limitation, we present a framework of stage-wise generative adversarial networks (GANs), which compile new whistle data suitable for deep model training via three stages: generation of background noise in the spectrogram, generation of whistle contours, and generation of whistle signals. By separating the generation of different components in the samples, our framework composes visually promising whistle data and labels even when few expert annotated data are available. Regardless of the amount of human-annotated data, the proposed data augmentation framework leads to a consistent improvement in performance of the whistle extraction model, with a maximum increase of 1.69 in the whistle extraction mean F1-score. Our stage-wise GAN also surpasses one single GAN in improving whistle extraction models with augmented data. The data and code will be available at https://github.com/Paul-LiPu/CompositeGAN\\_WhistleAugment.","sentences":["Whistle contour extraction aims to derive animal whistles from time-frequency spectrograms as polylines.","For toothed whales, whistle extraction results can serve as the basis for analyzing animal abundance, species identity, and social activities.","During the last few decades, as long-term recording systems have become affordable, automated whistle extraction algorithms were proposed to process large volumes of recording data.","Recently, a deep learning-based method demonstrated superior performance in extracting whistles under varying noise conditions.","However, training such networks requires a large amount of labor-intensive annotation, which is not available for many species.","To overcome this limitation, we present a framework of stage-wise generative adversarial networks (GANs), which compile new whistle data suitable for deep model training via three stages: generation of background noise in the spectrogram, generation of whistle contours, and generation of whistle signals.","By separating the generation of different components in the samples, our framework composes visually promising whistle data and labels even when few expert annotated data are available.","Regardless of the amount of human-annotated data, the proposed data augmentation framework leads to a consistent improvement in performance of the whistle extraction model, with a maximum increase of 1.69 in the whistle extraction mean F1-score.","Our stage-wise GAN also surpasses one single GAN in improving whistle extraction models with augmented data.","The data and code will be available at https://github.com/Paul-LiPu/CompositeGAN\\_WhistleAugment."],"url":"http://arxiv.org/abs/2304.02714v1"}
{"created":"2023-04-05","title":"Human Error Management in Requirements Engineering: Should We Fix the People, the Processes, or the Environment?","abstract":"Context: Software development is human-centric and vulnerable to human error. Human errors are errors in the human thought process. To ensure software quality, practitioners must understand how to manage these human errors. Organizations often change the requirements engineering process to prevent human errors from occurring or to mitigate the harm caused when those errors do occur. While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in software engineering, and requirements engineering specifically, are limited. The software engineering studies do not provide strong results about the types of changes that are most effective in requirements engineering. Objective: The goal of this paper is to develop a taxonomy of human error prevention and mitigation strategies based on data from requirements engineering professionals. Method: We performed a qualitative analysis of two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors. Results: We organized the human error management strategies into a taxonomy based on whether they primarily affect People, Processes, or the Environment. Inside each high-level category, we further organized the strategies into low-level classes. More than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify. In addition, more than 50\\% of the strategies focus on Management activities. Conclusions: The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering. This systematic organization provides a foundation upon which research can build.","sentences":["Context: Software development is human-centric and vulnerable to human error.","Human errors are errors in the human thought process.","To ensure software quality, practitioners must understand how to manage these human errors.","Organizations often change the requirements engineering process to prevent human errors from occurring or to mitigate the harm caused when those errors do occur.","While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in software engineering, and requirements engineering specifically, are limited.","The software engineering studies do not provide strong results about the types of changes that are most effective in requirements engineering.","Objective: The goal of this paper is to develop a taxonomy of human error prevention and mitigation strategies based on data from requirements engineering professionals.","Method: We performed a qualitative analysis of two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors.","Results:","We organized the human error management strategies into a taxonomy based on whether they primarily affect People, Processes, or the Environment.","Inside each high-level category, we further organized the strategies into low-level classes.","More than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify.","In addition, more than 50\\% of the strategies focus on Management activities.","Conclusions: The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering.","This systematic organization provides a foundation upon which research can build."],"url":"http://arxiv.org/abs/2304.02702v1"}
{"created":"2023-04-05","title":"Fixing the Kawarabayashi-Thomas-Wollan Flat Wall","abstract":"Two recent papers by Kawarabayashi, Thomas and Wollan, \"A New Proof of the Flat Wall Theorem\" (arXiv:1207.6927) and \"Quickly Excluding a Non-Planar Graph\" (arXiv:2010.12397) provide major improvements over Robertson and Seymour's original proof of the structure theorem for finite graphs that exclude a given graph. The first paper redefines the notion of a flat wall. Unfortunately, this new notion is too strong. As a result, the new Flat Wall Theorem in that paper is incorrect. A counterexample is given in Appendix A. A follow-on lemma in the first paper, about the transitivity of flatness, is also incorrect, a fact that was noticed by Dimitrios Thilikos et al in arXiv:2102.06463. However, that error is derivative and not the main issue. This paper provides a weaker definition of the notion of a flat wall, provides a correction to the proof of the new Flat Wall Theorem and a new proof of flatness transitivity. The notion of a tight rendition as presented here differs from Thilikos' definition but is defined much more simply, and the notion of a proper cycle is introduced. The notions of certificates and tilted walls used by Thilikos turn out of be unnecessary and transitivity is preserved in its original simplicity and generality. Most importantly, it looks like the new weaker definition of flatness is all that is really necessary to carry through the proof of the structure theorem in the second paper of Kawarabayashi, Thomas and Wollan.","sentences":["Two recent papers by Kawarabayashi, Thomas and Wollan, \"A New Proof of the Flat Wall Theorem\" (arXiv:1207.6927) and \"Quickly Excluding a Non-Planar Graph\" (arXiv:2010.12397) provide major improvements over Robertson and Seymour's original proof of the structure theorem for finite graphs that exclude a given graph.","The first paper redefines the notion of a flat wall.","Unfortunately, this new notion is too strong.","As a result, the new Flat Wall Theorem in that paper is incorrect.","A counterexample is given in Appendix A. A follow-on lemma in the first paper, about the transitivity of flatness, is also incorrect, a fact that was noticed by Dimitrios Thilikos et al in arXiv:2102.06463.","However, that error is derivative and not the main issue.","This paper provides a weaker definition of the notion of a flat wall, provides a correction to the proof of the new Flat Wall Theorem and a new proof of flatness transitivity.","The notion of a tight rendition as presented here differs from Thilikos' definition but is defined much more simply, and the notion of a proper cycle is introduced.","The notions of certificates and tilted walls used by Thilikos turn out of be unnecessary and transitivity is preserved in its original simplicity and generality.","Most importantly, it looks like the new weaker definition of flatness is all that is really necessary to carry through the proof of the structure theorem in the second paper of Kawarabayashi, Thomas and Wollan."],"url":"http://arxiv.org/abs/2304.02701v1"}
{"created":"2023-04-05","title":"Agnostic proper learning of monotone functions: beyond the black-box correction barrier","abstract":"We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this gap in our knowledge between the run-time and sample complexity.   This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs. This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels.","sentences":["We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions.","Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function.","The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15).","We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient.","Our work thus closes this gap in our knowledge between the run-time and sample complexity.   ","This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs.","This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   ","Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels."],"url":"http://arxiv.org/abs/2304.02700v1"}
{"created":"2023-04-05","title":"A Unified Approach to Optimally Solving Sensor Scheduling and Sensor Selection Problems in Kalman Filtering","abstract":"We consider a general form of the sensor scheduling problem for state estimation of linear dynamical systems, which involves selecting sensors that minimize the trace of the Kalman filter error covariance (weighted by a positive semidefinite matrix) subject to polyhedral constraints on the selected sensors. This general form captures several well-studied problems including sensor placement, sensor scheduling with budget constraints, and Linear Quadratic Gaussian (LQG) control and sensing co-design. We present a mixed integer optimization approach that is derived by exploiting the optimality of the Kalman filter. While existing work has focused on approximate methods to specific problem variants, our work provides a unified approach to computing optimal solutions to the general version of sensor scheduling. In simulation, we show this approach finds optimal solutions for systems with 30 to 50 states in seconds.","sentences":["We consider a general form of the sensor scheduling problem for state estimation of linear dynamical systems, which involves selecting sensors that minimize the trace of the Kalman filter error covariance (weighted by a positive semidefinite matrix) subject to polyhedral constraints on the selected sensors.","This general form captures several well-studied problems including sensor placement, sensor scheduling with budget constraints, and Linear Quadratic Gaussian (LQG) control and sensing co-design.","We present a mixed integer optimization approach that is derived by exploiting the optimality of the Kalman filter.","While existing work has focused on approximate methods to specific problem variants, our work provides a unified approach to computing optimal solutions to the general version of sensor scheduling.","In simulation, we show this approach finds optimal solutions for systems with 30 to 50 states in seconds."],"url":"http://arxiv.org/abs/2304.02692v1"}
{"created":"2023-04-05","title":"ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast","abstract":"Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects). Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria. However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced. In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation. Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers. Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes. Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings. Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency.","sentences":["Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects).","Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria.","However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced.","In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation.","Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers.","Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes.","Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings.","Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency."],"url":"http://arxiv.org/abs/2304.02689v1"}
{"created":"2023-04-05","title":"Chebyshev approximation of exponential data","abstract":"In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm. We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset.","sentences":["In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm.","We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset."],"url":"http://arxiv.org/abs/2304.02686v1"}
{"created":"2023-04-05","title":"High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation","abstract":"The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior. As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines. This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset. Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting. Our code is available at https://github.com/arvijj/hfpl.","sentences":["The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models.","The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps.","This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions.","The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth.","In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images.","In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior.","As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines.","This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset.","Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting.","Our code is available at https://github.com/arvijj/hfpl."],"url":"http://arxiv.org/abs/2304.02621v1"}
{"created":"2023-04-05","title":"Efficient Quantum Algorithms for Quantum Optimal Control","abstract":"In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem. This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schr\\\"odinger equation. This type of control problem also has an intricate relation with machine learning. Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm. We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schr\\\"odinger equation, the numerical quadrature, and optimization. Our quantum algorithms require fault-tolerant quantum computers.","sentences":["In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem.","This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schr\\\"odinger equation.","This type of control problem also has an intricate relation with machine learning.","Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm.","We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schr\\\"odinger equation, the numerical quadrature, and optimization.","Our quantum algorithms require fault-tolerant quantum computers."],"url":"http://arxiv.org/abs/2304.02613v1"}
{"created":"2023-04-05","title":"Energy Efficiency of Unsourced Random Access over the Binary-Input Gaussian Channel","abstract":"We investigate the fundamental limits of the unsourced random access over the binary-input Gaussian channel. By fundamental limits, we mean the minimal energy per bit required to achieve the target per-user probability of error. The original method proposed by Y. Polyanskiy (2017) and based on Gallager's trick does not work well for binary signaling. We utilize Fano's method, which is based on the choice of the so-called ``good'' region. We apply this method for the cases of Gaussian and binary codebooks and obtain two achievability bounds. The first bound is very close to Polyanskiy's bound but does not lead to any improvement. At the same time, the numerical results show that the bound for the binary case practically coincides with the bound for the Gaussian codebook. Thus, we conclude that binary modulation does not lead to performance degradation, and energy-efficient schemes with binary modulation do exist.","sentences":["We investigate the fundamental limits of the unsourced random access over the binary-input Gaussian channel.","By fundamental limits, we mean the minimal energy per bit required to achieve the target per-user probability of error.","The original method proposed by Y. Polyanskiy (2017) and based on Gallager's trick does not work well for binary signaling.","We utilize Fano's method, which is based on the choice of the so-called ``good'' region.","We apply this method for the cases of Gaussian and binary codebooks and obtain two achievability bounds.","The first bound is very close to Polyanskiy's bound but does not lead to any improvement.","At the same time, the numerical results show that the bound for the binary case practically coincides with the bound for the Gaussian codebook.","Thus, we conclude that binary modulation does not lead to performance degradation, and energy-efficient schemes with binary modulation do exist."],"url":"http://arxiv.org/abs/2304.02598v1"}
{"created":"2023-04-05","title":"A force-sensing surgical drill for real-time force feedback in robotic mastoidectomy","abstract":"Purpose: Robotic assistance in otologic surgery can reduce the task load of operating surgeons during the removal of bone around the critical structures in the lateral skull base. However, safe deployment into the anatomical passageways necessitates the development of advanced sensing capabilities to actively limit the interaction forces between the surgical tools and critical anatomy.   Methods: We introduce a surgical drill equipped with a force sensor that is capable of measuring accurate tool-tissue interaction forces to enable force control and feedback to surgeons. The design, calibration and validation of the force-sensing surgical drill mounted on a cooperatively controlled surgical robot are described in this work.   Results: The force measurements on the tip of the surgical drill are validated with raw-egg drilling experiments, where a force sensor mounted below the egg serves as ground truth. The average root mean square error (RMSE) for points and path drilling experiments are 41.7 (pm 12.2) mN and 48.3 (pm 13.7) mN respectively.   Conclusions: The force-sensing prototype measures forces with sub-millinewton resolution and the results demonstrate that the calibrated force-sensing drill generates accurate force measurements with minimal error compared to the measured drill forces. The development of such sensing capabilities is crucial for the safe use of robotic systems in a clinical context.","sentences":["Purpose: Robotic assistance in otologic surgery can reduce the task load of operating surgeons during the removal of bone around the critical structures in the lateral skull base.","However, safe deployment into the anatomical passageways necessitates the development of advanced sensing capabilities to actively limit the interaction forces between the surgical tools and critical anatomy.   ","Methods: We introduce a surgical drill equipped with a force sensor that is capable of measuring accurate tool-tissue interaction forces to enable force control and feedback to surgeons.","The design, calibration and validation of the force-sensing surgical drill mounted on a cooperatively controlled surgical robot are described in this work.   ","Results:","The force measurements on the tip of the surgical drill are validated with raw-egg drilling experiments, where a force sensor mounted below the egg serves as ground truth.","The average root mean square error (RMSE) for points and path drilling experiments are 41.7 (pm 12.2) mN and 48.3 (pm 13.7) mN respectively.   ","Conclusions: The force-sensing prototype measures forces with sub-millinewton resolution and the results demonstrate that the calibrated force-sensing drill generates accurate force measurements with minimal error compared to the measured drill forces.","The development of such sensing capabilities is crucial for the safe use of robotic systems in a clinical context."],"url":"http://arxiv.org/abs/2304.02583v1"}
{"created":"2023-04-05","title":"Sensor-based Planning and Control for Robotic Systems: Introducing Clarity and Perceivability","abstract":"We introduce an information measure, termed clarity, motivated by information entropy, and show that it has intuitive properties relevant to dynamic coverage control and informative path planning. Clarity defines the quality of the information we have about a variable of interest in an environment on a scale of [0, 1], and has useful properties for control and planning such as: (I) clarity lower bounds the expected estimation error of any estimator, and (II) given noisy measurements, clarity monotonically approaches a level q_infty < 1. We establish a connection between coverage controllers and information theory via clarity, suggesting a coverage model that is physically consistent with how information is acquired. Next, we define the notion of perceivability of an environment under a given robotic (or more generally, sensing and control) system, i.e., whether the system has sufficient sensing and actuation capabilities to gather desired information. We show that perceivability relates to the reachability of an augmented system, and derive the corresponding Hamilton-Jacobi-Bellman equations to determine perceivability. In simulations, we demonstrate how clarity is a useful concept for planning trajectories, how perceivability can be determined using reachability analysis, and how a Control Barrier Function (CBF) based controller can dramatically reduce the computational burden.","sentences":["We introduce an information measure, termed clarity, motivated by information entropy, and show that it has intuitive properties relevant to dynamic coverage control and informative path planning.","Clarity defines the quality of the information we have about a variable of interest in an environment on a scale of [0, 1], and has useful properties for control and planning such as: (I) clarity lower bounds the expected estimation error of any estimator, and (II) given noisy measurements, clarity monotonically approaches a level q_infty <","1.","We establish a connection between coverage controllers and information theory via clarity, suggesting a coverage model that is physically consistent with how information is acquired.","Next, we define the notion of perceivability of an environment under a given robotic (or more generally, sensing and control) system, i.e., whether the system has sufficient sensing and actuation capabilities to gather desired information.","We show that perceivability relates to the reachability of an augmented system, and derive the corresponding Hamilton-Jacobi-Bellman equations to determine perceivability.","In simulations, we demonstrate how clarity is a useful concept for planning trajectories, how perceivability can be determined using reachability analysis, and how a Control Barrier Function (CBF) based controller can dramatically reduce the computational burden."],"url":"http://arxiv.org/abs/2304.02578v1"}
{"created":"2023-04-05","title":"The transcoding sampler for stick-breaking inferences on Dirichlet process mixtures","abstract":"An issue of Dirichlet process mixture models is the slow mixing of the MCMC posterior chain produced by conditional Gibbs samplers based on its stick-breaking representation, as opposed to marginal collapsed Gibbs samplers based on the Polya urn, which have smaller integrated autocorrelation times.   We solve the issue by introducing the transcoding sampler, a new stick-breaking sampler which, conditional to the exchangeable partition posterior produced by any other sampler, enriches it with posterior samples of the stick-breaking parameters. This new sampler is therefore able to match the autocorrelation times of any other sampler, including marginal collapsed Gibbs samplers; it outperforms the slice sampler and removes the need to accelerate it with label-switching Metropolis jumps.   As a building block for the transcoding sampler we develop the i.i.d. transcoding algorithm which, conditional to a posterior partition of the data, can infer back which specific stick in the stick-breaking construction each observation originated from.","sentences":["An issue of Dirichlet process mixture models is the slow mixing of the MCMC posterior chain produced by conditional Gibbs samplers based on its stick-breaking representation, as opposed to marginal collapsed Gibbs samplers based on the Polya urn, which have smaller integrated autocorrelation times.   ","We solve the issue by introducing the transcoding sampler, a new stick-breaking sampler which, conditional to the exchangeable partition posterior produced by any other sampler, enriches it with posterior samples of the stick-breaking parameters.","This new sampler is therefore able to match the autocorrelation times of any other sampler, including marginal collapsed Gibbs samplers; it outperforms the slice sampler and removes the need to accelerate it with label-switching Metropolis jumps.   ","As a building block for the transcoding sampler we develop the i.i.d. transcoding algorithm which, conditional to a posterior partition of the data, can infer back which specific stick in the stick-breaking construction each observation originated from."],"url":"http://arxiv.org/abs/2304.02563v1"}
{"created":"2023-04-05","title":"Self-Supervised Siamese Autoencoders","abstract":"Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire. In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance. The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data. These features are then used as inputs in downstream tasks, such as image classification. Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks. Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set. In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders. We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two self-supervised baselines across multiple data sets, settings, and scenarios. Crucially, this includes conditions in which only a small amount of labeled data is available.","sentences":["Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire.","In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance.","The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data.","These features are then used as inputs in downstream tasks, such as image classification.","Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks.","Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set.","In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders.","We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two self-supervised baselines across multiple data sets, settings, and scenarios.","Crucially, this includes conditions in which only a small amount of labeled data is available."],"url":"http://arxiv.org/abs/2304.02549v1"}
{"created":"2023-04-05","title":"Multi-annotator Deep Learning: A Probabilistic Framework for Classification","abstract":"Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances. A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations. Together with a weighted loss function, we improve the learning from correlated annotation patterns. In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning. Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators.","sentences":["Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data.","However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings.","We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL).","A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach.","The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances.","A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency.","Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations.","Together with a weighted loss function, we improve the learning from correlated annotation patterns.","In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning.","Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators."],"url":"http://arxiv.org/abs/2304.02539v1"}
{"created":"2023-04-05","title":"Inferring nonlinear fractional diffusion processes from single trajectories","abstract":"We present a method to infer the arbitrary space-dependent drift and diffusion of a nonlinear stochastic model driven by multiplicative fractional Gaussian noise from a single trajectory. Our method, fractional Onsager-Machlup optimisation (fOMo), introduces a maximum likelihood estimator by minimising a field-theoretic action which we construct from the observed time series. We successfully test fOMo for a wide range of Hurst exponents using artificial data with strong nonlinearities, and apply it to a data set of daily mean temperatures. We further highlight the significant systematic estimation errors when ignoring non-Markovianity, underlining the need for nonlinear fractional inference methods when studying real-world long-range (anti-)correlated systems.","sentences":["We present a method to infer the arbitrary space-dependent drift and diffusion of a nonlinear stochastic model driven by multiplicative fractional Gaussian noise from a single trajectory.","Our method, fractional Onsager-Machlup optimisation (fOMo), introduces a maximum likelihood estimator by minimising a field-theoretic action which we construct from the observed time series.","We successfully test fOMo for a wide range of Hurst exponents using artificial data with strong nonlinearities, and apply it to a data set of daily mean temperatures.","We further highlight the significant systematic estimation errors when ignoring non-Markovianity, underlining the need for nonlinear fractional inference methods when studying real-world long-range (anti-)correlated systems."],"url":"http://arxiv.org/abs/2304.02536v1"}
{"created":"2023-04-05","title":"A proof that Reed-Muller codes achieve Shannon capacity on symmetric channels","abstract":"Reed-Muller codes were introduced in 1954, with a simple explicit construction based on polynomial evaluations, and have long been conjectured to achieve Shannon capacity on symmetric channels. Major progress was made towards a proof over the last decades; using combinatorial weight enumerator bounds, a breakthrough on the erasure channel from sharp thresholds, hypercontractivity arguments, and polarization theory. Another major progress recently established that the bit error probability vanishes slowly below capacity. However, when channels allow for errors, the results of Bourgain-Kalai do not apply for converting a vanishing bit to a vanishing block error probability, neither do the known weight enumerator bounds. The conjecture that RM codes achieve Shannon capacity on symmetric channels, with high probability of recovering the codewords, has thus remained open.   This paper closes the conjecture's proof. It uses a new recursive boosting framework, which aggregates the decoding of codeword restrictions on `subspace-sunflowers', handling their dependencies via an $L_p$ Boolean Fourier analysis, and using a list-decoding argument with a weight enumerator bound from Sberlo-Shpilka. The proof does not require a vanishing bit error probability for the base case, but only a non-trivial probability, obtained here for general symmetric codes. This gives in particular a shortened and tightened argument for the vanishing bit error probability result of Reeves-Pfister, and with prior works, it implies the strong wire-tap secrecy of RM codes on pure-state classical-quantum channels.","sentences":["Reed-Muller codes were introduced in 1954, with a simple explicit construction based on polynomial evaluations, and have long been conjectured to achieve Shannon capacity on symmetric channels.","Major progress was made towards a proof over the last decades; using combinatorial weight enumerator bounds, a breakthrough on the erasure channel from sharp thresholds, hypercontractivity arguments, and polarization theory.","Another major progress recently established that the bit error probability vanishes slowly below capacity.","However, when channels allow for errors, the results of Bourgain-Kalai do not apply for converting a vanishing bit to a vanishing block error probability, neither do the known weight enumerator bounds.","The conjecture that RM codes achieve Shannon capacity on symmetric channels, with high probability of recovering the codewords, has thus remained open.   ","This paper closes the conjecture's proof.","It uses a new recursive boosting framework, which aggregates the decoding of codeword restrictions on `subspace-sunflowers', handling their dependencies via an $L_p$ Boolean Fourier analysis, and using a list-decoding argument with a weight enumerator bound from Sberlo-Shpilka.","The proof does not require a vanishing bit error probability for the base case, but only a non-trivial probability, obtained here for general symmetric codes.","This gives in particular a shortened and tightened argument for the vanishing bit error probability result of Reeves-Pfister, and with prior works, it implies the strong wire-tap secrecy of RM codes on pure-state classical-quantum channels."],"url":"http://arxiv.org/abs/2304.02509v1"}
{"created":"2023-04-05","title":"Distance maps between Japanese kanji characters based on hierarchical optimal transport","abstract":"We introduce a general framework for assigning distances between kanji based on their dissimilarity. What we mean by this term may depend on the concrete application. The only assumption we make is that the dissimilarity between two kanji is adequately expressed as a weighted mean of penalties obtained from matching nested structures of components in an optimal way. For the cost of matching, we suggest a number of modules that can be freely combined or replaced with other modules, including the relative unbalanced ink transport between registered components, the distance between the transformations required for registration, and the difference in prespecified labels.   We give a concrete example of a kanji distance function obtained in this way as a proof of concept. Based on this function, we produce 2D kanji maps by multidimensional scaling and a table of 100 randomly selected J\\=oj\\=o kanji with their 16 nearest neighbors.   Our kanji distance functions can be used to help Japanese learners from non-CJK backgrounds acquire kanji literacy. In addition, they may assist editors of kanji dictionaries in presenting their materials and may serve in text processing and optical character recognition systems for assessing the likelihood of errors.","sentences":["We introduce a general framework for assigning distances between kanji based on their dissimilarity.","What we mean by this term may depend on the concrete application.","The only assumption we make is that the dissimilarity between two kanji is adequately expressed as a weighted mean of penalties obtained from matching nested structures of components in an optimal way.","For the cost of matching, we suggest a number of modules that can be freely combined or replaced with other modules, including the relative unbalanced ink transport between registered components, the distance between the transformations required for registration, and the difference in prespecified labels.   ","We give a concrete example of a kanji distance function obtained in this way as a proof of concept.","Based on this function, we produce 2D kanji maps by multidimensional scaling and a table of 100 randomly selected J\\=oj\\=o kanji with their 16 nearest neighbors.   ","Our kanji distance functions can be used to help Japanese learners from non-CJK backgrounds acquire kanji literacy.","In addition, they may assist editors of kanji dictionaries in presenting their materials and may serve in text processing and optical character recognition systems for assessing the likelihood of errors."],"url":"http://arxiv.org/abs/2304.02493v1"}
{"created":"2023-04-05","title":"SCB-dataset: A Dataset for Detecting Student Classroom Behavior","abstract":"The use of deep learning methods for automatic detection of students' classroom behavior is a promising approach to analyze their class performance and enhance teaching effectiveness. However, the lack of publicly available datasets on student behavior poses a challenge for researchers in this field. To address this issue, we propose a Student Classroom Behavior dataset (SCB-dataset) that reflects real-life scenarios. Our dataset includes 11,248 labels and 4,003 images, with a focus on hand-raising behavior. We evaluated the dataset using the YOLOv7 algorithm, achieving a mean average precision (map) of up to 85.3%. We believe that our dataset can serve as a robust foundation for future research in the field of student behavior detection and promote further advancements in this area.Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset","sentences":["The use of deep learning methods for automatic detection of students' classroom behavior is a promising approach to analyze their class performance and enhance teaching effectiveness.","However, the lack of publicly available datasets on student behavior poses a challenge for researchers in this field.","To address this issue, we propose a Student Classroom Behavior dataset (SCB-dataset) that reflects real-life scenarios.","Our dataset includes 11,248 labels and 4,003 images, with a focus on hand-raising behavior.","We evaluated the dataset using the YOLOv7 algorithm, achieving a mean average precision (map) of up to 85.3%.","We believe that our dataset can serve as a robust foundation for future research in the field of student behavior detection and promote further advancements in this area.","Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset"],"url":"http://arxiv.org/abs/2304.02488v1"}
{"created":"2023-04-05","title":"Checking the reliability of opacity databases","abstract":"Mathematical inequalities, combined with atomic-physics sum rules, enable one to derive lower and upper bounds for the Rosseland and/or Planck mean opacities. The resulting constraints must be satisfied, either for pure elements or mixtures. The intriguing law of anomalous numbers, also named Benford's law, is of great interest to detect errors in line-strength collections required for fine-structure calculations. Testing regularities may reveal hidden properties, such as the fractal nature of complex atomic spectra. The aforementioned constraints can also be useful to assess the reliability of experimental measurements. Finally, we recall that it is important to quantify the uncertainties due to interpolations in density-temperature opacity (or more generally atomic-data) tables, and that convergence studies are of course unavoidable in order to address the issue of completeness in terms of levels, configurations or superconfigurations, which is a cornerstone of opacity calculations.","sentences":["Mathematical inequalities, combined with atomic-physics sum rules, enable one to derive lower and upper bounds for the Rosseland and/or Planck mean opacities.","The resulting constraints must be satisfied, either for pure elements or mixtures.","The intriguing law of anomalous numbers, also named Benford's law, is of great interest to detect errors in line-strength collections required for fine-structure calculations.","Testing regularities may reveal hidden properties, such as the fractal nature of complex atomic spectra.","The aforementioned constraints can also be useful to assess the reliability of experimental measurements.","Finally, we recall that it is important to quantify the uncertainties due to interpolations in density-temperature opacity (or more generally atomic-data) tables, and that convergence studies are of course unavoidable in order to address the issue of completeness in terms of levels, configurations or superconfigurations, which is a cornerstone of opacity calculations."],"url":"http://arxiv.org/abs/2304.02469v1"}
{"created":"2023-04-05","title":"MS3D: Leveraging Multiple Detectors for Unsupervised Domain Adaptation in 3D Object Detection","abstract":"We introduce Multi-Source 3D (MS3D), a new self-training pipeline for unsupervised domain adaptation in 3D object detection. Despite the remarkable accuracy of 3D detectors, they often overfit to specific domain biases, leading to suboptimal performance in various sensor setups and environments. Existing methods typically focus on adapting a single detector to the target domain, overlooking the fact that different detectors possess distinct expertise on different unseen domains. MS3D leverages this by combining different pre-trained detectors from multiple source domains and incorporating temporal information to produce high-quality pseudo-labels for fine-tuning. Our proposed Kernel-Density Estimation (KDE) Box Fusion method fuses box proposals from multiple domains to obtain pseudo-labels that surpass the performance of the best source domain detectors. MS3D exhibits greater robustness to domain shifts and produces accurate pseudo-labels over greater distances, making it well-suited for high-to-low beam domain adaptation and vice versa. Our method achieved state-of-the-art performance on all evaluated datasets, and we demonstrate that the choice of pre-trained source detectors has minimal impact on the self-training result, making MS3D suitable for real-world applications.","sentences":["We introduce Multi-Source 3D (MS3D), a new self-training pipeline for unsupervised domain adaptation in 3D object detection.","Despite the remarkable accuracy of 3D detectors, they often overfit to specific domain biases, leading to suboptimal performance in various sensor setups and environments.","Existing methods typically focus on adapting a single detector to the target domain, overlooking the fact that different detectors possess distinct expertise on different unseen domains.","MS3D leverages this by combining different pre-trained detectors from multiple source domains and incorporating temporal information to produce high-quality pseudo-labels for fine-tuning.","Our proposed Kernel-Density Estimation (KDE) Box Fusion method fuses box proposals from multiple domains to obtain pseudo-labels that surpass the performance of the best source domain detectors.","MS3D exhibits greater robustness to domain shifts and produces accurate pseudo-labels over greater distances, making it well-suited for high-to-low beam domain adaptation and vice versa.","Our method achieved state-of-the-art performance on all evaluated datasets, and we demonstrate that the choice of pre-trained source detectors has minimal impact on the self-training result, making MS3D suitable for real-world applications."],"url":"http://arxiv.org/abs/2304.02431v1"}
{"created":"2023-04-05","title":"ParroT: Translating During Chat Using Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human. Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning. Codes: https://github.com/wxjiao/ParroT","sentences":["Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat.","However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field.","Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data.","Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process.","Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction.","Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human.","Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning.","Codes: https://github.com/wxjiao/ParroT"],"url":"http://arxiv.org/abs/2304.02426v2"}
{"created":"2023-04-05","title":"Spatial Scattering Modulation with Multipath Component Aggregation Based on Antenna Arrays","abstract":"In this paper, a multipath component aggregation (MCA) mechanism is introduced for spatial scattering modulation (SSM) to overcome the limitation in conventional SSM that the transmit antenna array steers the beam to a single multipath (MP) component at each instance. In the proposed MCA-SSM system, information bits are divided into two streams. One is mapped to an amplitude-phase-modulation (APM) constellation symbol, and the other is mapped to a beam vector symbol which steers multiple beams to selected strongest MP components via an MCA matrix. In comparison with the conventional SSM system, the proposed MCA-SSM enhances the bit error performance by avoiding both low receiving power due to steering the beam to a single weak MP component and inter-MP interference due to MP components with close values of angle of arrival (AoA) or angle of departure (AoD). For the proposed MCA-SSM, a union upper bound (UUB) on the average bit error probability (ABEP) with any MCA matrix is analytically derived and validated via Monte Carlo simulations. Based on the UUB, the MCA matrix is analytically optimized to minimize the ABEP of the MCA-SSM. Finally, numerical experiments are carried out, which show that the proposed MCA-SSM system remarkably outperforms the state-of-the-art SSM system in terms of ABEP under a typical indoor environment.","sentences":["In this paper, a multipath component aggregation (MCA) mechanism is introduced for spatial scattering modulation (SSM) to overcome the limitation in conventional SSM that the transmit antenna array steers the beam to a single multipath (MP) component at each instance.","In the proposed MCA-SSM system, information bits are divided into two streams.","One is mapped to an amplitude-phase-modulation (APM) constellation symbol, and the other is mapped to a beam vector symbol which steers multiple beams to selected strongest MP components via an MCA matrix.","In comparison with the conventional SSM system, the proposed MCA-SSM enhances the bit error performance by avoiding both low receiving power due to steering the beam to a single weak MP component and inter-MP interference due to MP components with close values of angle of arrival (AoA) or angle of departure (AoD).","For the proposed MCA-SSM, a union upper bound (UUB) on the average bit error probability (ABEP) with any MCA matrix is analytically derived and validated via Monte Carlo simulations.","Based on the UUB, the MCA matrix is analytically optimized to minimize the ABEP of the MCA-SSM.","Finally, numerical experiments are carried out, which show that the proposed MCA-SSM system remarkably outperforms the state-of-the-art SSM system in terms of ABEP under a typical indoor environment."],"url":"http://arxiv.org/abs/2304.02424v1"}
{"created":"2023-04-05","title":"Semantic Validation in Structure from Motion","abstract":"The Structure from Motion (SfM) challenge in computer vision is the process of recovering the 3D structure of a scene from a series of projective measurements that are calculated from a collection of 2D images, taken from different perspectives. SfM consists of three main steps; feature detection and matching, camera motion estimation, and recovery of 3D structure from estimated intrinsic and extrinsic parameters and features.   A problem encountered in SfM is that scenes lacking texture or with repetitive features can cause erroneous feature matching between frames. Semantic segmentation offers a route to validate and correct SfM models by labelling pixels in the input images with the use of a deep convolutional neural network. The semantic and geometric properties associated with classes in the scene can be taken advantage of to apply prior constraints to each class of object. The SfM pipeline COLMAP and semantic segmentation pipeline DeepLab were used. This, along with planar reconstruction of the dense model, were used to determine erroneous points that may be occluded from the calculated camera position, given the semantic label, and thus prior constraint of the reconstructed plane. Herein, semantic segmentation is integrated into SfM to apply priors on the 3D point cloud, given the object detection in the 2D input images. Additionally, the semantic labels of matched keypoints are compared and inconsistent semantically labelled points discarded. Furthermore, semantic labels on input images are used for the removal of objects associated with motion in the output SfM models. The proposed approach is evaluated on a data-set of 1102 images of a repetitive architecture scene. This project offers a novel method for improved validation of 3D SfM models.","sentences":["The Structure from Motion (SfM) challenge in computer vision is the process of recovering the 3D structure of a scene from a series of projective measurements that are calculated from a collection of 2D images, taken from different perspectives.","SfM consists of three main steps; feature detection and matching, camera motion estimation, and recovery of 3D structure from estimated intrinsic and extrinsic parameters and features.   ","A problem encountered in SfM is that scenes lacking texture or with repetitive features can cause erroneous feature matching between frames.","Semantic segmentation offers a route to validate and correct SfM models by labelling pixels in the input images with the use of a deep convolutional neural network.","The semantic and geometric properties associated with classes in the scene can be taken advantage of to apply prior constraints to each class of object.","The SfM pipeline COLMAP and semantic segmentation pipeline DeepLab were used.","This, along with planar reconstruction of the dense model, were used to determine erroneous points that may be occluded from the calculated camera position, given the semantic label, and thus prior constraint of the reconstructed plane.","Herein, semantic segmentation is integrated into SfM to apply priors on the 3D point cloud, given the object detection in the 2D input images.","Additionally, the semantic labels of matched keypoints are compared and inconsistent semantically labelled points discarded.","Furthermore, semantic labels on input images are used for the removal of objects associated with motion in the output SfM models.","The proposed approach is evaluated on a data-set of 1102 images of a repetitive architecture scene.","This project offers a novel method for improved validation of 3D SfM models."],"url":"http://arxiv.org/abs/2304.02420v1"}
{"created":"2023-04-05","title":"STRV -- A radiation hard RISC-V microprocessor for high-energy physics applications","abstract":"While microprocessors are used in various applications, they are precluded from the use in high-energy physics applications due to the harsh radiation present. To overcome this limitation a microprocessor design must withstand high doses of radiation and mitigate radiation induced soft errors. A TMR protection scheme is applied to protect a RISC-V microprocessor core against these faults. The protection of the integrated SRAM by an independent scrubbing algorithm is discussed. Initial irradiation results and power consumption measurements of the radiation-resistant RISC-V microprocessor implemented in 65 nm CMOS technology are presented.","sentences":["While microprocessors are used in various applications, they are precluded from the use in high-energy physics applications due to the harsh radiation present.","To overcome this limitation a microprocessor design must withstand high doses of radiation and mitigate radiation induced soft errors.","A TMR protection scheme is applied to protect a RISC-V microprocessor core against these faults.","The protection of the integrated SRAM by an independent scrubbing algorithm is discussed.","Initial irradiation results and power consumption measurements of the radiation-resistant RISC-V microprocessor implemented in 65 nm CMOS technology are presented."],"url":"http://arxiv.org/abs/2304.02410v1"}
{"created":"2023-04-05","title":"Learning earthquake sources using symmetric autoencoders","abstract":"We introduce Symmetric Autoencoder (SymAE), a neural-network architecture designed to automatically extract earthquake information from far-field seismic waves. SymAE represents the measured displacement field using a code that is partitioned into two interpretable components: source and path-scattering information. We achieve this source-path representation using the scale separation principle and stochastic regularization, which traditional autoencoding methods lack. According to the scale separation principle, the variations in far-field band-limited seismic measurements resulting from finite faulting occur across two spatial scales: a slower scale associated with the source processes and a faster scale corresponding to path effects. Once trained, SymAE facilitates the generation of virtual seismograms, engineered to not contain subsurface scattering effects. We present time-reversal imaging of virtual seismograms to accurately infer the kinematic rupture parameters without knowledge of empirical Green's function. SymAE is an unsupervised learning method that can efficiently scale with large amounts of seismic data and does not require labeled seismograms, making it the first framework that can learn from all available previous earthquakes to accurately characterize a given earthquake. The paper presents the results of an analysis of nearly thirty complex earthquake events, revealing differences between earthquakes in energy rise times, stopping phases, and providing insights into their rupture complexity.","sentences":["We introduce Symmetric Autoencoder (SymAE), a neural-network architecture designed to automatically extract earthquake information from far-field seismic waves.","SymAE represents the measured displacement field using a code that is partitioned into two interpretable components: source and path-scattering information.","We achieve this source-path representation using the scale separation principle and stochastic regularization, which traditional autoencoding methods lack.","According to the scale separation principle, the variations in far-field band-limited seismic measurements resulting from finite faulting occur across two spatial scales: a slower scale associated with the source processes and a faster scale corresponding to path effects.","Once trained, SymAE facilitates the generation of virtual seismograms, engineered to not contain subsurface scattering effects.","We present time-reversal imaging of virtual seismograms to accurately infer the kinematic rupture parameters without knowledge of empirical Green's function.","SymAE is an unsupervised learning method that can efficiently scale with large amounts of seismic data and does not require labeled seismograms, making it the first framework that can learn from all available previous earthquakes to accurately characterize a given earthquake.","The paper presents the results of an analysis of nearly thirty complex earthquake events, revealing differences between earthquakes in energy rise times, stopping phases, and providing insights into their rupture complexity."],"url":"http://arxiv.org/abs/2304.02404v1"}
{"created":"2023-04-05","title":"Robust Secure Transmission for Active RIS Enabled Symbiotic Radio Multicast Communications","abstract":"In this paper, we propose a robust secure transmission scheme for an active reconfigurable intelligent surface (RIS) enabled symbiotic radio (SR) system in the presence of multiple eavesdroppers (Eves). In the considered system, the active RIS is adopted to enable the secure transmission of primary signals from the primary transmitter to multiple primary users in a multicasting manner, and simultaneously achieve its own information delivery to the secondary user by riding over the primary signals. Taking into account the imperfect channel state information (CSI) related with Eves, we formulate the system power consumption minimization problem by optimizing the transmit beamforming and reflection beamforming for the bounded and statistical CSI error models, taking the worst-case SNR constraints and the SNR outage probability constraints at the Eves into considerations, respectively. Specifically, the S-Procedure and the Bernstein-Type Inequality are implemented to approximately transform the worst-case SNR and the SNR outage probability constraints into tractable forms, respectively. After that, the formulated problems can be solved by the proposed alternating optimization (AO) algorithm with the semi-definite relaxation and sequential rank-one constraint relaxation techniques. Numerical results show that the proposed active RIS scheme can reduce up to 27.0% system power consumption compared to the passive RIS.","sentences":["In this paper, we propose a robust secure transmission scheme for an active reconfigurable intelligent surface (RIS) enabled symbiotic radio (SR) system in the presence of multiple eavesdroppers (Eves).","In the considered system, the active RIS is adopted to enable the secure transmission of primary signals from the primary transmitter to multiple primary users in a multicasting manner, and simultaneously achieve its own information delivery to the secondary user by riding over the primary signals.","Taking into account the imperfect channel state information (CSI) related with Eves, we formulate the system power consumption minimization problem by optimizing the transmit beamforming and reflection beamforming for the bounded and statistical CSI error models, taking the worst-case SNR constraints and the SNR outage probability constraints at the Eves into considerations, respectively.","Specifically, the S-Procedure and the Bernstein-Type Inequality are implemented to approximately transform the worst-case SNR and the SNR outage probability constraints into tractable forms, respectively.","After that, the formulated problems can be solved by the proposed alternating optimization (AO) algorithm with the semi-definite relaxation and sequential rank-one constraint relaxation techniques.","Numerical results show that the proposed active RIS scheme can reduce up to 27.0% system power consumption compared to the passive RIS."],"url":"http://arxiv.org/abs/2304.02398v1"}
{"created":"2023-04-05","title":"Network-Aware Electric Vehicle Coordination for Vehicle-to-Anything Value Stacking Considering Uncertainties","abstract":"The increased adoption of electric vehicles (EVs) has led to the development of vehicle-to-anything (V2X) technologies, including vehicle-to-home (V2H), vehicle-to-grid (V2G), and energy trading of EVs in the local grid. The EV coordination can provide value to the grid and generate benefits for EVs. However, network constraints and uncertainties in renewable energy and demand pose significant challenges to EV coordination and restrict the realization of these benefits. This paper develops a rolling-horizon optimization problem for V2X value stacking to fully unlock the value of EV coordination, considering power network constraints (such as voltage limits) and uncertainties in the energy system. By coordinating EVs to perform V2H, V2G, and energy trading, our approach exploits the most valuable services in real-time. We also analyze the expected extra costs caused by the prediction errors to evaluate the impact of uncertainties on V2X value stacking. We validate our value-stacking model using real data from Australia's National Electricity Market (NEM), ISO New England (ISO-NE), and New York ISO (NY-ISO) in the US. The results show that V2X value stacking achieves significant benefits to EVs through energy cost reduction. The uncertainty in the load has a higher impact on the value-stacking performance than PV generation, indicating the importance of load prediction.","sentences":["The increased adoption of electric vehicles (EVs) has led to the development of vehicle-to-anything (V2X) technologies, including vehicle-to-home (V2H), vehicle-to-grid (V2G), and energy trading of EVs in the local grid.","The EV coordination can provide value to the grid and generate benefits for EVs.","However, network constraints and uncertainties in renewable energy and demand pose significant challenges to EV coordination and restrict the realization of these benefits.","This paper develops a rolling-horizon optimization problem for V2X value stacking to fully unlock the value of EV coordination, considering power network constraints (such as voltage limits) and uncertainties in the energy system.","By coordinating EVs to perform V2H, V2G, and energy trading, our approach exploits the most valuable services in real-time.","We also analyze the expected extra costs caused by the prediction errors to evaluate the impact of uncertainties on V2X value stacking.","We validate our value-stacking model using real data from Australia's National Electricity Market (NEM), ISO New England (ISO-NE), and New York ISO (NY-ISO) in the US.","The results show that V2X value stacking achieves significant benefits to EVs through energy cost reduction.","The uncertainty in the load has a higher impact on the value-stacking performance than PV generation, indicating the importance of load prediction."],"url":"http://arxiv.org/abs/2304.02392v1"}
{"created":"2023-04-05","title":"A Dual System-Level Parameterization for Identification from Closed-Loop Data","abstract":"This work presents a dual system-level parameterization (D-SLP) method for closed-loop system identification. The recent system-level synthesis framework parameterizes all stabilizing controllers via linear constraints on closed-loop response functions, known as system-level parameters. It was demonstrated that several structural, locality, and communication constraints on the controller can be posed as convex constraints on these system-level parameters. In the current work, the identification problem is treated as a {\\em dual} of the system-level synthesis problem. The plant model is identified from the dual system-level parameters associated to the plant. In comparison to existing closed-loop identification approaches (such as the dual-Youla parameterization), the D-SLP framework neither requires the knowledge of a nominal plant that is stabilized by the known controller, nor depends upon the choice of factorization of the nominal plant and the stabilizing controller. Numerical simulations demonstrate the efficacy of the proposed D-SLP method in terms of identification errors, compared to existing closed-loop identification techniques.","sentences":["This work presents a dual system-level parameterization (D-SLP) method for closed-loop system identification.","The recent system-level synthesis framework parameterizes all stabilizing controllers via linear constraints on closed-loop response functions, known as system-level parameters.","It was demonstrated that several structural, locality, and communication constraints on the controller can be posed as convex constraints on these system-level parameters.","In the current work, the identification problem is treated as a {\\em dual} of the system-level synthesis problem.","The plant model is identified from the dual system-level parameters associated to the plant.","In comparison to existing closed-loop identification approaches (such as the dual-Youla parameterization), the D-SLP framework neither requires the knowledge of a nominal plant that is stabilized by the known controller, nor depends upon the choice of factorization of the nominal plant and the stabilizing controller.","Numerical simulations demonstrate the efficacy of the proposed D-SLP method in terms of identification errors, compared to existing closed-loop identification techniques."],"url":"http://arxiv.org/abs/2304.02379v1"}
{"created":"2023-04-05","title":"Modeling still matters: a surprising instance of catastrophic floating point errors in mathematical biology and numerical methods for ODEs","abstract":"We guide the reader on a journey through mathematical modeling and numerical analysis, emphasizing the crucial interplay of both disciplines. Targeting undergraduate students with basic knowledge in dynamical systems and numerical methods for ordinary differential equations, we explore a model from mathematical biology where numerical methods fail badly due to catastrophic floating point errors. We analyze the reasons for this behavior by studying the steady states of the model and use the theory of invariants to develop an alternative model that is suited for numerical simulations. Our story intends to motivate combining analytical and numerical knowledge, even in cases where the world looks fine at first sight. We have set up an online repository containing an interactive notebook with all numerical experiments to make this study fully reproducible and useful for classroom teaching.","sentences":["We guide the reader on a journey through mathematical modeling and numerical analysis, emphasizing the crucial interplay of both disciplines.","Targeting undergraduate students with basic knowledge in dynamical systems and numerical methods for ordinary differential equations, we explore a model from mathematical biology where numerical methods fail badly due to catastrophic floating point errors.","We analyze the reasons for this behavior by studying the steady states of the model and use the theory of invariants to develop an alternative model that is suited for numerical simulations.","Our story intends to motivate combining analytical and numerical knowledge, even in cases where the world looks fine at first sight.","We have set up an online repository containing an interactive notebook with all numerical experiments to make this study fully reproducible and useful for classroom teaching."],"url":"http://arxiv.org/abs/2304.02365v1"}
{"created":"2023-04-05","title":"Convex Optimization-based Policy Adaptation to Compensate for Distributional Shifts","abstract":"Many real-world systems often involve physical components or operating environments with highly nonlinear and uncertain dynamics. A number of different control algorithms can be used to design optimal controllers for such systems, assuming a reasonably high-fidelity model of the actual system. However, the assumptions made on the stochastic dynamics of the model when designing the optimal controller may no longer be valid when the system is deployed in the real-world. The problem addressed by this paper is the following: Suppose we obtain an optimal trajectory by solving a control problem in the training environment, how do we ensure that the real-world system trajectory tracks this optimal trajectory with minimal amount of error in a deployment environment. In other words, we want to learn how we can adapt an optimal trained policy to distribution shifts in the environment. Distribution shifts are problematic in safety-critical systems, where a trained policy may lead to unsafe outcomes during deployment. We show that this problem can be cast as a nonlinear optimization problem that could be solved using heuristic method such as particle swarm optimization (PSO). However, if we instead consider a convex relaxation of this problem, we can learn policies that track the optimal trajectory with much better error performance, and faster computation times. We demonstrate the efficacy of our approach on tracking an optimal path using a Dubin's car model, and collision avoidance using both a linear and nonlinear model for adaptive cruise control.","sentences":["Many real-world systems often involve physical components or operating environments with highly nonlinear and uncertain dynamics.","A number of different control algorithms can be used to design optimal controllers for such systems, assuming a reasonably high-fidelity model of the actual system.","However, the assumptions made on the stochastic dynamics of the model when designing the optimal controller may no longer be valid when the system is deployed in the real-world.","The problem addressed by this paper is the following: Suppose we obtain an optimal trajectory by solving a control problem in the training environment, how do we ensure that the real-world system trajectory tracks this optimal trajectory with minimal amount of error in a deployment environment.","In other words, we want to learn how we can adapt an optimal trained policy to distribution shifts in the environment.","Distribution shifts are problematic in safety-critical systems, where a trained policy may lead to unsafe outcomes during deployment.","We show that this problem can be cast as a nonlinear optimization problem that could be solved using heuristic method such as particle swarm optimization (PSO).","However, if we instead consider a convex relaxation of this problem, we can learn policies that track the optimal trajectory with much better error performance, and faster computation times.","We demonstrate the efficacy of our approach on tracking an optimal path using a Dubin's car model, and collision avoidance using both a linear and nonlinear model for adaptive cruise control."],"url":"http://arxiv.org/abs/2304.02324v1"}
{"created":"2023-04-05","title":"FASTAGEDS: Fast Approximate Graph Entity Dependency Discovery","abstract":"This paper studies the discovery of approximate rules in property graphs. We propose a semantically meaningful measure of error for mining graph entity dependencies (GEDs) at almost hold, to tolerate errors and inconsistencies that exist in real-world graphs. We present a new characterisation of GED satisfaction, and devise a depth-first search strategy to traverse the search space of candidate rules efficiently. Further, we perform experiments to demonstrate the feasibility and scalability of our solution, FASTAGEDS, with three real-world graphs.","sentences":["This paper studies the discovery of approximate rules in property graphs.","We propose a semantically meaningful measure of error for mining graph entity dependencies (GEDs) at almost hold, to tolerate errors and inconsistencies that exist in real-world graphs.","We present a new characterisation of GED satisfaction, and devise a depth-first search strategy to traverse the search space of candidate rules efficiently.","Further, we perform experiments to demonstrate the feasibility and scalability of our solution, FASTAGEDS, with three real-world graphs."],"url":"http://arxiv.org/abs/2304.02323v1"}
{"created":"2023-04-05","title":"Few-shot Semantic Image Synthesis with Class Affinity Transfer","abstract":"Semantic image synthesis aims to generate photo realistic images given a semantic segmentation map. Despite much recent progress, training them still requires large datasets of images annotated with per-pixel label maps that are extremely tedious to obtain. To alleviate the high annotation cost, we propose a transfer method that leverages a model trained on a large source dataset to improve the learning ability on small target datasets via estimated pairwise relations between source and target classes. The class affinity matrix is introduced as a first layer to the source model to make it compatible with the target label maps, and the source model is then further finetuned for the target domain. To estimate the class affinities we consider different approaches to leverage prior knowledge: semantic segmentation on the source domain, textual label embeddings, and self-supervised vision features. We apply our approach to GAN-based and diffusion-based architectures for semantic synthesis. Our experiments show that the different ways to estimate class affinity can be effectively combined, and that our approach significantly improves over existing state-of-the-art transfer approaches for generative image models.","sentences":["Semantic image synthesis aims to generate photo realistic images given a semantic segmentation map.","Despite much recent progress, training them still requires large datasets of images annotated with per-pixel label maps that are extremely tedious to obtain.","To alleviate the high annotation cost, we propose a transfer method that leverages a model trained on a large source dataset to improve the learning ability on small target datasets via estimated pairwise relations between source and target classes.","The class affinity matrix is introduced as a first layer to the source model to make it compatible with the target label maps, and the source model is then further finetuned for the target domain.","To estimate the class affinities we consider different approaches to leverage prior knowledge: semantic segmentation on the source domain, textual label embeddings, and self-supervised vision features.","We apply our approach to GAN-based and diffusion-based architectures for semantic synthesis.","Our experiments show that the different ways to estimate class affinity can be effectively combined, and that our approach significantly improves over existing state-of-the-art transfer approaches for generative image models."],"url":"http://arxiv.org/abs/2304.02321v1"}
{"created":"2023-04-05","title":"Semantic Communications for Image Recovery and Classification via Deep Joint Source and Channel Coding","abstract":"With the recent advancements in edge artificial intelligence (AI), future sixth-generation (6G) networks need to support new AI tasks such as classification and clustering apart from data recovery. Motivated by the success of deep learning, the semantic-aware and task-oriented communications with deep joint source and channel coding (JSCC) have emerged as new paradigm shifts in 6G from the conventional data-oriented communications with separate source and channel coding (SSCC). However, most existing works focused on the deep JSCC designs for one task of data recovery or AI task execution independently, which cannot be transferred to other unintended tasks. Differently, this paper investigates the JSCC semantic communications to support multi-task services, by performing the image data recovery and classification task execution simultaneously. First, we propose a new end-to-end deep JSCC framework by unifying the coding rate reduction maximization and the mean square error (MSE) minimization in the loss function. Here, the coding rate reduction maximization facilitates the learning of discriminative features for enabling to perform classification tasks directly in the feature space, and the MSE minimization helps the learning of informative features for high-quality image data recovery. Next, to further improve the robustness against variational wireless channels, we propose a new gated deep JSCC design, in which a gated net is incorporated for adaptively pruning the output features to adjust their dimensions based on channel conditions. Finally, we present extensive numerical experiments to validate the performance of our proposed deep JSCC designs as compared to various benchmark schemes.","sentences":["With the recent advancements in edge artificial intelligence (AI), future sixth-generation (6G) networks need to support new AI tasks such as classification and clustering apart from data recovery.","Motivated by the success of deep learning, the semantic-aware and task-oriented communications with deep joint source and channel coding (JSCC) have emerged as new paradigm shifts in 6G from the conventional data-oriented communications with separate source and channel coding (SSCC).","However, most existing works focused on the deep JSCC designs for one task of data recovery or AI task execution independently, which cannot be transferred to other unintended tasks.","Differently, this paper investigates the JSCC semantic communications to support multi-task services, by performing the image data recovery and classification task execution simultaneously.","First, we propose a new end-to-end deep JSCC framework by unifying the coding rate reduction maximization and the mean square error (MSE) minimization in the loss function.","Here, the coding rate reduction maximization facilitates the learning of discriminative features for enabling to perform classification tasks directly in the feature space, and the MSE minimization helps the learning of informative features for high-quality image data recovery.","Next, to further improve the robustness against variational wireless channels, we propose a new gated deep JSCC design, in which a gated net is incorporated for adaptively pruning the output features to adjust their dimensions based on channel conditions.","Finally, we present extensive numerical experiments to validate the performance of our proposed deep JSCC designs as compared to various benchmark schemes."],"url":"http://arxiv.org/abs/2304.02317v1"}
{"created":"2023-04-05","title":"Topological Characterization of Consensus Solvability in Directed Dynamic Networks","abstract":"Consensus is one of the most fundamental problems in distributed computing. This paper studies the consensus problem in a synchronous dynamic directed network, in which communication is controlled by an oblivious message adversary. The question when consensus is possible in this model has already been studied thoroughly in the literature from a combinatorial perspective, and is known to be challenging. This paper presents a topological perspective on consensus solvability under oblivious message adversaries, which provides interesting new insights. Our main contribution is a topological characterization of consensus solvability, which also leads to explicit decision procedures. Our approach is based on the novel notion of a communication pseudosphere, which can be seen as the message-passing analog of the well-known standard chromatic subdivision for wait-free shared memory systems. We further push the elegance and expressiveness of the \"geometric\" reasoning enabled by the topological approach by dealing with uninterpreted complexes, which considerably reduce the size of the protocol complex, and by labeling facets with information flow arrows, which give an intuitive meaning to the implicit epistemic status of the faces in a protocol complex.","sentences":["Consensus is one of the most fundamental problems in distributed computing.","This paper studies the consensus problem in a synchronous dynamic directed network, in which communication is controlled by an oblivious message adversary.","The question when consensus is possible in this model has already been studied thoroughly in the literature from a combinatorial perspective, and is known to be challenging.","This paper presents a topological perspective on consensus solvability under oblivious message adversaries, which provides interesting new insights.","Our main contribution is a topological characterization of consensus solvability, which also leads to explicit decision procedures.","Our approach is based on the novel notion of a communication pseudosphere, which can be seen as the message-passing analog of the well-known standard chromatic subdivision for wait-free shared memory systems.","We further push the elegance and expressiveness of the \"geometric\" reasoning enabled by the topological approach by dealing with uninterpreted complexes, which considerably reduce the size of the protocol complex, and by labeling facets with information flow arrows, which give an intuitive meaning to the implicit epistemic status of the faces in a protocol complex."],"url":"http://arxiv.org/abs/2304.02316v1"}
{"created":"2023-04-05","title":"Quantum Approximation Optimization Algorithm for the trellis based Viterbi decoding of classical error correcting codes","abstract":"We construct a quantum-classical Viterbi decoder for the classical error-correcting codes. Viterbi decoding is a trellis-based procedure for maximum likelihood decoding of classical error-correcting codes. In this article, we show that any number of paths with the minimum Hamming distance with respect to the received erroneous vector present in the trellis can be found using the quantum approximate optimization algorithm. We construct a generalized method to map the Viterbi decoding problem into a parameterized quantum circuit for any classical linear block codes. We propose a uniform parameter optimization strategy to optimize the parameterized quantum circuit. We observe that the proposed method is efficient for generating low-depth trainable parameterized quantum circuits. This renders the hybrid decoder more efficient than previous attempts at making quantum Viterbi algorithm. We show that using uniform parameter optimization, we obtain parameters more efficiently for the parameterized quantum circuit than many previous attempts made through random sampling and fixing the parameters.","sentences":["We construct a quantum-classical Viterbi decoder for the classical error-correcting codes.","Viterbi decoding is a trellis-based procedure for maximum likelihood decoding of classical error-correcting codes.","In this article, we show that any number of paths with the minimum Hamming distance with respect to the received erroneous vector present in the trellis can be found using the quantum approximate optimization algorithm.","We construct a generalized method to map the Viterbi decoding problem into a parameterized quantum circuit for any classical linear block codes.","We propose a uniform parameter optimization strategy to optimize the parameterized quantum circuit.","We observe that the proposed method is efficient for generating low-depth trainable parameterized quantum circuits.","This renders the hybrid decoder more efficient than previous attempts at making quantum Viterbi algorithm.","We show that using uniform parameter optimization, we obtain parameters more efficiently for the parameterized quantum circuit than many previous attempts made through random sampling and fixing the parameters."],"url":"http://arxiv.org/abs/2304.02292v1"}
{"created":"2023-04-05","title":"Optimal Sketching Bounds for Sparse Linear Regression","abstract":"We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression. For this problem, under the $\\ell_2$ norm, we observe an upper bound of $O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $o(d)$ rows showing that $O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions. We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight.","sentences":["We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses.","We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor.","This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound.","This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression.","For this problem, under the $\\ell_2$ norm, we observe an upper bound of $O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression.","For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $o(d)$ rows showing that $O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions.","We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight."],"url":"http://arxiv.org/abs/2304.02261v1"}
{"created":"2023-04-05","title":"DPPD: Deformable Polar Polygon Object Detection","abstract":"Regular object detection methods output rectangle bounding boxes, which are unable to accurately describe the actual object shapes. Instance segmentation methods output pixel-level labels, which are computationally expensive for real-time applications. Therefore, a polygon representation is needed to achieve precise shape alignment, while retaining low computation cost. We develop a novel Deformable Polar Polygon Object Detection method (DPPD) to detect objects in polygon shapes. In particular, our network predicts, for each object, a sparse set of flexible vertices to construct the polygon, where each vertex is represented by a pair of angle and distance in the Polar coordinate system. To enable training, both ground truth and predicted polygons are densely resampled to have the same number of vertices with equal-spaced raypoints. The resampling operation is fully differentable, allowing gradient back-propagation. Sparse polygon predicton ensures high-speed runtime inference while dense resampling allows the network to learn object shapes with high precision. The polygon detection head is established on top of an anchor-free and NMS-free network architecture. DPPD has been demonstrated successfully in various object detection tasks for autonomous driving such as traffic-sign, crosswalk, vehicle and pedestrian objects.","sentences":["Regular object detection methods output rectangle bounding boxes, which are unable to accurately describe the actual object shapes.","Instance segmentation methods output pixel-level labels, which are computationally expensive for real-time applications.","Therefore, a polygon representation is needed to achieve precise shape alignment, while retaining low computation cost.","We develop a novel Deformable Polar Polygon Object Detection method (DPPD) to detect objects in polygon shapes.","In particular, our network predicts, for each object, a sparse set of flexible vertices to construct the polygon, where each vertex is represented by a pair of angle and distance in the Polar coordinate system.","To enable training, both ground truth and predicted polygons are densely resampled to have the same number of vertices with equal-spaced raypoints.","The resampling operation is fully differentable, allowing gradient back-propagation.","Sparse polygon predicton ensures high-speed runtime inference while dense resampling allows the network to learn object shapes with high precision.","The polygon detection head is established on top of an anchor-free and NMS-free network architecture.","DPPD has been demonstrated successfully in various object detection tasks for autonomous driving such as traffic-sign, crosswalk, vehicle and pedestrian objects."],"url":"http://arxiv.org/abs/2304.02250v1"}
{"created":"2023-04-05","title":"Low Latency Computing for Time Stretch Instruments","abstract":"Time stretch instruments have been exceptionally successful in discovering single-shot ultrafast phenomena such as optical rogue waves and have led to record-speed microscopy, spectroscopy, lidar, etc. These instruments encode the ultrafast events into the spectrum of a femtosecond pulse and then dilate the time scale of the data using group velocity dispersion. Generating as much as Tbit per second of data, they are ideal partners for deep learning networks which by their inherent complexity, require large datasets for training. However, the inference time scale of neural networks in the millisecond regime is orders of magnitude longer than the data acquisition rate of time stretch instruments. This underscores the need to explore means where some of the lower-level computational tasks can be done while the data is still in the optical domain. The Nonlinear Schr\\\"{o}dinger Kernel computing addresses this predicament. It utilizes optical nonlinearities to map the data onto a new domain in which classification accuracy is enhanced, without increasing the data dimensions. One limitation of this technique is the fixed optical transfer function, which prevents training and generalizability. Here we show that the optical kernel can be effectively tuned and trained by utilizing digital phase encoding of the femtosecond laser pulse leading to a reduction of the error rate in data classification.","sentences":["Time stretch instruments have been exceptionally successful in discovering single-shot ultrafast phenomena such as optical rogue waves and have led to record-speed microscopy, spectroscopy, lidar, etc.","These instruments encode the ultrafast events into the spectrum of a femtosecond pulse and then dilate the time scale of the data using group velocity dispersion.","Generating as much as Tbit per second of data, they are ideal partners for deep learning networks which by their inherent complexity, require large datasets for training.","However, the inference time scale of neural networks in the millisecond regime is orders of magnitude longer than the data acquisition rate of time stretch instruments.","This underscores the need to explore means where some of the lower-level computational tasks can be done while the data is still in the optical domain.","The Nonlinear Schr\\\"{o}dinger Kernel computing addresses this predicament.","It utilizes optical nonlinearities to map the data onto a new domain in which classification accuracy is enhanced, without increasing the data dimensions.","One limitation of this technique is the fixed optical transfer function, which prevents training and generalizability.","Here we show that the optical kernel can be effectively tuned and trained by utilizing digital phase encoding of the femtosecond laser pulse leading to a reduction of the error rate in data classification."],"url":"http://arxiv.org/abs/2304.02249v1"}
{"created":"2023-04-05","title":"Mixed Regression via Approximate Message Passing","abstract":"We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error. The state evolution characterization can be used to tailor the AMP algorithm to take advantage of any structural information known about the signals. Using state evolution, we derive an optimal choice of AMP `denoising' functions that minimizes the estimation error in each iteration.   The theoretical results are validated by numerical simulations for mixed linear regression, max-affine regression, and mixture-of-experts. For max-affine regression, we propose an algorithm that combines AMP with expectation-maximization to estimate intercepts of the model along with the signals. The numerical results show that AMP significantly outperforms other estimators for mixed linear regression and max-affine regression in most parameter regimes.","sentences":["We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables.","This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts.","In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector.","The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations.","We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit.","This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error.","The state evolution characterization can be used to tailor the AMP algorithm to take advantage of any structural information known about the signals.","Using state evolution, we derive an optimal choice of AMP `denoising' functions that minimizes the estimation error in each iteration.   ","The theoretical results are validated by numerical simulations for mixed linear regression, max-affine regression, and mixture-of-experts.","For max-affine regression, we propose an algorithm that combines AMP with expectation-maximization to estimate intercepts of the model along with the signals.","The numerical results show that AMP significantly outperforms other estimators for mixed linear regression and max-affine regression in most parameter regimes."],"url":"http://arxiv.org/abs/2304.02229v1"}
{"created":"2023-04-05","title":"Maxflow-Based Bounds for Low-Rate Information Propagation over Noisy Networks","abstract":"We study error exponents for the problem of low-rate communication over a directed graph, where each edge in the graph represents a noisy communication channel, and there is a single source and destination. We derive maxflow-based achievability and converse bounds on the error exponent that match when there are two messages and all channels satisfy a symmetry condition called pairwise reversibility. More generally, we show that the upper and lower bounds match to within a factor of 4. We also show that with three messages there are cases where the maxflow-based error exponent is strictly suboptimal, thus showing that our tightness result cannot be extended beyond two messages without further assumptions.","sentences":["We study error exponents for the problem of low-rate communication over a directed graph, where each edge in the graph represents a noisy communication channel, and there is a single source and destination.","We derive maxflow-based achievability and converse bounds on the error exponent that match when there are two messages and all channels satisfy a symmetry condition called pairwise reversibility.","More generally, we show that the upper and lower bounds match to within a factor of 4.","We also show that with three messages there are cases where the maxflow-based error exponent is strictly suboptimal, thus showing that our tightness result cannot be extended beyond two messages without further assumptions."],"url":"http://arxiv.org/abs/2304.02226v1"}
{"created":"2023-04-05","title":"DiGA: Distil to Generalize and then Adapt for Domain Adaptive Semantic Segmentation","abstract":"Domain adaptive semantic segmentation methods commonly utilize stage-wise training, consisting of a warm-up and a self-training stage. However, this popular approach still faces several challenges in each stage: for warm-up, the widely adopted adversarial training often results in limited performance gain, due to blind feature alignment; for self-training, finding proper categorical thresholds is very tricky. To alleviate these issues, we first propose to replace the adversarial training in the warm-up stage by a novel symmetric knowledge distillation module that only accesses the source domain data and makes the model domain generalizable. Surprisingly, this domain generalizable warm-up model brings substantial performance improvement, which can be further amplified via our proposed cross-domain mixture data augmentation technique. Then, for the self-training stage, we propose a threshold-free dynamic pseudo-label selection mechanism to ease the aforementioned threshold problem and make the model better adapted to the target domain. Extensive experiments demonstrate that our framework achieves remarkable and consistent improvements compared to the prior arts on popular benchmarks. Codes and models are available at https://github.com/fy-vision/DiGA","sentences":["Domain adaptive semantic segmentation methods commonly utilize stage-wise training, consisting of a warm-up and a self-training stage.","However, this popular approach still faces several challenges in each stage: for warm-up, the widely adopted adversarial training often results in limited performance gain, due to blind feature alignment; for self-training, finding proper categorical thresholds is very tricky.","To alleviate these issues, we first propose to replace the adversarial training in the warm-up stage by a novel symmetric knowledge distillation module that only accesses the source domain data and makes the model domain generalizable.","Surprisingly, this domain generalizable warm-up model brings substantial performance improvement, which can be further amplified via our proposed cross-domain mixture data augmentation technique.","Then, for the self-training stage, we propose a threshold-free dynamic pseudo-label selection mechanism to ease the aforementioned threshold problem and make the model better adapted to the target domain.","Extensive experiments demonstrate that our framework achieves remarkable and consistent improvements compared to the prior arts on popular benchmarks.","Codes and models are available at https://github.com/fy-vision/DiGA"],"url":"http://arxiv.org/abs/2304.02222v1"}
{"created":"2023-04-05","title":"Zero-shot domain adaptation of anomalous samples for semi-supervised anomaly detection","abstract":"Semi-supervised anomaly detection~(SSAD) is a task where normal data and a limited number of anomalous data are available for training. In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase. To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain. First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables. Since the decoder cannot reconstruct the original data solely from domain-invariant latent variables, we conditioned the decoder on the domain label. To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function. Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain.","sentences":["Semi-supervised anomaly detection~(SSAD) is a task where normal data and a limited number of anomalous data are available for training.","In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase.","To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain.","First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables.","Since the decoder cannot reconstruct the original data solely from domain-invariant latent variables, we conditioned the decoder on the domain label.","To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function.","Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain."],"url":"http://arxiv.org/abs/2304.02221v1"}
{"created":"2023-04-05","title":"Identification of high-reliability regions of machine learning predictions in materials science using transparent conducting oxides and perovskites as examples","abstract":"Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science. Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML. We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials. Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science.","sentences":["Progress in the application of machine learning (ML) methods to materials design is hindered by the lack of understanding of the reliability of ML predictions, in particular for the application of ML to small data sets often found in materials science.","Using ML prediction for transparent conductor oxide formation energy and band gap, dilute solute diffusion, and perovskite formation energy, band gap and lattice parameter as examples, we demonstrate that 1) analysis of ML results by construction of a convex hull in feature space that encloses accurately predicted systems can be used to identify regions in feature space for which ML predictions are highly reliable 2) analysis of the systems enclosed by the convex hull can be used to extract physical understanding and 3) materials that satisfy all well-known chemical and physical principles that make a material physically reasonable are likely to be similar and show strong relationships between the properties of interest and the standard features used in ML.","We also show that similar to the composition-structure-property relationships, inclusion in the ML training data set of materials from classes with different chemical properties will not be beneficial and will slightly decrease the accuracy of ML prediction and that reliable results likely will be obtained by ML model for narrow classes of similar materials even in the case where the ML model will show large errors on the dataset consisting of several classes of materials.","Our work suggests that analysis of the error distributions of ML predictions will be beneficial for the further development of the application of ML methods in material science."],"url":"http://arxiv.org/abs/2304.02218v1"}
{"created":"2023-04-05","title":"MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs","abstract":"Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods. Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar.","sentences":["Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education.","Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels.","In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records.","Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels.","The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods.","Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar."],"url":"http://arxiv.org/abs/2304.02205v1"}
{"created":"2023-04-04","title":"Pac-HuBERT: Self-Supervised Music Source Separation via Primitive Auditory Clustering and Hidden-Unit BERT","abstract":"In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance. Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data. In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model. We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture. We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation. Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset. The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models. We further demonstrate that it can boost performance with small amounts of supervised data. Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation.","sentences":["In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance.","Thus, recent advances in self-supervised learning present a largely-unexplored opportunity for improving separation models by leveraging unlabelled music data.","In this paper, we propose a self-supervised learning framework for music source separation inspired by the HuBERT speech representation model.","We first investigate the potential impact of the original HuBERT model by inserting an adapted version of it into the well-known Demucs V2 time-domain separation model architecture.","We then propose a time-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory clustering HuBERT), that we later use in combination with a Res-U-Net decoder for source separation.","Pac-HuBERT uses primitive auditory features of music as unsupervised clustering labels to initialize the self-supervised pretraining process using the Free Music Archive (FMA) dataset.","The resulting framework achieves better source-to-distortion ratio (SDR) performance on the MusDB18 test set than the original Demucs V2 and Res-U-Net models.","We further demonstrate that it can boost performance with small amounts of supervised data.","Ultimately, our proposed framework is an effective solution to the challenge of limited clean source data for music source separation."],"url":"http://arxiv.org/abs/2304.02160v1"}
{"created":"2023-04-04","title":"Re-Evaluating LiDAR Scene Flow for Autonomous Driving","abstract":"Current methods for self-supervised LiDAR scene flow estimation work poorly on real data. A variety of flaws in common evaluation protocols have caused leading approaches to focus on problems that do not exist in real data. We analyze a suite of recent works and find that despite their focus on deep learning, the main challenges of the LiDAR scene flow problem -- removing the dominant rigid motion and robustly estimating the simple motions that remain -- can be more effectively solved with classical techniques such as ICP motion compensation and enforcing piecewise rigid assumptions. We combine these steps with a test-time optimization method to form a state-of-the-art system that does not require any training data. Because our final approach is dataless, it can be applied on different datasets with diverse LiDAR rigs without retraining. Our proposed approach outperforms all existing methods on Argoverse 2.0, halves the error rate on NuScenes, and even rivals the performance of supervised networks on Waymo and lidarKITTI.","sentences":["Current methods for self-supervised LiDAR scene flow estimation work poorly on real data.","A variety of flaws in common evaluation protocols have caused leading approaches to focus on problems that do not exist in real data.","We analyze a suite of recent works and find that despite their focus on deep learning, the main challenges of the LiDAR scene flow problem -- removing the dominant rigid motion and robustly estimating the simple motions that remain -- can be more effectively solved with classical techniques such as ICP motion compensation and enforcing piecewise rigid assumptions.","We combine these steps with a test-time optimization method to form a state-of-the-art system that does not require any training data.","Because our final approach is dataless, it can be applied on different datasets with diverse LiDAR rigs without retraining.","Our proposed approach outperforms all existing methods on Argoverse 2.0, halves the error rate on NuScenes, and even rivals the performance of supervised networks on Waymo and lidarKITTI."],"url":"http://arxiv.org/abs/2304.02150v1"}
{"created":"2023-04-04","title":"Gradual Typing for Effect Handlers","abstract":"We present a gradually typed language, GrEff, with effects and handlers that supports migration from unchecked to checked effect typing. This serves as a simple model of the integration of an effect typing discipline with an existing effectful typed language that does not track fine-grained effect information. Our language supports a simple module system to model the programming model of gradual migration from unchecked to checked effect typing in the style of Typed Racket.   The surface language GrEff is given semantics by elaboration to a core language Core GrEff. We equip Core GrEff with an inequational theory for reasoning about the semantic error ordering and desired program equivalences for programming with effects and handlers. We derive an operational semantics for the language from the equations provable in the theory. We then show that the theory is sound by constructing an operational logical relations model to prove the graduality theorem. This extends prior work on embedding-projection pair models of gradual typing to handle effect typing and subtyping.","sentences":["We present a gradually typed language, GrEff, with effects and handlers that supports migration from unchecked to checked effect typing.","This serves as a simple model of the integration of an effect typing discipline with an existing effectful typed language that does not track fine-grained effect information.","Our language supports a simple module system to model the programming model of gradual migration from unchecked to checked effect typing in the style of Typed Racket.   ","The surface language GrEff is given semantics by elaboration to a core language Core GrEff.","We equip Core GrEff with an inequational theory for reasoning about the semantic error ordering and desired program equivalences for programming with effects and handlers.","We derive an operational semantics for the language from the equations provable in the theory.","We then show that the theory is sound by constructing an operational logical relations model to prove the graduality theorem.","This extends prior work on embedding-projection pair models of gradual typing to handle effect typing and subtyping."],"url":"http://arxiv.org/abs/2304.02145v1"}
{"created":"2023-04-04","title":"A Data Fusion Framework for Multi-Domain Morality Learning","abstract":"Language models can be trained to recognize the moral sentiment of text, creating new opportunities to study the role of morality in human life. As interest in language and morality has grown, several ground truth datasets with moral annotations have been released. However, these datasets vary in the method of data collection, domain, topics, instructions for annotators, etc. Simply aggregating such heterogeneous datasets during training can yield models that fail to generalize well. We describe a data fusion framework for training on multiple heterogeneous datasets that improve performance and generalizability. The model uses domain adversarial training to align the datasets in feature space and a weighted loss function to deal with label shift. We show that the proposed framework achieves state-of-the-art performance in different datasets compared to prior works in morality inference.","sentences":["Language models can be trained to recognize the moral sentiment of text, creating new opportunities to study the role of morality in human life.","As interest in language and morality has grown, several ground truth datasets with moral annotations have been released.","However, these datasets vary in the method of data collection, domain, topics, instructions for annotators, etc.","Simply aggregating such heterogeneous datasets during training can yield models that fail to generalize well.","We describe a data fusion framework for training on multiple heterogeneous datasets that improve performance and generalizability.","The model uses domain adversarial training to align the datasets in feature space and a weighted loss function to deal with label shift.","We show that the proposed framework achieves state-of-the-art performance in different datasets compared to prior works in morality inference."],"url":"http://arxiv.org/abs/2304.02144v1"}
{"created":"2023-04-04","title":"A Bayesian Collocation Integral Method for Parameter Estimation in Ordinary Differential Equations","abstract":"Inferring the parameters of ordinary differential equations (ODEs) from noisy observations is an important problem in many scientific fields. Currently, most parameter estimation methods that bypass numerical integration tend to rely on basis functions or Gaussian processes to approximate the ODE solution and its derivatives. Due to the sensitivity of the ODE solution to its derivatives, these methods can be hindered by estimation error, especially when only sparse time-course observations are available. We present a Bayesian collocation framework that operates on the integrated form of the ODEs and also avoids the expensive use of numerical solvers. Our methodology has the capability to handle general nonlinear ODE systems. We demonstrate the accuracy of the proposed method through a simulation study, where the estimated parameters and recovered system trajectories are compared with other recent methods. A real data example is also provided.","sentences":["Inferring the parameters of ordinary differential equations (ODEs) from noisy observations is an important problem in many scientific fields.","Currently, most parameter estimation methods that bypass numerical integration tend to rely on basis functions or Gaussian processes to approximate the ODE solution and its derivatives.","Due to the sensitivity of the ODE solution to its derivatives, these methods can be hindered by estimation error, especially when only sparse time-course observations are available.","We present a Bayesian collocation framework that operates on the integrated form of the ODEs and also avoids the expensive use of numerical solvers.","Our methodology has the capability to handle general nonlinear ODE systems.","We demonstrate the accuracy of the proposed method through a simulation study, where the estimated parameters and recovered system trajectories are compared with other recent methods.","A real data example is also provided."],"url":"http://arxiv.org/abs/2304.02127v1"}
{"created":"2023-04-04","title":"The Bit Complexity of Efficient Continuous Optimization","abstract":"We analyze the bit complexity of efficient algorithms for fundamental optimization problems, such as linear regression, $p$-norm regression, and linear programming (LP). State-of-the-art algorithms are iterative, and in terms of the number of arithmetic operations, they match the current time complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic factors). However, previous work has typically assumed infinite precision arithmetic, and due to complicated inverse maintenance techniques, the actual running times of these algorithms are unknown. To settle the running time and bit complexity of these algorithms, we demonstrate that a core common subroutine, known as \\emph{inverse maintenance}, is backward-stable. Additionally, we show that iterative approaches for solving constrained weighted regression problems can be accomplished with bounded-error pre-conditioners. Specifically, we prove that linear programs can be solved approximately in matrix multiplication time multiplied by polylog factors that depend on the condition number $\\kappa$ of the matrix and the inner and outer radius of the LP problem. $p$-norm regression can be solved approximately in matrix multiplication time multiplied by polylog factors in $\\kappa$. Lastly, linear regression can be solved approximately in input-sparsity time multiplied by polylog factors in $\\kappa$. Furthermore, we present results for achieving lower than matrix multiplication time for $p$-norm regression by utilizing faster solvers for sparse linear systems.","sentences":["We analyze the bit complexity of efficient algorithms for fundamental optimization problems, such as linear regression, $p$-norm regression, and linear programming (LP).","State-of-the-art algorithms are iterative, and in terms of the number of arithmetic operations, they match the current time complexity of multiplying two $n$-by-$n$ matrices (up to polylogarithmic factors).","However, previous work has typically assumed infinite precision arithmetic, and due to complicated inverse maintenance techniques, the actual running times of these algorithms are unknown.","To settle the running time and bit complexity of these algorithms, we demonstrate that a core common subroutine, known as \\emph{inverse maintenance}, is backward-stable.","Additionally, we show that iterative approaches for solving constrained weighted regression problems can be accomplished with bounded-error pre-conditioners.","Specifically, we prove that linear programs can be solved approximately in matrix multiplication time multiplied by polylog factors that depend on the condition number $\\kappa$ of the matrix and the inner and outer radius of the LP problem.","$p$-norm regression can be solved approximately in matrix multiplication time multiplied by polylog factors in $\\kappa$. Lastly, linear regression can be solved approximately in input-sparsity time multiplied by polylog factors in $\\kappa$.","Furthermore, we present results for achieving lower than matrix multiplication time for $p$-norm regression by utilizing faster solvers for sparse linear systems."],"url":"http://arxiv.org/abs/2304.02124v1"}
{"created":"2023-04-04","title":"OpenContrails: Benchmarking Contrail Detection on GOES-16 ABI","abstract":"Contrails (condensation trails) are line-shaped ice clouds caused by aircraft and are likely the largest contributor of aviation-induced climate change. Contrail avoidance is potentially an inexpensive way to significantly reduce the climate impact of aviation. An automated contrail detection system is an essential tool to develop and evaluate contrail avoidance systems. In this paper, we present a human-labeled dataset named OpenContrails to train and evaluate contrail detection models based on GOES-16 Advanced Baseline Imager (ABI) data. We propose and evaluate a contrail detection model that incorporates temporal context for improved detection accuracy. The human labeled dataset and the contrail detection outputs are publicly available on Google Cloud Storage at gs://goes_contrails_dataset.","sentences":["Contrails (condensation trails) are line-shaped ice clouds caused by aircraft and are likely the largest contributor of aviation-induced climate change.","Contrail avoidance is potentially an inexpensive way to significantly reduce the climate impact of aviation.","An automated contrail detection system is an essential tool to develop and evaluate contrail avoidance systems.","In this paper, we present a human-labeled dataset named OpenContrails to train and evaluate contrail detection models based on GOES-16 Advanced Baseline Imager (ABI) data.","We propose and evaluate a contrail detection model that incorporates temporal context for improved detection accuracy.","The human labeled dataset and the contrail detection outputs are publicly available on Google Cloud Storage at gs://goes_contrails_dataset."],"url":"http://arxiv.org/abs/2304.02122v1"}
{"created":"2023-04-04","title":"Deep learning for diffusion in porous media","abstract":"We adopt convolutional neural networks (CNN) to predict the basic properties of the porous media. Two different media types are considered: one mimics the sandstone, and the other mimics the systems derived from the extracellular space of biological tissues. The Lattice Boltzmann Method is used to obtain the labeled data necessary for performing supervised learning. We distinguish two tasks. In the first, networks based on the analysis of the system's geometry predict porosity and effective diffusion coefficient. In the second, networks reconstruct the system's geometry and concentration map. In the first task, we propose two types of CNN models: the C-Net and the encoder part of the U-Net. Both networks are modified by adding a self-normalization module. The models predict with reasonable accuracy but only within the data type, they are trained on. For instance, the model trained on sandstone-like samples overshoots or undershoots for biological-like samples. In the second task, we propose the usage of the U-Net architecture. It accurately reconstructs the concentration fields. Moreover, the network trained on one data type works well for the other. For instance, the model trained on sandstone-like samples works perfectly on biological-like samples.","sentences":["We adopt convolutional neural networks (CNN) to predict the basic properties of the porous media.","Two different media types are considered: one mimics the sandstone, and the other mimics the systems derived from the extracellular space of biological tissues.","The Lattice Boltzmann Method is used to obtain the labeled data necessary for performing supervised learning.","We distinguish two tasks.","In the first, networks based on the analysis of the system's geometry predict porosity and effective diffusion coefficient.","In the second, networks reconstruct the system's geometry and concentration map.","In the first task, we propose two types of CNN models: the C-Net and the encoder part of the U-Net.","Both networks are modified by adding a self-normalization module.","The models predict with reasonable accuracy but only within the data type, they are trained on.","For instance, the model trained on sandstone-like samples overshoots or undershoots for biological-like samples.","In the second task, we propose the usage of the U-Net architecture.","It accurately reconstructs the concentration fields.","Moreover, the network trained on one data type works well for the other.","For instance, the model trained on sandstone-like samples works perfectly on biological-like samples."],"url":"http://arxiv.org/abs/2304.02104v1"}
{"created":"2023-04-04","title":"Generalized functional linear regression models with a mixture of complex function-valued and scalar-valued covariates prone to measurement error","abstract":"While extensive work has been done to correct for biases due to measurement error in scalar-valued covariates prone to errors in generalized linear regression models, limited work has been done to address biases associated with functional covariates prone to errors or the combination of scalar and functional covariates prone to errors in these models. We propose Simulation Extrapolation (SIMEX) and Regression Calibration approaches to correct measurement errors associated with a mixture of functional and scalar covariates prone to classical measurement errors in generalized functional linear regression. The simulation extrapolation method is developed to handle the functional and scalar covariates prone to errors. We also develop methods based on regression calibration extended to our current measurement error settings. Extensive simulation studies are conducted to assess the finite sample performance of our developed methods. The methods are applied to the 2011-2014 cycles of the National Health and Examination Survey data to assess the relationship between physical activity and total caloric intake with type 2 diabetes among community-dwelling adults living in the United States. We treat the device-based measures of physical activity as error-prone functional covariates prone to complex arbitrary heteroscedastic errors, while the total caloric intake is considered a scalar-valued covariate prone to error. We also examine the characteristics of observed measurement errors in device-based physical activity by important demographic subgroups including age, sex, and race.","sentences":["While extensive work has been done to correct for biases due to measurement error in scalar-valued covariates prone to errors in generalized linear regression models, limited work has been done to address biases associated with functional covariates prone to errors or the combination of scalar and functional covariates prone to errors in these models.","We propose Simulation Extrapolation (SIMEX) and Regression Calibration approaches to correct measurement errors associated with a mixture of functional and scalar covariates prone to classical measurement errors in generalized functional linear regression.","The simulation extrapolation method is developed to handle the functional and scalar covariates prone to errors.","We also develop methods based on regression calibration extended to our current measurement error settings.","Extensive simulation studies are conducted to assess the finite sample performance of our developed methods.","The methods are applied to the 2011-2014 cycles of the National Health and Examination Survey data to assess the relationship between physical activity and total caloric intake with type 2 diabetes among community-dwelling adults living in the United States.","We treat the device-based measures of physical activity as error-prone functional covariates prone to complex arbitrary heteroscedastic errors, while the total caloric intake is considered a scalar-valued covariate prone to error.","We also examine the characteristics of observed measurement errors in device-based physical activity by important demographic subgroups including age, sex, and race."],"url":"http://arxiv.org/abs/2304.02651v1"}
{"created":"2023-04-04","title":"Quantum networks with neutral atom processing nodes","abstract":"Quantum networks providing shared entanglement over a mesh of quantum nodes will revolutionize the field of quantum information science by offering novel applications in quantum computation, enhanced precision in networks of sensors and clocks, and efficient quantum communication over large distances. Recent experimental progress with individual neutral atoms demonstrates a high potential for implementing the crucial components of such networks. We highlight latest developments and near-term prospects on how arrays of individually controlled neutral atoms are suited for both efficient remote entanglement generation and large-scale quantum information processing, thereby providing the necessary features for sharing high-fidelity and error-corrected multi-qubit entangled states between the nodes. We describe both the functionality requirements and several examples for advanced, large-scale quantum networks composed of neutral atom processing nodes.","sentences":["Quantum networks providing shared entanglement over a mesh of quantum nodes will revolutionize the field of quantum information science by offering novel applications in quantum computation, enhanced precision in networks of sensors and clocks, and efficient quantum communication over large distances.","Recent experimental progress with individual neutral atoms demonstrates a high potential for implementing the crucial components of such networks.","We highlight latest developments and near-term prospects on how arrays of individually controlled neutral atoms are suited for both efficient remote entanglement generation and large-scale quantum information processing, thereby providing the necessary features for sharing high-fidelity and error-corrected multi-qubit entangled states between the nodes.","We describe both the functionality requirements and several examples for advanced, large-scale quantum networks composed of neutral atom processing nodes."],"url":"http://arxiv.org/abs/2304.02088v1"}
{"created":"2023-04-04","title":"EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT","abstract":"We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images. This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images. We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem. EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls. The dataset also contains 2D image labels that are used in the supervised training of an ink detection model. Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers. To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain. Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth. Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review. EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here. We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues.","sentences":["We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images.","This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images.","We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem.","EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls.","The dataset also contains 2D image labels that are used in the supervised training of an ink detection model.","Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities.","This alignment permits supervised learning for the detection of \"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for human expert labelers.","To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","Our method is capable of revealing accurate lines of text on scroll fragments with known ground truth.","Revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review.","EduceLab-Scrolls has also enabled the discovery, for the first time, of hidden texts from the Herculaneum papyri, which we present here.","We anticipate that the EduceLab-Scrolls dataset will generate more textual discovery as research continues."],"url":"http://arxiv.org/abs/2304.02084v1"}
{"created":"2023-04-04","title":"A Complete V-Equational System for Graded lambda-Calculus","abstract":"Modern programming frequently requires generalised notions of program equivalence based on a metric or a similar structure. Previous work addressed this challenge by introducing the notion of a V-equation, i.e. an equation labelled by an element of a quantale V, which covers inter alia (ultra-)metric, classical, and fuzzy (in)equations. It also introduced a V-equational system for the linear variant of lambda-calculus where any given resource must be used exactly once.   In this paper we drop the (often too strict) linearity constraint by adding graded modal types which allow multiple uses of a resource in a controlled manner. We show that such a control, whilst providing more expressivity to the programmer, also interacts more richly with V-equations than the linear or Cartesian cases. Our main result is the introduction of a sound and complete V-equational system for a lambda-calculus with graded modal types interpreted by what we call a Lipschitz exponential comonad. We also show how to build such comonads canonically via a universal construction, and use our results to derive graded metric equational systems (and corresponding models) for programs with timed and probabilistic behaviour.","sentences":["Modern programming frequently requires generalised notions of program equivalence based on a metric or a similar structure.","Previous work addressed this challenge by introducing the notion of a V-equation, i.e. an equation labelled by an element of a quantale V, which covers inter alia (ultra-)metric, classical, and fuzzy (in)equations.","It also introduced a V-equational system for the linear variant of lambda-calculus where any given resource must be used exactly once.   ","In this paper we drop the (often too strict) linearity constraint by adding graded modal types which allow multiple uses of a resource in a controlled manner.","We show that such a control, whilst providing more expressivity to the programmer, also interacts more richly with V-equations than the linear or Cartesian cases.","Our main result is the introduction of a sound and complete V-equational system for a lambda-calculus with graded modal types interpreted by what we call a Lipschitz exponential comonad.","We also show how to build such comonads canonically via a universal construction, and use our results to derive graded metric equational systems (and corresponding models) for programs with timed and probabilistic behaviour."],"url":"http://arxiv.org/abs/2304.02082v1"}
{"created":"2023-04-04","title":"A non-backtracking method for long matrix completion","abstract":"We consider the problem of rectangular matrix completion in the regime where the matrix $M$ of size $n\\times m$ is ``long\", i.e., the aspect ratio $m/n$ diverges to infinity. Such matrices are of particular interest in the study of tensor completion, where they arise from the unfolding of an odd-order low-rank tensor. In the case where the sampling probability is $\\frac{d}{\\sqrt{mn}}$, we propose a new algorithm for recovering the singular values and left singular vectors of the original matrix based on a variant of the standard non-backtracking operator of a suitably defined bipartite graph. We show that when $d$ is above a Kesten-Stigum-type sampling threshold, our algorithm recovers a correlated version of the singular value decomposition of $M$ with quantifiable error bounds. This is the first result in the regime of bounded $d$ for weak recovery and the first result for weak consistency when $d\\to\\infty$ arbitrarily slowly without any polylog factors.","sentences":["We consider the problem of rectangular matrix completion in the regime where the matrix $M$ of size $n\\times m$ is ``long\", i.e., the aspect ratio $m/n$ diverges to infinity.","Such matrices are of particular interest in the study of tensor completion, where they arise from the unfolding of an odd-order low-rank tensor.","In the case where the sampling probability is $\\frac{d}{\\sqrt{mn}}$, we propose a new algorithm for recovering the singular values and left singular vectors of the original matrix based on a variant of the standard non-backtracking operator of a suitably defined bipartite graph.","We show that when $d$ is above a Kesten-Stigum-type sampling threshold, our algorithm recovers a correlated version of the singular value decomposition of $M$ with quantifiable error bounds.","This is the first result in the regime of bounded $d$ for weak recovery and the first result for weak consistency when $d\\to\\infty$ arbitrarily slowly without any polylog factors."],"url":"http://arxiv.org/abs/2304.02077v2"}
{"created":"2023-04-04","title":"Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation","abstract":"We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.","sentences":["We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective.","Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied.","We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data.","Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment.","Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation.","The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency."],"url":"http://arxiv.org/abs/2304.02064v1"}
{"created":"2023-04-04","title":"An Error Estimator for Electrically Coupled Liquid Crystals","abstract":"This paper extends an a posteriori error estimator for the elastic, Frank-Oseen model of liquid crystals, derived in [9], to include electric and flexoelectric effects. The problem involves a nonlinear coupled system of equations with a local unit-length constraint imposed via a penalty method. The proposed estimator is proven to be a reliable estimate of global approximation error. The performance of the coupled error estimator as a guide for adaptive refinement is shown in the numerical results, where the adapted grids successfully yield substantial reductions in computational work and comparable or better conformance to important physical laws.","sentences":["This paper extends an a posteriori error estimator for the elastic, Frank-Oseen model of liquid crystals, derived in [9], to include electric and flexoelectric effects.","The problem involves a nonlinear coupled system of equations with a local unit-length constraint imposed via a penalty method.","The proposed estimator is proven to be a reliable estimate of global approximation error.","The performance of the coupled error estimator as a guide for adaptive refinement is shown in the numerical results, where the adapted grids successfully yield substantial reductions in computational work and comparable or better conformance to important physical laws."],"url":"http://arxiv.org/abs/2304.02062v1"}
{"created":"2023-04-04","title":"EGC: Image Generation and Classification via a Single Energy-Based Model","abstract":"Learning image classification and image generation using the same set of network parameters is a challenging problem. Recent advanced approaches perform well in one task often exhibit poor performance in the other. This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network. Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10. This work represents the first successful attempt to simultaneously excel in both tasks using a single set of network parameters. We believe that EGC bridges the gap between discriminative and generative learning.","sentences":["Learning image classification and image generation using the same set of network parameters is a challenging problem.","Recent advanced approaches perform well in one task often exhibit poor performance in the other.","This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network.","Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass.","EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10.","This work represents the first successful attempt to simultaneously excel in both tasks using a single set of network parameters.","We believe that EGC bridges the gap between discriminative and generative learning."],"url":"http://arxiv.org/abs/2304.02012v1"}
{"created":"2023-04-04","title":"Approaches for Retrieving Sulfur Species Abundances from Dual X/Ka Band Radio Occultations of Venus with EnVision and VERITAS","abstract":"The EnVision and VERITAS missions to Venus will fly with X and Ka band telecommunications channels which can be used to conduct radio occultation studies of Venus' atmosphere. While link attenuation measurements during prior S and X band occultation experiments have been used to determine vertical profiles of H$_2$SO$_4$ vapor abundance, the addition of the Ka band channel introduces greater sensitivity to the abundances of H$_2$SO$_4$ aerosols and SO$_2$ gas, permitting retrieval of their vertical profiles from dual band measurements. Such measurements would be valuable in the assessment of chemical and dynamical processes governing short and long-term variability in Venus' atmosphere. This paper considers the sensitivity of the X/Ka band radio attenuation measurement to these atmospheric constituents, as well as uncertainties and regularization approaches for conducting retrievals of these atmospheric sulfur species from future occultation experiments. We introduce methods for seeding maximum likelihood estimation retrievals using shape models and simple atmospheric transport constraints. From simulated retrievals, we obtain mean errors of the order of 0.5 ppm, 20 ppm, and 10 mg/m$^3$ for H$_2$SO$_4$ vapor, SO$_2$, and H$_2$SO$_4$ aerosol abundances, respectively, for simultaneous retrieval.","sentences":["The EnVision and VERITAS missions to Venus will fly with X and Ka band telecommunications channels which can be used to conduct radio occultation studies of Venus' atmosphere.","While link attenuation measurements during prior S and X band occultation experiments have been used to determine vertical profiles of H$_2$SO$_4$ vapor abundance, the addition of the Ka band channel introduces greater sensitivity to the abundances of H$_2$SO$_4$ aerosols and SO$_2$ gas, permitting retrieval of their vertical profiles from dual band measurements.","Such measurements would be valuable in the assessment of chemical and dynamical processes governing short and long-term variability in Venus' atmosphere.","This paper considers the sensitivity of the X/Ka band radio attenuation measurement to these atmospheric constituents, as well as uncertainties and regularization approaches for conducting retrievals of these atmospheric sulfur species from future occultation experiments.","We introduce methods for seeding maximum likelihood estimation retrievals using shape models and simple atmospheric transport constraints.","From simulated retrievals, we obtain mean errors of the order of 0.5 ppm, 20 ppm, and 10 mg/m$^3$ for H$_2$SO$_4$ vapor, SO$_2$, and H$_2$SO$_4$ aerosol abundances, respectively, for simultaneous retrieval."],"url":"http://arxiv.org/abs/2304.02006v1"}
{"created":"2023-04-04","title":"Risk-Aware Distributed Multi-Agent Reinforcement Learning","abstract":"Autonomous cyber and cyber-physical systems need to perform decision-making, learning, and control in unknown environments. Such decision-making can be sensitive to multiple factors, including modeling errors, changes in costs, and impacts of events in the tails of probability distributions. Although multi-agent reinforcement learning (MARL) provides a framework for learning behaviors through repeated interactions with the environment by minimizing an average cost, it will not be adequate to overcome the above challenges. In this paper, we develop a distributed MARL approach to solve decision-making problems in unknown environments by learning risk-aware actions. We use the conditional value-at-risk (CVaR) to characterize the cost function that is being minimized, and define a Bellman operator to characterize the value function associated to a given state-action pair. We prove that this operator satisfies a contraction property, and that it converges to the optimal value function. We then propose a distributed MARL algorithm called the CVaR QD-Learning algorithm, and establish that value functions of individual agents reaches consensus. We identify several challenges that arise in the implementation of the CVaR QD-Learning algorithm, and present solutions to overcome these. We evaluate the CVaR QD-Learning algorithm through simulations, and demonstrate the effect of a risk parameter on value functions at consensus.","sentences":["Autonomous cyber and cyber-physical systems need to perform decision-making, learning, and control in unknown environments.","Such decision-making can be sensitive to multiple factors, including modeling errors, changes in costs, and impacts of events in the tails of probability distributions.","Although multi-agent reinforcement learning (MARL) provides a framework for learning behaviors through repeated interactions with the environment by minimizing an average cost, it will not be adequate to overcome the above challenges.","In this paper, we develop a distributed MARL approach to solve decision-making problems in unknown environments by learning risk-aware actions.","We use the conditional value-at-risk (CVaR) to characterize the cost function that is being minimized, and define a Bellman operator to characterize the value function associated to a given state-action pair.","We prove that this operator satisfies a contraction property, and that it converges to the optimal value function.","We then propose a distributed MARL algorithm called the CVaR QD-Learning algorithm, and establish that value functions of individual agents reaches consensus.","We identify several challenges that arise in the implementation of the CVaR QD-Learning algorithm, and present solutions to overcome these.","We evaluate the CVaR QD-Learning algorithm through simulations, and demonstrate the effect of a risk parameter on value functions at consensus."],"url":"http://arxiv.org/abs/2304.02005v1"}
{"created":"2023-04-04","title":"Inference of the low-energy constants in delta-full chiral effective field theory including a correlated truncation error","abstract":"We sample the posterior probability distributions of the low-energy constants (LECs) in delta-full chiral effective field theory ($\\chi$EFT) up to third order. We use eigenvector continuation for fast and accurate emulation of the likelihood and Hamiltonian Monte Carlo to draw effectively independent samples from the posteriors. Our Bayesian inference is conditioned on the Granada database of neutron-proton ($np$) cross sections and polarizations. We use priors grounded in $\\chi$EFT assumptions and a Roy-Steiner analysis of pion-nucleon scattering data. We model correlated EFT truncation errors using a two-feature Gaussian process, and find correlation lengths for $np$ scattering energies and angles in the ranges 40--120 MeV and 25--45 degrees, respectively. These correlations yield a non-diagonal covariance matrix and reduce the number of independent scattering data with a factor of eight and four at the second and third chiral orders, respectively. The relatively small difference between the second and third order predictions in delta-full $\\chi$EFT suppresses the marginal variance of the truncation error and the effects of its correlation structure. Our results are particularly important for analyzing the predictive capabilities in \\textit{ab initio} nuclear theory.","sentences":["We sample the posterior probability distributions of the low-energy constants (LECs) in delta-full chiral effective field theory ($\\chi$EFT) up to third order.","We use eigenvector continuation for fast and accurate emulation of the likelihood and Hamiltonian Monte Carlo to draw effectively independent samples from the posteriors.","Our Bayesian inference is conditioned on the Granada database of neutron-proton ($np$) cross sections and polarizations.","We use priors grounded in $\\chi$EFT assumptions and a Roy-Steiner analysis of pion-nucleon scattering data.","We model correlated EFT truncation errors using a two-feature Gaussian process, and find correlation lengths for $np$ scattering energies and angles in the ranges 40--120 MeV and 25--45 degrees, respectively.","These correlations yield a non-diagonal covariance matrix and reduce the number of independent scattering data with a factor of eight and four at the second and third chiral orders, respectively.","The relatively small difference between the second and third order predictions in delta-full $\\chi$EFT suppresses the marginal variance of the truncation error and the effects of its correlation structure.","Our results are particularly important for analyzing the predictive capabilities in \\textit{ab initio} nuclear theory."],"url":"http://arxiv.org/abs/2304.02004v1"}
{"created":"2023-04-04","title":"Side Channel-Assisted Inference Leakage from Machine Learning-based ECG Classification","abstract":"The Electrocardiogram (ECG) measures the electrical cardiac activity generated by the heart to detect abnormal heartbeat and heart attack. However, the irregular occurrence of the abnormalities demands continuous monitoring of heartbeats. Machine learning techniques are leveraged to automate the task to reduce labor work needed during monitoring. In recent years, many companies have launched products with ECG monitoring and irregular heartbeat alert. Among all classification algorithms, the time series-based algorithm dynamic time warping (DTW) is widely adopted to undertake the ECG classification task. Though progress has been achieved, the DTW-based ECG classification also brings a new attacking vector of leaking the patients' diagnosis results. This paper shows that the ECG input samples' labels can be stolen via a side-channel attack, Flush+Reload. In particular, we first identify the vulnerability of DTW for ECG classification, i.e., the correlation between warping path choice and prediction results. Then we implement an attack that leverages Flush+Reload to monitor the warping path selection with known ECG data and then build a predictor for constructing the relation between warping path selection and labels of input ECG samples. Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW.","sentences":["The Electrocardiogram (ECG) measures the electrical cardiac activity generated by the heart to detect abnormal heartbeat and heart attack.","However, the irregular occurrence of the abnormalities demands continuous monitoring of heartbeats.","Machine learning techniques are leveraged to automate the task to reduce labor work needed during monitoring.","In recent years, many companies have launched products with ECG monitoring and irregular heartbeat alert.","Among all classification algorithms, the time series-based algorithm dynamic time warping (DTW) is widely adopted to undertake the ECG classification task.","Though progress has been achieved, the DTW-based ECG classification also brings a new attacking vector of leaking the patients' diagnosis results.","This paper shows that the ECG input samples' labels can be stolen via a side-channel attack, Flush+Reload.","In particular, we first identify the vulnerability of DTW for ECG classification, i.e., the correlation between warping path choice and prediction results.","Then we implement an attack that leverages Flush+Reload to monitor the warping path selection with known ECG data and then build a predictor for constructing the relation between warping path selection and labels of input ECG samples.","Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW."],"url":"http://arxiv.org/abs/2304.01990v1"}
{"created":"2023-04-04","title":"ERM++: An Improved Baseline for Domain Generalization","abstract":"Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains. While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels. Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods. We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization. We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive. Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark. We hope that ERM++ becomes a strong baseline for future DG research. Code is released at https://github.com/piotr-teterwak/erm_plusplus.","sentences":["Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains.","While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels.","Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods.","We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization.","We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive.","Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset, a challenging DG benchmark.","We hope that ERM++ becomes a strong baseline for future DG research.","Code is released at https://github.com/piotr-teterwak/erm_plusplus."],"url":"http://arxiv.org/abs/2304.01973v1"}
{"created":"2023-04-04","title":"MEGClass: Text Classification with Extremely Weak Supervision via Mutually-Enhancing Text Granularities","abstract":"Text classification typically requires a substantial amount of human-annotated data to serve as supervision, which is costly to obtain in dynamic emerging domains. Certain methods seek to address this problem by solely relying on the surface text of class names to serve as extremely weak supervision. However, existing methods fail to account for single-class documents discussing multiple topics. Both topic diversity and vague sentences may introduce noise into the document's underlying representation and consequently the precision of the predicted class. Furthermore, current work focuses on text granularities (documents, sentences, or words) independently, which limits the degree of coarse- or fine-grained context that we can jointly extract from all three to identify significant subtext for classification. In order to address this problem, we propose MEGClass, an extremely weakly-supervised text classification method to exploit Mutually-Enhancing Text Granularities. Specifically, MEGClass constructs class-oriented sentence and class representations based on keywords for performing a sentence-level confidence-weighted label ensemble in order to estimate a document's initial class distribution. This serves as the target distribution for a multi-head attention network with a class-weighted contrastive loss. This network learns contextualized sentence representations and weights to form document representations that reflect its original document and sentence-level topic diversity. Retaining this heterogeneity allows MEGClass to select the most class-indicative documents to serve as iterative feedback for enhancing the class representations. Finally, these top documents are used to fine-tune a pre-trained text classifier. As demonstrated through extensive experiments on six benchmark datasets, MEGClass outperforms other weakly and extremely weakly supervised methods.","sentences":["Text classification typically requires a substantial amount of human-annotated data to serve as supervision, which is costly to obtain in dynamic emerging domains.","Certain methods seek to address this problem by solely relying on the surface text of class names to serve as extremely weak supervision.","However, existing methods fail to account for single-class documents discussing multiple topics.","Both topic diversity and vague sentences may introduce noise into the document's underlying representation and consequently the precision of the predicted class.","Furthermore, current work focuses on text granularities (documents, sentences, or words) independently, which limits the degree of coarse- or fine-grained context that we can jointly extract from all three to identify significant subtext for classification.","In order to address this problem, we propose MEGClass, an extremely weakly-supervised text classification method to exploit Mutually-Enhancing Text Granularities.","Specifically, MEGClass constructs class-oriented sentence and class representations based on keywords for performing a sentence-level confidence-weighted label ensemble in order to estimate a document's initial class distribution.","This serves as the target distribution for a multi-head attention network with a class-weighted contrastive loss.","This network learns contextualized sentence representations and weights to form document representations that reflect its original document and sentence-level topic diversity.","Retaining this heterogeneity allows MEGClass to select the most class-indicative documents to serve as iterative feedback for enhancing the class representations.","Finally, these top documents are used to fine-tune a pre-trained text classifier.","As demonstrated through extensive experiments on six benchmark datasets, MEGClass outperforms other weakly and extremely weakly supervised methods."],"url":"http://arxiv.org/abs/2304.01969v1"}
{"created":"2023-04-04","title":"Model-corrected learned primal-dual models for fast limited-view photoacoustic tomography","abstract":"Learned iterative reconstructions hold great promise to accelerate tomographic imaging with empirical robustness to model perturbations. Nevertheless, an adoption for photoacoustic tomography is hindered by the need to repeatedly evaluate the computational expensive forward model. Computational feasibility can be obtained by the use of fast approximate models, but a need to compensate model errors arises. In this work we advance the methodological and theoretical basis for model corrections in learned image reconstructions by embedding the model correction in a learned primal-dual framework. Here, the model correction is jointly learned in data space coupled with a learned updating operator in image space within an unrolled end-to-end learned iterative reconstruction approach. The proposed formulation allows an extension to a primal-dual deep equilibrium model providing fixed-point convergence as well as reduced memory requirements for training. We provide theoretical and empirical insights into the proposed models with numerical validation in a realistic 2D limited-view setting. The model-corrected learned primal-dual methods show excellent reconstruction quality with fast inference times and thus providing a methodological basis for real-time capable and scalable iterative reconstructions in photoacoustic tomography.","sentences":["Learned iterative reconstructions hold great promise to accelerate tomographic imaging with empirical robustness to model perturbations.","Nevertheless, an adoption for photoacoustic tomography is hindered by the need to repeatedly evaluate the computational expensive forward model.","Computational feasibility can be obtained by the use of fast approximate models, but a need to compensate model errors arises.","In this work we advance the methodological and theoretical basis for model corrections in learned image reconstructions by embedding the model correction in a learned primal-dual framework.","Here, the model correction is jointly learned in data space coupled with a learned updating operator in image space within an unrolled end-to-end learned iterative reconstruction approach.","The proposed formulation allows an extension to a primal-dual deep equilibrium model providing fixed-point convergence as well as reduced memory requirements for training.","We provide theoretical and empirical insights into the proposed models with numerical validation in a realistic 2D limited-view setting.","The model-corrected learned primal-dual methods show excellent reconstruction quality with fast inference times and thus providing a methodological basis for real-time capable and scalable iterative reconstructions in photoacoustic tomography."],"url":"http://arxiv.org/abs/2304.01963v1"}
{"created":"2023-04-04","title":"Online Time-Windows TSP with Predictions","abstract":"In the Time-Windows TSP (TW-TSP) we are given requests at different locations on a network; each request is endowed with a reward and an interval of time; the goal is to find a tour that visits as much reward as possible during the corresponding time window. For the online version of this problem, where each request is revealed at the start of its time window, no finite competitive ratio can be obtained. We consider a version of the problem where the algorithm is presented with predictions of where and when the online requests will appear, without any knowledge of the quality of this side information.   Vehicle routing problems such as the TW-TSP can be very sensitive to errors or changes in the input due to the hard time-window constraints, and it is unclear whether imperfect predictions can be used to obtain a finite competitive ratio. We show that good performance can be achieved by explicitly building slack into the solution. Our main result is an online algorithm that achieves a competitive ratio logarithmic in the diameter of the underlying network, matching the performance of the best offline algorithm to within factors that depend on the quality of the provided predictions. The competitive ratio degrades smoothly as a function of the quality and we show that this dependence is tight within constant factors.","sentences":["In the Time-Windows TSP (TW-TSP) we are given requests at different locations on a network; each request is endowed with a reward and an interval of time; the goal is to find a tour that visits as much reward as possible during the corresponding time window.","For the online version of this problem, where each request is revealed at the start of its time window, no finite competitive ratio can be obtained.","We consider a version of the problem where the algorithm is presented with predictions of where and when the online requests will appear, without any knowledge of the quality of this side information.   ","Vehicle routing problems such as the TW-TSP can be very sensitive to errors or changes in the input due to the hard time-window constraints, and it is unclear whether imperfect predictions can be used to obtain a finite competitive ratio.","We show that good performance can be achieved by explicitly building slack into the solution.","Our main result is an online algorithm that achieves a competitive ratio logarithmic in the diameter of the underlying network, matching the performance of the best offline algorithm to within factors that depend on the quality of the provided predictions.","The competitive ratio degrades smoothly as a function of the quality and we show that this dependence is tight within constant factors."],"url":"http://arxiv.org/abs/2304.01958v1"}
{"created":"2023-04-04","title":"Analysis and systematic discretization of a Fokker-Planck equation with Lorentz force","abstract":"The propagation of charged particles through a scattering medium in the presence of a magnetic field can be described by a Fokker-Planck equation with Lorentz force. This model is studied both, from a theoretical and a numerical point of view. A particular trace estimate is derived for the relevant function spaces to clarify the meaning of boundary values. Existence of a weak solution is then proven by the Rothe method. In the second step of our investigations, a fully practicable discretization scheme is proposed based on implicit time-stepping through the energy levels and a spherical-harmonics finite-element discretization with respect to the remaining variables. A full error analysis of the resulting scheme is given, and numerical results are presented to illustrate the theoretical results and the performance of the proposed method.","sentences":["The propagation of charged particles through a scattering medium in the presence of a magnetic field can be described by a Fokker-Planck equation with Lorentz force.","This model is studied both, from a theoretical and a numerical point of view.","A particular trace estimate is derived for the relevant function spaces to clarify the meaning of boundary values.","Existence of a weak solution is then proven by the Rothe method.","In the second step of our investigations, a fully practicable discretization scheme is proposed based on implicit time-stepping through the energy levels and a spherical-harmonics finite-element discretization with respect to the remaining variables.","A full error analysis of the resulting scheme is given, and numerical results are presented to illustrate the theoretical results and the performance of the proposed method."],"url":"http://arxiv.org/abs/2304.01937v1"}
{"created":"2023-04-04","title":"Distributed Attitude Estimation for Multi-agent Systems on $SO(3)$","abstract":"We consider the problem of distributed attitude estimation of multi-agent systems, evolving on $SO(3)$, relying on individual angular velocity and relative attitude measurements. The interaction graph topology is assumed to be an undirected tree. First, we propose a continuous nonlinear distributed attitude estimation scheme with almost global asymptotic stability guarantees. Thereafter, we proceed with the \\textit{hybridization} of the proposed estimation scheme to derive a new hybrid nonlinear distributed attitude estimation scheme enjoying global asymptotic stabilization of the attitude estimation errors to a common constant orientation. In addition, the proposed hybrid attitude estimation scheme is used to solve the problem of formation estimation of $N$-vehicles navigating in a three-dimensional space, with global asymptotic stability guarantees, where the only available measurements are the local relative bearings and the individual linear velocities. Simulation results are provided to illustrate the effectiveness of the proposed estimation schemes.","sentences":["We consider the problem of distributed attitude estimation of multi-agent systems, evolving on $SO(3)$, relying on individual angular velocity and relative attitude measurements.","The interaction graph topology is assumed to be an undirected tree.","First, we propose a continuous nonlinear distributed attitude estimation scheme with almost global asymptotic stability guarantees.","Thereafter, we proceed with the \\textit{hybridization} of the proposed estimation scheme to derive a new hybrid nonlinear distributed attitude estimation scheme enjoying global asymptotic stabilization of the attitude estimation errors to a common constant orientation.","In addition, the proposed hybrid attitude estimation scheme is used to solve the problem of formation estimation of $N$-vehicles navigating in a three-dimensional space, with global asymptotic stability guarantees, where the only available measurements are the local relative bearings and the individual linear velocities.","Simulation results are provided to illustrate the effectiveness of the proposed estimation schemes."],"url":"http://arxiv.org/abs/2304.01928v1"}
{"created":"2023-04-04","title":"Bayesian Meta-Analysis of Penetrance for Cancer Risk","abstract":"Multi-gene panel testing allows many cancer susceptibility genes to be tested quickly at a lower cost making such testing accessible to a broader population. Thus, more patients carrying pathogenic germline mutations in various cancer-susceptibility genes are being identified. This creates a great opportunity, as well as an urgent need, to counsel these patients about appropriate risk reducing management strategies. Counseling hinges on accurate estimates of age-specific risks of developing various cancers associated with mutations in a specific gene, i.e., penetrance estimation. We propose a meta-analysis approach based on a Bayesian hierarchical random-effects model to obtain penetrance estimates by integrating studies reporting different types of risk measures (e.g., penetrance, relative risk, odds ratio) while accounting for the associated uncertainties. After estimating posterior distributions of the parameters via a Markov chain Monte Carlo algorithm, we estimate penetrance and credible intervals. We investigate the proposed method and compare with an existing approach via simulations based on studies reporting risks for two moderate-risk breast cancer susceptibility genes, ATM and PALB2. Our proposed method is far superior in terms of coverage probability of credible intervals and mean square error of estimates. Finally, we apply our method to estimate the penetrance of breast cancer among carriers of pathogenic mutations in the ATM gene.","sentences":["Multi-gene panel testing allows many cancer susceptibility genes to be tested quickly at a lower cost making such testing accessible to a broader population.","Thus, more patients carrying pathogenic germline mutations in various cancer-susceptibility genes are being identified.","This creates a great opportunity, as well as an urgent need, to counsel these patients about appropriate risk reducing management strategies.","Counseling hinges on accurate estimates of age-specific risks of developing various cancers associated with mutations in a specific gene, i.e., penetrance estimation.","We propose a meta-analysis approach based on a Bayesian hierarchical random-effects model to obtain penetrance estimates by integrating studies reporting different types of risk measures (e.g., penetrance, relative risk, odds ratio) while accounting for the associated uncertainties.","After estimating posterior distributions of the parameters via a Markov chain Monte Carlo algorithm, we estimate penetrance and credible intervals.","We investigate the proposed method and compare with an existing approach via simulations based on studies reporting risks for two moderate-risk breast cancer susceptibility genes, ATM and PALB2.","Our proposed method is far superior in terms of coverage probability of credible intervals and mean square error of estimates.","Finally, we apply our method to estimate the penetrance of breast cancer among carriers of pathogenic mutations in the ATM gene."],"url":"http://arxiv.org/abs/2304.01912v2"}
{"created":"2023-04-04","title":"Robustness Benchmark of Road User Trajectory Prediction Models for Automated Driving","abstract":"Accurate and robust trajectory predictions of road users are needed to enable safe automated driving. To do this, machine learning models are often used, which can show erratic behavior when presented with previously unseen inputs. In this work, two environment-aware models (MotionCNN and MultiPath++) and two common baselines (Constant Velocity and an LSTM) are benchmarked for robustness against various perturbations that simulate functional insufficiencies observed during model deployment in a vehicle: unavailability of road information, late detections, and noise. Results show significant performance degradation under the presence of these perturbations, with errors increasing up to +1444.8\\% in commonly used trajectory prediction evaluation metrics. Training the models with similar perturbations effectively reduces performance degradation, with error increases of up to +87.5\\%. We argue that despite being an effective mitigation strategy, data augmentation through perturbations during training does not guarantee robustness towards unforeseen perturbations, since identification of all possible on-road complications is unfeasible. Furthermore, degrading the inputs sometimes leads to more accurate predictions, suggesting that the models are unable to learn the true relationships between the different elements in the data.","sentences":["Accurate and robust trajectory predictions of road users are needed to enable safe automated driving.","To do this, machine learning models are often used, which can show erratic behavior when presented with previously unseen inputs.","In this work, two environment-aware models (MotionCNN and MultiPath++) and two common baselines (Constant Velocity and an LSTM) are benchmarked for robustness against various perturbations that simulate functional insufficiencies observed during model deployment in a vehicle: unavailability of road information, late detections, and noise.","Results show significant performance degradation under the presence of these perturbations, with errors increasing up to +1444.8\\% in commonly used trajectory prediction evaluation metrics.","Training the models with similar perturbations effectively reduces performance degradation, with error increases of up to +87.5\\%.","We argue that despite being an effective mitigation strategy, data augmentation through perturbations during training does not guarantee robustness towards unforeseen perturbations, since identification of all possible on-road complications is unfeasible.","Furthermore, degrading the inputs sometimes leads to more accurate predictions, suggesting that the models are unable to learn the true relationships between the different elements in the data."],"url":"http://arxiv.org/abs/2304.01895v1"}
{"created":"2023-04-04","title":"SportsPose -- A Dynamic 3D sports pose dataset","abstract":"Accurate 3D human pose estimation is essential for sports analytics, coaching, and injury prevention. However, existing datasets for monocular pose estimation do not adequately capture the challenging and dynamic nature of sports movements. In response, we introduce SportsPose, a large-scale 3D human pose dataset consisting of highly dynamic sports movements. With more than 176,000 3D poses from 24 different subjects performing 5 different sports activities, SportsPose provides a diverse and comprehensive set of 3D poses that reflect the complex and dynamic nature of sports movements. Contrary to other markerless datasets we have quantitatively evaluated the precision of SportsPose by comparing our poses with a commercial marker-based system and achieve a mean error of 34.5 mm across all evaluation sequences. This is comparable to the error reported on the commonly used 3DPW dataset. We further introduce a new metric, local movement, which describes the movement of the wrist and ankle joints in relation to the body. With this, we show that SportsPose contains more movement than the Human3.6M and 3DPW datasets in these extremum joints, indicating that our movements are more dynamic. The dataset with accompanying code can be downloaded from our website. We hope that SportsPose will allow researchers and practitioners to develop and evaluate more effective models for the analysis of sports performance and injury prevention. With its realistic and diverse dataset, SportsPose provides a valuable resource for advancing the state-of-the-art in pose estimation in sports.","sentences":["Accurate 3D human pose estimation is essential for sports analytics, coaching, and injury prevention.","However, existing datasets for monocular pose estimation do not adequately capture the challenging and dynamic nature of sports movements.","In response, we introduce SportsPose, a large-scale 3D human pose dataset consisting of highly dynamic sports movements.","With more than 176,000 3D poses from 24 different subjects performing 5 different sports activities, SportsPose provides a diverse and comprehensive set of 3D poses that reflect the complex and dynamic nature of sports movements.","Contrary to other markerless datasets we have quantitatively evaluated the precision of SportsPose by comparing our poses with a commercial marker-based system and achieve a mean error of 34.5 mm across all evaluation sequences.","This is comparable to the error reported on the commonly used 3DPW dataset.","We further introduce a new metric, local movement, which describes the movement of the wrist and ankle joints in relation to the body.","With this, we show that SportsPose contains more movement than the Human3.6M and 3DPW datasets in these extremum joints, indicating that our movements are more dynamic.","The dataset with accompanying code can be downloaded from our website.","We hope that SportsPose will allow researchers and practitioners to develop and evaluate more effective models for the analysis of sports performance and injury prevention.","With its realistic and diverse dataset, SportsPose provides a valuable resource for advancing the state-of-the-art in pose estimation in sports."],"url":"http://arxiv.org/abs/2304.01865v1"}
{"created":"2023-04-04","title":"Learning to Name Classes for Vision and Language Models","abstract":"Large scale vision and language models can achieve impressive zero-shot recognition performance by mapping class specific text queries to image content. Two distinct challenges that remain however, are high sensitivity to the choice of handcrafted class names that define queries, and the difficulty of adaptation to new, smaller datasets. Towards addressing these problems, we propose to leverage available data to learn, for each class, an optimal word embedding as a function of the visual content. By learning new word embeddings on an otherwise frozen model, we are able to retain zero-shot capabilities for new classes, easily adapt models to new datasets, and adjust potentially erroneous, non-descriptive or ambiguous class names. We show that our solution can easily be integrated in image classification and object detection pipelines, yields significant performance gains in multiple scenarios and provides insights into model biases and labelling errors.","sentences":["Large scale vision and language models can achieve impressive zero-shot recognition performance by mapping class specific text queries to image content.","Two distinct challenges that remain however, are high sensitivity to the choice of handcrafted class names that define queries, and the difficulty of adaptation to new, smaller datasets.","Towards addressing these problems, we propose to leverage available data to learn, for each class, an optimal word embedding as a function of the visual content.","By learning new word embeddings on an otherwise frozen model, we are able to retain zero-shot capabilities for new classes, easily adapt models to new datasets, and adjust potentially erroneous, non-descriptive or ambiguous class names.","We show that our solution can easily be integrated in image classification and object detection pipelines, yields significant performance gains in multiple scenarios and provides insights into model biases and labelling errors."],"url":"http://arxiv.org/abs/2304.01830v1"}
{"created":"2023-04-04","title":"CoreDiff: Contextual Error-Modulated Generalized Diffusion Model for Low-Dose CT Denoising and Generalization","abstract":"Low-dose computed tomography (CT) images suffer from noise and artifacts due to photon starvation and electronic noise. Recently, some works have attempted to use diffusion models to address the over-smoothness and training instability encountered by previous deep-learning-based denoising models. However, diffusion models suffer from long inference times due to the large number of sampling steps involved. Very recently, cold diffusion model generalizes classical diffusion models and has greater flexibility. Inspired by the cold diffusion, this paper presents a novel COntextual eRror-modulated gEneralized Diffusion model for low-dose CT (LDCT) denoising, termed CoreDiff. First, CoreDiff utilizes LDCT images to displace the random Gaussian noise and employs a novel mean-preserving degradation operator to mimic the physical process of CT degradation, significantly reducing sampling steps thanks to the informative LDCT images as the starting point of the sampling process. Second, to alleviate the error accumulation problem caused by the imperfect restoration operator in the sampling process, we propose a novel ContextuaL Error-modulAted Restoration Network (CLEAR-Net), which can leverage contextual information to constrain the sampling process from structural distortion and modulate time step embedding features for better alignment with the input at the next time step. Third, to rapidly generalize to a new, unseen dose level with as few resources as possible, we devise a one-shot learning framework to make CoreDiff generalize faster and better using only a single LDCT image (un)paired with NDCT. Extensive experimental results on two datasets demonstrate that our CoreDiff outperforms competing methods in denoising and generalization performance, with a clinically acceptable inference time.","sentences":["Low-dose computed tomography (CT) images suffer from noise and artifacts due to photon starvation and electronic noise.","Recently, some works have attempted to use diffusion models to address the over-smoothness and training instability encountered by previous deep-learning-based denoising models.","However, diffusion models suffer from long inference times due to the large number of sampling steps involved.","Very recently, cold diffusion model generalizes classical diffusion models and has greater flexibility.","Inspired by the cold diffusion, this paper presents a novel COntextual eRror-modulated gEneralized Diffusion model for low-dose CT (LDCT) denoising, termed CoreDiff.","First, CoreDiff utilizes LDCT images to displace the random Gaussian noise and employs a novel mean-preserving degradation operator to mimic the physical process of CT degradation, significantly reducing sampling steps thanks to the informative LDCT images as the starting point of the sampling process.","Second, to alleviate the error accumulation problem caused by the imperfect restoration operator in the sampling process, we propose a novel ContextuaL","Error-modulAted Restoration Network (CLEAR-Net), which can leverage contextual information to constrain the sampling process from structural distortion and modulate time step embedding features for better alignment with the input at the next time step.","Third, to rapidly generalize to a new, unseen dose level with as few resources as possible, we devise a one-shot learning framework to make CoreDiff generalize faster and better using only a single LDCT image (un)paired with NDCT.","Extensive experimental results on two datasets demonstrate that our CoreDiff outperforms competing methods in denoising and generalization performance, with a clinically acceptable inference time."],"url":"http://arxiv.org/abs/2304.01814v1"}
{"created":"2023-04-04","title":"Bridging the Gap between Model Explanations in Partially Annotated Multi-label Classification","abstract":"Due to the expensive costs of collecting labels in multi-label classification datasets, partially annotated multi-label classification has become an emerging field in computer vision. One baseline approach to this task is to assume unobserved labels as negative labels, but this assumption induces label noise as a form of false negative. To understand the negative impact caused by false negative labels, we study how these labels affect the model's explanation. We observe that the explanation of two models, trained with full and partial labels each, highlights similar regions but with different scaling, where the latter tends to have lower attribution scores. Based on these findings, we propose to boost the attribution scores of the model trained with partial labels to make its explanation resemble that of the model trained with full labels. Even with the conceptually simple approach, the multi-label classification performance improves by a large margin in three different datasets on a single positive label setting and one on a large-scale partial label setting. Code is available at https://github.com/youngwk/BridgeGapExplanationPAMC.","sentences":["Due to the expensive costs of collecting labels in multi-label classification datasets, partially annotated multi-label classification has become an emerging field in computer vision.","One baseline approach to this task is to assume unobserved labels as negative labels, but this assumption induces label noise as a form of false negative.","To understand the negative impact caused by false negative labels, we study how these labels affect the model's explanation.","We observe that the explanation of two models, trained with full and partial labels each, highlights similar regions but with different scaling, where the latter tends to have lower attribution scores.","Based on these findings, we propose to boost the attribution scores of the model trained with partial labels to make its explanation resemble that of the model trained with full labels.","Even with the conceptually simple approach, the multi-label classification performance improves by a large margin in three different datasets on a single positive label setting and one on a large-scale partial label setting.","Code is available at https://github.com/youngwk/BridgeGapExplanationPAMC."],"url":"http://arxiv.org/abs/2304.01804v1"}
{"created":"2023-04-04","title":"Minimizing Running Buffers for Tabletop Object Rearrangement: Complexity, Fast Algorithms, and Applications","abstract":"For rearranging objects on tabletops with overhand grasps, temporarily relocating objects to some buffer space may be necessary. This raises the natural question of how many simultaneous storage spaces, or \"running buffers\", are required so that certain classes of tabletop rearrangement problems are feasible. In this work, we examine the problem for both labeled and unlabeled settings. On the structural side, we observe that finding the minimum number of running buffers (MRB) can be carried out on a dependency graph abstracted from a problem instance, and show that computing MRB is NP-hard. We then prove that under both labeled and unlabeled settings, even for uniform cylindrical objects, the number of required running buffers may grow unbounded as the number of objects to be rearranged increases. We further show that the bound for the unlabeled case is tight. On the algorithmic side, we develop effective exact algorithms for finding MRB for both labeled and unlabeled tabletop rearrangement problems, scalable to over a hundred objects under very high object density. More importantly, our algorithms also compute a sequence witnessing the computed MRB that can be used for solving object rearrangement tasks. Employing these algorithms, empirical evaluations reveal that random labeled and unlabeled instances, which more closely mimics real-world setups, generally have fairly small MRBs. Using real robot experiments, we demonstrate that the running buffer abstraction leads to state-of-the-art solutions for in-place rearrangement of many objects in tight, bounded workspace.","sentences":["For rearranging objects on tabletops with overhand grasps, temporarily relocating objects to some buffer space may be necessary.","This raises the natural question of how many simultaneous storage spaces, or \"running buffers\", are required so that certain classes of tabletop rearrangement problems are feasible.","In this work, we examine the problem for both labeled and unlabeled settings.","On the structural side, we observe that finding the minimum number of running buffers (MRB) can be carried out on a dependency graph abstracted from a problem instance, and show that computing MRB is NP-hard.","We then prove that under both labeled and unlabeled settings, even for uniform cylindrical objects, the number of required running buffers may grow unbounded as the number of objects to be rearranged increases.","We further show that the bound for the unlabeled case is tight.","On the algorithmic side, we develop effective exact algorithms for finding MRB for both labeled and unlabeled tabletop rearrangement problems, scalable to over a hundred objects under very high object density.","More importantly, our algorithms also compute a sequence witnessing the computed MRB that can be used for solving object rearrangement tasks.","Employing these algorithms, empirical evaluations reveal that random labeled and unlabeled instances, which more closely mimics real-world setups, generally have fairly small MRBs.","Using real robot experiments, we demonstrate that the running buffer abstraction leads to state-of-the-art solutions for in-place rearrangement of many objects in tight, bounded workspace."],"url":"http://arxiv.org/abs/2304.01764v1"}
{"created":"2023-04-04","title":"Incorporating Unlabelled Data into Bayesian Neural Networks","abstract":"We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.","sentences":["We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data.","With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods.","Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems."],"url":"http://arxiv.org/abs/2304.01762v1"}
{"created":"2023-04-04","title":"Comparing planar quantum computing platforms at the quantum speed limit","abstract":"An important aspect that strongly impacts the experimental feasibility of quantum circuits is the ratio of gate times and typical error time scales. Algorithms with circuit depths that significantly exceed the error time scales will result in faulty quantum states and error correction is inevitable. We present a comparison of the theoretical minimal gate time, i.e., the quantum speed limit (QSL), for realistic two- and multi-qubit gate implementations in neutral atoms and superconducting qubits. Subsequent to finding the QSLs for individual gates by means of optimal control theory we use them to quantify the circuit QSL of the quantum Fourier transform and the quantum approximate optimization algorithm. In particular, we analyze these quantum algorithms in terms of circuit run times and gate counts both in the standard gate model and the parity mapping. We find that neutral atom and superconducting qubit platforms show comparable weighted circuit QSLs with respect to the system size.","sentences":["An important aspect that strongly impacts the experimental feasibility of quantum circuits is the ratio of gate times and typical error time scales.","Algorithms with circuit depths that significantly exceed the error time scales will result in faulty quantum states and error correction is inevitable.","We present a comparison of the theoretical minimal gate time, i.e., the quantum speed limit (QSL), for realistic two- and multi-qubit gate implementations in neutral atoms and superconducting qubits.","Subsequent to finding the QSLs for individual gates by means of optimal control theory we use them to quantify the circuit QSL of the quantum Fourier transform and the quantum approximate optimization algorithm.","In particular, we analyze these quantum algorithms in terms of circuit run times and gate counts both in the standard gate model and the parity mapping.","We find that neutral atom and superconducting qubit platforms show comparable weighted circuit QSLs with respect to the system size."],"url":"http://arxiv.org/abs/2304.01756v1"}
{"created":"2023-04-04","title":"Infinite-dimensional integration and $L^2$-approximation on Hermite spaces","abstract":"We study integration and $L^2$-approximation of functions of infinitely many variables in the following setting: The underlying function space is the countably infinite tensor product of univariate Hermite spaces and the probability measure is the corresponding product of the standard normal distribution. The maximal domain of the functions from this tensor product space is necessarily a proper subset of the sequence space $\\mathbb{R}^\\mathbb{N}$. We establish upper and lower bounds for the minimal worst case errors under general assumptions; these bounds do match for tensor products of well-studied Hermite spaces of functions with finite or with infinite smoothness. In the proofs we employ embedding results, and the upper bounds are attained constructively with the help of multivariate decomposition methods.","sentences":["We study integration and $L^2$-approximation of functions of infinitely many variables in the following setting: The underlying function space is the countably infinite tensor product of univariate Hermite spaces and the probability measure is the corresponding product of the standard normal distribution.","The maximal domain of the functions from this tensor product space is necessarily a proper subset of the sequence space $\\mathbb{R}^\\mathbb{N}$. We establish upper and lower bounds for the minimal worst case errors under general assumptions; these bounds do match for tensor products of well-studied Hermite spaces of functions with finite or with infinite smoothness.","In the proofs we employ embedding results, and the upper bounds are attained constructively with the help of multivariate decomposition methods."],"url":"http://arxiv.org/abs/2304.01754v1"}
{"created":"2023-04-04","title":"Learning Invariant Representation via Contrastive Feature Alignment for Clutter Robust SAR Target Recognition","abstract":"The deep neural networks (DNNs) have freed the synthetic aperture radar automatic target recognition (SAR ATR) from expertise-based feature designing and demonstrated superiority over conventional solutions. There has been shown the unique deficiency of ground vehicle benchmarks in shapes of strong background correlation results in DNNs overfitting the clutter and being non-robust to unfamiliar surroundings. However, the gap between fixed background model training and varying background application remains underexplored. Inspired by contrastive learning, this letter proposes a solution called Contrastive Feature Alignment (CFA) aiming to learn invariant representation for robust recognition. The proposed method contributes a mixed clutter variants generation strategy and a new inference branch equipped with channel-weighted mean square error (CWMSE) loss for invariant representation learning. In specific, the generation strategy is delicately designed to better attract clutter-sensitive deviation in feature space. The CWMSE loss is further devised to better contrast this deviation and align the deep features activated by the original images and corresponding clutter variants. The proposed CFA combines both classification and CWMSE losses to train the model jointly, which allows for the progressive learning of invariant target representation. Extensive evaluations on the MSTAR dataset and six DNN models prove the effectiveness of our proposal. The results demonstrated that the CFA-trained models are capable of recognizing targets among unfamiliar surroundings that are not included in the dataset, and are robust to varying signal-to-clutter ratios.","sentences":["The deep neural networks (DNNs) have freed the synthetic aperture radar automatic target recognition (SAR ATR) from expertise-based feature designing and demonstrated superiority over conventional solutions.","There has been shown the unique deficiency of ground vehicle benchmarks in shapes of strong background correlation results in DNNs overfitting the clutter and being non-robust to unfamiliar surroundings.","However, the gap between fixed background model training and varying background application remains underexplored.","Inspired by contrastive learning, this letter proposes a solution called Contrastive Feature Alignment (CFA) aiming to learn invariant representation for robust recognition.","The proposed method contributes a mixed clutter variants generation strategy and a new inference branch equipped with channel-weighted mean square error (CWMSE) loss for invariant representation learning.","In specific, the generation strategy is delicately designed to better attract clutter-sensitive deviation in feature space.","The CWMSE loss is further devised to better contrast this deviation and align the deep features activated by the original images and corresponding clutter variants.","The proposed CFA combines both classification and CWMSE losses to train the model jointly, which allows for the progressive learning of invariant target representation.","Extensive evaluations on the MSTAR dataset and six DNN models prove the effectiveness of our proposal.","The results demonstrated that the CFA-trained models are capable of recognizing targets among unfamiliar surroundings that are not included in the dataset, and are robust to varying signal-to-clutter ratios."],"url":"http://arxiv.org/abs/2304.01747v1"}
{"created":"2023-04-04","title":"Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation","abstract":"ChatGPT, a large-scale language model based on the advanced GPT-3.5 architecture, has shown remarkable potential in various Natural Language Processing (NLP) tasks. However, there is currently a dearth of comprehensive study exploring its potential in the area of Grammatical Error Correction (GEC). To showcase its capabilities in GEC, we design zero-shot chain-of-thought (CoT) and few-shot CoT settings using in-context learning for ChatGPT. Our evaluation involves assessing ChatGPT's performance on five official test sets in three different languages, along with three document-level GEC test sets in English. Our experimental results and human evaluations demonstrate that ChatGPT has excellent error detection capabilities and can freely correct errors to make the corrected sentences very fluent, possibly due to its over-correction tendencies and not adhering to the principle of minimal edits. Additionally, its performance in non-English and low-resource settings highlights its potential in multilingual GEC tasks. However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors.","sentences":["ChatGPT, a large-scale language model based on the advanced GPT-3.5 architecture, has shown remarkable potential in various Natural Language Processing (NLP) tasks.","However, there is currently a dearth of comprehensive study exploring its potential in the area of Grammatical Error Correction (GEC).","To showcase its capabilities in GEC, we design zero-shot chain-of-thought (CoT) and few-shot CoT settings using in-context learning for ChatGPT.","Our evaluation involves assessing ChatGPT's performance on five official test sets in three different languages, along with three document-level GEC test sets in English.","Our experimental results and human evaluations demonstrate that ChatGPT has excellent error detection capabilities and can freely correct errors to make the corrected sentences very fluent, possibly due to its over-correction tendencies and not adhering to the principle of minimal edits.","Additionally, its performance in non-English and low-resource settings highlights its potential in multilingual GEC tasks.","However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors."],"url":"http://arxiv.org/abs/2304.01746v1"}
{"created":"2023-04-04","title":"Self-sufficient Method for Event Localization and Characterization of Power Transmission Lines Based on Traveling Waves","abstract":"We propose a self-sufficient online method that simultaneously performs transmission line characterization and event localization. Our proposed method eliminates the need for offline transmission line characterization or line parameter modeling based on the transmission line model. The method is based on traveling wave theory and adding a measurement device in a double-sided traveling wave event localization setup. The theoretical background of the method is derived, which is based on a complex continuous wavelet transform. The accuracy of the transmission line characterization method is evaluated using a frequency-dependent transmission line simulation model. The method was developed independently of the type of event and is evaluated in a variety of experimental setups that take into account different lengths of the monitored line section, line characteristics, location of the third measurement device, and location of the event. The localization accuracy is compared with other proposed online methods. The proposed method improves event localization and exhibits high characterization accuracy within a relative error of 1 %, even when mimicking real environmental conditions where noise and desynchronization between measurement devices occur.","sentences":["We propose a self-sufficient online method that simultaneously performs transmission line characterization and event localization.","Our proposed method eliminates the need for offline transmission line characterization or line parameter modeling based on the transmission line model.","The method is based on traveling wave theory and adding a measurement device in a double-sided traveling wave event localization setup.","The theoretical background of the method is derived, which is based on a complex continuous wavelet transform.","The accuracy of the transmission line characterization method is evaluated using a frequency-dependent transmission line simulation model.","The method was developed independently of the type of event and is evaluated in a variety of experimental setups that take into account different lengths of the monitored line section, line characteristics, location of the third measurement device, and location of the event.","The localization accuracy is compared with other proposed online methods.","The proposed method improves event localization and exhibits high characterization accuracy within a relative error of 1 %, even when mimicking real environmental conditions where noise and desynchronization between measurement devices occur."],"url":"http://arxiv.org/abs/2304.01733v1"}
{"created":"2023-04-04","title":"Risk Sensitive Filtering with Randomly Delayed Measurements","abstract":"Conventional Bayesian estimation requires an accurate stochastic model of a system. However, this requirement is not always met in many practical cases where the system is not completely known or may differ from the assumed model. For such a system, we consider a scenario where the measurements are transmitted to a remote location using a common communication network and due to which, a delay is introduced while receiving the measurements. The delay that we consider here is random and one step maximum at a given time instant. For such a scenario, this paper develops a robust estimator for a linear Gaussian system by minimizing the risk sensitive error criterion that is defined as an expectation of the accumulated exponential quadratic error. The criteria for the stability of the risk sensitive Kalman filter (RSKF) are derived and the results are used to study the stability of the developed filter. Further, it is assumed that the latency probability related to delay is not known and it is estimated by maximizing the likelihood function. Simulation results suggest that the proposed filter shows acceptable performance under the nominal conditions, and it performs better than the Kalman filter for randomly delayed measurements and the RSKF in presence of both the model uncertainty and random delays.","sentences":["Conventional Bayesian estimation requires an accurate stochastic model of a system.","However, this requirement is not always met in many practical cases where the system is not completely known or may differ from the assumed model.","For such a system, we consider a scenario where the measurements are transmitted to a remote location using a common communication network and due to which, a delay is introduced while receiving the measurements.","The delay that we consider here is random and one step maximum at a given time instant.","For such a scenario, this paper develops a robust estimator for a linear Gaussian system by minimizing the risk sensitive error criterion that is defined as an expectation of the accumulated exponential quadratic error.","The criteria for the stability of the risk sensitive Kalman filter (RSKF) are derived and the results are used to study the stability of the developed filter.","Further, it is assumed that the latency probability related to delay is not known and it is estimated by maximizing the likelihood function.","Simulation results suggest that the proposed filter shows acceptable performance under the nominal conditions, and it performs better than the Kalman filter for randomly delayed measurements and the RSKF in presence of both the model uncertainty and random delays."],"url":"http://arxiv.org/abs/2304.01727v1"}
{"created":"2023-04-04","title":"Modeling and Estimation for Systems with Randomly Delayed Measurements and Packet Dropouts","abstract":"A networked system often uses a shared communication network to transmit the measurements to a remotely located estimation center. Due to the limited bandwidth of the channel, a delay may appear while receiving the measurements. This delay can be arbitrary step random, and packets are sometimes dropped during transmission as it exceeds a certain permissible number. In this paper, such measurements are modeled with the Poisson distribution, which allows the user to determine the maximum delay the system might suffer. When the measurement delay exceeds the permissible number, the packet dropout happens. Based on the proposed model, we solve the problem by assuming that the prior and posterior densities of states are Gaussian and derive the expression of the estimated state and the error covariance. Later, relaxing the Gaussian assumption for densities, we propose a solution with the help of the sequential Monte Carlo (SMC) approach. The proposed SMC method divides the set of particles into several groups, where each group supports the possibility that the received measurement is delayed by a certain number of steps. The strength of an individual group is determined by the probability of a measurement being delayed with the same number of steps that the group represents. This approach estimates the states and also assesses the amount of delay from the received measurements. Finally, the developed estimators are implemented on two nonlinear estimation problems, and the simulation results are compared. The proposed SMC approach shows better results compared to the designed Gaussian delay filters and existing particle filters with delay.","sentences":["A networked system often uses a shared communication network to transmit the measurements to a remotely located estimation center.","Due to the limited bandwidth of the channel, a delay may appear while receiving the measurements.","This delay can be arbitrary step random, and packets are sometimes dropped during transmission as it exceeds a certain permissible number.","In this paper, such measurements are modeled with the Poisson distribution, which allows the user to determine the maximum delay the system might suffer.","When the measurement delay exceeds the permissible number, the packet dropout happens.","Based on the proposed model, we solve the problem by assuming that the prior and posterior densities of states are Gaussian and derive the expression of the estimated state and the error covariance.","Later, relaxing the Gaussian assumption for densities, we propose a solution with the help of the sequential Monte Carlo (SMC) approach.","The proposed SMC method divides the set of particles into several groups, where each group supports the possibility that the received measurement is delayed by a certain number of steps.","The strength of an individual group is determined by the probability of a measurement being delayed with the same number of steps that the group represents.","This approach estimates the states and also assesses the amount of delay from the received measurements.","Finally, the developed estimators are implemented on two nonlinear estimation problems, and the simulation results are compared.","The proposed SMC approach shows better results compared to the designed Gaussian delay filters and existing particle filters with delay."],"url":"http://arxiv.org/abs/2304.01707v1"}
{"created":"2023-04-04","title":"Cross-modal tumor segmentation using generative blending augmentation and self training","abstract":"Deep learning for medical imaging is limited by data scarcity and domain shift, which lead to biased training sets that do not accurately represent deployment conditions. A related practical problem is cross-modal segmentation where the objective is to segment unlabelled domains using previously labelled images from other modalites, which is the context of the MICCAI CrossMoDA 2022 challenge on vestibular schwannoma (VS) segmentation. In this context, we propose a VS segmentation method that leverages conventional image-to-image translation and segmentation using iterative self training combined to a dedicated data augmentation technique called Generative Blending Augmentation (GBA). GBA is based on a one-shot 2D SinGAN generative model that allows to realistically diversify target tumor appearances in a downstream segmentation model, improving its generalization power at test time. Our solution ranked first on the VS segmentation task during the validation and test phase of the CrossModa 2022 challenge.","sentences":["Deep learning for medical imaging is limited by data scarcity and domain shift, which lead to biased training sets that do not accurately represent deployment conditions.","A related practical problem is cross-modal segmentation where the objective is to segment unlabelled domains using previously labelled images from other modalites, which is the context of the MICCAI CrossMoDA 2022 challenge on vestibular schwannoma (VS) segmentation.","In this context, we propose a VS segmentation method that leverages conventional image-to-image translation and segmentation using iterative self training combined to a dedicated data augmentation technique called Generative Blending Augmentation (GBA).","GBA is based on a one-shot 2D SinGAN generative model that allows to realistically diversify target tumor appearances in a downstream segmentation model, improving its generalization power at test time.","Our solution ranked first on the VS segmentation task during the validation and test phase of the CrossModa 2022 challenge."],"url":"http://arxiv.org/abs/2304.01705v1"}
{"created":"2023-04-04","title":"Optimal Transport for Correctional Learning","abstract":"The contribution of this paper is a generalized formulation of correctional learning using optimal transport, which is about how to optimally transport one mass distribution to another. Correctional learning is a framework developed to enhance the accuracy of parameter estimation processes by means of a teacher-student approach. In this framework, an expert agent, referred to as the teacher, modifies the data used by a learning agent, known as the student, to improve its estimation process. The objective of the teacher is to alter the data such that the student's estimation error is minimized, subject to a fixed intervention budget. Compared to existing formulations of correctional learning, our novel optimal transport approach provides several benefits. It allows for the estimation of more complex characteristics as well as the consideration of multiple intervention policies for the teacher. We evaluate our approach on two theoretical examples, and on a human-robot interaction application in which the teacher's role is to improve the robots performance in an inverse reinforcement learning setting.","sentences":["The contribution of this paper is a generalized formulation of correctional learning using optimal transport, which is about how to optimally transport one mass distribution to another.","Correctional learning is a framework developed to enhance the accuracy of parameter estimation processes by means of a teacher-student approach.","In this framework, an expert agent, referred to as the teacher, modifies the data used by a learning agent, known as the student, to improve its estimation process.","The objective of the teacher is to alter the data such that the student's estimation error is minimized, subject to a fixed intervention budget.","Compared to existing formulations of correctional learning, our novel optimal transport approach provides several benefits.","It allows for the estimation of more complex characteristics as well as the consideration of multiple intervention policies for the teacher.","We evaluate our approach on two theoretical examples, and on a human-robot interaction application in which the teacher's role is to improve the robots performance in an inverse reinforcement learning setting."],"url":"http://arxiv.org/abs/2304.01701v1"}
{"created":"2023-04-04","title":"Inverse Unscented Kalman Filter","abstract":"Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters. In this setting, a cognitive `adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF). The target or `defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary. For linear systems, inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications. In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state with reduced linearization errors. We then generalize this framework to an unknown system model by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations. Our theoretical analyses to guarantee the stochastic stability of I-UKF and RKHS-UKF in the mean-squared sense shows that, provided the forward filters are stable, the inverse filters are also stable under mild system-level conditions. Our numerical experiments for several different applications demonstrate the state estimation performance of the proposed filters using recursive Cram\\'{e}r-Rao lower bound as a benchmark.","sentences":["Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters.","In this setting, a cognitive `adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF).","The target or `defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary.","For linear systems, inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications.","In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state with reduced linearization errors.","We then generalize this framework to an unknown system model by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations.","Our theoretical analyses to guarantee the stochastic stability of I-UKF and RKHS-UKF in the mean-squared sense shows that, provided the forward filters are stable, the inverse filters are also stable under mild system-level conditions.","Our numerical experiments for several different applications demonstrate the state estimation performance of the proposed filters using recursive Cram\\'{e}r-Rao lower bound as a benchmark."],"url":"http://arxiv.org/abs/2304.01698v1"}
{"created":"2023-04-04","title":"Predictive Resource Allocation for URLLC using Empirical Mode Decomposition","abstract":"Effective resource allocation is a crucial requirement to achieve the stringent performance targets of ultra-reliable low-latency communication (URLLC) services. Predicting future interference and utilizing it to design efficient interference management algorithms is one way to allocate resources for URLLC services effectively. This paper proposes an empirical mode decomposition (EMD) based hybrid prediction method to predict the interference and allocate resources for downlink based on the prediction results. EMD is used to decompose the past interference values faced by the user equipment. Long short-term memory and auto-regressive integrated moving average methods are used to predict the decomposed components. The final predicted interference value is reconstructed using individual predicted values of decomposed components. It is found that such a decomposition-based prediction method reduces the root mean squared error of the prediction by $20 - 25\\%$. The proposed resource allocation algorithm utilizing the EMD-based interference prediction was found to meet near-optimal allocation of resources and correspondingly results in $2-3$ orders of magnitude lower outage compared to state-of-the-art baseline prediction algorithm-based resource allocation.","sentences":["Effective resource allocation is a crucial requirement to achieve the stringent performance targets of ultra-reliable low-latency communication (URLLC) services.","Predicting future interference and utilizing it to design efficient interference management algorithms is one way to allocate resources for URLLC services effectively.","This paper proposes an empirical mode decomposition (EMD) based hybrid prediction method to predict the interference and allocate resources for downlink based on the prediction results.","EMD is used to decompose the past interference values faced by the user equipment.","Long short-term memory and auto-regressive integrated moving average methods are used to predict the decomposed components.","The final predicted interference value is reconstructed using individual predicted values of decomposed components.","It is found that such a decomposition-based prediction method reduces the root mean squared error of the prediction by $20 - 25\\%$.","The proposed resource allocation algorithm utilizing the EMD-based interference prediction was found to meet near-optimal allocation of resources and correspondingly results in $2-3$ orders of magnitude lower outage compared to state-of-the-art baseline prediction algorithm-based resource allocation."],"url":"http://arxiv.org/abs/2304.01696v1"}
{"created":"2023-04-04","title":"Lessons learned after three years of SPIDER operation and the first MITICA integrated tests","abstract":"ITER envisages the use of two heating neutral beam injectors plus an optional one as part of the auxiliary heating and current drive system. The 16.5 MW expected neutral beam power per injector is several notches higher than worldwide existing facilities. A Neutral Beam Test Facility (NBTF) was established at Consorzio RFX, exploiting the synergy of two test beds, SPIDER and MITICA. SPIDER is dedicated to developing and characterizing large efficient negative ion sources at relevant parameters in ITER-like conditions: source and accelerator located in the same vacuum where the beam propagates, immunity to electromagnetic interferences of multiple radio-frequency (RF) antennas, avoidance of RF-induced discharges on the outside of the source. Three years of experiments on SPIDER have addressed to the necessary design modifications to enable full performances. The source is presently under a long shut-down phase to incorporate learnings from the experimental campaign. Parallelly, developments on MITICA, the full-scale prototype of the ITER NBI featuring a 1 MV accelerator and ion neutralization, are underway including manufacturing of in-vessel components, while power supplies and auxiliary plants are already under final testing and commissioning. Integration, commissioning and tests of the 1MV power supplies are essential for this first-of-kind system, unparalleled both in research and industry field. The integrated test to confirm 1MV output by combining invertor systems, DC generators and transmission lines extracted errors/accidents in some components. To realize a concrete system for ITER, solutions for the repair and the improvement of the system were developed. Hence, NBTF is emerging as a necessary facility, due to the large gap with existing injectors, effectively dedicated to identify issues and find solutions to enable successful ITER NBI operations in a time bound fashion.","sentences":["ITER envisages the use of two heating neutral beam injectors plus an optional one as part of the auxiliary heating and current drive system.","The 16.5 MW expected neutral beam power per injector is several notches higher than worldwide existing facilities.","A Neutral Beam Test Facility (NBTF) was established at Consorzio RFX, exploiting the synergy of two test beds, SPIDER and MITICA.","SPIDER is dedicated to developing and characterizing large efficient negative ion sources at relevant parameters in ITER-like conditions: source and accelerator located in the same vacuum where the beam propagates, immunity to electromagnetic interferences of multiple radio-frequency (RF) antennas, avoidance of RF-induced discharges on the outside of the source.","Three years of experiments on SPIDER have addressed to the necessary design modifications to enable full performances.","The source is presently under a long shut-down phase to incorporate learnings from the experimental campaign.","Parallelly, developments on MITICA, the full-scale prototype of the ITER NBI featuring a 1 MV accelerator and ion neutralization, are underway including manufacturing of in-vessel components, while power supplies and auxiliary plants are already under final testing and commissioning.","Integration, commissioning and tests of the 1MV power supplies are essential for this first-of-kind system, unparalleled both in research and industry field.","The integrated test to confirm 1MV output by combining invertor systems, DC generators and transmission lines extracted errors/accidents in some components.","To realize a concrete system for ITER, solutions for the repair and the improvement of the system were developed.","Hence, NBTF is emerging as a necessary facility, due to the large gap with existing injectors, effectively dedicated to identify issues and find solutions to enable successful ITER NBI operations in a time bound fashion."],"url":"http://arxiv.org/abs/2304.01692v1"}
{"created":"2023-04-04","title":"Comparison of Two Search Criteria for Lattice-based Kernel Approximation","abstract":"The kernel interpolant in a reproducing kernel Hilbert space is optimal in the worst-case sense among all approximations of a function using the same set of function values. In this paper, we compare two search criteria to construct lattice point sets for use in lattice-based kernel approximation. The first candidate, $\\calP_n^*$, is based on the power function that appears in machine learning literature. The second, $\\calS_n^*$, is a search criterion used for generating lattices for approximation using truncated Fourier series. We find that the empirical difference in error between the lattices constructed using $\\calP_n^*$ and $\\calS_n^*$ is marginal. The criterion $\\calS_n^*$ is preferred as it is computationally more efficient and has a proven error bound.","sentences":["The kernel interpolant in a reproducing kernel Hilbert space is optimal in the worst-case sense among all approximations of a function using the same set of function values.","In this paper, we compare two search criteria to construct lattice point sets for use in lattice-based kernel approximation.","The first candidate, $\\calP_n^*$, is based on the power function that appears in machine learning literature.","The second, $\\calS_n^*$, is a search criterion used for generating lattices for approximation using truncated Fourier series.","We find that the empirical difference in error between the lattices constructed using $\\calP_n^*$ and $\\calS_n^*$ is marginal.","The criterion $\\calS_n^*$ is preferred as it is computationally more efficient and has a proven error bound."],"url":"http://arxiv.org/abs/2304.01685v1"}
{"created":"2023-04-04","title":"Low-overhead Joint Channel Estimation and Data Detection in ZP-OTFS System","abstract":"High pilot overhead and peak-to-average power ratio (PAPR) are challenging issues in channel estimation for orthogonal time frequency space (OTFS) systems. ZP-OTFS is a modified OTFS system where multiple rows along the delay axis are zero. We propose a two-step channel estimation method for the ZP-OTFS system. The proposed method inserts pilot sequences in the zero bins of the ZP-OTFS system, resulting in low overhead and PAPR. Our simulation results demonstrate the effectiveness of the proposed method and show that it outperforms embedded pilot estimation in terms of normalized mean square error (NMSE) at the same bit error rate (BER).","sentences":["High pilot overhead and peak-to-average power ratio (PAPR) are challenging issues in channel estimation for orthogonal time frequency space (OTFS) systems.","ZP-OTFS is a modified OTFS system where multiple rows along the delay axis are zero.","We propose a two-step channel estimation method for the ZP-OTFS system.","The proposed method inserts pilot sequences in the zero bins of the ZP-OTFS system, resulting in low overhead and PAPR.","Our simulation results demonstrate the effectiveness of the proposed method and show that it outperforms embedded pilot estimation in terms of normalized mean square error (NMSE) at the same bit error rate (BER)."],"url":"http://arxiv.org/abs/2304.01681v1"}
{"created":"2023-04-04","title":"Predicting the Performance-Cost Trade-off of Applications Across Multiple Systems","abstract":"In modern computing environments, users may have multiple systems accessible to them such as local clusters, private clouds, or public clouds. This abundance of choices makes it difficult for users to select the system and configuration for running an application that best meet their performance and cost objectives. To assist such users, we propose a prediction tool that predicts the full performance-cost trade-off space of an application across multiple systems. Our tool runs and profiles a submitted application on a small number of configurations from some of the systems, and uses that information to predict the application's performance on all configurations in all systems. The prediction models are trained offline with data collected from running a large number of applications on a wide variety of configurations. Notable aspects of our tool include: providing different scopes of prediction with varying online profiling requirements, automating the selection of the small number of configurations and systems used for online profiling, performing online profiling using partial runs thereby make predictions for applications without running them to completion, employing a classifier to distinguish applications that scale well from those that scale poorly, and predicting the sensitivity of applications to interference from other users. We evaluate our tool using 69 data analytics and scientific computing benchmarks executing on three different single-node CPU systems with 8-9 configurations each and show that it can achieve low prediction error with modest profiling overhead.","sentences":["In modern computing environments, users may have multiple systems accessible to them such as local clusters, private clouds, or public clouds.","This abundance of choices makes it difficult for users to select the system and configuration for running an application that best meet their performance and cost objectives.","To assist such users, we propose a prediction tool that predicts the full performance-cost trade-off space of an application across multiple systems.","Our tool runs and profiles a submitted application on a small number of configurations from some of the systems, and uses that information to predict the application's performance on all configurations in all systems.","The prediction models are trained offline with data collected from running a large number of applications on a wide variety of configurations.","Notable aspects of our tool include: providing different scopes of prediction with varying online profiling requirements, automating the selection of the small number of configurations and systems used for online profiling, performing online profiling using partial runs thereby make predictions for applications without running them to completion, employing a classifier to distinguish applications that scale well from those that scale poorly, and predicting the sensitivity of applications to interference from other users.","We evaluate our tool using 69 data analytics and scientific computing benchmarks executing on three different single-node CPU systems with 8-9 configurations each and show that it can achieve low prediction error with modest profiling overhead."],"url":"http://arxiv.org/abs/2304.01676v1"}
{"created":"2023-04-04","title":"Antenna Array Structures for Enhanced Cluster Index Modulation","abstract":"This paper investigates the effect of various antenna array structures, i.e., uniform linear array (ULA), uniform rectangular array (URA), uniform circular array (UCA), and concentric circular array (CCA), on cluster index modulation (CIM) enabled massive multiple-input multiple-output (mMIMO) millimeter-wave (mmWave) communications systems. As the CIM technique indexes spatial clusters to convey additional information bits, the different radiation characteristics caused by different array structures can significantly affect system performance. By analyzing the effects of array characteristics such as radiation pattern, array directivity, half-power beam width (HPBW), and radiation side lobes on bit error rate (BER) performance, we reveal that URA achieves better error performance than its counterparts in a CIM-enabled mmWave system. We demonstrate that narrower beams alone cannot guarantee better BER performance in a CIM-based system. Instead, other radiation characteristics, especially radiation side lobes, can significantly influence system performance by entailing extra interference in the non-intended directions. Illustrative results show that URA owes its superiority to its lower side lobes. We also propose an algorithm to implement fixed phase shifters (FPS) as a hardware-efficient (HE) analog network structure (beamformer/combiner) to reduce cost and energy consumption in mmWave systems and investigate the effect of a non-ideal analog network on the BER performance for different array structures. It is demonstrated that HE systems with a few FPSs can achieve similar BER performance compared to the optimum (OP) analog network structure.","sentences":["This paper investigates the effect of various antenna array structures, i.e., uniform linear array (ULA), uniform rectangular array (URA), uniform circular array (UCA), and concentric circular array (CCA), on cluster index modulation (CIM) enabled massive multiple-input multiple-output (mMIMO) millimeter-wave (mmWave) communications systems.","As the CIM technique indexes spatial clusters to convey additional information bits, the different radiation characteristics caused by different array structures can significantly affect system performance.","By analyzing the effects of array characteristics such as radiation pattern, array directivity, half-power beam width (HPBW), and radiation side lobes on bit error rate (BER) performance, we reveal that URA achieves better error performance than its counterparts in a CIM-enabled mmWave system.","We demonstrate that narrower beams alone cannot guarantee better BER performance in a CIM-based system.","Instead, other radiation characteristics, especially radiation side lobes, can significantly influence system performance by entailing extra interference in the non-intended directions.","Illustrative results show that URA owes its superiority to its lower side lobes.","We also propose an algorithm to implement fixed phase shifters (FPS) as a hardware-efficient (HE) analog network structure (beamformer/combiner) to reduce cost and energy consumption in mmWave systems and investigate the effect of a non-ideal analog network on the BER performance for different array structures.","It is demonstrated that HE systems with a few FPSs can achieve similar BER performance compared to the optimum (OP) analog network structure."],"url":"http://arxiv.org/abs/2304.01675v1"}
{"created":"2023-04-04","title":"Online Joint Assortment-Inventory Optimization under MNL Choices","abstract":"We study an online joint assortment-inventory optimization problem, in which we assume that the choice behavior of each customer follows the Multinomial Logit (MNL) choice model, and the attraction parameters are unknown a priori. The retailer makes periodic assortment and inventory decisions to dynamically learn from the realized demands about the attraction parameters while maximizing the expected total profit over time. In this paper, we propose a novel algorithm that can effectively balance the exploration and exploitation in the online decision-making of assortment and inventory. Our algorithm builds on a new estimator for the MNL attraction parameters, a novel approach to incentivize exploration by adaptively tuning certain known and unknown parameters, and an optimization oracle to static single-cycle assortment-inventory planning problems with given parameters. We establish a regret upper bound for our algorithm and a lower bound for the online joint assortment-inventory optimization problem, suggesting that our algorithm achieves nearly optimal regret rate, provided that the static optimization oracle is exact. Then we incorporate more practical approximate static optimization oracles into our algorithm, and bound from above the impact of static optimization errors on the regret of our algorithm. At last, we perform numerical studies to demonstrate the effectiveness of our proposed algorithm.","sentences":["We study an online joint assortment-inventory optimization problem, in which we assume that the choice behavior of each customer follows the Multinomial Logit (MNL) choice model, and the attraction parameters are unknown a priori.","The retailer makes periodic assortment and inventory decisions to dynamically learn from the realized demands about the attraction parameters while maximizing the expected total profit over time.","In this paper, we propose a novel algorithm that can effectively balance the exploration and exploitation in the online decision-making of assortment and inventory.","Our algorithm builds on a new estimator for the MNL attraction parameters, a novel approach to incentivize exploration by adaptively tuning certain known and unknown parameters, and an optimization oracle to static single-cycle assortment-inventory planning problems with given parameters.","We establish a regret upper bound for our algorithm and a lower bound for the online joint assortment-inventory optimization problem, suggesting that our algorithm achieves nearly optimal regret rate, provided that the static optimization oracle is exact.","Then we incorporate more practical approximate static optimization oracles into our algorithm, and bound from above the impact of static optimization errors on the regret of our algorithm.","At last, we perform numerical studies to demonstrate the effectiveness of our proposed algorithm."],"url":"http://arxiv.org/abs/2304.02022v1"}
{"created":"2023-04-04","title":"Socio-economic landscape of digital transformation & public NLP systems: A critical review","abstract":"The current wave of digital transformation has spurred digitisation reforms and has led to prodigious development of AI & NLP systems, with several of them entering the public domain. There is a perception that these systems have a non trivial impact on society but there is a dearth of literature in critical AI on what are the kinds of these systems and how do they operate. This paper constructs a broad taxonomy of NLP systems which impact or are impacted by the ``public'' and provides a concrete analyses via various instrumental and normative lenses on the socio-technical nature of these systems. This paper categorises thirty examples of these systems into seven families, namely; finance, customer service, policy making, education, healthcare, law, and security, based on their public use cases. It then critically analyses these applications, first the priors and assumptions they are based on, then their mechanisms, possible methods of data collection, the models and error functions used, etc. This paper further delves into exploring the socio-economic and political contexts in which these families of systems are generally used and their potential impact on the same, and the function creep of these systems. It provides commentary on the potential long-term downstream impact of these systems on communities which use them. Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system.","sentences":["The current wave of digital transformation has spurred digitisation reforms and has led to prodigious development of AI & NLP systems, with several of them entering the public domain.","There is a perception that these systems have a non trivial impact on society but there is a dearth of literature in critical AI on what are the kinds of these systems and how do they operate.","This paper constructs a broad taxonomy of NLP systems which impact or are impacted by the ``public'' and provides a concrete analyses via various instrumental and normative lenses on the socio-technical nature of these systems.","This paper categorises thirty examples of these systems into seven families, namely; finance, customer service, policy making, education, healthcare, law, and security, based on their public use cases.","It then critically analyses these applications, first the priors and assumptions they are based on, then their mechanisms, possible methods of data collection, the models and error functions used, etc.","This paper further delves into exploring the socio-economic and political contexts in which these families of systems are generally used and their potential impact on the same, and the function creep of these systems.","It provides commentary on the potential long-term downstream impact of these systems on communities which use them.","Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system."],"url":"http://arxiv.org/abs/2304.01651v1"}
{"created":"2023-04-04","title":"Constructing and evaluating machine-learned interatomic potentials for Li-based disordered rocksalts","abstract":"Lithium-based disordered rocksalts (LDRs), which are an important class of cathodes for advanced Li-ion batteries, represent a complex chemical and configurational space for conventional density functional theory (DFT)-based high-throughput screening approaches. Notably, atom-centered machine-learned interatomic potentials (MLIPs) are a promising pathway to accurately model the potential energy surface of highly-disordered systems, such as LDRs, where the performance of such MLIPs have not been rigorously explored yet. Here, we represent a comprehensive evaluation of the accuracy, transferability, and ease of training of five MLIPs in modelling LDRs, including artificial neural network potential developed by the atomic energy network (AENET), Gaussian approximation potential (GAP), spectral neighbor analysis potential (SNAP) and its quadratic extension (qSNAP), and moment tensor potential (MTP). Specifically, we generate a DFT-calculated dataset of 10842 disordered LiTMO$_2$ and TMO$_2$ configurations, where TM = Sc, Ti, V, Cr, Mn, Fe, Co, Ni, and/or Cu. Importantly, we find AENET to be the best in terms of accuracy and transferability for energy predictions, while MTP is the best for atomic forces. While AENET is the fastest to train at low number of epochs, the training time increases significantly as epochs increase, with a corresponding reduction in training errors. Note that AENET and GAP tend to overfit in small datasets, with the extent of overfitting reducing with larger datasets. Finally, we observe AENET to provide reasonable predictions of average Li-intercalation voltages in layered, single-TM LiTMO$_2$ frameworks, compared to DFT ($\\sim$10% error on average). Our study should pave the way both for discovering novel LDR electrodes and for modelling other configurationally complex systems, such as high-entropy ceramics and alloys.","sentences":["Lithium-based disordered rocksalts (LDRs), which are an important class of cathodes for advanced Li-ion batteries, represent a complex chemical and configurational space for conventional density functional theory (DFT)-based high-throughput screening approaches.","Notably, atom-centered machine-learned interatomic potentials (MLIPs) are a promising pathway to accurately model the potential energy surface of highly-disordered systems, such as LDRs, where the performance of such MLIPs have not been rigorously explored yet.","Here, we represent a comprehensive evaluation of the accuracy, transferability, and ease of training of five MLIPs in modelling LDRs, including artificial neural network potential developed by the atomic energy network (AENET), Gaussian approximation potential (GAP), spectral neighbor analysis potential (SNAP) and its quadratic extension (qSNAP), and moment tensor potential (MTP).","Specifically, we generate a DFT-calculated dataset of 10842 disordered LiTMO$_2$ and TMO$_2$ configurations, where TM = Sc, Ti, V, Cr, Mn, Fe, Co, Ni, and/or Cu.","Importantly, we find AENET to be the best in terms of accuracy and transferability for energy predictions, while MTP is the best for atomic forces.","While AENET is the fastest to train at low number of epochs, the training time increases significantly as epochs increase, with a corresponding reduction in training errors.","Note that AENET and GAP tend to overfit in small datasets, with the extent of overfitting reducing with larger datasets.","Finally, we observe AENET to provide reasonable predictions of average Li-intercalation voltages in layered, single-TM LiTMO$_2$ frameworks, compared to DFT ($\\sim$10% error on average).","Our study should pave the way both for discovering novel LDR electrodes and for modelling other configurationally complex systems, such as high-entropy ceramics and alloys."],"url":"http://arxiv.org/abs/2304.01650v1"}
{"created":"2023-04-04","title":"High-rate Reliable Communication using Multi-hop and Mesh THz/FSO Networks","abstract":"In this work, we consider multi-hop and mesh hybrid teraHertz/free-space optics (THz/FSO)-based backhaul networks for high data-rate communications. The results are presented for the cases with both out-band integrated access and backhaul (IAB) and non-IAB based communication setups. We consider different deployments of the THz and FSO networks and consider both switching and combining methods between the hybrid FSO/THz links. We study the impact of atmospheric turbulence, atmospheric attenuation, and the pointing error on the FSO communication. The THz communication suffers from small scale fading, path-loss, and the misalignment error. Finally, we evaluate the effects of atmospheric attenuation/path-loss, pointing/misalignment error, small-scale fading, atmospheric turbulence, number of antennas, number of user equipments, number of hops, and the threshold data-rates on the performance of considered systems. As we show, with different network deployments and switching/combining methods, the hybrid implementation of the THz/FSO links improves the network reliability significantly.","sentences":["In this work, we consider multi-hop and mesh hybrid teraHertz/free-space optics (THz/FSO)-based backhaul networks for high data-rate communications.","The results are presented for the cases with both out-band integrated access and backhaul (IAB) and non-IAB based communication setups.","We consider different deployments of the THz and FSO networks and consider both switching and combining methods between the hybrid FSO/THz links.","We study the impact of atmospheric turbulence, atmospheric attenuation, and the pointing error on the FSO communication.","The THz communication suffers from small scale fading, path-loss, and the misalignment error.","Finally, we evaluate the effects of atmospheric attenuation/path-loss, pointing/misalignment error, small-scale fading, atmospheric turbulence, number of antennas, number of user equipments, number of hops, and the threshold data-rates on the performance of considered systems.","As we show, with different network deployments and switching/combining methods, the hybrid implementation of the THz/FSO links improves the network reliability significantly."],"url":"http://arxiv.org/abs/2304.01643v1"}
{"created":"2023-04-04","title":"Adaptive Image Compression via Optimal Mesh Refinement","abstract":"The JPEG algorithm is a defacto standard for image compression. We investigate whether adaptive mesh refinement can be used to optimize the compression ratio and propose a new adaptive image compression algorithm. We prove that it produces a quasi-optimal subdivision grid for a given error norm with high probability. This subdivision can be stored with very little overhead and thus leads to an efficient compression algorithm. We demonstrate experimentally, that the new algorithm can achieve better compression ratios than standard JPEG compression with no visible loss of quality on many images.   The mathematical core of this work shows that Binev's optimal tree approximation algorithm is applicable to image compression with high probability, when we assume small additive Gaussian noise on the pixels of the image.","sentences":["The JPEG algorithm is a defacto standard for image compression.","We investigate whether adaptive mesh refinement can be used to optimize the compression ratio and propose a new adaptive image compression algorithm.","We prove that it produces a quasi-optimal subdivision grid for a given error norm with high probability.","This subdivision can be stored with very little overhead and thus leads to an efficient compression algorithm.","We demonstrate experimentally, that the new algorithm can achieve better compression ratios than standard JPEG compression with no visible loss of quality on many images.   ","The mathematical core of this work shows that Binev's optimal tree approximation algorithm is applicable to image compression with high probability, when we assume small additive Gaussian noise on the pixels of the image."],"url":"http://arxiv.org/abs/2304.01640v1"}
{"created":"2023-04-04","title":"Multidimensional Perceptron for Efficient and Explainable Long Text Classification","abstract":"Because of the inevitable cost and complexity of transformer and pre-trained models, efficiency concerns are raised for long text classification. Meanwhile, in the highly sensitive domains, e.g., healthcare and legal long-text mining, potential model distrust, yet underrated and underexplored, may hatch vital apprehension. Existing methods generally segment the long text, encode each piece with the pre-trained model, and use attention or RNNs to obtain long text representation for classification. In this work, we propose a simple but effective model, Segment-aWare multIdimensional PErceptron (SWIPE), to replace attention/RNNs in the above framework. Unlike prior efforts, SWIPE can effectively learn the label of the entire text with supervised training, while perceive the labels of the segments and estimate their contributions to the long-text labeling in an unsupervised manner. As a general classifier, SWIPE can endorse different encoders, and it outperforms SOTA models in terms of classification accuracy and model efficiency. It is noteworthy that SWIPE achieves superior interpretability to transparentize long text classification results.","sentences":["Because of the inevitable cost and complexity of transformer and pre-trained models, efficiency concerns are raised for long text classification.","Meanwhile, in the highly sensitive domains, e.g., healthcare and legal long-text mining, potential model distrust, yet underrated and underexplored, may hatch vital apprehension.","Existing methods generally segment the long text, encode each piece with the pre-trained model, and use attention or RNNs to obtain long text representation for classification.","In this work, we propose a simple but effective model, Segment-aWare multIdimensional PErceptron (SWIPE), to replace attention/RNNs in the above framework.","Unlike prior efforts, SWIPE can effectively learn the label of the entire text with supervised training, while perceive the labels of the segments and estimate their contributions to the long-text labeling in an unsupervised manner.","As a general classifier, SWIPE can endorse different encoders, and it outperforms SOTA models in terms of classification accuracy and model efficiency.","It is noteworthy that SWIPE achieves superior interpretability to transparentize long text classification results."],"url":"http://arxiv.org/abs/2304.01638v1"}
{"created":"2023-04-04","title":"A unified approach to maximum-norm a posteriori error estimation for second-order time discretisations of parabolic equations","abstract":"A class of linear parabolic equations are considered. We derive a common framework for the a posteriori error analysis of certain second-order time discretisations combined with finite element discretisations in space. In particular we study the Crank-Nicolson method, the extrapolated Euler method, the backward differentiation formula of order 2 (BDF-2), the Lobatto IIIC method and a two-stage SDIRK method. We use the idea of elliptic reconstructions and certain bounds for the Green's function of the parabolic operator.","sentences":["A class of linear parabolic equations are considered.","We derive a common framework for the a posteriori error analysis of certain second-order time discretisations combined with finite element discretisations in space.","In particular we study the Crank-Nicolson method, the extrapolated Euler method, the backward differentiation formula of order 2 (BDF-2), the Lobatto IIIC method and a two-stage SDIRK method.","We use the idea of elliptic reconstructions and certain bounds for the Green's function of the parabolic operator."],"url":"http://arxiv.org/abs/2304.01637v1"}
{"created":"2023-04-04","title":"Label-guided Attention Distillation for Lane Segmentation","abstract":"Contemporary segmentation methods are usually based on deep fully convolutional networks (FCNs). However, the layer-by-layer convolutions with a growing receptive field is not good at capturing long-range contexts such as lane markers in the scene. In this paper, we address this issue by designing a distillation method that exploits label structure when training segmentation network. The intuition is that the ground-truth lane annotations themselves exhibit internal structure. We broadcast the structure hints throughout a teacher network, i.e., we train a teacher network that consumes a lane label map as input and attempts to replicate it as output. Then, the attention maps of the teacher network are adopted as supervisors of the student segmentation network. The teacher network, with label structure information embedded, knows distinctly where the convolution layers should pay visual attention into. The proposed method is named as Label-guided Attention Distillation (LGAD). It turns out that the student network learns significantly better with LGAD than when learning alone. As the teacher network is deprecated after training, our method do not increase the inference time. Note that LGAD can be easily incorporated in any lane segmentation network.","sentences":["Contemporary segmentation methods are usually based on deep fully convolutional networks (FCNs).","However, the layer-by-layer convolutions with a growing receptive field is not good at capturing long-range contexts such as lane markers in the scene.","In this paper, we address this issue by designing a distillation method that exploits label structure when training segmentation network.","The intuition is that the ground-truth lane annotations themselves exhibit internal structure.","We broadcast the structure hints throughout a teacher network, i.e., we train a teacher network that consumes a lane label map as input and attempts to replicate it as output.","Then, the attention maps of the teacher network are adopted as supervisors of the student segmentation network.","The teacher network, with label structure information embedded, knows distinctly where the convolution layers should pay visual attention into.","The proposed method is named as Label-guided Attention Distillation (LGAD).","It turns out that the student network learns significantly better with LGAD than when learning alone.","As the teacher network is deprecated after training, our method do not increase the inference time.","Note that LGAD can be easily incorporated in any lane segmentation network."],"url":"http://arxiv.org/abs/2304.01636v1"}
{"created":"2023-04-04","title":"SimCSum: Joint Learning of Simplification and Cross-lingual Summarization for Cross-lingual Science Journalism","abstract":"Cross-lingual science journalism generates popular science stories of scientific articles different from the source language for a non-expert audience. Hence, a cross-lingual popular summary must contain the salient content of the input document, and the content should be coherent, comprehensible, and in a local language for the targeted audience. We improve these aspects of cross-lingual summary generation by joint training of two high-level NLP tasks, simplification and cross-lingual summarization. The former task reduces linguistic complexity, and the latter focuses on cross-lingual abstractive summarization. We propose a novel multi-task architecture - SimCSum consisting of one shared encoder and two parallel decoders jointly learning simplification and cross-lingual summarization. We empirically investigate the performance of SimCSum by comparing it with several strong baselines over several evaluation metrics and by human evaluation. Overall, SimCSum demonstrates statistically significant improvements over the state-of-the-art on two non-synthetic cross-lingual scientific datasets. Furthermore, we conduct an in-depth investigation into the linguistic properties of generated summaries and an error analysis.","sentences":["Cross-lingual science journalism generates popular science stories of scientific articles different from the source language for a non-expert audience.","Hence, a cross-lingual popular summary must contain the salient content of the input document, and the content should be coherent, comprehensible, and in a local language for the targeted audience.","We improve these aspects of cross-lingual summary generation by joint training of two high-level NLP tasks, simplification and cross-lingual summarization.","The former task reduces linguistic complexity, and the latter focuses on cross-lingual abstractive summarization.","We propose a novel multi-task architecture - SimCSum consisting of one shared encoder and two parallel decoders jointly learning simplification and cross-lingual summarization.","We empirically investigate the performance of SimCSum by comparing it with several strong baselines over several evaluation metrics and by human evaluation.","Overall, SimCSum demonstrates statistically significant improvements over the state-of-the-art on two non-synthetic cross-lingual scientific datasets.","Furthermore, we conduct an in-depth investigation into the linguistic properties of generated summaries and an error analysis."],"url":"http://arxiv.org/abs/2304.01621v1"}
{"created":"2023-04-04","title":"Tractable Identification of Electric Distribution Networks","abstract":"The identification of distribution network topology and parameters is a critical problem that lays the foundation for improving network efficiency, enhancing reliability, and increasing its capacity to host distributed energy resources. Network identification problems often involve estimating a large number of parameters based on highly correlated measurements, resulting in an ill-conditioned and computationally demanding estimation process. We address these challenges by proposing two admittance matrix estimation methods. In the first method, we use the eigendecomposition of the admittance matrix to generalize the notion of stationarity to electrical signals and demonstrate how the stationarity property can be used to facilitate a maximum a posteriori estimation procedure. We relax the stationarity assumption in the second proposed method by employing Linear Minimum Mean Square Error (LMMSE) estimation. Since LMMSE estimation is often ill-conditioned, we introduce an approximate well-conditioned solution based on eigenvalue truncation. Our quantitative results demonstrate the improvement in computational efficiency compared to the state-of-the-art methods while preserving the estimation accuracy.","sentences":["The identification of distribution network topology and parameters is a critical problem that lays the foundation for improving network efficiency, enhancing reliability, and increasing its capacity to host distributed energy resources.","Network identification problems often involve estimating a large number of parameters based on highly correlated measurements, resulting in an ill-conditioned and computationally demanding estimation process.","We address these challenges by proposing two admittance matrix estimation methods.","In the first method, we use the eigendecomposition of the admittance matrix to generalize the notion of stationarity to electrical signals and demonstrate how the stationarity property can be used to facilitate a maximum a posteriori estimation procedure.","We relax the stationarity assumption in the second proposed method by employing Linear Minimum Mean Square Error (LMMSE) estimation.","Since LMMSE estimation is often ill-conditioned, we introduce an approximate well-conditioned solution based on eigenvalue truncation.","Our quantitative results demonstrate the improvement in computational efficiency compared to the state-of-the-art methods while preserving the estimation accuracy."],"url":"http://arxiv.org/abs/2304.01615v1"}
{"created":"2023-04-04","title":"EDeR: A Dataset for Exploring Dependency Relations Between Events","abstract":"Relation extraction is a central task in natural language processing (NLP) and information retrieval (IR) research. We argue that an important type of relation not explored in NLP or IR research to date is that of an event being an argument - required or optional - of another event. We introduce the human-annotated Event Dependency Relation dataset (EDeR) which provides this dependency relation. The annotation is done on a sample of documents from the OntoNotes dataset, which has the added benefit that it integrates with existing, orthogonal, annotations of this dataset. We investigate baseline approaches for predicting the event dependency relation, the best of which achieves an accuracy of 82.61 for binary argument/non-argument classification. We show that recognizing this relation leads to more accurate event extraction (semantic role labelling) and can improve downstream tasks that depend on this, such as co-reference resolution. Furthermore, we demonstrate that predicting the three-way classification into the required argument, optional argument or non-argument is a more challenging task.","sentences":["Relation extraction is a central task in natural language processing (NLP) and information retrieval (IR) research.","We argue that an important type of relation not explored in NLP or IR research to date is that of an event being an argument - required or optional - of another event.","We introduce the human-annotated Event Dependency Relation dataset (EDeR) which provides this dependency relation.","The annotation is done on a sample of documents from the OntoNotes dataset, which has the added benefit that it integrates with existing, orthogonal, annotations of this dataset.","We investigate baseline approaches for predicting the event dependency relation, the best of which achieves an accuracy of 82.61 for binary argument/non-argument classification.","We show that recognizing this relation leads to more accurate event extraction (semantic role labelling) and can improve downstream tasks that depend on this, such as co-reference resolution.","Furthermore, we demonstrate that predicting the three-way classification into the required argument, optional argument or non-argument is a more challenging task."],"url":"http://arxiv.org/abs/2304.01612v1"}
{"created":"2023-04-04","title":"$^{18}$O$/^{17}$O abundance ratio toward a sample of massive star forming regions with parallax distances","abstract":"The $^{18}$O$/^{17}$O abundance ratio is, in principle, a powerful tool to estimate the relative contributions of massive stars and low- to intermediate-mass stars to the chemical enrichment of galaxies. We present $^{18}$O$/^{17}$O ratios derived from simultaneous observations of C$^{18}$O and C$^{17}$O 1-0 toward fifty-one massive star forming regions with the Institut de Radioastronomie Millim\\'etrique (IRAM) 30 meter telescope. Simultaneous observations of HC$^{18}$O$^{+}$ 1-0 and HC$^{17}$O$^{+}$ 1-0 with the Yebes 40m telescope toward five sources from this sample were also done to test the consistency of $^{18}$O$/^{17}$O ratios derived from different isotopic pairs. From our improved measurements, resulting in smaller errors than previous work in the literature, we obtain a clear trend of increasing $^{18}$O$/^{17}$O ratio with increasing galactocentric distance (D$_{GC}$), which provides a significant constraint on Galactic chemical evolution (GCE) models. Current GCE models have to be improved in order to explain the observed C$^{18}$O/C$^{17}$O 1-0 gradient.","sentences":["The $^{18}$O$/^{17}$O abundance ratio is, in principle, a powerful tool to estimate the relative contributions of massive stars and low- to intermediate-mass stars to the chemical enrichment of galaxies.","We present $^{18}$O$/^{17}$O ratios derived from simultaneous observations of C$^{18}$O and C$^{17}$O 1-0 toward fifty-one massive star forming regions with the Institut de Radioastronomie Millim\\'etrique (IRAM) 30 meter telescope.","Simultaneous observations of HC$^{18}$O$^{+}$ 1-0 and HC$^{17}$O$^{+}$ 1-0 with the Yebes 40m telescope toward five sources from this sample were also done to test the consistency of $^{18}$O$/^{17}$O ratios derived from different isotopic pairs.","From our improved measurements, resulting in smaller errors than previous work in the literature, we obtain a clear trend of increasing $^{18}$O$/^{17}$O ratio with increasing galactocentric distance (D$_{GC}$), which provides a significant constraint on Galactic chemical evolution (GCE) models.","Current GCE models have to be improved in order to explain the observed C$^{18}$O/C$^{17}$O 1-0 gradient."],"url":"http://arxiv.org/abs/2304.01610v1"}
{"created":"2023-04-04","title":"Exponential superiority in probability of stochastic symplectic methods for linear stochastic oscillator","abstract":"This paper proposes a novel concept of exponential superiority in probability to compare the numerical methods for general stochastic differential equations from the perspective of the tail probability of the error. We take the linear stochastic oscillator as the test equation and consider several concrete numerical methods. By establishing the large deviation principles of the errors of the considered numerical methods, we show that the symplectic methods are exponentially superior to the non-symplectic methods in probability when the computational time $T$ is sufficiently large. This provides a new way to explain the superiority of stochastic symplectic methods over non-symplectic methods in the long-time simulation.","sentences":["This paper proposes a novel concept of exponential superiority in probability to compare the numerical methods for general stochastic differential equations from the perspective of the tail probability of the error.","We take the linear stochastic oscillator as the test equation and consider several concrete numerical methods.","By establishing the large deviation principles of the errors of the considered numerical methods, we show that the symplectic methods are exponentially superior to the non-symplectic methods in probability when the computational time $T$ is sufficiently large.","This provides a new way to explain the superiority of stochastic symplectic methods over non-symplectic methods in the long-time simulation."],"url":"http://arxiv.org/abs/2304.01602v1"}
{"created":"2023-04-04","title":"Primitive Simultaneous Optimization of Similarity Metrics for Image Registration","abstract":"Even though simultaneous optimization of similarity metrics represents a standard procedure in the field of semantic segmentation, surprisingly, this does not hold true for image registration. To close this unexpected gap in the literature, we investigate in a complex multi-modal 3D setting whether simultaneous optimization of registration metrics, here implemented by means of primitive summation, can benefit image registration. We evaluate two challenging datasets containing collections of pre- to post-operative and pre- to intra-operative Magnetic Resonance Imaging (MRI) of glioma. Employing the proposed optimization we demonstrate improved registration accuracy in terms of Target Registration Error (TRE) on expert neuroradiologists' landmark annotations.","sentences":["Even though simultaneous optimization of similarity metrics represents a standard procedure in the field of semantic segmentation, surprisingly, this does not hold true for image registration.","To close this unexpected gap in the literature, we investigate in a complex multi-modal 3D setting whether simultaneous optimization of registration metrics, here implemented by means of primitive summation, can benefit image registration.","We evaluate two challenging datasets containing collections of pre- to post-operative and pre- to intra-operative Magnetic Resonance Imaging (MRI) of glioma.","Employing the proposed optimization we demonstrate improved registration accuracy in terms of Target Registration Error (TRE) on expert neuroradiologists' landmark annotations."],"url":"http://arxiv.org/abs/2304.01601v1"}
{"created":"2023-04-04","title":"Minimum Cost Flow in the CONGEST Model","abstract":"We consider the CONGEST model on a network with $n$ nodes, $m$ edges, diameter $D$, and integer costs and capacities bounded by $\\text{poly} n$. In this paper, we show how to find an exact solution to the minimum cost flow problem in $n^{1/2+o(1)}(\\sqrt{n}+D)$ rounds, improving the state of the art algorithm with running time $m^{3/7+o(1)}(\\sqrt nD^{1/4}+D)$ [Forster et al. FOCS 2021], which only holds for the special case of unit capacity graphs. For certain graphs, we achieve even better results. In particular, for planar graphs, expander graphs, $n^{o(1)}$-genus graphs, $n^{o(1)}$-treewidth graphs, and excluded-minor graphs our algorithm takes $n^{1/2+o(1)}D$ rounds. We obtain this result by combining recent results on Laplacian solvers in the CONGEST model [Forster et al. FOCS 2021, Anagnostides et al. DISC 2022] with a CONGEST implementation of the LP solver of Lee and Sidford [FOCS 2014], and finally show that we can round the approximate solution to an exact solution. Our algorithm solves certain linear programs, that generalize minimum cost flow, up to additive error $\\epsilon$ in $n^{1/2+o(1)}(\\sqrt{n}+D)\\log^3 (1/\\epsilon)$ rounds.","sentences":["We consider the CONGEST model on a network with $n$ nodes, $m$ edges, diameter $D$, and integer costs and capacities bounded by $\\text{poly} n$.","In this paper, we show how to find an exact solution to the minimum cost flow problem in $n^{1/2+o(1)}(\\sqrt{n}+D)$ rounds, improving the state of the art algorithm with running time $m^{3/7+o(1)}(\\sqrt nD^{1/4}+D)$","[Forster et al. FOCS 2021], which only holds for the special case of unit capacity graphs.","For certain graphs, we achieve even better results.","In particular, for planar graphs, expander graphs, $n^{o(1)}$-genus graphs, $n^{o(1)}$-treewidth graphs, and excluded-minor graphs our algorithm takes $n^{1/2+o(1)}D$ rounds.","We obtain this result by combining recent results on Laplacian solvers in the CONGEST model [Forster et al. FOCS 2021, Anagnostides et al. DISC 2022] with a CONGEST implementation of the LP solver of Lee and Sidford [FOCS 2014], and finally show that we can round the approximate solution to an exact solution.","Our algorithm solves certain linear programs, that generalize minimum cost flow, up to additive error $\\epsilon$ in $n^{1/2+o(1)}(\\sqrt{n}+D)\\log^3 (1/\\epsilon)$ rounds."],"url":"http://arxiv.org/abs/2304.01600v1"}
{"created":"2023-04-04","title":"MM-BSN: Self-Supervised Image Denoising for Real-World with Multi-Mask based on Blind-Spot Network","abstract":"Recent advances in deep learning have been pushing image denoising techniques to a new level. In self-supervised image denoising, blind-spot network (BSN) is one of the most common methods. However, most of the existing BSN algorithms use a dot-based central mask, which is recognized as inefficient for images with large-scale spatially correlated noise. In this paper, we give the definition of large-noise and propose a multi-mask strategy using multiple convolutional kernels masked in different shapes to further break the noise spatial correlation. Furthermore, we propose a novel self-supervised image denoising method that combines the multi-mask strategy with BSN (MM-BSN). We show that different masks can cause significant performance differences, and the proposed MM-BSN can efficiently fuse the features extracted by multi-masked layers, while recovering the texture structures destroyed by multi-masking and information transmission. Our MM-BSN can be used to address the problem of large-noise denoising, which cannot be efficiently handled by other BSN methods. Extensive experiments on public real-world datasets demonstrate that the proposed MM-BSN achieves state-of-the-art performance among self-supervised and even unpaired image denoising methods for sRGB images denoising, without any labelling effort or prior knowledge. Code can be found in https://github.com/dannie125/MM-BSN.","sentences":["Recent advances in deep learning have been pushing image denoising techniques to a new level.","In self-supervised image denoising, blind-spot network (BSN) is one of the most common methods.","However, most of the existing BSN algorithms use a dot-based central mask, which is recognized as inefficient for images with large-scale spatially correlated noise.","In this paper, we give the definition of large-noise and propose a multi-mask strategy using multiple convolutional kernels masked in different shapes to further break the noise spatial correlation.","Furthermore, we propose a novel self-supervised image denoising method that combines the multi-mask strategy with BSN (MM-BSN).","We show that different masks can cause significant performance differences, and the proposed MM-BSN can efficiently fuse the features extracted by multi-masked layers, while recovering the texture structures destroyed by multi-masking and information transmission.","Our MM-BSN can be used to address the problem of large-noise denoising, which cannot be efficiently handled by other BSN methods.","Extensive experiments on public real-world datasets demonstrate that the proposed MM-BSN achieves state-of-the-art performance among self-supervised and even unpaired image denoising methods for sRGB images denoising, without any labelling effort or prior knowledge.","Code can be found in https://github.com/dannie125/MM-BSN."],"url":"http://arxiv.org/abs/2304.01598v2"}
{"created":"2023-04-04","title":"PAC-Based Formal Verification for Out-of-Distribution Data Detection","abstract":"Cyber-physical systems (CPS) like autonomous vehicles, that utilize learning components, are often sensitive to noise and out-of-distribution (OOD) instances encountered during runtime. As such, safety critical tasks depend upon OOD detection subsystems in order to restore the CPS to a known state or interrupt execution to prevent safety from being compromised. However, it is difficult to guarantee the performance of OOD detectors as it is difficult to characterize the OOD aspect of an instance, especially in high-dimensional unstructured data.   To distinguish between OOD data and data known to the learning component through the training process, an emerging technique is to incorporate variational autoencoders (VAE) within systems and apply classification or anomaly detection techniques on their latent spaces. The rationale for doing so is the reduction of the data domain size through the encoding process, which benefits real-time systems through decreased processing requirements, facilitates feature analysis for unstructured data and allows more explainable techniques to be implemented.   This study places probably approximately correct (PAC) based guarantees on OOD detection using the encoding process within VAEs to quantify image features and apply conformal constraints over them. This is used to bound the detection error on unfamiliar instances with user-defined confidence. The approach used in this study is to empirically establish these bounds by sampling the latent probability distribution and evaluating the error with respect to the constraint violations that are encountered. The guarantee is then verified using data generated from CARLA, an open-source driving simulator.","sentences":["Cyber-physical systems (CPS) like autonomous vehicles, that utilize learning components, are often sensitive to noise and out-of-distribution (OOD) instances encountered during runtime.","As such, safety critical tasks depend upon OOD detection subsystems in order to restore the CPS to a known state or interrupt execution to prevent safety from being compromised.","However, it is difficult to guarantee the performance of OOD detectors as it is difficult to characterize the OOD aspect of an instance, especially in high-dimensional unstructured data.   ","To distinguish between OOD data and data known to the learning component through the training process, an emerging technique is to incorporate variational autoencoders (VAE) within systems and apply classification or anomaly detection techniques on their latent spaces.","The rationale for doing so is the reduction of the data domain size through the encoding process, which benefits real-time systems through decreased processing requirements, facilitates feature analysis for unstructured data and allows more explainable techniques to be implemented.   ","This study places probably approximately correct (PAC) based guarantees on OOD detection using the encoding process within VAEs to quantify image features and apply conformal constraints over them.","This is used to bound the detection error on unfamiliar instances with user-defined confidence.","The approach used in this study is to empirically establish these bounds by sampling the latent probability distribution and evaluating the error with respect to the constraint violations that are encountered.","The guarantee is then verified using data generated from CARLA, an open-source driving simulator."],"url":"http://arxiv.org/abs/2304.01592v1"}
{"created":"2023-04-04","title":"Spatiotemporal and Semantic Zero-inflated Urban Anomaly Prediction","abstract":"Urban anomaly predictions, such as traffic accident prediction and crime prediction, are of vital importance to smart city security and maintenance. Existing methods typically use deep learning to capture the intra-dependencies in spatial and temporal dimensions. However, numerous key challenges remain unsolved, for instance, sparse zero-inflated data due to urban anomalies occurring with low frequency (which can lead to poor performance on real-world datasets), and both intra- and inter-dependencies of abnormal patterns across spatial, temporal, and semantic dimensions. Moreover, a unified approach to predict multiple kinds of anomaly is left to explore. In this paper, we propose STS to jointly capture the intra- and inter-dependencies between the patterns and the influential factors in three dimensions. Further, we use a multi-task prediction module with a customized loss function to solve the zero-inflated issue. To verify the effectiveness of the model, we apply it to two urban anomaly prediction tasks, crime prediction and traffic accident risk prediction, respectively. Experiments on two application scenarios with four real-world datasets demonstrate the superiority of STS, which outperforms state-of-the-art methods in the mean absolute error and the root mean square error by 37.88% and 18.10% on zero-inflated datasets, and, 60.32% and 37.28% on non-zero datasets, respectively.","sentences":["Urban anomaly predictions, such as traffic accident prediction and crime prediction, are of vital importance to smart city security and maintenance.","Existing methods typically use deep learning to capture the intra-dependencies in spatial and temporal dimensions.","However, numerous key challenges remain unsolved, for instance, sparse zero-inflated data due to urban anomalies occurring with low frequency (which can lead to poor performance on real-world datasets), and both intra- and inter-dependencies of abnormal patterns across spatial, temporal, and semantic dimensions.","Moreover, a unified approach to predict multiple kinds of anomaly is left to explore.","In this paper, we propose STS to jointly capture the intra- and inter-dependencies between the patterns and the influential factors in three dimensions.","Further, we use a multi-task prediction module with a customized loss function to solve the zero-inflated issue.","To verify the effectiveness of the model, we apply it to two urban anomaly prediction tasks, crime prediction and traffic accident risk prediction, respectively.","Experiments on two application scenarios with four real-world datasets demonstrate the superiority of STS, which outperforms state-of-the-art methods in the mean absolute error and the root mean square error by 37.88% and 18.10% on zero-inflated datasets, and, 60.32% and 37.28% on non-zero datasets, respectively."],"url":"http://arxiv.org/abs/2304.01569v1"}
{"created":"2023-04-04","title":"MEnsA: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds","abstract":"Unsupervised domain adaptation (UDA) addresses the problem of distribution shift between the unlabelled target domain and labelled source domain. While the single target domain adaptation (STDA) is well studied in the literature for both 2D and 3D vision tasks, multi-target domain adaptation (MTDA) is barely explored for 3D data despite its wide real-world applications such as autonomous driving systems for various geographical and climatic conditions. We establish an MTDA baseline for 3D point cloud data by proposing to mix the feature representations from all domains together to achieve better domain adaptation performance by an ensemble average, which we call Mixup Ensemble Average or MEnsA. With the mixed representation, we use a domain classifier to improve at distinguishing the feature representations of source domain from those of target domains in a shared latent space. In empirical validations on the challenging PointDA-10 dataset, we showcase a clear benefit of our simple method over previous unsupervised STDA and MTDA methods by large margins (up to 17.10% and 4.76% on averaged over all domain shifts).","sentences":["Unsupervised domain adaptation (UDA) addresses the problem of distribution shift between the unlabelled target domain and labelled source domain.","While the single target domain adaptation (STDA) is well studied in the literature for both 2D and 3D vision tasks, multi-target domain adaptation (MTDA) is barely explored for 3D data despite its wide real-world applications such as autonomous driving systems for various geographical and climatic conditions.","We establish an MTDA baseline for 3D point cloud data by proposing to mix the feature representations from all domains together to achieve better domain adaptation performance by an ensemble average, which we call Mixup Ensemble Average or MEnsA. With the mixed representation, we use a domain classifier to improve at distinguishing the feature representations of source domain from those of target domains in a shared latent space.","In empirical validations on the challenging PointDA-10 dataset, we showcase a clear benefit of our simple method over previous unsupervised STDA and MTDA methods by large margins (up to 17.10% and 4.76% on averaged over all domain shifts)."],"url":"http://arxiv.org/abs/2304.01554v2"}
{"created":"2023-04-04","title":"Superglitter and squarodiamond, novel C12 (sp2/sp3) and C16 (sp3) allotropes from first principles","abstract":"Original carbon allotropes C12 and C16 called superglitter and squarodiamond from relationships with literature glitter and squaroglitter respectively are shown through DFT-based geometry to be cohesive with energy dependent properties as hardness from the elastic constants, the phonon band structures, and thermal behavior related to diamond. Like C6 glitter, C12 superglitter exhibiting mixed sp2-sp3 carbon hybridization shows metallic behavior and moderate hardness and metallic behavior arising from trigonal C(sp2) forming C=C pairs connecting tetrahedra. Oppositely, C16 showing square C4 motifs as in squaroglitter characterized by both sp2-sp3 carbons, is characterized by edge and corner sharing tetrahedra with only sp3 carbons resulting in insulating behavior and shear modulus and Vickers hardness H(V) larger than 100 GPa as well as heat capacity alike diamond, whence its labeling as squarodiamond. The novel carbon allotropes are proposed as an opportunity to enrich the carbon database and the materials science with potentials of applications as abrasives and in electronic devices.","sentences":["Original carbon allotropes C12 and C16 called superglitter and squarodiamond from relationships with literature glitter and squaroglitter respectively are shown through DFT-based geometry to be cohesive with energy dependent properties as hardness from the elastic constants, the phonon band structures, and thermal behavior related to diamond.","Like C6 glitter, C12 superglitter exhibiting mixed sp2-sp3 carbon hybridization shows metallic behavior and moderate hardness and metallic behavior arising from trigonal C(sp2)","forming C=C pairs connecting tetrahedra.","Oppositely, C16 showing square C4 motifs as in squaroglitter characterized by both sp2-sp3 carbons, is characterized by edge and corner sharing tetrahedra with only sp3 carbons resulting in insulating behavior and shear modulus and Vickers hardness H(V) larger than 100 GPa as well as heat capacity alike diamond, whence its labeling as squarodiamond.","The novel carbon allotropes are proposed as an opportunity to enrich the carbon database and the materials science with potentials of applications as abrasives and in electronic devices."],"url":"http://arxiv.org/abs/2304.01549v1"}
{"created":"2023-04-04","title":"Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation","abstract":"Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\\varepsilon, \\delta)$-differential privacy (DP) constraints. We show that in order to achieve the optimal error under $(\\varepsilon, \\delta)$-DP, it is sufficient for each client to send $\\Theta\\left( n \\min\\left(\\varepsilon, \\varepsilon^2\\right)\\right)$ bits for FL and $\\Theta\\left(\\log\\left( n\\min\\left(\\varepsilon, \\varepsilon^2\\right) \\right)\\right)$ bits for FA to the server, where $n$ is the number of participating clients. Without compression, each client needs $O(d)$ bits and $\\log d$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime $ n \\min\\left(\\varepsilon, \\varepsilon^2\\right) = o(d)$, which is often the relevant regime in practice. Our algorithms leverage compression for privacy amplification: when each client communicates only partial information about its sample, we show that privacy can be amplified by randomly selecting the part contributed by each client.","sentences":["Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA).","We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\\varepsilon, \\delta)$-differential privacy (DP) constraints.","We show that in order to achieve the optimal error under $(\\varepsilon, \\delta)$-DP, it is sufficient for each client to send $\\Theta\\left( n \\min\\left(\\varepsilon, \\varepsilon^2\\right)\\right)$ bits for FL and $\\Theta\\left(\\log\\left( n\\min\\left(\\varepsilon, \\varepsilon^2\\right) \\right)\\right)$ bits for FA to the server, where $n$ is the number of participating clients.","Without compression, each client needs $O(d)$ bits and $\\log d$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime $ n \\min\\left(\\varepsilon, \\varepsilon^2\\right) = o(d)$, which is often the relevant regime in practice.","Our algorithms leverage compression for privacy amplification: when each client communicates only partial information about its sample, we show that privacy can be amplified by randomly selecting the part contributed by each client."],"url":"http://arxiv.org/abs/2304.01541v1"}
{"created":"2023-04-04","title":"State and Parameter Estimation for Affine Nonlinear Systems","abstract":"This paper proposes a new approach to online state and parameter estimation for nonlinear systems that address limitations in traditional adaptive control methods. Conventional methods apply to a narrow class of nonlinear systems and rely on stringent excitation conditions, which can be challenging to obtain in practice. In contrast, the proposed approach uses multiplier matrices and a data-driven concurrent learning method to develop an adaptive observer for affine nonlinear systems. Through Lyapunov-based analysis, the technique is proven to guarantee locally exponentially stable state estimates and ultimately bounded parameter estimation errors. Additionally, under certain excitation conditions, the parameter estimation error is guaranteed to converge to zero. Simulation results confirm the effectiveness of the approach, even under mild excitation conditions, highlighting its potential applicability in real-world systems.","sentences":["This paper proposes a new approach to online state and parameter estimation for nonlinear systems that address limitations in traditional adaptive control methods.","Conventional methods apply to a narrow class of nonlinear systems and rely on stringent excitation conditions, which can be challenging to obtain in practice.","In contrast, the proposed approach uses multiplier matrices and a data-driven concurrent learning method to develop an adaptive observer for affine nonlinear systems.","Through Lyapunov-based analysis, the technique is proven to guarantee locally exponentially stable state estimates and ultimately bounded parameter estimation errors.","Additionally, under certain excitation conditions, the parameter estimation error is guaranteed to converge to zero.","Simulation results confirm the effectiveness of the approach, even under mild excitation conditions, highlighting its potential applicability in real-world systems."],"url":"http://arxiv.org/abs/2304.01526v1"}
{"created":"2023-04-04","title":"Multimodal Neural Processes for Uncertainty Estimation","abstract":"Neural processes (NPs) have brought the representation power of parametric deep neural networks and the reliable uncertainty estimation of non-parametric Gaussian processes together. Although recent development of NPs has shown success in both regression and classification, how to adapt NPs to multimodal data has not be carefully studied. For the first time, we propose a new model of NP family for multimodal uncertainty estimation, namely Multimodal Neural Processes. In a holistic and principled way, we develop a dynamic context memory updated by the classification error, a multimodal Bayesian aggregation mechanism to aggregate multimodal representations, and a new attention mechanism for calibrated predictions. In extensive empirical evaluation, our method achieves the state-of-the-art multimodal uncertainty estimation performance, showing its appealing ability of being robust against noisy samples and reliable in out-of-domain detection.","sentences":["Neural processes (NPs) have brought the representation power of parametric deep neural networks and the reliable uncertainty estimation of non-parametric Gaussian processes together.","Although recent development of NPs has shown success in both regression and classification, how to adapt NPs to multimodal data has not be carefully studied.","For the first time, we propose a new model of NP family for multimodal uncertainty estimation, namely Multimodal Neural Processes.","In a holistic and principled way, we develop a dynamic context memory updated by the classification error, a multimodal Bayesian aggregation mechanism to aggregate multimodal representations, and a new attention mechanism for calibrated predictions.","In extensive empirical evaluation, our method achieves the state-of-the-art multimodal uncertainty estimation performance, showing its appealing ability of being robust against noisy samples and reliable in out-of-domain detection."],"url":"http://arxiv.org/abs/2304.01518v1"}
{"created":"2023-04-04","title":"Code-Division OFDM Joint Communication and Sensing System for 6G Machine-type Communication","abstract":"The joint communication and sensing (JCS) system can provide higher spectrum efficiency and load-saving for 6G machine-type communication (MTC) applications by merging necessary communication and sensing abilities with unified spectrum and transceivers. In order to suppress the mutual interference between the communication and radar sensing signals to improve the communication reliability and radar sensing accuracy, we propose a novel code-division orthogonal frequency division multiplex (CD-OFDM) JCS MTC system, where MTC users can simultaneously and continuously conduct communication and sensing with each other. {\\color{black} We propose a novel CD-OFDM JCS signal and corresponding successive-interference-cancellation (SIC) based signal processing technique that obtains code-division multiplex (CDM) gain, which is compatible with the prevalent orthogonal frequency division multiplex (OFDM) communication system.} To model the unified JCS signal transmission and reception process, we propose a novel unified JCS channel model. Finally, the simulation and numerical results are shown to verify the feasibility of the CD-OFDM JCS MTC system {\\color{black} and the error propagation performance}. We show that the CD-OFDM JCS MTC system can achieve not only more reliable communication but also comparably robust radar sensing compared with the precedent OFDM JCS system, especially in low signal-to-interference-and-noise ratio (SINR) regime.","sentences":["The joint communication and sensing (JCS) system can provide higher spectrum efficiency and load-saving for 6G machine-type communication (MTC) applications by merging necessary communication and sensing abilities with unified spectrum and transceivers.","In order to suppress the mutual interference between the communication and radar sensing signals to improve the communication reliability and radar sensing accuracy, we propose a novel code-division orthogonal frequency division multiplex (CD-OFDM) JCS MTC system, where MTC users can simultaneously and continuously conduct communication and sensing with each other.","{\\color{black} We propose a novel CD-OFDM JCS signal and corresponding successive-interference-cancellation (SIC) based signal processing technique that obtains code-division multiplex (CDM) gain, which is compatible with the prevalent orthogonal frequency division multiplex (OFDM) communication system.}","To model the unified JCS signal transmission and reception process, we propose a novel unified JCS channel model.","Finally, the simulation and numerical results are shown to verify the feasibility of the CD-OFDM JCS MTC system {\\color{black} and the error propagation performance}.","We show that the CD-OFDM JCS MTC system can achieve not only more reliable communication but also comparably robust radar sensing compared with the precedent OFDM JCS system, especially in low signal-to-interference-and-noise ratio (SINR) regime."],"url":"http://arxiv.org/abs/2304.01517v1"}
{"created":"2023-04-04","title":"Robust Outlier Rejection for 3D Registration with Variational Bayes","abstract":"Learning-based outlier (mismatched correspondence) rejection for robust 3D registration generally formulates the outlier removal as an inlier/outlier classification problem. The core for this to be successful is to learn the discriminative inlier/outlier feature representations. In this paper, we develop a novel variational non-local network-based outlier rejection framework for robust alignment. By reformulating the non-local feature learning with variational Bayesian inference, the Bayesian-driven long-range dependencies can be modeled to aggregate discriminative geometric context information for inlier/outlier distinction. Specifically, to achieve such Bayesian-driven contextual dependencies, each query/key/value component in our non-local network predicts a prior feature distribution and a posterior one. Embedded with the inlier/outlier label, the posterior feature distribution is label-dependent and discriminative. Thus, pushing the prior to be close to the discriminative posterior in the training step enables the features sampled from this prior at test time to model high-quality long-range dependencies. Notably, to achieve effective posterior feature guidance, a specific probabilistic graphical model is designed over our non-local model, which lets us derive a variational low bound as our optimization objective for model training. Finally, we propose a voting-based inlier searching strategy to cluster the high-quality hypothetical inliers for transformation estimation. Extensive experiments on 3DMatch, 3DLoMatch, and KITTI datasets verify the effectiveness of our method.","sentences":["Learning-based outlier (mismatched correspondence) rejection for robust 3D registration generally formulates the outlier removal as an inlier/outlier classification problem.","The core for this to be successful is to learn the discriminative inlier/outlier feature representations.","In this paper, we develop a novel variational non-local network-based outlier rejection framework for robust alignment.","By reformulating the non-local feature learning with variational Bayesian inference, the Bayesian-driven long-range dependencies can be modeled to aggregate discriminative geometric context information for inlier/outlier distinction.","Specifically, to achieve such Bayesian-driven contextual dependencies, each query/key/value component in our non-local network predicts a prior feature distribution and a posterior one.","Embedded with the inlier/outlier label, the posterior feature distribution is label-dependent and discriminative.","Thus, pushing the prior to be close to the discriminative posterior in the training step enables the features sampled from this prior at test time to model high-quality long-range dependencies.","Notably, to achieve effective posterior feature guidance, a specific probabilistic graphical model is designed over our non-local model, which lets us derive a variational low bound as our optimization objective for model training.","Finally, we propose a voting-based inlier searching strategy to cluster the high-quality hypothetical inliers for transformation estimation.","Extensive experiments on 3DMatch, 3DLoMatch, and KITTI datasets verify the effectiveness of our method."],"url":"http://arxiv.org/abs/2304.01514v1"}
{"created":"2023-04-04","title":"Handling Concept Drift in Global Time Series Forecasting","abstract":"Machine learning (ML) based time series forecasting models often require and assume certain degrees of stationarity in the data when producing forecasts. However, in many real-world situations, the data distributions are not stationary and they can change over time while reducing the accuracy of the forecasting models, which in the ML literature is known as concept drift. Handling concept drift in forecasting is essential for many ML methods in use nowadays, however, the prior work only proposes methods to handle concept drift in the classification domain. To fill this gap, we explore concept drift handling methods in particular for Global Forecasting Models (GFM) which recently have gained popularity in the forecasting domain. We propose two new concept drift handling methods, namely: Error Contribution Weighting (ECW) and Gradient Descent Weighting (GDW), based on a continuous adaptive weighting concept. These methods use two forecasting models which are separately trained with the most recent series and all series, and finally, the weighted average of the forecasts provided by the two models are considered as the final forecasts. Using LightGBM as the underlying base learner, in our evaluation on three simulated datasets, the proposed models achieve significantly higher accuracy than a set of statistical benchmarks and LightGBM baselines across four evaluation metrics.","sentences":["Machine learning (ML) based time series forecasting models often require and assume certain degrees of stationarity in the data when producing forecasts.","However, in many real-world situations, the data distributions are not stationary and they can change over time while reducing the accuracy of the forecasting models, which in the ML literature is known as concept drift.","Handling concept drift in forecasting is essential for many ML methods in use nowadays, however, the prior work only proposes methods to handle concept drift in the classification domain.","To fill this gap, we explore concept drift handling methods in particular for Global Forecasting Models (GFM) which recently have gained popularity in the forecasting domain.","We propose two new concept drift handling methods, namely: Error Contribution Weighting (ECW) and Gradient Descent Weighting (GDW), based on a continuous adaptive weighting concept.","These methods use two forecasting models which are separately trained with the most recent series and all series, and finally, the weighted average of the forecasts provided by the two models are considered as the final forecasts.","Using LightGBM as the underlying base learner, in our evaluation on three simulated datasets, the proposed models achieve significantly higher accuracy than a set of statistical benchmarks and LightGBM baselines across four evaluation metrics."],"url":"http://arxiv.org/abs/2304.01512v1"}
{"created":"2023-04-04","title":"EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition","abstract":"Skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios. However, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments. To address this issue, we propose a novel domain generalization method called EPVT, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains. Concretely, EPVT leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset. To facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt. A domain mixup strategy is additionally devised to reduce the co-occurring artifacts in each domain, which allows for more flexible decision margins and mitigates the issue of incorrectly assigned domain labels. Experiments on four out-of-distribution datasets and six different biased ISIC datasets demonstrate the superior generalization ability of EPVT in skin lesion recognition across various environments. Our code and dataset will be released at https://github.com/SiyuanYan1/EPVT.","sentences":["Skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios.","However, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments.","To address this issue, we propose a novel domain generalization method called EPVT, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains.","Concretely, EPVT leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset.","To facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt.","A domain mixup strategy is additionally devised to reduce the co-occurring artifacts in each domain, which allows for more flexible decision margins and mitigates the issue of incorrectly assigned domain labels.","Experiments on four out-of-distribution datasets and six different biased ISIC datasets demonstrate the superior generalization ability of EPVT in skin lesion recognition across various environments.","Our code and dataset will be released at https://github.com/SiyuanYan1/EPVT."],"url":"http://arxiv.org/abs/2304.01508v1"}
{"created":"2023-04-04","title":"SLPerf: a Unified Framework for Benchmarking Split Learning","abstract":"Data privacy concerns has made centralized training of data, which is scattered across silos, infeasible, leading to the need for collaborative learning frameworks. To address that, two prominent frameworks emerged, i.e., federated learning (FL) and split learning (SL). While FL has established various benchmark frameworks and research libraries, SL currently lacks a unified library despite its diversity in terms of label sharing, model aggregation, and cut layer choice. This lack of standardization makes comparing SL paradigms difficult. To address this, we propose SLPerf, a unified research framework and open research library for SL, and conduct extensive experiments on four widely-used datasets under both IID and Non-IID data settings. Our contributions include a comprehensive survey of recently proposed SL paradigms, a detailed benchmark comparison of different SL paradigms in different situations, and rich engineering take-away messages and research insights for improving SL paradigms. SLPerf can facilitate SL algorithm development and fair performance comparisons.","sentences":["Data privacy concerns has made centralized training of data, which is scattered across silos, infeasible, leading to the need for collaborative learning frameworks.","To address that, two prominent frameworks emerged, i.e., federated learning (FL) and split learning (SL).","While FL has established various benchmark frameworks and research libraries, SL currently lacks a unified library despite its diversity in terms of label sharing, model aggregation, and cut layer choice.","This lack of standardization makes comparing SL paradigms difficult.","To address this, we propose SLPerf, a unified research framework and open research library for SL, and conduct extensive experiments on four widely-used datasets under both IID and Non-IID data settings.","Our contributions include a comprehensive survey of recently proposed SL paradigms, a detailed benchmark comparison of different SL paradigms in different situations, and rich engineering take-away messages and research insights for improving SL paradigms.","SLPerf can facilitate SL algorithm development and fair performance comparisons."],"url":"http://arxiv.org/abs/2304.01502v1"}
{"created":"2023-04-04","title":"Algebraic discrete quantum harmonic oscillator with dynamic resolution scaling","abstract":"An algebraic model for the discrete quantum harmonic oscillator (DQHO) is developed by modifying the oscillator algebra to allow for resolution ladder operators in addition to energy ladder operators, enabling dynamic scaling of the resolution in finite degree-of-freedom quantum simulations. The algebraic DQHO has equally-spaced, Kravchuk function energy eigenstates determined by an embedded su(2) algebra, each irreducible representation of which defines a distinct numerical QHO labeled by its resolution and furnishes a structure-preserving discretization of the QHO.","sentences":["An algebraic model for the discrete quantum harmonic oscillator (DQHO) is developed by modifying the oscillator algebra to allow for resolution ladder operators in addition to energy ladder operators, enabling dynamic scaling of the resolution in finite degree-of-freedom quantum simulations.","The algebraic DQHO has equally-spaced, Kravchuk function energy eigenstates determined by an embedded su(2) algebra, each irreducible representation of which defines a distinct numerical QHO labeled by its resolution and furnishes a structure-preserving discretization of the QHO."],"url":"http://arxiv.org/abs/2304.01486v1"}
{"created":"2023-04-04","title":"Mapping Degeneration Meets Label Evolution: Learning Infrared Small Target Detection with Single Point Supervision","abstract":"Training a convolutional neural network (CNN) to detect infrared small targets in a fully supervised manner has gained remarkable research interests in recent years, but is highly labor expensive since a large number of per-pixel annotations are required. To handle this problem, in this paper, we make the first attempt to achieve infrared small target detection with point-level supervision. Interestingly, during the training phase supervised by point labels, we discover that CNNs first learn to segment a cluster of pixels near the targets, and then gradually converge to predict groundtruth point labels. Motivated by this \"mapping degeneration\" phenomenon, we propose a label evolution framework named label evolution with single point supervision (LESPS) to progressively expand the point label by leveraging the intermediate predictions of CNNs. In this way, the network predictions can finally approximate the updated pseudo labels, and a pixel-level target mask can be obtained to train CNNs in an end-to-end manner. We conduct extensive experiments with insightful visualizations to validate the effectiveness of our method. Experimental results show that CNNs equipped with LESPS can well recover the target masks from corresponding point labels, {and can achieve over 70% and 95% of their fully supervised performance in terms of pixel-level intersection over union (IoU) and object-level probability of detection (Pd), respectively. Code is available at https://github.com/XinyiYing/LESPS.","sentences":["Training a convolutional neural network (CNN) to detect infrared small targets in a fully supervised manner has gained remarkable research interests in recent years, but is highly labor expensive since a large number of per-pixel annotations are required.","To handle this problem, in this paper, we make the first attempt to achieve infrared small target detection with point-level supervision.","Interestingly, during the training phase supervised by point labels, we discover that CNNs first learn to segment a cluster of pixels near the targets, and then gradually converge to predict groundtruth point labels.","Motivated by this \"mapping degeneration\" phenomenon, we propose a label evolution framework named label evolution with single point supervision (LESPS) to progressively expand the point label by leveraging the intermediate predictions of CNNs.","In this way, the network predictions can finally approximate the updated pseudo labels, and a pixel-level target mask can be obtained to train CNNs in an end-to-end manner.","We conduct extensive experiments with insightful visualizations to validate the effectiveness of our method.","Experimental results show that CNNs equipped with LESPS can well recover the target masks from corresponding point labels, {and can achieve over 70% and 95% of their fully supervised performance in terms of pixel-level intersection over union (IoU) and object-level probability of detection (Pd), respectively.","Code is available at https://github.com/XinyiYing/LESPS."],"url":"http://arxiv.org/abs/2304.01484v1"}
{"created":"2023-04-04","title":"Entanglement distillation based on polarization and frequency hyperentanglement","abstract":"Entanglement distillation has many applications in quantum information processing and is an important tool for improving the quality and efficiency of quantum communication, cryptography, computing, and simulation. We propose an entanglement distillation scheme using only one pair of polarization-frequency hyperentangled photons, which can be equivalently viewed as containing two pairs of entangled logical qubits: a pair of polarization-entangled qubits and a pair of frequency-entangled qubits. To perform the required CNOT operation between the two qubits we consider the use of a polarization-dependent frequency converter. Compared to past methods of entanglement distillation that relied on polarization and spatial-mode/energy-time degree of freedom, the utilization of frequency-encoded qubits offers an advantage in that it is immune to bit-flip errors when the channel is linear. After distillation, the fidelity of polarization entanglement can be significantly improved by sacrificing the frequency degree of freedom. Through simulation, we show that high fidelity gains, large yield, and high distillation rate can be achieved. Our distillation scheme is simple to implement with current technologies, compatible with existing telecommunication fiber networks, and is a promising approach for achieving efficient quantum communication.","sentences":["Entanglement distillation has many applications in quantum information processing and is an important tool for improving the quality and efficiency of quantum communication, cryptography, computing, and simulation.","We propose an entanglement distillation scheme using only one pair of polarization-frequency hyperentangled photons, which can be equivalently viewed as containing two pairs of entangled logical qubits: a pair of polarization-entangled qubits and a pair of frequency-entangled qubits.","To perform the required CNOT operation between the two qubits we consider the use of a polarization-dependent frequency converter.","Compared to past methods of entanglement distillation that relied on polarization and spatial-mode/energy-time degree of freedom, the utilization of frequency-encoded qubits offers an advantage in that it is immune to bit-flip errors when the channel is linear.","After distillation, the fidelity of polarization entanglement can be significantly improved by sacrificing the frequency degree of freedom.","Through simulation, we show that high fidelity gains, large yield, and high distillation rate can be achieved.","Our distillation scheme is simple to implement with current technologies, compatible with existing telecommunication fiber networks, and is a promising approach for achieving efficient quantum communication."],"url":"http://arxiv.org/abs/2304.01470v1"}
{"created":"2023-04-04","title":"Fabrication of a Monolithic 5-Meter Aluminum Reflector for Millimeter-Wavelength Observations of the Cosmic Microwave Background","abstract":"We have demonstrated the fabrication of a monolithic, 5-meter diameter, aluminum reflector with 17.4 $\\mu$m RMS surface error. The reflector was designed to avoid the problem of pickup due to scattering from panel gaps in a large, millimeter-wavelength telescope that will be used for measurements on the cosmic microwave background.","sentences":["We have demonstrated the fabrication of a monolithic, 5-meter diameter, aluminum reflector with 17.4 $\\mu$m RMS surface error.","The reflector was designed to avoid the problem of pickup due to scattering from panel gaps in a large, millimeter-wavelength telescope that will be used for measurements on the cosmic microwave background."],"url":"http://arxiv.org/abs/2304.01469v1"}
{"created":"2023-04-04","title":"Hierarchical Supervision and Shuffle Data Augmentation for 3D Semi-Supervised Object Detection","abstract":"State-of-the-art 3D object detectors are usually trained on large-scale datasets with high-quality 3D annotations. However, such 3D annotations are often expensive and time-consuming, which may not be practical for real applications. A natural remedy is to adopt semi-supervised learning (SSL) by leveraging a limited amount of labeled samples and abundant unlabeled samples. Current pseudolabeling-based SSL object detection methods mainly adopt a teacher-student framework, with a single fixed threshold strategy to generate supervision signals, which inevitably brings confused supervision when guiding the student network training. Besides, the data augmentation of the point cloud in the typical teacher-student framework is too weak, and only contains basic down sampling and flip-and-shift (i.e., rotate and scaling), which hinders the effective learning of feature information. Hence, we address these issues by introducing a novel approach of Hierarchical Supervision and Shuffle Data Augmentation (HSSDA), which is a simple yet effective teacher-student framework. The teacher network generates more reasonable supervision for the student network by designing a dynamic dual-threshold strategy. Besides, the shuffle data augmentation strategy is designed to strengthen the feature representation ability of the student network. Extensive experiments show that HSSDA consistently outperforms the recent state-of-the-art methods on different datasets. The code will be released at https://github.com/azhuantou/HSSDA.","sentences":["State-of-the-art 3D object detectors are usually trained on large-scale datasets with high-quality 3D annotations.","However, such 3D annotations are often expensive and time-consuming, which may not be practical for real applications.","A natural remedy is to adopt semi-supervised learning (SSL) by leveraging a limited amount of labeled samples and abundant unlabeled samples.","Current pseudolabeling-based SSL object detection methods mainly adopt a teacher-student framework, with a single fixed threshold strategy to generate supervision signals, which inevitably brings confused supervision when guiding the student network training.","Besides, the data augmentation of the point cloud in the typical teacher-student framework is too weak, and only contains basic down sampling and flip-and-shift (i.e., rotate and scaling), which hinders the effective learning of feature information.","Hence, we address these issues by introducing a novel approach of Hierarchical Supervision and Shuffle Data Augmentation (HSSDA), which is a simple yet effective teacher-student framework.","The teacher network generates more reasonable supervision for the student network by designing a dynamic dual-threshold strategy.","Besides, the shuffle data augmentation strategy is designed to strengthen the feature representation ability of the student network.","Extensive experiments show that HSSDA consistently outperforms the recent state-of-the-art methods on different datasets.","The code will be released at https://github.com/azhuantou/HSSDA."],"url":"http://arxiv.org/abs/2304.01464v1"}
{"created":"2023-04-04","title":"Tight Space Lower Bound for Pseudo-Deterministic Approximate Counting","abstract":"We investigate one of the most basic problems in streaming algorithms: approximating the number of elements in the stream. In 1978, Morris famously gave a randomized algorithm achieving a constant-factor approximation error for streams of length at most N in space $O(\\log \\log N)$. We investigate the pseudo-deterministic complexity of the problem and prove a tight $\\Omega(\\log N)$ lower bound, thus resolving a problem of Goldwasser-Grossman-Mohanty-Woodruff.","sentences":["We investigate one of the most basic problems in streaming algorithms: approximating the number of elements in the stream.","In 1978, Morris famously gave a randomized algorithm achieving a constant-factor approximation error for streams of length at most N in space $O(\\log \\log N)$. We investigate the pseudo-deterministic complexity of the problem and prove a tight $\\Omega(\\log N)$ lower bound, thus resolving a problem of Goldwasser-Grossman-Mohanty-Woodruff."],"url":"http://arxiv.org/abs/2304.01438v1"}
{"created":"2023-04-04","title":"Reducing Discretization Error in the Frank-Wolfe Method","abstract":"The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe \\emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.","sentences":["The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity.","However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution.","We view this as an artifact of discretization; that is to say, the Frank-Wolfe \\emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties.","We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$."],"url":"http://arxiv.org/abs/2304.01432v1"}
{"created":"2023-04-04","title":"Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots","abstract":"We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision. It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself. In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots. This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene. Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation. The resulting min-max optimization fosters the separation of objects and their assignment to different attention slots, leading to Divided Attention, or DivA. DivA outperforms recent unsupervised multi-object motion segmentation methods while tripling run-time speed up to 104FPS and reducing the performance gap from supervised methods to 12% or less. DivA can handle different numbers of objects and different image sizes at training and test time, is invariant to permutation of object labels, and does not require explicit regularization.","sentences":["We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision.","It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself.","In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots.","This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene.","Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation.","The resulting min-max optimization fosters the separation of objects and their assignment to different attention slots, leading to Divided Attention, or DivA. DivA outperforms recent unsupervised multi-object motion segmentation methods while tripling run-time speed up to 104FPS and reducing the performance gap from supervised methods to 12% or less.","DivA can handle different numbers of objects and different image sizes at training and test time, is invariant to permutation of object labels, and does not require explicit regularization."],"url":"http://arxiv.org/abs/2304.01430v1"}
{"created":"2023-04-03","title":"Learning with augmented target information: An alternative theory of Feedback Alignment","abstract":"While error backpropagation (BP) has dominated the training of nearly all modern neural networks for a long time, it suffers from several biological plausibility issues such as the symmetric weight requirement and synchronous updates. Feedback Alignment (FA) was proposed as an alternative to BP to address those dilemmas and has been demonstrated to be effective on various tasks and network architectures. Despite its simplicity and effectiveness, a satisfying explanation of how FA works across different architectures is still lacking. Here we propose a novel, architecture-agnostic theory of how FA works through the lens of information theory: Instead of approximating gradients calculated by BP with the same parameter, FA learns effective representations by embedding target information into neural networks to be trained. We show this through the analysis of FA dynamics in idealized settings and then via a series of experiments. Based on the implications of this theory, we designed three variants of FA and show their comparable performance on several tasks. These variants also account for some phenomena and theories in neuroscience such as predictive coding and representational drift.","sentences":["While error backpropagation (BP) has dominated the training of nearly all modern neural networks for a long time, it suffers from several biological plausibility issues such as the symmetric weight requirement and synchronous updates.","Feedback Alignment (FA) was proposed as an alternative to BP to address those dilemmas and has been demonstrated to be effective on various tasks and network architectures.","Despite its simplicity and effectiveness, a satisfying explanation of how FA works across different architectures is still lacking.","Here we propose a novel, architecture-agnostic theory of how FA works through the lens of information theory: Instead of approximating gradients calculated by BP with the same parameter, FA learns effective representations by embedding target information into neural networks to be trained.","We show this through the analysis of FA dynamics in idealized settings and then via a series of experiments.","Based on the implications of this theory, we designed three variants of FA and show their comparable performance on several tasks.","These variants also account for some phenomena and theories in neuroscience such as predictive coding and representational drift."],"url":"http://arxiv.org/abs/2304.01406v1"}
{"created":"2023-04-03","title":"Can listening to more neighbours help CAVs be faster and safer?","abstract":"Connected Autonomous Vehicles (CAVs) are widely expected to improve traffic safety and efficiency by exploiting information from surrounding vehicles via V2V communication. A CAV typically adapts its speed based on information from the vehicle it follows. CAVs can also use information from vehicles further ahead within their communication range, and this results in improved traffic safety and efficiency. In mixed traffic scenarios, however, this may not always be possible due to the presence of human-driven vehicles that do not have communication capabilities. Furthermore, as wireless vehicular networks are unreliable, information from other vehicles can be delayed or lost, which brings more challenges for CAVs in utilizing information from multiple leading vehicles. A few studies have investigated the impact of CAVs where they use information from multiple leading vehicles on traffic safety and efficiency, but only in very limited scenarios (i.e., with a very small number of vehicles).   In contrast, this paper investigates the impact of CAV car-following control based on multiple leading vehicles information on both mixed traffic safety and efficiency in realistic scenarios in terms of imperfect communication, vehicle modelling, and traffic scenario. Results show that exploiting information from multiple, rather than a single, leading vehicles in CAV controller design further improves both traffic safety and efficiency especially at high penetration rates. In addition to proper tuning of CAV controller parameters (control gains and time headways), the scale of the improvement depends on both market penetration rate (MPR) and communication reliability. A packet error rate (PER) of 70% leads to an increase in traffic efficiency by 4.18% (at 40% MPR) and 12.19% (at 70% MPR), compared to the simple single leading vehicle information based controller.","sentences":["Connected Autonomous Vehicles (CAVs) are widely expected to improve traffic safety and efficiency by exploiting information from surrounding vehicles via V2V communication.","A CAV typically adapts its speed based on information from the vehicle it follows.","CAVs can also use information from vehicles further ahead within their communication range, and this results in improved traffic safety and efficiency.","In mixed traffic scenarios, however, this may not always be possible due to the presence of human-driven vehicles that do not have communication capabilities.","Furthermore, as wireless vehicular networks are unreliable, information from other vehicles can be delayed or lost, which brings more challenges for CAVs in utilizing information from multiple leading vehicles.","A few studies have investigated the impact of CAVs where they use information from multiple leading vehicles on traffic safety and efficiency, but only in very limited scenarios (i.e., with a very small number of vehicles).   ","In contrast, this paper investigates the impact of CAV car-following control based on multiple leading vehicles information on both mixed traffic safety and efficiency in realistic scenarios in terms of imperfect communication, vehicle modelling, and traffic scenario.","Results show that exploiting information from multiple, rather than a single, leading vehicles in CAV controller design further improves both traffic safety and efficiency especially at high penetration rates.","In addition to proper tuning of CAV controller parameters (control gains and time headways), the scale of the improvement depends on both market penetration rate (MPR) and communication reliability.","A packet error rate (PER) of 70% leads to an increase in traffic efficiency by 4.18% (at 40% MPR) and 12.19% (at 70% MPR), compared to the simple single leading vehicle information based controller."],"url":"http://arxiv.org/abs/2304.01402v1"}
{"created":"2023-04-03","title":"Connecting Simple and Precise P-values to Complex and Ambiguous Realities","abstract":"Mathematics is a limited component of solutions to real-world problems, as it expresses only what is expected to be true if all our assumptions are correct, including implicit assumptions that are omnipresent and often incorrect. Statistical methods are rife with implicit assumptions whose violation can be life-threatening when results from them are used to set policy. Among them are that there is human equipoise or unbiasedness in data generation, management, analysis, and reporting. These assumptions correspond to levels of cooperation, competence, neutrality, and integrity that are absent more often than we would like to believe.   Given this harsh reality, we should ask what meaning, if any, we can assign to the P-values, 'statistical significance' declarations, 'confidence' intervals, and posterior probabilities that are used to decide what and how to present (or spin) discussions of analyzed data. By themselves, P-values and CI do not test any hypothesis, nor do they measure the significance of results or the confidence we should have in them. The sense otherwise is an ongoing cultural error perpetuated by large segments of the statistical and research community via misleading terminology.   So-called 'inferential' statistics can only become contextually interpretable when derived explicitly from causal stories about the real data generator (such as randomization), and can only become reliable when those stories are based on valid and public documentation of the physical mechanisms that generated the data. Absent these assurances, traditional interpretations of statistical results become pernicious fictions that need to be replaced by far more circumspect descriptions of data and model relations.","sentences":["Mathematics is a limited component of solutions to real-world problems, as it expresses only what is expected to be true if all our assumptions are correct, including implicit assumptions that are omnipresent and often incorrect.","Statistical methods are rife with implicit assumptions whose violation can be life-threatening when results from them are used to set policy.","Among them are that there is human equipoise or unbiasedness in data generation, management, analysis, and reporting.","These assumptions correspond to levels of cooperation, competence, neutrality, and integrity that are absent more often than we would like to believe.   ","Given this harsh reality, we should ask what meaning, if any, we can assign to the P-values, 'statistical significance' declarations, 'confidence' intervals, and posterior probabilities that are used to decide what and how to present (or spin) discussions of analyzed data.","By themselves, P-values and CI do not test any hypothesis, nor do they measure the significance of results or the confidence we should have in them.","The sense otherwise is an ongoing cultural error perpetuated by large segments of the statistical and research community via misleading terminology.   ","So-called 'inferential' statistics can only become contextually interpretable when derived explicitly from causal stories about the real data generator (such as randomization), and can only become reliable when those stories are based on valid and public documentation of the physical mechanisms that generated the data.","Absent these assurances, traditional interpretations of statistical results become pernicious fictions that need to be replaced by far more circumspect descriptions of data and model relations."],"url":"http://arxiv.org/abs/2304.01392v1"}
{"created":"2023-04-03","title":"Surveying the Giant HII Regions of the Milky Way with SOFIA: V. DR7 and K3-50","abstract":"We present our fifth set of results from our mid-infrared imaging survey of Milky Way Giant HII (GHII) regions with our detailed analysis of DR7 and K3-50. We obtained 20/25 and 37um imaging maps of both regions using the FORCAST instrument on the Stratospheric Observatory For Infrared Astronomy (SOFIA). We investigate the multi-scale properties of DR7 and K3-50 using our data in conjunction with previous multi-wavelength observations. Near to far-infrared spectral energy distributions of individual compact infrared sources were constructed and fitted with massive young stellar object (MYSO) models. We find eight out of the ten (80%) compact sources in K3-50 and three out of the four (75%) sources in DR7 are likely to be MYSOs. We derived luminosity-to-mass ratios of the extended radio sub-regions of DR7 and K3-50 to estimate their relative ages. The large spread in evolutionary state for the sub-regions in K3-50 likely indicates that the star-forming complex has undergone multiple star-forming events separated more widely in time, whereas the smaller spread in DR7 likely indicates the star formation sub-regions are more co-eval. DR7 and K3-50 have Lyman continuum photon rates just above the formal threshold criterion for being categorized as a GHII region (10^50 photons/s) but with large enough errors that this classification is uncertain. By measuring other observational characteristics in the infrared, we find that K3-50 has properties more akin to previous bona fide GHII regions we have studied, whereas DR7 has values more like those of the non-GHII regions we have previously studied.","sentences":["We present our fifth set of results from our mid-infrared imaging survey of Milky Way Giant HII (GHII) regions with our detailed analysis of DR7 and K3-50.","We obtained 20/25 and 37um imaging maps of both regions using the FORCAST instrument on the Stratospheric Observatory For Infrared Astronomy (SOFIA).","We investigate the multi-scale properties of DR7 and K3-50 using our data in conjunction with previous multi-wavelength observations.","Near to far-infrared spectral energy distributions of individual compact infrared sources were constructed and fitted with massive young stellar object (MYSO) models.","We find eight out of the ten (80%) compact sources in K3-50 and three out of the four (75%) sources in DR7 are likely to be MYSOs.","We derived luminosity-to-mass ratios of the extended radio sub-regions of DR7 and K3-50 to estimate their relative ages.","The large spread in evolutionary state for the sub-regions in K3-50 likely indicates that the star-forming complex has undergone multiple star-forming events separated more widely in time, whereas the smaller spread in DR7 likely indicates the star formation sub-regions are more co-eval.","DR7 and K3-50 have Lyman continuum photon rates just above the formal threshold criterion for being categorized as a GHII region (10^50 photons/s) but with large enough errors that this classification is uncertain.","By measuring other observational characteristics in the infrared, we find that K3-50 has properties more akin to previous bona fide GHII regions we have studied, whereas DR7 has values more like those of the non-GHII regions we have previously studied."],"url":"http://arxiv.org/abs/2304.01390v1"}
{"created":"2023-04-03","title":"End-to-End Models for Chemical-Protein Interaction Extraction: Better Tokenization and Span-Based Pipeline Strategies","abstract":"End-to-end relation extraction (E2ERE) is an important task in information extraction, more so for biomedicine as scientific literature continues to grow exponentially. E2ERE typically involves identifying entities (or named entity recognition (NER)) and associated relations, while most RE tasks simply assume that the entities are provided upfront and end up performing relation classification. E2ERE is inherently more difficult than RE alone given the potential snowball effect of errors from NER leading to more errors in RE. A complex dataset in biomedical E2ERE is the ChemProt dataset (BioCreative VI, 2017) that identifies relations between chemical compounds and genes/proteins in scientific literature. ChemProt is included in all recent biomedical natural language processing benchmarks including BLUE, BLURB, and BigBio. However, its treatment in these benchmarks and in other separate efforts is typically not end-to-end, with few exceptions. In this effort, we employ a span-based pipeline approach to produce a new state-of-the-art E2ERE performance on the ChemProt dataset, resulting in $> 4\\%$ improvement in F1-score over the prior best effort. Our results indicate that a straightforward fine-grained tokenization scheme helps span-based approaches excel in E2ERE, especially with regards to handling complex named entities. Our error analysis also identifies a few key failure modes in E2ERE for ChemProt.","sentences":["End-to-end relation extraction (E2ERE) is an important task in information extraction, more so for biomedicine as scientific literature continues to grow exponentially.","E2ERE typically involves identifying entities (or named entity recognition (NER)) and associated relations, while most RE tasks simply assume that the entities are provided upfront and end up performing relation classification.","E2ERE is inherently more difficult than RE alone given the potential snowball effect of errors from NER leading to more errors in RE.","A complex dataset in biomedical E2ERE is the ChemProt dataset (BioCreative VI, 2017) that identifies relations between chemical compounds and genes/proteins in scientific literature.","ChemProt is included in all recent biomedical natural language processing benchmarks including BLUE, BLURB, and BigBio.","However, its treatment in these benchmarks and in other separate efforts is typically not end-to-end, with few exceptions.","In this effort, we employ a span-based pipeline approach to produce a new state-of-the-art E2ERE performance on the ChemProt dataset, resulting in $> 4\\%$ improvement in F1-score over the prior best effort.","Our results indicate that a straightforward fine-grained tokenization scheme helps span-based approaches excel in E2ERE, especially with regards to handling complex named entities.","Our error analysis also identifies a few key failure modes in E2ERE for ChemProt."],"url":"http://arxiv.org/abs/2304.01344v1"}
{"created":"2023-04-03","title":"A Scale-Invariant Trajectory Simplification Method for Efficient Data Collection in Videos","abstract":"Training data is a critical requirement for machine learning tasks, and labeled training data can be expensive to acquire, often requiring manual or semi-automated data collection pipelines. For tracking applications, the data collection involves drawing bounding boxes around the classes of interest on each frame, and associate detections of the same \"instance\" over frames. In a semi-automated data collection pipeline, this can be achieved by running a baseline detection and tracking algorithm, and relying on manual correction to add/remove/change bounding boxes on each frame, as well as resolving errors in the associations over frames (track switches). In this paper, we propose a data correction pipeline to generate ground-truth data more efficiently in this semi-automated scenario. Our method simplifies the trajectories from the tracking systems and let the annotator verify and correct the objects in the sampled keyframes. Once the objects in the keyframes are corrected, the bounding boxes in the other frames are obtained by interpolation. Our method achieves substantial reduction in the number of frames requiring manual correction. In the MOT dataset, it reduces the number of frames by 30x while maintaining a HOTA score of 89.61% . Moreover, it reduces the number of frames by a factor of 10x while achieving a HOTA score of 79.24% in the SoccerNet dataset, and 85.79% in the DanceTrack dataset. The project code and data are publicly released at https://github.com/foreverYoungGitHub/trajectory-simplify-benchmark.","sentences":["Training data is a critical requirement for machine learning tasks, and labeled training data can be expensive to acquire, often requiring manual or semi-automated data collection pipelines.","For tracking applications, the data collection involves drawing bounding boxes around the classes of interest on each frame, and associate detections of the same \"instance\" over frames.","In a semi-automated data collection pipeline, this can be achieved by running a baseline detection and tracking algorithm, and relying on manual correction to add/remove/change bounding boxes on each frame, as well as resolving errors in the associations over frames (track switches).","In this paper, we propose a data correction pipeline to generate ground-truth data more efficiently in this semi-automated scenario.","Our method simplifies the trajectories from the tracking systems and let the annotator verify and correct the objects in the sampled keyframes.","Once the objects in the keyframes are corrected, the bounding boxes in the other frames are obtained by interpolation.","Our method achieves substantial reduction in the number of frames requiring manual correction.","In the MOT dataset, it reduces the number of frames by 30x while maintaining a HOTA score of 89.61% .","Moreover, it reduces the number of frames by a factor of 10x while achieving a HOTA score of 79.24% in the SoccerNet dataset, and 85.79% in the DanceTrack dataset.","The project code and data are publicly released at https://github.com/foreverYoungGitHub/trajectory-simplify-benchmark."],"url":"http://arxiv.org/abs/2304.01340v1"}
{"created":"2023-04-03","title":"Clustering Social Touch Gestures for Human-Robot Interaction","abstract":"Social touch provides a rich non-verbal communication channel between humans and robots. Prior work has identified a set of touch gestures for human-robot interaction and described them with natural language labels (e.g., stroking, patting). Yet, no data exists on the semantic relationships between the touch gestures in users' minds. To endow robots with touch intelligence, we investigated how people perceive the similarities of social touch labels from the literature. In an online study, 45 participants grouped 36 social touch labels based on their perceived similarities and annotated their groupings with descriptive names. We derived quantitative similarities of the gestures from these groupings and analyzed the similarities using hierarchical clustering. The analysis resulted in 9 clusters of touch gestures formed around the social, emotional, and contact characteristics of the gestures. We discuss the implications of our results for designing and evaluating touch sensing and interactions with social robots.","sentences":["Social touch provides a rich non-verbal communication channel between humans and robots.","Prior work has identified a set of touch gestures for human-robot interaction and described them with natural language labels (e.g., stroking, patting).","Yet, no data exists on the semantic relationships between the touch gestures in users' minds.","To endow robots with touch intelligence, we investigated how people perceive the similarities of social touch labels from the literature.","In an online study, 45 participants grouped 36 social touch labels based on their perceived similarities and annotated their groupings with descriptive names.","We derived quantitative similarities of the gestures from these groupings and analyzed the similarities using hierarchical clustering.","The analysis resulted in 9 clusters of touch gestures formed around the social, emotional, and contact characteristics of the gestures.","We discuss the implications of our results for designing and evaluating touch sensing and interactions with social robots."],"url":"http://arxiv.org/abs/2304.01334v1"}
{"created":"2023-04-03","title":"Kernel Affine Hull Machines for Differentially Private Learning","abstract":"This paper explores the use of affine hulls of points as a means of representing data via learning in Reproducing Kernel Hilbert Spaces (RKHS), with the goal of partitioning the data space into geometric bodies that conceal privacy-sensitive information about individual data points, while preserving the structure of the original learning problem. To this end, we introduce the Kernel Affine Hull Machine (KAHM), which provides an effective way of computing a distance measure from the resulting bounded geometric body. KAHM is a critical building block in wide and deep autoencoders, which enable data representation learning for classification applications. To ensure privacy-preserving learning, we propose a novel method for generating fabricated data, which involves smoothing differentially private data samples through a transformation process. The resulting fabricated data guarantees not only differential privacy but also ensures that the KAHM modeling error is not larger than that of the original training data samples. We also address the accuracy-loss issue that arises with differentially private classifiers by using fabricated data. This approach results in a significant reduction in the risk of membership inference attacks while incurring only a marginal loss of accuracy. As an application, a KAHM based differentially private federated learning scheme is introduced featuring that the evaluation of global classifier requires only locally computed distance measures. Overall, our findings demonstrate the potential of KAHM as effective tool for privacy-preserving learning and classification.","sentences":["This paper explores the use of affine hulls of points as a means of representing data via learning in Reproducing Kernel Hilbert Spaces (RKHS), with the goal of partitioning the data space into geometric bodies that conceal privacy-sensitive information about individual data points, while preserving the structure of the original learning problem.","To this end, we introduce the Kernel Affine Hull Machine (KAHM), which provides an effective way of computing a distance measure from the resulting bounded geometric body.","KAHM is a critical building block in wide and deep autoencoders, which enable data representation learning for classification applications.","To ensure privacy-preserving learning, we propose a novel method for generating fabricated data, which involves smoothing differentially private data samples through a transformation process.","The resulting fabricated data guarantees not only differential privacy but also ensures that the KAHM modeling error is not larger than that of the original training data samples.","We also address the accuracy-loss issue that arises with differentially private classifiers by using fabricated data.","This approach results in a significant reduction in the risk of membership inference attacks while incurring only a marginal loss of accuracy.","As an application, a KAHM based differentially private federated learning scheme is introduced featuring that the evaluation of global classifier requires only locally computed distance measures.","Overall, our findings demonstrate the potential of KAHM as effective tool for privacy-preserving learning and classification."],"url":"http://arxiv.org/abs/2304.01300v1"}
{"created":"2023-04-03","title":"Non-Generative Energy Based Models","abstract":"Energy-based models (EBM) have become increasingly popular within computer vision. EBMs bring a probabilistic approach to training deep neural networks (DNN) and have been shown to enhance performance in areas such as calibration, out-of-distribution detection, and adversarial resistance. However, these advantages come at the cost of estimating input data probabilities, usually using a Langevin based method such as Stochastic Gradient Langevin Dynamics (SGLD), which bring additional computational costs, require parameterization, caching methods for efficiency, and can run into stability and scaling issues. EBMs use dynamical methods to draw samples from the probability density function (PDF) defined by the current state of the network and compare them to the training data using a maximum log likelihood approach to learn the correct PDF.   We propose a non-generative training approach, Non-Generative EBM (NG-EBM), that utilizes the {\\it{Approximate Mass}}, identified by Grathwohl et al., as a loss term to direct the training. We show that our NG-EBM training strategy retains many of the benefits of EBM in calibration, out-of-distribution detection, and adversarial resistance, but without the computational complexity and overhead of the traditional approaches. In particular, the NG-EBM approach improves the Expected Calibration Error by a factor of 2.5 for CIFAR10 and 7.5 times for CIFAR100, when compared to traditionally trained models.","sentences":["Energy-based models (EBM) have become increasingly popular within computer vision.","EBMs bring a probabilistic approach to training deep neural networks (DNN) and have been shown to enhance performance in areas such as calibration, out-of-distribution detection, and adversarial resistance.","However, these advantages come at the cost of estimating input data probabilities, usually using a Langevin based method such as Stochastic Gradient Langevin Dynamics (SGLD), which bring additional computational costs, require parameterization, caching methods for efficiency, and can run into stability and scaling issues.","EBMs use dynamical methods to draw samples from the probability density function (PDF) defined by the current state of the network and compare them to the training data using a maximum log likelihood approach to learn the correct PDF.   ","We propose a non-generative training approach, Non-Generative EBM (NG-EBM), that utilizes the {\\it{Approximate Mass}}, identified by Grathwohl et al., as a loss term to direct the training.","We show that our NG-EBM training strategy retains many of the benefits of EBM in calibration, out-of-distribution detection, and adversarial resistance, but without the computational complexity and overhead of the traditional approaches.","In particular, the NG-EBM approach improves the Expected Calibration Error by a factor of 2.5 for CIFAR10 and 7.5 times for CIFAR100, when compared to traditionally trained models."],"url":"http://arxiv.org/abs/2304.01297v1"}
{"created":"2023-04-03","title":"Asymptotic expansions for the maximum likelihood estimation errors of the rotating parameter of the gravitational wave from core-collapse supernovae","abstract":"In this work, we obtain the error estimate of the rotation parameter $\\beta$ from the core bounce phase of the characteristic gravitational wave signal of a rapidly rotating core collapse supernova (CCSN). We quantify the error with asymptotic expansions of the covariance of a Maximum Likelihood Estimator (MLE) in terms of inverse powers of Signal-Noise Ratio (SNR), this method has been previously applied to parameter estimation for compact binary coalescences. When the second order of this expansion is negligible, it indicates that the first order is a good approximation of the error that will have a matching filter approach when estimating $\\beta$. The analysis indicates that we should be able to resolve the presence of rotation for the galactic and nearby extragalactic progenitors. We show that the estimation error $\\Delta \\beta$ can be as small as a few percent and is larger for small values of $\\beta$.","sentences":["In this work, we obtain the error estimate of the rotation parameter $\\beta$ from the core bounce phase of the characteristic gravitational wave signal of a rapidly rotating core collapse supernova (CCSN).","We quantify the error with asymptotic expansions of the covariance of a Maximum Likelihood Estimator (MLE) in terms of inverse powers of Signal-Noise Ratio (SNR), this method has been previously applied to parameter estimation for compact binary coalescences.","When the second order of this expansion is negligible, it indicates that the first order is a good approximation of the error that will have a matching filter approach when estimating $\\beta$. The analysis indicates that we should be able to resolve the presence of rotation for the galactic and nearby extragalactic progenitors.","We show that the estimation error $\\Delta \\beta$ can be as small as a few percent and is larger for small values of $\\beta$."],"url":"http://arxiv.org/abs/2304.01267v1"}
{"created":"2023-04-06","title":"$\\text{DC}^2$: Dual-Camera Defocus Control by Learning to Refocus","abstract":"Smartphone cameras today are increasingly approaching the versatility and quality of professional cameras through a combination of hardware and software advancements. However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images. At the same time, many smartphones now have multiple cameras with different fixed apertures -- specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF. In this work, we propose $\\text{DC}^2$, a system for defocus control for synthetically varying camera aperture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system. Our key insight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to control defocus. Quantitative and qualitative evaluations on real-world data demonstrate our system's efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus. Finally, we demonstrate creative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects.","sentences":["Smartphone cameras today are increasingly approaching the versatility and quality of professional cameras through a combination of hardware and software advancements.","However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images.","At the same time, many smartphones now have multiple cameras with different fixed apertures -- specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF.","In this work, we propose $\\text{DC}^2$, a system for defocus control for synthetically varying camera aperture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system.","Our key insight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to control defocus.","Quantitative and qualitative evaluations on real-world data demonstrate our system's efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus.","Finally, we demonstrate creative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects."],"url":"http://arxiv.org/abs/2304.03285v1"}
{"created":"2023-04-06","title":"SegGPT: Segmenting Everything In Context","abstract":"We present SegGPT, a generalist model for segmenting everything in context. We unify various segmentation tasks into a generalist in-context learning framework that accommodates different kinds of segmentation data by transforming them into the same format of images. The training of SegGPT is formulated as an in-context coloring problem with random color mapping for each data sample. The objective is to accomplish diverse tasks according to the context, rather than relying on specific colors. After training, SegGPT can perform arbitrary segmentation tasks in images or videos via in-context inference, such as object instance, stuff, part, contour, and text. SegGPT is evaluated on a broad range of tasks, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation. Our results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively.","sentences":["We present SegGPT, a generalist model for segmenting everything in context.","We unify various segmentation tasks into a generalist in-context learning framework that accommodates different kinds of segmentation data by transforming them into the same format of images.","The training of SegGPT is formulated as an in-context coloring problem with random color mapping for each data sample.","The objective is to accomplish diverse tasks according to the context, rather than relying on specific colors.","After training, SegGPT can perform arbitrary segmentation tasks in images or videos via in-context inference, such as object instance, stuff, part, contour, and text.","SegGPT is evaluated on a broad range of tasks, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation.","Our results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively."],"url":"http://arxiv.org/abs/2304.03284v1"}
{"created":"2023-04-06","title":"Diffusion Models as Masked Autoencoders","abstract":"There has been a longstanding belief that generation can facilitate a true understanding of visual data. In line with this, we revisit generatively pre-training visual representations in light of recent interest in denoising diffusion models. While directly pre-training with diffusion models does not produce strong representations, we condition diffusion models on masked input and formulate diffusion models as masked autoencoders (DiffMAE). Our approach is capable of (i) serving as a strong initialization for downstream recognition tasks, (ii) conducting high-quality image inpainting, and (iii) being effortlessly extended to video where it produces state-of-the-art classification accuracy. We further perform a comprehensive study on the pros and cons of design choices and build connections between diffusion models and masked autoencoders.","sentences":["There has been a longstanding belief that generation can facilitate a true understanding of visual data.","In line with this, we revisit generatively pre-training visual representations in light of recent interest in denoising diffusion models.","While directly pre-training with diffusion models does not produce strong representations, we condition diffusion models on masked input and formulate diffusion models as masked autoencoders (DiffMAE).","Our approach is capable of (i) serving as a strong initialization for downstream recognition tasks, (ii) conducting high-quality image inpainting, and (iii) being effortlessly extended to video where it produces state-of-the-art classification accuracy.","We further perform a comprehensive study on the pros and cons of design choices and build connections between diffusion models and masked autoencoders."],"url":"http://arxiv.org/abs/2304.03283v1"}
{"created":"2023-04-06","title":"How Do US Congress Members Advertise Climate Change: An Analysis Of Ads Run On Meta's Platforms","abstract":"Ensuring transparency and integrity in political communication on climate change has arguably never been more important than today. Yet we know little about how politicians focus on, talk about, and portray climate change on social media. Here we study it from the perspective of political advertisement. We use Meta's Ad Library to collect 602,546 ads that have been issued by US Congress members since mid-2018. Out of those only 19,176 (3.2%) are climate-related. Analyzing this data, we find that Democrats focus substantially more on climate change than Republicans, with 99.7% of all climate-related ads stemming from Democratic politicians. In particular, we find this is driven by a small core of Democratic politicians, where 72% of all impressions can be attributed to 10 politicians. Interestingly, we find a significant difference in the average amount of impressions generated per dollar spent between the two parties. Republicans generate on average 188% more impressions with their climate ads for the same money spent as Democrats. We build models to explain the differences and find that demographic factors only partially explain the variance. Our results demonstrate differences of climate-related advertisements of US congress members and reveal differences in advertising characteristics between the two political parties. We anticipate our work to be a starting point for further studies about climate-related ads on Meta's platforms.","sentences":["Ensuring transparency and integrity in political communication on climate change has arguably never been more important than today.","Yet we know little about how politicians focus on, talk about, and portray climate change on social media.","Here we study it from the perspective of political advertisement.","We use Meta's Ad Library to collect 602,546 ads that have been issued by US Congress members since mid-2018.","Out of those only 19,176 (3.2%) are climate-related.","Analyzing this data, we find that Democrats focus substantially more on climate change than Republicans, with 99.7% of all climate-related ads stemming from Democratic politicians.","In particular, we find this is driven by a small core of Democratic politicians, where 72% of all impressions can be attributed to 10 politicians.","Interestingly, we find a significant difference in the average amount of impressions generated per dollar spent between the two parties.","Republicans generate on average 188% more impressions with their climate ads for the same money spent as Democrats.","We build models to explain the differences and find that demographic factors only partially explain the variance.","Our results demonstrate differences of climate-related advertisements of US congress members and reveal differences in advertising characteristics between the two political parties.","We anticipate our work to be a starting point for further studies about climate-related ads on Meta's platforms."],"url":"http://arxiv.org/abs/2304.03278v1"}
{"created":"2023-04-06","title":"Instruction Tuning with GPT-4","abstract":"Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.","sentences":["Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed.","In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning.","Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models.","We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training.","We make our data generated using GPT-4 as well as our codebase publicly available."],"url":"http://arxiv.org/abs/2304.03277v1"}
{"created":"2023-04-06","title":"That's What I Said: Fully-Controllable Talking Face Generation","abstract":"The goal of this paper is to synthesise talking faces with controllable facial motions. To achieve this goal, we propose two key ideas. The first is to establish a canonical space where every face has the same motion patterns but different identities. The second is to navigate a multimodal motion space that only represents motion-related features while eliminating identity information. To disentangle identity and motion, we introduce an orthogonality constraint between the two different latent spaces. From this, our method can generate natural-looking talking faces with fully controllable facial attributes and accurate lip synchronisation. Extensive experiments demonstrate that our method achieves state-of-the-art results in terms of both visual quality and lip-sync score. To the best of our knowledge, we are the first to develop a talking face generation framework that can accurately manifest full target facial motions including lip, head pose, and eye movements in the generated video without any additional supervision beyond RGB video with audio.","sentences":["The goal of this paper is to synthesise talking faces with controllable facial motions.","To achieve this goal, we propose two key ideas.","The first is to establish a canonical space where every face has the same motion patterns but different identities.","The second is to navigate a multimodal motion space that only represents motion-related features while eliminating identity information.","To disentangle identity and motion, we introduce an orthogonality constraint between the two different latent spaces.","From this, our method can generate natural-looking talking faces with fully controllable facial attributes and accurate lip synchronisation.","Extensive experiments demonstrate that our method achieves state-of-the-art results in terms of both visual quality and lip-sync score.","To the best of our knowledge, we are the first to develop a talking face generation framework that can accurately manifest full target facial motions including lip, head pose, and eye movements in the generated video without any additional supervision beyond RGB video with audio."],"url":"http://arxiv.org/abs/2304.03275v1"}
{"created":"2023-04-06","title":"Towards self-driving laboratories in chemistry and materials sciences: The central role of DFT in the era of AI","abstract":"Density functional theory plays a pivotal role for the chemical and materials science due to its relatively high predictive power, applicability, versatility and low computational cost. We review recent progress in machine learning model developments, which has relied heavily on density functional theory for synthetic data generation and model architecture, and provide some broader context for its general relevance to the chemical sciences. Resulting in models with high efficiency, accuracy, scalability, and transferability (EAST), these developments will pave the way for the routine use of successful experimental planning software within self-driving laboratories.","sentences":["Density functional theory plays a pivotal role for the chemical and materials science due to its relatively high predictive power, applicability, versatility and low computational cost.","We review recent progress in machine learning model developments, which has relied heavily on density functional theory for synthetic data generation and model architecture, and provide some broader context for its general relevance to the chemical sciences.","Resulting in models with high efficiency, accuracy, scalability, and transferability (EAST), these developments will pave the way for the routine use of successful experimental planning software within self-driving laboratories."],"url":"http://arxiv.org/abs/2304.03272v1"}
{"created":"2023-04-06","title":"Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models","abstract":"The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny. Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar. For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret. This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures. To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own water footprint. In this paper, we provide a principled methodology to estimate fine-grained water footprint of AI models, and also discuss the unique spatial-temporal diversities of AI models' runtime water efficiency. Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to enable truly sustainable AI.","sentences":["The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny.","Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar.","For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret.","This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures.","To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own water footprint.","In this paper, we provide a principled methodology to estimate fine-grained water footprint of AI models, and also discuss the unique spatial-temporal diversities of AI models' runtime water efficiency.","Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to enable truly sustainable AI."],"url":"http://arxiv.org/abs/2304.03271v1"}
{"created":"2023-04-06","title":"Causal Discovery with Score Matching on Additive Models with Arbitrary Noise","abstract":"Causal discovery methods are intrinsically constrained by the set of assumptions needed to ensure structure identifiability. Moreover additional restrictions are often imposed in order to simplify the inference task: this is the case for the Gaussian noise assumption on additive non-linear models, which is common to many causal discovery approaches. In this paper we show the shortcomings of inference under this hypothesis, analyzing the risk of edge inversion under violation of Gaussianity of the noise terms. Then, we propose a novel method for inferring the topological ordering of the variables in the causal graph, from data generated according to an additive non-linear model with a generic noise distribution. This leads to NoGAM (Not only Gaussian Additive noise Models), a causal discovery algorithm with a minimal set of assumptions and state of the art performance, experimentally benchmarked on synthetic data.","sentences":["Causal discovery methods are intrinsically constrained by the set of assumptions needed to ensure structure identifiability.","Moreover additional restrictions are often imposed in order to simplify the inference task: this is the case for the Gaussian noise assumption on additive non-linear models, which is common to many causal discovery approaches.","In this paper we show the shortcomings of inference under this hypothesis, analyzing the risk of edge inversion under violation of Gaussianity of the noise terms.","Then, we propose a novel method for inferring the topological ordering of the variables in the causal graph, from data generated according to an additive non-linear model with a generic noise distribution.","This leads to NoGAM (Not only Gaussian Additive noise Models), a causal discovery algorithm with a minimal set of assumptions and state of the art performance, experimentally benchmarked on synthetic data."],"url":"http://arxiv.org/abs/2304.03265v1"}
{"created":"2023-04-06","title":"Parsimonious Identification of Continuous-Time Systems: A Block-Coordinate Descent Approach","abstract":"The identification of electrical, mechanical, and biological systems using data can benefit greatly from prior knowledge extracted from physical modeling. Parametric continuous-time identification methods can naturally incorporate this knowledge, which leads to interpretable and parsimonious models. However, some applications lead to model structures that lack parsimonious descriptions using unfactored transfer functions, which are commonly used in standard direct approaches for continuous-time system identification. In this paper we characterize this parsimony problem, and develop a block-coordinate descent algorithm that delivers parsimonious models by sequentially estimating an additive decomposition of the transfer function of interest. Numerical simulations show the efficacy of the proposed approach.","sentences":["The identification of electrical, mechanical, and biological systems using data can benefit greatly from prior knowledge extracted from physical modeling.","Parametric continuous-time identification methods can naturally incorporate this knowledge, which leads to interpretable and parsimonious models.","However, some applications lead to model structures that lack parsimonious descriptions using unfactored transfer functions, which are commonly used in standard direct approaches for continuous-time system identification.","In this paper we characterize this parsimony problem, and develop a block-coordinate descent algorithm that delivers parsimonious models by sequentially estimating an additive decomposition of the transfer function of interest.","Numerical simulations show the efficacy of the proposed approach."],"url":"http://arxiv.org/abs/2304.03259v1"}
{"created":"2023-04-06","title":"Introducing the Texas Euclid Survey for Lyman Alpha (TESLA) Survey: Initial Study Correlating Galaxy Properties to Lyman-Alpha Emission","abstract":"We present the Texas Euclid Survey for Lyman-Alpha (TESLA), a spectroscopic survey in the 10 square degree of the Euclid North Ecliptic Pole (NEP) field. Using TESLA, we study how the physical properties of Lyman-alpha emitters (LAEs) correlate with Lyman-alpha emission to understand the escape of Lyman alpha from galaxies at redshifts 2 -- 3.5. We present an analysis of 43 LAEs performed in the NEP field using early data from the TESLA survey. We use Subaru Hyper Suprime-Cam imaging in the grizy-bands, Spitzer/IRAC channels 1 and 2 from the Hawaii 20 square degree (H20) survey and spectra acquired by the Visible Integral-Field Replicable Unit Spectrograph (VIRUS) on the Hobby-Eberly Telescope. We perform spectral energy distribution (SED) fitting to compute the galaxy properties of 43 LAEs, and study correlations between stellar mass, star formation rate (SFR), and dust, to the Lyman-alpha rest-frame equivalent widths (EW). We uncover marginal (1 sigma significance) correlations between stellar mass and Lyman-alpha EW, and star formation rate (SFR) and Lyman-alpha EW, with a Spearman correlation coefficient of -0.$34_{-.14}^{+.17}$ and -0.$37_{-.14}^{+.16}$ respectively. We show that the Lyman-alpha distribution of the 43 LAEs is consistent with being drawn from an exponential distribution with an e-folding scale of 150 Angstrom. Once complete the TESLA survey will enable the study of ~ thousands of LAEs to explore correlations between galaxy properties and Lyman-alpha EW. The large sample size will allow the construction of a predictive model for the Lyman-alpha EW as a function of SED-derived galaxy properties, which could be used to improve Lyman-alpha based constraints on reionization.","sentences":["We present the Texas Euclid Survey for Lyman-Alpha (TESLA), a spectroscopic survey in the 10 square degree of the Euclid North Ecliptic Pole (NEP) field.","Using TESLA, we study how the physical properties of Lyman-alpha emitters (LAEs) correlate with Lyman-alpha emission to understand the escape of Lyman alpha from galaxies at redshifts 2 -- 3.5.","We present an analysis of 43 LAEs performed in the NEP field using early data from the TESLA survey.","We use Subaru Hyper Suprime-Cam imaging in the grizy-bands, Spitzer/IRAC channels 1 and 2 from the Hawaii 20 square degree (H20) survey and spectra acquired by the Visible Integral-Field Replicable Unit Spectrograph (VIRUS) on the Hobby-Eberly Telescope.","We perform spectral energy distribution (SED) fitting to compute the galaxy properties of 43 LAEs, and study correlations between stellar mass, star formation rate (SFR), and dust, to the Lyman-alpha rest-frame equivalent widths (EW).","We uncover marginal (1 sigma significance) correlations between stellar mass and Lyman-alpha EW, and star formation rate (SFR) and Lyman-alpha EW, with a Spearman correlation coefficient of -0.$34_{-.14}^{+.17}$ and -0.$37_{-.14}^{+.16}$","respectively.","We show that the Lyman-alpha distribution of the 43 LAEs is consistent with being drawn from an exponential distribution with an e-folding scale of 150 Angstrom.","Once complete the TESLA survey will enable the study of ~ thousands of LAEs to explore correlations between galaxy properties and Lyman-alpha EW.","The large sample size will allow the construction of a predictive model for the Lyman-alpha EW as a function of SED-derived galaxy properties, which could be used to improve Lyman-alpha based constraints on reionization."],"url":"http://arxiv.org/abs/2304.03258v1"}
{"created":"2023-04-06","title":"SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation","abstract":"Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains. This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions. This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation. To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data. As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data. This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques. Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios.","sentences":["Learning models on one labeled dataset that generalize well on another domain is a difficult task, as several shifts might happen between the data domains.","This is notably the case for lidar data, for which models can exhibit large performance discrepancies due for instance to different lidar patterns or changes in acquisition conditions.","This paper addresses the corresponding Unsupervised Domain Adaptation (UDA) task for semantic segmentation.","To mitigate this problem, we introduce an unsupervised auxiliary task of learning an implicit underlying surface representation simultaneously on source and target data.","As both domains share the same latent representation, the model is forced to accommodate discrepancies between the two sources of data.","This novel strategy differs from classical minimization of statistical divergences or lidar-specific state-of-the-art domain adaptation techniques.","Our experiments demonstrate that our method achieves a better performance than the current state of the art in synthetic-to-real and real-to-real scenarios."],"url":"http://arxiv.org/abs/2304.03251v1"}
{"created":"2023-04-06","title":"Age-Aware Gossiping in Network Topologies","abstract":"We consider a fully-connected wireless gossip network which consists of a source and $n$ receiver nodes. The source updates itself with a Poisson process and also sends updates to the nodes as Poisson arrivals. Upon receiving the updates, the nodes update their knowledge about the source. The nodes gossip the data among themselves in the form of Poisson arrivals to disperse their knowledge about the source. The total gossiping rate is bounded by a constraint. The goal of the network is to be as timely as possible with the source. We propose a scheme which we coin \\emph{age sense updating multiple access in networks (ASUMAN)}, which is a distributed opportunistic gossiping scheme, where after each time the source updates itself, each node waits for a time proportional to its current age and broadcasts a signal to the other nodes of the network. This allows the nodes in the network which have higher age to remain silent and only the low-age nodes to gossip, thus utilizing a significant portion of the constrained total gossip rate. We calculate the average age for a typical node in such a network with symmetric settings, and show that the theoretical upper bound on the age scales as $O(1)$. ASUMAN, with an average age of $O(1)$, offers significant gains compared to a system where the nodes just gossip blindly with a fixed update rate, in which case the age scales as $O(\\log n)$. Further, we analyzed the performance of ASUMAN for fractional, finitely connected, sublinear and hierarchical cluster networks. Finally, we show that the $O(1)$ age scaling can be extended to asymmetric settings as well. We give an example of power law arrivals, where nodes' ages scale differently but follow the $O(1)$ bound.","sentences":["We consider a fully-connected wireless gossip network which consists of a source and $n$ receiver nodes.","The source updates itself with a Poisson process and also sends updates to the nodes as Poisson arrivals.","Upon receiving the updates, the nodes update their knowledge about the source.","The nodes gossip the data among themselves in the form of Poisson arrivals to disperse their knowledge about the source.","The total gossiping rate is bounded by a constraint.","The goal of the network is to be as timely as possible with the source.","We propose a scheme which we coin \\emph{age sense updating multiple access in networks (ASUMAN)}, which is a distributed opportunistic gossiping scheme, where after each time the source updates itself, each node waits for a time proportional to its current age and broadcasts a signal to the other nodes of the network.","This allows the nodes in the network which have higher age to remain silent and only the low-age nodes to gossip, thus utilizing a significant portion of the constrained total gossip rate.","We calculate the average age for a typical node in such a network with symmetric settings, and show that the theoretical upper bound on the age scales as $O(1)$. ASUMAN, with an average age of $O(1)$, offers significant gains compared to a system where the nodes just gossip blindly with a fixed update rate, in which case the age scales as $O(\\log n)$. Further, we analyzed the performance of ASUMAN for fractional, finitely connected, sublinear and hierarchical cluster networks.","Finally, we show that the $O(1)$ age scaling can be extended to asymmetric settings as well.","We give an example of power law arrivals, where nodes' ages scale differently but follow the $O(1)$ bound."],"url":"http://arxiv.org/abs/2304.03249v1"}
{"created":"2023-04-06","title":"A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk","abstract":"Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on treatment at eligibility while others are off treatment but may switch to treatment at a specified time - if they survive long enough. We define and identify an average causal effect of switching under specified causal assumptions. Estimation is done using a g-computation framework with a joint semiparametric Bayesian model for the death and recurrent event processes. Computing the estimand for various switching times allows us to assess the impact of treatment timing. We apply the method to contrast hospitalization rates under different opioid treatment strategies among patients with chronic back pain using Medicare claims data.","sentences":["Observational studies of recurrent event rates are common in biomedical statistics.","Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window.","Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility.","Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias.","Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest.","Both processes are also censored so that events are not observed over the entire followup window.","Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on treatment at eligibility while others are off treatment but may switch to treatment at a specified time - if they survive long enough.","We define and identify an average causal effect of switching under specified causal assumptions.","Estimation is done using a g-computation framework with a joint semiparametric Bayesian model for the death and recurrent event processes.","Computing the estimand for various switching times allows us to assess the impact of treatment timing.","We apply the method to contrast hospitalization rates under different opioid treatment strategies among patients with chronic back pain using Medicare claims data."],"url":"http://arxiv.org/abs/2304.03247v1"}
{"created":"2023-04-06","title":"Inst-Inpaint: Instructing to Remove Objects with Diffusion Models","abstract":"Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way. Traditionally, the pixels that are wished to be erased are defined with binary masks. From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors. In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously. For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon. Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts. We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets. We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements.","sentences":["Image inpainting task refers to erasing unwanted pixels from images and filling them in a semantically consistent and realistic way.","Traditionally, the pixels that are wished to be erased are defined with binary masks.","From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors.","In this work, we are interested in an image inpainting algorithm that estimates which object to be removed based on natural language input and also removes it, simultaneously.","For this purpose, first, we construct a dataset named GQA-Inpaint for this task which will be released soon.","Second, we present a novel inpainting framework, Inst-Inpaint, that can remove objects from images based on the instructions given as text prompts.","We set various GAN and diffusion-based baselines and run experiments on synthetic and real image datasets.","We compare methods with different evaluation metrics that measure the quality and accuracy of the models and show significant quantitative and qualitative improvements."],"url":"http://arxiv.org/abs/2304.03246v1"}
{"created":"2023-04-06","title":"Large language models effectively leverage document-level context for literary translation, but critical errors persist","abstract":"Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches. With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact. We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation.","sentences":["Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets.","However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult.","We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003)","LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English).","Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better.","We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches.","With that said, critical errors still abound, including occasional content omissions, and a human translator's intervention remains necessary to ensure that the author's voice remains intact.","We publicly release our dataset and error annotations to spur future research on evaluation of document-level literary translation."],"url":"http://arxiv.org/abs/2304.03245v1"}
{"created":"2023-04-06","title":"Synthetic Data in Healthcare","abstract":"Synthetic data are becoming a critical tool for building artificially intelligent systems. Simulators provide a way of generating data systematically and at scale. These data can then be used either exclusively, or in conjunction with real data, for training and testing systems. Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck. While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial. Furthermore, these data are highly sensitive and often patient specific. Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists. In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine. We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases.","sentences":["Synthetic data are becoming a critical tool for building artificially intelligent systems.","Simulators provide a way of generating data systematically and at scale.","These data can then be used either exclusively, or in conjunction with real data, for training and testing systems.","Synthetic data are particularly attractive in cases where the availability of ``real'' training examples might be a bottleneck.","While the volume of data in healthcare is growing exponentially, creating datasets for novel tasks and/or that reflect a diverse set of conditions and causal relationships is not trivial.","Furthermore, these data are highly sensitive and often patient specific.","Recent research has begun to illustrate the potential for synthetic data in many areas of medicine, but no systematic review of the literature exists.","In this paper, we present the cases for physical and statistical simulations for creating data and the proposed applications in healthcare and medicine.","We discuss that while synthetics can promote privacy, equity, safety and continual and causal learning, they also run the risk of introducing flaws, blind spots and propagating or exaggerating biases."],"url":"http://arxiv.org/abs/2304.03243v1"}
{"created":"2023-04-06","title":"Assessing the Reproducibility of Machine-learning-based Biomarker Discovery in Parkinson's Disease","abstract":"Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease. Thus, GWAS data can be used to identify genetic variations associated with the disease. Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers. However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped. To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies. We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers. Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies. However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers. These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before. These findings open up new potential avenues of investigation.","sentences":["Genome-Wide Association Studies (GWAS) help identify genetic variations in people with diseases such as Parkinson's disease (PD), which are less common in those without the disease.","Thus, GWAS data can be used to identify genetic variations associated with the disease.","Feature selection and machine learning approaches can be used to analyze GWAS data and identify potential disease biomarkers.","However, GWAS studies have technical variations that affect the reproducibility of identified biomarkers, such as differences in genotyping platforms and selection criteria for individuals to be genotyped.","To address this issue, we collected five GWAS datasets from the database of Genotypes and Phenotypes (dbGaP) and explored several data integration strategies.","We evaluated the agreement among different strategies in terms of the Single Nucleotide Polymorphisms (SNPs) that were identified as potential PD biomarkers.","Our results showed a low concordance of biomarkers discovered using different datasets or integration strategies.","However, we identified fifty SNPs that were identified at least twice, which could potentially serve as novel PD biomarkers.","These SNPs are indirectly linked to PD in the literature but have not been directly associated with PD before.","These findings open up new potential avenues of investigation."],"url":"http://arxiv.org/abs/2304.03239v1"}
{"created":"2023-04-06","title":"On evanescent wave field retrieval with the Marchenko method in 2D settings","abstract":"We show the capability of the Marchenko method to retrieve not only propagating waves, but also evanescent waves, based on a recent derivation of the Marchenko method that does not depend on up-down decomposition inside the medium of interest. We show how these wave fields can be easily retrieved in the slowness-intercept-time domain and what the wave fields look like when they are transformed back to the space-time domain. It is vital for the retrieval of the coda of the wave field that the initial estimate of the focusing function is a direct arrival that contains both the up-going and down-going component of the evanescent wave field. This is because these events directly overlay each other in time.","sentences":["We show the capability of the Marchenko method to retrieve not only propagating waves, but also evanescent waves, based on a recent derivation of the Marchenko method that does not depend on up-down decomposition inside the medium of interest.","We show how these wave fields can be easily retrieved in the slowness-intercept-time domain and what the wave fields look like when they are transformed back to the space-time domain.","It is vital for the retrieval of the coda of the wave field that the initial estimate of the focusing function is a direct arrival that contains both the up-going and down-going component of the evanescent wave field.","This is because these events directly overlay each other in time."],"url":"http://arxiv.org/abs/2304.03238v1"}
{"created":"2023-04-06","title":"GI Software with fewer Data Cache Misses","abstract":"By their very name caches are often overlooked and yet play a vital role in the performance of modern and indeed future hardware. Using MAGPIE (Machine Automated General Performance Improvement via Evolution of software) we show genetic improvement GI can reduce the cache load of existing computer programs. Operating on lines of C and C++ source code using local search, Magpie can generate new functionally equivalent variants which generate fewer L1 data cache misses. Cache miss reduction is tested on two industrial open source programs (Google's Open Location Code OLC and Uber's Hexagonal Hierarchical Spatial Index H3) and two 2D photograph image processing tasks, counting pixels and OpenCV's SEEDS segmentation algorithm.   Magpie's patches functionally generalise. In one case they reduce data misses on the highest performance L1 cache dramatically by 47 percent.","sentences":["By their very name caches are often overlooked and yet play a vital role in the performance of modern and indeed future hardware.","Using MAGPIE (Machine Automated General Performance Improvement via Evolution of software) we show genetic improvement GI can reduce the cache load of existing computer programs.","Operating on lines of C and C++ source code using local search, Magpie can generate new functionally equivalent variants which generate fewer L1 data cache misses.","Cache miss reduction is tested on two industrial open source programs (Google's Open Location Code OLC and Uber's Hexagonal Hierarchical Spatial Index H3) and two 2D photograph image processing tasks, counting pixels and OpenCV's SEEDS segmentation algorithm.   ","Magpie's patches functionally generalise.","In one case they reduce data misses on the highest performance L1 cache dramatically by 47 percent."],"url":"http://arxiv.org/abs/2304.03235v1"}
{"created":"2023-04-06","title":"Parameterized algorithms for Eccentricity Shortest Path Problem","abstract":"Given an undirected graph $G=(V,E)$ and an integer $\\ell$, the Eccentricity Shortest Path (ESP) asks to find a shortest path $P$ such that for every vertex $v\\in V(G)$, there is a vertex $w\\in P$ such that $d_G(v,w)\\leq \\ell$, where $d_G(v,w)$ represents the distance between $v$ and $w$ in $G$. Dragan and Leitert [Theor. Comput. Sci. 2017] showed that the optimization version of this problem, which asks to find the minimum $\\ell$ for the ESP problem, is NP-hard even on planar bipartite graphs with maximum degree 3. They also showed that ESP is W[2]-hard when parameterized by $\\ell$. On the positive side, Ku\\v cera and Such\\'y [IWOCA 2021] showed that the problem exhibits fixed parameter tractable (FPT) behavior when parameterized by modular width, cluster vertex deletion set, maximum leaf number, or the combined parameters disjoint paths deletion set and $\\ell$. It was asked as an open question in the above paper, if ESP is FPT parameterized by disjoint paths deletion set or feedback vertex set. We answer these questions partially and obtain the following results: - ESP is FPT when parameterized by disjoint paths deletion set, split vertex deletion set or the combined parameters feedback vertex set and eccentricity of the graph. - We design a $(1+\\epsilon)$-factor FPT approximation algorithm when parameterized by the feedback vertex set number. - ESP is W[2]-hard when parameterized by the chordal vertex deletion set.","sentences":["Given an undirected graph $G=(V,E)$ and an integer $\\ell$, the Eccentricity Shortest Path (ESP) asks to find a shortest path $P$ such that for every vertex $v\\in V(G)$, there is a vertex $w\\in P$ such that $d_G(v,w)\\leq \\ell$, where $d_G(v,w)$ represents the distance between $v$ and $w$ in $G$. Dragan and Leitert [Theor.","Comput.","Sci. 2017] showed that the optimization version of this problem, which asks to find the minimum $\\ell$ for the ESP problem, is NP-hard even on planar bipartite graphs with maximum degree 3.","They also showed that ESP is W[2]-hard when parameterized by $\\ell$. On the positive side, Ku\\v cera and Such\\'y [IWOCA 2021] showed that the problem exhibits fixed parameter tractable (FPT) behavior when parameterized by modular width, cluster vertex deletion set, maximum leaf number, or the combined parameters disjoint paths deletion set and $\\ell$. It was asked as an open question in the above paper, if ESP is FPT parameterized by disjoint paths deletion set or feedback vertex set.","We answer these questions partially and obtain the following results: - ESP is FPT when parameterized by disjoint paths deletion set, split vertex deletion set or the combined parameters feedback vertex set and eccentricity of the graph.","- We design a $(1+\\epsilon)$-factor FPT approximation algorithm when parameterized by the feedback vertex set number.","- ESP is W[2]-hard when parameterized by the chordal vertex deletion set."],"url":"http://arxiv.org/abs/2304.03233v1"}
{"created":"2023-04-06","title":"Reverse-time analysis uncovers universality classes in directional biological dynamics","abstract":"Mesoscopic bio-systems typically evolve towards functionally important target states, such as cell-cycle checkpoints or decision boundaries for the release of specific behaviors. For the data-driven inference of the underlying directional out-of-equilibrium dynamics, we here develop a theory of target state aligned (TSA) ensembles. Target state alignment allows to analyze directional dynamics in reverse time, starting from the final conditions of the forward process. Knowledge about the initial conditions of the forward process is not required for the analysis. Our theory reveals whether and when such a system can be represented by a single, effective stochastic equation of motion. We show how, in these effective dynamics, genuine biological forces can be separated from spurious forces, which invariably arise from target state alignment. We apply our inference scheme to the example of cytokinetic ring constriction, and derive the universal low-noise and short-term behavior of TSA ensembles. Our theory establishes a transparent mathematical foundation for the analysis and inference of directed biological dynamics by target state alignment.","sentences":["Mesoscopic bio-systems typically evolve towards functionally important target states, such as cell-cycle checkpoints or decision boundaries for the release of specific behaviors.","For the data-driven inference of the underlying directional out-of-equilibrium dynamics, we here develop a theory of target state aligned (TSA) ensembles.","Target state alignment allows to analyze directional dynamics in reverse time, starting from the final conditions of the forward process.","Knowledge about the initial conditions of the forward process is not required for the analysis.","Our theory reveals whether and when such a system can be represented by a single, effective stochastic equation of motion.","We show how, in these effective dynamics, genuine biological forces can be separated from spurious forces, which invariably arise from target state alignment.","We apply our inference scheme to the example of cytokinetic ring constriction, and derive the universal low-noise and short-term behavior of TSA ensembles.","Our theory establishes a transparent mathematical foundation for the analysis and inference of directed biological dynamics by target state alignment."],"url":"http://arxiv.org/abs/2304.03226v1"}
{"created":"2023-04-06","title":"Anomaly Detection via Gumbel Noise Score Matching","abstract":"We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data. GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions. We test our method on a suite of anomaly detection tabular datasets. GNSM achieves a consistently high performance across all experiments. We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions. Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth. We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work.","sentences":["We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data.","GNSM accomplishes this by estimating the scores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuously relaxed categorical distributions.","We test our method on a suite of anomaly detection tabular datasets.","GNSM achieves a consistently high performance across all experiments.","We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions.","Images ranked anomalous by GNSM show clear segmentation failures, with the outputs of GNSM strongly correlating with segmentation metrics computed on ground-truth.","We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work."],"url":"http://arxiv.org/abs/2304.03220v1"}
{"created":"2023-04-06","title":"Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models","abstract":"To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable. Towards that goal, algorithmic auditing has received substantial attention. To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race). However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences. To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets. Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label). To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples. Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts. Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success. Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models.","sentences":["To safely deploy deep learning-based computer vision models for computer-aided detection and diagnosis, we must ensure that they are robust and reliable.","Towards that goal, algorithmic auditing has received substantial attention.","To guide their audit procedures, existing methods rely on heuristic approaches or high-level objectives (e.g., non-discrimination in regards to protected attributes, such as sex, gender, or race).","However, algorithms may show bias with respect to various attributes beyond the more obvious ones, and integrity issues related to these more subtle attributes can have serious consequences.","To enable the generation of actionable, data-driven hypotheses which identify specific dataset attributes likely to induce model bias, we contribute a first technique for the rigorous, quantitative screening of medical image datasets.","Drawing from literature in the causal inference and information theory domains, our procedure decomposes the risks associated with dataset attributes in terms of their detectability and utility (defined as the amount of information knowing the attribute gives about a task label).","To demonstrate the effectiveness and sensitivity of our method, we develop a variety of datasets with synthetically inserted artifacts with different degrees of association to the target label that allow evaluation of inherited model biases via comparison of performance against true counterfactual examples.","Using these datasets and results from hundreds of trained models, we show our screening method reliably identifies nearly imperceptible bias-inducing artifacts.","Lastly, we apply our method to the natural attributes of a popular skin-lesion dataset and demonstrate its success.","Our approach provides a means to perform more systematic algorithmic audits and guide future data collection efforts in pursuit of safer and more reliable models."],"url":"http://arxiv.org/abs/2304.03218v1"}
{"created":"2023-04-06","title":"On the Pareto Front of Multilingual Neural Machine Translation","abstract":"In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better performance than temperature searching and gradient manipulation methods using up to half of the total training budget in our experiments.","sentences":["In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT).","By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus.","That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions.","Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks.","Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better performance than temperature searching and gradient manipulation methods using up to half of the total training budget in our experiments."],"url":"http://arxiv.org/abs/2304.03216v1"}
{"created":"2023-04-06","title":"Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching","abstract":"Cross-device user matching is a critical problem in numerous domains, including advertising, recommender systems, and cybersecurity. It involves identifying and linking different devices belonging to the same person, utilizing sequence logs. Previous data mining techniques have struggled to address the long-range dependencies and higher-order connections between the logs. Recently, researchers have modeled this problem as a graph problem and proposed a two-tier graph contextual embedding (TGCE) neural network architecture, which outperforms previous methods. In this paper, we propose a novel hierarchical graph neural network architecture (HGNN), which has a more computationally efficient second level design than TGCE. Furthermore, we introduce a cross-attention (Cross-Att) mechanism in our model, which improves performance by 5% compared to the state-of-the-art TGCE method.","sentences":["Cross-device user matching is a critical problem in numerous domains, including advertising, recommender systems, and cybersecurity.","It involves identifying and linking different devices belonging to the same person, utilizing sequence logs.","Previous data mining techniques have struggled to address the long-range dependencies and higher-order connections between the logs.","Recently, researchers have modeled this problem as a graph problem and proposed a two-tier graph contextual embedding (TGCE) neural network architecture, which outperforms previous methods.","In this paper, we propose a novel hierarchical graph neural network architecture (HGNN), which has a more computationally efficient second level design than TGCE.","Furthermore, we introduce a cross-attention (Cross-Att) mechanism in our model, which improves performance by 5% compared to the state-of-the-art TGCE method."],"url":"http://arxiv.org/abs/2304.03215v1"}
{"created":"2023-04-06","title":"HOTGP -- Higher-Order Typed Genetic Programming","abstract":"Program synthesis is the process of generating a computer program following a set of specifications, which can be a high-level description of the problem and/or a set of input-output examples. The synthesis can be modeled as a search problem in which the search space is the set of all the programs valid under a grammar. As the search space is vast, brute force is usually not viable and search heuristics, such as genetic programming, also have difficulty navigating it without any guidance. In this paper we present HOTGP, a new genetic programming algorithm that synthesizes pure, typed, and functional programs. HOTGP leverages the knowledge provided by the rich data-types associated with the specification and the built-in grammar to constrain the search space and improve the performance of the synthesis. The grammar is based on Haskell's standard base library (the synthesized code can be directly compiled using any standard Haskell compiler) and includes support for higher-order functions, $\\lambda$-functions, and parametric polymorphism. Experimental results show that, when compared to $6$ state-of-the-art algorithms using a standard set of benchmarks, HOTGP is competitive and capable of synthesizing the correct programs more frequently than any other of the evaluated algorithms.","sentences":["Program synthesis is the process of generating a computer program following a set of specifications, which can be a high-level description of the problem and/or a set of input-output examples.","The synthesis can be modeled as a search problem in which the search space is the set of all the programs valid under a grammar.","As the search space is vast, brute force is usually not viable and search heuristics, such as genetic programming, also have difficulty navigating it without any guidance.","In this paper we present HOTGP, a new genetic programming algorithm that synthesizes pure, typed, and functional programs.","HOTGP leverages the knowledge provided by the rich data-types associated with the specification and the built-in grammar to constrain the search space and improve the performance of the synthesis.","The grammar is based on Haskell's standard base library (the synthesized code can be directly compiled using any standard Haskell compiler) and includes support for higher-order functions, $\\lambda$-functions, and parametric polymorphism.","Experimental results show that, when compared to $6$ state-of-the-art algorithms using a standard set of benchmarks, HOTGP is competitive and capable of synthesizing the correct programs more frequently than any other of the evaluated algorithms."],"url":"http://arxiv.org/abs/2304.03200v1"}
{"created":"2023-04-06","title":"Complementary structural and functional abnormalities to localise epileptogenic tissue","abstract":"When investigating suitability for surgery, people with drug-refractory focal epilepsy may have intracranial EEG (iEEG) electrodes implanted to localise seizure onset. Diffusion-weighted magnetic resonance imaging (dMRI) may be acquired to identify key white matter tracts for surgical avoidance. Here, we investigate whether structural connectivity abnormalities, inferred from dMRI, may be used in conjunction with functional iEEG abnormalities to aid localisation and resection of the epileptogenic zone (EZ), and improve surgical outcomes in epilepsy.   We retrospectively investigated data from 43 patients with epilepsy who had surgery following iEEG. Twenty five patients (58%) were free from disabling seizures (ILAE 1 or 2) at one year. For all patients, T1-weighted and diffusion-weighted MRIs were acquired prior to iEEG implantation. Interictal iEEG functional, and dMRI structural connectivity abnormalities were quantified by comparison to a normative map and healthy controls respectively.   First, we explored whether the resection of maximal (dMRI and iEEG) abnormalities related to improved surgical outcomes. Second, we investigated whether the modalities provided complementary information for improved prediction of surgical outcome. Third, we suggest how dMRI abnormalities may be useful to inform the placement of iEEG electrodes as part of the pre-surgical evaluation using a patient case study.   Seizure freedom was 15 times more likely in those patients with resection of maximal dMRI and iEEG abnormalities (p=0.008). Both modalities were separately able to distinguish patient outcome groups and when combined, a decision tree correctly separated 36 out of 43 (84%) patients based on surgical outcome.   Structural dMRI could be used in pre-surgical evaluations, particularly when localisation of the EZ is uncertain, to inform personalised iEEG implantation and resection.","sentences":["When investigating suitability for surgery, people with drug-refractory focal epilepsy may have intracranial EEG (iEEG) electrodes implanted to localise seizure onset.","Diffusion-weighted magnetic resonance imaging (dMRI) may be acquired to identify key white matter tracts for surgical avoidance.","Here, we investigate whether structural connectivity abnormalities, inferred from dMRI, may be used in conjunction with functional iEEG abnormalities to aid localisation and resection of the epileptogenic zone (EZ), and improve surgical outcomes in epilepsy.   ","We retrospectively investigated data from 43 patients with epilepsy who had surgery following iEEG.","Twenty five patients (58%) were free from disabling seizures (ILAE 1 or 2) at one year.","For all patients, T1-weighted and diffusion-weighted MRIs were acquired prior to iEEG implantation.","Interictal iEEG functional, and dMRI structural connectivity abnormalities were quantified by comparison to a normative map and healthy controls respectively.   ","First, we explored whether the resection of maximal (dMRI and iEEG) abnormalities related to improved surgical outcomes.","Second, we investigated whether the modalities provided complementary information for improved prediction of surgical outcome.","Third, we suggest how dMRI abnormalities may be useful to inform the placement of iEEG electrodes as part of the pre-surgical evaluation using a patient case study.   ","Seizure freedom was 15 times more likely in those patients with resection of maximal dMRI and iEEG abnormalities (p=0.008).","Both modalities were separately able to distinguish patient outcome groups and when combined, a decision tree correctly separated 36 out of 43 (84%) patients based on surgical outcome.   ","Structural dMRI could be used in pre-surgical evaluations, particularly when localisation of the EZ is uncertain, to inform personalised iEEG implantation and resection."],"url":"http://arxiv.org/abs/2304.03192v1"}
{"created":"2023-04-06","title":"Krylov Methods are (nearly) Optimal for Low-Rank Approximation","abstract":"We consider the problem of rank-$1$ low-rank approximation (LRA) in the matrix-vector product model under various Schatten norms: $$   \\min_{\\|u\\|_2=1} \\|A (I - u u^\\top)\\|_{\\mathcal{S}_p} , $$ where $\\|M\\|_{\\mathcal{S}_p}$ denotes the $\\ell_p$ norm of the singular values of $M$. Given $\\varepsilon>0$, our goal is to output a unit vector $v$ such that $$   \\|A(I - vv^\\top)\\|_{\\mathcal{S}_p} \\leq (1+\\varepsilon) \\min_{\\|u\\|_2=1}\\|A(I - u u^\\top)\\|_{\\mathcal{S}_p}. $$ Our main result shows that Krylov methods (nearly) achieve the information-theoretically optimal number of matrix-vector products for Spectral ($p=\\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.   In particular, for Spectral LRA, we show that any algorithm requires $\\Omega\\left(\\log(n)/\\varepsilon^{1/2}\\right)$ matrix-vector products, exactly matching the upper bound obtained by Krylov methods [MM15, BCW22]. Our lower bound addresses Open Question 1 in [Woo14], providing evidence for the lack of progress on algorithms for Spectral LRA and resolves Open Question 1.2 in [BCW22]. Next, we show that for any fixed constant $p$, i.e. $1\\leq p =O(1)$, there is an upper bound of $O\\left(\\log(1/\\varepsilon)/\\varepsilon^{1/3}\\right)$ matrix-vector products, implying that the complexity does not grow as a function of input size. This improves the $O\\left(\\log(n/\\varepsilon)/\\varepsilon^{1/3}\\right)$ bound recently obtained in [BCW22], and matches their $\\Omega\\left(1/\\varepsilon^{1/3}\\right)$ lower bound, to a $\\log(1/\\varepsilon)$ factor.","sentences":["We consider the problem of rank-$1$ low-rank approximation (LRA) in the matrix-vector product model under various Schatten norms: $$   \\min_{\\|u\\|_2=1} \\|A (I - u u^\\top)\\|_{\\mathcal{S}_p} , $$ where $\\|M\\|_{\\mathcal{S}_p}$ denotes the $\\ell_p$ norm of the singular values of $M$. Given $\\varepsilon>0$, our goal is to output a unit vector $v$ such that $$   \\|A(I - vv^\\top)\\|_{\\mathcal{S}_p} \\leq (1+\\varepsilon) \\min_{\\|u\\|_2=1}\\|A(I - u u^\\top)\\|_{\\mathcal{S}_p}.","$$ Our main result shows that Krylov methods (nearly) achieve the information-theoretically optimal number of matrix-vector products for Spectral ($p=\\infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.   ","In particular, for Spectral LRA, we show that any algorithm requires $\\Omega\\left(\\log(n)/\\varepsilon^{1/2}\\right)$ matrix-vector products, exactly matching the upper bound obtained by Krylov methods","[MM15, BCW22].","Our lower bound addresses Open Question 1 in [Woo14], providing evidence for the lack of progress on algorithms for Spectral LRA and resolves Open Question 1.2 in [BCW22].","Next, we show that for any fixed constant $p$, i.e. $1\\leq p =O(1)$, there is an upper bound of $O\\left(\\log(1/\\varepsilon)/\\varepsilon^{1/3}\\right)$ matrix-vector products, implying that the complexity does not grow as a function of input size.","This improves the $O\\left(\\log(n/\\varepsilon)/\\varepsilon^{1/3}\\right)$ bound recently obtained in [BCW22], and matches their $\\Omega\\left(1/\\varepsilon^{1/3}\\right)$ lower bound, to a $\\log(1/\\varepsilon)$ factor."],"url":"http://arxiv.org/abs/2304.03191v1"}
{"created":"2023-04-06","title":"The Concept of Forward-Forward Learning Applied to a Multi Output Perceptron","abstract":"The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification. The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples. Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries. Moreover, the overall performance is comparable to more complex neural networks with hidden layers. The benefit of the approach presented here is that it only involves a single matrix multiplication.","sentences":["The concept of a recently proposed Forward-Forward learning algorithm for fully connected artificial neural networks is applied to a single multi output perceptron for classification.","The parameters of the system are trained with respect to increased (decreased) \"goodness\" for correctly (incorrectly) labelled input samples.","Basic numerical tests demonstrate that the trained perceptron effectively deals with data sets that have non-linear decision boundaries.","Moreover, the overall performance is comparable to more complex neural networks with hidden layers.","The benefit of the approach presented here is that it only involves a single matrix multiplication."],"url":"http://arxiv.org/abs/2304.03189v1"}
{"created":"2023-04-06","title":"Advances in Data-Driven Analysis and Synthesis of 3D Indoor Scenes","abstract":"This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes. We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations. Specifically, we focus on the analysis and synthesis of 3D indoor scenes. With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity. And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis. We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general. For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature. Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse.","sentences":["This report surveys advances in deep learning-based modeling techniques that address four different 3D indoor scene analysis tasks, as well as synthesis of 3D indoor scenes.","We describe different kinds of representations for indoor scenes, various indoor scene datasets available for research in the aforementioned areas, and discuss notable works employing machine learning models for such scene modeling tasks based on these representations.","Specifically, we focus on the analysis and synthesis of 3D indoor scenes.","With respect to analysis, we focus on four basic scene understanding tasks -- 3D object detection, 3D scene segmentation, 3D scene reconstruction and 3D scene similarity.","And for synthesis, we mainly discuss neural scene synthesis works, though also highlighting model-driven methods that allow for human-centric, progressive scene synthesis.","We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general.","For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature.","Towards the end, we discuss some interesting research directions that have the potential to make a direct impact on the way users interact and engage with these virtual scene models, making them an integral part of the metaverse."],"url":"http://arxiv.org/abs/2304.03188v1"}
{"created":"2023-04-06","title":"Cavitation Rheology of Model Yield Stress Fluids Based on Carbopol","abstract":"Measuring surface tension of yield stress fluids has remained a critical challenge due to limitations of the traditional tensiometry techniques. Here, we overcome those limits and successfully measure the surface tension and mechanical properties of a model yield stress fluid based on Carbopol gels via a needle-induced cavitation (NIC) technique. Our results indicate that the surface tension is approximately 70, and is independent of the rheology of yield stress fluid over a wide range of yield stress values. In addition, we demonstrate that a Young modulus smaller than 1 kPa can be successfully measured for Carbopol gels with NIC method. Finally, we present a time-resolved flow structure around the cavity in a host of yield stress fluids, and assess the impact of fluid rheology on the detailed form of flow around the cavity. Interestingly, prior to the critical point associated with cavitation, the yield stress fluid is weakly deformed suggesting that the measured surface tension data reflect the near equilibrium values. Beyond the critical point, the yield stress fluid experiences a strong flow that is controlled by both the critical pressure and the non-Newtonian rheology of the yield stress fluid.","sentences":["Measuring surface tension of yield stress fluids has remained a critical challenge due to limitations of the traditional tensiometry techniques.","Here, we overcome those limits and successfully measure the surface tension and mechanical properties of a model yield stress fluid based on Carbopol gels via a needle-induced cavitation (NIC) technique.","Our results indicate that the surface tension is approximately 70, and is independent of the rheology of yield stress fluid over a wide range of yield stress values.","In addition, we demonstrate that a Young modulus smaller than 1 kPa can be successfully measured for Carbopol gels with NIC method.","Finally, we present a time-resolved flow structure around the cavity in a host of yield stress fluids, and assess the impact of fluid rheology on the detailed form of flow around the cavity.","Interestingly, prior to the critical point associated with cavitation, the yield stress fluid is weakly deformed suggesting that the measured surface tension data reflect the near equilibrium values.","Beyond the critical point, the yield stress fluid experiences a strong flow that is controlled by both the critical pressure and the non-Newtonian rheology of the yield stress fluid."],"url":"http://arxiv.org/abs/2304.03187v1"}
{"created":"2023-04-06","title":"On the tractability of sampling from the Potts model at low temperatures via Swendsen--Wang dynamics","abstract":"Sampling from the $q$-state ferromagnetic Potts model is a fundamental question in statistical physics, probability theory, and theoretical computer science. On general graphs, this problem is computationally hard, and this hardness holds at arbitrarily low temperatures. At the same time, in recent years, there has been significant progress showing the existence of low-temperature sampling algorithms in various specific families of graphs. Our aim in this paper is to understand the minimal structural properties of general graphs that enable polynomial-time sampling from the $q$-state ferromagnetic Potts model at low temperatures. We study this problem from the perspective of the widely-used Swendsen--Wang dynamics and the closely related random-cluster dynamics.   Our results demonstrate that the key graph property behind fast or slow convergence time for these dynamics is whether the independent edge-percolation on the graph admits a strongly supercritical phase. By this, we mean that at large $p<1$, it has a unique giant component of linear size, and the complement of that giant component is comprised of only small components. Specifically, we prove that such a condition implies fast mixing of the Swendsen--Wang and random-cluster dynamics on two general families of bounded-degree graphs: (a) graphs of at most stretched-exponential volume growth and (b) locally treelike graphs. In the other direction, we show that, even among graphs in those families, these Markov chains can converge exponentially slowly at arbitrarily low temperatures if the edge-percolation condition does not hold. In the process, we develop new tools for the analysis of non-local Markov chains, including a framework to bound the speed of disagreement propagation in the presence of long-range correlations, and an understanding of spatial mixing properties on trees with random boundary conditions.","sentences":["Sampling from the $q$-state ferromagnetic Potts model is a fundamental question in statistical physics, probability theory, and theoretical computer science.","On general graphs, this problem is computationally hard, and this hardness holds at arbitrarily low temperatures.","At the same time, in recent years, there has been significant progress showing the existence of low-temperature sampling algorithms in various specific families of graphs.","Our aim in this paper is to understand the minimal structural properties of general graphs that enable polynomial-time sampling from the $q$-state ferromagnetic Potts model at low temperatures.","We study this problem from the perspective of the widely-used Swendsen--Wang dynamics and the closely related random-cluster dynamics.   ","Our results demonstrate that the key graph property behind fast or slow convergence time for these dynamics is whether the independent edge-percolation on the graph admits a strongly supercritical phase.","By this, we mean that at large $p<1$, it has a unique giant component of linear size, and the complement of that giant component is comprised of only small components.","Specifically, we prove that such a condition implies fast mixing of the Swendsen--Wang and random-cluster dynamics on two general families of bounded-degree graphs: (a) graphs of at most stretched-exponential volume growth and (b) locally treelike graphs.","In the other direction, we show that, even among graphs in those families, these Markov chains can converge exponentially slowly at arbitrarily low temperatures if the edge-percolation condition does not hold.","In the process, we develop new tools for the analysis of non-local Markov chains, including a framework to bound the speed of disagreement propagation in the presence of long-range correlations, and an understanding of spatial mixing properties on trees with random boundary conditions."],"url":"http://arxiv.org/abs/2304.03182v1"}
{"created":"2023-04-06","title":"Interference-Aware Deployment for Maximizing User Satisfaction in Multi-UAV Wireless Networks","abstract":"In this letter, we study the deployment of Unmanned Aerial Vehicle mounted Base Stations (UAV-BSs) in multi-UAV cellular networks. We model the multi-UAV deployment problem as a user satisfaction maximization problem, that is, maximizing the proportion of served ground users (GUs) that meet a given minimum data rate requirement. We propose an interference-aware deployment (IAD) algorithm for serving arbitrarily distributed outdoor GUs. The proposed algorithm can alleviate the problem of overlapping coverage between adjacent UAV-BSs to minimize inter-cell interference. Therefore, reducing co-channel interference between UAV-BSs will improve user satisfaction and ensure that most GUs can achieve the minimum data rate requirement. Simulation results show that our proposed IAD outperforms comparative methods by more than 10% in user satisfaction in high-density environments.","sentences":["In this letter, we study the deployment of Unmanned Aerial Vehicle mounted Base Stations (UAV-BSs) in multi-UAV cellular networks.","We model the multi-UAV deployment problem as a user satisfaction maximization problem, that is, maximizing the proportion of served ground users (GUs) that meet a given minimum data rate requirement.","We propose an interference-aware deployment (IAD) algorithm for serving arbitrarily distributed outdoor GUs.","The proposed algorithm can alleviate the problem of overlapping coverage between adjacent UAV-BSs to minimize inter-cell interference.","Therefore, reducing co-channel interference between UAV-BSs will improve user satisfaction and ensure that most GUs can achieve the minimum data rate requirement.","Simulation results show that our proposed IAD outperforms comparative methods by more than 10% in user satisfaction in high-density environments."],"url":"http://arxiv.org/abs/2304.03168v1"}
{"created":"2023-04-06","title":"CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition","abstract":"Creating animatable avatars from static scans requires the modeling of clothing deformations in different poses. Existing learning-based methods typically add pose-dependent deformations upon a minimally-clothed mesh template or a learned implicit template, which have limitations in capturing details or hinder end-to-end learning. In this paper, we revisit point-based solutions and propose to decompose explicit garment-related templates and then add pose-dependent wrinkles to them. In this way, the clothing deformations are disentangled such that the pose-dependent wrinkles can be better learned and applied to unseen poses. Additionally, to tackle the seam artifact issues in recent state-of-the-art point-based methods, we propose to learn point features on a body surface, which establishes a continuous and compact feature space to capture the fine-grained and pose-dependent clothing geometry. To facilitate the research in this field, we also introduce a high-quality scan dataset of humans in real-world clothing. Our approach is validated on two existing datasets and our newly introduced dataset, showing better clothing deformation results in unseen poses. The project page with code and dataset can be found at https://www.liuyebin.com/closet.","sentences":["Creating animatable avatars from static scans requires the modeling of clothing deformations in different poses.","Existing learning-based methods typically add pose-dependent deformations upon a minimally-clothed mesh template or a learned implicit template, which have limitations in capturing details or hinder end-to-end learning.","In this paper, we revisit point-based solutions and propose to decompose explicit garment-related templates and then add pose-dependent wrinkles to them.","In this way, the clothing deformations are disentangled such that the pose-dependent wrinkles can be better learned and applied to unseen poses.","Additionally, to tackle the seam artifact issues in recent state-of-the-art point-based methods, we propose to learn point features on a body surface, which establishes a continuous and compact feature space to capture the fine-grained and pose-dependent clothing geometry.","To facilitate the research in this field, we also introduce a high-quality scan dataset of humans in real-world clothing.","Our approach is validated on two existing datasets and our newly introduced dataset, showing better clothing deformation results in unseen poses.","The project page with code and dataset can be found at https://www.liuyebin.com/closet."],"url":"http://arxiv.org/abs/2304.03167v1"}
{"created":"2023-04-06","title":"Temporal variation of the photometric magnetic activity for the Sun and Kepler solar-like stars","abstract":"The photometric time series of solar-like stars can exhibit rotational modulation due to active regions co-rotating with the stellar surface, allowing us to constrain stellar rotation and magnetic activity. In this work we investigate the behavior, particularly the variability, of the photometric magnetic activity of Kepler solar-like stars and compare it with that of the Sun. We adopted the photometric magnetic activity proxy Sph, which was computed with a cadence of 5 x the rotation period, Prot. The average Sph was taken as the mean activity level, and the standard deviation was taken as a measure of the temporal variation of the magnetic activity over the observations. We also analyzed Sun-as-a-star photometric data from VIRGO. Sun-like stars were selected from a very narrow parameter space around the solar properties. We also looked into KIC 8006161 (HD 173701), an active metal-rich G dwarf, and we compared its magnetic activity to that of stars with similar stellar parameters. We find that the amplitude of Sph variability is strongly correlated with its mean value, independent of spectral type. An equivalent relationship has been found for ground-based observations of chromospheric activity emission and magnetic field strength, but in this work we show that photometric Kepler data also present the same behavior. While, depending on the cycle phase, the Sun is among the less active stars, we find that the solar Sph properties are consistent with those observed in Kepler Sun-like stars. KIC 8006161 is, however, among the most active of its peers, which tend to be metal-rich. This results from an underlying relationship between Prot and metallicity and supports the following interpretation of the magnetic activity of KIC 8006161: its strong activity is a consequence of its high metallicity, which affects the depth of the convection zone and, consequently, the efficiency of the dynamo.","sentences":["The photometric time series of solar-like stars can exhibit rotational modulation due to active regions co-rotating with the stellar surface, allowing us to constrain stellar rotation and magnetic activity.","In this work we investigate the behavior, particularly the variability, of the photometric magnetic activity of Kepler solar-like stars and compare it with that of the Sun.","We adopted the photometric magnetic activity proxy Sph, which was computed with a cadence of 5 x the rotation period, Prot.","The average Sph was taken as the mean activity level, and the standard deviation was taken as a measure of the temporal variation of the magnetic activity over the observations.","We also analyzed Sun-as-a-star photometric data from VIRGO.","Sun-like stars were selected from a very narrow parameter space around the solar properties.","We also looked into KIC 8006161 (HD 173701), an active metal-rich G dwarf, and we compared its magnetic activity to that of stars with similar stellar parameters.","We find that the amplitude of Sph variability is strongly correlated with its mean value, independent of spectral type.","An equivalent relationship has been found for ground-based observations of chromospheric activity emission and magnetic field strength, but in this work we show that photometric Kepler data also present the same behavior.","While, depending on the cycle phase, the Sun is among the less active stars, we find that the solar Sph properties are consistent with those observed in Kepler Sun-like stars.","KIC 8006161 is, however, among the most active of its peers, which tend to be metal-rich.","This results from an underlying relationship between Prot and metallicity and supports the following interpretation of the magnetic activity of KIC 8006161: its strong activity is a consequence of its high metallicity, which affects the depth of the convection zone and, consequently, the efficiency of the dynamo."],"url":"http://arxiv.org/abs/2304.03165v1"}
{"created":"2023-04-06","title":"Patch-wise Features for Blur Image Classification","abstract":"Images captured through smartphone cameras often suffer from degradation, blur being one of the major ones, posing a challenge in processing these images for downstream tasks. In this paper we propose low-compute lightweight patch-wise features for image quality assessment. Using our method we can discriminate between blur vs sharp image degradation. To this end, we train a decision-tree based XGBoost model on various intuitive image features like gray level variance, first and second order gradients, texture features like local binary patterns. Experiments conducted on an open dataset show that the proposed low compute method results in 90.1% mean accuracy on the validation set, which is comparable to the accuracy of a compute-intensive VGG16 network with 94% mean accuracy fine-tuned to this task. To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively. The proposed method is 10x faster than the VGG16 based model on CPU and scales linearly to the input image size making it suitable to be implemented on low compute edge devices.","sentences":["Images captured through smartphone cameras often suffer from degradation, blur being one of the major ones, posing a challenge in processing these images for downstream tasks.","In this paper we propose low-compute lightweight patch-wise features for image quality assessment.","Using our method we can discriminate between blur vs sharp image degradation.","To this end, we train a decision-tree based XGBoost model on various intuitive image features like gray level variance, first and second order gradients, texture features like local binary patterns.","Experiments conducted on an open dataset show that the proposed low compute method results in 90.1% mean accuracy on the validation set, which is comparable to the accuracy of a compute-intensive VGG16 network with 94% mean accuracy fine-tuned to this task.","To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively.","The proposed method is 10x faster than the VGG16 based model on CPU and scales linearly to the input image size making it suitable to be implemented on low compute edge devices."],"url":"http://arxiv.org/abs/2304.03156v1"}
{"created":"2023-04-06","title":"Assessing VoD pressure on network power consumption","abstract":"Assessing the energy consumption or carbon footprint of data distribution of video streaming services is usually carried out through energy or carbon intensity figures (in Wh or gCO2e per GB). In this paper, we first review the reasons why such approaches are likely to lead to misunderstandings and potentially to erroneous conclusions. To overcome those shortcomings, we propose a new methodology whose key idea is to consider a video streaming usage at the whole scale of a territory, and evaluate the impact of this usage on the network infrastructure. At the core of our methodology is a parametric model of a simplified network and Content Delivery Network (CDN) infrastructure, which is automatically scaled according to peak usage needs. This allows us to compare the power consumption of this infrastructure under different scenarios, ranging from a sober baseline to a generalized use of high bitrate videos. Our results show that classical efficiency indicators do not reflect the power consumption increase of more intensive Internet usage, and might even lead to misleading conclusions.","sentences":["Assessing the energy consumption or carbon footprint of data distribution of video streaming services is usually carried out through energy or carbon intensity figures (in Wh or gCO2e per GB).","In this paper, we first review the reasons why such approaches are likely to lead to misunderstandings and potentially to erroneous conclusions.","To overcome those shortcomings, we propose a new methodology whose key idea is to consider a video streaming usage at the whole scale of a territory, and evaluate the impact of this usage on the network infrastructure.","At the core of our methodology is a parametric model of a simplified network and Content Delivery Network (CDN) infrastructure, which is automatically scaled according to peak usage needs.","This allows us to compare the power consumption of this infrastructure under different scenarios, ranging from a sober baseline to a generalized use of high bitrate videos.","Our results show that classical efficiency indicators do not reflect the power consumption increase of more intensive Internet usage, and might even lead to misleading conclusions."],"url":"http://arxiv.org/abs/2304.03151v1"}
{"created":"2023-04-06","title":"Chemically detaching hBN crystals grown at atmospheric pressure and high temperature for high-performance graphene devices","abstract":"In this work, we report on the growth of hexagonal boron nitride (hBN) crystals from an iron flux at atmospheric pressure and high temperature and demonstrate that (i) the entire sheet of hBN crystals can be detached from the metal in a single step using hydrochloric acid and that (ii) these hBN crystals allow the fabrication of high carrier mobility graphene devices. By combining spatially-resolved confocal Raman spectroscopy and electrical transport measurements, we confirm the excellent quality of these crystals for high-performance hBN-graphene-based van der Waals heterostructures. The full width at half maximum of the graphene Raman 2D peak is as low as 16 cm$^{-1}$, and the room temperature charge carrier mobilitiy is around 80000 cm$^2$/(Vs) at a carrier density 1$\\times$10$^{12}$cm$^{-12}$. This is fully comparable with devices of similar dimensions fabricated using crystalline hBN synthesized by the high pressure and high temperature method. Finally, we show that for high quality hBN crystals the hBN Raman peak line width, in contrast to the graphene 2D line width, does not contain any useful information for benchmarking the hBN substrate or encapsulant.","sentences":["In this work, we report on the growth of hexagonal boron nitride (hBN) crystals from an iron flux at atmospheric pressure and high temperature and demonstrate that (i) the entire sheet of hBN crystals can be detached from the metal in a single step using hydrochloric acid and that (ii) these hBN crystals allow the fabrication of high carrier mobility graphene devices.","By combining spatially-resolved confocal Raman spectroscopy and electrical transport measurements, we confirm the excellent quality of these crystals for high-performance hBN-graphene-based van der Waals heterostructures.","The full width at half maximum of the graphene Raman 2D peak is as low as 16 cm$^{-1}$, and the room temperature charge carrier mobilitiy is around 80000 cm$^2$/(Vs) at a carrier density","1$\\times$10$^{12}$cm$^{-12}$.","This is fully comparable with devices of similar dimensions fabricated using crystalline hBN synthesized by the high pressure and high temperature method.","Finally, we show that for high quality hBN crystals the hBN Raman peak line width, in contrast to the graphene 2D line width, does not contain any useful information for benchmarking the hBN substrate or encapsulant."],"url":"http://arxiv.org/abs/2304.03149v1"}
{"created":"2023-04-06","title":"The Eyes Have It!: Using Human-Selected Features for Predicting Athletes' Performance","abstract":"Predicting athletes' performance has relied mostly on statistical data. Besides the traditional data, various types of data, including video, have become available. However, it is challenging to use them for deep learning, especially when the size of the athletes' dataset is small. This research proposes a feature-selection strategy based on the criteria used by insightful people, which could improve ML performance. Our ML model employs features selected by people who correctly evaluated the athletes' future performance. We tested out a strategy to predict the LPGA players' next day performance using their interview video. We asked study participants to predict the players' next day score after watching the interviews and asked why. Using combined features of the facial landmarks' movements, derived from the participants, and meta-data showed a better F1-score than using each feature separately. This study suggests that the human-in-the-loop model could improve algorithms' performance with small-dataset.","sentences":["Predicting athletes' performance has relied mostly on statistical data.","Besides the traditional data, various types of data, including video, have become available.","However, it is challenging to use them for deep learning, especially when the size of the athletes' dataset is small.","This research proposes a feature-selection strategy based on the criteria used by insightful people, which could improve ML performance.","Our ML model employs features selected by people who correctly evaluated the athletes' future performance.","We tested out a strategy to predict the LPGA players' next day performance using their interview video.","We asked study participants to predict the players' next day score after watching the interviews and asked why.","Using combined features of the facial landmarks' movements, derived from the participants, and meta-data showed a better F1-score than using each feature separately.","This study suggests that the human-in-the-loop model could improve algorithms' performance with small-dataset."],"url":"http://arxiv.org/abs/2304.03148v1"}
{"created":"2023-04-06","title":"Parameterized Approximation Schemes for Clustering with General Norm Objectives","abstract":"This paper considers the well-studied algorithmic regime of designing a $(1+\\epsilon)$-approximation algorithm for a $k$-clustering problem that runs in time $f(k,\\epsilon)poly(n)$ (sometimes called an efficient parameterized approximation scheme or EPAS for short). Notable results of this kind include EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\\u{o}iu, Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means [Kumar, Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to the specific objective and metric space.   Our main contribution is a clean and simple EPAS that settles more than ten clustering problems (across multiple well-studied objectives as well as metric spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large variety of clustering objectives (for example, $k$-means, $k$-center, $k$-median, priority $k$-center, $\\ell$-centrum, ordered $k$-median, socially fair $k$-median aka robust $k$-median, or more generally monotone norm $k$-clustering) and metric spaces (for example, continuous high-dimensional Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth metrics, and planar metrics).   Key to our approach is a new concept that we call bounded $\\epsilon$-scatter dimension--an intrinsic complexity measure of a metric space that is a relaxation of the standard notion of bounded doubling dimension. Our main technical result shows that two conditions are essentially sufficient for our algorithm to yield an EPAS on the input metric $M$ for any clustering objective: (i) The objective is described by a monotone (not necessarily symmetric!) norm, and (ii) the $\\epsilon$-scatter dimension of $M$ is upper bounded by a function of $\\epsilon$.","sentences":["This paper considers the well-studied algorithmic regime of designing a $(1+\\epsilon)$-approximation algorithm for a $k$-clustering problem that runs in time $f(k,\\epsilon)poly(n)$ (sometimes called an efficient parameterized approximation scheme or EPAS for short).","Notable results of this kind include EPASes in the high-dimensional Euclidean setting for $k$-center","[Bad\\u{o}iu, Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means","[Kumar, Sabharwal, Sen; J. ACM 2010].","However, existing EPASes handle only basic objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to the specific objective and metric space.   ","Our main contribution is a clean and simple EPAS that settles more than ten clustering problems (across multiple well-studied objectives as well as metric spaces) and unifies well-known EPASes.","Our algorithm gives EPASes for a large variety of clustering objectives (for example, $k$-means, $k$-center, $k$-median, priority $k$-center, $\\ell$-centrum, ordered $k$-median, socially fair $k$-median aka robust $k$-median, or more generally monotone norm $k$-clustering) and metric spaces (for example, continuous high-dimensional Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth metrics, and planar metrics).   ","Key to our approach is a new concept that we call bounded $\\epsilon$-scatter dimension--an intrinsic complexity measure of a metric space that is a relaxation of the standard notion of bounded doubling dimension.","Our main technical result shows that two conditions are essentially sufficient for our algorithm to yield an EPAS on the input metric $M$ for any clustering objective: (i)","The objective is described by a monotone (not necessarily symmetric!)","norm, and (ii) the $\\epsilon$-scatter dimension of $M$ is upper bounded by a function of $\\epsilon$."],"url":"http://arxiv.org/abs/2304.03146v1"}
{"created":"2023-04-06","title":"For-Each Operations in Collaborative Apps","abstract":"Conflict-free Replicated Data Types (CRDTs) allow collaborative access to an app's data. We describe a novel CRDT operation, for-each on the list of CRDTs, and demonstrate its use in collaborative apps. Our for-each operation applies a given mutation to each element of a list, including elements inserted concurrently. This often preserves user intention in a way that would otherwise require custom CRDT algorithms. We give example applications of our for-each operation to collaborative rich-text, recipe, and slideshow editors.","sentences":["Conflict-free Replicated Data Types (CRDTs) allow collaborative access to an app's data.","We describe a novel CRDT operation, for-each on the list of CRDTs, and demonstrate its use in collaborative apps.","Our for-each operation applies a given mutation to each element of a list, including elements inserted concurrently.","This often preserves user intention in a way that would otherwise require custom CRDT algorithms.","We give example applications of our for-each operation to collaborative rich-text, recipe, and slideshow editors."],"url":"http://arxiv.org/abs/2304.03141v1"}
{"created":"2023-04-06","title":"From Saliency to DINO: Saliency-guided Vision Transformer for Few-shot Keypoint Detection","abstract":"Unlike current deep keypoint detectors that are trained to recognize limited number of body parts, few-shot keypoint detection (FSKD) attempts to localize any keypoints, including novel or base keypoints, depending on the reference samples. FSKD requires the semantically meaningful relations for keypoint similarity learning to overcome the ubiquitous noise and ambiguous local patterns. One rescue comes with vision transformer (ViT) as it captures long-range relations well. However, ViT may model irrelevant features outside of the region of interest due to the global attention matrix, thus degrading similarity learning between support and query features. In this paper, we present a novel saliency-guided vision transformer, dubbed SalViT, for few-shot keypoint detection. Our SalViT enjoys a uniquely designed masked self-attention and a morphology learner, where the former introduces saliency map as a soft mask to constrain the self-attention on foregrounds, while the latter leverages the so-called power normalization to adjust morphology of saliency map, realizing ``dynamically changing receptive field''. Moreover, as salinecy detectors add computations, we show that attentive masks of DINO transformer can replace saliency. On top of SalViT, we also investigate i) transductive FSKD that enhances keypoint representations with unlabelled data and ii) FSKD under occlusions. We show that our model performs well on five public datasets and achieves ~10% PCK higher than the normally trained model under severe occlusions.","sentences":["Unlike current deep keypoint detectors that are trained to recognize limited number of body parts, few-shot keypoint detection (FSKD) attempts to localize any keypoints, including novel or base keypoints, depending on the reference samples.","FSKD requires the semantically meaningful relations for keypoint similarity learning to overcome the ubiquitous noise and ambiguous local patterns.","One rescue comes with vision transformer (ViT) as it captures long-range relations well.","However, ViT may model irrelevant features outside of the region of interest due to the global attention matrix, thus degrading similarity learning between support and query features.","In this paper, we present a novel saliency-guided vision transformer, dubbed SalViT, for few-shot keypoint detection.","Our SalViT enjoys a uniquely designed masked self-attention and a morphology learner, where the former introduces saliency map as a soft mask to constrain the self-attention on foregrounds, while the latter leverages the so-called power normalization to adjust morphology of saliency map, realizing ``dynamically changing receptive field''.","Moreover, as salinecy detectors add computations, we show that attentive masks of DINO transformer can replace saliency.","On top of SalViT, we also investigate i) transductive FSKD that enhances keypoint representations with unlabelled data and ii) FSKD under occlusions.","We show that our model performs well on five public datasets and achieves ~10% PCK higher than the normally trained model under severe occlusions."],"url":"http://arxiv.org/abs/2304.03140v1"}
{"created":"2023-04-06","title":"$B \\rightarrow D^*$ vector, axial-vector and tensor form factors for the full $q^2$ range from lattice QCD","abstract":"We compute the complete set of SM and tensor $B_{(s)}\\to D_{(s)}^*\\ell\\bar{\\nu}$ semileptonic form factors across the full kinematic range of the decay using second generation MILC $n_f=2+1+1$ HISQ gluon field configurations and HISQ valence quarks, with the heavy-HISQ method. Lattice spacings range from $0.09\\mathrm{fm}$ to $0.044\\mathrm{fm}$ with pion masses from $\\approx 300\\mathrm{GeV}$ down to the physical value; currents are normalised nonperturbatively. Using the recent untagged $B\\to D^*\\ell\\bar{\\nu}_\\ell$ data from Belle and $B_s\\to D_s^*\\mu\\bar{\\nu}_\\mu$ from LHCb together with our form factors we determine a model independent value of $V_{cb}=0.03931(54)_\\mathrm{exp}(51)_\\mathrm{latt}\\times 10^{-3}$, in agreement with previous exclusive determinations and in tension with the most recent inclusive result at the level of $3.6\\sigma$. We also observe a $1.5\\sigma$ tension between the shape of the differential decay rates computed using our form factors and those measured by Belle. We compute a purely theoretical Standard Model value for the ratio of semitauonic and semimuonic decay rates, $R(D^*)=0.279(13)$, which we find to be closer to the recent Belle measurement and HFLAV average than theory predictions using fits to experimental differential rate data for $B\\to D^*\\ell\\bar{\\nu}_\\ell$. Determining $V_{cb}$ from our form factors and the experimental total rate for $B\\to D^*\\ell\\nu$ also gives a value in agreement with inclusive results. We compute the longitudinal polarisation fraction for the semitauonic mode, $F_L^{D^*}=0.395(17)$, which is in tension at the level of $2.2\\sigma$ with the recent Belle measurement. Our calculation combines $B\\to D^*$ and $B_s\\to D_s^*$ lattice results, and we provide an update on our previous lattice computation of the $B_s\\to D_s^*$ form factors. We also give the chiral perturbation theory needed to analyse the tensor form factors.","sentences":["We compute the complete set of SM and tensor $B_{(s)}\\to D_{(s)}^*\\ell\\bar{\\nu}$ semileptonic form factors across the full kinematic range of the decay using second generation MILC $n_f=2+1+1$ HISQ gluon field configurations and HISQ valence quarks, with the heavy-HISQ method.","Lattice spacings range from $0.09\\mathrm{fm}$ to $0.044\\mathrm{fm}$ with pion masses from $\\approx 300\\mathrm{GeV}$ down to the physical value; currents are normalised nonperturbatively.","Using the recent untagged $B\\to D^*\\ell\\bar{\\nu}_\\ell$ data from Belle and $B_s\\to D_s^*\\mu\\bar{\\nu}_\\mu$ from LHCb together with our form factors we determine a model independent value of $V_{cb}=0.03931(54)_\\mathrm{exp}(51)_\\mathrm{latt}\\times 10^{-3}$, in agreement with previous exclusive determinations and in tension with the most recent inclusive result at the level of $3.6\\sigma$. We also observe a $1.5\\sigma$ tension between the shape of the differential decay rates computed using our form factors and those measured by Belle.","We compute a purely theoretical Standard Model value for the ratio of semitauonic and semimuonic decay rates, $R(D^*)=0.279(13)$, which we find to be closer to the recent Belle measurement and HFLAV average than theory predictions using fits to experimental differential rate data for $B\\to D^*\\ell\\bar{\\nu}_\\ell$. Determining $V_{cb}$ from our form factors and the experimental total rate for $B\\to D^*\\ell\\nu$ also gives a value in agreement with inclusive results.","We compute the longitudinal polarisation fraction for the semitauonic mode, $F_L^{D^*}=0.395(17)$, which is in tension at the level of $2.2\\sigma$ with the recent Belle measurement.","Our calculation combines $B\\to D^*$ and $B_s\\to D_s^*$ lattice results, and we provide an update on our previous lattice computation of the $B_s\\to D_s^*$ form factors.","We also give the chiral perturbation theory needed to analyse the tensor form factors."],"url":"http://arxiv.org/abs/2304.03137v1"}
{"created":"2023-04-06","title":"Cascaded Calibration of Mechatronic Systems via Bayesian Inference","abstract":"Sensors in high-precision mechatronic systems require accurate calibration, which is achieved using test beds that, in turn, require even more accurate calibration. The aim of this paper is to develop a cascaded calibration method for position sensors of mechatronic systems while taking into account the variance of the calibration model of the test bed. The developed calibration method employs Gaussian Process regression to obtain a model of the position-dependent sensor inaccuracies by combining prior knowledge of the sensor with data using Bayesian inference. Monte Carlo simulations show that the developed calibration approach leads to significantly higher calibration accuracy when compared to alternative regression techniques, especially when the number of available calibration points is limited. The results indicate that more accurate calibration of position sensors is possible with fewer resources.","sentences":["Sensors in high-precision mechatronic systems require accurate calibration, which is achieved using test beds that, in turn, require even more accurate calibration.","The aim of this paper is to develop a cascaded calibration method for position sensors of mechatronic systems while taking into account the variance of the calibration model of the test bed.","The developed calibration method employs Gaussian Process regression to obtain a model of the position-dependent sensor inaccuracies by combining prior knowledge of the sensor with data using Bayesian inference.","Monte Carlo simulations show that the developed calibration approach leads to significantly higher calibration accuracy when compared to alternative regression techniques, especially when the number of available calibration points is limited.","The results indicate that more accurate calibration of position sensors is possible with fewer resources."],"url":"http://arxiv.org/abs/2304.03136v1"}
{"created":"2023-04-06","title":"Do All Asians Look the Same?: A Comparative Analysis of the East Asian Facial Color Desires using Instagram","abstract":"Selfies represent people's desires, and social media platforms like Instagram have been flooded with them. This study uses selfie data to examine how peoples' desires for ideal facial representations vary by region, particularly in East Asia. Through the analysis, we aim to refute the \"all Asians prefer identical visuals,\" which is a subset of the prevalent Western belief that \"all Asians look the same.\" Our findings, reinforced by postcolonial interpretations, dispute those assumptions. We propose a strategy for resolving the mismatch between real-world desires and the Western beauty market's views. We expect the disparity between hegemonic color schemes and the augmented skin colors shown by our results may facilitate the study of color and Asian identity.","sentences":["Selfies represent people's desires, and social media platforms like Instagram have been flooded with them.","This study uses selfie data to examine how peoples' desires for ideal facial representations vary by region, particularly in East Asia.","Through the analysis, we aim to refute the \"all Asians prefer identical visuals,\" which is a subset of the prevalent Western belief that \"all Asians look the same.\"","Our findings, reinforced by postcolonial interpretations, dispute those assumptions.","We propose a strategy for resolving the mismatch between real-world desires and the Western beauty market's views.","We expect the disparity between hegemonic color schemes and the augmented skin colors shown by our results may facilitate the study of color and Asian identity."],"url":"http://arxiv.org/abs/2304.03132v1"}
{"created":"2023-04-06","title":"Direct vs. global transition paths in Potts-like energy landscapes","abstract":"Identifying transition paths between distant regions of an energy landscape is an important goal in statistical and computational physics, with relevant applications in evolutionary biology. We here consider the case of Potts-like landscapes, in which configurations are made of a large number of categorical variables, taking A distinct values. We show that, when A $\\ge$ 3, a phase transition arises, separating a regime in which transition paths connect directly the two edge configurations, from another regime, where paths can explore the energy landscape more globally to minimize the energy. This phase transition, controlled by the elasticity of the path, is first illustrated and studied in detail on a mathematically tractable Hopfield-Potts toy model. We then show that this direct-to-global phase transition is also found in energy landscapes inferred from protein-sequence data using Restricted Boltzmann machines.","sentences":["Identifying transition paths between distant regions of an energy landscape is an important goal in statistical and computational physics, with relevant applications in evolutionary biology.","We here consider the case of Potts-like landscapes, in which configurations are made of a large number of categorical variables, taking A distinct values.","We show that, when A $\\ge$ 3, a phase transition arises, separating a regime in which transition paths connect directly the two edge configurations, from another regime, where paths can explore the energy landscape more globally to minimize the energy.","This phase transition, controlled by the elasticity of the path, is first illustrated and studied in detail on a mathematically tractable Hopfield-Potts toy model.","We then show that this direct-to-global phase transition is also found in energy landscapes inferred from protein-sequence data using Restricted Boltzmann machines."],"url":"http://arxiv.org/abs/2304.03128v1"}
{"created":"2023-04-06","title":"Statistical constraints on climate model parameters using a scalable cloud-based inference framework","abstract":"Atmospheric aerosols influence the Earth's climate, primarily by affecting cloud formation and scattering visible radiation. However, aerosol-related physical processes in climate simulations are highly uncertain. Constraining these processes could help improve model-based climate predictions. We propose a scalable statistical framework for constraining parameters in expensive climate models by comparing model outputs with observations. Using the C3.ai Suite, a cloud computing platform, we use a perturbed parameter ensemble of the UKESM1 climate model to efficiently train a surrogate model. A method for estimating a data-driven model discrepancy term is described. The strict bounds method is applied to quantify parametric uncertainty in a principled way. We demonstrate the scalability of this framework with two weeks' worth of simulated aerosol optical depth data over the South Atlantic and Central African region, written from the model every three hours and matched in time to twice-daily MODIS satellite observations. When constraining the model using real satellite observations, we establish constraints on combinations of two model parameters using much higher time-resolution outputs from the climate model than previous studies. This result suggests that, within the limits imposed by an imperfect climate model, potentially very powerful constraints may be achieved when our framework is scaled to the analysis of more observations and for longer time periods.","sentences":["Atmospheric aerosols influence the Earth's climate, primarily by affecting cloud formation and scattering visible radiation.","However, aerosol-related physical processes in climate simulations are highly uncertain.","Constraining these processes could help improve model-based climate predictions.","We propose a scalable statistical framework for constraining parameters in expensive climate models by comparing model outputs with observations.","Using the C3.ai Suite, a cloud computing platform, we use a perturbed parameter ensemble of the UKESM1 climate model to efficiently train a surrogate model.","A method for estimating a data-driven model discrepancy term is described.","The strict bounds method is applied to quantify parametric uncertainty in a principled way.","We demonstrate the scalability of this framework with two weeks' worth of simulated aerosol optical depth data over the South Atlantic and Central African region, written from the model every three hours and matched in time to twice-daily MODIS satellite observations.","When constraining the model using real satellite observations, we establish constraints on combinations of two model parameters using much higher time-resolution outputs from the climate model than previous studies.","This result suggests that, within the limits imposed by an imperfect climate model, potentially very powerful constraints may be achieved when our framework is scaled to the analysis of more observations and for longer time periods."],"url":"http://arxiv.org/abs/2304.03127v1"}
{"created":"2023-04-06","title":"Urania: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition","abstract":"Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis. However, creating a datamation is not easy. A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent. Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users. None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation. To fill this gap, we introduce Urania, an intelligent authoring tool developed to support datamation design and generation. It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language. The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences. Our system produces an animated sequence of visualizations driven by a set of low-level data actions. It supports unit visualizations, which provide a mapping from each data item to a unique visual mark. We demonstrate the effectiveness of Urania via a series of evaluations including case studies, performance validation, and a controlled user study.","sentences":["Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis.","However, creating a datamation is not easy.","A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent.","Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users.","None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation.","To fill this gap, we introduce Urania, an intelligent authoring tool developed to support datamation design and generation.","It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language.","The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences.","Our system produces an animated sequence of visualizations driven by a set of low-level data actions.","It supports unit visualizations, which provide a mapping from each data item to a unique visual mark.","We demonstrate the effectiveness of Urania via a series of evaluations including case studies, performance validation, and a controlled user study."],"url":"http://arxiv.org/abs/2304.03126v1"}
{"created":"2023-04-06","title":"Is it conceivable that neurogenesis, neural Darwinism, and species evolution could all serve as inspiration for the creation of evolutionary deep neural networks?","abstract":"Deep Neural Networks (DNNs) are built using artificial neural networks. They are part of machine learning methods that are capable of learning from data that have been used in a wide range of applications. DNNs are mainly handcrafted and they usually contain numerous layers. Research frontier has emerged that concerns automated construction of DNNs via evolutionary algorithms. This paper emphasizes the importance of what we call two-dimensional brain evolution and how it can inspire two dimensional DNN evolutionary modeling. We also highlight the connection between the dropout method which is widely-used in regularizing DNNs and neurogenesis of the brain, and how these concepts could benefit DNNs evolution.The paper concludes with several recommendations for enhancing the automatic construction of DNNs.","sentences":["Deep Neural Networks (DNNs) are built using artificial neural networks.","They are part of machine learning methods that are capable of learning from data that have been used in a wide range of applications.","DNNs are mainly handcrafted and they usually contain numerous layers.","Research frontier has emerged that concerns automated construction of DNNs via evolutionary algorithms.","This paper emphasizes the importance of what we call two-dimensional brain evolution and how it can inspire two dimensional DNN evolutionary modeling.","We also highlight the connection between the dropout method which is widely-used in regularizing DNNs and neurogenesis of the brain, and how these concepts could benefit DNNs evolution.","The paper concludes with several recommendations for enhancing the automatic construction of DNNs."],"url":"http://arxiv.org/abs/2304.03122v1"}
{"created":"2023-04-06","title":"Zero-shot Generative Model Adaptation via Image-specific Prompt Learning","abstract":"Recently, CLIP-guided image synthesis has shown appealing performance on adapting a pre-trained source-domain generator to an unseen target domain. It does not require any target-domain samples but only the textual domain labels. The training is highly efficient, e.g., a few minutes. However, existing methods still have some limitations in the quality of generated images and may suffer from the mode collapse issue. A key reason is that a fixed adaptation direction is applied for all cross-domain image pairs, which leads to identical supervision signals. To address this issue, we propose an Image-specific Prompt Learning (IPL) method, which learns specific prompt vectors for each source-domain image. This produces a more precise adaptation direction for every cross-domain image pair, endowing the target-domain generator with greatly enhanced flexibility. Qualitative and quantitative evaluations on various domains demonstrate that IPL effectively improves the quality and diversity of synthesized images and alleviates the mode collapse. Moreover, IPL is independent of the structure of the generative model, such as generative adversarial networks or diffusion models. Code is available at https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation.","sentences":["Recently, CLIP-guided image synthesis has shown appealing performance on adapting a pre-trained source-domain generator to an unseen target domain.","It does not require any target-domain samples but only the textual domain labels.","The training is highly efficient, e.g., a few minutes.","However, existing methods still have some limitations in the quality of generated images and may suffer from the mode collapse issue.","A key reason is that a fixed adaptation direction is applied for all cross-domain image pairs, which leads to identical supervision signals.","To address this issue, we propose an Image-specific Prompt Learning (IPL) method, which learns specific prompt vectors for each source-domain image.","This produces a more precise adaptation direction for every cross-domain image pair, endowing the target-domain generator with greatly enhanced flexibility.","Qualitative and quantitative evaluations on various domains demonstrate that IPL effectively improves the quality and diversity of synthesized images and alleviates the mode collapse.","Moreover, IPL is independent of the structure of the generative model, such as generative adversarial networks or diffusion models.","Code is available at https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation."],"url":"http://arxiv.org/abs/2304.03119v1"}
{"created":"2023-04-06","title":"Efficient SAGE Estimation via Causal Structure Learning","abstract":"The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features. However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose $d$-SAGE, a method that accelerates SAGE approximation. $d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations. This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations. Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values.","sentences":["The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features.","However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets.","This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions.","Thus, SAGE approximation algorithms only take a fraction of the feature sets into account.","We propose $d$-SAGE, a method that accelerates SAGE approximation.","$d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped.","To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations.","This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations.","Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values."],"url":"http://arxiv.org/abs/2304.03113v1"}
{"created":"2023-04-06","title":"Multi-task learning for tissue segmentation and tumor detection in colorectal cancer histology slides","abstract":"Automating tissue segmentation and tumor detection in histopathology images of colorectal cancer (CRC) is an enabler for faster diagnostic pathology workflows. At the same time it is a challenging task due to low availability of public annotated datasets and high variability of image appearance. The semi-supervised learning for CRC detection (SemiCOL) challenge 2023 provides partially annotated data to encourage the development of automated solutions for tissue segmentation and tumor detection. We propose a U-Net based multi-task model combined with channel-wise and image-statistics-based color augmentations, as well as test-time augmentation, as a candidate solution to the SemiCOL challenge. Our approach achieved a multi-task Dice score of .8655 (Arm 1) and .8515 (Arm 2) for tissue segmentation and AUROC of .9725 (Arm 1) and 0.9750 (Arm 2) for tumor detection on the challenge validation set. The source code for our approach is made publicly available at https://github.com/lely475/CTPLab_SemiCOL2023.","sentences":["Automating tissue segmentation and tumor detection in histopathology images of colorectal cancer (CRC) is an enabler for faster diagnostic pathology workflows.","At the same time it is a challenging task due to low availability of public annotated datasets and high variability of image appearance.","The semi-supervised learning for CRC detection (SemiCOL) challenge 2023 provides partially annotated data to encourage the development of automated solutions for tissue segmentation and tumor detection.","We propose a U-Net based multi-task model combined with channel-wise and image-statistics-based color augmentations, as well as test-time augmentation, as a candidate solution to the SemiCOL challenge.","Our approach achieved a multi-task Dice score of .8655 (Arm 1) and .8515 (Arm 2) for tissue segmentation and AUROC of .9725 (Arm 1) and 0.9750 (Arm 2) for tumor detection on the challenge validation set.","The source code for our approach is made publicly available at https://github.com/lely475/CTPLab_SemiCOL2023."],"url":"http://arxiv.org/abs/2304.03101v1"}
{"created":"2023-04-06","title":"PopulAtion Parameter Averaging (PAPA)","abstract":"Ensemble methods combine the predictions of multiple models to improve performance, but they require significantly higher computation costs at inference time. To avoid these costs, multiple neural networks can be combined into one by averaging their weights (model soups). However, this usually performs significantly worse than ensembling. Weight averaging is only beneficial when weights are similar enough (in weight or feature space) to average well but different enough to benefit from combining them. Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a method that combines the generality of ensembling with the efficiency of weight averaging. PAPA leverages a population of diverse models (trained on different data orders, augmentations, and regularizations) while occasionally (not too often, not too rarely) replacing the weights of the networks with the population average of the weights. PAPA reduces the performance gap between averaging and ensembling, increasing the average accuracy of a population of models by up to 1.1% on CIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to training independent (non-averaged) models.","sentences":["Ensemble methods combine the predictions of multiple models to improve performance, but they require significantly higher computation costs at inference time.","To avoid these costs, multiple neural networks can be combined into one by averaging their weights (model soups).","However, this usually performs significantly worse than ensembling.","Weight averaging is only beneficial when weights are similar enough (in weight or feature space) to average well but different enough to benefit from combining them.","Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): a method that combines the generality of ensembling with the efficiency of weight averaging.","PAPA leverages a population of diverse models (trained on different data orders, augmentations, and regularizations) while occasionally (not too often, not too rarely) replacing the weights of the networks with the population average of the weights.","PAPA reduces the performance gap between averaging and ensembling, increasing the average accuracy of a population of models by up to 1.1% on CIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to training independent (non-averaged) models."],"url":"http://arxiv.org/abs/2304.03094v1"}
{"created":"2023-04-06","title":"Inductive Graph Unlearning","abstract":"As a way to implement the \"right to be forgotten\" in machine learning, \\textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples. Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data. To extend machine unlearning to graph data, \\textit{GraphEraser} has been proposed. However, a critical issue is that \\textit{GraphEraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training. It is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance. Such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks. To fill this gap, we propose the \\underline{{\\bf G}}\\underline{{\\bf U}}ided \\underline{{\\bf I}}n\\underline{{\\bf D}}uctiv\\underline{{\\bf E}} Graph Unlearning framework (GUIDE). GUIDE consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation. Empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs. Generally speaking, GUIDE can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information. The code will be available here: https://github.com/Happy2Git/GUIDE.","sentences":["As a way to implement the \"right to be forgotten\" in machine learning, \\textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples.","Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data.","To extend machine unlearning to graph data, \\textit{GraphEraser} has been proposed.","However, a critical issue is that \\textit{GraphEraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training.","It is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance.","Such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks.","To fill this gap, we propose the \\underline{{\\bf G}}\\underline{{\\bf U}}ided \\underline{{\\bf I}}n\\underline{{\\bf D}}uctiv\\underline{{\\bf E}} Graph Unlearning framework (GUIDE).","GUIDE consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation.","Empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs.","Generally speaking, GUIDE can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information.","The code will be available here: https://github.com/Happy2Git/GUIDE."],"url":"http://arxiv.org/abs/2304.03093v1"}
{"created":"2023-04-06","title":"Rate Splitting for 6G Optical Wireless Networks","abstract":"This paper evaluates the performance of rate splitting (RS), a robust interference management scheme, in an optical wireless communication (OWC) network that uses infrared lasers referred to as vertical-cavity surface-emitting lasers (VCSELs) as optical transmitters. In 6G OWC, providing high spectral and energy efficiency requires advanced multiple access schemes that can serve multiple users simultaneously in a non-orthogonal fashion. In this context, RS has the potential to manage multi-user interference at high data rates compared to orthogonal transmission schemes. Simulation results show the high performance of RS compared to baseline approaches.","sentences":["This paper evaluates the performance of rate splitting (RS), a robust interference management scheme, in an optical wireless communication (OWC) network that uses infrared lasers referred to as vertical-cavity surface-emitting lasers (VCSELs) as optical transmitters.","In 6G OWC, providing high spectral and energy efficiency requires advanced multiple access schemes that can serve multiple users simultaneously in a non-orthogonal fashion.","In this context, RS has the potential to manage multi-user interference at high data rates compared to orthogonal transmission schemes.","Simulation results show the high performance of RS compared to baseline approaches."],"url":"http://arxiv.org/abs/2304.03090v1"}
{"created":"2023-04-06","title":"Offline Uncertainty Sampling in Data-driven Stochastic MPC","abstract":"In this work, we exploit an offline-sampling based strategy for the constrained data-driven predictive control of an unknown linear system subject to random measurement noise. The strategy uses only past measured, potentially noisy data in a non-parametric system representation and does not require any prior model identification. The approximation of chance constraints using uncertainty sampling leads to efficient constraint tightening. Under mild assumptions, robust recursive feasibility and closed-loop constraint satisfaction is shown. In a simulation example, we provide evidence for the improved control performance of the proposed control scheme in comparison to a purely robust data-driven predictive control approach.","sentences":["In this work, we exploit an offline-sampling based strategy for the constrained data-driven predictive control of an unknown linear system subject to random measurement noise.","The strategy uses only past measured, potentially noisy data in a non-parametric system representation and does not require any prior model identification.","The approximation of chance constraints using uncertainty sampling leads to efficient constraint tightening.","Under mild assumptions, robust recursive feasibility and closed-loop constraint satisfaction is shown.","In a simulation example, we provide evidence for the improved control performance of the proposed control scheme in comparison to a purely robust data-driven predictive control approach."],"url":"http://arxiv.org/abs/2304.03088v1"}
{"created":"2023-04-06","title":"Data-driven HVAC Control Using Symbolic Regression: Design and Implementation","abstract":"The large amount of data collected in buildings makes energy management smarter and more energy efficient. This study proposes a design and implementation methodology of data-driven heating, ventilation, and air conditioning (HVAC) control. Building thermodynamics is modeled using a symbolic regression model (SRM) built from the collected data. Additionally, an HVAC system model is also developed with a data-driven approach. A model predictive control (MPC) based HVAC scheduling is formulated with the developed models to minimize energy consumption and peak power demand and maximize thermal comfort. The performance of the proposed framework is demonstrated in the workspace in the actual campus building. The HVAC system using the proposed framework reduces the peak power by 16.1\\% compared to the widely used thermostat controller.","sentences":["The large amount of data collected in buildings makes energy management smarter and more energy efficient.","This study proposes a design and implementation methodology of data-driven heating, ventilation, and air conditioning (HVAC) control.","Building thermodynamics is modeled using a symbolic regression model (SRM) built from the collected data.","Additionally, an HVAC system model is also developed with a data-driven approach.","A model predictive control (MPC) based HVAC scheduling is formulated with the developed models to minimize energy consumption and peak power demand and maximize thermal comfort.","The performance of the proposed framework is demonstrated in the workspace in the actual campus building.","The HVAC system using the proposed framework reduces the peak power by 16.1\\% compared to the widely used thermostat controller."],"url":"http://arxiv.org/abs/2304.03078v1"}
{"created":"2023-04-06","title":"Fast QTMT Partition for VVC Intra Coding Using U-Net Framework","abstract":"Versatile Video Coding (VVC) has significantly increased encoding efficiency at the expense of numerous complex coding tools, particularly the flexible Quad-Tree plus Multi-type Tree (QTMT) block partition. This paper proposes a deep learning-based algorithm applied in fast QTMT partition for VVC intra coding. Our solution greatly reduces encoding time by early termination of less-likely intra prediction and partitions with negligible BD-BR increase. Firstly, a redesigned U-Net is recommended as the network's fundamental framework. Next, we design a Quality Parameter (QP) fusion network to regulate the effect of QPs on the partition results. Finally, we adopt a refined post-processing strategy to better balance encoding performance and complexity. Experimental results demonstrate that our solution outperforms the state-of-the-art works with a complexity reduction of 44.74% to 68.76% and a BD-BR increase of 0.60% to 2.33%.","sentences":["Versatile Video Coding (VVC) has significantly increased encoding efficiency at the expense of numerous complex coding tools, particularly the flexible Quad-Tree plus Multi-type Tree (QTMT) block partition.","This paper proposes a deep learning-based algorithm applied in fast QTMT partition for VVC intra coding.","Our solution greatly reduces encoding time by early termination of less-likely intra prediction and partitions with negligible BD-BR increase.","Firstly, a redesigned U-Net is recommended as the network's fundamental framework.","Next, we design a Quality Parameter (QP) fusion network to regulate the effect of QPs on the partition results.","Finally, we adopt a refined post-processing strategy to better balance encoding performance and complexity.","Experimental results demonstrate that our solution outperforms the state-of-the-art works with a complexity reduction of 44.74% to 68.76% and a BD-BR increase of 0.60% to 2.33%."],"url":"http://arxiv.org/abs/2304.03076v1"}
{"created":"2023-04-06","title":"Protection of Ising spin-orbit coupling in bulk misfit superconductors","abstract":"Low-dimensional materials have remarkable properties that are distinct from their bulk counterparts. A paradigmatic example is Ising superconductivity that occurs in monolayer materials such as NbSe2 which show a strong violation of the Pauli limit. In monolayers, this occurs due to a combination of broken inversion symmetry and spin-orbit coupling that locks the spins of the electrons out-of-plane. Bulk NbSe2 is centrosymmetric and is therefore not an Ising superconductor. We show that bulk misfit compound superconductors, (LaSe)1.14(NbSe2) and (LaSe)1.14(NbSe2)2, comprised of monolayers and bilayers of NbSe2, exhibit unexpected Ising protection with a Pauli-limit violation comparable to monolayer NbSe2, despite formally having inversion symmetry. We study these misfit compounds using complementary experimental methods in combination with first-principles calculations. We propose theoretical mechanisms of how the Ising protection can survive in bulk materials. We show how some of these mechanisms operate in these bulk compounds due to a concerted effect of charge-transfer, defects, reduction of interlayer hopping, and stacking. This highlights how Ising superconductivity can, unexpectedly, arise in bulk materials, and possibly enable the design of bulk superconductors that are resilient to magnetic fields.","sentences":["Low-dimensional materials have remarkable properties that are distinct from their bulk counterparts.","A paradigmatic example is Ising superconductivity that occurs in monolayer materials such as NbSe2 which show a strong violation of the Pauli limit.","In monolayers, this occurs due to a combination of broken inversion symmetry and spin-orbit coupling that locks the spins of the electrons out-of-plane.","Bulk NbSe2 is centrosymmetric and is therefore not an Ising superconductor.","We show that bulk misfit compound superconductors, (LaSe)1.14(NbSe2) and (LaSe)1.14(NbSe2)2, comprised of monolayers and bilayers of NbSe2, exhibit unexpected Ising protection with a Pauli-limit violation comparable to monolayer NbSe2, despite formally having inversion symmetry.","We study these misfit compounds using complementary experimental methods in combination with first-principles calculations.","We propose theoretical mechanisms of how the Ising protection can survive in bulk materials.","We show how some of these mechanisms operate in these bulk compounds due to a concerted effect of charge-transfer, defects, reduction of interlayer hopping, and stacking.","This highlights how Ising superconductivity can, unexpectedly, arise in bulk materials, and possibly enable the design of bulk superconductors that are resilient to magnetic fields."],"url":"http://arxiv.org/abs/2304.03074v1"}
{"created":"2023-04-06","title":"A VLT/VIMOS view of two $Planck$ multiple-cluster systems: structure and galaxy properties","abstract":"We analysed spectroscopic data obtained with VLT-VIMOS for two multiple-cluster systems, PLCKG$214.6+36.9$ and PLCKG$334.8-38.0$, discovered via their thermal Sunyaev-Zel'dovich signal by $Planck$. Combining the Optical spectroscopy, for the redshift determination, and photometric data from galaxy surveys (SDSS, WISE, DESI), we were able to study the structure of the two multiple-cluster systems, to determine their nature and the properties of their member galaxies. We found that the two systems are populated mainly with passive galaxies and that PLCKG$214.6+36.9$ consists of a pair of clusters at redshift $z = 0.445$ and a background isolated cluster at $z = 0.498$, whereas the system PLCKG$334.8-38.0$ is a chance association of three independent clusters at redshifts $z = 0.367$, $z =0.292$, and $z = 0.33$. We also find evidence for remaining star formation activity in the highest-redshift cluster of PLCKG$214.6+36.9$, at $z = 0.498$.","sentences":["We analysed spectroscopic data obtained with VLT-VIMOS for two multiple-cluster systems, PLCKG$214.6+36.9$ and PLCKG$334.8-38.0$, discovered via their thermal Sunyaev-Zel'dovich signal by $Planck$. Combining the Optical spectroscopy, for the redshift determination, and photometric data from galaxy surveys (SDSS, WISE, DESI), we were able to study the structure of the two multiple-cluster systems, to determine their nature and the properties of their member galaxies.","We found that the two systems are populated mainly with passive galaxies and that PLCKG$214.6+36.9$ consists of a pair of clusters at redshift $z = 0.445$ and a background isolated cluster at $z = 0.498$, whereas the system PLCKG$334.8-38.0$ is a chance association of three independent clusters at redshifts $z = 0.367$, $z =0.292$, and $z = 0.33$.","We also find evidence for remaining star formation activity in the highest-redshift cluster of PLCKG$214.6+36.9$, at $z = 0.498$."],"url":"http://arxiv.org/abs/2304.03058v1"}
{"created":"2023-04-06","title":"Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures","abstract":"Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data. Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients. However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness. To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge. Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products. We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets. The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks. In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs. Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks. The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs.","sentences":["Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data.","Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients.","However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness.","To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge.","Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products.","We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets.","The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks.","In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs.","Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks.","The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs."],"url":"http://arxiv.org/abs/2304.03054v1"}
{"created":"2023-04-06","title":"Fiducial and differential cross-section measurements for the vector-boson-fusion production of the Higgs boson in the $H \\rightarrow WW^{\\ast} \\rightarrow e\u03bd\u03bc\u03bd$ decay channel at 13 $\\text{TeV}$ with the ATLAS detector","abstract":"The vector-boson production cross-section for the Higgs boson decay in the $H \\rightarrow WW^{\\ast} \\rightarrow e\\nu\\mu\\nu$ channel is measured as a function of kinematic observables sensitive to the Higgs boson production and decay properties as well as integrated in a fiducial phase space. The analysis is performed using the proton--proton collision data collected by the ATLAS detector in Run 2 of the LHC at $\\sqrt{s}= 13$ $\\text{TeV}$ center-of-mass energy, corresponding to an integrated luminosity of 139 fb$^{-1}$. The opposite lepton flavor final state is studied by selecting an electron and a muon originating from a pair of $W$ bosons and compatible with the Higgs boson decay. The data are corrected for the effects of detector inefficiency and resolution, and the measurements are compared with different state-of-the-art theoretical predictions. The differential cross-sections are used to constrain anomalous interactions described by dimension-six operators in an Effective Field Theory.","sentences":["The vector-boson production cross-section for the Higgs boson decay in the $H \\rightarrow WW^{\\ast} \\rightarrow e\\nu\\mu\\nu$ channel is measured as a function of kinematic observables sensitive to the Higgs boson production and decay properties as well as integrated in a fiducial phase space.","The analysis is performed using the proton--proton collision data collected by the ATLAS detector in Run 2 of the LHC at $\\sqrt{s}= 13$ $\\text{TeV}$ center-of-mass energy, corresponding to an integrated luminosity of 139 fb$^{-1}$. The opposite lepton flavor final state is studied by selecting an electron and a muon originating from a pair of $W$ bosons and compatible with the Higgs boson decay.","The data are corrected for the effects of detector inefficiency and resolution, and the measurements are compared with different state-of-the-art theoretical predictions.","The differential cross-sections are used to constrain anomalous interactions described by dimension-six operators in an Effective Field Theory."],"url":"http://arxiv.org/abs/2304.03053v1"}
{"created":"2023-04-06","title":"Expert-Independent Generalization of Well and Seismic Data Using Machine Learning Methods for Complex Reservoirs Predicting During Early-Stage Geological Exploration","abstract":"The aim of this study is to develop and apply an autonomous approach for predicting the probability of hydrocarbon reservoirs spreading in the studied area. Autonomy means that after preparing and inputting geological-geophysical information, the influence of an expert on the algorithms is minimized. The study was made based on the 3D seismic survey data and well information on the early exploration stage of the studied field. As a result, a forecast of the probability of spatial distribution of reservoirs was made for two sets of input data: the base set and the set after reverse-calibration, and three-dimensional cubes of calibrated probabilities of belonging of the studied space to the identified classes were obtained. The approach presented in the paper allows for expert-independent generalization of geological and geophysical data, and to use this generalization for hypothesis testing and creating geological models based on a probabilistic representation of the reservoir. The quality of the probabilistic representation depends on the quality and quantity of the input data. Depending on the input data, the approach can be a useful tool for exploration and prospecting of geological objects, identifying potential resources, optimizing and designing field development.","sentences":["The aim of this study is to develop and apply an autonomous approach for predicting the probability of hydrocarbon reservoirs spreading in the studied area.","Autonomy means that after preparing and inputting geological-geophysical information, the influence of an expert on the algorithms is minimized.","The study was made based on the 3D seismic survey data and well information on the early exploration stage of the studied field.","As a result, a forecast of the probability of spatial distribution of reservoirs was made for two sets of input data: the base set and the set after reverse-calibration, and three-dimensional cubes of calibrated probabilities of belonging of the studied space to the identified classes were obtained.","The approach presented in the paper allows for expert-independent generalization of geological and geophysical data, and to use this generalization for hypothesis testing and creating geological models based on a probabilistic representation of the reservoir.","The quality of the probabilistic representation depends on the quality and quantity of the input data.","Depending on the input data, the approach can be a useful tool for exploration and prospecting of geological objects, identifying potential resources, optimizing and designing field development."],"url":"http://arxiv.org/abs/2304.03048v1"}
{"created":"2023-04-06","title":"Protected or Porous: A Comparative Analysis of Threat Detection Capability of IoT Safeguards","abstract":"Consumer Internet of Things (IoT) devices are increasingly common, from smart speakers to security cameras, in homes. Along with their benefits come potential privacy and security threats. To limit these threats a number of commercial services have become available (IoT safeguards). The safeguards claim to provide protection against IoT privacy risks and security threats. However, the effectiveness and the associated privacy risks of these safeguards remains a key open question. In this paper, we investigate the threat detection capabilities of IoT safeguards for the first time. We develop and release an approach for automated safeguards experimentation to reveal their response to common security threats and privacy risks. We perform thousands of automated experiments using popular commercial IoT safeguards when deployed in a large IoT testbed. Our results indicate not only that these devices may be ineffective in preventing risks, but also their cloud interactions and data collection operations may introduce privacy risks for the households that adopt them.","sentences":["Consumer Internet of Things (IoT) devices are increasingly common, from smart speakers to security cameras, in homes.","Along with their benefits come potential privacy and security threats.","To limit these threats a number of commercial services have become available (IoT safeguards).","The safeguards claim to provide protection against IoT privacy risks and security threats.","However, the effectiveness and the associated privacy risks of these safeguards remains a key open question.","In this paper, we investigate the threat detection capabilities of IoT safeguards for the first time.","We develop and release an approach for automated safeguards experimentation to reveal their response to common security threats and privacy risks.","We perform thousands of automated experiments using popular commercial IoT safeguards when deployed in a large IoT testbed.","Our results indicate not only that these devices may be ineffective in preventing risks, but also their cloud interactions and data collection operations may introduce privacy risks for the households that adopt them."],"url":"http://arxiv.org/abs/2304.03045v1"}
{"created":"2023-04-06","title":"Data Processing with FPGAs on Modern Architectures","abstract":"Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale. These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression). In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks. We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers. The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs. The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints.","sentences":["Trends in hardware, the prevalence of the cloud, and the rise of highly demanding applications have ushered an era of specialization that quickly changes how data is processed at scale.","These changes are likely to continue and accelerate in the next years as new technologies are adopted and deployed: smart NICs, smart storage, smart memory, disaggregated storage, disaggregated memory, specialized accelerators (GPUS, TPUs, FPGAs), and a wealth of ASICs specifically created to deal with computationally expensive tasks (e.g., cryptography or compression).","In this tutorial, we focus on data processing on FPGAs, a technology that has received less attention than, e.g., TPUs or GPUs but that is, however, increasingly being deployed in the cloud for data processing tasks due to the architectural flexibility of FPGAs, along with their ability to process data at line rate, something not possible with other types of processors or accelerators.   ","In the tutorial, we will cover what FPGAs are, their characteristics, their advantages and disadvantages, as well as examples from deployments in the industry and how they are used in various data processing tasks.","We will introduce FPGA programming with high-level languages and describe hardware and software resources available to researchers.","The tutorial includes case studies borrowed from research done in collaboration with companies that illustrate the potential of FPGAs in data processing and how software and hardware are evolving to take advantage of the possibilities offered by FPGAs.","The use cases include: (1) approximated nearest neighbor search, which is relevant to databases and machine learning, (2) remote disaggregated memory, showing how the cloud architecture is evolving and demonstrating the potential for operator offloading and line rate data processing, and (3) recommendation system as an application with tight latency constraints."],"url":"http://arxiv.org/abs/2304.03044v1"}
{"created":"2023-04-06","title":"Multi-Linear Kernel Regression and Imputation in Data Manifolds","abstract":"This paper introduces an efficient multi-linear nonparametric (kernel-based) approximation framework for data regression and imputation, and its application to dynamic magnetic-resonance imaging (dMRI). Data features are assumed to reside in or close to a smooth manifold embedded in a reproducing kernel Hilbert space. Landmark points are identified to describe concisely the point cloud of features by linear approximating patches which mimic the concept of tangent spaces to smooth manifolds. The multi-linear model effects dimensionality reduction, enables efficient computations, and extracts data patterns and their geometry without any training data or additional information. Numerical tests on dMRI data under severe under-sampling demonstrate remarkable improvements in efficiency and accuracy of the proposed approach over its predecessors, popular data modeling methods, as well as recent tensor-based and deep-image-prior schemes.","sentences":["This paper introduces an efficient multi-linear nonparametric (kernel-based) approximation framework for data regression and imputation, and its application to dynamic magnetic-resonance imaging (dMRI).","Data features are assumed to reside in or close to a smooth manifold embedded in a reproducing kernel Hilbert space.","Landmark points are identified to describe concisely the point cloud of features by linear approximating patches which mimic the concept of tangent spaces to smooth manifolds.","The multi-linear model effects dimensionality reduction, enables efficient computations, and extracts data patterns and their geometry without any training data or additional information.","Numerical tests on dMRI data under severe under-sampling demonstrate remarkable improvements in efficiency and accuracy of the proposed approach over its predecessors, popular data modeling methods, as well as recent tensor-based and deep-image-prior schemes."],"url":"http://arxiv.org/abs/2304.03041v1"}
{"created":"2023-04-06","title":"A computation of D(9) using FPGA Supercomputing","abstract":"This preprint makes the claim of having computed the $9^{th}$ Dedekind Number. This was done by building an efficient FPGA Accelerator for the core operation of the process, and parallelizing it on the Noctua 2 Supercluster at Paderborn University. The resulting value is 286386577668298411128469151667598498812366. This value can be verified in two steps. We have made the data file containing the 490M results available, each of which can be verified separately on CPU, and the whole file sums to our proposed value.","sentences":["This preprint makes the claim of having computed the $9^{th}$ Dedekind Number.","This was done by building an efficient FPGA Accelerator for the core operation of the process, and parallelizing it on the Noctua 2 Supercluster at Paderborn University.","The resulting value is 286386577668298411128469151667598498812366.","This value can be verified in two steps.","We have made the data file containing the 490M results available, each of which can be verified separately on CPU, and the whole file sums to our proposed value."],"url":"http://arxiv.org/abs/2304.03039v1"}
{"created":"2023-04-06","title":"Hall anomaly and vortex charge in Bi$_2$Sr$_2$CaCu$_2$O$_x$","abstract":"We present a systematic study of the Hall conductance in Bi$_2$Sr$_2$CaCu$_2$O$_x$ (Bi2212) thin films over a large range of doping. We find that in a large part of the phase diagram the Hall coefficient changes sign as a function of temperature in the flux-flow regime. By comparing data from many samples, we show that the sign reversal is tied to the superconducting transition and is not a result of a competing order. We then compare our data to the predictions of the Bardeen-Stephan model and show that in all samples there is an additional negative contribution to the Hall conductivity. We extract from the negative excess Hall a vortex-charge that is found to be strongly doping dependent.","sentences":["We present a systematic study of the Hall conductance in Bi$_2$Sr$_2$CaCu$_2$O$_x$ (Bi2212) thin films over a large range of doping.","We find that in a large part of the phase diagram the Hall coefficient changes sign as a function of temperature in the flux-flow regime.","By comparing data from many samples, we show that the sign reversal is tied to the superconducting transition and is not a result of a competing order.","We then compare our data to the predictions of the Bardeen-Stephan model and show that in all samples there is an additional negative contribution to the Hall conductivity.","We extract from the negative excess Hall a vortex-charge that is found to be strongly doping dependent."],"url":"http://arxiv.org/abs/2304.03028v1"}
{"created":"2023-04-06","title":"TagGPT: Large Language Models are Zero-shot Multimodal Taggers","abstract":"Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.","sentences":["Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems.","Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks.","In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion.","Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc.","Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics.","Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts.","It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want.","TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications.","We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers.","Project page: https://github.com/TencentARC/TagGPT."],"url":"http://arxiv.org/abs/2304.03022v1"}
{"created":"2023-04-06","title":"Optimal subsampling designs","abstract":"Subsampling is commonly used to overcome computational and economical bottlenecks in the analysis of finite populations and massive datasets. Existing methods are often limited in scope and use optimality criteria (e.g., A-optimality) with well-known deficiencies, such as lack of invariance to the measurement-scale of the data and parameterisation of the model. A unified theory of optimal subsampling design is still lacking. We present a theory of optimal design for general data subsampling problems, including finite population inference, parametric density estimation, and regression modelling. Our theory encompasses and generalises most existing methods in the field of optimal subdata selection based on unequal probability sampling and inverse probability weighting. We derive optimality conditions for a general class of optimality criteria, and present corresponding algorithms for finding optimal sampling schemes under Poisson and multinomial sampling designs. We present a novel class of transformation- and parameterisation-invariant linear optimality criteria which enjoy the best of two worlds: the computational tractability of A-optimality and invariance properties similar to D-optimality. The methodology is illustrated on an application in the traffic safety domain. In our experiments, the proposed invariant linear optimality criteria achieve 92-99% D-efficiency with 90-95% lower computational demand. In contrast, the A-optimality criterion has only 46% and 60% D-efficiency on two of the examples.","sentences":["Subsampling is commonly used to overcome computational and economical bottlenecks in the analysis of finite populations and massive datasets.","Existing methods are often limited in scope and use optimality criteria (e.g., A-optimality) with well-known deficiencies, such as lack of invariance to the measurement-scale of the data and parameterisation of the model.","A unified theory of optimal subsampling design is still lacking.","We present a theory of optimal design for general data subsampling problems, including finite population inference, parametric density estimation, and regression modelling.","Our theory encompasses and generalises most existing methods in the field of optimal subdata selection based on unequal probability sampling and inverse probability weighting.","We derive optimality conditions for a general class of optimality criteria, and present corresponding algorithms for finding optimal sampling schemes under Poisson and multinomial sampling designs.","We present a novel class of transformation- and parameterisation-invariant linear optimality criteria which enjoy the best of two worlds: the computational tractability of A-optimality and invariance properties similar to D-optimality.","The methodology is illustrated on an application in the traffic safety domain.","In our experiments, the proposed invariant linear optimality criteria achieve 92-99% D-efficiency with 90-95% lower computational demand.","In contrast, the A-optimality criterion has only 46% and 60% D-efficiency on two of the examples."],"url":"http://arxiv.org/abs/2304.03019v1"}
{"created":"2023-04-06","title":"Photometry of outer Solar System objects from the Dark Energy Survey I: photometric methods, light curve distributions and trans-Neptunian binaries","abstract":"We report the methods of and initial scientific inferences from the extraction of precision photometric information for the $>800$ trans-Neptunian objects (TNOs) discovered in the images of the Dark Energy Survey (DES). Scene-modelling photometry is used to obtain shot-noise-limited flux measures for each exposure of each TNO, with background sources subtracted. Comparison of double-source fits to the pixel data with single-source fits are used to identify and characterize two binary TNO systems. A Markov Chain Monte Carlo method samples the joint likelihood of the intrinsic colors of each source as well as the amplitude of its flux variation, given the time series of multiband flux measurements and their uncertainties. A catalog of these colors and light curve amplitudes $A$ is included with this publication. We show how to assign a likelihood to the distribution $q(A)$ of light curve amplitudes in any subpopulation. Using this method, we find decisive evidence (i.e. evidence ratio $<0.01$) that cold classical (CC) TNOs with absolute magnitude $6<H_r<8.2$ are more variable than the hot classical (HC) population of the same $H_r$, reinforcing theories that the former form in situ and the latter arise from a different physical population. Resonant and scattering TNOs in this $H_r$ range have variability consistent with either the HC's or CC's. DES TNOs with $H_r<6$ are seen to be decisively less variable than higher-$H_r$ members of any dynamical group, as expected. More surprising is that detached TNOs are decisively less variable than scattering TNOs, which requires them to have distinct source regions or some subsequent differential processing.","sentences":["We report the methods of and initial scientific inferences from the extraction of precision photometric information for the $>800$ trans-Neptunian objects (TNOs) discovered in the images of the Dark Energy Survey (DES).","Scene-modelling photometry is used to obtain shot-noise-limited flux measures for each exposure of each TNO, with background sources subtracted.","Comparison of double-source fits to the pixel data with single-source fits are used to identify and characterize two binary TNO systems.","A Markov Chain Monte Carlo method samples the joint likelihood of the intrinsic colors of each source as well as the amplitude of its flux variation, given the time series of multiband flux measurements and their uncertainties.","A catalog of these colors and light curve amplitudes $A$ is included with this publication.","We show how to assign a likelihood to the distribution $q(A)$ of light curve amplitudes in any subpopulation.","Using this method, we find decisive evidence (i.e. evidence ratio $<0.01$) that cold classical (CC) TNOs with absolute magnitude $6<H_r<8.2$ are more variable than the hot classical (HC) population of the same $H_r$, reinforcing theories that the former form in situ and the latter arise from a different physical population.","Resonant and scattering TNOs in this $H_r$ range have variability consistent with either the HC's or CC's.","DES TNOs with $H_r<6$ are seen to be decisively less variable than higher-$H_r$ members of any dynamical group, as expected.","More surprising is that detached TNOs are decisively less variable than scattering TNOs, which requires them to have distinct source regions or some subsequent differential processing."],"url":"http://arxiv.org/abs/2304.03017v1"}
{"created":"2023-04-06","title":"Spectral Energy Distribution profiles from AGN accretion disc in multi-gap setup","abstract":"Spectral Energy Distribution (SED) of the broad-band continuum emission from black-hole accretion discs can serve as a tool to measure parameters of the central body and constrain the geometry of the inner accretion flow. We focus on the case of an active galactic nucleus (AGN), with an accretion disc dominating the UV/optical bands. We parameterize the changes in the thermal and power-law components, which can reveal the diminution of the emissivity. To this end we explore the effects of gaps in the accretion disc and the emerging SED that can be caused by the presence of either (i) the inner, optically thin, radiatively inefficient hot flow; (ii) a secondary black hole embedded within the accretion disc; or (iii) a combination of both components. We suggest that the resulting changes in the SED of the underlying continuum can help us to understand some departures from the standard-disc scenario. We estimate that the data required for such a project must be sampled in detail over the far-UV to soft X-ray bands during the interval of about a month corresponding to the characteristic variability timescale of an AGN. Detecting a gap at intermediate radii of a few 100 gravitational radii would require quality photometry with uncertainties up to $\\sim$ 1%. The presence of the central cavity in the standard disc can be recovered in UV photometric data with an accuracy of 5% and better. We show the effect of the intrinsic reddening of the source and demonstrate when it can be disentangled.","sentences":["Spectral Energy Distribution (SED) of the broad-band continuum emission from black-hole accretion discs can serve as a tool to measure parameters of the central body and constrain the geometry of the inner accretion flow.","We focus on the case of an active galactic nucleus (AGN), with an accretion disc dominating the UV/optical bands.","We parameterize the changes in the thermal and power-law components, which can reveal the diminution of the emissivity.","To this end we explore the effects of gaps in the accretion disc and the emerging SED that can be caused by the presence of either (i) the inner, optically thin, radiatively inefficient hot flow; (ii) a secondary black hole embedded within the accretion disc; or (iii) a combination of both components.","We suggest that the resulting changes in the SED of the underlying continuum can help us to understand some departures from the standard-disc scenario.","We estimate that the data required for such a project must be sampled in detail over the far-UV to soft X-ray bands during the interval of about a month corresponding to the characteristic variability timescale of an AGN.","Detecting a gap at intermediate radii of a few 100 gravitational radii would require quality photometry with uncertainties up to $\\sim$ 1%.","The presence of the central cavity in the standard disc can be recovered in UV photometric data with an accuracy of 5% and better.","We show the effect of the intrinsic reddening of the source and demonstrate when it can be disentangled."],"url":"http://arxiv.org/abs/2304.03015v1"}
{"created":"2023-04-06","title":"Tensor Slicing and Optimization for Multicore NPUs","abstract":"Although code generation for Convolution Neural Network (CNN) models has been extensively studied, performing efficient data slicing and parallelization for highly-constrai\\-ned Multicore Neural Processor Units (NPUs) is still a challenging problem. Given the size of convolutions' input/output tensors and the small footprint of NPU on-chip memories, minimizing memory transactions while maximizing parallelism and MAC utilization are central to any effective solution. This paper proposes a TensorFlow XLA/LLVM compiler optimization pass for Multicore NPUs, called Tensor Slicing Optimization (TSO), which: (a) maximizes convolution parallelism and memory usage across NPU cores; and (b) reduces data transfers between host and NPU on-chip memories by using DRAM memory burst time estimates to guide tensor slicing. To evaluate the proposed approach, a set of experiments was performed using the NeuroMorphic Processor (NMP), a multicore NPU containing 32 RISC-V cores extended with novel CNN instructions. Experimental results show that TSO is capable of identifying the best tensor slicing that minimizes execution time for a set of CNN models. Speed-ups of up to 21.7\\% result when comparing the TSO burst-based technique to a no-burst data slicing approach. To validate the generality of the TSO approach, the algorithm was also ported to the Glow Machine Learning framework. The performance of the models were measured on both Glow and TensorFlow XLA/LLVM compilers, revealing similar results.","sentences":["Although code generation for Convolution Neural Network (CNN) models has been extensively studied, performing efficient data slicing and parallelization for highly-constrai\\-ned Multicore Neural Processor Units (NPUs) is still a challenging problem.","Given the size of convolutions' input/output tensors and the small footprint of NPU on-chip memories, minimizing memory transactions while maximizing parallelism and MAC utilization are central to any effective solution.","This paper proposes a TensorFlow XLA/LLVM compiler optimization pass for Multicore NPUs, called Tensor Slicing Optimization (TSO), which: (a) maximizes convolution parallelism and memory usage across NPU cores; and (b) reduces data transfers between host and NPU on-chip memories by using DRAM memory burst time estimates to guide tensor slicing.","To evaluate the proposed approach, a set of experiments was performed using the NeuroMorphic Processor (NMP), a multicore NPU containing 32 RISC-V cores extended with novel CNN instructions.","Experimental results show that TSO is capable of identifying the best tensor slicing that minimizes execution time for a set of CNN models.","Speed-ups of up to 21.7\\% result when comparing the TSO burst-based technique to a no-burst data slicing approach.","To validate the generality of the TSO approach, the algorithm was also ported to the Glow Machine Learning framework.","The performance of the models were measured on both Glow and TensorFlow XLA/LLVM compilers, revealing similar results."],"url":"http://arxiv.org/abs/2304.03013v1"}
{"created":"2023-04-06","title":"PointCAT: Cross-Attention Transformer for point cloud","abstract":"Transformer-based models have significantly advanced natural language processing and computer vision in recent years. However, due to the irregular and disordered structure of point cloud data, transformer-based models for 3D deep learning are still in their infancy compared to other methods. In this paper we present Point Cross-Attention Transformer (PointCAT), a novel end-to-end network architecture using cross-attentions mechanism for point cloud representing. Our approach combines multi-scale features via two seprate cross-attention transformer branches. To reduce the computational increase brought by multi-branch structure, we further introduce an efficient model for shape classification, which only process single class token of one branch as a query to calculate attention map with the other. Extensive experiments demonstrate that our method outperforms or achieves comparable performance to several approaches in shape classification, part segmentation and semantic segmentation tasks.","sentences":["Transformer-based models have significantly advanced natural language processing and computer vision in recent years.","However, due to the irregular and disordered structure of point cloud data, transformer-based models for 3D deep learning are still in their infancy compared to other methods.","In this paper we present Point Cross-Attention Transformer (PointCAT), a novel end-to-end network architecture using cross-attentions mechanism for point cloud representing.","Our approach combines multi-scale features via two seprate cross-attention transformer branches.","To reduce the computational increase brought by multi-branch structure, we further introduce an efficient model for shape classification, which only process single class token of one branch as a query to calculate attention map with the other.","Extensive experiments demonstrate that our method outperforms or achieves comparable performance to several approaches in shape classification, part segmentation and semantic segmentation tasks."],"url":"http://arxiv.org/abs/2304.03012v1"}
{"created":"2023-04-06","title":"IoT Federated Blockchain Learning at the Edge","abstract":"IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits. IoT devices are low-cost, energy-efficient, small and intelligent devices. In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge. The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy. Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained. 2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists. 3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models.","sentences":["IoT devices are sorely underutilized in the medical field, especially within machine learning for medicine, yet they offer unrivaled benefits.","IoT devices are low-cost, energy-efficient, small and intelligent devices.","In this paper, we propose a distributed federated learning framework for IoT devices, more specifically for IoMT (Internet of Medical Things), using blockchain to allow for a decentralized scheme improving privacy and efficiency over a centralized system; this allows us to move from the cloud-based architectures, that are prevalent, to the edge.","The system is designed for three paradigms: 1) Training neural networks on IoT devices to allow for collaborative training of a shared model whilst decoupling the learning from the dataset to ensure privacy.","Training is performed in an online manner simultaneously amongst all participants, allowing for the training of actual data that may not have been present in a dataset collected in the traditional way and dynamically adapt the system whilst it is being trained.","2) Training of an IoMT system in a fully private manner such as to mitigate the issue with confidentiality of medical data and to build robust, and potentially bespoke, models where not much, if any, data exists.","3) Distribution of the actual network training, something federated learning itself does not do, to allow hospitals, for example, to utilize their spare computing resources to train network models."],"url":"http://arxiv.org/abs/2304.03006v1"}
{"created":"2023-04-06","title":"Right-Handed Neutrino Dark Matter with Forbidden Annihilation","abstract":"The seesaw mechanism with three right-handed neutrinos has one as a well-motivated dark matter candidate if stable and the other two can explain baryon asymmetry via the thermal leptogenesis scenario. We explore the possibility of introducing additional particles to make the right-handed neutrino dark matter in thermal equilibrium and freeze out through a forbidden annihilation channel. Nowadays in the Universe, this forbidden channel can be reactivated by a strong gravitational potential such as the supermassive black hole in our galaxy center. The Fermi-LAT gamma ray data and dark matter relic density require this right-handed neutrino dark matter to have mass below $100\\,$GeV and the existence of an additional boson $\\phi$ that can be tested at future lepton colliders.","sentences":["The seesaw mechanism with three right-handed neutrinos has one as a well-motivated dark matter candidate if stable and the other two can explain baryon asymmetry via the thermal leptogenesis scenario.","We explore the possibility of introducing additional particles to make the right-handed neutrino dark matter in thermal equilibrium and freeze out through a forbidden annihilation channel.","Nowadays in the Universe, this forbidden channel can be reactivated by a strong gravitational potential such as the supermassive black hole in our galaxy center.","The Fermi-LAT gamma ray data and dark matter relic density require this right-handed neutrino dark matter to have mass below $100\\,$GeV and the existence of an additional boson $\\phi$ that can be tested at future lepton colliders."],"url":"http://arxiv.org/abs/2304.02997v1"}
{"created":"2023-04-06","title":"Minihalos as probes of the inflationary spectrum: accurate boost factor calculation and new CMB constraints","abstract":"Although the spectrum of primordial fluctuations has been accurately measured on scales above $\\sim 0.1~\\rm{Mpc}$, only upper limits exist on smaller scales. In this study, we investigate generic monochromatic enhancements to the $\\Lambda$CDM spectrum that trigger the collapse of ultracompact minihalos (UCMHs) well before standard structure formation. We refine previous treatments by considering a mixed population of halos with different density profiles, that should realistically arise as a consequence of late-time accretion and mergers. Assuming that dark matter (DM) can self-annihilate, we find, as expected, that UCMHs can greatly enhance the annihilation rate around recombination, significantly imprinting the cosmic microwave background (CMB) anisotropies. However, we provide additional insight on the theoretical uncertainties that currently impact that boost and which may affect late-time probes such as the 21 cm line or $\\gamma$-ray signals. We derive constraints on the primordial power spectrum on small scales using the ExoCLASS/HYREC codes and the Planck legacy data. We account for the velocity dependence of the DM annihilation cross-section ($s$- or $p$-wave), annihilation channel, the DM particle mass and the inclusion of late-time halo mergers. Our $s$-wave constraints are competitive with previous literature, excluding primordial amplitudes $A_{\\star} \\gtrsim 10^{-6.5}$ at wavenumbers $k \\sim 10^4-10^7 \\ \\rm{Mpc}^{-1}$. For the first time, we highlight that even $p$-wave processes have constraining power on the primordial spectrum for cross-sections still allowed by currently the strongest astrophysical constraints. Finally, we provide an up-to-date compilation of the most stringent limits on the primordial power spectrum across a wide range of scales.","sentences":["Although the spectrum of primordial fluctuations has been accurately measured on scales above $\\sim 0.1~\\rm{Mpc}$, only upper limits exist on smaller scales.","In this study, we investigate generic monochromatic enhancements to the $\\Lambda$CDM spectrum that trigger the collapse of ultracompact minihalos (UCMHs) well before standard structure formation.","We refine previous treatments by considering a mixed population of halos with different density profiles, that should realistically arise as a consequence of late-time accretion and mergers.","Assuming that dark matter (DM) can self-annihilate, we find, as expected, that UCMHs can greatly enhance the annihilation rate around recombination, significantly imprinting the cosmic microwave background (CMB) anisotropies.","However, we provide additional insight on the theoretical uncertainties that currently impact that boost and which may affect late-time probes such as the 21 cm line or $\\gamma$-ray signals.","We derive constraints on the primordial power spectrum on small scales using the ExoCLASS/HYREC codes and the Planck legacy data.","We account for the velocity dependence of the DM annihilation cross-section ($s$- or $p$-wave), annihilation channel, the DM particle mass and the inclusion of late-time halo mergers.","Our $s$-wave constraints are competitive with previous literature, excluding primordial amplitudes $A_{\\star} \\gtrsim 10^{-6.5}$ at wavenumbers $k \\sim 10^4-10^7 \\ \\rm{Mpc}^{-1}$.","For the first time, we highlight that even $p$-wave processes have constraining power on the primordial spectrum for cross-sections still allowed by currently the strongest astrophysical constraints.","Finally, we provide an up-to-date compilation of the most stringent limits on the primordial power spectrum across a wide range of scales."],"url":"http://arxiv.org/abs/2304.02996v1"}
{"created":"2023-04-06","title":"Natural Language Robot Programming: NLP integrated with autonomous robotic grasping","abstract":"In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks. Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database. We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone. Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot. Our results indicate that our approach has a high system usability score. The framework's dictionary can be easily extended without relying on transfer learning or large data sets. In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study.","sentences":["In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks.","Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database.","We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone.","Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot.","Our results indicate that our approach has a high system usability score.","The framework's dictionary can be easily extended without relying on transfer learning or large data sets.","In the future, we plan to compare the presented framework with different approaches of human-assisted pick-and-place tasks via a comprehensive user study."],"url":"http://arxiv.org/abs/2304.02993v1"}
{"created":"2023-04-06","title":"Leveraging Social Interactions to Detect Misinformation on Social Media","abstract":"Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-the-art models.","sentences":["Detecting misinformation threads is crucial to guarantee a healthy environment on social media.","We address the problem using the data set created during the COVID-19 pandemic.","It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source.","The models identifying unreliable threads usually rely on textual features.","But reliability is not just what is said, but by whom and to whom.","We additionally leverage on network information.","Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not.","We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework.","Keeping track of the sequence of the interactions during the time, we improve over previous state-of-the-art models."],"url":"http://arxiv.org/abs/2304.02983v1"}
{"created":"2023-04-06","title":"Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations","abstract":"In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time. The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs). We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control. Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters. We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification.","sentences":["In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time.","The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs).","We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control.","Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters.","We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification."],"url":"http://arxiv.org/abs/2304.02976v1"}
{"created":"2023-04-06","title":"Deep Long-Short Term Memory networks: Stability properties and Experimental validation","abstract":"The aim of this work is to investigate the use of Incrementally Input-to-State Stable ($\\delta$ISS) deep Long Short Term Memory networks (LSTMs) for the identification of nonlinear dynamical systems. We show that suitable sufficient conditions on the weights of the network can be leveraged to setup a training procedure able to learn provenly-$\\delta$ISS LSTM models from data. The proposed approach is tested on a real brake-by-wire apparatus to identify a model of the system from input-output experimentally collected data. Results show satisfactory modeling performances.","sentences":["The aim of this work is to investigate the use of Incrementally Input-to-State Stable ($\\delta$ISS) deep Long Short Term Memory networks (LSTMs) for the identification of nonlinear dynamical systems.","We show that suitable sufficient conditions on the weights of the network can be leveraged to setup a training procedure able to learn provenly-$\\delta$ISS LSTM models from data.","The proposed approach is tested on a real brake-by-wire apparatus to identify a model of the system from input-output experimentally collected data.","Results show satisfactory modeling performances."],"url":"http://arxiv.org/abs/2304.02975v1"}
{"created":"2023-04-06","title":"A Closer Look at Audio-Visual Semantic Segmentation","abstract":"Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries. Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object. However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set. In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks. Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks. We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+. Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set. We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy. Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models. Code and dataset will be available.","sentences":["Audio-visual segmentation (AVS) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries.","Successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object.","However, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set.","In this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks.","Our strategy, called Visual Post-production (VPO), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks.","We also refine the previously proposed AVSBench to transform it into the audio-visual semantic segmentation benchmark AVSBench-Single+.","Furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set.","We verify the validity of the VPO strategy by showing that state-of-the-art (SOTA) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy.","Then, using the proposed VPO benchmarks and AVSBench-Single+, we show that our method produces more accurate audio-visual semantic segmentation than SOTA models.","Code and dataset will be available."],"url":"http://arxiv.org/abs/2304.02970v1"}
{"created":"2023-04-06","title":"Technology-Circuit-Algorithm Tri-Design for Processing-in-Pixel-in-Memory (P2M)","abstract":"The massive amounts of data generated by camera sensors motivate data processing inside pixel arrays, i.e., at the extreme-edge. Several critical developments have fueled recent interest in the processing-in-pixel-in-memory paradigm for a wide range of visual machine intelligence tasks, including (1) advances in 3D integration technology to enable complex processing inside each pixel in a 3D integrated manner while maintaining pixel density, (2) analog processing circuit techniques for massively parallel low-energy in-pixel computations, and (3) algorithmic techniques to mitigate non-idealities associated with analog processing through hardware-aware training schemes. This article presents a comprehensive technology-circuit-algorithm landscape that connects technology capabilities, circuit design strategies, and algorithmic optimizations to power, performance, area, bandwidth reduction, and application-level accuracy metrics. We present our results using a comprehensive co-design framework incorporating hardware and algorithmic optimizations for various complex real-life visual intelligence tasks mapped onto our P2M paradigm.","sentences":["The massive amounts of data generated by camera sensors motivate data processing inside pixel arrays, i.e., at the extreme-edge.","Several critical developments have fueled recent interest in the processing-in-pixel-in-memory paradigm for a wide range of visual machine intelligence tasks, including (1) advances in 3D integration technology to enable complex processing inside each pixel in a 3D integrated manner while maintaining pixel density, (2) analog processing circuit techniques for massively parallel low-energy in-pixel computations, and (3) algorithmic techniques to mitigate non-idealities associated with analog processing through hardware-aware training schemes.","This article presents a comprehensive technology-circuit-algorithm landscape that connects technology capabilities, circuit design strategies, and algorithmic optimizations to power, performance, area, bandwidth reduction, and application-level accuracy metrics.","We present our results using a comprehensive co-design framework incorporating hardware and algorithmic optimizations for various complex real-life visual intelligence tasks mapped onto our P2M paradigm."],"url":"http://arxiv.org/abs/2304.02968v1"}
{"created":"2023-04-06","title":"Collective variables between large-scale states in turbulent convection","abstract":"The dynamics in a confined turbulent convection flow is dominated by multiple long-lived macroscopic circulation states, which are visited subsequently by the system in a Markov-type hopping process. In the present work, we analyze the short transition paths between these subsequent macroscopic system states by a data-driven learning algorithm that extracts the low-dimensional transition manifold and the related new coordinates, which we term collective variables, in the state space of the complex turbulent flow. We therefore transfer and extend concepts for conformation transitions in stochastic microscopic systems, such as in the dynamics of macromolecules, to a deterministic macroscopic flow. Our analysis is based on long-term direct numerical simulation trajectories of turbulent convection in a closed cubic cell at a Prandtl number $Pr = 0.7$ and Rayleigh numbers $Ra = 10^6$ and $10^7$ for a time lag of $10^5$ convective free-fall time units. The simulations resolve vortices and plumes of all physically relevant scales resulting in a state space spanned by more than 3.5 million degrees of freedom. The transition dynamics between the large-scale circulation states can be captured by the transition manifold analysis with only two collective variables which implies a reduction of the data dimension by a factor of more than a million. Our method demonstrates that cessations and subsequent reversals of the large-scale flow are unlikely in the present setup and thus paves the way to the development of efficient reduced-order models of the macroscopic complex nonlinear dynamical system.","sentences":["The dynamics in a confined turbulent convection flow is dominated by multiple long-lived macroscopic circulation states, which are visited subsequently by the system in a Markov-type hopping process.","In the present work, we analyze the short transition paths between these subsequent macroscopic system states by a data-driven learning algorithm that extracts the low-dimensional transition manifold and the related new coordinates, which we term collective variables, in the state space of the complex turbulent flow.","We therefore transfer and extend concepts for conformation transitions in stochastic microscopic systems, such as in the dynamics of macromolecules, to a deterministic macroscopic flow.","Our analysis is based on long-term direct numerical simulation trajectories of turbulent convection in a closed cubic cell at a Prandtl number $Pr = 0.7$ and Rayleigh numbers $Ra = 10^6$ and $10^7$ for a time lag of $10^5$ convective free-fall time units.","The simulations resolve vortices and plumes of all physically relevant scales resulting in a state space spanned by more than 3.5 million degrees of freedom.","The transition dynamics between the large-scale circulation states can be captured by the transition manifold analysis with only two collective variables which implies a reduction of the data dimension by a factor of more than a million.","Our method demonstrates that cessations and subsequent reversals of the large-scale flow are unlikely in the present setup and thus paves the way to the development of efficient reduced-order models of the macroscopic complex nonlinear dynamical system."],"url":"http://arxiv.org/abs/2304.02966v1"}
{"created":"2023-04-06","title":"Benchmarking Robustness to Text-Guided Corruptions","abstract":"This study investigates the robustness of image classifiers to text-guided corruptions. We utilize diffusion models to edit images to different domains. Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content. Thus, the corruptions will be more realistic and the comparison will be more informative. Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort. We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains. As well as introducing a new benchmark we try to investigate the robustness of different vision models. The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains. We also observe that convolutional models are more robust than transformer architectures. Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images. The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems. The code for generating the benchmark will be made available online upon publication.","sentences":["This study investigates the robustness of image classifiers to text-guided corruptions.","We utilize diffusion models to edit images to different domains.","Unlike other works that use synthetic or hand-picked data for benchmarking, we use diffusion models as they are generative models capable of learning to edit images while preserving their semantic content.","Thus, the corruptions will be more realistic and the comparison will be more informative.","Also, there is no need for manual labeling and we can create large-scale benchmarks with less effort.","We define a prompt hierarchy based on the original ImageNet hierarchy to apply edits in different domains.","As well as introducing a new benchmark we try to investigate the robustness of different vision models.","The results of this study demonstrate that the performance of image classifiers decreases significantly in different language-based corruptions and edit domains.","We also observe that convolutional models are more robust than transformer architectures.","Additionally, we see that common data augmentation techniques can improve the performance on both the original data and the edited images.","The findings of this research can help improve the design of image classifiers and contribute to the development of more robust machine learning systems.","The code for generating the benchmark will be made available online upon publication."],"url":"http://arxiv.org/abs/2304.02963v1"}
{"created":"2023-04-06","title":"The encloure method for semilinear elliptic equations with power type nonlinearities","abstract":"We use the enclosure method to detect and reconstruct unknown inclusions within a body using boundary measurements, where the governing equation is semilinear elliptic equations with the Laplacian leading term and power type nonlinearities. A significant challenge in applying the enclosure method to this nonlinear equations is constructing suitable test data. To overcome this, we incorporate an idea of higher order linearization methods to obtain approximate solutions. Additionally, by setting an appropriate indicator functional, interestingly, CGO solutions for Laplace equations can be utilized to construct test data.","sentences":["We use the enclosure method to detect and reconstruct unknown inclusions within a body using boundary measurements, where the governing equation is semilinear elliptic equations with the Laplacian leading term and power type nonlinearities.","A significant challenge in applying the enclosure method to this nonlinear equations is constructing suitable test data.","To overcome this, we incorporate an idea of higher order linearization methods to obtain approximate solutions.","Additionally, by setting an appropriate indicator functional, interestingly, CGO solutions for Laplace equations can be utilized to construct test data."],"url":"http://arxiv.org/abs/2304.02962v1"}
{"created":"2023-04-06","title":"HGCC: Enhancing Hyperbolic Graph Convolution Networks on Heterogeneous Collaborative Graph for Recommendation","abstract":"Due to the naturally power-law distributed nature of user-item interaction data in recommendation tasks, hyperbolic space modeling has recently been introduced into collaborative filtering methods. Among them, hyperbolic GCN combines the advantages of GCN and hyperbolic space and achieves a surprising performance. However, these methods only partially exploit the nature of hyperbolic space in their designs due to completely random embedding initialization and an inaccurate tangent space aggregation. In addition, the data used in these works mainly focus on user-item interaction data only, which further limits the performance of the models. In this paper, we propose a hyperbolic GCN collaborative filtering model, HGCC, which improves the existing hyperbolic GCN structure for collaborative filtering and incorporates side information. It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically. Experimental results on four real datasets show that our model is highly competitive and outperforms leading baselines, including hyperbolic GCNs. Further experiments validate the efficacy of our proposed approach and give a further explanation by the learned embedding.","sentences":["Due to the naturally power-law distributed nature of user-item interaction data in recommendation tasks, hyperbolic space modeling has recently been introduced into collaborative filtering methods.","Among them, hyperbolic GCN combines the advantages of GCN and hyperbolic space and achieves a surprising performance.","However, these methods only partially exploit the nature of hyperbolic space in their designs due to completely random embedding initialization and an inaccurate tangent space aggregation.","In addition, the data used in these works mainly focus on user-item interaction data only, which further limits the performance of the models.","In this paper, we propose a hyperbolic GCN collaborative filtering model, HGCC, which improves the existing hyperbolic GCN structure for collaborative filtering and incorporates side information.","It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically.","Experimental results on four real datasets show that our model is highly competitive and outperforms leading baselines, including hyperbolic GCNs.","Further experiments validate the efficacy of our proposed approach and give a further explanation by the learned embedding."],"url":"http://arxiv.org/abs/2304.02961v1"}
{"created":"2023-04-06","title":"When approximate design for fast homomorphic computation provides differential privacy guarantees","abstract":"While machine learning has become pervasive in as diversified fields as industry, healthcare, social networks, privacy concerns regarding the training data have gained a critical importance. In settings where several parties wish to collaboratively train a common model without jeopardizing their sensitive data, the need for a private training protocol is particularly stringent and implies to protect the data against both the model's end-users and the actors of the training phase. Differential privacy (DP) and cryptographic primitives are complementary popular countermeasures against privacy attacks. Among these cryptographic primitives, fully homomorphic encryption (FHE) offers ciphertext malleability at the cost of time-consuming operations in the homomorphic domain. In this paper, we design SHIELD, a probabilistic approximation algorithm for the argmax operator which is both fast when homomorphically executed and whose inaccuracy is used as a feature to ensure DP guarantees. Even if SHIELD could have other applications, we here focus on one setting and seamlessly integrate it in the SPEED collaborative training framework from \"SPEED: Secure, PrivatE, and Efficient Deep learning\" (Grivet S\\'ebert et al., 2021) to improve its computational efficiency. After thoroughly describing the FHE implementation of our algorithm and its DP analysis, we present experimental results. To the best of our knowledge, it is the first work in which relaxing the accuracy of an homomorphic calculation is constructively usable as a degree of freedom to achieve better FHE performances.","sentences":["While machine learning has become pervasive in as diversified fields as industry, healthcare, social networks, privacy concerns regarding the training data have gained a critical importance.","In settings where several parties wish to collaboratively train a common model without jeopardizing their sensitive data, the need for a private training protocol is particularly stringent and implies to protect the data against both the model's end-users and the actors of the training phase.","Differential privacy (DP) and cryptographic primitives are complementary popular countermeasures against privacy attacks.","Among these cryptographic primitives, fully homomorphic encryption (FHE) offers ciphertext malleability at the cost of time-consuming operations in the homomorphic domain.","In this paper, we design SHIELD, a probabilistic approximation algorithm for the argmax operator which is both fast when homomorphically executed and whose inaccuracy is used as a feature to ensure DP guarantees.","Even if SHIELD could have other applications, we here focus on one setting and seamlessly integrate it in the SPEED collaborative training framework from \"SPEED: Secure, PrivatE, and Efficient Deep learning\" (Grivet S\\'ebert et al., 2021) to improve its computational efficiency.","After thoroughly describing the FHE implementation of our algorithm and its DP analysis, we present experimental results.","To the best of our knowledge, it is the first work in which relaxing the accuracy of an homomorphic calculation is constructively usable as a degree of freedom to achieve better FHE performances."],"url":"http://arxiv.org/abs/2304.02959v1"}
{"created":"2023-04-06","title":"B meson production in Pb+Pb at 5.02 ATeV at LHC: estimating the diffusion coefficient in the infinite mass limit","abstract":"In the last decade a Quasi-Particle Model (QPM) has been developed to study charm quark dynamics in ultra-relativistic heavy-ion collisions supplying a satisfactory description of the main observables for $D$ meson and providing an estimate of the space-diffusion coefficient $D_s(T)$ from the phenomenology. In this paper, we extend the approach to bottom quarks describing their propagation in the quark-gluon plasma within an event-by-event full Boltzmann transport approach followed by a coalescence plus fragmentation hadronization. We find that QPM approach is able to correctly predict the first available data on $R_{AA}(p_T)$ and $v_{2}(p_T)$ of single-electron from B decays without any parameter modification w.r.t. the charm. We show also predictions for centralities where data are not yet available for both $v_{2}(p_T)$ and $v_{3}(p_T)$. Moreover, we discuss the significant breaking of the expected scaling of the thermalization time $\\tau_{th}$ with $M_Q/T$, discussing the evolution with mass of $D_s(T)$ to better assess the comparison to lQCD calculations. We find that at $T=T_c$ charm quark $D_s(T)$ is about a factor of 2 larger than the asymptotic value for $M \\rightarrow \\infty$, while bottom $D_s(T)$ is only a $20-25\\%$ higher. This implies a $D_{s}(T)$ which is consistent within the current uncertainty to the most recent lattice QCD calculations with dynamical quarks for $M \\rightarrow \\infty$.","sentences":["In the last decade a Quasi-Particle Model (QPM) has been developed to study charm quark dynamics in ultra-relativistic heavy-ion collisions supplying a satisfactory description of the main observables for $D$ meson and providing an estimate of the space-diffusion coefficient $D_s(T)$ from the phenomenology.","In this paper, we extend the approach to bottom quarks describing their propagation in the quark-gluon plasma within an event-by-event full Boltzmann transport approach followed by a coalescence plus fragmentation hadronization.","We find that QPM approach is able to correctly predict the first available data on $R_{AA}(p_T)$ and $v_{2}(p_T)$ of single-electron from B decays without any parameter modification w.r.t.","the charm.","We show also predictions for centralities where data are not yet available for both $v_{2}(p_T)$ and $v_{3}(p_T)$. Moreover, we discuss the significant breaking of the expected scaling of the thermalization time $\\tau_{th}$ with $M_Q/T$, discussing the evolution with mass of $D_s(T)$ to better assess the comparison to lQCD calculations.","We find that at $T=T_c$ charm quark $D_s(T)$ is about a factor of 2 larger than the asymptotic value for $M \\rightarrow \\infty$, while bottom $D_s(T)$ is only a $20-25\\%$ higher.","This implies a $D_{s}(T)$ which is consistent within the current uncertainty to the most recent lattice QCD calculations with dynamical quarks for $M \\rightarrow \\infty$."],"url":"http://arxiv.org/abs/2304.02953v1"}
{"created":"2023-04-06","title":"Gotta Assess `Em All: A Risk Analysis of Criminal Offenses Facilitated through PokemonGO","abstract":"Location-based games have come to the forefront of popularity in casual and mobile gaming over the past six years. However, there is no hard data on crimes that these games enable, ranging from assault to cyberstalking to grooming. Given these potential harms, we conduct a risk assessment and quasi-experiment on the game features of location-based games. Using PokemonGO as a case study, we identify and establish cyber-enabled stalking as the main risk event where in-game features such as an innocent function to share in-game postcards can be exploited by malicious users. Users obtain postcards that are unique to each Pokestop and represent gifts that can be shared with in-game friends. The number of postcards that each user can retain is limited, so they send the excess to their friends with items that boost their friends' game activities. The postcard often also unintentionally leaks the users' commonly visited locations to their in-game friends. We analyze these in-game features using risk assessment and identify cyber-enabled stalking as one of the main threats. We further evaluate the feasibility of this crime through a quasi-experiment. Our results show that participants' routine locations such as home and work can be reliably re-identified within days from the first gift exchange. This exploitation of a previously unconsidered in-game feature enables physical stalking of previously unknown persons which can escalate into more serious crimes. Given current data protection legislation in Europe, further preventive measures are required by Niantic to protect pseudonymized users from being re-identified by in-game features and (potentially) stalked.","sentences":["Location-based games have come to the forefront of popularity in casual and mobile gaming over the past six years.","However, there is no hard data on crimes that these games enable, ranging from assault to cyberstalking to grooming.","Given these potential harms, we conduct a risk assessment and quasi-experiment on the game features of location-based games.","Using PokemonGO as a case study, we identify and establish cyber-enabled stalking as the main risk event where in-game features such as an innocent function to share in-game postcards can be exploited by malicious users.","Users obtain postcards that are unique to each Pokestop and represent gifts that can be shared with in-game friends.","The number of postcards that each user can retain is limited, so they send the excess to their friends with items that boost their friends' game activities.","The postcard often also unintentionally leaks the users' commonly visited locations to their in-game friends.","We analyze these in-game features using risk assessment and identify cyber-enabled stalking as one of the main threats.","We further evaluate the feasibility of this crime through a quasi-experiment.","Our results show that participants' routine locations such as home and work can be reliably re-identified within days from the first gift exchange.","This exploitation of a previously unconsidered in-game feature enables physical stalking of previously unknown persons which can escalate into more serious crimes.","Given current data protection legislation in Europe, further preventive measures are required by Niantic to protect pseudonymized users from being re-identified by in-game features and (potentially) stalked."],"url":"http://arxiv.org/abs/2304.02952v1"}
{"created":"2023-04-06","title":"Load and generation time series for German federal states: Static vs. dynamic regionalization factors","abstract":"Electricity generation and demand time series often are only available on a national scale. In this contribution, we derive regionalization factors to allocate publicly available national generation and demand time series for Germany to the federal-state level. We compare two different types of regionalization approaches: Static factors are based on the regional distribution of capacities or population and GPD, whereas dynamic factors take plant-specific generation time series, regionally resolved weather patterns or compositions of different load profiles into account. We observe that dynamic regionalization factors show significant temporal variability, emphasizing the limitations of static regionalization factors for a spatio-temporally more detailed representation of power system time series.","sentences":["Electricity generation and demand time series often are only available on a national scale.","In this contribution, we derive regionalization factors to allocate publicly available national generation and demand time series for Germany to the federal-state level.","We compare two different types of regionalization approaches: Static factors are based on the regional distribution of capacities or population and GPD, whereas dynamic factors take plant-specific generation time series, regionally resolved weather patterns or compositions of different load profiles into account.","We observe that dynamic regionalization factors show significant temporal variability, emphasizing the limitations of static regionalization factors for a spatio-temporally more detailed representation of power system time series."],"url":"http://arxiv.org/abs/2304.02951v1"}
{"created":"2023-04-06","title":"Multi-view Adversarial Discriminator: Mine the Non-causal Factors for Object Detection in Unseen Domains","abstract":"Domain shift degrades the performance of object detection models in practical applications. To alleviate the influence of domain shift, plenty of previous work try to decouple and learn the domain-invariant (common) features from source domains via domain adversarial learning (DAL). However, inspired by causal mechanisms, we find that previous methods ignore the implicit insignificant non-causal factors hidden in the common features. This is mainly due to the single-view nature of DAL. In this work, we present an idea to remove non-causal factors from common features by multi-view adversarial training on source domains, because we observe that such insignificant non-causal factors may still be significant in other latent spaces (views) due to the multi-mode structure of data. To summarize, we propose a Multi-view Adversarial Discriminator (MAD) based domain generalization model, consisting of a Spurious Correlations Generator (SCG) that increases the diversity of source domain by random augmentation and a Multi-View Domain Classifier (MVDC) that maps features to multiple latent spaces, such that the non-causal factors are removed and the domain-invariant features are purified. Extensive experiments on six benchmarks show our MAD obtains state-of-the-art performance.","sentences":["Domain shift degrades the performance of object detection models in practical applications.","To alleviate the influence of domain shift, plenty of previous work try to decouple and learn the domain-invariant (common) features from source domains via domain adversarial learning (DAL).","However, inspired by causal mechanisms, we find that previous methods ignore the implicit insignificant non-causal factors hidden in the common features.","This is mainly due to the single-view nature of DAL.","In this work, we present an idea to remove non-causal factors from common features by multi-view adversarial training on source domains, because we observe that such insignificant non-causal factors may still be significant in other latent spaces (views) due to the multi-mode structure of data.","To summarize, we propose a Multi-view Adversarial Discriminator (MAD) based domain generalization model, consisting of a Spurious Correlations Generator (SCG) that increases the diversity of source domain by random augmentation and a Multi-View Domain Classifier (MVDC) that maps features to multiple latent spaces, such that the non-causal factors are removed and the domain-invariant features are purified.","Extensive experiments on six benchmarks show our MAD obtains state-of-the-art performance."],"url":"http://arxiv.org/abs/2304.02950v1"}
{"created":"2023-04-06","title":"FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead","abstract":"We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI). Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective. Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner. Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance. With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution. Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware. The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time.","sentences":["We present FengWu, an advanced data-driven global medium-range weather forecast system based on Artificial Intelligence (AI).","Different from existing data-driven weather forecast methods, FengWu solves the medium-range forecast problem from a multi-modal and multi-task perspective.","Specifically, a deep learning architecture equipped with model-specific encoder-decoders and cross-modal fusion Transformer is elaborately designed, which is learned under the supervision of an uncertainty loss to balance the optimization of different predictors in a region-adaptive manner.","Besides this, a replay buffer mechanism is introduced to improve medium-range forecast performance.","With 39-year data training based on the ERA5 reanalysis, FengWu is able to accurately reproduce the atmospheric dynamics and predict the future land and atmosphere states at 37 vertical levels on a 0.25{\\deg} latitude-longitude resolution.","Hindcasts of 6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs better than GraphCast in predicting 80\\% of the 880 reported predictands, e.g., reducing the root mean square error (RMSE) of 10-day lead global z500 prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of each iteration is merely 600ms on NVIDIA Tesla A100 hardware.","The results suggest that FengWu can significantly improve the forecast skill and extend the skillful global medium-range weather forecast out to 10.75 days lead (with ACC of z500 > 0.6) for the first time."],"url":"http://arxiv.org/abs/2304.02948v1"}
{"created":"2023-04-06","title":"Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems","abstract":"This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm. The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions. The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life. A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits. RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains. Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy.","sentences":["This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm.","The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions.","The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life.","A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits.","RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains.","Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy."],"url":"http://arxiv.org/abs/2304.02947v1"}
{"created":"2023-04-06","title":"Multi-label classification of open-ended questions with BERT","abstract":"Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases. However, answers to open-ended questions are text data which are harder to analyze. Traditionally, answers were manually classified as specified in the coding manual. Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code. However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently. This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys. We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels). We find that classification with BERT (forcing at least one label) has the smallest 0/1 loss (13.1%) among methods considered (18.9%-21.6%). As expected, it is much easier to correctly predict answer texts that correspond to a single label (7.1% loss) than those that correspond to multiple labels ($\\sim$50% loss). Because BERT predicts zero labels for only 1.5% of the answers, forcing at least one label, while recommended, ultimately does not lower the 0/1 loss by much. Our work has important implications for social scientists: 1) We have shown multi-label classification with BERT works in the German language for open-ends. 2) For mildly multi-label classification tasks, the loss now appears small enough to allow for fully automatic classification (as compared to semi-automatic approaches). 3) Multi-label classification with BERT requires only a single model. The leading competitor, ECC, iterates through individual single label predictions.","sentences":["Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases.","However, answers to open-ended questions are text data which are harder to analyze.","Traditionally, answers were manually classified as specified in the coding manual.","Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code.","However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently.","This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys.","We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels).","We find that classification with BERT (forcing at least one label) has the smallest 0/1 loss (13.1%) among methods considered (18.9%-21.6%).","As expected, it is much easier to correctly predict answer texts that correspond to a single label (7.1% loss) than those that correspond to multiple labels ($\\sim$50% loss).","Because BERT predicts zero labels for only 1.5% of the answers, forcing at least one label, while recommended, ultimately does not lower the 0/1 loss by much.","Our work has important implications for social scientists: 1) We have shown multi-label classification with BERT works in the German language for open-ends.","2) For mildly multi-label classification tasks, the loss now appears small enough to allow for fully automatic classification (as compared to semi-automatic approaches).","3) Multi-label classification with BERT requires only a single model.","The leading competitor, ECC, iterates through individual single label predictions."],"url":"http://arxiv.org/abs/2304.02945v1"}
{"created":"2023-04-06","title":"InterFormer: Real-time Interactive Image Segmentation","abstract":"Interactive image segmentation enables annotators to efficiently perform pixel-level annotation for segmentation tasks. However, the existing interactive segmentation pipeline suffers from inefficient computations of interactive models because of the following two issues. First, annotators' later click is based on models' feedback of annotators' former click. This serial interaction is unable to utilize model's parallelism capabilities. Second, the model has to repeatedly process the image, the annotator's current click, and the model's feedback of the annotator's former clicks at each step of interaction, resulting in redundant computations. For efficient computation, we propose a method named InterFormer that follows a new pipeline to address these issues. InterFormer extracts and preprocesses the computationally time-consuming part i.e. image processing from the existing process. Specifically, InterFormer employs a large vision transformer (ViT) on high-performance devices to preprocess images in parallel, and then uses a lightweight module called interactive multi-head self attention (I-MSA) for interactive segmentation. Furthermore, the I-MSA module's deployment on low-power devices extends the practical application of interactive segmentation. The I-MSA module utilizes the preprocessed features to efficiently response to the annotator inputs in real-time. The experiments on several datasets demonstrate the effectiveness of InterFormer, which outperforms previous interactive segmentation models in terms of computational efficiency and segmentation quality, achieve real-time high-quality interactive segmentation on CPU-only devices.","sentences":["Interactive image segmentation enables annotators to efficiently perform pixel-level annotation for segmentation tasks.","However, the existing interactive segmentation pipeline suffers from inefficient computations of interactive models because of the following two issues.","First, annotators' later click is based on models' feedback of annotators' former click.","This serial interaction is unable to utilize model's parallelism capabilities.","Second, the model has to repeatedly process the image, the annotator's current click, and the model's feedback of the annotator's former clicks at each step of interaction, resulting in redundant computations.","For efficient computation, we propose a method named InterFormer that follows a new pipeline to address these issues.","InterFormer extracts and preprocesses the computationally time-consuming part i.e. image processing from the existing process.","Specifically, InterFormer employs a large vision transformer (ViT) on high-performance devices to preprocess images in parallel, and then uses a lightweight module called interactive multi-head self attention (I-MSA) for interactive segmentation.","Furthermore, the I-MSA module's deployment on low-power devices extends the practical application of interactive segmentation.","The I-MSA module utilizes the preprocessed features to efficiently response to the annotator inputs in real-time.","The experiments on several datasets demonstrate the effectiveness of InterFormer, which outperforms previous interactive segmentation models in terms of computational efficiency and segmentation quality, achieve real-time high-quality interactive segmentation on CPU-only devices."],"url":"http://arxiv.org/abs/2304.02942v1"}
{"created":"2023-04-06","title":"Data-driven prediction and control for NARX systems","abstract":"We consider two problems related to control of unknown nonlinear systems: find the input which generates a given trajectory and tracking a given trajectory from a predicted one. The proposed method predicts the system future evolution directly from the available data, hence without estimating a system plant. While data-driven control problem are known and studied for linear systems, only special classes of systems are considered in the literature for the nonlinear case.","sentences":["We consider two problems related to control of unknown nonlinear systems: find the input which generates a given trajectory and tracking a given trajectory from a predicted one.","The proposed method predicts the system future evolution directly from the available data, hence without estimating a system plant.","While data-driven control problem are known and studied for linear systems, only special classes of systems are considered in the literature for the nonlinear case."],"url":"http://arxiv.org/abs/2304.02930v1"}
{"created":"2023-04-06","title":"A data-driven approach to solving a 1D inverse scattering problem","abstract":"In this paper, we extend the ROM-based approach for inverse scattering with Neumann boundary conditions, introduced by Druskin at. al. (Inverse Problems 37, 2021), to the 1D Schr{\\\"o}dinger equation with impedance (Robin) boundary conditions. We also propose a novel data-assimilation (DA) inversion method based on the ROM approach, thereby avoiding the need for a Lanczos-orthogonalization (LO) step. Furthermore, we present a detailed numerical study and comparison of the accuracy and stability of the DA and LO methods.","sentences":["In this paper, we extend the ROM-based approach for inverse scattering with Neumann boundary conditions, introduced by Druskin at.","al.","(Inverse Problems 37, 2021), to the 1D Schr{\\\"o}dinger equation with impedance (Robin) boundary conditions.","We also propose a novel data-assimilation (DA) inversion method based on the ROM approach, thereby avoiding the need for a Lanczos-orthogonalization (LO) step.","Furthermore, we present a detailed numerical study and comparison of the accuracy and stability of the DA and LO methods."],"url":"http://arxiv.org/abs/2304.02926v1"}
{"created":"2023-04-06","title":"Super-Resolving Face Image by Facial Parsing Information","abstract":"Face super-resolution is a technology that transforms a low-resolution face image into the corresponding high-resolution one. In this paper, we build a novel parsing map guided face super-resolution network which extracts the face prior (i.e., parsing map) directly from low-resolution face image for the following utilization. To exploit the extracted prior fully, a parsing map attention fusion block is carefully designed, which can not only effectively explore the information of parsing map, but also combines powerful attention mechanism. Moreover, in light of that high-resolution features contain more precise spatial information while low-resolution features provide strong contextual information, we hope to maintain and utilize these complementary information. To achieve this goal, we develop a multi-scale refine block to maintain spatial and contextual information and take advantage of multi-scale features to refine the feature representations. Experimental results demonstrate that our method outperforms the state-of-the-arts in terms of quantitative metrics and visual quality. The source codes will be available at https://github.com/wcy-cs/FishFSRNet.","sentences":["Face super-resolution is a technology that transforms a low-resolution face image into the corresponding high-resolution one.","In this paper, we build a novel parsing map guided face super-resolution network which extracts the face prior (i.e., parsing map) directly from low-resolution face image for the following utilization.","To exploit the extracted prior fully, a parsing map attention fusion block is carefully designed, which can not only effectively explore the information of parsing map, but also combines powerful attention mechanism.","Moreover, in light of that high-resolution features contain more precise spatial information while low-resolution features provide strong contextual information, we hope to maintain and utilize these complementary information.","To achieve this goal, we develop a multi-scale refine block to maintain spatial and contextual information and take advantage of multi-scale features to refine the feature representations.","Experimental results demonstrate that our method outperforms the state-of-the-arts in terms of quantitative metrics and visual quality.","The source codes will be available at https://github.com/wcy-cs/FishFSRNet."],"url":"http://arxiv.org/abs/2304.02923v1"}
{"created":"2023-04-06","title":"Efficient Audio Captioning Transformer with Patchout and Text Guidance","abstract":"Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity. Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022.","sentences":["Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip.","In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting.","The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions.","To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset.","Moreover, we propose a method to apply Mixup augmentation for AAC.","Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance.","The results show that the proposed techniques improve the performance of our system and while reducing the computational complexity.","Our proposed method received the Judges Award at the Task6A of DCASE Challenge 2022."],"url":"http://arxiv.org/abs/2304.02916v1"}
{"created":"2023-04-06","title":"Global solutions to a chemotaxis consumption model involving signal-dependent degenerate diffusion and logistic-type dampening","abstract":"This work considers the Keller-Segel consumption system \\begin{eqnarray*} \\left\\{ \\begin{array}{llll} u_t=\\Delta (u\\phi(v))+au-bu^\\gamma,\\quad &x\\in \\Omega,\\quad t>0,\\\\ v_t=\\Delta v-uv,\\quad &x\\in\\Omega,\\quad t>0 \\end{array} \\right. \\end{eqnarray*} in a smoothly bounded domain $\\Omega\\subset \\mathbb{R}^n,$ $n\\geq1$, under no-flux boundary conditions, where the parameters $a,b>0$, $\\gamma\\geq2$, and the motility function $\\phi$ suitably generalizes the prototype given by $\\phi(s)=s^\\alpha$ for all $s\\geq0$ with $\\alpha>0$.   When $\\phi$ is appropriately smooth with $\\alpha\\geq1$, it is shown that if one of the following cases holds: (i) $\\gamma>2$; (ii) $\\gamma=2$, either $n\\leq2$ or $n\\geq3$ and $b$ is sufficiently large, then for all suitably regular initial data global classical solutions can be constructed. Whereas when $\\phi$ is considered to be with rather mild regularity properties and $\\gamma=2$, for arbitrary $b>0$, this system admits at least one global weak solution in case $\\alpha>0$. In addition, if $\\phi$ is suitably smooth with $\\alpha>1$, then the above weak solutions become eventually smooth.","sentences":["This work considers the Keller-Segel consumption system \\begin{eqnarray*} \\left\\{ \\begin{array}{llll} u_t=\\Delta (u\\phi(v))+au-bu^\\gamma,\\quad &x\\in \\Omega,\\quad t>0,\\\\ v_t=\\Delta v-uv,\\quad &x\\in\\Omega,\\quad t>0 \\end{array} \\right.","\\end{eqnarray*} in a smoothly bounded domain $\\Omega\\subset \\mathbb{R}^n,$ $n\\geq1$, under no-flux boundary conditions, where the parameters $a,b>0$, $\\gamma\\geq2$, and the motility function $\\phi$ suitably generalizes the prototype given by $\\phi(s)=s^\\alpha$ for all $s\\geq0$ with $\\alpha>0$.   When $\\phi$ is appropriately smooth with $\\alpha\\geq1$, it is shown that if one of the following cases holds: (i) $\\gamma>2$; (ii) $\\gamma=2$, either $n\\leq2$ or $n\\geq3$ and $b$ is sufficiently large, then for all suitably regular initial data global classical solutions can be constructed.","Whereas when $\\phi$ is considered to be with rather mild regularity properties and $\\gamma=2$, for arbitrary $b>0$, this system admits at least one global weak solution in case $\\alpha>0$. In addition, if $\\phi$ is suitably smooth with $\\alpha>1$, then the above weak solutions become eventually smooth."],"url":"http://arxiv.org/abs/2304.02915v1"}
{"created":"2023-04-06","title":"Classification of Superstatistical Features in High Dimensions","abstract":"We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.","sentences":["We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation.","Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance.","We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters."],"url":"http://arxiv.org/abs/2304.02912v1"}
{"created":"2023-04-06","title":"A Context-Switching/Dual-Context ROM Augmented RAM using Standard 8T SRAM","abstract":"The landscape of emerging applications has been continually widening, encompassing various data-intensive applications like artificial intelligence, machine learning, secure encryption, Internet-of-Things, etc. A sustainable approach toward creating dedicated hardware platforms that can cater to multiple applications often requires the underlying hardware to context-switch or support more than one context simultaneously. This paper presents a context-switching and dual-context memory based on the standard 8T SRAM bit-cell. Specifically, we exploit the availability of multi-VT transistors by selectively choosing the read-port transistors of the 8T SRAM cell to be either high-VT or low-VT. The 8T SRAM cell is thus augmented to store ROM data (represented as the VT of the transistors constituting the read-port) while simultaneously storing RAM data. Further, we propose specific sensing methodologies such that the memory array can support RAM-only or ROM-only mode (context-switching (CS) mode) or RAM and ROM mode simultaneously (dual-context (DC) mode). Extensive Monte-Carlo simulations have verified the robustness of our proposed ROM-augmented CS/DC memory on the Globalfoundries 22nm-FDX technology node.","sentences":["The landscape of emerging applications has been continually widening, encompassing various data-intensive applications like artificial intelligence, machine learning, secure encryption, Internet-of-Things, etc.","A sustainable approach toward creating dedicated hardware platforms that can cater to multiple applications often requires the underlying hardware to context-switch or support more than one context simultaneously.","This paper presents a context-switching and dual-context memory based on the standard 8T SRAM bit-cell.","Specifically, we exploit the availability of multi-VT transistors by selectively choosing the read-port transistors of the 8T SRAM cell to be either high-VT or low-VT.","The 8T SRAM cell is thus augmented to store ROM data (represented as the VT of the transistors constituting the read-port) while simultaneously storing RAM data.","Further, we propose specific sensing methodologies such that the memory array can support RAM-only or ROM-only mode (context-switching (CS) mode) or RAM and ROM mode simultaneously (dual-context (DC) mode).","Extensive Monte-Carlo simulations have verified the robustness of our proposed ROM-augmented CS/DC memory on the Globalfoundries 22nm-FDX technology node."],"url":"http://arxiv.org/abs/2304.02908v1"}
{"created":"2023-04-06","title":"The new detection of blue straggler stars in 50 open clusters using Gaia DR3","abstract":"The particularly abundant presence of blue straggler stars (BSS) in Galactic open clusters offers favorable conditions for detailed studies on the statistical properties and the origin of the blue straggler population. With the help of Gaia DR3, the number of identified open clusters continuously increases, and the determination of star cluster members is more reliable. We performed a more thorough search for BSS in newly found open clusters based on Gaia data. We implemented a uniform membership determination for over one thousand newly identified open clusters with larger sky coverage based on the astrometric and photometric data from Gaia DR3. The membership probabilities of stars were assigned by the pyUPMASK algorithm. Then we estimated the physical parameters of these clusters by isochrone fitting on their CMDs and picked out BSS in the specific region of these CMDs. We identified 138 BSS that had not been reported before in 50 open clusters. Compared with recent catalogs that present more than 1500 BSS in 339 open clusters, our new catalog increased the number of BSS in Galactic open clusters by about 10%, and the number of open clusters with BSS by nearly 17%. In the future, more accurate abundance measurements are anticipated to better probe the origin of BSS in open clusters.","sentences":["The particularly abundant presence of blue straggler stars (BSS) in Galactic open clusters offers favorable conditions for detailed studies on the statistical properties and the origin of the blue straggler population.","With the help of Gaia DR3, the number of identified open clusters continuously increases, and the determination of star cluster members is more reliable.","We performed a more thorough search for BSS in newly found open clusters based on Gaia data.","We implemented a uniform membership determination for over one thousand newly identified open clusters with larger sky coverage based on the astrometric and photometric data from Gaia DR3.","The membership probabilities of stars were assigned by the pyUPMASK algorithm.","Then we estimated the physical parameters of these clusters by isochrone fitting on their CMDs and picked out BSS in the specific region of these CMDs.","We identified 138 BSS that had not been reported before in 50 open clusters.","Compared with recent catalogs that present more than 1500 BSS in 339 open clusters, our new catalog increased the number of BSS in Galactic open clusters by about 10%, and the number of open clusters with BSS by nearly 17%.","In the future, more accurate abundance measurements are anticipated to better probe the origin of BSS in open clusters."],"url":"http://arxiv.org/abs/2304.02907v1"}
{"created":"2023-04-06","title":"Non-thermal Dark Matter via Lepton Portal: Hubble Tension and Stellar Cooling","abstract":"We propose a new non-thermal dark matter which feebly couples to the standard model charged leptons.The feeble interactions allow it $(1)$ to freeze-in from standard model thermal bath with its relic density being a partial or a whole of the observed dark matter density and $(2)$ to radiatively decay to two photons in the dark matter mass ranges of order keV scale with lifetime larger than the age of Universe.These features make this non-thermal dark matter a realistic realization of dark matter with late-time decay as a solution to Hubble tension.We show that the $68\\%$ CL best fit value of $H_{0}=68.3~(69.6)$ km s$^{-1}$Mpc$^{-1}$ compared to CMB+BAO (+LSS) data sets.We then use complimentary stellar cooling data to place stringent constraints on the parameter space.While the universal coupling scenario is excluded, the hierarchical coupling scenario can be tested by future observations on white dwarfs after a careful look into photon annihilation, Primakoff and Bremsstrahlung emission of the dark matter in various stellar systems.The viable parameter space may be linked to anomalies in future X-ray telescopes.","sentences":["We propose a new non-thermal dark matter which feebly couples to the standard model charged leptons.","The feeble interactions allow it $(1)$ to freeze-in from standard model thermal bath with its relic density being a partial or a whole of the observed dark matter density and $(2)$ to radiatively decay to two photons in the dark matter mass ranges of order keV scale with lifetime larger than the age of Universe.","These features make this non-thermal dark matter a realistic realization of dark matter with late-time decay as a solution to Hubble tension.","We show that the $68\\%$ CL best fit value of $H_{0}=68.3~(69.6)$ km s$^{-1}$Mpc$^{-1}$ compared to CMB+BAO (+LSS) data sets.","We then use complimentary stellar cooling data to place stringent constraints on the parameter space.","While the universal coupling scenario is excluded, the hierarchical coupling scenario can be tested by future observations on white dwarfs after a careful look into photon annihilation, Primakoff and Bremsstrahlung emission of the dark matter in various stellar systems.","The viable parameter space may be linked to anomalies in future X-ray telescopes."],"url":"http://arxiv.org/abs/2304.02904v1"}
{"created":"2023-04-06","title":"LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries","abstract":"Graph streams represent data interactions in real applications. The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others. However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them. Current studies apply sketches to summarize graph streams. We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches. In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance. Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically. LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy. We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency.","sentences":["Graph streams represent data interactions in real applications.","The mining of graph streams plays an important role in network security, social network analysis, and traffic control, among others.","However, the sheer volume and high dynamics cause great challenges for efficient storage and subsequent query analysis on them.","Current studies apply sketches to summarize graph streams.","We propose LSketch that works for heterogeneous graph streams, which effectively preserves the label information carried by the streams in real scenes, thereby enriching the expressive ability of sketches.","In addition, as graph streams continue to evolve over time, edges too old may lose their practical significance.","Therefore, we introduce the sliding window model into LSketch to eliminate the expired edges automatically.","LSketch uses sub-linear storage space and can support structure based queries and time-sensitive queries with high accuracy.","We perform extensive experiments over four real datasets, demonstrating the superiority of the proposed method over state-of-the-art methods, in aspects of query accuracy and time efficiency."],"url":"http://arxiv.org/abs/2304.02897v1"}
{"created":"2023-04-06","title":"Affect as a proxy for literary mood","abstract":"We propose to use affect as a proxy for mood in literary texts. In this study, we explore the differences in computationally detecting tone versus detecting mood. Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments. We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses.","sentences":["We propose to use affect as a proxy for mood in literary texts.","In this study, we explore the differences in computationally detecting tone versus detecting mood.","Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments.","We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses."],"url":"http://arxiv.org/abs/2304.02894v1"}
{"created":"2023-04-06","title":"Object-centric Inference for Language Conditioned Placement: A Foundation Model based Approach","abstract":"We focus on the task of language-conditioned object placement, in which a robot should generate placements that satisfy all the spatial relational constraints in language instructions. Previous works based on rule-based language parsing or scene-centric visual representation have restrictions on the form of instructions and reference objects or require large amounts of training data. We propose an object-centric framework that leverages foundation models to ground the reference objects and spatial relations for placement, which is more sample efficient and generalizable. Experiments indicate that our model can achieve a 97.75% success rate of placement with only ~0.26M trainable parameters. Besides, our method generalizes better to both unseen objects and instructions. Moreover, with only 25% training data, we still outperform the top competing approach.","sentences":["We focus on the task of language-conditioned object placement, in which a robot should generate placements that satisfy all the spatial relational constraints in language instructions.","Previous works based on rule-based language parsing or scene-centric visual representation have restrictions on the form of instructions and reference objects or require large amounts of training data.","We propose an object-centric framework that leverages foundation models to ground the reference objects and spatial relations for placement, which is more sample efficient and generalizable.","Experiments indicate that our model can achieve a 97.75% success rate of placement with only ~0.26M trainable parameters.","Besides, our method generalizes better to both unseen objects and instructions.","Moreover, with only 25% training data, we still outperform the top competing approach."],"url":"http://arxiv.org/abs/2304.02893v1"}
{"created":"2023-04-06","title":"Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients","abstract":"Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees. In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise). The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective. To address the challenges, we propose FedCNI without using an additional clean proxy dataset. It includes a noise-resilient local solver and a robust global aggregator. For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples. Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy. For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods. Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments.","sentences":["Federated learning (FL) is a distributed framework for collaboratively training with privacy guarantees.","In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise).","The co-existence of label noise and class imbalance in FL's small local datasets renders conventional FL methods and noisy-label learning methods both ineffective.","To address the challenges, we propose FedCNI without using an additional clean proxy dataset.","It includes a noise-resilient local solver and a robust global aggregator.","For the local solver, we design a more robust prototypical noise detector to distinguish noisy samples.","Further to reduce the negative impact brought by the noisy samples, we devise a curriculum pseudo labeling method and a denoise Mixup training strategy.","For the global aggregator, we propose a switching re-weighted aggregation method tailored to different learning periods.","Extensive experiments demonstrate our method can substantially outperform state-of-the-art solutions in mix-heterogeneous FL environments."],"url":"http://arxiv.org/abs/2304.02892v1"}
{"created":"2023-04-06","title":"ViralVectors: Compact and Scalable Alignment-free Virome Feature Generation","abstract":"The amount of sequencing data for SARS-CoV-2 is several orders of magnitude larger than any virus. This will continue to grow geometrically for SARS-CoV-2, and other viruses, as many countries heavily finance genomic surveillance efforts. Hence, we need methods for processing large amounts of sequence data to allow for effective yet timely decision-making. Such data will come from heterogeneous sources: aligned, unaligned, or even unassembled raw nucleotide or amino acid sequencing reads pertaining to the whole genome or regions (e.g., spike) of interest. In this work, we propose \\emph{ViralVectors}, a compact feature vector generation from virome sequencing data that allows effective downstream analysis. Such generation is based on \\emph{minimizers}, a type of lightweight \"signature\" of a sequence, used traditionally in assembly and read mapping -- to our knowledge, the first use minimizers in this way. We validate our approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spike sequences (to show scalability); (b) 3K Coronaviridae spike sequences (to show robustness to more genomic variability); and (c) 4K raw WGS reads sets taken from nasal-swab PCR tests (to show the ability to process unassembled reads). Our results show that ViralVectors outperforms current benchmarks in most classification and clustering tasks.","sentences":["The amount of sequencing data for SARS-CoV-2 is several orders of magnitude larger than any virus.","This will continue to grow geometrically for SARS-CoV-2, and other viruses, as many countries heavily finance genomic surveillance efforts.","Hence, we need methods for processing large amounts of sequence data to allow for effective yet timely decision-making.","Such data will come from heterogeneous sources: aligned, unaligned, or even unassembled raw nucleotide or amino acid sequencing reads pertaining to the whole genome or regions (e.g., spike) of interest.","In this work, we propose \\emph{ViralVectors}, a compact feature vector generation from virome sequencing data that allows effective downstream analysis.","Such generation is based on \\emph{minimizers}, a type of lightweight \"signature\" of a sequence, used traditionally in assembly and read mapping -- to our knowledge, the first use minimizers in this way.","We validate our approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spike sequences (to show scalability); (b) 3K Coronaviridae spike sequences (to show robustness to more genomic variability); and (c) 4K raw WGS reads sets taken from nasal-swab PCR tests (to show the ability to process unassembled reads).","Our results show that ViralVectors outperforms current benchmarks in most classification and clustering tasks."],"url":"http://arxiv.org/abs/2304.02891v1"}
{"created":"2023-04-06","title":"Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts","abstract":"Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research. NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language. This paper adapts these models to automatically associate the ICD codes. Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed. In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association. Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results.","sentences":["Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research.","NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language.","This paper adapts these models to automatically associate the ICD codes.","Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed.","In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association.","Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\\% compared to state-of-the-art results."],"url":"http://arxiv.org/abs/2304.02886v1"}
{"created":"2023-04-06","title":"Connected and Automated Vehicles Investment and Smart Infrastructure in Tennessee Part 3: Infrastructure and Vehicular communications: From Dedicated Short-Range Communications to Cellular Vehicle-to-Everything","abstract":"This report aims to support the Tennessee Department of Transportation's decisions about vehicle and infrastructure communication technologies. The transition from Dedicated Short-Range communication (DSRC) V2X to Cellular Vehicle to Everything (C-V2X) is explored using USDOT guidance on relevant issues and presenting the results of experimentation in Tennessee and the potential pros and cons. DSRC V2X technology has been planned at traffic signal in Tennessee, e.g., 152 Roadside Units (RSUs) were planned by TDOT using DSRC V2X and Bluetooth combination units in the I-24 smart corridor. Similarly, many pilot programs and testbeds around the nation have deployed DSRC V2X technology and are now impacted by the Federal Communication Commission's (FCC) ruling on opening safety band. The implication is that DSRC V2X deployments (and future deployments) should migrate to C-V2X. Notably, dual-mode RSUs are available along with LTE C-V2X. The transition can be done by working with vendors, but surely this involves more than swapping DSRC V2X devices with LTE C-V2X devices. Complicating the migration to C-V2X is TDOT's role in traffic signal operations and maintenance, which is limited to funding and designing/construction of traffic signals, but local agencies operate and maintain signals. Hence, local agencies will work with TDOT to operate and maintain C-V2X technology. Moreover, C-V2X technologies are not widely tested-interference by unlicensed devices and channel congestion can adversely affect safety-critical applications. Given the substantial uncertainties in transitioning to these technologies, TDOT's discussion with IOOs about the operation and maintenance of C-V2X may have to wait for the resolution issues, while TDOT can invest in experimentation with dual-mode devices. Recommendations are provided about dual-mode devices, CAV data, and needed research and testing.","sentences":["This report aims to support the Tennessee Department of Transportation's decisions about vehicle and infrastructure communication technologies.","The transition from Dedicated Short-Range communication (DSRC) V2X to Cellular Vehicle to Everything (C-V2X) is explored using USDOT guidance on relevant issues and presenting the results of experimentation in Tennessee and the potential pros and cons.","DSRC V2X technology has been planned at traffic signal in Tennessee, e.g., 152 Roadside Units (RSUs) were planned by TDOT using DSRC V2X and Bluetooth combination units in the I-24 smart corridor.","Similarly, many pilot programs and testbeds around the nation have deployed DSRC V2X technology and are now impacted by the Federal Communication Commission's (FCC) ruling on opening safety band.","The implication is that DSRC V2X deployments (and future deployments) should migrate to C-V2X. Notably, dual-mode RSUs are available along with LTE C-V2X.","The transition can be done by working with vendors, but surely this involves more than swapping DSRC V2X devices with LTE C-V2X devices.","Complicating the migration to C-V2X is TDOT's role in traffic signal operations and maintenance, which is limited to funding and designing/construction of traffic signals, but local agencies operate and maintain signals.","Hence, local agencies will work with TDOT to operate and maintain C-V2X technology.","Moreover, C-V2X technologies are not widely tested-interference by unlicensed devices and channel congestion can adversely affect safety-critical applications.","Given the substantial uncertainties in transitioning to these technologies, TDOT's discussion with IOOs about the operation and maintenance of C-V2X may have to wait for the resolution issues, while TDOT can invest in experimentation with dual-mode devices.","Recommendations are provided about dual-mode devices, CAV data, and needed research and testing."],"url":"http://arxiv.org/abs/2304.02885v1"}
{"created":"2023-04-06","title":"The Westervelt--Pennes--Cattaneo model: local well-posedness and singular limit for vanishing relaxation time","abstract":"In this work, we investigate a mathematical model of nonlinear ultrasonic heating based on a coupled system of the Westervelt equation and the hyperbolic Pennes bioheat equation (Westervelt--Pennes--Cattaneo model). Using the energy method together with a fixed point argument, we prove that our model is locally well-posed and does not degenerate under a smallness assumption on the pressure data in the Westervelt equation. In addition, we perform a singular limit analysis and show that the Westervelt--Pennes--Fourier model can be seen as an approximation of the Westervelt--Pennes--Cattaneo model as the relaxation parameter tends to zero. This is done by deriving uniform bounds of the solution with respect to the relaxation parameter.","sentences":["In this work, we investigate a mathematical model of nonlinear ultrasonic heating based on a coupled system of the Westervelt equation and the hyperbolic Pennes bioheat equation (Westervelt--Pennes--Cattaneo model).","Using the energy method together with a fixed point argument, we prove that our model is locally well-posed and does not degenerate under a smallness assumption on the pressure data in the Westervelt equation.","In addition, we perform a singular limit analysis and show that the Westervelt--Pennes--Fourier model can be seen as an approximation of the Westervelt--Pennes--Cattaneo model as the relaxation parameter tends to zero.","This is done by deriving uniform bounds of the solution with respect to the relaxation parameter."],"url":"http://arxiv.org/abs/2304.02881v1"}
{"created":"2023-04-06","title":"On Elusive Observations and a Sly Companion of Comet Wirtanen (C/1956 F1)","abstract":"Noting that the extensive astrometric observations of the double comet Wirtanen (C/1956 F1) made by E. Roemer have never been published, I replicate the contents of a fortuitously discovered copy of her measurement records of the companion's offsets from the main mass in 1957-1959 and use with such data by others to refine the fragmentation solution. The sublimation-driven nongravitational acceleration is shown to essentially control the companion's motion in the orbital plane. The fragmentation parameters derived by the author in 1978 have now been improved and strong disagreement with the independent results by Roemer is noted. The revised model is employed to predict the positions of the companion on the plates exposed by Roemer on 25 September 1960, which she reported to show the principal nucleus but not the companion. At my request, these plates have now been scanned and processed at the Lowell Observatory, and the companion is found to be located at the predicted position. The images of the main mass and the companion on one of the two plates are displayed.","sentences":["Noting that the extensive astrometric observations of the double comet Wirtanen (C/1956 F1) made by E. Roemer have never been published, I replicate the contents of a fortuitously discovered copy of her measurement records of the companion's offsets from the main mass in 1957-1959 and use with such data by others to refine the fragmentation solution.","The sublimation-driven nongravitational acceleration is shown to essentially control the companion's motion in the orbital plane.","The fragmentation parameters derived by the author in 1978 have now been improved and strong disagreement with the independent results by Roemer is noted.","The revised model is employed to predict the positions of the companion on the plates exposed by Roemer on 25 September 1960, which she reported to show the principal nucleus but not the companion.","At my request, these plates have now been scanned and processed at the Lowell Observatory, and the companion is found to be located at the predicted position.","The images of the main mass and the companion on one of the two plates are displayed."],"url":"http://arxiv.org/abs/2304.02872v1"}
{"created":"2023-04-06","title":"Protecting User Privacy in Online Settings via Supervised Learning","abstract":"Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit. Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money. However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics. The problem is the sale of user data to third parties. In this work, we design an intelligent approach to online privacy protection that leverages supervised learning. By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user. In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm. The results of our evaluation demonstrate the feasibility and potential of our approach.","sentences":["Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit.","Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money.","However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics.","The problem is the sale of user data to third parties.","In this work, we design an intelligent approach to online privacy protection that leverages supervised learning.","By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user.","In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm.","The results of our evaluation demonstrate the feasibility and potential of our approach."],"url":"http://arxiv.org/abs/2304.02870v1"}
{"created":"2023-04-06","title":"MULLER: Multilayer Laplacian Resizer for Vision","abstract":"Image resizing operation is a fundamental preprocessing module in modern computer vision. Throughout the deep learning revolution, researchers have overlooked the potential of alternative resizing methods beyond the commonly used resizers that are readily available, such as nearest-neighbors, bilinear, and bicubic. The key question of our interest is whether the front-end resizer affects the performance of deep vision models? In this paper, we present an extremely lightweight multilayer Laplacian resizer with only a handful of trainable parameters, dubbed MULLER resizer. MULLER has a bandpass nature in that it learns to boost details in certain frequency subbands that benefit the downstream recognition models. We show that MULLER can be easily plugged into various training pipelines, and it effectively boosts the performance of the underlying vision task with little to no extra cost. Specifically, we select a state-of-the-art vision Transformer, MaxViT, as the baseline, and show that, if trained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhile enjoys 36% inference cost saving to achieve similar top-1 accuracy on ImageNet-1k, as compared to the standard training scheme. Notably, MULLER's performance also scales with model size and training data size such as ImageNet-21k and JFT, and it is widely applicable to multiple vision tasks, including image classification, object detection and segmentation, as well as image quality assessment.","sentences":["Image resizing operation is a fundamental preprocessing module in modern computer vision.","Throughout the deep learning revolution, researchers have overlooked the potential of alternative resizing methods beyond the commonly used resizers that are readily available, such as nearest-neighbors, bilinear, and bicubic.","The key question of our interest is whether the front-end resizer affects the performance of deep vision models?","In this paper, we present an extremely lightweight multilayer Laplacian resizer with only a handful of trainable parameters, dubbed MULLER resizer.","MULLER has a bandpass nature in that it learns to boost details in certain frequency subbands that benefit the downstream recognition models.","We show that MULLER can be easily plugged into various training pipelines, and it effectively boosts the performance of the underlying vision task with little to no extra cost.","Specifically, we select a state-of-the-art vision Transformer, MaxViT, as the baseline, and show that, if trained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhile enjoys 36% inference cost saving to achieve similar top-1 accuracy on ImageNet-1k, as compared to the standard training scheme.","Notably, MULLER's performance also scales with model size and training data size such as ImageNet-21k and JFT, and it is widely applicable to multiple vision tasks, including image classification, object detection and segmentation, as well as image quality assessment."],"url":"http://arxiv.org/abs/2304.02859v1"}
{"created":"2023-04-06","title":"A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation","abstract":"Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets. The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets. These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications.","sentences":["Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes.","Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems.","In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs).","A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review.","In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems.","We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems.","Our objective was to identify the most effective combination for improving classification performance on imbalanced datasets.","The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets.","These findings have important implications for the development of more effective approaches for handling imbalanced datasets in machine learning applications."],"url":"http://arxiv.org/abs/2304.02858v1"}
{"created":"2023-04-06","title":"Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce","abstract":"This paper aims to establish a generic multi-modal foundation model that has the scalable capability to massive downstream applications in E-commerce. Recently, large-scale vision-language pretraining approaches have achieved remarkable advances in the general domain. However, due to the significant differences between natural and product images, directly applying these frameworks for modeling image-level representations to E-commerce will be inevitably sub-optimal. To this end, we propose an instance-centric multi-modal pretraining paradigm called ECLIP in this work. In detail, we craft a decoder architecture that introduces a set of learnable instance queries to explicitly aggregate instance-level semantics. Moreover, to enable the model to focus on the desired product instance without reliance on expensive manual annotations, two specially configured pretext tasks are further proposed. Pretrained on the 100 million E-commerce-related data, ECLIP successfully extracts more generic, semantic-rich, and robust representations. Extensive experimental results show that, without further fine-tuning, ECLIP surpasses existing methods by a large margin on a broad range of downstream tasks, demonstrating the strong transferability to real-world E-commerce applications.","sentences":["This paper aims to establish a generic multi-modal foundation model that has the scalable capability to massive downstream applications in E-commerce.","Recently, large-scale vision-language pretraining approaches have achieved remarkable advances in the general domain.","However, due to the significant differences between natural and product images, directly applying these frameworks for modeling image-level representations to E-commerce will be inevitably sub-optimal.","To this end, we propose an instance-centric multi-modal pretraining paradigm called ECLIP in this work.","In detail, we craft a decoder architecture that introduces a set of learnable instance queries to explicitly aggregate instance-level semantics.","Moreover, to enable the model to focus on the desired product instance without reliance on expensive manual annotations, two specially configured pretext tasks are further proposed.","Pretrained on the 100 million E-commerce-related data, ECLIP successfully extracts more generic, semantic-rich, and robust representations.","Extensive experimental results show that, without further fine-tuning, ECLIP surpasses existing methods by a large margin on a broad range of downstream tasks, demonstrating the strong transferability to real-world E-commerce applications."],"url":"http://arxiv.org/abs/2304.02853v1"}
{"created":"2023-04-06","title":"Classification of Skin Disease Using Transfer Learning in Convolutional Neural Networks","abstract":"Automatic classification of skin disease plays an important role in healthcare especially in dermatology. Dermatologists can determine different skin diseases with the help of an android device and with the use of Artificial Intelligence. Deep learning requires a lot of time to train due to the number of sequential layers and input data involved. Powerful computer involving a Graphic Processing Unit is an ideal approach to the training process due to its parallel processing capability. This study gathered images of 7 types of skin disease prevalent in the Philippines for a skin disease classification system. There are 3400 images composed of different skin diseases like chicken pox, acne, eczema, Pityriasis rosea, psoriasis, Tinea corporis and vitiligo that was used for training and testing of different convolutional network models. This study used transfer learning to skin disease classification using pre-trained weights from different convolutional neural network models such as VGG16, VGG19, MobileNet, ResNet50, InceptionV3, Inception-ResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201 and NASNet mobile. The MobileNet model achieved the highest accuracy, 94.1% and the VGG16 model achieved the lowest accuracy, 44.1%.","sentences":["Automatic classification of skin disease plays an important role in healthcare especially in dermatology.","Dermatologists can determine different skin diseases with the help of an android device and with the use of Artificial Intelligence.","Deep learning requires a lot of time to train due to the number of sequential layers and input data involved.","Powerful computer involving a Graphic Processing Unit is an ideal approach to the training process due to its parallel processing capability.","This study gathered images of 7 types of skin disease prevalent in the Philippines for a skin disease classification system.","There are 3400 images composed of different skin diseases like chicken pox, acne, eczema, Pityriasis rosea, psoriasis, Tinea corporis and vitiligo that was used for training and testing of different convolutional network models.","This study used transfer learning to skin disease classification using pre-trained weights from different convolutional neural network models such as VGG16, VGG19, MobileNet, ResNet50, InceptionV3, Inception-ResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201 and NASNet mobile.","The MobileNet model achieved the highest accuracy, 94.1% and the VGG16 model achieved the lowest accuracy, 44.1%."],"url":"http://arxiv.org/abs/2304.02852v1"}
{"created":"2023-04-06","title":"N$_c$-mixture occupancy model","abstract":"A class of occupancy models for detection/non-detection data is proposed to relax the closure assumption of N$-$mixture models. We introduce a community parameter $c$, ranging from $0$ to $1$, which characterizes a certain portion of individuals being fixed across multiple visits. As a result, when $c$ equals $1$, the model reduces to the N$-$mixture model; this reduced model is shown to overestimate abundance when the closure assumption is not fully satisfied. Additionally, by including a zero-inflated component, the proposed model can bridge the standard occupancy model ($c=0$) and the zero-inflated N$-$mixture model ($c=1$). We then study the behavior of the estimators for the two extreme models as $c$ varies from $0$ to $1$. An interesting finding is that the zero-inflated N$-$mixture model can consistently estimate the zero-inflated probability (occupancy) as $c$ approaches $0$, but the bias can be positive, negative, or unbiased when $c>0$ depending on other parameters. We also demonstrate these results through simulation studies and data analysis.","sentences":["A class of occupancy models for detection/non-detection data is proposed to relax the closure assumption of N$-$mixture models.","We introduce a community parameter $c$, ranging from $0$ to $1$, which characterizes a certain portion of individuals being fixed across multiple visits.","As a result, when $c$ equals $1$, the model reduces to the N$-$mixture model; this reduced model is shown to overestimate abundance when the closure assumption is not fully satisfied.","Additionally, by including a zero-inflated component, the proposed model can bridge the standard occupancy model ($c=0$) and the zero-inflated N$-$mixture model ($c=1$).","We then study the behavior of the estimators for the two extreme models as $c$ varies from $0$ to $1$. An interesting finding is that the zero-inflated N$-$mixture model can consistently estimate the zero-inflated probability (occupancy) as $c$ approaches $0$, but the bias can be positive, negative, or unbiased when $c>0$ depending on other parameters.","We also demonstrate these results through simulation studies and data analysis."],"url":"http://arxiv.org/abs/2304.02851v1"}
{"created":"2023-04-06","title":"Patch-aware Batch Normalization for Improving Cross-domain Robustness","abstract":"Despite the significant success of deep learning in computer vision tasks, cross-domain tasks still present a challenge in which the model's performance will degrade when the training set and the test set follow different distributions. Most existing methods employ adversarial learning or instance normalization for achieving data augmentation to solve this task. In contrast, considering that the batch normalization (BN) layer may not be robust for unseen domains and there exist the differences between local patches of an image, we propose a novel method called patch-aware batch normalization (PBN). To be specific, we first split feature maps of a batch into non-overlapping patches along the spatial dimension, and then independently normalize each patch to jointly optimize the shared BN parameter at each iteration. By exploiting the differences between local patches of an image, our proposed PBN can effectively enhance the robustness of the model's parameters. Besides, considering the statistics from each patch may be inaccurate due to their smaller size compared to the global feature maps, we incorporate the globally accumulated statistics with the statistics from each batch to obtain the final statistics for normalizing each patch. Since the proposed PBN can replace the typical BN, it can be integrated into most existing state-of-the-art methods. Extensive experiments and analysis demonstrate the effectiveness of our PBN in multiple computer vision tasks, including classification, object detection, instance retrieval, and semantic segmentation.","sentences":["Despite the significant success of deep learning in computer vision tasks, cross-domain tasks still present a challenge in which the model's performance will degrade when the training set and the test set follow different distributions.","Most existing methods employ adversarial learning or instance normalization for achieving data augmentation to solve this task.","In contrast, considering that the batch normalization (BN) layer may not be robust for unseen domains and there exist the differences between local patches of an image, we propose a novel method called patch-aware batch normalization (PBN).","To be specific, we first split feature maps of a batch into non-overlapping patches along the spatial dimension, and then independently normalize each patch to jointly optimize the shared BN parameter at each iteration.","By exploiting the differences between local patches of an image, our proposed PBN can effectively enhance the robustness of the model's parameters.","Besides, considering the statistics from each patch may be inaccurate due to their smaller size compared to the global feature maps, we incorporate the globally accumulated statistics with the statistics from each batch to obtain the final statistics for normalizing each patch.","Since the proposed PBN can replace the typical BN, it can be integrated into most existing state-of-the-art methods.","Extensive experiments and analysis demonstrate the effectiveness of our PBN in multiple computer vision tasks, including classification, object detection, instance retrieval, and semantic segmentation."],"url":"http://arxiv.org/abs/2304.02848v1"}
{"created":"2023-04-06","title":"Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets","abstract":"Deep networks have achieved impressive results on a range of well-curated benchmark datasets. Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance. In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features. We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet. It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations. We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline.","sentences":["Deep networks have achieved impressive results on a range of well-curated benchmark datasets.","Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance.","In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features.","We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet.","It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations.","We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline."],"url":"http://arxiv.org/abs/2304.02847v1"}
{"created":"2023-04-06","title":"Synthetic Sample Selection for Generalized Zero-Shot Learning","abstract":"Generalized Zero-Shot Learning (GZSL) has emerged as a pivotal research domain in computer vision, owing to its capability to recognize objects that have not been seen during training. Despite the significant progress achieved by generative techniques in converting traditional GZSL to fully supervised learning, they tend to generate a large number of synthetic features that are often redundant, thereby increasing training time and decreasing accuracy. To address this issue, this paper proposes a novel approach for synthetic feature selection using reinforcement learning. In particular, we propose a transformer-based selector that is trained through proximal policy optimization (PPO) to select synthetic features based on the validation classification accuracy of the seen classes, which serves as a reward. The proposed method is model-agnostic and data-agnostic, making it applicable to both images and videos and versatile for diverse applications. Our experimental results demonstrate the superiority of our approach over existing feature-generating methods, yielding improved overall performance on multiple benchmarks.","sentences":["Generalized Zero-Shot Learning (GZSL) has emerged as a pivotal research domain in computer vision, owing to its capability to recognize objects that have not been seen during training.","Despite the significant progress achieved by generative techniques in converting traditional GZSL to fully supervised learning, they tend to generate a large number of synthetic features that are often redundant, thereby increasing training time and decreasing accuracy.","To address this issue, this paper proposes a novel approach for synthetic feature selection using reinforcement learning.","In particular, we propose a transformer-based selector that is trained through proximal policy optimization (PPO) to select synthetic features based on the validation classification accuracy of the seen classes, which serves as a reward.","The proposed method is model-agnostic and data-agnostic, making it applicable to both images and videos and versatile for diverse applications.","Our experimental results demonstrate the superiority of our approach over existing feature-generating methods, yielding improved overall performance on multiple benchmarks."],"url":"http://arxiv.org/abs/2304.02846v1"}
{"created":"2023-04-06","title":"A variational model for wrapped phase denoising","abstract":"In this paper, we introduce a total variation based variational model for denoising wrapped phase images. Our model improves on former methods by preserving discontinuities of the phase map and enforcing the fundamental Pythagorean trigonometric identity between the real and imaginary parts of the phase map enhancing the quality of the restored phase. The existence and uniqueness of the solution of our model is proven using standard methods. Further, we provide a fast fixed point method for finding the numerical solution and prove its convergence. Experiments on both synthetic and real patterns verify our findings.","sentences":["In this paper, we introduce a total variation based variational model for denoising wrapped phase images.","Our model improves on former methods by preserving discontinuities of the phase map and enforcing the fundamental Pythagorean trigonometric identity between the real and imaginary parts of the phase map enhancing the quality of the restored phase.","The existence and uniqueness of the solution of our model is proven using standard methods.","Further, we provide a fast fixed point method for finding the numerical solution and prove its convergence.","Experiments on both synthetic and real patterns verify our findings."],"url":"http://arxiv.org/abs/2304.02842v1"}
{"created":"2023-04-06","title":"Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation","abstract":"Unsupervised semantic segmentation is a long-standing challenge in computer vision with great significance. Spectral clustering is a theoretically grounded solution to it where the spectral embeddings for pixels are computed to construct distinct clusters. Despite recent progress in enhancing spectral clustering with powerful pre-trained models, current approaches still suffer from inefficiencies in spectral decomposition and inflexibility in applying them to the test data. This work addresses these issues by casting spectral clustering as a parametric approach that employs neural network-based eigenfunctions to produce spectral embeddings. The outputs of the neural eigenfunctions are further restricted to discrete vectors that indicate clustering assignments directly. As a result, an end-to-end NN-based paradigm of spectral clustering emerges. In practice, the neural eigenfunctions are lightweight and take the features from pre-trained models as inputs, improving training efficiency and unleashing the potential of pre-trained models for dense prediction. We conduct extensive empirical studies to validate the effectiveness of our approach and observe significant performance gains over competitive baselines on Pascal Context, Cityscapes, and ADE20K benchmarks.","sentences":["Unsupervised semantic segmentation is a long-standing challenge in computer vision with great significance.","Spectral clustering is a theoretically grounded solution to it where the spectral embeddings for pixels are computed to construct distinct clusters.","Despite recent progress in enhancing spectral clustering with powerful pre-trained models, current approaches still suffer from inefficiencies in spectral decomposition and inflexibility in applying them to the test data.","This work addresses these issues by casting spectral clustering as a parametric approach that employs neural network-based eigenfunctions to produce spectral embeddings.","The outputs of the neural eigenfunctions are further restricted to discrete vectors that indicate clustering assignments directly.","As a result, an end-to-end NN-based paradigm of spectral clustering emerges.","In practice, the neural eigenfunctions are lightweight and take the features from pre-trained models as inputs, improving training efficiency and unleashing the potential of pre-trained models for dense prediction.","We conduct extensive empirical studies to validate the effectiveness of our approach and observe significant performance gains over competitive baselines on Pascal Context, Cityscapes, and ADE20K benchmarks."],"url":"http://arxiv.org/abs/2304.02841v1"}
{"created":"2023-04-06","title":"NTK-SAP: Improving neural network pruning by aligning training dynamics","abstract":"Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent. In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well. We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP). Empirically, our method achieves better performance than all baselines on multiple datasets.","sentences":["Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory.","One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice.","Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK.","Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK.","This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart.","However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase.","We further propose to sample multiple realizations of random weights to estimate the NTK spectrum.","Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent.","In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well.","We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP).","Empirically, our method achieves better performance than all baselines on multiple datasets."],"url":"http://arxiv.org/abs/2304.02840v1"}
{"created":"2023-04-06","title":"Whose Text Is It Anyway? Exploring BigCode, Intellectual Property, and Ethics","abstract":"Intelligent or generative writing tools rely on large language models that recognize, summarize, translate, and predict content. This position paper probes the copyright interests of open data sets used to train large language models (LLMs). Our paper asks, how do LLMs trained on open data sets circumvent the copyright interests of the used data? We start by defining software copyright and tracing its history. We rely on GitHub Copilot as a modern case study challenging software copyright. Our conclusion outlines obstacles that generative writing assistants create for copyright, and offers a practical road map for copyright analysis for developers, software law experts, and general users to consider in the context of intelligent LLM-powered writing tools.","sentences":["Intelligent or generative writing tools rely on large language models that recognize, summarize, translate, and predict content.","This position paper probes the copyright interests of open data sets used to train large language models (LLMs).","Our paper asks, how do LLMs trained on open data sets circumvent the copyright interests of the used data?","We start by defining software copyright and tracing its history.","We rely on GitHub Copilot as a modern case study challenging software copyright.","Our conclusion outlines obstacles that generative writing assistants create for copyright, and offers a practical road map for copyright analysis for developers, software law experts, and general users to consider in the context of intelligent LLM-powered writing tools."],"url":"http://arxiv.org/abs/2304.02839v1"}
{"created":"2023-04-06","title":"GIF: A General Graph Unlearning Strategy via Influence Function","abstract":"With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention. However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning. We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature. Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data. The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency. Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism. We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency. Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}.","sentences":["With the greater emphasis on privacy and security in our society, the problem of graph unlearning -- revoking the influence of specific data on the trained GNN model, is drawing increasing attention.","However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs.   ","In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning.","We first present a unified problem formulation of diverse graph unlearning tasks \\wrt node, edge, and feature.","Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a $\\epsilon$-mass perturbation in deleted data.","The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency.","Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism.","We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency.","Our implementations are available at \\url{https://github.com/wujcan/GIF-torch/}."],"url":"http://arxiv.org/abs/2304.02835v1"}
{"created":"2023-04-06","title":"Probing the Purview of Neural Networks via Gradient Analysis","abstract":"We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference. The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data. We define purview as the additional capacity necessary to characterize inference samples that differ from the training data. To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately. To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels. We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features. We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples. Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.","sentences":["We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference.","The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data.","We define purview as the additional capacity necessary to characterize inference samples that differ from the training data.","To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately.","To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels.","We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features.","We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and corrupted samples.","Our approach requires no hyperparameter tuning or additional data processing and outperforms state-of-the-art methods by up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively."],"url":"http://arxiv.org/abs/2304.02834v1"}
{"created":"2023-04-06","title":"Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing","abstract":"In the traditional vehicular network, computing tasks generated by the vehicles are usually uploaded to the cloud for processing. However, since task offloading toward the cloud will cause a large delay, vehicular edge computing (VEC) is introduced to avoid such a problem and improve the whole system performance, where a roadside unit (RSU) with certain computing capability is used to process the data of vehicles as an edge entity. Owing to the privacy and security issues, vehicles are reluctant to upload local data directly to the RSU, and thus federated learning (FL) becomes a promising technology for some machine learning tasks in VEC, where vehicles only need to upload the local model hyperparameters instead of transferring their local data to the nearby RSU. Furthermore, as vehicles have different local training time due to various sizes of local data and their different computing capabilities, asynchronous federated learning (AFL) is employed to facilitate the RSU to update the global model immediately after receiving a local model to reduce the aggregation delay. However, in AFL of VEC, different vehicles may have different impact on the global model updating because of their various local training delay, transmission delay and local data sizes. Also, if there are bad nodes among the vehicles, it will affect the global aggregation quality at the RSU. To solve the above problem, we shall propose a deep reinforcement learning (DRL) based vehicle selection scheme to improve the accuracy of the global model in AFL of vehicular network. In the scheme, we present the model including the state, action and reward in the DRL based to the specific problem. Simulation results demonstrate our scheme can effectively remove the bad nodes and improve the aggregation accuracy of the global model.","sentences":["In the traditional vehicular network, computing tasks generated by the vehicles are usually uploaded to the cloud for processing.","However, since task offloading toward the cloud will cause a large delay, vehicular edge computing (VEC) is introduced to avoid such a problem and improve the whole system performance, where a roadside unit (RSU) with certain computing capability is used to process the data of vehicles as an edge entity.","Owing to the privacy and security issues, vehicles are reluctant to upload local data directly to the RSU, and thus federated learning (FL) becomes a promising technology for some machine learning tasks in VEC, where vehicles only need to upload the local model hyperparameters instead of transferring their local data to the nearby RSU.","Furthermore, as vehicles have different local training time due to various sizes of local data and their different computing capabilities, asynchronous federated learning (AFL) is employed to facilitate the RSU to update the global model immediately after receiving a local model to reduce the aggregation delay.","However, in AFL of VEC, different vehicles may have different impact on the global model updating because of their various local training delay, transmission delay and local data sizes.","Also, if there are bad nodes among the vehicles, it will affect the global aggregation quality at the RSU.","To solve the above problem, we shall propose a deep reinforcement learning (DRL) based vehicle selection scheme to improve the accuracy of the global model in AFL of vehicular network.","In the scheme, we present the model including the state, action and reward in the DRL based to the specific problem.","Simulation results demonstrate our scheme can effectively remove the bad nodes and improve the aggregation accuracy of the global model."],"url":"http://arxiv.org/abs/2304.02832v1"}
{"created":"2023-04-06","title":"Electric charge and strangeness-dependent directed flow splitting of produced quarks in Au+Au collisions","abstract":"We report directed flow ($v_1$) of multistrange baryons ($\\Xi$ and $\\Omega$) and improved $v_1$ data for $K^{-}$, $\\bar{p}$, $\\bar{\\Lambda}$ and $\\phi$ in Au+Au collisions at $\\sqrt{s_{\\mathrm{NN}}}=$27 and 200 GeV from the STAR at the Relativistic Heavy Ion Collider (RHIC). We focus on particles whose constituent quarks are not transported from beam rapidity rather produced in the collisions. In midcentral collisions, we observe a coalescence sum rule for hadron combinations with identical quark content and a difference (``splitting'') in the slope of $v_1$ vs. rapidity for combinations having nonidentical quark content. The splitting strength appears to increase with the electric charge difference and strangeness content difference of the constituent quarks in the combinations, consistent with an electromagnetic effect. The peripheral collision statistics are insufficient to draw firm conclusions.","sentences":["We report directed flow ($v_1$) of multistrange baryons ($\\Xi$ and $\\Omega$) and improved $v_1$ data for $K^{-}$, $\\bar{p}$, $\\bar{\\Lambda}$ and $\\phi$ in Au+Au collisions at $\\sqrt{s_{\\mathrm{NN}}}=$27 and 200 GeV from the STAR at the Relativistic Heavy Ion Collider (RHIC).","We focus on particles whose constituent quarks are not transported from beam rapidity rather produced in the collisions.","In midcentral collisions, we observe a coalescence sum rule for hadron combinations with identical quark content and a difference (``splitting'') in the slope of $v_1$ vs. rapidity for combinations having nonidentical quark content.","The splitting strength appears to increase with the electric charge difference and strangeness content difference of the constituent quarks in the combinations, consistent with an electromagnetic effect.","The peripheral collision statistics are insufficient to draw firm conclusions."],"url":"http://arxiv.org/abs/2304.02831v1"}
{"created":"2023-04-06","title":"Uncurated Image-Text Datasets: Shedding Light on Demographic Bias","abstract":"The increasing tendency to collect large and uncurated datasets to train vision-and-language models has raised concerns about fair representations. It is known that even small but manually annotated datasets, such as MSCOCO, are affected by societal bias. This problem, far from being solved, may be getting worse with data crawled from the Internet without much control. In addition, the lack of tools to analyze societal bias in big collections of images makes addressing the problem extremely challenging. Our first contribution is to annotate part of the Google Conceptual Captions dataset, widely used for training vision-and-language models, with four demographic and two contextual attributes. Our second contribution is to conduct a comprehensive analysis of the annotations, focusing on how different demographic groups are represented. Our last contribution lies in evaluating three prevailing vision-and-language tasks: image captioning, text-image CLIP embeddings, and text-to-image generation, showing that societal bias is a persistent problem in all of them.","sentences":["The increasing tendency to collect large and uncurated datasets to train vision-and-language models has raised concerns about fair representations.","It is known that even small but manually annotated datasets, such as MSCOCO, are affected by societal bias.","This problem, far from being solved, may be getting worse with data crawled from the Internet without much control.","In addition, the lack of tools to analyze societal bias in big collections of images makes addressing the problem extremely challenging.","Our first contribution is to annotate part of the Google Conceptual Captions dataset, widely used for training vision-and-language models, with four demographic and two contextual attributes.","Our second contribution is to conduct a comprehensive analysis of the annotations, focusing on how different demographic groups are represented.","Our last contribution lies in evaluating three prevailing vision-and-language tasks: image captioning, text-image CLIP embeddings, and text-to-image generation, showing that societal bias is a persistent problem in all of them."],"url":"http://arxiv.org/abs/2304.02828v1"}
{"created":"2023-04-06","title":"DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model","abstract":"The increasing demand for high-quality 3D content creation has motivated the development of automated methods for creating 3D object models from a single image and/or from a text prompt. However, the reconstructed 3D objects using state-of-the-art image-to-3D methods still exhibit low correspondence to the given image and low multi-view consistency. Recent state-of-the-art text-to-3D methods are also limited, yielding 3D samples with low diversity per prompt with long synthesis time. To address these challenges, we propose DITTO-NeRF, a novel pipeline to generate a high-quality 3D NeRF model from a text prompt or a single image. Our DITTO-NeRF consists of constructing high-quality partial 3D object for limited in-boundary (IB) angles using the given or text-generated 2D image from the frontal view and then iteratively reconstructing the remaining 3D NeRF using inpainting latent diffusion model. We propose progressive 3D object reconstruction schemes in terms of scales (low to high resolution), angles (IB angles initially to outer-boundary (OB) later), and masks (object to background boundary) in our DITTO-NeRF so that high-quality information on IB can be propagated into OB. Our DITTO-NeRF outperforms state-of-the-art methods in terms of fidelity and diversity qualitatively and quantitatively with much faster training times than prior arts on image/text-to-3D such as DreamFusion, and NeuralLift-360.","sentences":["The increasing demand for high-quality 3D content creation has motivated the development of automated methods for creating 3D object models from a single image and/or from a text prompt.","However, the reconstructed 3D objects using state-of-the-art image-to-3D methods still exhibit low correspondence to the given image and low multi-view consistency.","Recent state-of-the-art text-to-3D methods are also limited, yielding 3D samples with low diversity per prompt with long synthesis time.","To address these challenges, we propose DITTO-NeRF, a novel pipeline to generate a high-quality 3D NeRF model from a text prompt or a single image.","Our DITTO-NeRF consists of constructing high-quality partial 3D object for limited in-boundary (IB) angles using the given or text-generated 2D image from the frontal view and then iteratively reconstructing the remaining 3D NeRF using inpainting latent diffusion model.","We propose progressive 3D object reconstruction schemes in terms of scales (low to high resolution), angles (IB angles initially to outer-boundary (OB) later), and masks (object to background boundary) in our DITTO-NeRF so that high-quality information on IB can be propagated into OB.","Our DITTO-NeRF outperforms state-of-the-art methods in terms of fidelity and diversity qualitatively and quantitatively with much faster training times than prior arts on image/text-to-3D such as DreamFusion, and NeuralLift-360."],"url":"http://arxiv.org/abs/2304.02827v1"}
{"created":"2023-04-06","title":"Asymptotic normalization coefficients of alpha-particle removal from $^{16}$O($3^-,2^+,1^-$)","abstract":"Asymptotic normalization coefficients (ANC) determine the overall normalization of cross sections of peripheral radiative capture reactions. In a recent paper [Blokhintsev {\\em et al.}, Eur. Phys. J. A {\\bf 58}, 257 (2022)], we considered the ANC $C_0$ for the virtual decay $^{16}$O$(0^+; 6.05$ MeV)$\\to \\alpha+^{12}$C(g.s.). In the present paper, which can be regarded as a continuation of the previous, we treat the ANCs $C_l$ for the vertices $^{16}$O$(J^\\pi)\\to \\alpha+^{12}$C(g.s.) corresponding to the other three bound excited states of $^{16}$O ($J^\\pi=3^-$, $2^+$, $1^-$, $l=J$). ANCs $C_l$ ($l=3,\\,2,\\,1$) are found by analytic continuation in energy of the $\\alpha^{12}$C $l$-wave partial scattering amplitudes, known from the phase-shift analysis of experimental data, to the pole corresponding to the $^{16}$O bound state and lying in the unphysical region of negative energies. To determine $C_l$, the scattering data are approximated by the sum of polynomials in energy in the physical region and then extrapolated to the pole. For a more reliable determination of the ANCs, various forms of functions expressed in terms of phase shifts were used in analytical approximation and subsequent extrapolation.","sentences":["Asymptotic normalization coefficients (ANC) determine the overall normalization of cross sections of peripheral radiative capture reactions.","In a recent paper [Blokhintsev {\\em et al.}, Eur. Phys.","J. A {\\bf 58}, 257 (2022)], we considered the ANC $C_0$ for the virtual decay $^{16}$O$(0^+; 6.05$ MeV)$\\to \\alpha+^{12}$C(g.s.).","In the present paper, which can be regarded as a continuation of the previous, we treat the ANCs $C_l$ for the vertices $^{16}$O$(J^\\pi)\\to \\alpha+^{12}$C(g.s.)","corresponding to the other three bound excited states of $^{16}$O ($J^\\pi=3^-$, $2^+$, $1^-$, $l=J$).","ANCs $C_l$ ($l=3,\\,2,\\,1$) are found by analytic continuation in energy of the $\\alpha^{12}$C $l$-wave partial scattering amplitudes, known from the phase-shift analysis of experimental data, to the pole corresponding to the $^{16}$O bound state and lying in the unphysical region of negative energies.","To determine $C_l$, the scattering data are approximated by the sum of polynomials in energy in the physical region and then extrapolated to the pole.","For a more reliable determination of the ANCs, various forms of functions expressed in terms of phase shifts were used in analytical approximation and subsequent extrapolation."],"url":"http://arxiv.org/abs/2304.02821v1"}
{"created":"2023-04-06","title":"MOA-2022-BLG-249Lb: Nearby microlensing super-Earth planet detected from high-cadence surveys","abstract":"We investigate the data collected by the high-cadence microlensing surveys during the 2022 season in search for planetary signals appearing in the light curves of microlensing events. From this search, we find that the lensing event MOA-2022-BLG-249 exhibits a brief positive anomaly that lasted for about 1 day with a maximum deviation of $\\sim 0.2$~mag from a single-source single-lens model. We analyze the light curve under the two interpretations of the anomaly: one originated by a low-mass companion to the lens (planetary model) and the other originated by a faint companion to the source (binary-source model). It is found that the anomaly is better explained by the planetary model than the binary-source model. We identify two solutions rooted in the inner--outer degeneracy, for both of which the estimated planet-to-host mass ratio, $q\\sim 8\\times 10^{-5}$, is very small. With the constraints provided by the microlens parallax and the lower limit on the Einstein radius, as well as the blend-flux constraint, we find that the lens is a planetary system, in which a super-Earth planet, with a mass $(4.83\\pm 1.44)~M_\\oplus$, orbits a low-mass host star, with a mass $(0.18\\pm 0.05)~M_\\odot$, lying in the Galactic disk at a distance $(2.00\\pm 0.42)$~kpc. The planet detection demonstrates the elevated microlensing sensitivity of the current high-cadence lensing surveys to low-mass planets.","sentences":["We investigate the data collected by the high-cadence microlensing surveys during the 2022 season in search for planetary signals appearing in the light curves of microlensing events.","From this search, we find that the lensing event MOA-2022-BLG-249 exhibits a brief positive anomaly that lasted for about 1 day with a maximum deviation of $\\sim 0.2$~mag from a single-source single-lens model.","We analyze the light curve under the two interpretations of the anomaly: one originated by a low-mass companion to the lens (planetary model) and the other originated by a faint companion to the source (binary-source model).","It is found that the anomaly is better explained by the planetary model than the binary-source model.","We identify two solutions rooted in the inner--outer degeneracy, for both of which the estimated planet-to-host mass ratio, $q\\sim 8\\times 10^{-5}$, is very small.","With the constraints provided by the microlens parallax and the lower limit on the Einstein radius, as well as the blend-flux constraint, we find that the lens is a planetary system, in which a super-Earth planet, with a mass $(4.83\\pm 1.44)~M_\\oplus$, orbits a low-mass host star, with a mass $(0.18\\pm 0.05)~M_\\odot$, lying in the Galactic disk at a distance $(2.00\\pm 0.42)$~kpc.","The planet detection demonstrates the elevated microlensing sensitivity of the current high-cadence lensing surveys to low-mass planets."],"url":"http://arxiv.org/abs/2304.02815v1"}
{"created":"2023-04-06","title":"4D Agnostic Real-Time Facial Animation Pipeline for Desktop Scenarios","abstract":"We present a high-precision real-time facial animation pipeline suitable for animators to use on their desktops. This pipeline is about to be launched in FACEGOOD's Avatary\\footnote{https://www.avatary.com/} software, which will accelerate animators' productivity. The pipeline differs from professional head-mounted facial capture solutions in that it only requires the use of a consumer-grade 3D camera on the desk to achieve high-precision real-time facial capture. The system enables animators to create high-quality facial animations with ease and speed, while reducing the cost and complexity of traditional facial capture solutions. Our approach has the potential to revolutionize the way facial animation is done in the entertainment industry.","sentences":["We present a high-precision real-time facial animation pipeline suitable for animators to use on their desktops.","This pipeline is about to be launched in FACEGOOD's Avatary\\footnote{https://www.avatary.com/} software, which will accelerate animators' productivity.","The pipeline differs from professional head-mounted facial capture solutions in that it only requires the use of a consumer-grade 3D camera on the desk to achieve high-precision real-time facial capture.","The system enables animators to create high-quality facial animations with ease and speed, while reducing the cost and complexity of traditional facial capture solutions.","Our approach has the potential to revolutionize the way facial animation is done in the entertainment industry."],"url":"http://arxiv.org/abs/2304.02814v1"}
{"created":"2023-04-06","title":"Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit Diversity Modeling","abstract":"Graph neural networks (GNNs) have been widely applied to learning over graph data. Yet, real-world graphs commonly exhibit diverse graph structures and contain heterogeneous nodes and edges. Moreover, to enhance the generalization ability of GNNs, it has become common practice to further increase the diversity of training graph structures by incorporating graph augmentations and/or performing large-scale pre-training on more graphs. Therefore, it becomes essential for a GNN to simultaneously model diverse graph structures. Yet, naively increasing the GNN model capacity will suffer from both higher inference costs and the notorious trainability issue of GNNs. This paper introduces the Mixture-of-Expert (MoE) idea to GNNs, aiming to enhance their ability to accommodate the diversity of training graph structures, without incurring computational overheads. Our new Graph Mixture of Expert (GMoE) model enables each node in the graph to dynamically select its own optimal \\textit{information aggregation experts}. These experts are trained to model different subgroups of graph structures in the training set. Additionally, GMoE includes information aggregation experts with varying aggregation hop sizes, where the experts with larger hop sizes are specialized in capturing information over longer ranges. The effectiveness of GMoE is verified through experimental results on a large variety of graph, node, and link prediction tasks in the OGB benchmark. For instance, it enhances ROC-AUC by $1.81\\%$ in ogbg-molhiv and by $1.40\\%$ in ogbg-molbbbp, as compared to the non-MoE baselines. Our code is available at https://github.com/VITA-Group/Graph-Mixture-of-Experts.","sentences":["Graph neural networks (GNNs) have been widely applied to learning over graph data.","Yet, real-world graphs commonly exhibit diverse graph structures and contain heterogeneous nodes and edges.","Moreover, to enhance the generalization ability of GNNs, it has become common practice to further increase the diversity of training graph structures by incorporating graph augmentations and/or performing large-scale pre-training on more graphs.","Therefore, it becomes essential for a GNN to simultaneously model diverse graph structures.","Yet, naively increasing the GNN model capacity will suffer from both higher inference costs and the notorious trainability issue of GNNs.","This paper introduces the Mixture-of-Expert (MoE) idea to GNNs, aiming to enhance their ability to accommodate the diversity of training graph structures, without incurring computational overheads.","Our new Graph Mixture of Expert (GMoE) model enables each node in the graph to dynamically select its own optimal \\textit{information aggregation experts}.","These experts are trained to model different subgroups of graph structures in the training set.","Additionally, GMoE includes information aggregation experts with varying aggregation hop sizes, where the experts with larger hop sizes are specialized in capturing information over longer ranges.","The effectiveness of GMoE is verified through experimental results on a large variety of graph, node, and link prediction tasks in the OGB benchmark.","For instance, it enhances ROC-AUC by $1.81\\%$ in ogbg-molhiv and by $1.40\\%$ in ogbg-molbbbp, as compared to the non-MoE baselines.","Our code is available at https://github.com/VITA-Group/Graph-Mixture-of-Experts."],"url":"http://arxiv.org/abs/2304.02806v1"}
{"created":"2023-04-06","title":"End-to-end Manipulator Calligraphy Planning via Variational Imitation Learning","abstract":"Planning from demonstrations has shown promising results with the advances of deep neural networks. One of the most popular real-world applications is automated handwriting using a robotic manipulator. Classically it is simplified as a two-dimension problem. This representation is suitable for elementary drawings, but it is not sufficient for Japanese calligraphy or complex work of art where the orientation of a pen is part of the user expression. In this study, we focus on automated planning of Japanese calligraphy using a three-dimension representation of the trajectory as well as the rotation of the pen tip, and propose a novel deep imitation learning neural network that learns from expert demonstrations through a combination of images and pose data. The network consists of a combination of variational auto-encoder, bi-directional LSTM, and Multi-Layer Perceptron (MLP). Experiments are conducted in a progressive way, and results demonstrate that the proposed approach is successful in completion of tasks for real-world robots, overcoming the distribution shift problem in imitation learning. The source code and dataset will be public.","sentences":["Planning from demonstrations has shown promising results with the advances of deep neural networks.","One of the most popular real-world applications is automated handwriting using a robotic manipulator.","Classically it is simplified as a two-dimension problem.","This representation is suitable for elementary drawings, but it is not sufficient for Japanese calligraphy or complex work of art where the orientation of a pen is part of the user expression.","In this study, we focus on automated planning of Japanese calligraphy using a three-dimension representation of the trajectory as well as the rotation of the pen tip, and propose a novel deep imitation learning neural network that learns from expert demonstrations through a combination of images and pose data.","The network consists of a combination of variational auto-encoder, bi-directional LSTM, and Multi-Layer Perceptron (MLP).","Experiments are conducted in a progressive way, and results demonstrate that the proposed approach is successful in completion of tasks for real-world robots, overcoming the distribution shift problem in imitation learning.","The source code and dataset will be public."],"url":"http://arxiv.org/abs/2304.02801v1"}
{"created":"2023-04-06","title":"Source-free Domain Adaptation Requires Penalized Diversity","abstract":"While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset. Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy. Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains. In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor. Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA). Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses. Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy. Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift. In addition, PD is augmented with a weighted MI maximization objective for label distribution shift. Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts.","sentences":["While neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset.","Source-free domain adaptation (SFDA) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy.","Diversity in representation space can be vital to a model`s adaptability in varied and difficult domains.","In unsupervised SFDA, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor.","Motivated by the improved predictive performance of ensembles, we propose a novel unsupervised SFDA algorithm that promotes representational diversity through the use of separate feature extractors with Distinct Backbone Architectures (DBA).","Although diversity in feature space is increased, the unconstrained mutual information (MI) maximization may potentially introduce amplification of weak hypotheses.","Thus we introduce the Weak Hypothesis Penalization (WHP) regularizer as a mitigation strategy.","Our work proposes Penalized Diversity (PD) where the synergy of DBA and WHP is applied to unsupervised source-free domain adaptation for covariate shift.","In addition, PD is augmented with a weighted MI maximization objective for label distribution shift.","Empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of PD under different distributional shifts."],"url":"http://arxiv.org/abs/2304.02798v1"}
{"created":"2023-04-06","title":"DeLiRa: Self-Supervised Depth, Light, and Radiance Fields","abstract":"Differentiable volumetric rendering is a powerful paradigm for 3D reconstruction and novel view synthesis. However, standard volume rendering approaches struggle with degenerate geometries in the case of limited viewpoint diversity, a common scenario in robotics applications. In this work, we propose to use the multi-view photometric objective from the self-supervised depth estimation literature as a geometric regularizer for volumetric rendering, significantly improving novel view synthesis without requiring additional information. Building upon this insight, we explore the explicit modeling of scene geometry using a generalist Transformer, jointly learning a radiance field as well as depth and light fields with a set of shared latent codes. We demonstrate that sharing geometric information across tasks is mutually beneficial, leading to improvements over single-task learning without an increase in network complexity. Our DeLiRa architecture achieves state-of-the-art results on the ScanNet benchmark, enabling high quality volumetric rendering as well as real-time novel view and depth synthesis in the limited viewpoint diversity setting.","sentences":["Differentiable volumetric rendering is a powerful paradigm for 3D reconstruction and novel view synthesis.","However, standard volume rendering approaches struggle with degenerate geometries in the case of limited viewpoint diversity, a common scenario in robotics applications.","In this work, we propose to use the multi-view photometric objective from the self-supervised depth estimation literature as a geometric regularizer for volumetric rendering, significantly improving novel view synthesis without requiring additional information.","Building upon this insight, we explore the explicit modeling of scene geometry using a generalist Transformer, jointly learning a radiance field as well as depth and light fields with a set of shared latent codes.","We demonstrate that sharing geometric information across tasks is mutually beneficial, leading to improvements over single-task learning without an increase in network complexity.","Our DeLiRa architecture achieves state-of-the-art results on the ScanNet benchmark, enabling high quality volumetric rendering as well as real-time novel view and depth synthesis in the limited viewpoint diversity setting."],"url":"http://arxiv.org/abs/2304.02797v1"}
{"created":"2023-04-06","title":"Opportunities and challenges of ChatGPT for design knowledge management","abstract":"Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information. However, integrating ChatGPT into the design process also presents new challenges. In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge. We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions. A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt.","sentences":["Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information.","However, integrating ChatGPT into the design process also presents new challenges.","In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge.","We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions.","A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt."],"url":"http://arxiv.org/abs/2304.02796v1"}
{"created":"2023-04-05","title":"A method for extracting effective interactions from Hi-C data with applications to interphase chromosomes and inverted nuclei","abstract":"Contact probabilities between loci, separated by arbitrary genomic distance, for a number of cell types have been reported using genome-wide chromosome conformation capture (Hi-C) experiments. How to directly use the experimental data, without an underlying model, to extract the effective interaction energies between active euchromatin (A) and inactive heterochromatin (B) is an open problem. Here we first calculate the pairwise effective interaction energies (A-A, B-B, or A-B) for interphase chromosomes based on Hi-C data by using the concept of Statistical Potential (SP). The assumption in the SP evaluation is that the interaction energy between two loci is proportional to the logarithm of the frequency with which they interact. Polymer simulations, using the extracted interaction energy values without any parameter, naturally results in the segregation between A and B type loci (compartments), and the emergence of topologically associating domains (TADs), features that are prominent in the Hi-C data for interphase chromosomes. Remarkably, the values of the SP automatically satisfy the Flory-Huggins phase separation criterion for all the chromosomes, which explains the compartment formation in interphase chromosomes. Strikingly, simulations using the SP that accounts for pericentromeric constitutive heterochromatin (C), show hierarchical structuring with the high density of C in the nuclear center, followed by localization of the B type loci, with euchromatin being confined to the nuclear periphery, which is in accord with the imaging data for photoreceptor rods in nocturnal mammals. The proposed parameter free method and applications show that compartment formation in conventional and inverted nuclei is best explained by the inequality between the effective interaction energies, with heterochromatin attraction being the dominant driving force.","sentences":["Contact probabilities between loci, separated by arbitrary genomic distance, for a number of cell types have been reported using genome-wide chromosome conformation capture (Hi-C) experiments.","How to directly use the experimental data, without an underlying model, to extract the effective interaction energies between active euchromatin (A) and inactive heterochromatin (B) is an open problem.","Here we first calculate the pairwise effective interaction energies (A-A, B-B, or A-B) for interphase chromosomes based on Hi-C data by using the concept of Statistical Potential (SP).","The assumption in the SP evaluation is that the interaction energy between two loci is proportional to the logarithm of the frequency with which they interact.","Polymer simulations, using the extracted interaction energy values without any parameter, naturally results in the segregation between A and B type loci (compartments), and the emergence of topologically associating domains (TADs), features that are prominent in the Hi-C data for interphase chromosomes.","Remarkably, the values of the SP automatically satisfy the Flory-Huggins phase separation criterion for all the chromosomes, which explains the compartment formation in interphase chromosomes.","Strikingly, simulations using the SP that accounts for pericentromeric constitutive heterochromatin (C), show hierarchical structuring with the high density of C in the nuclear center, followed by localization of the B type loci, with euchromatin being confined to the nuclear periphery, which is in accord with the imaging data for photoreceptor rods in nocturnal mammals.","The proposed parameter free method and applications show that compartment formation in conventional and inverted nuclei is best explained by the inequality between the effective interaction energies, with heterochromatin attraction being the dominant driving force."],"url":"http://arxiv.org/abs/2304.02795v1"}
{"created":"2023-04-05","title":"Immune recognition dynamics of a primary infection","abstract":"The immune response to an acute primary infection is a coupled process of antigen proliferation, molecular recognition by naive B-cells, and their subsequent proliferation and antibody shedding. Here we show B-cells can efficiently recognise new antigens by a tuned kinetic proofreading mechanism, where the number of proofreading steps and the characteristic rate of each step are set by the complexity of the immune repertoire. This process produces potent, specific and fast recognition of antigens, maintaining a spectrum of genetically distinct B-cell lineages as input for affinity maturation. We show that the proliferation-recognition dynamics of a primary infection can me mapped onto a generalised Luria-Delbr\\\"uck process, akin to the dynamics of the classic fluctuation experiment. We derive the resulting statistics of the activated immune repertoire: antigen binding affinity, expected size, and frequency of active B-cell clones are related by power laws. Their exponents depend on the antigen and B-cell proliferation rate, the number of proofreading steps, and the lineage density of the naive repertoire. Empirical data of mouse immune repertoires are found to be consistent with activation involving at least three proofreading steps. Our model predicts key clinical characteristics of acute infections. The primary immune response to a given antigen is strongly heterogeneous across individuals; few elite responders are distinguished by early activation of high-affinity clones. Conversely, ageing of the immune system, by reducing the density of naive clones, degrades potency and speed of pathogen recognition.","sentences":["The immune response to an acute primary infection is a coupled process of antigen proliferation, molecular recognition by naive B-cells, and their subsequent proliferation and antibody shedding.","Here we show B-cells can efficiently recognise new antigens by a tuned kinetic proofreading mechanism, where the number of proofreading steps and the characteristic rate of each step are set by the complexity of the immune repertoire.","This process produces potent, specific and fast recognition of antigens, maintaining a spectrum of genetically distinct B-cell lineages as input for affinity maturation.","We show that the proliferation-recognition dynamics of a primary infection can me mapped onto a generalised Luria-Delbr\\\"uck process, akin to the dynamics of the classic fluctuation experiment.","We derive the resulting statistics of the activated immune repertoire: antigen binding affinity, expected size, and frequency of active B-cell clones are related by power laws.","Their exponents depend on the antigen and B-cell proliferation rate, the number of proofreading steps, and the lineage density of the naive repertoire.","Empirical data of mouse immune repertoires are found to be consistent with activation involving at least three proofreading steps.","Our model predicts key clinical characteristics of acute infections.","The primary immune response to a given antigen is strongly heterogeneous across individuals; few elite responders are distinguished by early activation of high-affinity clones.","Conversely, ageing of the immune system, by reducing the density of naive clones, degrades potency and speed of pathogen recognition."],"url":"http://arxiv.org/abs/2304.02794v1"}
{"created":"2023-04-05","title":"Improving pulsar-timing solutions through dynamic pulse fitting","abstract":"Precision pulsar timing is integral to the detection of the nanohertz stochastic gravitational-wave background as well as understanding the physics of neutron stars. Conventional pulsar timing often uses fixed time and frequency-averaged templates to determine the pulse times of arrival, which can lead to reduced accuracy when the pulse profile evolves over time. We illustrate a dynamic timing method that fits each observing epoch using basis functions. By fitting each epoch separately, we allow for the evolution of the pulse shape epoch to epoch. We apply our method to PSR J1103$-$5403 and demonstrate that it undergoes mode changing, making it the fourth millisecond pulsar to exhibit such behaviour. Our method, which is able to identify and time a single mode, yields a timing solution with a root-mean-square error of 1.343 $\\mu \\mathrm{s}$, a factor of 1.78 improvement over template fitting on both modes. In addition, the white-noise amplitude is reduced 4.3 times, suggesting that fitting the full data set causes the mode changing to be incorrectly classified as white noise. This reduction in white noise boosts the signal-to-noise ratio of a gravitational-wave background signal for this particular pulsar by 32%. We discuss the possible applications for this method of timing to study pulsar magnetospheres and further improve the sensitivity of searches for nanohertz gravitational waves.","sentences":["Precision pulsar timing is integral to the detection of the nanohertz stochastic gravitational-wave background as well as understanding the physics of neutron stars.","Conventional pulsar timing often uses fixed time and frequency-averaged templates to determine the pulse times of arrival, which can lead to reduced accuracy when the pulse profile evolves over time.","We illustrate a dynamic timing method that fits each observing epoch using basis functions.","By fitting each epoch separately, we allow for the evolution of the pulse shape epoch to epoch.","We apply our method to PSR J1103$-$5403 and demonstrate that it undergoes mode changing, making it the fourth millisecond pulsar to exhibit such behaviour.","Our method, which is able to identify and time a single mode, yields a timing solution with a root-mean-square error of 1.343 $\\mu \\mathrm{s}$, a factor of 1.78 improvement over template fitting on both modes.","In addition, the white-noise amplitude is reduced 4.3 times, suggesting that fitting the full data set causes the mode changing to be incorrectly classified as white noise.","This reduction in white noise boosts the signal-to-noise ratio of a gravitational-wave background signal for this particular pulsar by 32%.","We discuss the possible applications for this method of timing to study pulsar magnetospheres and further improve the sensitivity of searches for nanohertz gravitational waves."],"url":"http://arxiv.org/abs/2304.02793v1"}
{"created":"2023-04-05","title":"Vertical-slice ocean tomography with seismic waves","abstract":"Seismically generated sound waves that propagate through the ocean are used to infer temperature anomalies and their vertical structure in the deep East Indian Ocean. These T waves are generated by earthquakes off Sumatra and received by hydrophone stations off Diego Garcia and Cape Leeuwin. Between repeating earthquakes, a T wave's travel time changes in response to temperature anomalies along the wave's path. What part of the water column the travel time is sensitive to depends on the frequency of the wave, so measuring travel time changes at a few low frequencies constrains the vertical structure of the inferred temperature anomalies. These measurements reveal anomalies due to equatorial waves, mesoscale eddies, and decadal warming trends. By providing direct constraints on basin-scale averages with dense sampling in time, these data complement previous point measurements that alias local and transient temperature anomalies.","sentences":["Seismically generated sound waves that propagate through the ocean are used to infer temperature anomalies and their vertical structure in the deep East Indian Ocean.","These T waves are generated by earthquakes off Sumatra and received by hydrophone stations off Diego Garcia and Cape Leeuwin.","Between repeating earthquakes, a T wave's travel time changes in response to temperature anomalies along the wave's path.","What part of the water column the travel time is sensitive to depends on the frequency of the wave, so measuring travel time changes at a few low frequencies constrains the vertical structure of the inferred temperature anomalies.","These measurements reveal anomalies due to equatorial waves, mesoscale eddies, and decadal warming trends.","By providing direct constraints on basin-scale averages with dense sampling in time, these data complement previous point measurements that alias local and transient temperature anomalies."],"url":"http://arxiv.org/abs/2304.02791v1"}
{"created":"2023-04-05","title":"Performance of Data Augmentation Methods for Brazilian Portuguese Text Classification","abstract":"Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers. Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora. In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora. As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity.","sentences":["Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers.","Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora.","In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora.","As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity."],"url":"http://arxiv.org/abs/2304.02785v1"}
{"created":"2023-04-05","title":"FACE-AUDITOR: Data Auditing in Facial Recognition Systems","abstract":"Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase. However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent. To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks. Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed.   In this paper, we formulate the auditing process as a user-level membership inference problem and propose a complete toolkit FACE-AUDITOR that can carefully choose the probing set to query the few-shot-based facial recognition model and determine whether any of a user's face images is used in training the model. We further propose to use the similarity scores between the original face images as reference information to improve the auditing performance. Extensive experiments on multiple real-world face image datasets show that FACE-AUDITOR can achieve auditing accuracy of up to $99\\%$. Finally, we show that FACE-AUDITOR is robust in the presence of several perturbation mechanisms to the training images or the target models. The source code of our experiments can be found at \\url{https://github.com/MinChen00/Face-Auditor}.","sentences":["Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase.","However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent.","To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks.","Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed.   ","In this paper, we formulate the auditing process as a user-level membership inference problem and propose a complete toolkit FACE-AUDITOR that can carefully choose the probing set to query the few-shot-based facial recognition model and determine whether any of a user's face images is used in training the model.","We further propose to use the similarity scores between the original face images as reference information to improve the auditing performance.","Extensive experiments on multiple real-world face image datasets show that FACE-AUDITOR can achieve auditing accuracy of up to $99\\%$. Finally, we show that FACE-AUDITOR is robust in the presence of several perturbation mechanisms to the training images or the target models.","The source code of our experiments can be found at \\url{https://github.com/MinChen00/Face-Auditor}."],"url":"http://arxiv.org/abs/2304.02782v1"}
{"created":"2023-04-05","title":"A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors","abstract":"Liver transplantation is a life-saving procedure for patients with end-stage liver disease. There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations. The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days. However, the donor-patient matching should also take into consideration post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant. Accurate prediction of these risk scores remains a significant challenge. In this study, we will use predictive models to solve the above challenge. We propose a deep learning framework model to predict multiple risk factors after a liver transplant. By formulating it as a multi-task learning problem, the proposed deep neural network was trained on this data to simultaneously predict the five post-transplant risks and achieve equally good performance by leveraging task balancing techniques. We also propose a novel fairness achieving algorithm and to ensure prediction fairness across different subpopulations. We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018. The performance of the model was evaluated using various performance metrics such as AUROC, AURPC, and accuracy. The results of our experiments demonstrate that the proposed multitask prediction model achieved high accuracy and good balance in predicting all five post-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%. The fairness-achieving algorithm significantly reduced the fairness disparity compared to the baseline model.","sentences":["Liver transplantation is a life-saving procedure for patients with end-stage liver disease.","There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations.","The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days.","However, the donor-patient matching should also take into consideration post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant.","Accurate prediction of these risk scores remains a significant challenge.","In this study, we will use predictive models to solve the above challenge.","We propose a deep learning framework model to predict multiple risk factors after a liver transplant.","By formulating it as a multi-task learning problem, the proposed deep neural network was trained on this data to simultaneously predict the five post-transplant risks and achieve equally good performance by leveraging task balancing techniques.","We also propose a novel fairness achieving algorithm and to ensure prediction fairness across different subpopulations.","We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018.","The performance of the model was evaluated using various performance metrics such as AUROC, AURPC, and accuracy.","The results of our experiments demonstrate that the proposed multitask prediction model achieved high accuracy and good balance in predicting all five post-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%.","The fairness-achieving algorithm significantly reduced the fairness disparity compared to the baseline model."],"url":"http://arxiv.org/abs/2304.02780v1"}
{"created":"2023-04-05","title":"Hyades Member K2-136c: The Smallest Planet in an Open Cluster with a Precisely Measured Mass","abstract":"K2-136 is a late-K dwarf ($0.742\\pm0.039$ M$_\\odot$) in the Hyades open cluster with three known, transiting planets and an age of $650\\pm70$ Myr. Analyzing K2 photometry, we found that planets K2-136b, c, and d have periods of $8.0$, $17.3$, and $25.6$ days and radii of $1.014\\pm0.050$ R$_\\oplus$, $3.00\\pm0.13$ R$_\\oplus$, and $1.565\\pm0.077$ R$_\\oplus$, respectively. We collected 93 radial velocity measurements (RVs) with the HARPS-N spectrograph (TNG) and 22 RVs with the ESPRESSO spectrograph (VLT). Analyzing HARPS-N and ESPRESSO data jointly, we found K2-136c induced a semi-amplitude of $5.49\\pm0.53$ m s$^{-1}$, corresponding to a mass of $18.1\\pm1.9$ M$_\\oplus$. We also placed $95$% upper mass limits on K2-136b and d of $4.3$ and $3.0$ M$_\\oplus$, respectively. Further, we analyzed HST and XMM-Newton observations to establish the planetary high-energy environment and investigate possible atmospheric loss. K2-136c is now the smallest planet to have a measured mass in an open cluster and one of the youngest planets ever with a mass measurement. K2-136c has $\\sim$75% the radius of Neptune but is similar in mass, yielding a density of $3.69^{+0.67}_{-0.56}$ g cm$^{-3}$ ($\\sim$2-3 times denser than Neptune). Mass estimates for K2-136b (and possibly d) may be feasible with more RV observations, and insights into all three planets' atmospheres through transmission spectroscopy would be challenging but potentially fruitful. This research and future mass measurements of young planets are critical for investigating the compositions and characteristics of small exoplanets at very early stages of their lives and providing insights into how exoplanets evolve with time.","sentences":["K2-136 is a late-K dwarf ($0.742\\pm0.039$ M$_\\odot$) in the Hyades open cluster with three known, transiting planets and an age of $650\\pm70$ Myr.","Analyzing K2 photometry, we found that planets K2-136b, c, and d have periods of $8.0$, $17.3$, and $25.6$ days and radii of $1.014\\pm0.050$ R$_\\oplus$, $3.00\\pm0.13$ R$_\\oplus$, and $1.565\\pm0.077$ R$_\\oplus$, respectively.","We collected 93 radial velocity measurements (RVs) with the HARPS-N spectrograph (TNG) and 22 RVs with the ESPRESSO spectrograph (VLT).","Analyzing HARPS-N and ESPRESSO data jointly, we found K2-136c induced a semi-amplitude of $5.49\\pm0.53$ m s$^{-1}$, corresponding to a mass of $18.1\\pm1.9$ M$_\\oplus$. We also placed $95$% upper mass limits on K2-136b and d of $4.3$ and $3.0$ M$_\\oplus$, respectively.","Further, we analyzed HST and XMM-Newton observations to establish the planetary high-energy environment and investigate possible atmospheric loss.","K2-136c is now the smallest planet to have a measured mass in an open cluster and one of the youngest planets ever with a mass measurement.","K2-136c has $\\sim$75% the radius of Neptune but is similar in mass, yielding a density of $3.69^{+0.67}_{-0.56}$ g cm$^{-3}$ ($\\sim$2-3 times denser than Neptune).","Mass estimates for K2-136b (and possibly d) may be feasible with more RV observations, and insights into all three planets' atmospheres through transmission spectroscopy would be challenging but potentially fruitful.","This research and future mass measurements of young planets are critical for investigating the compositions and characteristics of small exoplanets at very early stages of their lives and providing insights into how exoplanets evolve with time."],"url":"http://arxiv.org/abs/2304.02779v1"}
{"created":"2023-04-05","title":"The Colorado Ultraviolet Transit Experiment (CUTE) signal to noise calculator","abstract":"We present here the signal-to-noise (S/N) calculator developed for the Colorado Ultraviolet Transit Experiment (CUTE) mission. CUTE is a 6U CubeSat operating in the near-ultraviolet (NUV) observing exoplanetary transits to study their upper atmospheres. CUTE was launched into a low-Earth orbit in September 2021 and it is currently gathering scientific data. As part of the S/N calculator, we also present the error propagation for computing transit depth uncertainties starting from the S/N of the original spectroscopic observations. The CUTE S/N calculator is currently extensively used for target selection and scheduling. The modular construction of the CUTE S/N calculator enables its adaptation and can be used also for other missions and instruments.","sentences":["We present here the signal-to-noise (S/N) calculator developed for the Colorado Ultraviolet Transit Experiment (CUTE) mission.","CUTE is a 6U CubeSat operating in the near-ultraviolet (NUV) observing exoplanetary transits to study their upper atmospheres.","CUTE was launched into a low-Earth orbit in September 2021 and it is currently gathering scientific data.","As part of the S/N calculator, we also present the error propagation for computing transit depth uncertainties starting from the S/N of the original spectroscopic observations.","The CUTE S/N calculator is currently extensively used for target selection and scheduling.","The modular construction of the CUTE S/N calculator enables its adaptation and can be used also for other missions and instruments."],"url":"http://arxiv.org/abs/2304.02776v1"}
{"created":"2023-04-05","title":"Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review","abstract":"The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis. This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks. To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field. In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis. The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format. The paper presents some limitations of current research and some recommendations for further research.","sentences":["The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis.","This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks.","To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field.","In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis.","The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format.","The paper presents some limitations of current research and some recommendations for further research."],"url":"http://arxiv.org/abs/2304.02768v1"}
{"created":"2023-04-05","title":"MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection","abstract":"Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methane plume sites. Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact. Dataset and source code are public","sentences":["Methane (CH$_4$) is the chief contributor to global climate change.","Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions.","Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable.","To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions.","MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately.","Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art.","In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1200 AVIRIS-NG flight lines from 2015-2022.","It contains over 4000 methane plume sites.","Our dataset will provide researchers the opportunity to develop and advance new methods for tackling this challenging green-house gas detection problem with significant broader social impact.","Dataset and source code are public"],"url":"http://arxiv.org/abs/2304.02767v1"}
{"created":"2023-04-05","title":"Integrating U-nets into a Multi-scale Waveform Inversion for Salt Body Building","abstract":"In salt provinces, full-waveform inversion (FWI) is most likely to fail when starting with a poor initial model that lacks the salt information. Conventionally, salt bodies are included in the FWI starting model by interpreting the salt boundaries from seismic images, which is time-consuming and prone to error. Studies show that FWI can improve the interpreted salt provided that the data are recorded using long offsets, and contain low frequencies, which are not always available. Thus, we develop an approach to invert for the salt body starting from a poor initial model, limited data offsets, and the absence of low frequencies. We leverage deep learning to apply multi-stage flooding and unflooding of the velocity model. Specifically, we apply a multi-scale FWI using three frequency bandwidths. We apply a network after each frequency scale. After the first two bandwidths, the networks are trained to flood the salt, while the network after the last frequency bandwidth is trained to unflood it. We verify the method on the synthetic BP 2004 salt model benchmark. We only use the synthetic data of short offsets up to 6 km and remove frequencies below 3 Hz. We also apply the method to real vintage data acquired in the Gulf of Mexico region. The real data lack frequencies below 6 Hz and the streamer length is only 4.8 km. With these limitations, we manage to recover the salt body and verify the result by using them to image the data and analyze the resulting angle gathers.","sentences":["In salt provinces, full-waveform inversion (FWI) is most likely to fail when starting with a poor initial model that lacks the salt information.","Conventionally, salt bodies are included in the FWI starting model by interpreting the salt boundaries from seismic images, which is time-consuming and prone to error.","Studies show that FWI can improve the interpreted salt provided that the data are recorded using long offsets, and contain low frequencies, which are not always available.","Thus, we develop an approach to invert for the salt body starting from a poor initial model, limited data offsets, and the absence of low frequencies.","We leverage deep learning to apply multi-stage flooding and unflooding of the velocity model.","Specifically, we apply a multi-scale FWI using three frequency bandwidths.","We apply a network after each frequency scale.","After the first two bandwidths, the networks are trained to flood the salt, while the network after the last frequency bandwidth is trained to unflood it.","We verify the method on the synthetic BP 2004 salt model benchmark.","We only use the synthetic data of short offsets up to 6 km and remove frequencies below 3 Hz.","We also apply the method to real vintage data acquired in the Gulf of Mexico region.","The real data lack frequencies below 6 Hz and the streamer length is only 4.8 km.","With these limitations, we manage to recover the salt body and verify the result by using them to image the data and analyze the resulting angle gathers."],"url":"http://arxiv.org/abs/2304.02758v1"}
{"created":"2023-04-05","title":"The Saudi Privacy Policy Dataset","abstract":"This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide. Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia. The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB. The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations. By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia.","sentences":["This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide.","Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia.","The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB.","The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations.","By providing a comprehensive and annotated dataset of privacy policies, this paper aims to facilitate further research and development in the areas of privacy policy analysis, natural language processing, and machine learning applications related to privacy and data protection, while also serving as an essential resource for researchers, policymakers, and industry professionals interested in understanding and promoting compliance with privacy regulations in Saudi Arabia."],"url":"http://arxiv.org/abs/2304.02757v1"}
{"created":"2023-04-05","title":"Optomechanical coupling and damping of a carbon nanotube quantum dot","abstract":"Carbon nanotubes are excellent nano-electromechanical systems, combining high resonance frequency, low mass, and large zero-point motion. At cryogenic temperatures they display high mechanical quality factors. Equally they are outstanding single electron devices with well-known quantum levels and have been proposed for the integration of charge or spin qubits. The integration of these devices into microwave optomechanical circuits is however hindered by a mismatch of scales, between typical microwave wavelengths, nanotube segment lengths, and nanotube deflections. As experimentally demonstrated recently in [Blien et al., Nat. Comm. 11, 1363 (2020)], coupling enhancement via the quantum capacitance allows to circumvent this restriction. Here we extend the discussion of this experiment. We present the subsystems of the device and their interactions in detail. An alternative approach to the optomechanical coupling is presented, allowing to estimate the mechanical zero point motion scale. Further, the mechanical damping is discussed, hinting at hitherto unknown interaction mechanisms.","sentences":["Carbon nanotubes are excellent nano-electromechanical systems, combining high resonance frequency, low mass, and large zero-point motion.","At cryogenic temperatures they display high mechanical quality factors.","Equally they are outstanding single electron devices with well-known quantum levels and have been proposed for the integration of charge or spin qubits.","The integration of these devices into microwave optomechanical circuits is however hindered by a mismatch of scales, between typical microwave wavelengths, nanotube segment lengths, and nanotube deflections.","As experimentally demonstrated recently in [Blien et al., Nat.","Comm. 11, 1363 (2020)], coupling enhancement via the quantum capacitance allows to circumvent this restriction.","Here we extend the discussion of this experiment.","We present the subsystems of the device and their interactions in detail.","An alternative approach to the optomechanical coupling is presented, allowing to estimate the mechanical zero point motion scale.","Further, the mechanical damping is discussed, hinting at hitherto unknown interaction mechanisms."],"url":"http://arxiv.org/abs/2304.02748v1"}
{"created":"2023-04-05","title":"The indication for $^{40}$K geo-antineutrino flux with Borexino phase-III data","abstract":"We provide the indication of high flux of $^{40}$K geo-antineutrino and geo-neutrino ($^{40}$K-geo-($\\bar{\\nu} + \\nu$)) with Borexino Phase III data. This result was obtained by introducing a new source of single events, namely $^{40}$K-geo-($\\bar{\\nu} + \\nu$) scattering on electrons, in multivariate fit analysis of Borexino Phase III data. Simultaneously we obtained the count rates of events from $^7$Be, $pep$ and CNO solar neutrinos. These count rates are consistent with the prediction of the Low metallicity Sun model SSM B16-AGSS09. MC pseudo-experiments showed that the case of High metallicity Sun and absence of $^{40}$K-geo-($\\bar{\\nu} + \\nu$) can not imitate the result of multivariate fit analysis of Borexino Phase III data with introducing $^{40}$K-geo-($\\bar{\\nu} + \\nu$) events. We also provide arguments for the high abundance of potassium in the Earth.","sentences":["We provide the indication of high flux of $^{40}$K geo-antineutrino and geo-neutrino ($^{40}$K-geo-($\\bar{\\nu} + \\nu$)) with Borexino Phase III data.","This result was obtained by introducing a new source of single events, namely $^{40}$K-geo-($\\bar{\\nu} + \\nu$) scattering on electrons, in multivariate fit analysis of Borexino Phase III data.","Simultaneously we obtained the count rates of events from $^7$Be, $pep$ and CNO solar neutrinos.","These count rates are consistent with the prediction of the Low metallicity Sun model SSM B16-AGSS09.","MC pseudo-experiments showed that the case of High metallicity Sun and absence of $^{40}$K-geo-($\\bar{\\nu} + \\nu$) can not imitate the result of multivariate fit analysis of Borexino Phase III data with introducing $^{40}$K-geo-($\\bar{\\nu} + \\nu$) events.","We also provide arguments for the high abundance of potassium in the Earth."],"url":"http://arxiv.org/abs/2304.02747v1"}
{"created":"2023-04-05","title":"StyleGAN Salon: Multi-View Latent Optimization for Pose-Invariant Hairstyle Transfer","abstract":"Our paper seeks to transfer the hairstyle of a reference image to an input photo for virtual hair try-on. We target a variety of challenges scenarios, such as transforming a long hairstyle with bangs to a pixie cut, which requires removing the existing hair and inferring how the forehead would look, or transferring partially visible hair from a hat-wearing person in a different pose. Past solutions leverage StyleGAN for hallucinating any missing parts and producing a seamless face-hair composite through so-called GAN inversion or projection. However, there remains a challenge in controlling the hallucinations to accurately transfer hairstyle and preserve the face shape and identity of the input. To overcome this, we propose a multi-view optimization framework that uses \"two different views\" of reference composites to semantically guide occluded or ambiguous regions. Our optimization shares information between two poses, which allows us to produce high fidelity and realistic results from incomplete references. Our framework produces high-quality results and outperforms prior work in a user study that consists of significantly more challenging hair transfer scenarios than previously studied. Project page: https://stylegan-salon.github.io/.","sentences":["Our paper seeks to transfer the hairstyle of a reference image to an input photo for virtual hair try-on.","We target a variety of challenges scenarios, such as transforming a long hairstyle with bangs to a pixie cut, which requires removing the existing hair and inferring how the forehead would look, or transferring partially visible hair from a hat-wearing person in a different pose.","Past solutions leverage StyleGAN for hallucinating any missing parts and producing a seamless face-hair composite through so-called GAN inversion or projection.","However, there remains a challenge in controlling the hallucinations to accurately transfer hairstyle and preserve the face shape and identity of the input.","To overcome this, we propose a multi-view optimization framework that uses \"two different views\" of reference composites to semantically guide occluded or ambiguous regions.","Our optimization shares information between two poses, which allows us to produce high fidelity and realistic results from incomplete references.","Our framework produces high-quality results and outperforms prior work in a user study that consists of significantly more challenging hair transfer scenarios than previously studied.","Project page: https://stylegan-salon.github.io/."],"url":"http://arxiv.org/abs/2304.02744v1"}
{"created":"2023-04-05","title":"Zero-shot Medical Image Translation via Frequency-Guided Diffusion Models","abstract":"Recently, the diffusion model has emerged as a superior generative model that can produce high-quality images with excellent realism. There is a growing interest in applying diffusion models to image translation tasks. However, for medical image translation, the existing diffusion models are deficient in accurately retaining structural information since the structure details of source domain images are lost during the forward diffusion process and cannot be fully recovered through learned reverse diffusion, while the integrity of anatomical structures is extremely important in medical images. Training and conditioning diffusion models using paired source and target images with matching anatomy can help. However, such paired data are very difficult and costly to obtain, and may also reduce the robustness of the developed model to out-of-distribution testing data. We propose a frequency-guided diffusion model (FGDM) that employs frequency-domain filters to guide the diffusion model for structure-preserving image translation. Based on its design, FGDM allows zero-shot learning, as it can be trained solely on the data from the target domain, and used directly for source-to-target domain translation without any exposure to the source-domain data during training. We trained FGDM solely on the head-and-neck CT data, and evaluated it on both head-and-neck and lung cone-beam CT (CBCT)-to-CT translation tasks. FGDM outperformed the state-of-the-art methods (GAN-based, VAE-based, and diffusion-based) in all metrics, showing its significant advantages in zero-shot medical image translation.","sentences":["Recently, the diffusion model has emerged as a superior generative model that can produce high-quality images with excellent realism.","There is a growing interest in applying diffusion models to image translation tasks.","However, for medical image translation, the existing diffusion models are deficient in accurately retaining structural information since the structure details of source domain images are lost during the forward diffusion process and cannot be fully recovered through learned reverse diffusion, while the integrity of anatomical structures is extremely important in medical images.","Training and conditioning diffusion models using paired source and target images with matching anatomy can help.","However, such paired data are very difficult and costly to obtain, and may also reduce the robustness of the developed model to out-of-distribution testing data.","We propose a frequency-guided diffusion model (FGDM) that employs frequency-domain filters to guide the diffusion model for structure-preserving image translation.","Based on its design, FGDM allows zero-shot learning, as it can be trained solely on the data from the target domain, and used directly for source-to-target domain translation without any exposure to the source-domain data during training.","We trained FGDM solely on the head-and-neck CT data, and evaluated it on both head-and-neck and lung cone-beam CT (CBCT)-to-CT translation tasks.","FGDM outperformed the state-of-the-art methods (GAN-based, VAE-based, and diffusion-based) in all metrics, showing its significant advantages in zero-shot medical image translation."],"url":"http://arxiv.org/abs/2304.02742v1"}
{"created":"2023-04-05","title":"Batch mode active learning for efficient parameter estimation","abstract":"For many tasks of data analysis, we may only have the information of the explanatory variable and the evaluation of the response values are quite expensive. While it is impractical or too costly to obtain the responses of all units, a natural remedy is to judiciously select a good sample of units, for which the responses are to be evaluated. In this paper, we adopt the classical criteria in design of experiments to quantify the information of a given sample regarding parameter estimation. Then, we provide a theoretical justification for approximating the optimal sample problem by a continuous problem, for which fast algorithms can be further developed with the guarantee of global convergence. Our results have the following novelties: (i) The statistical efficiency of any candidate sample can be evaluated without knowing the exact optimal sample; (ii) It can be applied to a very wide class of statistical models; (iii) It can be integrated with a broad class of information criteria; (iv) It is much faster than existing algorithms. $(v)$ A geometric interpretation is adopted to theoretically justify the relaxation of the original combinatorial problem to continuous optimization problem.","sentences":["For many tasks of data analysis, we may only have the information of the explanatory variable and the evaluation of the response values are quite expensive.","While it is impractical or too costly to obtain the responses of all units, a natural remedy is to judiciously select a good sample of units, for which the responses are to be evaluated.","In this paper, we adopt the classical criteria in design of experiments to quantify the information of a given sample regarding parameter estimation.","Then, we provide a theoretical justification for approximating the optimal sample problem by a continuous problem, for which fast algorithms can be further developed with the guarantee of global convergence.","Our results have the following novelties: (i)","The statistical efficiency of any candidate sample can be evaluated without knowing the exact optimal sample; (ii) It can be applied to a very wide class of statistical models; (iii) It can be integrated with a broad class of information criteria; (iv) It is much faster than existing algorithms.","$(v)$ A geometric interpretation is adopted to theoretically justify the relaxation of the original combinatorial problem to continuous optimization problem."],"url":"http://arxiv.org/abs/2304.02741v1"}
{"created":"2023-04-05","title":"PStrata: An R Package for Principal Stratification","abstract":"Post-treatment confounding is a common problem in causal inference, including special cases of noncompliance, truncation by death, surrogate endpoint, etc. Principal stratification (Frangakis and Rubin 2002) is a general framework for defining and estimating causal effects in the presence of post-treatment confounding. A prominent special case is the instrumental variable approach to noncompliance in randomized experiments (Angrist, Imbens, and Rubin 1996). Despite its versatility, principal stratification is not accessible to the vast majority of applied researchers because its inherent latent mixture structure requires complex inference tools and highly customized programming. We develop the R package PStrata to automatize statistical analysis of principal stratification for several common scenarios. PStrata supports both Bayesian and frequentist paradigms. For the Bayesian paradigm, the computing architecture combines R, C++, Stan, where R provides user-interface, Stan automatizes posterior sampling, and C++ bridges the two by automatically generating Stan code. For the Frequentist paradigm, PStrata implements a triply-robust weighting estimator. PStrata accommodates regular outcomes and time-to-event outcomes with both unstructured and clustered data.","sentences":["Post-treatment confounding is a common problem in causal inference, including special cases of noncompliance, truncation by death, surrogate endpoint, etc.","Principal stratification (Frangakis and Rubin 2002) is a general framework for defining and estimating causal effects in the presence of post-treatment confounding.","A prominent special case is the instrumental variable approach to noncompliance in randomized experiments (Angrist, Imbens, and Rubin 1996).","Despite its versatility, principal stratification is not accessible to the vast majority of applied researchers because its inherent latent mixture structure requires complex inference tools and highly customized programming.","We develop the R package PStrata to automatize statistical analysis of principal stratification for several common scenarios.","PStrata supports both Bayesian and frequentist paradigms.","For the Bayesian paradigm, the computing architecture combines R, C++, Stan, where R provides user-interface, Stan automatizes posterior sampling, and C++ bridges the two by automatically generating Stan code.","For the Frequentist paradigm, PStrata implements a triply-robust weighting estimator.","PStrata accommodates regular outcomes and time-to-event outcomes with both unstructured and clustered data."],"url":"http://arxiv.org/abs/2304.02740v1"}
{"created":"2023-04-05","title":"Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks","abstract":"This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy. The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups. Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology.","sentences":["This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data.","With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information.","Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali.","We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy.","The experiments were conducted on a manually labeled food review dataset consisting of total 6014 real and fake reviews collected from various social media groups.","Researchers that are experiencing difficulty recognizing not just fake reviews but other classification issues owing to a lack of labeled data may find a solution in our proposed methodology."],"url":"http://arxiv.org/abs/2304.02739v1"}
{"created":"2023-04-05","title":"Image Stabilization for Hololens Camera in Remote Collaboration","abstract":"With the advent of new technologies, Augmented Reality (AR) has become an effective tool in remote collaboration. Narrow field-of-view (FoV) and motion blur can offer an unpleasant experience with limited cognition for remote viewers of AR headsets. In this article, we propose a two-stage pipeline to tackle this issue and ensure a stable viewing experience with a larger FoV. The solution involves an offline 3D reconstruction of the indoor environment, followed by enhanced rendering using only the live poses of AR device. We experiment with and evaluate the two different 3D reconstruction methods, RGB-D geometric approach and Neural Radiance Fields (NeRF), based on their data requirements, reconstruction quality, rendering, and training times. The generated sequences from these methods had smoother transitions and provided a better perspective of the environment. The geometry-based enhanced FoV method had better renderings as it lacked blurry outputs making it better than the other attempted approaches. Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR) metrics were used to quantitatively show that the rendering quality using the geometry-based enhanced FoV method is better. Link to the code repository - https://github.com/MixedRealityETHZ/ImageStabilization.","sentences":["With the advent of new technologies, Augmented Reality (AR) has become an effective tool in remote collaboration.","Narrow field-of-view (FoV) and motion blur can offer an unpleasant experience with limited cognition for remote viewers of AR headsets.","In this article, we propose a two-stage pipeline to tackle this issue and ensure a stable viewing experience with a larger FoV.","The solution involves an offline 3D reconstruction of the indoor environment, followed by enhanced rendering using only the live poses of AR device.","We experiment with and evaluate the two different 3D reconstruction methods, RGB-D geometric approach and Neural Radiance Fields (NeRF), based on their data requirements, reconstruction quality, rendering, and training times.","The generated sequences from these methods had smoother transitions and provided a better perspective of the environment.","The geometry-based enhanced FoV method had better renderings as it lacked blurry outputs making it better than the other attempted approaches.","Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR) metrics were used to quantitatively show that the rendering quality using the geometry-based enhanced FoV method is better.","Link to the code repository - https://github.com/MixedRealityETHZ/ImageStabilization."],"url":"http://arxiv.org/abs/2304.02736v1"}
{"created":"2023-04-05","title":"Full Resolution Deconvolution of Complex Faraday Spectra","abstract":"Polarized synchrotron emission from multiple Faraday depths can be separated by calculating the complex Fourier transform of the Stokes' parameters as a function of the wavelength squared, known as Faraday Synthesis. As commonly implemented, the transform introduces an additional term $\\lambda_0^2$, which broadens the real and imaginary spectra, but not the amplitude spectrum. We use idealized tests to investigate whether additional information can be recovered with a clean process restoring beam set to the narrower width of the peak in the real ``full\" resolution spectrum with $\\lambda_0^2=0$. We find that the $\\lambda_0^2$ choice makes no difference, except for the use of a smaller restoring beam. With this smaller beam, the accuracy and phase stability are unchanged for single Faraday components. However, using the smaller restoring beam for multiple Faraday components we find a) better discrimination of the components, b) significant reductions in blending of structures in tomography images, and c) reduction of spurious features in the Faraday spectra and tomography maps. We also discuss the limited accuracy of information on scales comparable to the width of the amplitude spectrum peak, and note a clean-bias, reducing the recovered amplitudes. We present examples using MeerKAT L-band data. We also revisit the maximum width in Faraday depth to which surveys are sensitive, and introduce the variable $W_{max}$, the width for which the power drops by a factor of 2. We find that most surveys cannot resolve continuous Faraday distributions unless the narrower full restoring beam is used.","sentences":["Polarized synchrotron emission from multiple Faraday depths can be separated by calculating the complex Fourier transform of the Stokes' parameters as a function of the wavelength squared, known as Faraday Synthesis.","As commonly implemented, the transform introduces an additional term $\\lambda_0^2$, which broadens the real and imaginary spectra, but not the amplitude spectrum.","We use idealized tests to investigate whether additional information can be recovered with a clean process restoring beam set to the narrower width of the peak in the real ``full\" resolution spectrum with $\\lambda_0^2=0$.","We find that the $\\lambda_0^2$ choice makes no difference, except for the use of a smaller restoring beam.","With this smaller beam, the accuracy and phase stability are unchanged for single Faraday components.","However, using the smaller restoring beam for multiple Faraday components we find a) better discrimination of the components, b) significant reductions in blending of structures in tomography images, and c) reduction of spurious features in the Faraday spectra and tomography maps.","We also discuss the limited accuracy of information on scales comparable to the width of the amplitude spectrum peak, and note a clean-bias, reducing the recovered amplitudes.","We present examples using MeerKAT L-band data.","We also revisit the maximum width in Faraday depth to which surveys are sensitive, and introduce the variable $W_{max}$, the width for which the power drops by a factor of 2.","We find that most surveys cannot resolve continuous Faraday distributions unless the narrower full restoring beam is used."],"url":"http://arxiv.org/abs/2304.02728v1"}
{"created":"2023-04-05","title":"A Quantum-Chemical Bonding Database for Solid-State Materials","abstract":"An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials. Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties. Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis. With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data. We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database. The database structure of the bonding analysis database, which allows easy data retrieval, is also explained. The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively. Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features.","sentences":["An in-depth insight into the chemistry and nature of the individual chemical bonds is essential for understanding materials.","Bonding analysis is thus expected to provide important features for large-scale data analysis and machine learning of material properties.","Such chemical bonding information can be computed using the LOBSTER software package, which post-processes modern density functional theory data by projecting the plane wave-based wave functions onto a local, atomic orbital basis.","With the help of a fully automatic workflow, the VASP and LOBSTER software packages are used to generate the data.","We then perform bonding analyses on 1520 compounds (insulators and semiconductors) and provide the results as a database.","The database structure of the bonding analysis database, which allows easy data retrieval, is also explained.","The projected densities of states and bonding indicators are benchmarked on standard density-functional theory computations and available heuristics, respectively.","Lastly, we illustrate the predictive power of bonding descriptors by constructing a machine-learning model for phononic properties, which shows an increase in prediction accuracies by 27 % (mean absolute errors) compared to a benchmark model differing only by not relying on any quantum-chemical bonding features."],"url":"http://arxiv.org/abs/2304.02726v1"}
{"created":"2023-04-05","title":"Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound","abstract":"Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging. This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images. We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound. The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights. Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation. To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound.","sentences":["Self-supervised pretraining has been observed to improve performance in supervised learning tasks in medical imaging.","This study investigates the utility of self-supervised pretraining prior to conducting supervised fine-tuning for the downstream task of lung sliding classification in M-mode lung ultrasound images.","We propose a novel pairwise relationship that couples M-mode images constructed from the same B-mode image and investigate the utility of data augmentation procedure specific to M-mode lung ultrasound.","The results indicate that self-supervised pretraining yields better performance than full supervision, most notably for feature extractors not initialized with ImageNet-pretrained weights.","Moreover, we observe that including a vast volume of unlabelled data results in improved performance on external validation datasets, underscoring the value of self-supervision for improving generalizability in automatic ultrasound interpretation.","To the authors' best knowledge, this study is the first to characterize the influence of self-supervised pretraining for M-mode ultrasound."],"url":"http://arxiv.org/abs/2304.02724v1"}
{"created":"2023-04-05","title":"Measuring Discrete Risks on Infinite Domains: Theoretical Foundations, Conditional Five Number Summaries, and Data Analyses","abstract":"To accommodate numerous practical scenarios, in this paper we extend statistical inference for smoothed quantile estimators from finite domains to infinite domains. We accomplish the task with the help of a newly designed truncation methodology for discrete loss distributions with infinite domains. A simulation study illustrates the methodology in the case of several distributions, such as Poisson, negative binomial, and their zero inflated versions, which are commonly used in insurance industry to model claim frequencies. Additionally, we propose a very flexible bootstrap-based approach for the use in practice. Using automobile accident data and their modifications, we compute what we have termed the conditional five number summary (C5NS) for the tail risk and construct confidence intervals for each of the five quantiles making up C5NS, and then calculate the tail probabilities. The results show that the smoothed quantile approach classifies the tail riskiness of portfolios not only more accurately but also produces lower coefficients of variation in the estimation of tail probabilities than those obtained using the linear interpolation approach.","sentences":["To accommodate numerous practical scenarios, in this paper we extend statistical inference for smoothed quantile estimators from finite domains to infinite domains.","We accomplish the task with the help of a newly designed truncation methodology for discrete loss distributions with infinite domains.","A simulation study illustrates the methodology in the case of several distributions, such as Poisson, negative binomial, and their zero inflated versions, which are commonly used in insurance industry to model claim frequencies.","Additionally, we propose a very flexible bootstrap-based approach for the use in practice.","Using automobile accident data and their modifications, we compute what we have termed the conditional five number summary (C5NS) for the tail risk and construct confidence intervals for each of the five quantiles making up C5NS, and then calculate the tail probabilities.","The results show that the smoothed quantile approach classifies the tail riskiness of portfolios not only more accurately but also produces lower coefficients of variation in the estimation of tail probabilities than those obtained using the linear interpolation approach."],"url":"http://arxiv.org/abs/2304.02723v1"}
{"created":"2023-04-05","title":"Domain Generalization with Adversarial Intensity Attack for Medical Image Segmentation","abstract":"Most statistical learning algorithms rely on an over-simplified assumption, that is, the train and test data are independent and identically distributed. In real-world scenarios, however, it is common for models to encounter data from new and different domains to which they were not exposed to during training. This is often the case in medical imaging applications due to differences in acquisition devices, imaging protocols, and patient characteristics. To address this problem, domain generalization (DG) is a promising direction as it enables models to handle data from previously unseen domains by learning domain-invariant features robust to variations across different domains. To this end, we introduce a novel DG method called Adversarial Intensity Attack (AdverIN), which leverages adversarial training to generate training data with an infinite number of styles and increase data diversity while preserving essential content information. We conduct extensive evaluation experiments on various multi-domain segmentation datasets, including 2D retinal fundus optic disc/cup and 3D prostate MRI. Our results demonstrate that AdverIN significantly improves the generalization ability of the segmentation models, achieving significant improvement on these challenging datasets. Code is available upon publication.","sentences":["Most statistical learning algorithms rely on an over-simplified assumption, that is, the train and test data are independent and identically distributed.","In real-world scenarios, however, it is common for models to encounter data from new and different domains to which they were not exposed to during training.","This is often the case in medical imaging applications due to differences in acquisition devices, imaging protocols, and patient characteristics.","To address this problem, domain generalization (DG) is a promising direction as it enables models to handle data from previously unseen domains by learning domain-invariant features robust to variations across different domains.","To this end, we introduce a novel DG method called Adversarial Intensity Attack (AdverIN), which leverages adversarial training to generate training data with an infinite number of styles and increase data diversity while preserving essential content information.","We conduct extensive evaluation experiments on various multi-domain segmentation datasets, including 2D retinal fundus optic disc/cup and 3D prostate MRI.","Our results demonstrate that AdverIN significantly improves the generalization ability of the segmentation models, achieving significant improvement on these challenging datasets.","Code is available upon publication."],"url":"http://arxiv.org/abs/2304.02720v1"}
{"created":"2023-04-05","title":"The Large Array Survey Telescope -- Science Goals","abstract":"The Large Array Survey Telescope (LAST) is designed to survey the variable and transient sky at high temporal cadence. The array is comprised of 48 F/2.2 telescopes of 27.9cm aperture, coupled to full-frame backside-illuminated cooled CMOS detectors with $3.76$$\\mu$m pixels, resulting in a pixel scale of $1.25\\mathrm{arcsec}$. A single telescope with a field of view of $7.4\\mathrm{deg}^2$ reaches a $5\\sigma$ limiting magnitude of $19.6$ in $20$s. LAST 48 telescopes are mounted on 12 independent mounts -- a modular design which allows us to conduct optimized parallel surveys. Here we provide a detailed overview of the LAST survey strategy and its key scientific goals. These include the search for gravitational-wave (GW) electromagnetic counterparts with a system that can cover the uncertainty regions of the next-generation GW detectors in a single exposure, the study of planetary systems around white dwarfs, and the search for near-Earth objects. LAST is currently being commissioned, with full scientific operations expected in mid 2023. This paper is accompanied by two complementary publications in this issue, giving an overview of the system (Ofek et al. 2023a) and of the dedicated data reduction pipeline (Ofek et al. 2023b).","sentences":["The Large Array Survey Telescope (LAST) is designed to survey the variable and transient sky at high temporal cadence.","The array is comprised of 48 F/2.2 telescopes of 27.9cm aperture, coupled to full-frame backside-illuminated cooled CMOS detectors with $3.76$$\\mu$m pixels, resulting in a pixel scale of $1.25\\mathrm{arcsec}$. A single telescope with a field of view of $7.4\\mathrm{deg}^2$ reaches a $5\\sigma$ limiting magnitude of $19.6$ in $20$s.","LAST 48 telescopes are mounted on 12 independent mounts -- a modular design which allows us to conduct optimized parallel surveys.","Here we provide a detailed overview of the LAST survey strategy and its key scientific goals.","These include the search for gravitational-wave (GW) electromagnetic counterparts with a system that can cover the uncertainty regions of the next-generation GW detectors in a single exposure, the study of planetary systems around white dwarfs, and the search for near-Earth objects.","LAST is currently being commissioned, with full scientific operations expected in mid 2023.","This paper is accompanied by two complementary publications in this issue, giving an overview of the system (Ofek et al. 2023a) and of the dedicated data reduction pipeline (Ofek et al. 2023b)."],"url":"http://arxiv.org/abs/2304.02719v1"}
{"created":"2023-04-05","title":"Learning Stage-wise GANs for Whistle Extraction in Time-Frequency Spectrograms","abstract":"Whistle contour extraction aims to derive animal whistles from time-frequency spectrograms as polylines. For toothed whales, whistle extraction results can serve as the basis for analyzing animal abundance, species identity, and social activities. During the last few decades, as long-term recording systems have become affordable, automated whistle extraction algorithms were proposed to process large volumes of recording data. Recently, a deep learning-based method demonstrated superior performance in extracting whistles under varying noise conditions. However, training such networks requires a large amount of labor-intensive annotation, which is not available for many species. To overcome this limitation, we present a framework of stage-wise generative adversarial networks (GANs), which compile new whistle data suitable for deep model training via three stages: generation of background noise in the spectrogram, generation of whistle contours, and generation of whistle signals. By separating the generation of different components in the samples, our framework composes visually promising whistle data and labels even when few expert annotated data are available. Regardless of the amount of human-annotated data, the proposed data augmentation framework leads to a consistent improvement in performance of the whistle extraction model, with a maximum increase of 1.69 in the whistle extraction mean F1-score. Our stage-wise GAN also surpasses one single GAN in improving whistle extraction models with augmented data. The data and code will be available at https://github.com/Paul-LiPu/CompositeGAN\\_WhistleAugment.","sentences":["Whistle contour extraction aims to derive animal whistles from time-frequency spectrograms as polylines.","For toothed whales, whistle extraction results can serve as the basis for analyzing animal abundance, species identity, and social activities.","During the last few decades, as long-term recording systems have become affordable, automated whistle extraction algorithms were proposed to process large volumes of recording data.","Recently, a deep learning-based method demonstrated superior performance in extracting whistles under varying noise conditions.","However, training such networks requires a large amount of labor-intensive annotation, which is not available for many species.","To overcome this limitation, we present a framework of stage-wise generative adversarial networks (GANs), which compile new whistle data suitable for deep model training via three stages: generation of background noise in the spectrogram, generation of whistle contours, and generation of whistle signals.","By separating the generation of different components in the samples, our framework composes visually promising whistle data and labels even when few expert annotated data are available.","Regardless of the amount of human-annotated data, the proposed data augmentation framework leads to a consistent improvement in performance of the whistle extraction model, with a maximum increase of 1.69 in the whistle extraction mean F1-score.","Our stage-wise GAN also surpasses one single GAN in improving whistle extraction models with augmented data.","The data and code will be available at https://github.com/Paul-LiPu/CompositeGAN\\_WhistleAugment."],"url":"http://arxiv.org/abs/2304.02714v1"}
{"created":"2023-04-05","title":"NUMSnet: Nested-U Multi-class Segmentation network for 3D Medical Image Stacks","abstract":"Semantic segmentation for medical 3D image stacks enables accurate volumetric reconstructions, computer-aided diagnostics and follow up treatment planning. In this work, we present a novel variant of the Unet model called the NUMSnet that transmits pixel neighborhood features across scans through nested layers to achieve accurate multi-class semantic segmentations with minimal training data. We analyze the semantic segmentation performance of the NUMSnet model in comparison with several Unet model variants to segment 3-7 regions of interest using only 10% of images for training per Lung-CT and Heart-CT volumetric image stacks. The proposed NUMSnet model achieves up to 20% improvement in segmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and 2.5-10% improvement in Dice scores for Heart-CT stacks when compared to the Unet++ model. The NUMSnet model needs to be trained by ordered images around the central scan of each volumetric stack. Propagation of image feature information from the 6 nested layers of the Unet++ model are found to have better computation and segmentation performances than propagation of all up-sampling layers in a Unet++ model. The NUMSnet model achieves comparable segmentation performances to existing works, while being trained on as low as 5\\% of the training images. Also, transfer learning allows faster convergence of the NUMSnet model for multi-class semantic segmentation from pathology in Lung-CT images to cardiac segmentations in Heart-CT stacks. Thus, the proposed model can standardize multi-class semantic segmentation on a variety of volumetric image stacks with minimal training dataset. This can significantly reduce the cost, time and inter-observer variabilities associated with computer-aided detections and treatment.","sentences":["Semantic segmentation for medical 3D image stacks enables accurate volumetric reconstructions, computer-aided diagnostics and follow up treatment planning.","In this work, we present a novel variant of the Unet model called the NUMSnet that transmits pixel neighborhood features across scans through nested layers to achieve accurate multi-class semantic segmentations with minimal training data.","We analyze the semantic segmentation performance of the NUMSnet model in comparison with several Unet model variants to segment 3-7 regions of interest using only 10% of images for training per Lung-CT and Heart-CT volumetric image stacks.","The proposed NUMSnet model achieves up to 20% improvement in segmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and 2.5-10% improvement in Dice scores for Heart-CT stacks when compared to the Unet++ model.","The NUMSnet model needs to be trained by ordered images around the central scan of each volumetric stack.","Propagation of image feature information from the 6 nested layers of the Unet++ model are found to have better computation and segmentation performances than propagation of all up-sampling layers in a Unet++ model.","The NUMSnet model achieves comparable segmentation performances to existing works, while being trained on as low as 5\\% of the training images.","Also, transfer learning allows faster convergence of the NUMSnet model for multi-class semantic segmentation from pathology in Lung-CT images to cardiac segmentations in Heart-CT stacks.","Thus, the proposed model can standardize multi-class semantic segmentation on a variety of volumetric image stacks with minimal training dataset.","This can significantly reduce the cost, time and inter-observer variabilities associated with computer-aided detections and treatment."],"url":"http://arxiv.org/abs/2304.02713v1"}
{"created":"2023-04-05","title":"Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning","abstract":"Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt.","sentences":["Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation.","AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.   ","Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema.","Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema.","SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.   ","We present examples of use of SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease causation graphs.","Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction (RE) methods, but has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any training data.","This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.   ","SPIRES is available as part of the open source OntoGPT package: https://github.com/ monarch-initiative/ontogpt."],"url":"http://arxiv.org/abs/2304.02711v1"}
{"created":"2023-04-05","title":"Human Error Management in Requirements Engineering: Should We Fix the People, the Processes, or the Environment?","abstract":"Context: Software development is human-centric and vulnerable to human error. Human errors are errors in the human thought process. To ensure software quality, practitioners must understand how to manage these human errors. Organizations often change the requirements engineering process to prevent human errors from occurring or to mitigate the harm caused when those errors do occur. While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in software engineering, and requirements engineering specifically, are limited. The software engineering studies do not provide strong results about the types of changes that are most effective in requirements engineering. Objective: The goal of this paper is to develop a taxonomy of human error prevention and mitigation strategies based on data from requirements engineering professionals. Method: We performed a qualitative analysis of two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors. Results: We organized the human error management strategies into a taxonomy based on whether they primarily affect People, Processes, or the Environment. Inside each high-level category, we further organized the strategies into low-level classes. More than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify. In addition, more than 50\\% of the strategies focus on Management activities. Conclusions: The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering. This systematic organization provides a foundation upon which research can build.","sentences":["Context: Software development is human-centric and vulnerable to human error.","Human errors are errors in the human thought process.","To ensure software quality, practitioners must understand how to manage these human errors.","Organizations often change the requirements engineering process to prevent human errors from occurring or to mitigate the harm caused when those errors do occur.","While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in software engineering, and requirements engineering specifically, are limited.","The software engineering studies do not provide strong results about the types of changes that are most effective in requirements engineering.","Objective: The goal of this paper is to develop a taxonomy of human error prevention and mitigation strategies based on data from requirements engineering professionals.","Method: We performed a qualitative analysis of two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors.","Results:","We organized the human error management strategies into a taxonomy based on whether they primarily affect People, Processes, or the Environment.","Inside each high-level category, we further organized the strategies into low-level classes.","More than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify.","In addition, more than 50\\% of the strategies focus on Management activities.","Conclusions: The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering.","This systematic organization provides a foundation upon which research can build."],"url":"http://arxiv.org/abs/2304.02702v1"}
{"created":"2023-04-05","title":"Agnostic proper learning of monotone functions: beyond the black-box correction barrier","abstract":"We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this gap in our knowledge between the run-time and sample complexity.   This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs. This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels.","sentences":["We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions.","Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function.","The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15).","We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient.","Our work thus closes this gap in our knowledge between the run-time and sample complexity.   ","This work builds upon the improper learning algorithm of Bshouty and Tamon (JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld, and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued hypothesis, then ``corrects'' it to monotone using query-efficient local computation algorithms on graphs.","This black-box correction approach can achieve no error better than $2\\mathrm{opt} + \\varepsilon$ information-theoretically; we bypass this barrier by   a) augmenting the improper learner with a convex optimization step, and   b) learning and correcting a real-valued function before rounding its values to Boolean.   ","Our real-valued correction algorithm solves the ``poset sorting'' problem of [LRV22] for functions over general posets with non-Boolean labels."],"url":"http://arxiv.org/abs/2304.02700v1"}
{"created":"2023-04-05","title":"Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data Work","abstract":"Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional. However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when. In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes. We present a rigorous methodology for its creation and discuss its transferability to the visual design process. We operationalize the taxonomy through the development of AutoMLTrace, a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work. Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team. Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work.","sentences":["Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional.","However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when.","In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes.","We present a rigorous methodology for its creation and discuss its transferability to the visual design process.","We operationalize the taxonomy through the development of AutoMLTrace, a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work.","Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team.","Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work."],"url":"http://arxiv.org/abs/2304.02699v1"}
{"created":"2023-04-05","title":"Revolutionizing Single Cell Analysis: The Power of Large Language Models for Cell Type Annotation","abstract":"In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function. However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function. The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types. This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation. By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked. This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences. Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis.","sentences":["In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function.","However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function.","The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types.","This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation.","By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked.","This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences.","Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis."],"url":"http://arxiv.org/abs/2304.02697v1"}
{"created":"2023-04-05","title":"Hierarchical B-frame Video Coding Using Two-Layer CANF without Motion Coding","abstract":"Typical video compression systems consist of two main modules: motion coding and residual coding. This general architecture is adopted by classical coding schemes (such as international standards H.265 and H.266) and deep learning-based coding schemes. We propose a novel B-frame coding architecture based on two-layer Conditional Augmented Normalization Flows (CANF). It has the striking feature of not transmitting any motion information. Our proposed idea of video compression without motion coding offers a new direction for learned video coding. Our base layer is a low-resolution image compressor that replaces the full-resolution motion compressor. The low-resolution coded image is merged with the warped high-resolution images to generate a high-quality image as a conditioning signal for the enhancement-layer image coding in full resolution. One advantage of this architecture is significantly reduced computational complexity due to eliminating the motion information compressor. In addition, we adopt a skip-mode coding technique to reduce the transmitted latent samples. The rate-distortion performance of our scheme is slightly lower than that of the state-of-the-art learned B-frame coding scheme, B-CANF, but outperforms other learned B-frame coding schemes. However, compared to B-CANF, our scheme saves 45% of multiply-accumulate operations (MACs) for encoding and 27% of MACs for decoding. The code is available at https://nycu-clab.github.io.","sentences":["Typical video compression systems consist of two main modules: motion coding and residual coding.","This general architecture is adopted by classical coding schemes (such as international standards H.265 and H.266) and deep learning-based coding schemes.","We propose a novel B-frame coding architecture based on two-layer Conditional Augmented Normalization Flows (CANF).","It has the striking feature of not transmitting any motion information.","Our proposed idea of video compression without motion coding offers a new direction for learned video coding.","Our base layer is a low-resolution image compressor that replaces the full-resolution motion compressor.","The low-resolution coded image is merged with the warped high-resolution images to generate a high-quality image as a conditioning signal for the enhancement-layer image coding in full resolution.","One advantage of this architecture is significantly reduced computational complexity due to eliminating the motion information compressor.","In addition, we adopt a skip-mode coding technique to reduce the transmitted latent samples.","The rate-distortion performance of our scheme is slightly lower than that of the state-of-the-art learned B-frame coding scheme, B-CANF, but outperforms other learned B-frame coding schemes.","However, compared to B-CANF, our scheme saves 45% of multiply-accumulate operations (MACs) for encoding and 27% of MACs for decoding.","The code is available at https://nycu-clab.github.io."],"url":"http://arxiv.org/abs/2304.02690v1"}
{"created":"2023-04-05","title":"ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast","abstract":"Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects). Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria. However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced. In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation. Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers. Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes. Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings. Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency.","sentences":["Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects).","Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria.","However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced.","In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation.","Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers.","Moreover, we argue that blindly adopting a constant temperature $\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\\tau$ via a simple cosine schedule to yield better separation between majority and minority classes.","Empirically, we evaluate ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art across two semi-supervised settings.","Theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency."],"url":"http://arxiv.org/abs/2304.02689v1"}
{"created":"2023-04-05","title":"Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability","abstract":"Transferability is the property of adversarial examples to be misclassified by other models than the surrogate model for which they were crafted. Previous research has shown that transferability is substantially increased when the training of the surrogate model has been early stopped. A common hypothesis to explain this is that the later training epochs are when models learn the non-robust features that adversarial attacks exploit. Hence, an early stopped model is more robust (hence, a better surrogate) than fully trained models. We demonstrate that the reasons why early stopping improves transferability lie in the side effects it has on the learning dynamics of the model. We first show that early stopping benefits transferability even on models learning from data with non-robust features. We then establish links between transferability and the exploration of the loss landscape in the parameter space, on which early stopping has an inherent effect. More precisely, we observe that transferability peaks when the learning rate decays, which is also the time at which the sharpness of the loss significantly drops. This leads us to propose RFN, a new approach for transferability that minimizes loss sharpness during training in order to maximize transferability. We show that by searching for large flat neighborhoods, RFN always improves over early stopping (by up to 47 points of transferability rate) and is competitive to (if not better than) strong state-of-the-art baselines.","sentences":["Transferability is the property of adversarial examples to be misclassified by other models than the surrogate model for which they were crafted.","Previous research has shown that transferability is substantially increased when the training of the surrogate model has been early stopped.","A common hypothesis to explain this is that the later training epochs are when models learn the non-robust features that adversarial attacks exploit.","Hence, an early stopped model is more robust (hence, a better surrogate) than fully trained models.","We demonstrate that the reasons why early stopping improves transferability lie in the side effects it has on the learning dynamics of the model.","We first show that early stopping benefits transferability even on models learning from data with non-robust features.","We then establish links between transferability and the exploration of the loss landscape in the parameter space, on which early stopping has an inherent effect.","More precisely, we observe that transferability peaks when the learning rate decays, which is also the time at which the sharpness of the loss significantly drops.","This leads us to propose RFN, a new approach for transferability that minimizes loss sharpness during training in order to maximize transferability.","We show that by searching for large flat neighborhoods, RFN always improves over early stopping (by up to 47 points of transferability rate) and is competitive to (if not better than) strong state-of-the-art baselines."],"url":"http://arxiv.org/abs/2304.02688v1"}
{"created":"2023-04-05","title":"Chebyshev approximation of exponential data","abstract":"In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm. We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset.","sentences":["In this paper we present an algorithm to fit data via exponentials when the error is measured using the max-norm.","We prove the necesssary results to show that the algorithm will converge to the best approximation no matter the dataset."],"url":"http://arxiv.org/abs/2304.02686v1"}
{"created":"2023-04-05","title":"Causal inference is not a statistical problem","abstract":"This paper introduces a collection of four data sets, similar to Anscombe's Quartet, that aim to highlight the challenges involved when estimating causal effects. Each of the four data sets is generated based on a distinct causal mechanism: the first involves a collider, the second involves a confounder, the third involves a mediator, and the fourth involves the induction of M-Bias by an included factor. The paper includes a mathematical summary of each data set, as well as directed acyclic graphs that depict the relationships between the variables. Despite the fact that the statistical summaries and visualizations for each data set are identical, the true causal effect differs, and estimating it correctly requires knowledge of the data-generating mechanism. These example data sets can help practitioners gain a better understanding of the assumptions underlying causal inference methods and emphasize the importance of gathering more information beyond what can be obtained from statistical tools alone. The paper also includes R code for reproducing all figures and provides access to the data sets themselves through an R package named quartet.","sentences":["This paper introduces a collection of four data sets, similar to Anscombe's Quartet, that aim to highlight the challenges involved when estimating causal effects.","Each of the four data sets is generated based on a distinct causal mechanism: the first involves a collider, the second involves a confounder, the third involves a mediator, and the fourth involves the induction of M-Bias by an included factor.","The paper includes a mathematical summary of each data set, as well as directed acyclic graphs that depict the relationships between the variables.","Despite the fact that the statistical summaries and visualizations for each data set are identical, the true causal effect differs, and estimating it correctly requires knowledge of the data-generating mechanism.","These example data sets can help practitioners gain a better understanding of the assumptions underlying causal inference methods and emphasize the importance of gathering more information beyond what can be obtained from statistical tools alone.","The paper also includes R code for reproducing all figures and provides access to the data sets themselves through an R package named quartet."],"url":"http://arxiv.org/abs/2304.02683v1"}
{"created":"2023-04-05","title":"nD-PDPA: nDimensional Probability Density Profile Analysis","abstract":"Despite the recent advances in various Structural Genomics Projects, a large gap remains between the number of sequenced and structurally characterized proteins. Some reasons for this discrepancy include technical difficulties, labor, and the cost related to determining a structure by experimental methods such as NMR spectroscopy. Several computational methods have been developed to expand the applicability of NMR spectroscopy by addressing temporal and economical problems more efficiently. While these methods demonstrate successful outcomes to solve more challenging and structurally novel proteins, the cost has not been reduced significantly. Probability Density Profile Analysis (PDPA) has been previously introduced by our lab to directly address the economics of structure determination of routine proteins and the identification of novel structures from a minimal set of unassigned NMR data. 2D-PDPA (in which 2D denotes incorporation of data from two alignment media) has been successful in identifying the structural homolog of an unknown protein within a library of ~1000 decoy structures. In order to further expand the selectivity and sensitivity of PDPA, the incorporation of additional data was necessary. However, the expansion of the original PDPA approach was limited by its computational requirements where the inclusion of additional data would render it computationally intractable. Here we present the most recent developments of PDPA method (nD-PDPA: n Dimensional Probability Density Profile Analysis) that eliminate 2D-PDPA's computational limitations, and allows inclusion of RDC data from multiple vector types in multiple alignment media.","sentences":["Despite the recent advances in various Structural Genomics Projects, a large gap remains between the number of sequenced and structurally characterized proteins.","Some reasons for this discrepancy include technical difficulties, labor, and the cost related to determining a structure by experimental methods such as NMR spectroscopy.","Several computational methods have been developed to expand the applicability of NMR spectroscopy by addressing temporal and economical problems more efficiently.","While these methods demonstrate successful outcomes to solve more challenging and structurally novel proteins, the cost has not been reduced significantly.","Probability Density Profile Analysis (PDPA) has been previously introduced by our lab to directly address the economics of structure determination of routine proteins and the identification of novel structures from a minimal set of unassigned NMR data.","2D-PDPA (in which 2D denotes incorporation of data from two alignment media) has been successful in identifying the structural homolog of an unknown protein within a library of ~1000 decoy structures.","In order to further expand the selectivity and sensitivity of PDPA, the incorporation of additional data was necessary.","However, the expansion of the original PDPA approach was limited by its computational requirements where the inclusion of additional data would render it computationally intractable.","Here we present the most recent developments of PDPA method (nD-PDPA: n Dimensional Probability Density Profile Analysis) that eliminate 2D-PDPA's computational limitations, and allows inclusion of RDC data from multiple vector types in multiple alignment media."],"url":"http://arxiv.org/abs/2304.02682v1"}
{"created":"2023-04-05","title":"Reconstructing Network Dynamics of Coupled Discrete Chaotic Units from Data","abstract":"Reconstructing network dynamics from data is crucial for predicting the changes in the dynamics of complex systems such as neuron networks; however, previous research has shown that the reconstruction is possible under strong constraints such as the need for lengthy data or small system size. Here, we present a recovery scheme blending theoretical model reduction and sparse recovery to identify the governing equations and the interactions of weakly coupled chaotic maps on complex networks, easing unrealistic constraints for real-world applications. Learning dynamics and connectivity lead to detecting critical transitions for parameter changes. We apply our technique to realistic neuronal systems with and without noise on a real mouse neocortex and artificial networks.","sentences":["Reconstructing network dynamics from data is crucial for predicting the changes in the dynamics of complex systems such as neuron networks; however, previous research has shown that the reconstruction is possible under strong constraints such as the need for lengthy data or small system size.","Here, we present a recovery scheme blending theoretical model reduction and sparse recovery to identify the governing equations and the interactions of weakly coupled chaotic maps on complex networks, easing unrealistic constraints for real-world applications.","Learning dynamics and connectivity lead to detecting critical transitions for parameter changes.","We apply our technique to realistic neuronal systems with and without noise on a real mouse neocortex and artificial networks."],"url":"http://arxiv.org/abs/2304.02670v1"}
{"created":"2023-04-05","title":"Deep learning approach for identification of HII regions during reionization in 21-cm observations -- II. foreground contamination","abstract":"The upcoming Square Kilometre Array Observatory (SKAO) will produce images of neutral hydrogen distribution during the epoch of reionization by observing the corresponding 21-cm signal. However, the 21-cm signal will be subject to instrumental limitations such as noise, foreground contamination, and limited resolution, which pose a challenge for accurate detection. In this study, we present the \\texttt{SegU-Net v2} framework, which is an enhanced version of our U-Net architecture-based convolutional neural network built for segmenting image data into meaningful features. This framework is designed to identify neutral and ionized regions in the 21-cm signal contaminated with foreground emission that is $\\sim$3 order of magnitude larger. We demonstrate the effectiveness of our method by estimating the true ionization history from mock observations of SKA with an observation time of 1000 h, achieving an average classification accuracy of 71 per cent. As the photon sources driving reionization are expected to be located inside the ionised regions identified by \\texttt{SegU-Net v2}, this tool can be used to identify locations for follow-up studies with infrared/optical telescopes to detect these sources. Additionally, we derive summary statistics, such as the size distribution of neutral islands, from evaluating the reliability of our method on the tomographic data expected from the SKA-Low. Our study suggests that \\texttt{SegU-Net v2} can be a stable and reliable tool for analyzing the 3D tomographic data produced by the SKA and recovering important information about the non-Gaussian nature of the reionization process.","sentences":["The upcoming Square Kilometre Array Observatory (SKAO) will produce images of neutral hydrogen distribution during the epoch of reionization by observing the corresponding 21-cm signal.","However, the 21-cm signal will be subject to instrumental limitations such as noise, foreground contamination, and limited resolution, which pose a challenge for accurate detection.","In this study, we present the \\texttt{SegU-Net v2} framework, which is an enhanced version of our U-Net architecture-based convolutional neural network built for segmenting image data into meaningful features.","This framework is designed to identify neutral and ionized regions in the 21-cm signal contaminated with foreground emission that is $\\sim$3 order of magnitude larger.","We demonstrate the effectiveness of our method by estimating the true ionization history from mock observations of SKA with an observation time of 1000 h, achieving an average classification accuracy of 71 per cent.","As the photon sources driving reionization are expected to be located inside the ionised regions identified by \\texttt{SegU-Net v2}, this tool can be used to identify locations for follow-up studies with infrared/optical telescopes to detect these sources.","Additionally, we derive summary statistics, such as the size distribution of neutral islands, from evaluating the reliability of our method on the tomographic data expected from the SKA-Low.","Our study suggests that \\texttt{SegU-Net v2} can be a stable and reliable tool for analyzing the 3D tomographic data produced by the SKA and recovering important information about the non-Gaussian nature of the reionization process."],"url":"http://arxiv.org/abs/2304.02661v1"}
{"created":"2023-04-05","title":"Segment Anything","abstract":"We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.","sentences":["We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation.","Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images.","The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.","We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results.","We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision."],"url":"http://arxiv.org/abs/2304.02643v1"}
{"created":"2023-04-05","title":"Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models","abstract":"This paper proposes a method for generating images of customized objects specified by users. The method is based on a general framework that bypasses the lengthy optimization required by previous approaches, which often employ a per-object optimization paradigm. Our framework adopts an encoder to capture high-level identifiable semantics of objects, producing an object-specific embedding with only a single feed-forward pass. The acquired object embedding is then passed to a text-to-image synthesis model for subsequent generation. To effectively blend a object-aware embedding space into a well developed text-to-image model under the same generation context, we investigate different network designs and training strategies, and propose a simple yet effective regularized joint training scheme with an object identity preservation loss. Additionally, we propose a caption generation scheme that become a critical piece in fostering object specific embedding faithfully reflected into the generation process, while keeping control and editing abilities. Once trained, the network is able to produce diverse content and styles, conditioned on both texts and objects. We demonstrate through experiments that our proposed method is able to synthesize images with compelling output quality, appearance diversity, and object fidelity, without the need of test-time optimization. Systematic studies are also conducted to analyze our models, providing insights for future work.","sentences":["This paper proposes a method for generating images of customized objects specified by users.","The method is based on a general framework that bypasses the lengthy optimization required by previous approaches, which often employ a per-object optimization paradigm.","Our framework adopts an encoder to capture high-level identifiable semantics of objects, producing an object-specific embedding with only a single feed-forward pass.","The acquired object embedding is then passed to a text-to-image synthesis model for subsequent generation.","To effectively blend a object-aware embedding space into a well developed text-to-image model under the same generation context, we investigate different network designs and training strategies, and propose a simple yet effective regularized joint training scheme with an object identity preservation loss.","Additionally, we propose a caption generation scheme that become a critical piece in fostering object specific embedding faithfully reflected into the generation process, while keeping control and editing abilities.","Once trained, the network is able to produce diverse content and styles, conditioned on both texts and objects.","We demonstrate through experiments that our proposed method is able to synthesize images with compelling output quality, appearance diversity, and object fidelity, without the need of test-time optimization.","Systematic studies are also conducted to analyze our models, providing insights for future work."],"url":"http://arxiv.org/abs/2304.02642v1"}
{"created":"2023-04-05","title":"Self-Distillation for Gaussian Process Regression and Classification","abstract":"We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric. The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration. By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters. Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the model from a Binomial likelihood to a continuous Bernoulli likelihood to be well-specified. To the best of our knowledge, our proposed approaches are the first to formulate knowledge distillation specifically for Gaussian Process models.","sentences":["We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric.","The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration.","By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters.","Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the model from a Binomial likelihood to a continuous Bernoulli likelihood to be well-specified.","To the best of our knowledge, our proposed approaches are the first to formulate knowledge distillation specifically for Gaussian Process models."],"url":"http://arxiv.org/abs/2304.02641v1"}
{"created":"2023-04-05","title":"ENTL: Embodied Navigation Trajectory Learner","abstract":"We propose Embodied Navigation Trajectory Learner (ENTL), a method for extracting long sequence representations for embodied navigation. Our approach unifies world modeling, localization and imitation learning into a single sequence prediction task. We train our model using vector-quantized predictions of future states conditioned on current states and actions. ENTL's generic architecture enables the sharing of the the spatio-temporal sequence encoder for multiple challenging embodied tasks. We achieve competitive performance on navigation tasks using significantly less data than strong baselines while performing auxiliary tasks such as localization and future frame prediction (a proxy for world modeling). A key property of our approach is that the model is pre-trained without any explicit reward signal, which makes the resulting model generalizable to multiple tasks and environments.","sentences":["We propose Embodied Navigation Trajectory Learner (ENTL), a method for extracting long sequence representations for embodied navigation.","Our approach unifies world modeling, localization and imitation learning into a single sequence prediction task.","We train our model using vector-quantized predictions of future states conditioned on current states and actions.","ENTL's generic architecture enables the sharing of the the spatio-temporal sequence encoder for multiple challenging embodied tasks.","We achieve competitive performance on navigation tasks using significantly less data than strong baselines while performing auxiliary tasks such as localization and future frame prediction (a proxy for world modeling).","A key property of our approach is that the model is pre-trained without any explicit reward signal, which makes the resulting model generalizable to multiple tasks and environments."],"url":"http://arxiv.org/abs/2304.02639v1"}
{"created":"2023-04-05","title":"GenPhys: From Physical Processes to Generative Models","abstract":"Since diffusion models (DM) and the more recent Poisson flow generative models (PFGM) are inspired by physical processes, it is reasonable to ask: Can physical processes offer additional new generative models? We show that the answer is yes. We introduce a general family, Generative Models from Physical Processes (GenPhys), where we translate partial differential equations (PDEs) describing physical processes to generative models. We show that generative models can be constructed from s-generative PDEs (s for smooth). GenPhys subsume the two existing generative models (DM and PFGM) and even give rise to new families of generative models, e.g., \"Yukawa Generative Models\" inspired from weak interactions. On the other hand, some physical processes by default do not belong to the GenPhys family, e.g., the wave equation and the Schr\\\"{o}dinger equation, but could be made into the GenPhys family with some modifications. Our goal with GenPhys is to explore and expand the design space of generative models.","sentences":["Since diffusion models (DM) and the more recent Poisson flow generative models (PFGM) are inspired by physical processes, it is reasonable to ask: Can physical processes offer additional new generative models?","We show that the answer is yes.","We introduce a general family, Generative Models from Physical Processes (GenPhys), where we translate partial differential equations (PDEs) describing physical processes to generative models.","We show that generative models can be constructed from s-generative PDEs (s for smooth).","GenPhys subsume the two existing generative models (DM and PFGM) and even give rise to new families of generative models, e.g., \"Yukawa Generative Models\" inspired from weak interactions.","On the other hand, some physical processes by default do not belong to the GenPhys family, e.g., the wave equation and the Schr\\\"{o}dinger equation, but could be made into the GenPhys family with some modifications.","Our goal with GenPhys is to explore and expand the design space of generative models."],"url":"http://arxiv.org/abs/2304.02637v1"}
{"created":"2023-04-05","title":"HNeRV: A Hybrid Neural Representation for Videos","abstract":"Implicit neural representations store videos as neural networks and have performed well for various vision tasks such as video compression and denoising. With frame index or positional index as input, implicit representations (NeRV, E-NeRV, \\etc) reconstruct video from fixed and content-agnostic embeddings. Such embedding largely limits the regression capacity and internal generalization for video interpolation. In this paper, we propose a Hybrid Neural Representation for Videos (HNeRV), where a learnable encoder generates content-adaptive embeddings, which act as the decoder input. Besides the input embedding, we introduce HNeRV blocks, which ensure model parameters are evenly distributed across the entire network, such that higher layers (layers near the output) can have more capacity to store high-resolution content and video details. With content-adaptive embeddings and re-designed architecture, HNeRV outperforms implicit methods in video regression tasks for both reconstruction quality ($+4.7$ PSNR) and convergence speed ($16\\times$ faster), and shows better internal generalization. As a simple and efficient video representation, HNeRV also shows decoding advantages for speed, flexibility, and deployment, compared to traditional codecs~(H.264, H.265) and learning-based compression methods. Finally, we explore the effectiveness of HNeRV on downstream tasks such as video compression and video inpainting. We provide project page at https://haochen-rye.github.io/HNeRV, and Code at https://github.com/haochen-rye/HNeRV","sentences":["Implicit neural representations store videos as neural networks and have performed well for various vision tasks such as video compression and denoising.","With frame index or positional index as input, implicit representations (NeRV, E-NeRV, \\etc) reconstruct video from fixed and content-agnostic embeddings.","Such embedding largely limits the regression capacity and internal generalization for video interpolation.","In this paper, we propose a Hybrid Neural Representation for Videos (HNeRV), where a learnable encoder generates content-adaptive embeddings, which act as the decoder input.","Besides the input embedding, we introduce HNeRV blocks, which ensure model parameters are evenly distributed across the entire network, such that higher layers (layers near the output) can have more capacity to store high-resolution content and video details.","With content-adaptive embeddings and re-designed architecture, HNeRV outperforms implicit methods in video regression tasks for both reconstruction quality ($+4.7$ PSNR) and convergence speed ($16\\times$ faster), and shows better internal generalization.","As a simple and efficient video representation, HNeRV also shows decoding advantages for speed, flexibility, and deployment, compared to traditional codecs~(H.264, H.265) and learning-based compression methods.","Finally, we explore the effectiveness of HNeRV on downstream tasks such as video compression and video inpainting.","We provide project page at https://haochen-rye.github.io/HNeRV, and Code at https://github.com/haochen-rye/HNeRV"],"url":"http://arxiv.org/abs/2304.02633v1"}
{"created":"2023-04-05","title":"Mapping historical forest biomass for stock-change assessments at parcel to landscape scales","abstract":"Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios. Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time. Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.   Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches for mapping historical forest aboveground biomass (AGB): training on FIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps (indirect), and an ensemble averaging predictions from the direct and indirect models. Model prediction surfaces (maps) were tested against FIA estimates at multiple scales. All three approaches produced viable outputs, yet tradeoffs were evident in terms of model complexity, map accuracy, saturation, and fine-scale pattern representation. The resulting map products can help identify where, when, and how forest carbon stocks are changing as a result of both anthropogenic and natural drivers alike. These products can thus serve as inputs to a wide range of applications including stock-change assessments, monitoring reporting and verification frameworks, and prioritizing parcels for protection or enrollment in improved management programs.","sentences":["Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios.","Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time.","Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.   ","Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches for mapping historical forest aboveground biomass (AGB): training on FIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps (indirect), and an ensemble averaging predictions from the direct and indirect models.","Model prediction surfaces (maps) were tested against FIA estimates at multiple scales.","All three approaches produced viable outputs, yet tradeoffs were evident in terms of model complexity, map accuracy, saturation, and fine-scale pattern representation.","The resulting map products can help identify where, when, and how forest carbon stocks are changing as a result of both anthropogenic and natural drivers alike.","These products can thus serve as inputs to a wide range of applications including stock-change assessments, monitoring reporting and verification frameworks, and prioritizing parcels for protection or enrollment in improved management programs."],"url":"http://arxiv.org/abs/2304.02632v1"}
{"created":"2023-04-05","title":"Detection of extended gamma-ray emission around the Geminga pulsar with H.E.S.S","abstract":"Geminga is an enigmatic radio-quiet gamma-ray pulsar located at a mere 250 pc distance from Earth. Extended very-high-energy gamma-ray emission around the pulsar was discovered by Milagro and later confirmed by HAWC, which are both water Cherenkov detector-based experiments. However, evidence for the Geminga pulsar wind nebula in gamma rays has long evaded detection by imaging atmospheric Cherenkov telescopes (IACTs) despite targeted observations. The detection of gamma-ray emission on angular scales > 2 deg poses a considerable challenge for the background estimation in IACT data analysis. With recent developments in understanding the complementary background estimation techniques of water Cherenkov and atmospheric Cherenkov instruments, the H.E.S.S. IACT array can now confirm the detection of highly extended gamma-ray emission around the Geminga pulsar with a radius of at least 3 deg in the energy range 0.5-40 TeV. We find no indications for statistically significant asymmetries or energy-dependent morphology. A flux normalisation of $(2.8\\pm0.7)\\times10^{-12}$ cm$^{-2}$s$^{-1}$TeV$^{-1}$ at 1 TeV is obtained within a 1 deg radius region around the pulsar. To investigate the particle transport within the halo of energetic leptons around the pulsar, we fitted an electron diffusion model to the data. The normalisation of the diffusion coefficient obtained of $D_0 = 7.6^{+1.5}_{-1.2} \\times 10^{27}$ cm$^2$s$^{-1}$, at an electron energy of 100 TeV, is compatible with values previously reported for the pulsar halo around Geminga, which is considerably below the Galactic average.","sentences":["Geminga is an enigmatic radio-quiet gamma-ray pulsar located at a mere 250 pc distance from Earth.","Extended very-high-energy gamma-ray emission around the pulsar was discovered by Milagro and later confirmed by HAWC, which are both water Cherenkov detector-based experiments.","However, evidence for the Geminga pulsar wind nebula in gamma rays has long evaded detection by imaging atmospheric Cherenkov telescopes (IACTs) despite targeted observations.","The detection of gamma-ray emission on angular scales > 2 deg poses a considerable challenge for the background estimation in IACT data analysis.","With recent developments in understanding the complementary background estimation techniques of water Cherenkov and atmospheric Cherenkov instruments, the H.E.S.S. IACT array can now confirm the detection of highly extended gamma-ray emission around the Geminga pulsar with a radius of at least 3 deg in the energy range 0.5-40 TeV. We find no indications for statistically significant asymmetries or energy-dependent morphology.","A flux normalisation of $(2.8\\pm0.7)\\times10^{-12}$ cm$^{-2}$s$^{-1}$TeV$^{-1}$ at 1 TeV is obtained within a 1 deg radius region around the pulsar.","To investigate the particle transport within the halo of energetic leptons around the pulsar, we fitted an electron diffusion model to the data.","The normalisation of the diffusion coefficient obtained of $D_0 = 7.6^{+1.5}_{-1.2} \\times 10^{27}$ cm$^2$s$^{-1}$, at an electron energy of 100 TeV, is compatible with values previously reported for the pulsar halo around Geminga, which is considerably below the Galactic average."],"url":"http://arxiv.org/abs/2304.02631v1"}
{"created":"2023-04-05","title":"What Affects Learned Equivariance in Deep Image Recognition Models?","abstract":"Equivariance w.r.t. geometric transformations in neural networks improves data efficiency, parameter efficiency and robustness to out-of-domain perspective shifts. When equivariance is not designed into a neural network, the network can still learn equivariant functions from the data. We quantify this learned equivariance, by proposing an improved measure for equivariance. We find evidence for a correlation between learned translation equivariance and validation accuracy on ImageNet. We therefore investigate what can increase the learned equivariance in neural networks, and find that data augmentation, reduced model capacity and inductive bias in the form of convolutions induce higher learned equivariance in neural networks.","sentences":["Equivariance w.r.t. geometric transformations in neural networks improves data efficiency, parameter efficiency and robustness to out-of-domain perspective shifts.","When equivariance is not designed into a neural network, the network can still learn equivariant functions from the data.","We quantify this learned equivariance, by proposing an improved measure for equivariance.","We find evidence for a correlation between learned translation equivariance and validation accuracy on ImageNet.","We therefore investigate what can increase the learned equivariance in neural networks, and find that data augmentation, reduced model capacity and inductive bias in the form of convolutions induce higher learned equivariance in neural networks."],"url":"http://arxiv.org/abs/2304.02628v1"}
{"created":"2023-04-05","title":"Dynamic Point Fields","abstract":"Recent years have witnessed significant progress in the field of neural surface reconstruction. While the extensive focus was put on volumetric and implicit approaches, a number of works have shown that explicit graphics primitives such as point clouds can significantly reduce computational complexity, without sacrificing the reconstructed surface quality. However, less emphasis has been put on modeling dynamic surfaces with point primitives. In this work, we present a dynamic point field model that combines the representational benefits of explicit point-based graphics with implicit deformation networks to allow efficient modeling of non-rigid 3D surfaces. Using explicit surface primitives also allows us to easily incorporate well-established constraints such as-isometric-as-possible regularisation. While learning this deformation model is prone to local optima when trained in a fully unsupervised manner, we propose to additionally leverage semantic information such as keypoint dynamics to guide the deformation learning. We demonstrate our model with an example application of creating an expressive animatable human avatar from a collection of 3D scans. Here, previous methods mostly rely on variants of the linear blend skinning paradigm, which fundamentally limits the expressivity of such models when dealing with complex cloth appearances such as long skirts. We show the advantages of our dynamic point field framework in terms of its representational power, learning efficiency, and robustness to out-of-distribution novel poses.","sentences":["Recent years have witnessed significant progress in the field of neural surface reconstruction.","While the extensive focus was put on volumetric and implicit approaches, a number of works have shown that explicit graphics primitives such as point clouds can significantly reduce computational complexity, without sacrificing the reconstructed surface quality.","However, less emphasis has been put on modeling dynamic surfaces with point primitives.","In this work, we present a dynamic point field model that combines the representational benefits of explicit point-based graphics with implicit deformation networks to allow efficient modeling of non-rigid 3D surfaces.","Using explicit surface primitives also allows us to easily incorporate well-established constraints such as-isometric-as-possible regularisation.","While learning this deformation model is prone to local optima when trained in a fully unsupervised manner, we propose to additionally leverage semantic information such as keypoint dynamics to guide the deformation learning.","We demonstrate our model with an example application of creating an expressive animatable human avatar from a collection of 3D scans.","Here, previous methods mostly rely on variants of the linear blend skinning paradigm, which fundamentally limits the expressivity of such models when dealing with complex cloth appearances such as long skirts.","We show the advantages of our dynamic point field framework in terms of its representational power, learning efficiency, and robustness to out-of-distribution novel poses."],"url":"http://arxiv.org/abs/2304.02626v2"}
{"created":"2023-04-05","title":"High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation","abstract":"The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior. As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines. This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset. Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting. Our code is available at https://github.com/arvijj/hfpl.","sentences":["The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models.","The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps.","This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions.","The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth.","In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images.","In this work, we propose a different probabilistic interpretation of CAMs for these techniques, rendering the likelihood more appropriate than the multinomial posterior.","As a result, we propose an add-on method that can boost essentially any previous WSSS method, improving both the region similarity and contour quality of all implemented state-of-the-art baselines.","This is demonstrated on a wide variety of baselines on the PASCAL VOC dataset.","Experiments on the MS COCO dataset show that performance gains can also be achieved in a large-scale setting.","Our code is available at https://github.com/arvijj/hfpl."],"url":"http://arxiv.org/abs/2304.02621v1"}
{"created":"2023-04-05","title":"An atlas of the heterogeneous viscoelastic brain with local power-law attenuation synthesised using Prony-series","abstract":"This review addresses the acute need to acknowledge the mechanical heterogeneity of brain matter and to accurately calibrate its local viscoelastic material properties accordingly. Specifically, it is important to compile the existing and disparate literature on attenuation power laws and dispersion to make progress in wave physics of brain matter, a field of research that has the potential to explain the mechanisms at play in diffuse axonal injury and mild traumatic brain injury in general. Currently, viscous effects in the brain are modelled using Prony-series, i.e., a sum of decaying exponentials at different relaxation times. Here we collect and synthesise the Prony-series coefficients appearing in the literature for twelve regions: brainstem, basal ganglia, cerebellum, corona radiata, corpus callosum, cortex, dentate gyrus, hippocampus, thalamus, grey matter, white matter, homogeneous brain, and for eight different mammals: pig, rat, human, mouse, cow, sheep, monkey and dog. Using this data, we compute the fractional-exponent attenuation power laws for different tissues of the brain, the corresponding dispersion laws resulting from causality, and the averaged Prony-series coefficients.","sentences":["This review addresses the acute need to acknowledge the mechanical heterogeneity of brain matter and to accurately calibrate its local viscoelastic material properties accordingly.","Specifically, it is important to compile the existing and disparate literature on attenuation power laws and dispersion to make progress in wave physics of brain matter, a field of research that has the potential to explain the mechanisms at play in diffuse axonal injury and mild traumatic brain injury in general.","Currently, viscous effects in the brain are modelled using Prony-series, i.e., a sum of decaying exponentials at different relaxation times.","Here we collect and synthesise the Prony-series coefficients appearing in the literature for twelve regions: brainstem, basal ganglia, cerebellum, corona radiata, corpus callosum, cortex, dentate gyrus, hippocampus, thalamus, grey matter, white matter, homogeneous brain, and for eight different mammals: pig, rat, human, mouse, cow, sheep, monkey and dog.","Using this data, we compute the fractional-exponent attenuation power laws for different tissues of the brain, the corresponding dispersion laws resulting from causality, and the averaged Prony-series coefficients."],"url":"http://arxiv.org/abs/2304.02610v1"}
{"created":"2023-04-05","title":"A Checklist to Publish Collections as Data in GLAM Institutions","abstract":"Large-scale digitization in Galleries, Libraries, Archives and Museums (GLAM) created the conditions for providing access to collections as data. It opened new opportunities to explore, use and reuse digital collections. Strong proponents of collections as data are the Innovation Labs which provided numerous examples of publishing datasets under open licenses in order to reuse digital content in novel and creative ways. Within the current transition to the emerging data spaces, clouds for cultural heritage and open science, the need to identify practices which support more GLAM institutions to offer datasets becomes a priority, especially within the smaller and medium-sized institutions.   This paper answers the need to support GLAM institutions in facilitating the transition into publishing their digital content and to introduce collections as data services; this will also help their future efficient contribution to data spaces and cultural heritage clouds. It offers a checklist that can be used for both creating and evaluating digital collections suitable for computational use. The main contributions of this paper are i) a methodology for devising a checklist to create and assess digital collections for computational use; ii) a checklist to create and assess digital collections suitable for use with computational methods; iii) the assessment of the checklist against the practice of institutions innovating in the Collections as data field; and iv) the results obtained after the application and recommendations for the use of the checklist in GLAM institutions.","sentences":["Large-scale digitization in Galleries, Libraries, Archives and Museums (GLAM) created the conditions for providing access to collections as data.","It opened new opportunities to explore, use and reuse digital collections.","Strong proponents of collections as data are the Innovation Labs which provided numerous examples of publishing datasets under open licenses in order to reuse digital content in novel and creative ways.","Within the current transition to the emerging data spaces, clouds for cultural heritage and open science, the need to identify practices which support more GLAM institutions to offer datasets becomes a priority, especially within the smaller and medium-sized institutions.   ","This paper answers the need to support GLAM institutions in facilitating the transition into publishing their digital content and to introduce collections as data services; this will also help their future efficient contribution to data spaces and cultural heritage clouds.","It offers a checklist that can be used for both creating and evaluating digital collections suitable for computational use.","The main contributions of this paper are i) a methodology for devising a checklist to create and assess digital collections for computational use; ii) a checklist to create and assess digital collections suitable for use with computational methods; iii) the assessment of the checklist against the practice of institutions innovating in the Collections as data field; and iv) the results obtained after the application and recommendations for the use of the checklist in GLAM institutions."],"url":"http://arxiv.org/abs/2304.02603v1"}
{"created":"2023-04-05","title":"Efficient Gradient-based Optimization for Reconstructing Binary Images in Applications to Electrical Impedance Tomography","abstract":"A novel and highly efficient computational framework for reconstructing binary-type images suitable for models of various complexity seen in diverse biomedical applications is developed and validated. Efficiency in computational speed and accuracy is achieved by combining the advantages of recently developed optimization methods that use sample solutions with customized geometry and multiscale control space reduction, all paired with gradient-based techniques. The control space is effectively reduced based on the geometry of the samples and their individual contributions. The entire 3-step computational procedure has an easy-to-follow design due to a nominal number of tuning parameters making the approach simple for practical implementation in various settings. Fairly straightforward methods for computing gradients make the framework compatible with any optimization software, including black-box ones. The performance of the complete computational framework is tested in applications to 2D inverse problems of cancer detection by electrical impedance tomography (EIT) using data from models generated synthetically and obtained from medical images showing the natural development of cancerous regions of various sizes and shapes. The results demonstrate the superior performance of the new method and its high potential for improving the overall quality of the EIT-based procedures.","sentences":["A novel and highly efficient computational framework for reconstructing binary-type images suitable for models of various complexity seen in diverse biomedical applications is developed and validated.","Efficiency in computational speed and accuracy is achieved by combining the advantages of recently developed optimization methods that use sample solutions with customized geometry and multiscale control space reduction, all paired with gradient-based techniques.","The control space is effectively reduced based on the geometry of the samples and their individual contributions.","The entire 3-step computational procedure has an easy-to-follow design due to a nominal number of tuning parameters making the approach simple for practical implementation in various settings.","Fairly straightforward methods for computing gradients make the framework compatible with any optimization software, including black-box ones.","The performance of the complete computational framework is tested in applications to 2D inverse problems of cancer detection by electrical impedance tomography (EIT) using data from models generated synthetically and obtained from medical images showing the natural development of cancerous regions of various sizes and shapes.","The results demonstrate the superior performance of the new method and its high potential for improving the overall quality of the EIT-based procedures."],"url":"http://arxiv.org/abs/2304.02601v1"}
{"created":"2023-04-05","title":"Query lower bounds for log-concave sampling","abstract":"Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\\ge 2$ requires $\\Omega(\\log \\kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\\widetilde \\Omega(\\min(\\sqrt\\kappa \\log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this problem, as well as connections to lower bound techniques based on Wishart matrices developed in the matrix-vector query literature.","sentences":["Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one.","In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\\ge 2$ requires $\\Omega(\\log \\kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\\widetilde \\Omega(\\min(\\sqrt\\kappa \\log d, d))$ queries, which is nearly sharp for the class of Gaussians.","Here $\\kappa$ denotes the condition number of the target distribution.","Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this problem, as well as connections to lower bound techniques based on Wishart matrices developed in the matrix-vector query literature."],"url":"http://arxiv.org/abs/2304.02599v1"}
{"created":"2023-04-05","title":"Measurements of the Crab Pulsar's Giant Radio Pulse Amplitude Power-Law Index Using Low-Frequency Arecibo and Green Bank Telescope Observations","abstract":"We report two low-frequency measurements of the power-law index for the amplitudes of giant radio pulses from the Crab pulsar. The two observations were taken with the Arecibo and Green Bank radio telescopes at center frequencies of 327 MHz and 350 MHz, respectively. We find best-fit values for the differential power-law index $\\beta$ (where $dN/dS \\propto S^\\beta$ and $S$ is pulse amplitude) of $-2.63 \\pm 0.05$ and $-3.6 \\pm 0.5$ from the Arecibo and Green Bank data sets, respectively. Both values are broadly consistent with other values previously measured for the Crab pulsar at low radio frequencies. These reported values may be useful in future giant pulse studies of the Crab pulsar.","sentences":["We report two low-frequency measurements of the power-law index for the amplitudes of giant radio pulses from the Crab pulsar.","The two observations were taken with the Arecibo and Green Bank radio telescopes at center frequencies of 327 MHz and 350 MHz, respectively.","We find best-fit values for the differential power-law index $\\beta$ (where $dN/dS \\propto S^\\beta$ and $S$ is pulse amplitude) of $-2.63 \\pm 0.05$ and $-3.6 \\pm 0.5$ from the Arecibo and Green Bank data sets, respectively.","Both values are broadly consistent with other values previously measured for the Crab pulsar at low radio frequencies.","These reported values may be useful in future giant pulse studies of the Crab pulsar."],"url":"http://arxiv.org/abs/2304.02589v1"}
{"created":"2023-04-03","title":"Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles","abstract":"Role-based learning is a promising approach to improving the performance of Multi-Agent Reinforcement Learning (MARL). Nevertheless, without manual assistance, current role-based methods cannot guarantee stably discovering a set of roles to effectively decompose a complex task, as they assume either a predefined role structure or practical experience for selecting hyperparameters. In this article, we propose a mathematical Structural Information principles-based Role Discovery method, namely SIRD, and then present a SIRD optimizing MARL framework, namely SR-MARL, for multi-agent collaboration. The SIRD transforms role discovery into a hierarchical action space clustering. Specifically, the SIRD consists of structuralization, sparsification, and optimization modules, where an optimal encoding tree is generated to perform abstracting to discover roles. The SIRD is agnostic to specific MARL algorithms and flexibly integrated with various value function factorization approaches. Empirical evaluations on the StarCraft II micromanagement benchmark demonstrate that, compared with state-of-the-art MARL algorithms, the SR-MARL framework improves the average test win rate by 0.17%, 6.08%, and 3.24%, and reduces the deviation by 16.67%, 30.80%, and 66.30%, under easy, hard, and super hard scenarios.","sentences":["Role-based learning is a promising approach to improving the performance of Multi-Agent Reinforcement Learning (MARL).","Nevertheless, without manual assistance, current role-based methods cannot guarantee stably discovering a set of roles to effectively decompose a complex task, as they assume either a predefined role structure or practical experience for selecting hyperparameters.","In this article, we propose a mathematical Structural Information principles-based Role Discovery method, namely SIRD, and then present a SIRD optimizing MARL framework, namely SR-MARL, for multi-agent collaboration.","The SIRD transforms role discovery into a hierarchical action space clustering.","Specifically, the SIRD consists of structuralization, sparsification, and optimization modules, where an optimal encoding tree is generated to perform abstracting to discover roles.","The SIRD is agnostic to specific MARL algorithms and flexibly integrated with various value function factorization approaches.","Empirical evaluations on the StarCraft II micromanagement benchmark demonstrate that, compared with state-of-the-art MARL algorithms, the SR-MARL framework improves the average test win rate by 0.17%, 6.08%, and 3.24%, and reduces the deviation by 16.67%, 30.80%, and 66.30%, under easy, hard, and super hard scenarios."],"url":"http://arxiv.org/abs/2304.00755v1"}
{"created":"2023-03-31","title":"Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning","abstract":"Research in model-based reinforcement learning has made significant progress in recent years. Compared to single-agent settings, the exponential dimension growth of the joint state-action space in multi-agent systems dramatically increases the complexity of the environment dynamics, which makes it infeasible to learn an accurate global model and thus necessitates the use of agent-wise local models. However, during multi-step model rollouts, the prediction of one local model can affect the predictions of other local models in the next step. As a result, local prediction errors can be propagated to other localities and eventually give rise to considerably large global errors. Furthermore, since the models are generally used to predict for multiple steps, simply minimizing one-step prediction errors regardless of their long-term effect on other models may further aggravate the propagation of local errors. To this end, we propose Models as AGents (MAG), a multi-agent model optimization framework that reversely treats the local models as multi-step decision making agents and the current policies as the dynamics during the model rollout process. In this way, the local models are able to consider the multi-step mutual affect between each other before making predictions. Theoretically, we show that the objective of MAG is approximately equivalent to maximizing a lower bound of the true environment return. Experiments on the challenging StarCraft II benchmark demonstrate the effectiveness of MAG.","sentences":["Research in model-based reinforcement learning has made significant progress in recent years.","Compared to single-agent settings, the exponential dimension growth of the joint state-action space in multi-agent systems dramatically increases the complexity of the environment dynamics, which makes it infeasible to learn an accurate global model and thus necessitates the use of agent-wise local models.","However, during multi-step model rollouts, the prediction of one local model can affect the predictions of other local models in the next step.","As a result, local prediction errors can be propagated to other localities and eventually give rise to considerably large global errors.","Furthermore, since the models are generally used to predict for multiple steps, simply minimizing one-step prediction errors regardless of their long-term effect on other models may further aggravate the propagation of local errors.","To this end, we propose Models as AGents (MAG), a multi-agent model optimization framework that reversely treats the local models as multi-step decision making agents and the current policies as the dynamics during the model rollout process.","In this way, the local models are able to consider the multi-step mutual affect between each other before making predictions.","Theoretically, we show that the objective of MAG is approximately equivalent to maximizing a lower bound of the true environment return.","Experiments on the challenging StarCraft II benchmark demonstrate the effectiveness of MAG."],"url":"http://arxiv.org/abs/2303.17984v1"}
{"created":"2023-03-29","title":"Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks","abstract":"We study building a multi-task agent in Minecraft. Without human demonstrations, solving long-horizon tasks in this open-ended environment with reinforcement learning (RL) is extremely sample inefficient. To tackle the challenge, we decompose solving Minecraft tasks into learning basic skills and planning over the skills. We propose three types of fine-grained basic skills in Minecraft, and use RL with intrinsic rewards to accomplish basic skills with high success rates. For skill planning, we use Large Language Models to find the relationships between skills and build a skill graph in advance. When the agent is solving a task, our skill search algorithm walks on the skill graph and generates the proper skill plans for the agent. In experiments, our method accomplishes 24 diverse Minecraft tasks, where many tasks require sequentially executing for more than 10 skills. Our method outperforms baselines in most tasks by a large margin. The project's website and code can be found at https://sites.google.com/view/plan4mc.","sentences":["We study building a multi-task agent in Minecraft.","Without human demonstrations, solving long-horizon tasks in this open-ended environment with reinforcement learning (RL) is extremely sample inefficient.","To tackle the challenge, we decompose solving Minecraft tasks into learning basic skills and planning over the skills.","We propose three types of fine-grained basic skills in Minecraft, and use RL with intrinsic rewards to accomplish basic skills with high success rates.","For skill planning, we use Large Language Models to find the relationships between skills and build a skill graph in advance.","When the agent is solving a task, our skill search algorithm walks on the skill graph and generates the proper skill plans for the agent.","In experiments, our method accomplishes 24 diverse Minecraft tasks, where many tasks require sequentially executing for more than 10 skills.","Our method outperforms baselines in most tasks by a large margin.","The project's website and code can be found at https://sites.google.com/view/plan4mc."],"url":"http://arxiv.org/abs/2303.16563v1"}
{"created":"2023-03-23","title":"Towards Solving Fuzzy Tasks with Human Feedback: A Retrospective of the MineRL BASALT 2022 Competition","abstract":"To facilitate research in the direction of fine-tuning foundation models from human feedback, we held the MineRL BASALT Competition on Fine-Tuning from Human Feedback at NeurIPS 2022. The BASALT challenge asks teams to compete to develop algorithms to solve tasks with hard-to-specify reward functions in Minecraft. Through this competition, we aimed to promote the development of algorithms that use human feedback as channels to learn the desired behavior. We describe the competition and provide an overview of the top solutions. We conclude by discussing the impact of the competition and future directions for improvement.","sentences":["To facilitate research in the direction of fine-tuning foundation models from human feedback, we held the MineRL BASALT Competition on Fine-Tuning from Human Feedback at NeurIPS 2022.","The BASALT challenge asks teams to compete to develop algorithms to solve tasks with hard-to-specify reward functions in Minecraft.","Through this competition, we aimed to promote the development of algorithms that use human feedback as channels to learn the desired behavior.","We describe the competition and provide an overview of the top solutions.","We conclude by discussing the impact of the competition and future directions for improvement."],"url":"http://arxiv.org/abs/2303.13512v1"}
{"created":"2023-03-23","title":"Plotting Behind the Scenes: Towards Learnable Game Engines","abstract":"Game engines are powerful tools in computer graphics. Their power comes at the immense cost of their development. In this work, we present a framework to train game-engine-like neural models, solely from monocular annotated videos. The result-a Learnable Game Engine (LGE)-maintains states of the scene, objects and agents in it, and enables rendering the environment from a controllable viewpoint. Similarly to a game engine, it models the logic of the game and the underlying rules of physics, to make it possible for a user to play the game by specifying both high- and low-level action sequences. Most captivatingly, our LGE unlocks the director's mode, where the game is played by plotting behind the scenes, specifying high-level actions and goals for the agents in the form of language and desired states. This requires learning \"game AI\", encapsulated by our animation model, to navigate the scene using high-level constraints, play against an adversary, devise the strategy to win a point. The key to learning such game AI is the exploitation of a large and diverse text corpus, collected in this work, describing detailed actions in a game and used to train our animation model. To render the resulting state of the environment and its agents, we use a compositional NeRF representation used in our synthesis model. To foster future research, we present newly collected, annotated and calibrated large-scale Tennis and Minecraft datasets. Our method significantly outperforms existing neural video game simulators in terms of rendering quality. Besides, our LGEs unlock applications beyond capabilities of the current state of the art. Our framework, data, and models are available at https://learnable-game-engines.github.io/lge-website.","sentences":["Game engines are powerful tools in computer graphics.","Their power comes at the immense cost of their development.","In this work, we present a framework to train game-engine-like neural models, solely from monocular annotated videos.","The result-a Learnable Game Engine (LGE)-maintains states of the scene, objects and agents in it, and enables rendering the environment from a controllable viewpoint.","Similarly to a game engine, it models the logic of the game and the underlying rules of physics, to make it possible for a user to play the game by specifying both high- and low-level action sequences.","Most captivatingly, our LGE unlocks the director's mode, where the game is played by plotting behind the scenes, specifying high-level actions and goals for the agents in the form of language and desired states.","This requires learning \"game AI\", encapsulated by our animation model, to navigate the scene using high-level constraints, play against an adversary, devise the strategy to win a point.","The key to learning such game AI is the exploitation of a large and diverse text corpus, collected in this work, describing detailed actions in a game and used to train our animation model.","To render the resulting state of the environment and its agents, we use a compositional NeRF representation used in our synthesis model.","To foster future research, we present newly collected, annotated and calibrated large-scale Tennis and Minecraft datasets.","Our method significantly outperforms existing neural video game simulators in terms of rendering quality.","Besides, our LGEs unlock applications beyond capabilities of the current state of the art.","Our framework, data, and models are available at https://learnable-game-engines.github.io/lge-website."],"url":"http://arxiv.org/abs/2303.13472v1"}
{"created":"2023-03-19","title":"CLIP4MC: An RL-Friendly Vision-Language Model for Minecraft","abstract":"One of the essential missions in the AI research community is to build an autonomous embodied agent that can attain high-level performance across a wide spectrum of tasks. However, acquiring reward/penalty in all open-ended tasks is unrealistic, making the Reinforcement Learning (RL) training procedure impossible. In this paper, we propose a novel cross-modal contrastive learning framework architecture, CLIP4MC, aiming to learn an RL-friendly vision-language model that serves as a reward function for open-ended tasks. Therefore, no further task-specific reward design is needed. Intuitively, it is more reasonable for the model to address the similarity between the video snippet and the language prompt at both the action and entity levels. To this end, a motion encoder is proposed to capture the motion embeddings across different intervals. The correlation scores are then used to construct the auxiliary reward signal for RL agents. Moreover, we construct a neat YouTube dataset based on the large-scale YouTube database provided by MineDojo. Specifically, two rounds of filtering operations guarantee that the dataset covers enough essential information and that the video-text pair is highly correlated. Empirically, we show that the proposed method achieves better performance on RL tasks compared with baselines.","sentences":["One of the essential missions in the AI research community is to build an autonomous embodied agent that can attain high-level performance across a wide spectrum of tasks.","However, acquiring reward/penalty in all open-ended tasks is unrealistic, making the Reinforcement Learning (RL) training procedure impossible.","In this paper, we propose a novel cross-modal contrastive learning framework architecture, CLIP4MC, aiming to learn an RL-friendly vision-language model that serves as a reward function for open-ended tasks.","Therefore, no further task-specific reward design is needed.","Intuitively, it is more reasonable for the model to address the similarity between the video snippet and the language prompt at both the action and entity levels.","To this end, a motion encoder is proposed to capture the motion embeddings across different intervals.","The correlation scores are then used to construct the auxiliary reward signal for RL agents.","Moreover, we construct a neat YouTube dataset based on the large-scale YouTube database provided by MineDojo.","Specifically, two rounds of filtering operations guarantee that the dataset covers enough essential information and that the video-text pair is highly correlated.","Empirically, we show that the proposed method achieves better performance on RL tasks compared with baselines."],"url":"http://arxiv.org/abs/2303.10571v1"}
{"created":"2023-03-16","title":"SVDE: Scalable Value-Decomposition Exploration for Cooperative Multi-Agent Reinforcement Learning","abstract":"Value-decomposition methods, which reduce the difficulty of a multi-agent system by decomposing the joint state-action space into local observation-action spaces, have become popular in cooperative multi-agent reinforcement learning (MARL). However, value-decomposition methods still have the problems of tremendous sample consumption for training and lack of active exploration. In this paper, we propose a scalable value-decomposition exploration (SVDE) method, which includes a scalable training mechanism, intrinsic reward design, and explorative experience replay. The scalable training mechanism asynchronously decouples strategy learning with environmental interaction, so as to accelerate sample generation in a MapReduce manner. For the problem of lack of exploration, an intrinsic reward design and explorative experience replay are proposed, so as to enhance exploration to produce diverse samples and filter non-novel samples, respectively. Empirically, our method achieves the best performance on almost all maps compared to other popular algorithms in a set of StarCraft II micromanagement games. A data-efficiency experiment also shows the acceleration of SVDE for sample collection and policy convergence, and we demonstrate the effectiveness of factors in SVDE through a set of ablation experiments.","sentences":["Value-decomposition methods, which reduce the difficulty of a multi-agent system by decomposing the joint state-action space into local observation-action spaces, have become popular in cooperative multi-agent reinforcement learning (MARL).","However, value-decomposition methods still have the problems of tremendous sample consumption for training and lack of active exploration.","In this paper, we propose a scalable value-decomposition exploration (SVDE) method, which includes a scalable training mechanism, intrinsic reward design, and explorative experience replay.","The scalable training mechanism asynchronously decouples strategy learning with environmental interaction, so as to accelerate sample generation in a MapReduce manner.","For the problem of lack of exploration, an intrinsic reward design and explorative experience replay are proposed, so as to enhance exploration to produce diverse samples and filter non-novel samples, respectively.","Empirically, our method achieves the best performance on almost all maps compared to other popular algorithms in a set of StarCraft II micromanagement games.","A data-efficiency experiment also shows the acceleration of SVDE for sample collection and policy convergence, and we demonstrate the effectiveness of factors in SVDE through a set of ablation experiments."],"url":"http://arxiv.org/abs/2303.09058v1"}
{"created":"2023-03-02","title":"GHQ: Grouped Hybrid Q Learning for Heterogeneous Cooperative Multi-agent Reinforcement Learning","abstract":"Previous deep multi-agent reinforcement learning (MARL) algorithms have achieved impressive results, typically in homogeneous scenarios. However, heterogeneous scenarios are also very common and usually harder to solve. In this paper, we mainly discuss cooperative heterogeneous MARL problems in Starcraft Multi-Agent Challenges (SMAC) environment. We firstly define and describe the heterogeneous problems in SMAC. In order to comprehensively reveal and study the problem, we make new maps added to the original SMAC maps. We find that baseline algorithms fail to perform well in those heterogeneous maps. To address this issue, we propose the Grouped Individual-Global-Max Consistency (GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ). GHQ separates agents into several groups and keeps individual parameters for each group, along with a novel hybrid structure for factorization. To enhance coordination between groups, we maximize the Inter-group Mutual Information (IGMI) between groups' trajectories. Experiments on original and new heterogeneous maps show the fabulous performance of GHQ compared to other state-of-the-art algorithms.","sentences":["Previous deep multi-agent reinforcement learning (MARL) algorithms have achieved impressive results, typically in homogeneous scenarios.","However, heterogeneous scenarios are also very common and usually harder to solve.","In this paper, we mainly discuss cooperative heterogeneous MARL problems in Starcraft Multi-Agent Challenges (SMAC) environment.","We firstly define and describe the heterogeneous problems in SMAC.","In order to comprehensively reveal and study the problem, we make new maps added to the original SMAC maps.","We find that baseline algorithms fail to perform well in those heterogeneous maps.","To address this issue, we propose the Grouped Individual-Global-Max Consistency (GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ).","GHQ separates agents into several groups and keeps individual parameters for each group, along with a novel hybrid structure for factorization.","To enhance coordination between groups, we maximize the Inter-group Mutual Information (IGMI) between groups' trajectories.","Experiments on original and new heterogeneous maps show the fabulous performance of GHQ compared to other state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2303.01070v1"}
{"created":"2023-02-28","title":"Semantic Strengthening of Neuro-Symbolic Learning","abstract":"Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network's predictions satisfy the underlying domain. Unfortunately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible. We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation. This corresponds to computing the mutual information between pairs of constraints conditioned on the network's learned features, and may be construed as a measure of how well aligned the gradients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability.","sentences":["Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network.","Ideally, such losses maximize the probability that the neural network's predictions satisfy the underlying domain.","Unfortunately, this type of probabilistic inference is often computationally infeasible.","Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible.","We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network.","We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation.","This corresponds to computing the mutual information between pairs of constraints conditioned on the network's learned features, and may be construed as a measure of how well aligned the gradients of two distributions are.","We show how to compute this efficiently for tractable circuits.","We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability."],"url":"http://arxiv.org/abs/2302.14207v1"}
{"created":"2023-02-21","title":"MAC-PO: Multi-Agent Experience Replay via Collective Priority Optimization","abstract":"Experience replay is crucial for off-policy reinforcement learning (RL) methods. By remembering and reusing the experiences from past different policies, experience replay significantly improves the training efficiency and stability of RL algorithms. Many decision-making problems in practice naturally involve multiple agents and require multi-agent reinforcement learning (MARL) under centralized training decentralized execution paradigm. Nevertheless, existing MARL algorithms often adopt standard experience replay where the transitions are uniformly sampled regardless of their importance. Finding prioritized sampling weights that are optimized for MARL experience replay has yet to be explored. To this end, we propose MAC-PO, which formulates optimal prioritized experience replay for multi-agent problems as a regret minimization over the sampling weights of transitions. Such optimization is relaxed and solved using the Lagrangian multiplier approach to obtain the close-form optimal sampling weights. By minimizing the resulting policy regret, we can narrow the gap between the current policy and a nominal optimal policy, thus acquiring an improved prioritization scheme for multi-agent tasks. Our experimental results on Predator-Prey and StarCraft Multi-Agent Challenge environments demonstrate the effectiveness of our method, having a better ability to replay important transitions and outperforming other state-of-the-art baselines.","sentences":["Experience replay is crucial for off-policy reinforcement learning (RL) methods.","By remembering and reusing the experiences from past different policies, experience replay significantly improves the training efficiency and stability of RL algorithms.","Many decision-making problems in practice naturally involve multiple agents and require multi-agent reinforcement learning (MARL) under centralized training decentralized execution paradigm.","Nevertheless, existing MARL algorithms often adopt standard experience replay where the transitions are uniformly sampled regardless of their importance.","Finding prioritized sampling weights that are optimized for MARL experience replay has yet to be explored.","To this end, we propose MAC-PO, which formulates optimal prioritized experience replay for multi-agent problems as a regret minimization over the sampling weights of transitions.","Such optimization is relaxed and solved using the Lagrangian multiplier approach to obtain the close-form optimal sampling weights.","By minimizing the resulting policy regret, we can narrow the gap between the current policy and a nominal optimal policy, thus acquiring an improved prioritization scheme for multi-agent tasks.","Our experimental results on Predator-Prey and StarCraft Multi-Agent Challenge environments demonstrate the effectiveness of our method, having a better ability to replay important transitions and outperforming other state-of-the-art baselines."],"url":"http://arxiv.org/abs/2302.10418v2"}
{"created":"2023-02-19","title":"AIIR-MIX: Multi-Agent Reinforcement Learning Meets Attention Individual Intrinsic Reward Mixing Network","abstract":"Deducing the contribution of each agent and assigning the corresponding reward to them is a crucial problem in cooperative Multi-Agent Reinforcement Learning (MARL). Previous studies try to resolve the issue through designing an intrinsic reward function, but the intrinsic reward is simply combined with the environment reward by summation in these studies, which makes the performance of their MARL framework unsatisfactory. We propose a novel method named Attention Individual Intrinsic Reward Mixing Network (AIIR-MIX) in MARL, and the contributions of AIIR-MIX are listed as follows:(a) we construct a novel intrinsic reward network based on the attention mechanism to make teamwork more effective. (b) we propose a Mixing network that is able to combine intrinsic and extrinsic rewards non-linearly and dynamically in response to changing conditions of the environment. We compare AIIR-MIX with many State-Of-The-Art (SOTA) MARL methods on battle games in StarCraft II. And the results demonstrate that AIIR-MIX performs admirably and can defeat the current advanced methods on average test win rate. To validate the effectiveness of AIIR-MIX, we conduct additional ablation studies. The results show that AIIR-MIX can dynamically assign each agent a real-time intrinsic reward in accordance with their actual contribution.","sentences":["Deducing the contribution of each agent and assigning the corresponding reward to them is a crucial problem in cooperative Multi-Agent Reinforcement Learning (MARL).","Previous studies try to resolve the issue through designing an intrinsic reward function, but the intrinsic reward is simply combined with the environment reward by summation in these studies, which makes the performance of their MARL framework unsatisfactory.","We propose a novel method named Attention Individual Intrinsic Reward Mixing Network (AIIR-MIX) in MARL, and the contributions of AIIR-MIX are listed as follows:(a) we construct a novel intrinsic reward network based on the attention mechanism to make teamwork more effective.","(b) we propose a Mixing network that is able to combine intrinsic and extrinsic rewards non-linearly and dynamically in response to changing conditions of the environment.","We compare AIIR-MIX with many State-Of-The-Art (SOTA) MARL methods on battle games in StarCraft II.","And the results demonstrate that AIIR-MIX performs admirably and can defeat the current advanced methods on average test win rate.","To validate the effectiveness of AIIR-MIX, we conduct additional ablation studies.","The results show that AIIR-MIX can dynamically assign each agent a real-time intrinsic reward in accordance with their actual contribution."],"url":"http://arxiv.org/abs/2302.09531v1"}
{"created":"2023-02-12","title":"MANSA: Learning Fast and Slow in Multi-Agent Systems","abstract":"In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents. Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions. Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications. Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated. In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination. At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL. Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls. We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF.","sentences":["In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents.","Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions.","Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications.","Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated.","In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination.","At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL.","Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls.","We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF."],"url":"http://arxiv.org/abs/2302.05910v2"}
{"created":"2023-02-11","title":"ReMIX: Regret Minimization for Monotonic Value Function Factorization in Multiagent Reinforcement Learning","abstract":"Value function factorization methods have become a dominant approach for cooperative multiagent reinforcement learning under a centralized training and decentralized execution paradigm. By factorizing the optimal joint action-value function using a monotonic mixing function of agents' utilities, these algorithms ensure the consistency between joint and local action selections for decentralized decision-making. Nevertheless, the use of monotonic mixing functions also induces representational limitations. Finding the optimal projection of an unrestricted mixing function onto monotonic function classes is still an open problem. To this end, we propose ReMIX, formulating this optimal projection problem for value function factorization as a regret minimization over the projection weights of different state-action values. Such an optimization problem can be relaxed and solved using the Lagrangian multiplier method to obtain the close-form optimal projection weights. By minimizing the resulting policy regret, we can narrow the gap between the optimal and the restricted monotonic mixing functions, thus obtaining an improved monotonic value function factorization. Our experimental results on Predator-Prey and StarCraft Multiagent Challenge environments demonstrate the effectiveness of our method, indicating the better capabilities of handling environments with non-monotonic value functions.","sentences":["Value function factorization methods have become a dominant approach for cooperative multiagent reinforcement learning under a centralized training and decentralized execution paradigm.","By factorizing the optimal joint action-value function using a monotonic mixing function of agents' utilities, these algorithms ensure the consistency between joint and local action selections for decentralized decision-making.","Nevertheless, the use of monotonic mixing functions also induces representational limitations.","Finding the optimal projection of an unrestricted mixing function onto monotonic function classes is still an open problem.","To this end, we propose ReMIX, formulating this optimal projection problem for value function factorization as a regret minimization over the projection weights of different state-action values.","Such an optimization problem can be relaxed and solved using the Lagrangian multiplier method to obtain the close-form optimal projection weights.","By minimizing the resulting policy regret, we can narrow the gap between the optimal and the restricted monotonic mixing functions, thus obtaining an improved monotonic value function factorization.","Our experimental results on Predator-Prey and StarCraft Multiagent Challenge environments demonstrate the effectiveness of our method, indicating the better capabilities of handling environments with non-monotonic value functions."],"url":"http://arxiv.org/abs/2302.05593v1"}
{"created":"2023-02-09","title":"Equivariant MuZero","abstract":"Deep reinforcement learning repeatedly succeeds in closed, well-defined domains such as games (Chess, Go, StarCraft). The next frontier is real-world scenarios, where setups are numerous and varied. For this, agents need to learn the underlying rules governing the environment, so as to robustly generalise to conditions that differ from those they were trained on. Model-based reinforcement learning algorithms, such as the highly successful MuZero, aim to accomplish this by learning a world model. However, leveraging a world model has not consistently shown greater generalisation capabilities compared to model-free alternatives. In this work, we propose improving the data efficiency and generalisation capabilities of MuZero by explicitly incorporating the symmetries of the environment in its world-model architecture. We prove that, so long as the neural networks used by MuZero are equivariant to a particular symmetry group acting on the environment, the entirety of MuZero's action-selection algorithm will also be equivariant to that group. We evaluate Equivariant MuZero on procedurally-generated MiniPacman and on Chaser from the ProcGen suite: training on a set of mazes, and then testing on unseen rotated versions, demonstrating the benefits of equivariance. Further, we verify that our performance improvements hold even when only some of the components of Equivariant MuZero obey strict equivariance, which highlights the robustness of our construction.","sentences":["Deep reinforcement learning repeatedly succeeds in closed, well-defined domains such as games (Chess, Go, StarCraft).","The next frontier is real-world scenarios, where setups are numerous and varied.","For this, agents need to learn the underlying rules governing the environment, so as to robustly generalise to conditions that differ from those they were trained on.","Model-based reinforcement learning algorithms, such as the highly successful MuZero, aim to accomplish this by learning a world model.","However, leveraging a world model has not consistently shown greater generalisation capabilities compared to model-free alternatives.","In this work, we propose improving the data efficiency and generalisation capabilities of MuZero by explicitly incorporating the symmetries of the environment in its world-model architecture.","We prove that, so long as the neural networks used by MuZero are equivariant to a particular symmetry group acting on the environment, the entirety of MuZero's action-selection algorithm will also be equivariant to that group.","We evaluate Equivariant MuZero on procedurally-generated MiniPacman and on Chaser from the ProcGen suite: training on a set of mazes, and then testing on unseen rotated versions, demonstrating the benefits of equivariance.","Further, we verify that our performance improvements hold even when only some of the components of Equivariant MuZero obey strict equivariance, which highlights the robustness of our construction."],"url":"http://arxiv.org/abs/2302.04798v1"}
{"created":"2023-02-03","title":"Hierarchically Composing Level Generators for the Creation of Complex Structures","abstract":"Procedural content generation (PCG) is a growing field, with numerous applications in the video game industry, and great potential to help create better games at a fraction of the cost of manual creation. However, much of the work in PCG is focused on generating relatively straightforward levels in simple games, as it is challenging to design an optimisable objective function for complex settings. This limits the applicability of PCG to more complex and modern titles, hindering its adoption in industry. Our work aims to address this limitation by introducing a compositional level generation method, which recursively composes simple, low-level generators together to construct large and complex creations. This approach allows for easily-optimisable objectives and the ability to design a complex structure in an interpretable way by referencing lower-level components. We empirically demonstrate that our method outperforms a non-compositional baseline by more accurately satisfying a designer's functional requirements in several tasks. Finally, we provide a qualitative showcase (in Minecraft) illustrating the large and complex, but still coherent, structures that were generated using simple base generators.","sentences":["Procedural content generation (PCG) is a growing field, with numerous applications in the video game industry, and great potential to help create better games at a fraction of the cost of manual creation.","However, much of the work in PCG is focused on generating relatively straightforward levels in simple games, as it is challenging to design an optimisable objective function for complex settings.","This limits the applicability of PCG to more complex and modern titles, hindering its adoption in industry.","Our work aims to address this limitation by introducing a compositional level generation method, which recursively composes simple, low-level generators together to construct large and complex creations.","This approach allows for easily-optimisable objectives and the ability to design a complex structure in an interpretable way by referencing lower-level components.","We empirically demonstrate that our method outperforms a non-compositional baseline by more accurately satisfying a designer's functional requirements in several tasks.","Finally, we provide a qualitative showcase (in Minecraft) illustrating the large and complex, but still coherent, structures that were generated using simple base generators."],"url":"http://arxiv.org/abs/2302.01561v1"}
{"created":"2023-02-03","title":"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents","abstract":"In this paper, we study the problem of planning in Minecraft, a popular, democratized yet challenging open-ended environment for developing multi-task embodied agents. We've found two primary challenges of empowering such agents with planning: 1) planning in an open-ended world like Minecraft requires precise and multi-step reasoning due to the long-term nature of the tasks, and 2) as vanilla planners do not consider the proximity to the current agent when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient. To this end, we propose \"Describe, Explain, Plan and Select\" (DEPS), an interactive planning approach based on Large Language Models (LLMs). Our approach helps with better error correction from the feedback during the long-haul planning, while also bringing the sense of proximity via goal Selector, a learnable module that ranks parallel sub-goals based on the estimated steps of completion and improves the original plan accordingly. Our experiments mark the milestone of the first multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly doubles the overall performances. Finally, the ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\\texttt{ObtainDiamond}$ grand challenge with our approach. The code is released at https://github.com/CraftJarvis/MC-Planner.","sentences":["In this paper, we study the problem of planning in Minecraft, a popular, democratized yet challenging open-ended environment for developing multi-task embodied agents.","We've found two primary challenges of empowering such agents with planning: 1) planning in an open-ended world like Minecraft requires precise and multi-step reasoning due to the long-term nature of the tasks, and 2) as vanilla planners do not consider the proximity to the current agent when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient.","To this end, we propose \"Describe, Explain, Plan and Select\" (DEPS), an interactive planning approach based on Large Language Models (LLMs).","Our approach helps with better error correction from the feedback during the long-haul planning, while also bringing the sense of proximity via goal Selector, a learnable module that ranks parallel sub-goals based on the estimated steps of completion and improves the original plan accordingly.","Our experiments mark the milestone of the first multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly doubles the overall performances.","Finally, the ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\\texttt{ObtainDiamond}$ grand challenge with our approach.","The code is released at https://github.com/CraftJarvis/MC-Planner."],"url":"http://arxiv.org/abs/2302.01560v1"}
{"created":"2023-02-01","title":"Evolving Flying Machines in Minecraft Using Quality Diversity","abstract":"Minecraft is a great testbed for human creativity that has inspired the design of various structures and even functioning machines, including flying machines. EvoCraft is an API for programmatically generating structures in Minecraft, but the initial work in this domain was not capable of evolving flying machines. This paper applies fitness-based evolution and quality diversity search in order to evolve flying machines. Although fitness alone can occasionally produce flying machines, thanks in part to a more sophisticated fitness function than was used previously, the quality diversity algorithm MAP-Elites is capable of discovering flying machines much more reliably, at least when an appropriate behavior characterization is used to guide the search for diverse solutions.","sentences":["Minecraft is a great testbed for human creativity that has inspired the design of various structures and even functioning machines, including flying machines.","EvoCraft is an API for programmatically generating structures in Minecraft, but the initial work in this domain was not capable of evolving flying machines.","This paper applies fitness-based evolution and quality diversity search in order to evolve flying machines.","Although fitness alone can occasionally produce flying machines, thanks in part to a more sophisticated fitness function than was used previously, the quality diversity algorithm MAP-Elites is capable of discovering flying machines much more reliably, at least when an appropriate behavior characterization is used to guide the search for diverse solutions."],"url":"http://arxiv.org/abs/2302.00782v1"}
{"created":"2023-01-28","title":"Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling","abstract":"Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world, which makes learning complex tasks with sparse rewards difficult. If initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that is tested and verified during exploration, to improve sample efficiency in embodied RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM on the basis of its experiences. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.","sentences":["Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world, which makes learning complex tasks with sparse rewards difficult.","If initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration.","We propose using few-shot large language models (LLMs) to hypothesize an AWM, that is tested and verified during exploration, to improve sample efficiency in embodied RL agents.","Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM on the basis of its experiences.","Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics."],"url":"http://arxiv.org/abs/2301.12050v1"}
{"created":"2023-01-27","title":"Polycraft World AI Lab (PAL): An Extensible Platform for Evaluating Artificial Intelligence Agents","abstract":"As artificial intelligence research advances, the platforms used to evaluate AI agents need to adapt and grow to continue to challenge them. We present the Polycraft World AI Lab (PAL), a task simulator with an API based on the Minecraft mod Polycraft World. Our platform is built to allow AI agents with different architectures to easily interact with the Minecraft world, train and be evaluated in multiple tasks. PAL enables the creation of tasks in a flexible manner as well as having the capability to manipulate any aspect of the task during an evaluation. All actions taken by AI agents and external actors (non-player-characters, NPCs) in the open-world environment are logged to streamline evaluation. Here we present two custom tasks on the PAL platform, one focused on multi-step planning and one focused on navigation, and evaluations of agents solving them. In summary, we report a versatile and extensible AI evaluation platform with a low barrier to entry for AI researchers to utilize.","sentences":["As artificial intelligence research advances, the platforms used to evaluate AI agents need to adapt and grow to continue to challenge them.","We present the Polycraft World AI Lab (PAL), a task simulator with an API based on the Minecraft mod Polycraft World.","Our platform is built to allow AI agents with different architectures to easily interact with the Minecraft world, train and be evaluated in multiple tasks.","PAL enables the creation of tasks in a flexible manner as well as having the capability to manipulate any aspect of the task during an evaluation.","All actions taken by AI agents and external actors (non-player-characters, NPCs) in the open-world environment are logged to streamline evaluation.","Here we present two custom tasks on the PAL platform, one focused on multi-step planning and one focused on navigation, and evaluations of agents solving them.","In summary, we report a versatile and extensible AI evaluation platform with a low barrier to entry for AI researchers to utilize."],"url":"http://arxiv.org/abs/2301.11891v1"}
{"created":"2023-01-25","title":"Discriminative Experience Replay for Efficient Multi-agent Reinforcement Learning","abstract":"In cooperative multi-agent tasks, parameter sharing among agents is a common technique to decrease the number of trainable parameters and shorten training time. The existing value factorization methods adopt the joint transitions to train parameter-sharing individual value networks, $i.e.$, the transitions of all agents are replayed at the same frequency. Due to the discrepancy of learning difficulty among agents, the training level of agents in a team may be inconsistent with the same transition replay frequency leading to limited team performance. To this end, we propose Discriminative Experience Replay (DER), which transfers the minimal training sample from a multi-agent transition to a single-agent transition. It calculates the equivalent individual reward of each single-agent transition and then divides a multi-agent transition into multiple single-agent transitions. After division, DER selects significant single-agent transitions with large TD-error by referring to the single-agent experience replay methods. Our method can be adapted to existing value function decomposition methods. The experimental results show the optimization equivalence before and after division and that our method significantly improves the learning efficiency on the challenging StarCraft II micromanagement task and Multi-Agent Mujoco tasks.","sentences":["In cooperative multi-agent tasks, parameter sharing among agents is a common technique to decrease the number of trainable parameters and shorten training time.","The existing value factorization methods adopt the joint transitions to train parameter-sharing individual value networks, $i.e.$, the transitions of all agents are replayed at the same frequency.","Due to the discrepancy of learning difficulty among agents, the training level of agents in a team may be inconsistent with the same transition replay frequency leading to limited team performance.","To this end, we propose Discriminative Experience Replay (DER), which transfers the minimal training sample from a multi-agent transition to a single-agent transition.","It calculates the equivalent individual reward of each single-agent transition and then divides a multi-agent transition into multiple single-agent transitions.","After division, DER selects significant single-agent transitions with large TD-error by referring to the single-agent experience replay methods.","Our method can be adapted to existing value function decomposition methods.","The experimental results show the optimization equivalence before and after division and that our method significantly improves the learning efficiency on the challenging StarCraft II micromanagement task and Multi-Agent Mujoco tasks."],"url":"http://arxiv.org/abs/2301.10574v1"}
{"created":"2023-01-24","title":"PushWorld: A benchmark for manipulation planning with tools and movable obstacles","abstract":"While recent advances in artificial intelligence have achieved human-level performance in environments like Starcraft and Go, many physical reasoning tasks remain challenging for modern algorithms. To date, few algorithms have been evaluated on physical tasks that involve manipulating objects when movable obstacles are present and when tools must be used to perform the manipulation. To promote research on such tasks, we introduce PushWorld, an environment with simplistic physics that requires manipulation planning with both movable obstacles and tools. We provide a benchmark of more than 200 PushWorld puzzles in PDDL and in an OpenAI Gym environment. We evaluate state-of-the-art classical planning and reinforcement learning algorithms on this benchmark, and we find that these baseline results are below human-level performance. We then provide a new classical planning heuristic that solves the most puzzles among the baselines, and although it is 40 times faster than the best baseline planner, it remains below human-level performance.","sentences":["While recent advances in artificial intelligence have achieved human-level performance in environments like Starcraft and Go, many physical reasoning tasks remain challenging for modern algorithms.","To date, few algorithms have been evaluated on physical tasks that involve manipulating objects when movable obstacles are present and when tools must be used to perform the manipulation.","To promote research on such tasks, we introduce PushWorld, an environment with simplistic physics that requires manipulation planning with both movable obstacles and tools.","We provide a benchmark of more than 200 PushWorld puzzles in PDDL and in an OpenAI Gym environment.","We evaluate state-of-the-art classical planning and reinforcement learning algorithms on this benchmark, and we find that these baseline results are below human-level performance.","We then provide a new classical planning heuristic that solves the most puzzles among the baselines, and although it is 40 times faster than the best baseline planner, it remains below human-level performance."],"url":"http://arxiv.org/abs/2301.10289v2"}
{"created":"2023-01-21","title":"Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction","abstract":"We study the problem of learning goal-conditioned policies in Minecraft, a popular, widely accessible yet challenging open-ended environment for developing human-level multi-task agents. We first identify two main challenges of learning such policies: 1) the indistinguishability of tasks from the state distribution, due to the vast scene diversity, and 2) the non-stationary nature of environment dynamics caused by partial observability. To tackle the first challenge, we propose Goal-Sensitive Backbone (GSB) for the policy to encourage the emergence of goal-relevant visual state representations. To tackle the second challenge, the policy is further fueled by an adaptive horizon prediction module that helps alleviate the learning uncertainty brought by the non-stationary dynamics. Experiments on 20 Minecraft tasks show that our method significantly outperforms the best baseline so far; in many of them, we double the performance. Our ablation and exploratory studies then explain how our approach beat the counterparts and also unveil the surprising bonus of zero-shot generalization to new scenes (biomes). We hope our agent could help shed some light on learning goal-conditioned, multi-task agents in challenging, open-ended environments like Minecraft.","sentences":["We study the problem of learning goal-conditioned policies in Minecraft, a popular, widely accessible yet challenging open-ended environment for developing human-level multi-task agents.","We first identify two main challenges of learning such policies: 1) the indistinguishability of tasks from the state distribution, due to the vast scene diversity, and 2) the non-stationary nature of environment dynamics caused by partial observability.","To tackle the first challenge, we propose Goal-Sensitive Backbone (GSB) for the policy to encourage the emergence of goal-relevant visual state representations.","To tackle the second challenge, the policy is further fueled by an adaptive horizon prediction module that helps alleviate the learning uncertainty brought by the non-stationary dynamics.","Experiments on 20 Minecraft tasks show that our method significantly outperforms the best baseline so far; in many of them, we double the performance.","Our ablation and exploratory studies then explain how our approach beat the counterparts and also unveil the surprising bonus of zero-shot generalization to new scenes (biomes).","We hope our agent could help shed some light on learning goal-conditioned, multi-task agents in challenging, open-ended environments like Minecraft."],"url":"http://arxiv.org/abs/2301.10034v2"}
{"created":"2023-01-13","title":"TransfQMix: Transformers for Leveraging the Graph Structure of Multi-Agent Reinforcement Learning Problems","abstract":"Coordination is one of the most difficult aspects of multi-agent reinforcement learning (MARL). One reason is that agents normally choose their actions independently of one another. In order to see coordination strategies emerging from the combination of independent policies, the recent research has focused on the use of a centralized function (CF) that learns each agent's contribution to the team reward. However, the structure in which the environment is presented to the agents and to the CF is typically overlooked. We have observed that the features used to describe the coordination problem can be represented as vertex features of a latent graph structure. Here, we present TransfQMix, a new approach that uses transformers to leverage this latent structure and learn better coordination policies. Our transformer agents perform a graph reasoning over the state of the observable entities. Our transformer Q-mixer learns a monotonic mixing-function from a larger graph that includes the internal and external states of the agents. TransfQMix is designed to be entirely transferable, meaning that same parameters can be used to control and train larger or smaller teams of agents. This enables to deploy promising approaches to save training time and derive general policies in MARL, such as transfer learning, zero-shot transfer, and curriculum learning. We report TransfQMix's performances in the Spread and StarCraft II environments. In both settings, it outperforms state-of-the-art Q-Learning models, and it demonstrates effectiveness in solving problems that other methods can not solve.","sentences":["Coordination is one of the most difficult aspects of multi-agent reinforcement learning (MARL).","One reason is that agents normally choose their actions independently of one another.","In order to see coordination strategies emerging from the combination of independent policies, the recent research has focused on the use of a centralized function (CF) that learns each agent's contribution to the team reward.","However, the structure in which the environment is presented to the agents and to the CF is typically overlooked.","We have observed that the features used to describe the coordination problem can be represented as vertex features of a latent graph structure.","Here, we present TransfQMix, a new approach that uses transformers to leverage this latent structure and learn better coordination policies.","Our transformer agents perform a graph reasoning over the state of the observable entities.","Our transformer Q-mixer learns a monotonic mixing-function from a larger graph that includes the internal and external states of the agents.","TransfQMix is designed to be entirely transferable, meaning that same parameters can be used to control and train larger or smaller teams of agents.","This enables to deploy promising approaches to save training time and derive general policies in MARL, such as transfer learning, zero-shot transfer, and curriculum learning.","We report TransfQMix's performances in the Spread and StarCraft II environments.","In both settings, it outperforms state-of-the-art Q-Learning models, and it demonstrates effectiveness in solving problems that other methods can not solve."],"url":"http://arxiv.org/abs/2301.05334v1"}
{"created":"2023-01-10","title":"Mastering Diverse Domains through World Models","abstract":"General intelligence requires solving tasks across many domains. Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks. We present DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches across a wide range of domains with fixed hyperparameters. These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales. We observe favorable scaling properties of DreamerV3, with larger models directly translating to higher data-efficiency and final performance. Applied out of the box, DreamerV3 is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula, a long-standing challenge in artificial intelligence. Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems.","sentences":["General intelligence requires solving tasks across many domains.","Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks.","We present DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches across a wide range of domains with fixed hyperparameters.","These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales.","We observe favorable scaling properties of DreamerV3, with larger models directly translating to higher data-efficiency and final performance.","Applied out of the box, DreamerV3 is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula, a long-standing challenge in artificial intelligence.","Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems."],"url":"http://arxiv.org/abs/2301.04104v1"}
{"created":"2023-01-05","title":"Self-Motivated Multi-Agent Exploration","abstract":"In cooperative multi-agent reinforcement learning (CMARL), it is critical for agents to achieve a balance between self-exploration and team collaboration. However, agents can hardly accomplish the team task without coordination and they would be trapped in a local optimum where easy cooperation is accessed without enough individual exploration. Recent works mainly concentrate on agents' coordinated exploration, which brings about the exponentially grown exploration of the state space. To address this issue, we propose Self-Motivated Multi-Agent Exploration (SMMAE), which aims to achieve success in team tasks by adaptively finding a trade-off between self-exploration and team cooperation. In SMMAE, we train an independent exploration policy for each agent to maximize their own visited state space. Each agent learns an adjustable exploration probability based on the stability of the joint team policy. The experiments on highly cooperative tasks in StarCraft II micromanagement benchmark (SMAC) demonstrate that SMMAE can explore task-related states more efficiently, accomplish coordinated behaviours and boost the learning performance.","sentences":["In cooperative multi-agent reinforcement learning (CMARL), it is critical for agents to achieve a balance between self-exploration and team collaboration.","However, agents can hardly accomplish the team task without coordination and they would be trapped in a local optimum where easy cooperation is accessed without enough individual exploration.","Recent works mainly concentrate on agents' coordinated exploration, which brings about the exponentially grown exploration of the state space.","To address this issue, we propose Self-Motivated Multi-Agent Exploration (SMMAE), which aims to achieve success in team tasks by adaptively finding a trade-off between self-exploration and team cooperation.","In SMMAE, we train an independent exploration policy for each agent to maximize their own visited state space.","Each agent learns an adjustable exploration probability based on the stability of the joint team policy.","The experiments on highly cooperative tasks in StarCraft II micromanagement benchmark (SMAC) demonstrate that SMMAE can explore task-related states more efficiently, accomplish coordinated behaviours and boost the learning performance."],"url":"http://arxiv.org/abs/2301.02083v1"}
{"created":"2023-01-04","title":"Attention-Based Recurrence for Multi-Agent Reinforcement Learning under State Uncertainty","abstract":"State uncertainty poses a major challenge for decentralized coordination but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under agent-wise state uncertainty. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding state uncertainty. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various state uncertainty configurations in MessySMAC.","sentences":["State uncertainty poses a major challenge for decentralized coordination but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC).","In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under agent-wise state uncertainty.","AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE.","We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding state uncertainty.","We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE.","Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various state uncertainty configurations in MessySMAC."],"url":"http://arxiv.org/abs/2301.01649v2"}
{"created":"2023-04-06","title":"TagGPT: Large Language Models are Zero-shot Multimodal Taggers","abstract":"Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.","sentences":["Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems.","Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks.","In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion.","Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc.","Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics.","Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts.","It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want.","TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications.","We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers.","Project page: https://github.com/TencentARC/TagGPT."],"url":"http://arxiv.org/abs/2304.03022v1"}
{"created":"2023-04-05","title":"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification","abstract":"Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy. The simple BoW model performed on par with the most complex LLM prompting. Prompt engineering required significant investment.","sentences":["Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications.","This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering.","Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning.","The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice.","The second task is causal relation detection from the biomedical literature.","We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models.","Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy.","The simple BoW model performed on par with the most complex LLM prompting.","Prompt engineering required significant investment."],"url":"http://arxiv.org/abs/2304.02496v1"}
{"created":"2023-04-05","title":"Explainable Automated Debugging via Large Language Model-driven Scientific Debugging","abstract":"Automated debugging techniques have the potential to reduce developer effort in debugging, and have matured enough to be adopted by industry. However, one critical issue with existing techniques is that, while developers want rationales for the provided automatic debugging results, existing techniques are ill-suited to provide them, as their deduction process differs significantly from that of human developers. Inspired by the way developers interact with code when debugging, we propose Automated Scientific Debugging (AutoSD), a technique that given buggy code and a bug-revealing test, prompts large language models to automatically generate hypotheses, uses debuggers to actively interact with buggy code, and thus automatically reach conclusions prior to patch generation. By aligning the reasoning of automated debugging more closely with that of human developers, we aim to produce intelligible explanations of how a specific patch has been generated, with the hope that the explanation will lead to more efficient and accurate developer decisions. Our empirical analysis on three program repair benchmarks shows that AutoSD performs competitively with other program repair baselines, and that it can indicate when it is confident in its results. Furthermore, we perform a human study with 20 participants, including six professional developers, to evaluate the utility of explanations from AutoSD. Participants with access to explanations could judge patch correctness in roughly the same time as those without, but their accuracy improved for five out of six real-world bugs studied: 70% of participants answered that they wanted explanations when using repair tools, while 55% answered that they were satisfied with the Scientific Debugging presentation.","sentences":["Automated debugging techniques have the potential to reduce developer effort in debugging, and have matured enough to be adopted by industry.","However, one critical issue with existing techniques is that, while developers want rationales for the provided automatic debugging results, existing techniques are ill-suited to provide them, as their deduction process differs significantly from that of human developers.","Inspired by the way developers interact with code when debugging, we propose Automated Scientific Debugging (AutoSD), a technique that given buggy code and a bug-revealing test, prompts large language models to automatically generate hypotheses, uses debuggers to actively interact with buggy code, and thus automatically reach conclusions prior to patch generation.","By aligning the reasoning of automated debugging more closely with that of human developers, we aim to produce intelligible explanations of how a specific patch has been generated, with the hope that the explanation will lead to more efficient and accurate developer decisions.","Our empirical analysis on three program repair benchmarks shows that AutoSD performs competitively with other program repair baselines, and that it can indicate when it is confident in its results.","Furthermore, we perform a human study with 20 participants, including six professional developers, to evaluate the utility of explanations from AutoSD.","Participants with access to explanations could judge patch correctness in roughly the same time as those without, but their accuracy improved for five out of six real-world bugs studied: 70% of participants answered that they wanted explanations when using repair tools, while 55% answered that they were satisfied with the Scientific Debugging presentation."],"url":"http://arxiv.org/abs/2304.02195v1"}
{"created":"2023-04-04","title":"Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications","abstract":"The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionized various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.","sentences":["The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionized various industries, including geotechnical engineering.","However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations.","In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications.","We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses.","Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design.","We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis.","By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future."],"url":"http://arxiv.org/abs/2304.02138v1"}
{"created":"2023-04-03","title":"On the Prime Number Divisibility by Deep Learning","abstract":"Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms. In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers. It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models. We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided. We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success. Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes. We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs).","sentences":["Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms.","In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers.","It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models.","We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided.","We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success.","Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes.","We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs)."],"url":"http://arxiv.org/abs/2304.01333v1"}
{"created":"2023-04-01","title":"Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT","abstract":"Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches. While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards. This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same mistakes. For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT. By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!","sentences":["Automated Program Repair (APR) aims to automatically generate patches for buggy programs.","Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR.","Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches.","While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards.","This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   ","To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style.","ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR.","For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch.","In this way, we can avoid making the same mistakes.","For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches.","In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches.","While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT.","By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!"],"url":"http://arxiv.org/abs/2304.00385v1"}
{"created":"2023-03-31","title":"Pair Programming with Large Language Models for Sampling and Estimation of Copulas","abstract":"Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.","sentences":["Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations.","This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results.","In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI).","Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons.","It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner.","For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct.","Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques."],"url":"http://arxiv.org/abs/2303.18116v1"}
{"created":"2023-03-31","title":"Towards Enhancing In-Context Learning for Code Generation","abstract":"In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation. ICL does not require training. PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program. However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation. We refer to these studies as standard ICL.   Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder. Compared to standard ICL, AceCoder has two novelties. (1) Example retrieval. It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them. (2) Guided Code Generation. It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs. The preliminary can help PTLMs understand requirements and guide the next code generation. We apply AceCoder to six PTLMs (e.g., Codex) and evaluate it on three public benchmarks using the Pass@k. Results show that AceCoder can significantly improve the performance of PTLMs on code generation. (1) In terms of Pass@1, AceCoder outperforms standard ICL by up to 79.7% and fine-tuned models by up to 171%. (2) AceCoder is effective in PTLMs with different sizes (e.g., 1B to 175B) and different languages (e.g., Python, Java, and JavaScript). (3) We investigate multiple choices of the intermediate preliminary. (4) We manually evaluate generated programs in three aspects and prove the superiority of AceCoder. (5) Finally, we discuss some insights about ICL for practitioners.","sentences":["In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation.","ICL does not require training.","PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program.","However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation.","We refer to these studies as standard ICL.   ","Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder.","Compared to standard ICL, AceCoder has two novelties.","(1) Example retrieval.","It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them.","(2) Guided Code Generation.","It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs.","The preliminary can help PTLMs understand requirements and guide the next code generation.","We apply AceCoder to six PTLMs (e.g., Codex) and evaluate it on three public benchmarks using the Pass@k.","Results show that AceCoder can significantly improve the performance of PTLMs on code generation.","(1) In terms of Pass@1, AceCoder outperforms standard ICL by up to 79.7% and fine-tuned models by up to 171%.","(2) AceCoder is effective in PTLMs with different sizes (e.g., 1B to 175B) and different languages (e.g., Python, Java, and JavaScript).","(3) We investigate multiple choices of the intermediate preliminary.","(4) We manually evaluate generated programs in three aspects and prove the superiority of AceCoder.","(5) Finally, we discuss some insights about ICL for practitioners."],"url":"http://arxiv.org/abs/2303.17780v1"}
{"created":"2023-03-30","title":"Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure","abstract":"Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4. This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data. According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the \"bad\" cases could paradoxically be learned from the \"good\" cases. We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes.","sentences":["Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT.","Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases.","The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making.","We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark).","ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others.","GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4.","Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4.","This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the \"bad\" cases could paradoxically be learned from the \"good\" cases.","We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes."],"url":"http://arxiv.org/abs/2303.17276v1"}
{"created":"2023-03-29","title":"ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models","abstract":"Protein language models (pLMs), pre-trained via causal language modeling on protein sequences, have been a promising tool for protein sequence design. In real-world protein engineering, there are many cases where the amino acids in the middle of a protein sequence are optimized while maintaining other residues. Unfortunately, because of the left-to-right nature of pLMs, existing pLMs modify suffix residues by prompting prefix residues, which are insufficient for the infilling task that considers the whole surrounding context. To find the more effective pLMs for protein engineering, we design a new benchmark, Secondary structureE InFilling rEcoveRy, SEIFER, which approximates infilling sequence design scenarios. With the evaluation of existing models on the benchmark, we reveal the weakness of existing language models and show that language models trained via fill-in-middle transformation, called ProtFIM, are more appropriate for protein engineering. Also, we prove that ProtFIM generates protein sequences with decent protein representations through exhaustive experiments and visualizations.","sentences":["Protein language models (pLMs), pre-trained via causal language modeling on protein sequences, have been a promising tool for protein sequence design.","In real-world protein engineering, there are many cases where the amino acids in the middle of a protein sequence are optimized while maintaining other residues.","Unfortunately, because of the left-to-right nature of pLMs, existing pLMs modify suffix residues by prompting prefix residues, which are insufficient for the infilling task that considers the whole surrounding context.","To find the more effective pLMs for protein engineering, we design a new benchmark, Secondary structureE InFilling rEcoveRy, SEIFER, which approximates infilling sequence design scenarios.","With the evaluation of existing models on the benchmark, we reveal the weakness of existing language models and show that language models trained via fill-in-middle transformation, called ProtFIM, are more appropriate for protein engineering.","Also, we prove that ProtFIM generates protein sequences with decent protein representations through exhaustive experiments and visualizations."],"url":"http://arxiv.org/abs/2303.16452v1"}
{"created":"2023-03-29","title":"Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology","abstract":"The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.","sentences":["The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community.","ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology.","In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows.","We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering.","We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology.","Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt.","Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences."],"url":"http://arxiv.org/abs/2303.16429v1"}
{"created":"2023-03-28","title":"On Codex Prompt Engineering for OCL Generation: An Empirical Study","abstract":"The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the prompts with UML information and enabling few-shot learning increases the reliability of the generated OCL constraints. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex.","sentences":["The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models.","Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption.","Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation.","Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages.","We investigate the reliability of OCL constraints generated by Codex from natural language specifications.","To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods.","By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the prompts with UML information and enabling few-shot learning increases the reliability of the generated OCL constraints.","Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex."],"url":"http://arxiv.org/abs/2303.16244v1"}
{"created":"2023-03-28","title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds","abstract":"This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.","sentences":["This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games.","The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills.","ChatGPT is a conversational agent developed by OpenAI.","Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability.","To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters.","Here, the quality of the generated levels is determined by their stability and similarity to the given characters.","A sample prompt is provided to participants for their reference.","An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters.","To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation."],"url":"http://arxiv.org/abs/2303.15662v1"}
{"created":"2023-03-27","title":"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing","abstract":"Large language models have revolutionized the field of artificial intelligence and have been used in various applications. Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted. ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment. Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.","sentences":["Large language models have revolutionized the field of artificial intelligence and have been used in various applications.","Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted.","ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment.","Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts.","Its versatility and accuracy make it a powerful tool for natural language processing (NLP).","However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns.","This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations.","Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios.","Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques."],"url":"http://arxiv.org/abs/2304.02017v2"}
{"created":"2023-03-26","title":"Homochiral antiferromagnetic merons, antimerons and bimerons realized in synthetic antiferromagnets","abstract":"The ever-growing demand for device miniaturization and energy efficiency in data storage and computing technology has prompted a shift towards antiferromagnetic (AFM) topological spin textures as information carriers, owing to their negligible stray fields, leading to possible high device density and potentially ultrafast dynamics. We realize, in this work, such chiral in-plane (IP) topological antiferromagnetic spin textures, namely merons, antimerons, and bimerons in synthetic antiferromagnets by concurrently engineering the effective perpendicular magnetic anisotropy, the interlayer exchange coupling, and the magnetic compensation ratio. We demonstrate by three-dimensional vector imaging of the N\\'eel order parameter, the topology of those spin textures and reveal globally a well-defined chirality, which is a crucial requirement for controlled current-induced dynamics. Our analysis reveals that the interplay between interlayer exchange and interlayer magnetic dipolar interactions plays a key role in significantly reducing the critical strength of the Dzyaloshinskii-Moriya interaction required to stabilize topological spin textures, such as AFM merons, making synthetic antiferromagnets a promising platform for next-generation spintronics applications.","sentences":["The ever-growing demand for device miniaturization and energy efficiency in data storage and computing technology has prompted a shift towards antiferromagnetic (AFM) topological spin textures as information carriers, owing to their negligible stray fields, leading to possible high device density and potentially ultrafast dynamics.","We realize, in this work, such chiral in-plane (IP) topological antiferromagnetic spin textures, namely merons, antimerons, and bimerons in synthetic antiferromagnets by concurrently engineering the effective perpendicular magnetic anisotropy, the interlayer exchange coupling, and the magnetic compensation ratio.","We demonstrate by three-dimensional vector imaging of the N\\'eel order parameter, the topology of those spin textures and reveal globally a well-defined chirality, which is a crucial requirement for controlled current-induced dynamics.","Our analysis reveals that the interplay between interlayer exchange and interlayer magnetic dipolar interactions plays a key role in significantly reducing the critical strength of the Dzyaloshinskii-Moriya interaction required to stabilize topological spin textures, such as AFM merons, making synthetic antiferromagnets a promising platform for next-generation spintronics applications."],"url":"http://arxiv.org/abs/2303.14853v1"}
{"created":"2023-03-24","title":"Fermi-GBM Discovery of GRB 221009A: An Extraordinarily Bright GRB from Onset to Afterglow","abstract":"We report the discovery of GRB 221009A, the highest flux gamma-ray burst ever observed by the Fermi Gamma-ray Burst Monitor (GBM). This GRB has continuous prompt emission lasting more than 600 seconds, afterglow visible in the \\gbm energy range (8 keV--40 MeV), and total energetics higher than any other burst in the GBM sample. By using a variety of new and existing analysis techniques we probe the spectral and temporal evolution of GRB 221009A. We find no emission prior to the GBM trigger time (t0; 2022 October 9 at 13:16:59.99 UTC), indicating that this is the time of prompt emission onset. The triggering pulse exhibits distinct spectral and temporal properties suggestive of shock-breakout with significant emission up to $\\sim$15\\,MeV. We characterize the onset of external shock at \\t0+600\\,s and find evidence of a plateau region in the early-afterglow phase which transitions to a slope consistent with \\swift-XRT afterglow measurements. We place the total energetics of GRB 221009A in context with the rest of the GBM sample and find that this GRB has the highest total isotropic-equivalent energy ($\\textrm{E}_{\\gamma,\\textrm{iso}}=1.0\\times10^{55}$\\,erg) and second highest isotropic-equivalent luminosity ($\\textrm{L}_{\\gamma,\\textrm{iso}}=9.9\\times10^{53}$\\,erg/s) based on redshift of z = 0.151. These extreme energetics are what allowed GBMto observe the continuously emitting central engine from the beginning of the prompt emission phase through the onset of early afterglow.","sentences":["We report the discovery of GRB 221009A, the highest flux gamma-ray burst ever observed by the Fermi Gamma-ray Burst Monitor (GBM).","This GRB has continuous prompt emission lasting more than 600 seconds, afterglow visible in the \\gbm energy range (8 keV--40 MeV), and total energetics higher than any other burst in the GBM sample.","By using a variety of new and existing analysis techniques we probe the spectral and temporal evolution of GRB 221009A. We find no emission prior to the GBM trigger time (t0; 2022 October 9 at 13:16:59.99 UTC), indicating that this is the time of prompt emission onset.","The triggering pulse exhibits distinct spectral and temporal properties suggestive of shock-breakout with significant emission up to $\\sim$15\\,MeV. We characterize the onset of external shock at \\t0+600\\,s and find evidence of a plateau region in the early-afterglow phase which transitions to a slope consistent with \\swift-XRT afterglow measurements.","We place the total energetics of GRB 221009A in context with the rest of the GBM sample and find that this GRB has the highest total isotropic-equivalent energy ($\\textrm{E}_{\\gamma,\\textrm{iso}}=1.0\\times10^{55}$\\,erg) and second highest isotropic-equivalent luminosity ($\\textrm{L}_{\\gamma,\\textrm{iso}}=9.9\\times10^{53}$\\,erg/s) based on redshift of z = 0.151.","These extreme energetics are what allowed GBMto observe the continuously emitting central engine from the beginning of the prompt emission phase through the onset of early afterglow."],"url":"http://arxiv.org/abs/2303.14172v1"}
{"created":"2023-03-22","title":"Exploring the Benefits of Visual Prompting in Differential Privacy","abstract":"Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to downstream tasks by engineering a well-trained frozen source model. In this work, we explore the benefits of VP in constructing compelling neural network classifiers with differential privacy (DP). We explore and integrate VP into canonical DP training methods and demonstrate its simplicity and efficiency. In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget. Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP. Lastly, we also conduct extensive ablation studies to validate the effectiveness and contribution of VP under DP consideration.","sentences":["Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to downstream tasks by engineering a well-trained frozen source model.","In this work, we explore the benefits of VP in constructing compelling neural network classifiers with differential privacy (DP).","We explore and integrate VP into canonical DP training methods and demonstrate its simplicity and efficiency.","In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget.","Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP.","Lastly, we also conduct extensive ablation studies to validate the effectiveness and contribution of VP under DP consideration."],"url":"http://arxiv.org/abs/2303.12247v1"}
{"created":"2023-03-20","title":"Large Language Models and Simple, Stupid Bugs","abstract":"With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding \"prompt\". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase the possibility of producing known, verbatim fixes.","sentences":["With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system.","Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding \"prompt\".","Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities.","Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training.","In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community.","We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code.","We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase the possibility of producing known, verbatim fixes."],"url":"http://arxiv.org/abs/2303.11455v1"}
{"created":"2023-03-20","title":"Capabilities of GPT-4 on Medical Challenge Problems","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine.","We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets.","GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks.","Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States.","We also evaluate performance on the MultiMedQA suite of benchmark datasets.","Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine.","Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B).","In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct.","We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case.","Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety."],"url":"http://arxiv.org/abs/2303.13375v1"}
{"created":"2023-03-18","title":"Revisiting the Plastic Surgery Hypothesis via Large Language Models","abstract":"Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.   The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning and prompting. To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy for more powerful APR. Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming the best-performing baseline by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs.","sentences":["Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program.","Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications.","However, these techniques are limited in terms of the bug types and patch variety they can produce.","As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR.","While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.   ","The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project.","Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients.","However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored.","In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs?","Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning and prompting.","To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy for more powerful APR.","Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming the best-performing baseline by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs."],"url":"http://arxiv.org/abs/2303.10494v1"}
{"created":"2023-03-16","title":"LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations","abstract":"Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions.","sentences":["Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources.","Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories.","Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented.","In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models.","Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking.","Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs.","As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions."],"url":"http://arxiv.org/abs/2303.09384v1"}
{"created":"2023-03-16","title":"Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models","abstract":"For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwardly extended to the conditional case where the instance-conditional prompts are generated to improve the generalizability. Extensive experiments on 15 datasets show promising transferability and generalization performance of our proposed model.","sentences":["For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts.","Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications.","We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model.","Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories.","Moreover, the proposed model can also be straightforwardly extended to the conditional case where the instance-conditional prompts are generated to improve the generalizability.","Extensive experiments on 15 datasets show promising transferability and generalization performance of our proposed model."],"url":"http://arxiv.org/abs/2303.09100v1"}
{"created":"2023-03-15","title":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation","abstract":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs. Our model and code are available at https://github.com/microsoft/LMOps.","sentences":["Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization.","We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input.","Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.","Our model and code are available at https://github.com/microsoft/LMOps."],"url":"http://arxiv.org/abs/2303.08518v2"}
{"created":"2023-03-13","title":"InferFix: End-to-End Program Repair with LLMs","abstract":"Software development life cycle is profoundly influenced by bugs: their introduction, identification, and eventual resolution account for a significant portion of software cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large language models have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose InferFix: a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs. InferFix combines a Retriever -- transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator -- a large language model (Codex Cushman) finetuned on supervised bug-fix data with prompts augmented via bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that InferFix outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of InferFix alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration pipeline to automate the software development workflow.","sentences":["Software development life cycle is profoundly influenced by bugs: their introduction, identification, and eventual resolution account for a significant portion of software cost.","This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects.","Large language models have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task.","However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories.","In this paper, we propose InferFix: a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.","InferFix combines a Retriever -- transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator -- a large language model (Codex Cushman) finetuned on supervised bug-fix data with prompts augmented via bug type annotations and semantically similar fixes retrieved from an external non-parametric memory.","To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories.","Our evaluation demonstrates that InferFix outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java.","We discuss the deployment of InferFix alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration pipeline to automate the software development workflow."],"url":"http://arxiv.org/abs/2303.07263v1"}
{"created":"2023-03-13","title":"Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering","abstract":"Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content. The paradigm under which this revolution takes place is prompt-based learning (or in-context learning). This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art. This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images. In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art. In three studies with participants recruited from a crowdsourcing platform, we explore whether untrained participants could 1) recognize the quality of prompts, 2) write prompts, and 3) improve their prompts. Our results indicate that participants could assess the quality of prompts and respective images. This ability increased with the participants' experience and interest in art. Participants further were able to write prompts in rich descriptive language. However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images. Our results suggest that prompt engineering is a learned skill that requires expertise and practice. Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-to-image generation and prompt engineering with a paid crowd. Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering. We conclude by speculating on four possible futures of prompt engineering.","sentences":["Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content.","The paradigm under which this revolution takes place is prompt-based learning (or in-context learning).","This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art.","This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images.","In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art.","In three studies with participants recruited from a crowdsourcing platform, we explore whether untrained participants could 1) recognize the quality of prompts, 2) write prompts, and 3) improve their prompts.","Our results indicate that participants could assess the quality of prompts and respective images.","This ability increased with the participants' experience and interest in art.","Participants further were able to write prompts in rich descriptive language.","However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images.","Our results suggest that prompt engineering is a learned skill that requires expertise and practice.","Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-to-image generation and prompt engineering with a paid crowd.","Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering.","We conclude by speculating on four possible futures of prompt engineering."],"url":"http://arxiv.org/abs/2303.13534v1"}
{"created":"2023-03-13","title":"Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification","abstract":"This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach. Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate \"reasoning\" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance.","sentences":["This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position.","We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa.","We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings.","To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output.","Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo.","We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance.","Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach.","Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate \"reasoning\" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance."],"url":"http://arxiv.org/abs/2303.07142v2"}
{"created":"2023-03-12","title":"Evidence for self-organized criticality phenomena in prompt phase of short gamma-ray bursts","abstract":"The prompt phase of gamma-ray burst (GRB) contains essential information regarding the physical nature and central engine, which are as yet unknown. In this paper, we investigate the self-organized criticality (SOC) phenomena in GRB prompt phase as done in X-ray flares of GRBs. We obtain the differential and cumulative distributions of 243 short GRB pulses, such as peak flux, FWHM, rise time, decay time, and peak time in the fourth BATSE TTE Catalog with the Markov Chain Monte Carlo (MCMC) technique. It is found that these distributions can be well described by power-law models. In particular, comparisons are made in 182 short GRB pulses in the third Swift GRB Catalog from 2004 December to 2019 July. The results are essentially consistent with those in BATSE ones. We notice that there is no obvious power-law index evolution across different energy bands for either BATSE or Swift sGRBs. The joint analysis suggests that GRB prompt phase can be explained by a Fractal-Diffusive, Self-Organized Criticality (FD-SOC) system with the spatial dimension S = 3 and the classical diffusion ? = 1. Our findings show that GRB prompt phases and X-ray flares possess the very same magnetically dominated stochastic process and mechanism.","sentences":["The prompt phase of gamma-ray burst (GRB) contains essential information regarding the physical nature and central engine, which are as yet unknown.","In this paper, we investigate the self-organized criticality (SOC) phenomena in GRB prompt phase as done in X-ray flares of GRBs.","We obtain the differential and cumulative distributions of 243 short GRB pulses, such as peak flux, FWHM, rise time, decay time, and peak time in the fourth BATSE TTE Catalog with the Markov Chain Monte Carlo (MCMC) technique.","It is found that these distributions can be well described by power-law models.","In particular, comparisons are made in 182 short GRB pulses in the third Swift GRB Catalog from 2004 December to 2019 July.","The results are essentially consistent with those in BATSE ones.","We notice that there is no obvious power-law index evolution across different energy bands for either BATSE or Swift sGRBs.","The joint analysis suggests that GRB prompt phase can be explained by a Fractal-Diffusive, Self-Organized Criticality (FD-SOC) system with the spatial dimension S = 3 and the classical diffusion ?","= 1.","Our findings show that GRB prompt phases and X-ray flares possess the very same magnetically dominated stochastic process and mechanism."],"url":"http://arxiv.org/abs/2303.06667v1"}
{"created":"2023-03-11","title":"ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design","abstract":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","sentences":["This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented.","This paper provides two contributions to research on using LLMs for software engineering.","First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve.","Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design."],"url":"http://arxiv.org/abs/2303.07839v1"}
{"created":"2023-03-10","title":"Susceptibility to Influence of Large Language Models","abstract":"Two studies tested the hypothesis that a Large Language Model (LLM) can be used to model psychological change following exposure to influential input. The first study tested a generic mode of influence - the Illusory Truth Effect (ITE) - where earlier exposure to a statement (through, for example, rating its interest) boosts a later truthfulness test rating. Data was collected from 1000 human participants using an online experiment, and 1000 simulated participants using engineered prompts and LLM completion. 64 ratings per participant were collected, using all exposure-test combinations of the attributes: truth, interest, sentiment and importance. The results for human participants reconfirmed the ITE, and demonstrated an absence of effect for attributes other than truth, and when the same attribute is used for exposure and test. The same pattern of effects was found for LLM-simulated participants. The second study concerns a specific mode of influence - populist framing of news to increase its persuasion and political mobilization. Data from LLM-simulated participants was collected and compared to previously published data from a 15-country experiment on 7286 human participants. Several effects previously demonstrated from the human study were replicated by the simulated study, including effects that surprised the authors of the human study by contradicting their theoretical expectations (anti-immigrant framing of news decreases its persuasion and mobilization); but some significant relationships found in human data (modulation of the effectiveness of populist framing according to relative deprivation of the participant) were not present in the LLM data. Together the two studies support the view that LLMs have potential to act as models of the effect of influence.","sentences":["Two studies tested the hypothesis that a Large Language Model (LLM) can be used to model psychological change following exposure to influential input.","The first study tested a generic mode of influence - the Illusory Truth Effect (ITE) - where earlier exposure to a statement (through, for example, rating its interest) boosts a later truthfulness test rating.","Data was collected from 1000 human participants using an online experiment, and 1000 simulated participants using engineered prompts and LLM completion.","64 ratings per participant were collected, using all exposure-test combinations of the attributes: truth, interest, sentiment and importance.","The results for human participants reconfirmed the ITE, and demonstrated an absence of effect for attributes other than truth, and when the same attribute is used for exposure and test.","The same pattern of effects was found for LLM-simulated participants.","The second study concerns a specific mode of influence - populist framing of news to increase its persuasion and political mobilization.","Data from LLM-simulated participants was collected and compared to previously published data from a 15-country experiment on 7286 human participants.","Several effects previously demonstrated from the human study were replicated by the simulated study, including effects that surprised the authors of the human study by contradicting their theoretical expectations (anti-immigrant framing of news decreases its persuasion and mobilization); but some significant relationships found in human data (modulation of the effectiveness of populist framing according to relative deprivation of the participant) were not present in the LLM data.","Together the two studies support the view that LLMs have potential to act as models of the effect of influence."],"url":"http://arxiv.org/abs/2303.06074v1"}
{"created":"2023-03-10","title":"Automating Method Naming with Context-Aware Prompt-Tuning","abstract":"Method names are crucial to program comprehension and maintenance. Recently, many approaches have been proposed to automatically recommend method names and detect inconsistent names. Despite promising, their results are still sub-optimal considering the three following drawbacks: 1) These models are mostly trained from scratch, learning two different objectives simultaneously. The misalignment between two objectives will negatively affect training efficiency and model performance. 2) The enclosing class context is not fully exploited, making it difficult to learn the abstract function of the method. 3) Current method name consistency checking methods follow a generate-then-compare process, which restricts the accuracy as they highly rely on the quality of generated names and face difficulty measuring the semantic consistency.   In this paper, we propose an approach named AUMENA to AUtomate MEthod NAming tasks with context-aware prompt-tuning. Unlike existing deep learning based approaches, our model first learns the contextualized representation(i.e., class attributes) of PL and NL through the pre-training model, then fully exploits the capacity and knowledge of large language model with prompt-tuning to precisely detect inconsistent method names and recommend more accurate names. To better identify semantically consistent names, we model the method name consistency checking task as a two-class classification problem, avoiding the limitation of previous similarity-based consistency checking approaches. The experimental results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7% on four datasets of method name recommendation, surpassing the state-of-the-art baseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively. And our approach scores 80.8% accuracy on method name consistency checking, reaching an 5.5% outperformance. All data and trained models are publicly available.","sentences":["Method names are crucial to program comprehension and maintenance.","Recently, many approaches have been proposed to automatically recommend method names and detect inconsistent names.","Despite promising, their results are still sub-optimal considering the three following drawbacks: 1) These models are mostly trained from scratch, learning two different objectives simultaneously.","The misalignment between two objectives will negatively affect training efficiency and model performance.","2)","The enclosing class context is not fully exploited, making it difficult to learn the abstract function of the method.","3) Current method name consistency checking methods follow a generate-then-compare process, which restricts the accuracy as they highly rely on the quality of generated names and face difficulty measuring the semantic consistency.   ","In this paper, we propose an approach named AUMENA to AUtomate MEthod NAming tasks with context-aware prompt-tuning.","Unlike existing deep learning based approaches, our model first learns the contextualized representation(i.e., class attributes) of PL and NL through the pre-training model, then fully exploits the capacity and knowledge of large language model with prompt-tuning to precisely detect inconsistent method names and recommend more accurate names.","To better identify semantically consistent names, we model the method name consistency checking task as a two-class classification problem, avoiding the limitation of previous similarity-based consistency checking approaches.","The experimental results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7% on four datasets of method name recommendation, surpassing the state-of-the-art baseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively.","And our approach scores 80.8% accuracy on method name consistency checking, reaching an 5.5% outperformance.","All data and trained models are publicly available."],"url":"http://arxiv.org/abs/2303.05771v1"}
{"created":"2023-03-09","title":"Greener yet Powerful: Taming Large Code Generation Models with Quantization","abstract":"ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","sentences":["ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts.","Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance.","Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code.","Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   ","Model compression is a promising approach to address these challenges.","Several techniques are proposed to compress large pretrained models typically used for vision or textual data.","Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost.","As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation.","We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness.","To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation.","We further found the recipe is readily applicable to code summarization task as well."],"url":"http://arxiv.org/abs/2303.05378v1"}
{"created":"2023-03-08","title":"A Prompt Log Analysis of Text-to-Image Generation Systems","abstract":"Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \"prompt\". These systems have immediately received lots of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale. We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs. Users make more edits within creation sessions, which present remarkable exploratory patterns. There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.","sentences":["Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \"prompt\".","These systems have immediately received lots of attention from researchers, creators, and common users.","Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale.","We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems.","Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research.","Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs.","Users make more edits within creation sessions, which present remarkable exploratory patterns.","There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models.","Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes."],"url":"http://arxiv.org/abs/2303.04587v2"}
{"created":"2023-03-07","title":"Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering -- Example of ChatGPT","abstract":"There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI). ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions. These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future.","sentences":["There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs).","Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding.","In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI).","ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions.","These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses.","ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction.","In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases.","We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts.","These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future."],"url":"http://arxiv.org/abs/2303.05352v1"}
{"created":"2023-03-06","title":"Late-Time HST Observations of AT 2018cow I: Further Constraints on the Fading Prompt Emission and Thermal Properties 50-60 Days Post-Explosion","abstract":"The exact nature of the luminous Fast Blue Optical Transient AT 2018cow is still debated. In this first of a two-paper series, we present a detailed analysis of three Hubble Space Telescope (HST) observations of AT 2018cow covering $\\sim$50-60 days post-explosion, which provide significantly improved constraints of the fading prompt emission and late thermal properties. By modeling the Spectral Energy Distributions (SEDs), we confirm that the UV-optical emission over 50-60 days was still a smooth blackbody (i.e., optically thick) with a high temperature ($T_{\\mathrm{BB}}\\sim15000\\,\\mathrm{K}$) and small radius ($R_{\\mathrm{BB}}\\lesssim1000\\,R_\\odot$). Additionally, we report for the first time a break in the bolometric light curve: the thermal luminosity initially declined at a rate of $L_{\\mathrm{BB}}\\propto t^{-2.40}$, but faded much faster at $t^{-3.06}$ after day 13. Re-examining possible late-time power sources, we disfavor significant contributions from radioactive decay based on the required $^{56}$Ni mass and the complete lack of UV line blanketing in the HST SEDs. We argue that the commonly-proposed interaction with circumstellar material may face significant challenges in explaining the late thermal properties, particularly the effects of optical depth. Alternatively, we find that continuous outflow/wind driven by a central engine can still reasonably explain the combination of receding photosphere, optically thick and rapid fading emission, as well as the intermediate-width lines. However, the rapid fading may have further implications on the power output of the engine and structure of the wind. Our findings may support the hypothesis that AT 2018cow and other ``Cow-like transients'' are powered mainly by accretion onto a central engine.","sentences":["The exact nature of the luminous Fast Blue Optical Transient AT 2018cow is still debated.","In this first of a two-paper series, we present a detailed analysis of three Hubble Space Telescope (HST) observations of AT 2018cow covering $\\sim$50-60 days post-explosion, which provide significantly improved constraints of the fading prompt emission and late thermal properties.","By modeling the Spectral Energy Distributions (SEDs), we confirm that the UV-optical emission over 50-60 days was still a smooth blackbody (i.e., optically thick) with a high temperature ($T_{\\mathrm{BB}}\\sim15000\\,\\mathrm{K}$) and small radius ($R_{\\mathrm{BB}}\\lesssim1000\\,R_\\odot$).","Additionally, we report for the first time a break in the bolometric light curve: the thermal luminosity initially declined at a rate of $L_{\\mathrm{BB}}\\propto t^{-2.40}$, but faded much faster at $t^{-3.06}$ after day 13.","Re-examining possible late-time power sources, we disfavor significant contributions from radioactive decay based on the required $^{56}$Ni mass and the complete lack of UV line blanketing in the HST SEDs.","We argue that the commonly-proposed interaction with circumstellar material may face significant challenges in explaining the late thermal properties, particularly the effects of optical depth.","Alternatively, we find that continuous outflow/wind driven by a central engine can still reasonably explain the combination of receding photosphere, optically thick and rapid fading emission, as well as the intermediate-width lines.","However, the rapid fading may have further implications on the power output of the engine and structure of the wind.","Our findings may support the hypothesis that AT 2018cow and other ``Cow-like transients'' are powered mainly by accretion onto a central engine."],"url":"http://arxiv.org/abs/2303.03500v1"}
{"created":"2023-03-03","title":"Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering","abstract":"Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient. In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the model: answer candidates and answer-aware examples. Finally, the two types of answer heuristics are encoded into the prompts to enable GPT-3 to better comprehend the task thus enhancing its capacity. Prophet significantly outperforms all existing state-of-the-art methods on two challenging knowledge-based VQA datasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their testing sets, respectively.","sentences":["Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question.","Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models.","Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering.","Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient.","In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA.","Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge.","After that, we extract two types of complementary answer heuristics from the model: answer candidates and answer-aware examples.","Finally, the two types of answer heuristics are encoded into the prompts to enable GPT-3 to better comprehend the task thus enhancing its capacity.","Prophet significantly outperforms all existing state-of-the-art methods on two challenging knowledge-based VQA datasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their testing sets, respectively."],"url":"http://arxiv.org/abs/2303.01903v2"}
{"created":"2023-03-03","title":"A variational quantum algorithm-based numerical method for solving potential and Stokes flows","abstract":"This paper presents a numerical method based on the variational quantum algorithm to solve potential and Stokes flow problems. In this method, the governing equations for potential and Stokes flows can be respectively written in the form of Laplace's equation and Stokes equations using velocity potential, stream function and vorticity formulations. Then the finite difference method and the generalised differential quadrature (GDQ) method are applied to discretize the governing equations. For the prescribed boundary conditions, the corresponding linear systems of equations can be obtained. These linear systems are solved by using the variational quantum linear solver (VQLS), which resolves the potential and Stokes flow problems equivalently. To the best of authors' knowledge, this is the first study that incorporates the GDQ method which is inherently a high-order discretization method with the VQLS algorithm. Since the GDQ method can utilize much fewer grid points than the finite difference method to approximate derivatives with a higher order of accuracy, the size of the input matrix for the VQLS algorithm can be smaller. In this way, the computational cost may be saved. The performance of the present method is comprehensively assessed by two representative examples, namely, the potential flow around a circular cylinder and Stokes flow in a lid-driven cavity. Numerical results validate the applicability and accuracy of the present VQLS-based method. Furthermore, its time complexity is evaluated by the heuristic scaling, which demonstrates that the present method scales efficiently in the number of qubits and the precision. This work brings quantum computing to the field of computational fluid dynamics. By virtue of quantum advantage over classical methods, promising advances in solving large-scale fluid mechanics problems of engineering interest may be prompted.","sentences":["This paper presents a numerical method based on the variational quantum algorithm to solve potential and Stokes flow problems.","In this method, the governing equations for potential and Stokes flows can be respectively written in the form of Laplace's equation and Stokes equations using velocity potential, stream function and vorticity formulations.","Then the finite difference method and the generalised differential quadrature (GDQ) method are applied to discretize the governing equations.","For the prescribed boundary conditions, the corresponding linear systems of equations can be obtained.","These linear systems are solved by using the variational quantum linear solver (VQLS), which resolves the potential and Stokes flow problems equivalently.","To the best of authors' knowledge, this is the first study that incorporates the GDQ method which is inherently a high-order discretization method with the VQLS algorithm.","Since the GDQ method can utilize much fewer grid points than the finite difference method to approximate derivatives with a higher order of accuracy, the size of the input matrix for the VQLS algorithm can be smaller.","In this way, the computational cost may be saved.","The performance of the present method is comprehensively assessed by two representative examples, namely, the potential flow around a circular cylinder and Stokes flow in a lid-driven cavity.","Numerical results validate the applicability and accuracy of the present VQLS-based method.","Furthermore, its time complexity is evaluated by the heuristic scaling, which demonstrates that the present method scales efficiently in the number of qubits and the precision.","This work brings quantum computing to the field of computational fluid dynamics.","By virtue of quantum advantage over classical methods, promising advances in solving large-scale fluid mechanics problems of engineering interest may be prompted."],"url":"http://arxiv.org/abs/2303.01805v1"}
{"created":"2023-03-02","title":"Insight-HXMT and GECAM-C observations of the brightest-of-all-time GRB 221009A","abstract":"GRB 221009A is the brightest gamma-ray burst ever detected since the discovery of this kind of energetic explosions. However, an accurate measurement of the prompt emission properties of this burst is very challenging due to its exceptional brightness. With joint observations of \\textit{Insight}-HXMT and GECAM-C, we made an unprecedentedly accurate measurement of the emission during the first $\\sim$1800 s of GRB 221009A, including its precursor, main emission (ME, which dominates the burst in flux), flaring emission and early afterglow, in the hard X-ray to soft gamma-ray band from $\\sim$ 10 keV to $\\sim$ 6 MeV. Based on the GECAM-C unsaturated data of the ME, we measure a record-breaking isotropic equivalent energy ($E_{\\rm iso}$) of $\\bf \\sim 1.5 \\times 10^{55}$ erg, which is about eight times the total rest-mass energy of the Sun. The early afterglow data require a significant jet break between 650 s and 1100 s, most likely at $\\sim950$ s from the afterglow starting time $T_{AG}$, which corresponds to a jet opening angle of $\\sim {0.7^\\circ} \\ (\\eta_\\gamma n)^{1/8}$, where $n$ is the ambient medium density in units of $\\rm cm^{-3}$ and $\\eta_\\gamma$ is the ratio between $\\gamma$-ray energy and afterglow kinetic energy. The beaming-corrected total $\\gamma$-ray energy $E_{\\gamma}$ is $\\sim 1.15 \\times10^{51} \\ (\\eta_\\gamma n)^{1/4}$ erg, which is typical for long GRBs. These results suggest that this GRB may have a special central engine, which could launch and collimate a very narrowly beamed jet with an ordinary energy budget, leading to exceptionally luminous gamma-ray radiation per unit solid angle. Alternatively, more GRBs might have such a narrow and bright beam, which are missed by an unfavorable viewing angle or have been detected without distance measurement.","sentences":["GRB 221009A is the brightest gamma-ray burst ever detected since the discovery of this kind of energetic explosions.","However, an accurate measurement of the prompt emission properties of this burst is very challenging due to its exceptional brightness.","With joint observations of \\textit{Insight}-HXMT and GECAM-C, we made an unprecedentedly accurate measurement of the emission during the first $\\sim$1800 s of GRB 221009A, including its precursor, main emission (ME, which dominates the burst in flux), flaring emission and early afterglow, in the hard X-ray to soft gamma-ray band from $\\sim$ 10 keV to $\\sim$ 6 MeV. Based on the GECAM-C unsaturated data of the ME, we measure a record-breaking isotropic equivalent energy ($E_{\\rm iso}$) of $\\bf \\sim 1.5 \\times 10^{55}$ erg, which is about eight times the total rest-mass energy of the Sun.","The early afterglow data require a significant jet break between 650 s and 1100 s, most likely at $\\sim950$ s from the afterglow starting time $T_{AG}$, which corresponds to a jet opening angle of $\\sim {0.7^\\circ} \\ (\\eta_\\gamma n)^{1/8}$, where $n$ is the ambient medium density in units of $\\rm cm^{-3}$ and $\\eta_\\gamma$ is the ratio between $\\gamma$-ray energy and afterglow kinetic energy.","The beaming-corrected total $\\gamma$-ray energy $E_{\\gamma}$ is $\\sim 1.15 \\times10^{51} \\ (\\eta_\\gamma n)^{1/4}$ erg, which is typical for long GRBs.","These results suggest that this GRB may have a special central engine, which could launch and collimate a very narrowly beamed jet with an ordinary energy budget, leading to exceptionally luminous gamma-ray radiation per unit solid angle.","Alternatively, more GRBs might have such a narrow and bright beam, which are missed by an unfavorable viewing angle or have been detected without distance measurement."],"url":"http://arxiv.org/abs/2303.01203v2"}
{"created":"2023-02-28","title":"EvoPrompting: Language Models for Code-Level Neural Architecture Search","abstract":"Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 out of 30 algorithmic reasoning tasks while maintaining similar model size. EvoPrompting is successful at designing accurate and efficient neural network architectures across a variety of machine learning tasks, while also being general enough for easy adaptation to other tasks beyond neural network design.","sentences":["Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm.","While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models.","We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size.","We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 out of 30 algorithmic reasoning tasks while maintaining similar model size.","EvoPrompting is successful at designing accurate and efficient neural network architectures across a variety of machine learning tasks, while also being general enough for easy adaptation to other tasks beyond neural network design."],"url":"http://arxiv.org/abs/2302.14838v1"}
{"created":"2023-02-28","title":"Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning","abstract":"Multimodal few-shot learning is challenging due to the large domain gap between vision and language modalities. Existing methods are trying to communicate visual concepts as prompts to frozen language models, but rely on hand-engineered task induction to reduce the hypothesis space. To make the whole process learnable, we introduce a multimodal meta-learning approach. Specifically, our approach decomposes the training of the model into a set of related multimodal few-shot tasks. We define a meta-mapper network, acting as a meta-learner, to efficiently bridge frozen large-scale vision and language models and leverage their already learned capacity. By updating the learnable parameters only of the meta-mapper, it learns to accrue shared meta-knowledge among these tasks. Thus, it can rapidly adapt to newly presented samples with only a few gradient updates. Importantly, it induces the task in a completely data-driven manner, with no need for a hand-engineered task induction. We evaluate our approach on recently proposed multimodal few-shot benchmarks, measuring how rapidly the model can bind novel visual concepts to words and answer visual questions by observing only a limited set of labeled examples. The experimental results show that our meta-learning approach outperforms the baseline across multiple datasets and various training settings while being computationally more efficient.","sentences":["Multimodal few-shot learning is challenging due to the large domain gap between vision and language modalities.","Existing methods are trying to communicate visual concepts as prompts to frozen language models, but rely on hand-engineered task induction to reduce the hypothesis space.","To make the whole process learnable, we introduce a multimodal meta-learning approach.","Specifically, our approach decomposes the training of the model into a set of related multimodal few-shot tasks.","We define a meta-mapper network, acting as a meta-learner, to efficiently bridge frozen large-scale vision and language models and leverage their already learned capacity.","By updating the learnable parameters only of the meta-mapper, it learns to accrue shared meta-knowledge among these tasks.","Thus, it can rapidly adapt to newly presented samples with only a few gradient updates.","Importantly, it induces the task in a completely data-driven manner, with no need for a hand-engineered task induction.","We evaluate our approach on recently proposed multimodal few-shot benchmarks, measuring how rapidly the model can bind novel visual concepts to words and answer visual questions by observing only a limited set of labeled examples.","The experimental results show that our meta-learning approach outperforms the baseline across multiple datasets and various training settings while being computationally more efficient."],"url":"http://arxiv.org/abs/2302.14794v1"}
{"created":"2023-02-28","title":"GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation","abstract":"We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters capable of knowledge-grounded conversation in Chinese using a search engine to access the Internet knowledge. GLM-Dialog offers a series of applicable techniques for exploiting various external knowledge including both helpful and noisy knowledge, enabling the creation of robust knowledge-grounded dialogue LLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we also propose a novel evaluation method to allow humans to converse with multiple deployed bots simultaneously and compare their performance implicitly instead of explicitly rating using multidimensional metrics.Comprehensive evaluations from automatic to human perspective demonstrate the advantages of GLM-Dialog comparing with existing open source Chinese dialogue models. We release both the model checkpoint and source code, and also deploy it as a WeChat application to interact with users. We offer our evaluation platform online in an effort to prompt the development of open source models and reliable dialogue evaluation systems. The additional easy-to-use toolkit that consists of short text entity linking, query generation, and helpful knowledge classification is also released to enable diverse applications. All the source code is available on Github.","sentences":["We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters capable of knowledge-grounded conversation in Chinese using a search engine to access the Internet knowledge.","GLM-Dialog offers a series of applicable techniques for exploiting various external knowledge including both helpful and noisy knowledge, enabling the creation of robust knowledge-grounded dialogue LLMs with limited proper datasets.","To evaluate the GLM-Dialog more fairly, we also propose a novel evaluation method to allow humans to converse with multiple deployed bots simultaneously and compare their performance implicitly instead of explicitly rating using multidimensional metrics.","Comprehensive evaluations from automatic to human perspective demonstrate the advantages of GLM-Dialog comparing with existing open source Chinese dialogue models.","We release both the model checkpoint and source code, and also deploy it as a WeChat application to interact with users.","We offer our evaluation platform online in an effort to prompt the development of open source models and reliable dialogue evaluation systems.","The additional easy-to-use toolkit that consists of short text entity linking, query generation, and helpful knowledge classification is also released to enable diverse applications.","All the source code is available on Github."],"url":"http://arxiv.org/abs/2302.14401v1"}
{"created":"2023-02-27","title":"Electric Vehicle Sales Forecasting Model Considering Green Premium: A Chinese Market-based Perspective","abstract":"\"Green Premiums\" which means the difference in cost between emissions-emitting technology and zero-emissions or emissions-reducing technology is significant for those renewable energy technology to address the climate change challenge facing the world in this century. China's Electrical Vehicles (EVs) industry is the first to cross the green premium into the commercialization stage, prompting its market size to exceed that of the US and EU combined, making it the most inspiring case in global carbon reduction practices. This study, which is based on first-hand data from industry research and innovatively constructs a multi-factor green premium model for EVs based on Total Cost of Ownership (TCO) analysis, finds that EVs currently have a higher green premium than Internal Combustion Engine Vehicles (ICEVs) and is expected that short-range EVs will be the first to achieve parity in acquisition costs by 2025 and long-range EVs by 2030. Further, this paper constructs a generalized Bass diffusion model considering the green premium, selects the time series data of EVs diffusion in the Chinese market from 2010-2021, and uses a genetic algorithm to fit the parameters to predict the EVs market penetration in the next ten years under different scenarios. The model prediction results show that EVs are successful innovative diffusion products and the market penetration rate depends largely on their green premium. The Chinese EVs market may experience a slowdown or even a decline in growth in the short term, but will maintain high growth in the medium to long term, with annual sales expected to reach 10.77 million units by 2030 and a penetration rate of about 39%.","sentences":["\"Green Premiums\" which means the difference in cost between emissions-emitting technology and zero-emissions or emissions-reducing technology is significant for those renewable energy technology to address the climate change challenge facing the world in this century.","China's Electrical Vehicles (EVs) industry is the first to cross the green premium into the commercialization stage, prompting its market size to exceed that of the US and EU combined, making it the most inspiring case in global carbon reduction practices.","This study, which is based on first-hand data from industry research and innovatively constructs a multi-factor green premium model for EVs based on Total Cost of Ownership (TCO) analysis, finds that EVs currently have a higher green premium than Internal Combustion Engine Vehicles (ICEVs) and is expected that short-range EVs will be the first to achieve parity in acquisition costs by 2025 and long-range EVs by 2030.","Further, this paper constructs a generalized Bass diffusion model considering the green premium, selects the time series data of EVs diffusion in the Chinese market from 2010-2021, and uses a genetic algorithm to fit the parameters to predict the EVs market penetration in the next ten years under different scenarios.","The model prediction results show that EVs are successful innovative diffusion products and the market penetration rate depends largely on their green premium.","The Chinese EVs market may experience a slowdown or even a decline in growth in the short term, but will maintain high growth in the medium to long term, with annual sales expected to reach 10.77 million units by 2030 and a penetration rate of about 39%."],"url":"http://arxiv.org/abs/2302.13893v1"}
{"created":"2023-02-24","title":"Robot Behavior-Tree-Based Task Generation with Large Language Models","abstract":"Nowadays, the behavior tree is gaining popularity as a representation for robot tasks due to its modularity and reusability. Designing behavior-tree tasks manually is time-consuming for robot end-users, thus there is a need for investigating automatic behavior-tree-based task generation. Prior behavior-tree-based task generation approaches focus on fixed primitive tasks and lack generalizability to new task domains. To cope with this issue, we propose a novel behavior-tree-based task generation approach that utilizes state-of-the-art large language models. We propose a Phase-Step prompt design that enables a hierarchical-structured robot task generation and further integrate it with behavior-tree-embedding-based search to set up the appropriate prompt. In this way, we enable an automatic and cross-domain behavior-tree task generation. Our behavior-tree-based task generation approach does not require a set of pre-defined primitive tasks. End-users only need to describe an abstract desired task and our proposed approach can swiftly generate the corresponding behavior tree. A full-process case study is provided to demonstrate our proposed approach. An ablation study is conducted to evaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step prompts and the limitation of large language models are presented and discussed.","sentences":["Nowadays, the behavior tree is gaining popularity as a representation for robot tasks due to its modularity and reusability.","Designing behavior-tree tasks manually is time-consuming for robot end-users, thus there is a need for investigating automatic behavior-tree-based task generation.","Prior behavior-tree-based task generation approaches focus on fixed primitive tasks and lack generalizability to new task domains.","To cope with this issue, we propose a novel behavior-tree-based task generation approach that utilizes state-of-the-art large language models.","We propose a Phase-Step prompt design that enables a hierarchical-structured robot task generation and further integrate it with behavior-tree-embedding-based search to set up the appropriate prompt.","In this way, we enable an automatic and cross-domain behavior-tree task generation.","Our behavior-tree-based task generation approach does not require a set of pre-defined primitive tasks.","End-users only need to describe an abstract desired task and our proposed approach can swiftly generate the corresponding behavior tree.","A full-process case study is provided to demonstrate our proposed approach.","An ablation study is conducted to evaluate the effectiveness of our Phase-Step prompts.","Assessment on Phase-Step prompts and the limitation of large language models are presented and discussed."],"url":"http://arxiv.org/abs/2302.12927v1"}
{"created":"2023-02-24","title":"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data","abstract":"Chain-of-thought prompting (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in arithmetic, commonsense, and symbolic reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt the language model, which poses challenges for real-world applications where labeled training data is available without human-annotated rational chains. This creates barriers to applications of CoT prompting to these general tasks. This paper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoTs by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machine-generated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where state-of-the-art results are achieved on arithmetic reasoning (+2.7\\%), commonsense reasoning (+3.4\\%), symbolic reasoning (+3.2\\%), and non-reasoning tasks (+2.5\\%). Our code will be available at https://github.com/shizhediao/automate-cot.","sentences":["Chain-of-thought prompting (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in arithmetic, commonsense, and symbolic reasoning tasks.","However, most CoT studies rely on carefully designed human-annotated rational chains to prompt the language model, which poses challenges for real-world applications where labeled training data is available without human-annotated rational chains.","This creates barriers to applications of CoT prompting to these general tasks.","This paper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoTs by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machine-generated rationale chains based on the labels.","Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model.","Automate-CoT enables a quick adaptation of the CoT technique to different tasks.","Experimental results demonstrate the effectiveness of our method, where state-of-the-art results are achieved on arithmetic reasoning (+2.7\\%), commonsense reasoning (+3.4\\%), symbolic reasoning (+3.2\\%), and non-reasoning tasks (+2.5\\%).","Our code will be available at https://github.com/shizhediao/automate-cot."],"url":"http://arxiv.org/abs/2302.12822v1"}
{"created":"2023-02-23","title":"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness","abstract":"Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase. This knowledge is then used at inference to address the task specified by the user in their prompt. For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question. Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts. For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt. In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge. We study this in the context of consumers seeking health advice from the model. Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness. This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models.","sentences":["Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase.","This knowledge is then used at inference to address the task specified by the user in their prompt.","For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question.","Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts.","For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt.","In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge.","We study this in the context of consumers seeking health advice from the model.","Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness.","This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models."],"url":"http://arxiv.org/abs/2302.13793v1"}
{"created":"2023-02-23","title":"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models","abstract":"We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs). They are already being adopted in practice and integrated into many systems, including integrated development environments (IDEs) and search engines. The functionalities of current LLMs can be modulated via natural language prompts, while their exact internal functionality remains implicit and unassessable. This property, which makes them adaptable to even unseen tasks, might also make them susceptible to targeted adversarial prompting. Recently, several ways to misalign LLMs using Prompt Injection (PI) attacks have been introduced. In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes. Recent work showed that these attacks are hard to mitigate, as state-of-the-art LLMs are instruction-following. So far, these attacks assumed that the adversary is directly prompting the LLM.   In this work, we show that augmenting LLMs with retrieval and API calling capabilities (so-called Application-Integrated LLMs) induces a whole new set of attack vectors. These LLMs might process poisoned content retrieved from the Web that contains malicious prompts pre-injected and selected by adversaries. We demonstrate that an attacker can indirectly perform such PI attacks. Based on this key insight, we systematically analyze the resulting threat landscape of Application-Integrated LLMs and discuss a variety of new attack vectors. To demonstrate the practical viability of our attacks, we implemented specific demonstrations of the proposed attacks within synthetic applications. In summary, our work calls for an urgent evaluation of current mitigation techniques and an investigation of whether new techniques are needed to defend LLMs against these threats.","sentences":["We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs).","They are already being adopted in practice and integrated into many systems, including integrated development environments (IDEs) and search engines.","The functionalities of current LLMs can be modulated via natural language prompts, while their exact internal functionality remains implicit and unassessable.","This property, which makes them adaptable to even unseen tasks, might also make them susceptible to targeted adversarial prompting.","Recently, several ways to misalign LLMs using Prompt Injection (PI) attacks have been introduced.","In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes.","Recent work showed that these attacks are hard to mitigate, as state-of-the-art LLMs are instruction-following.","So far, these attacks assumed that the adversary is directly prompting the LLM.   ","In this work, we show that augmenting LLMs with retrieval and API calling capabilities (so-called Application-Integrated LLMs) induces a whole new set of attack vectors.","These LLMs might process poisoned content retrieved from the Web that contains malicious prompts pre-injected and selected by adversaries.","We demonstrate that an attacker can indirectly perform such PI attacks.","Based on this key insight, we systematically analyze the resulting threat landscape of Application-Integrated LLMs and discuss a variety of new attack vectors.","To demonstrate the practical viability of our attacks, we implemented specific demonstrations of the proposed attacks within synthetic applications.","In summary, our work calls for an urgent evaluation of current mitigation techniques and an investigation of whether new techniques are needed to defend LLMs against these threats."],"url":"http://arxiv.org/abs/2302.12173v1"}
{"created":"2023-02-23","title":"Controlled and Conditional Text to Image Generation with Diffusion Prior","abstract":"Denoising Diffusion models have shown remarkable performance in generating diverse, high quality images from text. Numerous techniques have been proposed on top of or in alignment with models like Stable Diffusion and Imagen that generate images directly from text. A lesser explored approach is DALLE-2's two step process comprising a Diffusion Prior that generates a CLIP image embedding from text and a Diffusion Decoder that generates an image from a CLIP image embedding. We explore the capabilities of the Diffusion Prior and the advantages of an intermediate CLIP representation. We observe that Diffusion Prior can be used in a memory and compute efficient way to constrain the generation to a specific domain without altering the larger Diffusion Decoder. Moreover, we show that the Diffusion Prior can be trained with additional conditional information such as color histogram to further control the generation. We show quantitatively and qualitatively that the proposed approaches perform better than prompt engineering for domain specific generation and existing baselines for color conditioned generation. We believe that our observations and results will instigate further research into the diffusion prior and uncover more of its capabilities.","sentences":["Denoising Diffusion models have shown remarkable performance in generating diverse, high quality images from text.","Numerous techniques have been proposed on top of or in alignment with models like Stable Diffusion and Imagen that generate images directly from text.","A lesser explored approach is DALLE-2's two step process comprising a Diffusion Prior that generates a CLIP image embedding from text and a Diffusion Decoder that generates an image from a CLIP image embedding.","We explore the capabilities of the Diffusion Prior and the advantages of an intermediate CLIP representation.","We observe that Diffusion Prior can be used in a memory and compute efficient way to constrain the generation to a specific domain without altering the larger Diffusion Decoder.","Moreover, we show that the Diffusion Prior can be trained with additional conditional information such as color histogram to further control the generation.","We show quantitatively and qualitatively that the proposed approaches perform better than prompt engineering for domain specific generation and existing baselines for color conditioned generation.","We believe that our observations and results will instigate further research into the diffusion prior and uncover more of its capabilities."],"url":"http://arxiv.org/abs/2302.11710v1"}
{"created":"2023-02-22","title":"Implication of GRB 221009A: Can TeV Emission Come from the GRB Prompt Phase?","abstract":"Recently, the B.O.A.T. (\"brightest of all time\") gamma-ray burst, dubbed GRB 221009A, was detected by various instruments. Unprecedentedly, the GRB presented very-high-energy (VHE, energy above 0.1 TeV) gamma-ray emission with energy extending above 10 TeV, as reported by the Large High Altitude Air Shower Observatory (LHAASO). We here demonstrate that the VHE and especially >10 TeV emission may originate from the internal hadronic dissipation of the GRB, without the need of invoking any exotic processes as suggested by some previous studies. We also discuss the constraints on the properties of the GRB ejecta from multiwavelength and multi-messenger observations, which favors a magnetically dominated GRB ejecta. The suggested Poynting-flux-dominated GRB ejecta in this work supports the Blandford & Znajek (BZ) mechanism as the possible central engine model of GRB.","sentences":["Recently, the B.O.A.T. (\"brightest of all time\") gamma-ray burst, dubbed GRB 221009A, was detected by various instruments.","Unprecedentedly, the GRB presented very-high-energy (VHE, energy above 0.1 TeV) gamma-ray emission with energy extending above 10 TeV, as reported by the Large High Altitude Air Shower Observatory (LHAASO).","We here demonstrate that the VHE and especially >10 TeV emission may originate from the internal hadronic dissipation of the GRB, without the need of invoking any exotic processes as suggested by some previous studies.","We also discuss the constraints on the properties of the GRB ejecta from multiwavelength and multi-messenger observations, which favors a magnetically dominated GRB ejecta.","The suggested Poynting-flux-dominated GRB ejecta in this work supports the Blandford & Znajek (BZ) mechanism as the possible central engine model of GRB."],"url":"http://arxiv.org/abs/2302.11111v1"}
{"created":"2023-02-21","title":"RealFusion: 360\u00b0 Reconstruction of Any Object from a Single Image","abstract":"We consider the problem of reconstructing a full 360{\\deg} photographic model of an object from a single image of it. We do so by fitting a neural radiance field to the image, but find this problem to be severely ill-posed. We thus take an off-the-self conditional image generator based on diffusion and engineer a prompt that encourages it to \"dream up\" novel views of the object. Using an approach inspired by DreamFields and DreamFusion, we fuse the given input view, the conditional prior, and other regularizers in a final, consistent reconstruction. We demonstrate state-of-the-art reconstruction results on benchmark images when compared to prior methods for monocular 3D reconstruction of objects. Qualitatively, our reconstructions provide a faithful match of the input view and a plausible extrapolation of its appearance and 3D shape, including to the side of the object not visible in the image.","sentences":["We consider the problem of reconstructing a full 360{\\deg} photographic model of an object from a single image of it.","We do so by fitting a neural radiance field to the image, but find this problem to be severely ill-posed.","We thus take an off-the-self conditional image generator based on diffusion and engineer a prompt that encourages it to \"dream up\" novel views of the object.","Using an approach inspired by DreamFields and DreamFusion, we fuse the given input view, the conditional prior, and other regularizers in a final, consistent reconstruction.","We demonstrate state-of-the-art reconstruction results on benchmark images when compared to prior methods for monocular 3D reconstruction of objects.","Qualitatively, our reconstructions provide a faithful match of the input view and a plausible extrapolation of its appearance and 3D shape, including to the side of the object not visible in the image."],"url":"http://arxiv.org/abs/2302.10663v2"}
{"created":"2023-02-21","title":"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT","abstract":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","sentences":["Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT.","Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output.","Prompts are also a form of programming that can customize the outputs and interactions with an LLM.","This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs.","This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks.","First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains.","Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations.","Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns."],"url":"http://arxiv.org/abs/2302.11382v1"}
{"created":"2023-02-20","title":"Prompt Stealing Attacks Against Text-to-Image Generation Models","abstract":"Text-to-Image generation models have revolutionized the artwork design process and enabled anyone to create high-quality images by entering text descriptions called prompts. Creating a high-quality prompt that consists of a subject and several modifiers can be time-consuming and costly. In consequence, a trend of trading high-quality prompts on specialized marketplaces has emerged. In this paper, we propose a novel attack, namely prompt stealing attack, which aims to steal prompts from generated images by text-to-image generation models. Successful prompt stealing attacks direct violate the intellectual property and privacy of prompt engineers and also jeopardize the business model of prompt trading marketplaces. We first perform a large-scale analysis on a dataset collected by ourselves and show that a successful prompt stealing attack should consider a prompt's subject as well as its modifiers. We then propose the first learning-based prompt stealing attack, PromptStealer, and demonstrate its superiority over two baseline methods quantitatively and qualitatively. We also make some initial attempts to defend PromptStealer. In general, our study uncovers a new attack surface in the ecosystem created by the popular text-to-image generation models. We hope our results can help to mitigate the threat. To facilitate research in this field, we will share our dataset and code with the community.","sentences":["Text-to-Image generation models have revolutionized the artwork design process and enabled anyone to create high-quality images by entering text descriptions called prompts.","Creating a high-quality prompt that consists of a subject and several modifiers can be time-consuming and costly.","In consequence, a trend of trading high-quality prompts on specialized marketplaces has emerged.","In this paper, we propose a novel attack, namely prompt stealing attack, which aims to steal prompts from generated images by text-to-image generation models.","Successful prompt stealing attacks direct violate the intellectual property and privacy of prompt engineers and also jeopardize the business model of prompt trading marketplaces.","We first perform a large-scale analysis on a dataset collected by ourselves and show that a successful prompt stealing attack should consider a prompt's subject as well as its modifiers.","We then propose the first learning-based prompt stealing attack, PromptStealer, and demonstrate its superiority over two baseline methods quantitatively and qualitatively.","We also make some initial attempts to defend PromptStealer.","In general, our study uncovers a new attack surface in the ecosystem created by the popular text-to-image generation models.","We hope our results can help to mitigate the threat.","To facilitate research in this field, we will share our dataset and code with the community."],"url":"http://arxiv.org/abs/2302.09923v1"}
{"created":"2023-02-20","title":"Photometric and Spectroscopic Observations of GRB 190106A: Emission from Reverse and Forward Shocks with Late-time Energy Injection","abstract":"Early optical observations of gamma-ray bursts can significantly contribute to the study of the central engine and physical processes therein. However, of the thousands observed so far, still only a few have data at optical wavelengths in the first minutes after the onset of the prompt emission. Here we report on GRB\\,190106A, whose afterglow was observed in optical bands just 36 s after the {\\em Swift}/BAT trigger, i.e., during the prompt emission phase. The early optical afterglow exhibits a bimodal structure followed by a normal decay, with a faster decay after $\\sim \\rm T_{0}+$1 day. We present optical photometric and spectroscopic observations of GRB\\,190106A. We derive the redshift via metal absorption lines from Xinglong 2.16-m/BFOSC spectroscopic observations. From the BFOSC spectrum, we measure $z= 1.861\\pm0.002$. The double-peak optical light curve is a significant feature predicted by the reverse-forward external shock model. The shallow decay followed by a normal decay in both the X-ray and optical light curves is well explained with the standard forward-shock model with late-time energy injection. Therefore, GRB\\,190106A offers a case study for GRBs emission from both reverse and forward shocks.","sentences":["Early optical observations of gamma-ray bursts can significantly contribute to the study of the central engine and physical processes therein.","However, of the thousands observed so far, still only a few have data at optical wavelengths in the first minutes after the onset of the prompt emission.","Here we report on GRB\\,190106A, whose afterglow was observed in optical bands just 36 s after the {\\em Swift}/BAT trigger, i.e., during the prompt emission phase.","The early optical afterglow exhibits a bimodal structure followed by a normal decay, with a faster decay after $\\sim \\rm T_{0}+$1 day.","We present optical photometric and spectroscopic observations of GRB\\,190106A.","We derive the redshift via metal absorption lines from Xinglong 2.16-m/BFOSC spectroscopic observations.","From the BFOSC spectrum, we measure $z= 1.861\\pm0.002$.","The double-peak optical light curve is a significant feature predicted by the reverse-forward external shock model.","The shallow decay followed by a normal decay in both the X-ray and optical light curves is well explained with the standard forward-shock model with late-time energy injection.","Therefore, GRB\\,190106A offers a case study for GRBs emission from both reverse and forward shocks."],"url":"http://arxiv.org/abs/2302.09722v2"}
{"created":"2023-02-19","title":"Few-shot Multimodal Multitask Multilingual Learning","abstract":"While few-shot learning as a transfer learning paradigm has gained significant traction for scenarios with limited data, it has primarily been explored in the context of building unimodal and unilingual models. Furthermore, a significant part of the existing literature in the domain of few-shot multitask learning perform in-context learning which requires manually generated prompts as the input, yielding varying outcomes depending on the level of manual prompt-engineering. In addition, in-context learning suffers from substantial computational, memory, and storage costs which eventually leads to high inference latency because it involves running all of the prompt's examples through the model every time a prediction is made. In contrast, methods based on the transfer learning via the fine-tuning paradigm avoid the aforementioned issues at a one-time cost of fine-tuning weights on a per-task basis. However, such methods lack exposure to few-shot multimodal multitask learning. In this paper, we propose few-shot learning for a multimodal multitask multilingual (FM3) setting by adapting pre-trained vision and language models using task-specific hypernetworks and contrastively fine-tuning them to enable few-shot learning. FM3's architecture combines the best of both worlds of in-context and fine-tuning based learning and consists of three major components: (i) multimodal contrastive fine-tuning to enable few-shot learning, (ii) hypernetwork task adaptation to perform multitask learning, and (iii) task-specific output heads to cater to a plethora of diverse tasks. FM3 learns the most prominent tasks in the vision and language domains along with their intersections, namely visual entailment (VE), visual question answering (VQA), and natural language understanding (NLU) tasks such as neural entity recognition (NER) and the GLUE benchmark including QNLI, MNLI, QQP, and SST-2.","sentences":["While few-shot learning as a transfer learning paradigm has gained significant traction for scenarios with limited data, it has primarily been explored in the context of building unimodal and unilingual models.","Furthermore, a significant part of the existing literature in the domain of few-shot multitask learning perform in-context learning which requires manually generated prompts as the input, yielding varying outcomes depending on the level of manual prompt-engineering.","In addition, in-context learning suffers from substantial computational, memory, and storage costs which eventually leads to high inference latency because it involves running all of the prompt's examples through the model every time a prediction is made.","In contrast, methods based on the transfer learning via the fine-tuning paradigm avoid the aforementioned issues at a one-time cost of fine-tuning weights on a per-task basis.","However, such methods lack exposure to few-shot multimodal multitask learning.","In this paper, we propose few-shot learning for a multimodal multitask multilingual (FM3) setting by adapting pre-trained vision and language models using task-specific hypernetworks and contrastively fine-tuning them to enable few-shot learning.","FM3's architecture combines the best of both worlds of in-context and fine-tuning based learning and consists of three major components: (i) multimodal contrastive fine-tuning to enable few-shot learning, (ii) hypernetwork task adaptation to perform multitask learning, and (iii) task-specific output heads to cater to a plethora of diverse tasks.","FM3 learns the most prominent tasks in the vision and language domains along with their intersections, namely visual entailment (VE), visual question answering (VQA), and natural language understanding (NLU) tasks such as neural entity recognition (NER) and the GLUE benchmark including QNLI, MNLI, QQP, and SST-2."],"url":"http://arxiv.org/abs/2303.12489v1"}
{"created":"2023-02-17","title":"Prompting Large Language Models With the Socratic Method","abstract":"This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.","sentences":["This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3.","Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified.","Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning.","Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated.","An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively."],"url":"http://arxiv.org/abs/2303.08769v2"}
{"created":"2023-02-17","title":"Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales","abstract":"The quality of text-to-image generation is continuously improving, yet the boundaries of its applicability are still unclear. In particular, refinement of the text input with the objective of achieving better results - commonly called prompt engineering - so far seems to have not been geared towards work with pre-existing texts. We investigate whether text-to-image generation and prompt engineering could be used to generate basic illustrations of popular fairytales. Using Midjourney v4, we engage in action research with a dual aim: to attempt to generate 5 believable illustrations for each of 5 popular fairytales, and to define a prompt engineering process that starts from a pre-existing text and arrives at an illustration of it. We arrive at a tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii) style refinement, and iv) variation selection. We also discuss three reasons why the generation model struggles with certain illustrations: difficulties with counts, bias from stereotypical configurations and inability to depict overly fantastic situations. Our findings are not limited to the specific generation model and are intended to be generalisable to future ones.","sentences":["The quality of text-to-image generation is continuously improving, yet the boundaries of its applicability are still unclear.","In particular, refinement of the text input with the objective of achieving better results - commonly called prompt engineering - so far seems to have not been geared towards work with pre-existing texts.","We investigate whether text-to-image generation and prompt engineering could be used to generate basic illustrations of popular fairytales.","Using Midjourney v4, we engage in action research with a dual aim: to attempt to generate 5 believable illustrations for each of 5 popular fairytales, and to define a prompt engineering process that starts from a pre-existing text and arrives at an illustration of it.","We arrive at a tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii) style refinement, and iv) variation selection.","We also discuss three reasons why the generation model struggles with certain illustrations: difficulties with counts, bias from stereotypical configurations and inability to depict overly fantastic situations.","Our findings are not limited to the specific generation model and are intended to be generalisable to future ones."],"url":"http://arxiv.org/abs/2302.08961v1"}
{"created":"2023-02-15","title":"Learning Performance-Improving Code Edits","abstract":"The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.","sentences":["The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains.","While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics.","In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits.","We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone.","We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE.","PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance.","We use PIE to evaluate and improve the capacity of large language models.","Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model.","Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting.","By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level.","Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task.","Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code."],"url":"http://arxiv.org/abs/2302.07867v3"}
{"created":"2023-02-15","title":"Log Parsing with Prompt-based Few-shot Learning","abstract":"Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems. Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics. Existing log parsers extract the common part as log templates using statistical features. However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets. To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning. LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data. In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set. We have conducted extensive experiments on 16 public log datasets. The experimental results show that LogPPT is effective and efficient for log parsing.","sentences":["Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems.","Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics.","Existing log parsers extract the common part as log templates using statistical features.","However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets.","To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning.","LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data.","In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set.","We have conducted extensive experiments on 16 public log datasets.","The experimental results show that LogPPT is effective and efficient for log parsing."],"url":"http://arxiv.org/abs/2302.07435v1"}
{"created":"2023-02-14","title":"Heterogeneous Anomaly Detection for Software Systems via Semi-supervised Cross-modal Attention","abstract":"Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems. Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among different types of data. Consequently, many false predictions occur. To better understand the manifestations of system anomalies, we conduct a systematical study on a large amount of heterogeneous data, i.e., logs and metrics. Our study demonstrates that logs and metrics can manifest system anomalies collaboratively and complementarily, and neither of them only is sufficient. Thus, integrating heterogeneous data can help recover the complete picture of a system's health status. In this context, we propose Hades, the first end-to-end semi-supervised approach to effectively identify system anomalies based on heterogeneous data. Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns. It captures discriminative features and meaningful interactions from heterogeneous data via a cross-modal attention module, trained in a semi-supervised manner. We evaluate Hades extensively on large-scale simulated data and datasets from Huawei Cloud. The experimental results present the effectiveness of our model in detecting system anomalies. We also release the code and the annotated dataset for replication and future research.","sentences":["Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems.","Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among different types of data.","Consequently, many false predictions occur.","To better understand the manifestations of system anomalies, we conduct a systematical study on a large amount of heterogeneous data, i.e., logs and metrics.","Our study demonstrates that logs and metrics can manifest system anomalies collaboratively and complementarily, and neither of them only is sufficient.","Thus, integrating heterogeneous data can help recover the complete picture of a system's health status.","In this context, we propose Hades, the first end-to-end semi-supervised approach to effectively identify system anomalies based on heterogeneous data.","Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns.","It captures discriminative features and meaningful interactions from heterogeneous data via a cross-modal attention module, trained in a semi-supervised manner.","We evaluate Hades extensively on large-scale simulated data and datasets from Huawei Cloud.","The experimental results present the effectiveness of our model in detecting system anomalies.","We also release the code and the annotated dataset for replication and future research."],"url":"http://arxiv.org/abs/2302.06914v1"}
{"created":"2023-02-13","title":"Adaptive Test Generation Using a Large Language Model","abstract":"Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. This paper presents TestPilot, an adaptive test generation technique that leverages Large Language Models (LLMs). TestPilot uses Codex, an off-the-shelf LLM, to automatically generate unit tests for a given program without requiring additional training or few-shot learning on examples of existing tests. In our approach, Codex is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. If a generated test fails, TestPilot's adaptive component attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We created an implementation of TestPilot for JavaScript and evaluated it on 25 npm packages with a total of 1,684 API functions to generate tests for. Our results show that the generated tests achieve up to 93.1% statement coverage (median 68.2%). Moreover, on average, 58.5% of the generated tests contain at least one assertion that exercises functionality from the package under test. Our experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. Finally, we find that TestPilot does not generate memorized tests: 92.7% of our generated tests have $\\leq$ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies.","sentences":["Unit tests play a key role in ensuring the correctness of software.","However, manually creating unit tests is a laborious task, motivating the need for automation.","This paper presents TestPilot, an adaptive test generation technique that leverages Large Language Models (LLMs).","TestPilot uses Codex, an off-the-shelf LLM, to automatically generate unit tests for a given program without requiring additional training or few-shot learning on examples of existing tests.","In our approach, Codex is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation.","If a generated test fails, TestPilot's adaptive component attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message.","We created an implementation of TestPilot for JavaScript and evaluated it on 25 npm packages with a total of 1,684 API functions to generate tests for.","Our results show that the generated tests achieve up to 93.1% statement coverage (median 68.2%).","Moreover, on average, 58.5% of the generated tests contain at least one assertion that exercises functionality from the package under test.","Our experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites.","Finally, we find that TestPilot does not generate memorized tests: 92.7% of our generated tests have $\\leq$ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies."],"url":"http://arxiv.org/abs/2302.06527v2"}
{"created":"2023-02-13","title":"A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models","abstract":"Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask \"Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?\". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring method that corrects for the biases. Using our proposed scoring method to create a weighted average prompt ensemble, our method outperforms equal average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its variants, and 11 fine-grained classification benchmarks, all while being fully automatic, optimization-free, and not requiring access to labeled validation data.","sentences":["Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify.","However, these zero-shot classifiers need prompt engineering to achieve high accuracy.","Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks.","In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling.","In particular, we ask \"Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?\".","We demonstrate that this is possible.","In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring method that corrects for the biases.","Using our proposed scoring method to create a weighted average prompt ensemble, our method outperforms equal average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its variants, and 11 fine-grained classification benchmarks, all while being fully automatic, optimization-free, and not requiring access to labeled validation data."],"url":"http://arxiv.org/abs/2302.06235v1"}
{"created":"2023-02-13","title":"GRB 190114C: Fireball Energy Budget and Radiative Efficiency Revisited","abstract":"The jet composition of gamma-ray bursts (GRBs), as well as how efficiently the jet converts its energy to radiation, are long-standing problems in GRB physics. Here, we reported a comprehensive temporal and spectral analysis of the TeV-emitting bright GRB 190114C. Its high fluence ($\\sim$ 4.436$\\times$10$^{-4}$ erg cm$^{-2}$) allows us to conduct the time-resolved spectral analysis in great detail and study their variations down to a very short time-scale ($\\sim$0.1 s) while preserving a high significance. Its prompt emission consists of three well-separated pulses. The first two main pulses ($P_1$ and $P_2$) exhibit independently strong thermal components, and starting from the third pulse ($P_3$) and extending to the entire afterglow, the spectra are all non-thermal, the synchrotron plus Compton up-scattering model well interpret the observation. By combining the thermal ($P_1$ and $P_2$) and the non-thermal ($P_3$) observations based on two different scenarios (global and pulse properties) and following the method described in \\cite{Zhang2021}, we measure the fireball parameters and GRB radiative efficiency with little uncertainties for this GRB. A relevantly high GRB radiative efficiency is obtained based on both the global and pulse properties, suggesting that if GRBs are powered by fireballs, the efficiency can be high sometimes. More interestingly, though the observed parameters are individually different (e.g., the amount of mass loading $M$), the radiative efficiency obtained from $P_1$ ($\\eta_\\gamma=36.0\\pm6.5\\%$) and $P_2$ ($\\eta_\\gamma=41.1\\pm1.9\\%$) is roughly the same, which implies that the central engine of the same GRB has some common properties.","sentences":["The jet composition of gamma-ray bursts (GRBs), as well as how efficiently the jet converts its energy to radiation, are long-standing problems in GRB physics.","Here, we reported a comprehensive temporal and spectral analysis of the TeV-emitting bright GRB 190114C.","Its high fluence ($\\sim$ 4.436$\\times$10$^{-4}$ erg cm$^{-2}$) allows us to conduct the time-resolved spectral analysis in great detail and study their variations down to a very short time-scale ($\\sim$0.1 s) while preserving a high significance.","Its prompt emission consists of three well-separated pulses.","The first two main pulses ($P_1$ and $P_2$) exhibit independently strong thermal components, and starting from the third pulse ($P_3$) and extending to the entire afterglow, the spectra are all non-thermal, the synchrotron plus Compton up-scattering model well interpret the observation.","By combining the thermal ($P_1$ and $P_2$) and the non-thermal ($P_3$) observations based on two different scenarios (global and pulse properties) and following the method described in \\cite{Zhang2021}, we measure the fireball parameters and GRB radiative efficiency with little uncertainties for this GRB.","A relevantly high GRB radiative efficiency is obtained based on both the global and pulse properties, suggesting that if GRBs are powered by fireballs, the efficiency can be high sometimes.","More interestingly, though the observed parameters are individually different (e.g., the amount of mass loading $M$), the radiative efficiency obtained from $P_1$ ($\\eta_\\gamma=36.0\\pm6.5\\%$) and $P_2$ ($\\eta_\\gamma=41.1\\pm1.9\\%$) is roughly the same, which implies that the central engine of the same GRB has some common properties."],"url":"http://arxiv.org/abs/2302.06116v1"}
{"created":"2023-02-08","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity","abstract":"This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We also release codebase for evaluation set extraction.","sentences":["This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets.","We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks.","We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset.","We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks.","We find that it is better at understanding non-Latin script languages than generating them.","It is able to generate multimodal content from textual prompts, via an intermediate code generation step.","Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner.","It is, for example, better at deductive than inductive reasoning.","ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base.","Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion.","We also release codebase for evaluation set extraction."],"url":"http://arxiv.org/abs/2302.04023v2"}
{"created":"2023-02-08","title":"Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models","abstract":"Recently, large language models for code generation have achieved breakthroughs in several programming language tasks. Their advances in competition-level programming problems have made them an emerging pillar in AI-assisted pair programming. Tools such as GitHub Copilot are already part of the daily programming workflow and are used by more than a million developers. The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities. This unsanitized training data can lead language models to learn these vulnerabilities and propagate them in the code generation procedure. Given the wide use of these models in the daily workflow of developers, it is crucial to study the security aspects of these models systematically.   In this work, we propose the first approach to automatically finding security vulnerabilities in black-box code generation models. To achieve this, we propose a novel black-box inversion approach based on few-shot prompting. We evaluate the effectiveness of our approach by examining code generation models in the generation of high-risk security weaknesses. We show that our approach automatically and systematically finds 1000s of security vulnerabilities in various code generation models, including the commercial black-box model GitHub Copilot.","sentences":["Recently, large language models for code generation have achieved breakthroughs in several programming language tasks.","Their advances in competition-level programming problems have made them an emerging pillar in AI-assisted pair programming.","Tools such as GitHub Copilot are already part of the daily programming workflow and are used by more than a million developers.","The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities.","This unsanitized training data can lead language models to learn these vulnerabilities and propagate them in the code generation procedure.","Given the wide use of these models in the daily workflow of developers, it is crucial to study the security aspects of these models systematically.   ","In this work, we propose the first approach to automatically finding security vulnerabilities in black-box code generation models.","To achieve this, we propose a novel black-box inversion approach based on few-shot prompting.","We evaluate the effectiveness of our approach by examining code generation models in the generation of high-risk security weaknesses.","We show that our approach automatically and systematically finds 1000s of security vulnerabilities in various code generation models, including the commercial black-box model GitHub Copilot."],"url":"http://arxiv.org/abs/2302.04012v1"}
{"created":"2023-02-07","title":"ChatGPT and Software Testing Education: Promises & Perils","abstract":"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.","sentences":["Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers.","More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language.","However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability.","Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.","The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock.","However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction.","As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum.","Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses.","Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors."],"url":"http://arxiv.org/abs/2302.03287v3"}
{"created":"2023-02-06","title":"CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets","abstract":"Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing CLIP pipelines and requires no additional training cost. Code is available at: https://github.com/acmi-lab/CHILS.","sentences":["Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names.","Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning).","However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and uninformative.","We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies.","CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction.","Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information.","CHiLS is simple to implement within existing CLIP pipelines and requires no additional training cost.","Code is available at: https://github.com/acmi-lab/CHILS."],"url":"http://arxiv.org/abs/2302.02551v2"}
{"created":"2023-02-04","title":"Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models","abstract":"The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies.","sentences":["The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text.","Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques.","However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent.","Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations.","This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches.","Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified.","This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models.","This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets.","This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies."],"url":"http://arxiv.org/abs/2302.02094v2"}
{"created":"2023-02-02","title":"Fixing Hardware Security Bugs with Large Language Models","abstract":"Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.","sentences":["Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains.","In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs.","We focus on bug repair in code written in the Hardware Description Language Verilog.","For this study we build a corpus of domain-representative hardware security bugs.","We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs.","The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM.","We show that an ensemble of LLMs can repair all ten of our benchmarks.","This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs.","These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework."],"url":"http://arxiv.org/abs/2302.01215v1"}
{"created":"2023-02-01","title":"Trash to Treasure: Using text-to-image models to inform the design of physical artefacts","abstract":"Text-to-image generative models have recently exploded in popularity and accessibility. Yet so far, use of these models in creative tasks that bridge the 2D digital world and the creation of physical artefacts has been understudied. We conduct a pilot study to investigate if and how text-to-image models can be used to assist in upstream tasks within the creative process, such as ideation and visualization, prior to a sculpture-making activity. Thirty participants selected sculpture-making materials and generated three images using the Stable Diffusion text-to-image generator, each with text prompts of their choice, with the aim of informing and then creating a physical sculpture. The majority of participants (23/30) reported that the generated images informed their sculptures, and 28/30 reported interest in using text-to-image models to help them in a creative task in the future. We identify several prompt engineering strategies and find that a participant's prompting strategy relates to their stage in the creative process. We discuss how our findings can inform support for users at different stages of the design process and for using text-to-image models for physical artefact design.","sentences":["Text-to-image generative models have recently exploded in popularity and accessibility.","Yet so far, use of these models in creative tasks that bridge the 2D digital world and the creation of physical artefacts has been understudied.","We conduct a pilot study to investigate if and how text-to-image models can be used to assist in upstream tasks within the creative process, such as ideation and visualization, prior to a sculpture-making activity.","Thirty participants selected sculpture-making materials and generated three images using the Stable Diffusion text-to-image generator, each with text prompts of their choice, with the aim of informing and then creating a physical sculpture.","The majority of participants (23/30) reported that the generated images informed their sculptures, and 28/30 reported interest in using text-to-image models to help them in a creative task in the future.","We identify several prompt engineering strategies and find that a participant's prompting strategy relates to their stage in the creative process.","We discuss how our findings can inform support for users at different stages of the design process and for using text-to-image models for physical artefact design."],"url":"http://arxiv.org/abs/2302.00561v1"}
{"created":"2023-01-30","title":"Conversational Automated Program Repair","abstract":"Automated Program Repair (APR) can help developers automatically generate patches for bugs. Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR. However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases. To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner. In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback. As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test. We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach.","sentences":["Automated Program Repair (APR) can help developers automatically generate patches for bugs.","Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR.","However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases.","To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner.","In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback.","As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test.","We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach."],"url":"http://arxiv.org/abs/2301.13246v1"}
{"created":"2023-01-29","title":"Distilling Internet-Scale Vision-Language Models into Embodied Agents","abstract":"Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.","sentences":["Instruction-following agents must ground language into their observation and action spaces.","Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data.","To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents.","We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior.","Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment.","Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects).","Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents."],"url":"http://arxiv.org/abs/2301.12507v1"}
{"created":"2023-01-28","title":"Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset","abstract":"It has been shown that accurate representation in media improves the well-being of the people who consume it. By contrast, inaccurate representations can negatively affect viewers and lead to harmful perceptions of other cultures. To achieve inclusive representation in generated images, we propose a culturally-aware priming approach for text-to-image synthesis using a small but culturally curated dataset that we collected, known here as Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias prevalent in giant datasets. Our proposed approach is comprised of two fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs, and (2) Adding semantic context via automated prompt engineering using the fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware text data. CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture. Our experiments indicate that priming using both text and image is effective in improving the cultural relevance and decreasing the offensiveness of generated images while maintaining quality.","sentences":["It has been shown that accurate representation in media improves the well-being of the people who consume it.","By contrast, inaccurate representations can negatively affect viewers and lead to harmful perceptions of other cultures.","To achieve inclusive representation in generated images, we propose a culturally-aware priming approach for text-to-image synthesis using a small but culturally curated dataset that we collected, known here as Cross-Cultural Understanding Benchmark (CCUB)","Dataset, to fight the bias prevalent in giant datasets.","Our proposed approach is comprised of two fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs, and (2) Adding semantic context via automated prompt engineering using the fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware text data.","CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture.","Our experiments indicate that priming using both text and image is effective in improving the cultural relevance and decreasing the offensiveness of generated images while maintaining quality."],"url":"http://arxiv.org/abs/2301.12073v1"}
{"created":"2023-01-26","title":"User-Customizable Transpilation of Scripting Languages","abstract":"A transpiler converts code from one programming language to another. Many practical uses of transpilers require the user to be able to guide or customize the program produced from a given input program. This customizability is important for satisfying many application-specific goals for the produced code such as ensuring performance, readability, maintainability, compatibility, and so on. Conventional transpilers are deterministic rule-driven systems often written without offering customizability per user and per program. Recent advances in transpilers based on neural networks offer some customizability to users, e.g. through interactive prompts, but they are still difficult to precisely control the production of a desired output. Both conventional and neural transpilation also suffer from the \"last mile\" problem: they produce correct code on average, i.e., on most parts of a given program, but not necessarily for all parts of it. We propose a new transpilation approach that offers fine-grained customizability and reusability of transpilation rules created by others, without burdening the user to understand the global semantics of the given source program. Our approach is mostly automatic and incremental, i.e., constructs translation rules needed to transpile the given program as per the user's guidance piece-by-piece. We implement the transpiler as a tool called DuoGlot, which translates Python to Javascript programs, and evaluate it on the popular GeeksForGeeks benchmarks. DuoGlot achieves 90% translation accuracy and so it outperforms all existing translators, while it produces readable code. We evaluate DuoGlot on two additional benchmarks, containing more challenging and longer programs, and similarly observe improved accuracy.","sentences":["A transpiler converts code from one programming language to another.","Many practical uses of transpilers require the user to be able to guide or customize the program produced from a given input program.","This customizability is important for satisfying many application-specific goals for the produced code such as ensuring performance, readability, maintainability, compatibility, and so on.","Conventional transpilers are deterministic rule-driven systems often written without offering customizability per user and per program.","Recent advances in transpilers based on neural networks offer some customizability to users, e.g. through interactive prompts, but they are still difficult to precisely control the production of a desired output.","Both conventional and neural transpilation also suffer from the \"last mile\" problem: they produce correct code on average, i.e., on most parts of a given program, but not necessarily for all parts of it.","We propose a new transpilation approach that offers fine-grained customizability and reusability of transpilation rules created by others, without burdening the user to understand the global semantics of the given source program.","Our approach is mostly automatic and incremental, i.e., constructs translation rules needed to transpile the given program as per the user's guidance piece-by-piece.","We implement the transpiler as a tool called DuoGlot, which translates Python to Javascript programs, and evaluate it on the popular GeeksForGeeks benchmarks.","DuoGlot achieves 90% translation accuracy and so it outperforms all existing translators, while it produces readable code.","We evaluate DuoGlot on two additional benchmarks, containing more challenging and longer programs, and similarly observe improved accuracy."],"url":"http://arxiv.org/abs/2301.11220v2"}
{"created":"2023-01-20","title":"Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine","abstract":"This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language. With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages. In other words, $\\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator","sentences":["This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness.","We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences.","By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages.","For distant languages, we explore an interesting strategy named $\\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly.","As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language.","With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages.","In other words, $\\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator"],"url":"http://arxiv.org/abs/2301.08745v3"}
{"created":"2023-01-13","title":"A Case Study in Engineering a Conversational Programming Assistant's Persona","abstract":"The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor. Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application. A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application.","sentences":["The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor.","Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application.","A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application."],"url":"http://arxiv.org/abs/2301.10016v1"}
{"created":"2023-01-10","title":"API Entity and Relation Joint Extraction from Text via Dynamic Prompt-tuned Language Model","abstract":"Extraction of Application Programming Interfaces (APIs) and their semantic relations from unstructured text (e.g., Stack Overflow) is a fundamental work for software engineering tasks (e.g., API recommendation). However, existing approaches are rule-based and sequence-labeling based. They must manually enumerate the rules or label data for a wide range of sentence patterns, which involves a significant amount of labor overhead and is exacerbated by morphological and common-word ambiguity. In contrast to matching or labeling API entities and relations, this paper formulates heterogeneous API extraction and API relation extraction task as a sequence-to-sequence generation task, and proposes AERJE, an API entity-relation joint extraction model based on the large pre-trained language model. After training on a small number of ambiguous but correctly labeled data, AERJE builds a multi-task architecture that extracts API entities and relations from unstructured text using dynamic prompts. We systematically evaluate AERJE on a set of long and ambiguous sentences from Stack Overflow. The experimental results show that AERJE achieves high accuracy and discrimination ability in API entity-relation joint extraction, even with zero or few-shot fine-tuning.","sentences":["Extraction of Application Programming Interfaces (APIs) and their semantic relations from unstructured text (e.g., Stack Overflow) is a fundamental work for software engineering tasks (e.g., API recommendation).","However, existing approaches are rule-based and sequence-labeling based.","They must manually enumerate the rules or label data for a wide range of sentence patterns, which involves a significant amount of labor overhead and is exacerbated by morphological and common-word ambiguity.","In contrast to matching or labeling API entities and relations, this paper formulates heterogeneous API extraction and API relation extraction task as a sequence-to-sequence generation task, and proposes AERJE, an API entity-relation joint extraction model based on the large pre-trained language model.","After training on a small number of ambiguous but correctly labeled data, AERJE builds a multi-task architecture that extracts API entities and relations from unstructured text using dynamic prompts.","We systematically evaluate AERJE on a set of long and ambiguous sentences from Stack Overflow.","The experimental results show that AERJE achieves high accuracy and discrimination ability in API entity-relation joint extraction, even with zero or few-shot fine-tuning."],"url":"http://arxiv.org/abs/2301.03987v1"}
{"created":"2023-01-09","title":"The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of Natural Scenes","abstract":"The sciences of biological and artificial intelligence are ever more intertwined. Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain. To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu). This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge. The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development. We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems.","sentences":["The sciences of biological and artificial intelligence are ever more intertwined.","Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain.","To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu).","This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD).","NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge.","The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development.","We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems."],"url":"http://arxiv.org/abs/2301.03198v2"}
{"created":"2023-01-03","title":"GRB minimum variability timescale with Insight-HXMT and Swift: implications for progenitor models, dissipation physics and GRB classifications","abstract":"The dissipation process of GRB prompt emission is still unknown. Study of temporal variability may provide a unique way to discriminate the imprint of the inner engine activity from geometry and propagation related effects. We define the minimum variability timescale (MVT) as the shortest duration of individual pulses that shape a light curve for a sample of GRBs and test correlations with peak luminosity, Lorentz factor, and jet opening angle. We compare these correlations with predictions from recent numerical simulations for a relativistic structured -- possibly wobbling -- jet and assess the value of MTV as probe of prompt-emission physics. We used the peak detection algorithm mepsa to identify the shortest pulse within a GRB time history and estimate its full width half maximum (FWHM). We applied this framework to two sets of GRBs: Swift (from 2005 to July 2022) and Insight-HXMT (from June 2017 to July 2021, including 221009A). We then selected 401 GRBs with measured z to test for correlations. On average short GRBs have significantly shorter MVT than long GRBs. The MVT distribution of short GRBs with extended emission such as 060614 and 211211A is compatible only with that of short GRBs. This provides a new clue on the progenitor's nature. The MVT for long GRBs anticorrelates with peak luminosity. We confirm the anticorrelation with the Lorentz factor and find a correlation with the jet opening angle as estimated from the afterglow, along with an inverse correlation with the number of pulses. The MVT can identify the emerging putative new class of long GRBs that are suggested to be produced by compact binary mergers. For otherwise typical long GRBs, the different correlations between MVT and peak luminosity, Lorentz factor, jet opening angle, and number of pulses can be explained within the context of structured, possibly wobbling, weakly magnetised relativistic jets. (summarised)","sentences":["The dissipation process of GRB prompt emission is still unknown.","Study of temporal variability may provide a unique way to discriminate the imprint of the inner engine activity from geometry and propagation related effects.","We define the minimum variability timescale (MVT) as the shortest duration of individual pulses that shape a light curve for a sample of GRBs and test correlations with peak luminosity, Lorentz factor, and jet opening angle.","We compare these correlations with predictions from recent numerical simulations for a relativistic structured -- possibly wobbling -- jet and assess the value of MTV as probe of prompt-emission physics.","We used the peak detection algorithm mepsa to identify the shortest pulse within a GRB time history and estimate its full width half maximum (FWHM).","We applied this framework to two sets of GRBs: Swift (from 2005 to July 2022) and Insight-HXMT (from June 2017 to July 2021, including 221009A).","We then selected 401 GRBs with measured z to test for correlations.","On average short GRBs have significantly shorter MVT than long GRBs.","The MVT distribution of short GRBs with extended emission such as 060614 and 211211A is compatible only with that of short GRBs.","This provides a new clue on the progenitor's nature.","The MVT for long GRBs anticorrelates with peak luminosity.","We confirm the anticorrelation with the Lorentz factor and find a correlation with the jet opening angle as estimated from the afterglow, along with an inverse correlation with the number of pulses.","The MVT can identify the emerging putative new class of long GRBs that are suggested to be produced by compact binary mergers.","For otherwise typical long GRBs, the different correlations between MVT and peak luminosity, Lorentz factor, jet opening angle, and number of pulses can be explained within the context of structured, possibly wobbling, weakly magnetised relativistic jets.","(summarised)"],"url":"http://arxiv.org/abs/2301.01176v1"}
{"created":"2023-04-06","title":"When do you need Chain-of-Thought Prompting for ChatGPT?","abstract":"Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs). For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%. However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks. Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so. Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs. In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT. Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage.","sentences":["Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs).","For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%.","However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT.","Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks.","Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so.","Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs.","In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT.","Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage."],"url":"http://arxiv.org/abs/2304.03262v1"}
{"created":"2023-04-06","title":"Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media","abstract":"Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.","sentences":["Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media.","Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models.","However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges.","The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative.","This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges."],"url":"http://arxiv.org/abs/2304.03087v1"}
{"created":"2023-04-06","title":"Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions","abstract":"Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.","sentences":["Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users.","In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world.","Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.","Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing."],"url":"http://arxiv.org/abs/2304.02868v1"}
{"created":"2023-04-06","title":"GPT detectors are biased against non-native English writers","abstract":"The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse.","sentences":["The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content.","Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored.","In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers.","Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified.","Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions.","Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse."],"url":"http://arxiv.org/abs/2304.02819v1"}
{"created":"2023-04-06","title":"Opportunities and challenges of ChatGPT for design knowledge management","abstract":"Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information. However, integrating ChatGPT into the design process also presents new challenges. In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge. We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions. A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt.","sentences":["Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information.","However, integrating ChatGPT into the design process also presents new challenges.","In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge.","We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions.","A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt."],"url":"http://arxiv.org/abs/2304.02796v1"}
{"created":"2023-04-05","title":"Revolutionizing Single Cell Analysis: The Power of Large Language Models for Cell Type Annotation","abstract":"In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function. However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function. The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types. This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation. By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked. This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences. Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis.","sentences":["In recent years, single cell RNA sequencing has become a widely used technique to study cellular diversity and function.","However, accurately annotating cell types from single cell data has been a challenging task, as it requires extensive knowledge of cell biology and gene function.","The emergence of large language models such as ChatGPT and New Bing in 2023 has revolutionized this process by integrating the scientific literature and providing accurate annotations of cell types.","This breakthrough enables researchers to conduct literature reviews more efficiently and accurately, and can potentially uncover new insights into cell type annotation.","By using ChatGPT to annotate single cell data, we can relate rare cell type to their function and reveal specific differentiation trajectories of cell subtypes that were previously overlooked.","This can have important applications in understanding cancer progression, mammalian development, and stem cell differentiation, and can potentially lead to the discovery of key cells that interrupt the differentiation pathway and solve key problems in the life sciences.","Overall, the future of cell type annotation in single cell data looks promising and the Large Language model will be an important milestone in the history of single cell analysis."],"url":"http://arxiv.org/abs/2304.02697v1"}
{"created":"2023-04-05","title":"Human-like Summarization Evaluation with ChatGPT","abstract":"Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory. In this study, we explored ChatGPT's ability to perform human-like summarization evaluation using four human evaluation methods on five datasets. We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation. Additionally, it outperformed commonly used automatic evaluation metrics on some datasets. Furthermore, we discussed the impact of different prompts, compared its performance with that of human evaluation, and analyzed the generated explanations and invalid responses.","sentences":["Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory.","In this study, we explored ChatGPT's ability to perform human-like summarization evaluation using four human evaluation methods on five datasets.","We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation.","Additionally, it outperformed commonly used automatic evaluation metrics on some datasets.","Furthermore, we discussed the impact of different prompts, compared its performance with that of human evaluation, and analyzed the generated explanations and invalid responses."],"url":"http://arxiv.org/abs/2304.02554v1"}
{"created":"2023-04-05","title":"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification","abstract":"Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy. The simple BoW model performed on par with the most complex LLM prompting. Prompt engineering required significant investment.","sentences":["Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications.","This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering.","Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning.","The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice.","The second task is causal relation detection from the biomedical literature.","We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models.","Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy.","The simple BoW model performed on par with the most complex LLM prompting.","Prompt engineering required significant investment."],"url":"http://arxiv.org/abs/2304.02496v1"}
{"created":"2023-04-05","title":"ParroT: Translating During Chat Using Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human. Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning. Codes: https://github.com/wxjiao/ParroT","sentences":["Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat.","However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field.","Therefore, we propose the $\\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data.","Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process.","Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction.","Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to a further improvement, which demonstrates the importance of learning from low-quality translations annotated by human.","Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning.","Codes: https://github.com/wxjiao/ParroT"],"url":"http://arxiv.org/abs/2304.02426v2"}
{"created":"2023-04-05","title":"Document-Level Machine Translation with Large Language Models","abstract":"Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks. Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling. The study fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of Chat-GPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and examine the impact of training techniques on discourse modeling. By evaluating a number of benchmarks, we surprisingly find that 1) leveraging their powerful long-text mod-eling capabilities, ChatGPT outperforms commercial MT systems in terms of human evaluation. 2) GPT-4 demonstrates a strong ability to explain discourse knowledge, even through it may select incorrect translation candidates in contrastive testing. 3) ChatGPT and GPT-4 have demonstrated superior performance and show potential to become a new and promising paradigm for document-level translation. This work highlights the challenges and opportunities of discourse modeling for LLMs, which we hope can inspire the future design and evaluation of LLMs.","sentences":["Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks.","Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling.","The study fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of Chat-GPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and examine the impact of training techniques on discourse modeling.","By evaluating a number of benchmarks, we surprisingly find that 1) leveraging their powerful long-text mod-eling capabilities, ChatGPT outperforms commercial MT systems in terms of human evaluation.","2) GPT-4 demonstrates a strong ability to explain discourse knowledge, even through it may select incorrect translation candidates in contrastive testing.","3) ChatGPT and GPT-4 have demonstrated superior performance and show potential to become a new and promising paradigm for document-level translation.","This work highlights the challenges and opportunities of discourse modeling for LLMs, which we hope can inspire the future design and evaluation of LLMs."],"url":"http://arxiv.org/abs/2304.02210v1"}
{"created":"2023-04-05","title":"Unleashing the Power of ChatGPT for Translation: An Empirical Study","abstract":"The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation. Machine translation is an important and extensively studied task in the field of natural language processing, which heavily relies on the abilities of language understanding and generation. Thus, in this paper, we explore how to assist machine translation with ChatGPT. We adopt several translation prompts on a wide range of translations. Our experimental results show that ChatGPT with designed translation prompts can achieve comparable or better performance over professional translation systems for high-resource language translations but lags behind significantly on low-resource translations. We further evaluate the translation quality using multiple references, and ChatGPT achieves superior performance compared to the professional systems. We also conduct experiments on domain-specific translations, the final results show that ChatGPT is able to comprehend the provided domain keyword and adjust accordingly to output proper translations. At last, we perform few-shot prompts that show consistent improvement across different base prompts. Our work provides empirical evidence that ChatGPT still has great potential in translations.","sentences":["The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.","Machine translation is an important and extensively studied task in the field of natural language processing, which heavily relies on the abilities of language understanding and generation.","Thus, in this paper, we explore how to assist machine translation with ChatGPT.","We adopt several translation prompts on a wide range of translations.","Our experimental results show that ChatGPT with designed translation prompts can achieve comparable or better performance over professional translation systems for high-resource language translations but lags behind significantly on low-resource translations.","We further evaluate the translation quality using multiple references, and ChatGPT achieves superior performance compared to the professional systems.","We also conduct experiments on domain-specific translations, the final results show that ChatGPT is able to comprehend the provided domain keyword and adjust accordingly to output proper translations.","At last, we perform few-shot prompts that show consistent improvement across different base prompts.","Our work provides empirical evidence that ChatGPT still has great potential in translations."],"url":"http://arxiv.org/abs/2304.02182v1"}
{"created":"2023-04-04","title":"Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications","abstract":"The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionized various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.","sentences":["The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionized various industries, including geotechnical engineering.","However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations.","In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications.","We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses.","Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design.","We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis.","By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future."],"url":"http://arxiv.org/abs/2304.02138v1"}
{"created":"2023-04-04","title":"Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT","abstract":"Deep Learning (DL) library bugs affect downstream DL applications, emphasizing the need for reliable systems. Generating valid input programs for fuzzing DL libraries is challenging due to the need for satisfying both language syntax/semantics and constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the constraints to generate valid DL programs for fuzzing. However, LLMs tend to generate ordinary programs following similar patterns seen in their massive training corpora, while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.   To fill this gap, this paper proposes FuzzGPT, the first technique to prime LLMs to synthesize unusual programs for fuzzing. FuzzGPT is built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Traditional techniques leveraging such historical information require intensive human efforts to design dedicated generators and ensure the validity of generated programs. FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruct-following capability of the recent ChatGPT for effective fuzzing. Evaluation on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.","sentences":["Deep Learning (DL) library bugs affect downstream DL applications, emphasizing the need for reliable systems.","Generating valid input programs for fuzzing DL libraries is challenging due to the need for satisfying both language syntax/semantics and constraints for constructing valid computational graphs.","Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the constraints to generate valid DL programs for fuzzing.","However, LLMs tend to generate ordinary programs following similar patterns seen in their massive training corpora, while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.   ","To fill this gap, this paper proposes FuzzGPT, the first technique to prime LLMs to synthesize unusual programs for fuzzing.","FuzzGPT is built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding.","Traditional techniques leveraging such historical information require intensive human efforts to design dedicated generators and ensure the validity of generated programs.","FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains.","While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen.","Moreover, FuzzGPT also shows the potential of directly leveraging the instruct-following capability of the recent ChatGPT for effective fuzzing.","Evaluation on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities."],"url":"http://arxiv.org/abs/2304.02014v1"}
{"created":"2023-04-04","title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models","abstract":"The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance. To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks. The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA. The framework is designed to be research-friendly, efficient, modular, and extendable, allowing the integration of new adapters and the evaluation of them with new and larger-scale LLMs. Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we conduct experiments on six math reasoning datasets. The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning datasets. Overall, we provide a promising framework for fine-tuning large LLMs on downstream tasks. We believe the proposed LLMs-Adapters will advance adapter-based PEFT research, facilitate the deployment of research pipelines, and enable practical applications to real-world systems.","sentences":["The success of large language models (LLMs), like GPT-3 and ChatGPT, has led to the development of numerous cost-effective and accessible alternatives that are created by fine-tuning open-access LLMs with task-specific data (e.g., ChatDoctor) or instruction data (e.g., Alpaca).","Among the various fine-tuning methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly one of the most attractive topics, as it only requires fine-tuning a few external parameters instead of the entire LLMs while achieving comparable or even better performance.","To enable further research on PEFT methods of LLMs, this paper presents LLM-Adapters, an easy-to-use framework that integrates various adapters into LLMs and can execute these adapter-based PEFT methods of LLMs for different tasks.","The framework includes state-of-the-art open-access LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such as Series adapter, Parallel adapter, and LoRA.","The framework is designed to be research-friendly, efficient, modular, and extendable, allowing the integration of new adapters and the evaluation of them with new and larger-scale LLMs.","Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we conduct experiments on six math reasoning datasets.","The results demonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra trainable parameters yields comparable, and in some cases superior, performance to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning datasets.","Overall, we provide a promising framework for fine-tuning large LLMs on downstream tasks.","We believe the proposed LLMs-Adapters will advance adapter-based PEFT research, facilitate the deployment of research pipelines, and enable practical applications to real-world systems."],"url":"http://arxiv.org/abs/2304.01933v1"}
{"created":"2023-04-04","title":"Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models","abstract":"This paper presents a comprehensive survey of ChatGPT and GPT-4, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT/GPT-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.","sentences":["This paper presents a comprehensive survey of ChatGPT and GPT-4, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains.","Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance.","We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains.","The findings reveal a significant and increasing interest in ChatGPT/GPT-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics.","This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field."],"url":"http://arxiv.org/abs/2304.01852v1"}
{"created":"2023-04-04","title":"Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems","abstract":"For a natural language problem that requires some non-trivial reasoning to solve, there are at least two ways to do it using a large language model (LLM). One is to ask it to solve it directly. The other is to use it to extract the facts from the problem text and then use a theorem prover to solve it. In this note, we compare the two methods using ChatGPT and GPT4 on a series of logic word puzzles, and conclude that the latter is the right approach.","sentences":["For a natural language problem that requires some non-trivial reasoning to solve, there are at least two ways to do it using a large language model (LLM).","One is to ask it to solve it directly.","The other is to use it to extract the facts from the problem text and then use a theorem prover to solve it.","In this note, we compare the two methods using ChatGPT and GPT4 on a series of logic word puzzles, and conclude that the latter is the right approach."],"url":"http://arxiv.org/abs/2304.01771v1"}
{"created":"2023-04-04","title":"Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation","abstract":"ChatGPT, a large-scale language model based on the advanced GPT-3.5 architecture, has shown remarkable potential in various Natural Language Processing (NLP) tasks. However, there is currently a dearth of comprehensive study exploring its potential in the area of Grammatical Error Correction (GEC). To showcase its capabilities in GEC, we design zero-shot chain-of-thought (CoT) and few-shot CoT settings using in-context learning for ChatGPT. Our evaluation involves assessing ChatGPT's performance on five official test sets in three different languages, along with three document-level GEC test sets in English. Our experimental results and human evaluations demonstrate that ChatGPT has excellent error detection capabilities and can freely correct errors to make the corrected sentences very fluent, possibly due to its over-correction tendencies and not adhering to the principle of minimal edits. Additionally, its performance in non-English and low-resource settings highlights its potential in multilingual GEC tasks. However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors.","sentences":["ChatGPT, a large-scale language model based on the advanced GPT-3.5 architecture, has shown remarkable potential in various Natural Language Processing (NLP) tasks.","However, there is currently a dearth of comprehensive study exploring its potential in the area of Grammatical Error Correction (GEC).","To showcase its capabilities in GEC, we design zero-shot chain-of-thought (CoT) and few-shot CoT settings using in-context learning for ChatGPT.","Our evaluation involves assessing ChatGPT's performance on five official test sets in three different languages, along with three document-level GEC test sets in English.","Our experimental results and human evaluations demonstrate that ChatGPT has excellent error detection capabilities and can freely correct errors to make the corrected sentences very fluent, possibly due to its over-correction tendencies and not adhering to the principle of minimal edits.","Additionally, its performance in non-English and low-resource settings highlights its potential in multilingual GEC tasks.","However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors."],"url":"http://arxiv.org/abs/2304.01746v1"}
{"created":"2023-04-04","title":"To ChatGPT, or not to ChatGPT: That is the question!","abstract":"ChatGPT has become a global sensation. As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud. Hence, distinguishing AI-generated from human-generated becomes increasingly essential. Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models. Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy. The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection. Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content. For our evaluation, we have curated a benchmark dataset consisting of prompts from ChatGPT and humans, including diverse questions from medical, open Q&A, and finance domains and user-generated responses from popular social networking platforms. The dataset serves as a reference to assess the performance of various techniques in detecting ChatGPT-generated content. Our evaluation results demonstrate that none of the existing methods can effectively detect ChatGPT-generated content.","sentences":["ChatGPT has become a global sensation.","As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud.","Hence, distinguishing AI-generated from human-generated becomes increasingly essential.","Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models.","Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy.","The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection.","Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content.","For our evaluation, we have curated a benchmark dataset consisting of prompts from ChatGPT and humans, including diverse questions from medical, open Q&A, and finance domains and user-generated responses from popular social networking platforms.","The dataset serves as a reference to assess the performance of various techniques in detecting ChatGPT-generated content.","Our evaluation results demonstrate that none of the existing methods can effectively detect ChatGPT-generated content."],"url":"http://arxiv.org/abs/2304.01487v2"}
{"created":"2023-04-04","title":"Blockwise Compression of Transformer-based Models without Retraining","abstract":"Transformer-based models, represented by GPT-3, ChatGPT, and GPT-4, have recently attracted increasing interest, research enthusiasm, and business demand. However, their massive computation resources and huge memory footprint are inevitable challenges. To tackle this issue, we propose BCT, a framework of blockwise compression for transformers without retraining, to lower deployment thresholds. BCT achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, Softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient model with BCT and evaluate it on several General Language Understanding Evaluation (GLUE) datasets. The results show that BCT can achieve a less than 0.90% accuracy drop in most tasks.","sentences":["Transformer-based models, represented by GPT-3, ChatGPT, and GPT-4, have recently attracted increasing interest, research enthusiasm, and business demand.","However, their massive computation resources and huge memory footprint are inevitable challenges.","To tackle this issue, we propose BCT, a framework of blockwise compression for transformers without retraining, to lower deployment thresholds.","BCT achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, Softmax, layer normalization, and all the intermediate results.","As a case, we compress an efficient model with BCT and evaluate it on several General Language Understanding Evaluation (GLUE) datasets.","The results show that BCT can achieve a less than 0.90% accuracy drop in most tasks."],"url":"http://arxiv.org/abs/2304.01483v1"}
{"created":"2023-04-04","title":"Integrating Commercial and Social Determinants of Health: A Unified Ontology for Non-Clinical Determinants of Health","abstract":"The objectives of this research are 1) to develop an ontology for CDoH by utilizing PubMed articles and ChatGPT; 2) to foster ontology reuse by integrating CDoH with an existing SDoH ontology into a unified structure; 3) to devise an overarching conception for all non-clinical determinants of health and to create an initial ontology, called N-CODH, for them; 4) and to validate the degree of correspondence between concepts provided by ChatGPT with the existing SDoH ontology","sentences":["The objectives of this research are 1) to develop an ontology for CDoH by utilizing PubMed articles and ChatGPT; 2) to foster ontology reuse by integrating CDoH with an existing SDoH ontology into a unified structure; 3) to devise an overarching conception for all non-clinical determinants of health and to create an initial ontology, called N-CODH, for them; 4) and to validate the degree of correspondence between concepts provided by ChatGPT with the existing SDoH ontology"],"url":"http://arxiv.org/abs/2304.01446v1"}
{"created":"2023-04-03","title":"On the Prime Number Divisibility by Deep Learning","abstract":"Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms. In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers. It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models. We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided. We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success. Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes. We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs).","sentences":["Certain tasks such as determining whether a given integer can be divided by 2, 3, or other prime numbers may be trivial for human beings, but can be less straightforward for computers in the absence of pre-specified algorithms.","In this paper, we tested multiple deep learning architectures and feature engineering approaches, and evaluated the scenario of determining divisibility of large finite integers (up to $2^{32}$) by small prime numbers.","It turns out that, regardless of the network frameworks or the complexity of the network structures (CNN, RNN, Transformer, etc.), the ability to predict the prime number divisibility critically depends on the feature space fed into the deep learning models.","We also evaluated commercially available Automated Machine Learning (AutoML) pipelines from Amazon, Google and Microsoft, and demonstrated that they failed to address this issue unless appropriately engineered features were provided.","We further proposed a closed form solution to the problem using the ordinary linear regression on Fourier series basis vectors, and showed its success.","Finally, we evaluated prompt-based learning using ChatGPT and demonstrated its success on small primes and apparent failures on larger primes.","We conclude that feature engineering remains an important task to improve the performance, increase the interpretability, and reduce the complexity of machine learning/deep learning models, even in the era of AutoML and large-language models (LLMs)."],"url":"http://arxiv.org/abs/2304.01333v1"}
{"created":"2023-04-03","title":"Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data","abstract":"Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize. An online demo is also available at https://huggingface.co/spaces/project-baize/baize-lora-7B.","sentences":["Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains.","However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field.","We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself.","Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model.","The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks.","The Baize models and data are released for research purposes only at https://github.com/project-baize/baize.","An online demo is also available at https://huggingface.co/spaces/project-baize/baize-lora-7B."],"url":"http://arxiv.org/abs/2304.01196v2"}
{"created":"2023-04-03","title":"Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT","abstract":"Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human experts' intervention can be inadequate due to reliability and accuracy issues of LLMs; (ii) more interactions between ChatGPT and human experts may yield better results; and (iii) using ChatGPT in STPA with extra care can outperform human safety experts alone, as demonstrated by reusing an existing comparison method with baselines. In addition to making the first attempt to apply LLMs in safety analysis, this paper also identifies key challenges (e.g., trustworthiness concern of LLMs, the need of standardisation) for future research in this direction.","sentences":["Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge.","While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs?","To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT.","STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address.","Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction.","Comparative results reveal that: (i) using ChatGPT without human experts' intervention can be inadequate due to reliability and accuracy issues of LLMs; (ii) more interactions between ChatGPT and human experts may yield better results; and (iii) using ChatGPT in STPA with extra care can outperform human safety experts alone, as demonstrated by reusing an existing comparison method with baselines.","In addition to making the first attempt to apply LLMs in safety analysis, this paper also identifies key challenges (e.g., trustworthiness concern of LLMs, the need of standardisation) for future research in this direction."],"url":"http://arxiv.org/abs/2304.01246v1"}
{"created":"2023-04-03","title":"DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task","abstract":"The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable. Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice. Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs. To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM. Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable. DoctorGLM is currently an early-stage engineering attempt and contain various mistakes. We are sharing it with the broader community to invite feedback and suggestions to improve its healthcare-focused capabilities: https://github.com/xionghonglin/DoctorGLM.","sentences":["The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable.","Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice.","Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs.","To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM.","Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable.","DoctorGLM is currently an early-stage engineering attempt and contain various mistakes.","We are sharing it with the broader community to invite feedback and suggestions to improve its healthcare-focused capabilities: https://github.com/xionghonglin/DoctorGLM."],"url":"http://arxiv.org/abs/2304.01097v1"}
{"created":"2023-04-03","title":"Understanding Individual and Team-based Human Factors in Detecting Deepfake Texts","abstract":"In recent years, Natural Language Generation (NLG) techniques in AI (e.g., T5, GPT-3, ChatGPT) have shown a massive improvement and are now capable of generating human-like long coherent texts at scale, yielding so-called deepfake texts. This advancement, despite their benefits, can also cause security and privacy issues (e.g., plagiarism, identity obfuscation, disinformation attack). As such, it has become critically important to develop effective, practical, and scalable solutions to differentiate deepfake texts from human-written texts. Toward this challenge, in this work, we investigate how factors such as skill levels and collaborations impact how humans identify deepfake texts, studying three research questions: (1) do collaborative teams detect deepfake texts better than individuals? (2) do expert humans detect deepfake texts better than non-expert humans? (3) what are the factors that maximize the detection performance of humans? We implement these questions on two platforms: (1) non-expert humans or asynchronous teams on Amazon Mechanical Turk (AMT) and (2) expert humans or synchronous teams on the Upwork. By analyzing the detection performance and the factors that affected performance, some of our key findings are: (1) expert humans detect deepfake texts significantly better than non-expert humans, (2) synchronous teams on the Upwork detect deepfake texts significantly better than individuals, while asynchronous teams on the AMT detect deepfake texts weakly better than individuals, and (3) among various error categories, examining coherence and consistency in texts is useful in detecting deepfake texts. In conclusion, our work could inform the design of future tools/framework to improve collaborative human detection of deepfake texts.","sentences":["In recent years, Natural Language Generation (NLG) techniques in AI (e.g., T5, GPT-3, ChatGPT) have shown a massive improvement and are now capable of generating human-like long coherent texts at scale, yielding so-called deepfake texts.","This advancement, despite their benefits, can also cause security and privacy issues (e.g., plagiarism, identity obfuscation, disinformation attack).","As such, it has become critically important to develop effective, practical, and scalable solutions to differentiate deepfake texts from human-written texts.","Toward this challenge, in this work, we investigate how factors such as skill levels and collaborations impact how humans identify deepfake texts, studying three research questions: (1) do collaborative teams detect deepfake texts better than individuals?","(2) do expert humans detect deepfake texts better than non-expert humans?","(3) what are the factors that maximize the detection performance of humans?","We implement these questions on two platforms: (1) non-expert humans or asynchronous teams on Amazon Mechanical Turk (AMT) and (2) expert humans or synchronous teams on the Upwork.","By analyzing the detection performance and the factors that affected performance, some of our key findings are: (1) expert humans detect deepfake texts significantly better than non-expert humans, (2) synchronous teams on the Upwork detect deepfake texts significantly better than individuals, while asynchronous teams on the AMT detect deepfake texts weakly better than individuals, and (3) among various error categories, examining coherence and consistency in texts is useful in detecting deepfake texts.","In conclusion, our work could inform the design of future tools/framework to improve collaborative human detection of deepfake texts."],"url":"http://arxiv.org/abs/2304.01002v1"}
{"created":"2023-04-03","title":"Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study","abstract":"Evaluating the quality of generated text is a challenging task in natural language processing. This difficulty arises from the inherent complexity and diversity of text. Recently, OpenAI's ChatGPT, a powerful large language model (LLM), has garnered significant attention due to its impressive performance in various tasks. Therefore, we present this report to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality. We compared three kinds of reference-free evaluation methods based on ChatGPT or similar LLMs. The experimental results prove that ChatGPT is capable to evaluate text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics. In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches. However, directly comparing the quality of two texts using ChatGPT may lead to suboptimal results. We hope this report will provide valuable insights into selecting appropriate methods for evaluating text quality with LLMs such as ChatGPT.","sentences":["Evaluating the quality of generated text is a challenging task in natural language processing.","This difficulty arises from the inherent complexity and diversity of text.","Recently, OpenAI's ChatGPT, a powerful large language model (LLM), has garnered significant attention due to its impressive performance in various tasks.","Therefore, we present this report to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality.","We compared three kinds of reference-free evaluation methods based on ChatGPT or similar LLMs.","The experimental results prove that ChatGPT is capable to evaluate text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics.","In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches.","However, directly comparing the quality of two texts using ChatGPT may lead to suboptimal results.","We hope this report will provide valuable insights into selecting appropriate methods for evaluating text quality with LLMs such as ChatGPT."],"url":"http://arxiv.org/abs/2304.00723v1"}
{"created":"2023-04-02","title":"LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models","abstract":"Large Language Models (LLMs) have revolutionized natural language processing and demonstrated impressive capabilities in various tasks. Unfortunately, they are prone to hallucinations, where the model exposes incorrect or false information in its responses, which renders diligent evaluation approaches mandatory. While LLM performance in specific knowledge fields is often evaluated based on question and answer (Q&A) datasets, such evaluations usually report only a single accuracy number for the entire field, a procedure which is problematic with respect to transparency and model improvement. A stratified evaluation could instead reveal subfields, where hallucinations are more likely to occur and thus help to better assess LLMs' risks and guide their further development. To support such stratified evaluations, we propose LLMMaps as a novel visualization technique that enables users to evaluate LLMs' performance with respect to Q&A datasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities in different subfields, by transforming Q&A datasets as well as LLM responses into our internal knowledge structure. An extension for comparative visualization furthermore, allows for the detailed comparison of multiple LLMs. To assess LLMMaps we use them to conduct a comparative analysis of several state-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as well as two qualitative user evaluations. All necessary source code and data for generating LLMMaps to be used in scientific publications and elsewhere will be available on GitHub.","sentences":["Large Language Models (LLMs) have revolutionized natural language processing and demonstrated impressive capabilities in various tasks.","Unfortunately, they are prone to hallucinations, where the model exposes incorrect or false information in its responses, which renders diligent evaluation approaches mandatory.","While LLM performance in specific knowledge fields is often evaluated based on question and answer (Q&A) datasets, such evaluations usually report only a single accuracy number for the entire field, a procedure which is problematic with respect to transparency and model improvement.","A stratified evaluation could instead reveal subfields, where hallucinations are more likely to occur and thus help to better assess LLMs' risks and guide their further development.","To support such stratified evaluations, we propose LLMMaps as a novel visualization technique that enables users to evaluate LLMs' performance with respect to Q&A datasets.","LLMMaps provide detailed insights into LLMs' knowledge capabilities in different subfields, by transforming Q&A datasets as well as LLM responses into our internal knowledge structure.","An extension for comparative visualization furthermore, allows for the detailed comparison of multiple LLMs.","To assess LLMMaps we use them to conduct a comparative analysis of several state-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as well as two qualitative user evaluations.","All necessary source code and data for generating LLMMaps to be used in scientific publications and elsewhere will be available on GitHub."],"url":"http://arxiv.org/abs/2304.00457v1"}
{"created":"2023-04-01","title":"Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT","abstract":"Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches. While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards. This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same mistakes. For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT. By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!","sentences":["Automated Program Repair (APR) aims to automatically generate patches for buggy programs.","Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR.","Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches.","While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards.","This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.   ","To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style.","ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR.","For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch.","In this way, we can avoid making the same mistakes.","For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches.","In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches.","While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM -- ChatGPT.","By calculating the cost of accessing ChatGPT, we can fix 162 out of 337 bugs for \\$0.42 each!"],"url":"http://arxiv.org/abs/2304.00385v1"}
{"created":"2023-04-01","title":"Network Visualization of ChatGPT Research: a study based on term and keyword co-occurrence network analysis","abstract":"The main objective of this paper is to identify the major research areas of ChatGPT through term and keyword co-occurrence network mapping techniques. For conducting the present study, total of 577 publications were retrieved from the Lens database for the network visualization. The findings of the study showed that chatgpt occurrence in maximum number of times followed by its related terms such as artificial intelligence, large language model, gpt, study etc. This study will be helpful to library and information science as well as computer or information technology professionals.","sentences":["The main objective of this paper is to identify the major research areas of ChatGPT through term and keyword co-occurrence network mapping techniques.","For conducting the present study, total of 577 publications were retrieved from the Lens database for the network visualization.","The findings of the study showed that chatgpt occurrence in maximum number of times followed by its related terms such as artificial intelligence, large language model, gpt, study etc.","This study will be helpful to library and information science as well as computer or information technology professionals."],"url":"http://arxiv.org/abs/2304.01948v1"}
{"created":"2023-04-01","title":"Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics","abstract":"We present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs. We developed an exam consisting of 100 radiation oncology physics questions based on our expertise at Mayo Clinic. Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts. ChatGPT (GPT-4) outperformed all other LLMs as well as medical physicists, on average. The performance of ChatGPT (GPT-4) was further improved when prompted to explain first, then answer. ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups. In evaluating ChatGPTs (GPT-4) deductive reasoning ability using a novel approach (substituting the correct answer with \"None of the above choices is the correct answer.\"), ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability. Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote. This study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants.","sentences":["We present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions.","Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs.","This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs.","We developed an exam consisting of 100 radiation oncology physics questions based on our expertise at Mayo Clinic.","Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts.","ChatGPT (GPT-4) outperformed all other LLMs as well as medical physicists, on average.","The performance of ChatGPT (GPT-4) was further improved when prompted to explain first, then answer.","ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups.","In evaluating ChatGPTs (GPT-4) deductive reasoning ability using a novel approach (substituting the correct answer with \"None of the above choices is the correct answer.\"), ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability.","Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials.","In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote.","This study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants."],"url":"http://arxiv.org/abs/2304.01938v1"}
{"created":"2023-04-01","title":"Large language models can rate news outlet credibility","abstract":"Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations. State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers. In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users. Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets. With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations. Our results show that these ratings correlate with those from human experts (Spearmam's $\\rho=0.54, p<0.001$). These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications. Future LLMs should enhance their alignment with human expert judgments of source credibility to improve information accuracy.","sentences":["Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations.","State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers.","In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users.","Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets.","With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations.","Our results show that these ratings correlate with those from human experts (Spearmam's $\\rho=0.54, p<0.001$).","These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications.","Future LLMs should enhance their alignment with human expert judgments of source credibility to improve information accuracy."],"url":"http://arxiv.org/abs/2304.00228v1"}
{"created":"2023-03-31","title":"A Survey of Large Language Models","abstract":"Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.","sentences":["Language is essentially a complex, intricate system of human expressions governed by grammatical rules.","It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language.","As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models.","Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks.","Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size.","Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models.","To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.","Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society.","The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms.","In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques.","In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation.","Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions."],"url":"http://arxiv.org/abs/2303.18223v1"}
{"created":"2023-03-31","title":"Pair Programming with Large Language Models for Sampling and Estimation of Copulas","abstract":"Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.","sentences":["Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations.","This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results.","In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI).","Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons.","It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner.","For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct.","Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques."],"url":"http://arxiv.org/abs/2303.18116v1"}
{"created":"2023-03-31","title":"Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations","abstract":"As large language models (LLMs) gain popularity among speakers of diverse languages, we believe that it is crucial to benchmark them to better understand model behaviors, failures, and limitations in languages beyond English. In this work, we evaluate LLM APIs (ChatGPT, GPT-3, and GPT-4) on the Japanese national medical licensing examinations from the past five years, including the current year. Our team comprises native Japanese-speaking NLP researchers and a practicing cardiologist based in Japan. Our experiments show that GPT-4 outperforms ChatGPT and GPT-3 and passes all six years of the exams, highlighting LLMs' potential in a language that is typologically distant from English. However, our evaluation also exposes critical limitations of the current LLM APIs. First, LLMs sometimes select prohibited choices that should be strictly avoided in medical practice in Japan, such as suggesting euthanasia. Further, our analysis shows that the API costs are generally higher and the maximum context size is smaller for Japanese because of the way non-Latin scripts are currently tokenized in the pipeline. We release our benchmark as Igaku QA as well as all model outputs and exam metadata. We hope that our results and benchmark will spur progress on more diverse applications of LLMs. Our benchmark is available at https://github.com/jungokasai/IgakuQA.","sentences":["As large language models (LLMs) gain popularity among speakers of diverse languages, we believe that it is crucial to benchmark them to better understand model behaviors, failures, and limitations in languages beyond English.","In this work, we evaluate LLM APIs (ChatGPT, GPT-3, and GPT-4) on the Japanese national medical licensing examinations from the past five years, including the current year.","Our team comprises native Japanese-speaking NLP researchers and a practicing cardiologist based in Japan.","Our experiments show that GPT-4 outperforms ChatGPT and GPT-3 and passes all six years of the exams, highlighting LLMs' potential in a language that is typologically distant from English.","However, our evaluation also exposes critical limitations of the current LLM APIs.","First, LLMs sometimes select prohibited choices that should be strictly avoided in medical practice in Japan, such as suggesting euthanasia.","Further, our analysis shows that the API costs are generally higher and the maximum context size is smaller for Japanese because of the way non-Latin scripts are currently tokenized in the pipeline.","We release our benchmark as Igaku QA as well as all model outputs and exam metadata.","We hope that our results and benchmark will spur progress on more diverse applications of LLMs.","Our benchmark is available at https://github.com/jungokasai/IgakuQA."],"url":"http://arxiv.org/abs/2303.18027v2"}
{"created":"2023-03-31","title":"Can AI Put Gamma-Ray Astrophysicists Out of a Job?","abstract":"In what will likely be a litany of generative-model-themed arXiv submissions celebrating April the 1st, we evaluate the capacity of state-of-the-art transformer models to create a paper detailing the detection of a Pulsar Wind Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT) Array. We do this to evaluate the ability of such models to interpret astronomical observations and sources based on language information alone, and to assess potential means by which fraudulently generated scientific papers could be identified during peer review (given that reliable generative model watermarking has yet to be deployed for these tools). We conclude that our jobs as astronomers are safe for the time being. From this point on, prompts given to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT is shown in black, whereas analysis by the (human) authors is in blue.","sentences":["In what will likely be a litany of generative-model-themed arXiv submissions celebrating April the 1st, we evaluate the capacity of state-of-the-art transformer models to create a paper detailing the detection of a Pulsar Wind Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT) Array.","We do this to evaluate the ability of such models to interpret astronomical observations and sources based on language information alone, and to assess potential means by which fraudulently generated scientific papers could be identified during peer review (given that reliable generative model watermarking has yet to be deployed for these tools).","We conclude that our jobs as astronomers are safe for the time being.","From this point on, prompts given to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT is shown in black, whereas analysis by the (human) authors is in blue."],"url":"http://arxiv.org/abs/2303.17853v2"}
{"created":"2023-03-30","title":"Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms","abstract":"Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities. Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist. To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers. We also build automatic text classifiers to detect ChatGPT generated summaries. We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT.","sentences":["Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks.","ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities.","Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist.","To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers.","We also build automatic text classifiers to detect ChatGPT generated summaries.","We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT."],"url":"http://arxiv.org/abs/2303.17650v1"}
{"created":"2023-03-30","title":"ChatGPT scores a bad birdie in counting gravitational-wave chirps","abstract":"How many gravitational-wave observations from compact object mergers have we seen to date? This seemingly simple question has a surprisingly complex answer that even ChatGPT struggles to answer. To shed light on this, we present a database with the literature's answers to this question. We find values spanning 67-100 for the number of detections from double compact object mergers to date, emphasizing that the exact number of detections is uncertain and depends on the chosen data analysis pipeline and underlying assumptions. We also review the number of gravitational-wave detections expected in the coming decades with future observing runs, finding values up to millions of detections per year in the era of Cosmic Explorer and Einstein Telescope. We present a publicly available code to visualize the detection numbers, highlighting the exponential growth in gravitational-wave observations in the coming decades and the exciting prospects of gravitational-wave astrophysics. See http://www.broekgaarden.nl/floor/wordpress/elementor-967/. We plan to keep this database up-to-date and welcome comments and suggestions for additional references.","sentences":["How many gravitational-wave observations from compact object mergers have we seen to date?","This seemingly simple question has a surprisingly complex answer that even ChatGPT struggles to answer.","To shed light on this, we present a database with the literature's answers to this question.","We find values spanning 67-100 for the number of detections from double compact object mergers to date, emphasizing that the exact number of detections is uncertain and depends on the chosen data analysis pipeline and underlying assumptions.","We also review the number of gravitational-wave detections expected in the coming decades with future observing runs, finding values up to millions of detections per year in the era of Cosmic Explorer and Einstein Telescope.","We present a publicly available code to visualize the detection numbers, highlighting the exponential growth in gravitational-wave observations in the coming decades and the exciting prospects of gravitational-wave astrophysics.","See http://www.broekgaarden.nl/floor/wordpress/elementor-967/.","We plan to keep this database up-to-date and welcome comments and suggestions for additional references."],"url":"http://arxiv.org/abs/2303.17628v1"}
{"created":"2023-03-30","title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace","abstract":"Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence. While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artificial intelligence.","sentences":["Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence.","While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks.","Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this.","Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks.","Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results.","By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artificial intelligence."],"url":"http://arxiv.org/abs/2303.17580v2"}
{"created":"2023-03-30","title":"Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study","abstract":"The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue. Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation. In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences. Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts. Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture. This study provides valuable insights into the cultural implications of ChatGPT and highlights the necessity of greater diversity and cultural awareness in language technologies.","sentences":["The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue.","Given its usage by users from various nations and its training on a vast multilingual corpus that incorporates diverse cultural and societal norms, it is crucial to evaluate its effectiveness in cultural adaptation.","In this paper, we investigate the underlying cultural background of ChatGPT by analyzing its responses to questions designed to quantify human cultural differences.","Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts.","Furthermore, by using different prompts to probe the model, we show that English prompts reduce the variance in model responses, flattening out cultural differences and biasing them towards American culture.","This study provides valuable insights into the cultural implications of ChatGPT and highlights the necessity of greater diversity and cultural awareness in language technologies."],"url":"http://arxiv.org/abs/2303.17466v2"}
{"created":"2023-03-30","title":"WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research","abstract":"The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years. However, researchers face challenges due to the costly and time-consuming collection process of existing audio-language datasets, which are limited in size. To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audio-language multimodal learning tasks. The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin. Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing ChatGPT to enhance academic research. Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps.","sentences":["The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years.","However, researchers face challenges due to the costly and time-consuming collection process of existing audio-language datasets, which are limited in size.","To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions.","We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset.","However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning.","To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically.","We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audio-language multimodal learning tasks.","The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin.","Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing ChatGPT to enhance academic research.","Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps."],"url":"http://arxiv.org/abs/2303.17395v1"}
{"created":"2023-03-30","title":"Yes but.. Can ChatGPT Identify Entities in Historical Documents?","abstract":"Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents. For the last few months, the conversational agent ChatGPT has \"prompted\" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers. In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems. Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting. Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance.","sentences":["Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents.","For the last few months, the conversational agent ChatGPT has \"prompted\" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers.","In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems.","Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting.","Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance."],"url":"http://arxiv.org/abs/2303.17322v1"}
{"created":"2023-03-30","title":"Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed","abstract":"We investigated some difficulties that students often face when studying linear algebra at the undergraduate level, and identified some common mistakes and difficulties they often encountered when dealing with topics that require algorithmic thinking skills such as matrix factorization. In particular, we focused on (orthogonal) diagonalization and singular value decomposition (SVD). We also offered the possibility of exploring these topics using SageMath, a Python-based free open software computer algebra system (CAS) that has been identified to be useful for assisting many students in the computational process even though its output is static by nature. We then explored dynamic ChatGPT by inquiring the chatbot about the topic, either by asking to provide an example or to solve a problem, that is by constructing an (orthogonal) diagonalization or SVD from a particular matrix. By consolidating essential concepts in linear algebra and improving computational skills through effective practice, mastering these topics would become easier and mistakes could be minimized. Static SageMath, in particular, is a great aid for calculation confirmation and handling tedious computations. Although dynamic ChatGPT is relatively unreliable for solving problems in linear algebra, the mistakes it produces could become a valuable tool for improving critical thinking skills.","sentences":["We investigated some difficulties that students often face when studying linear algebra at the undergraduate level, and identified some common mistakes and difficulties they often encountered when dealing with topics that require algorithmic thinking skills such as matrix factorization.","In particular, we focused on (orthogonal) diagonalization and singular value decomposition (SVD).","We also offered the possibility of exploring these topics using SageMath, a Python-based free open software computer algebra system (CAS) that has been identified to be useful for assisting many students in the computational process even though its output is static by nature.","We then explored dynamic ChatGPT by inquiring the chatbot about the topic, either by asking to provide an example or to solve a problem, that is by constructing an (orthogonal) diagonalization or SVD from a particular matrix.","By consolidating essential concepts in linear algebra and improving computational skills through effective practice, mastering these topics would become easier and mistakes could be minimized.","Static SageMath, in particular, is a great aid for calculation confirmation and handling tedious computations.","Although dynamic ChatGPT is relatively unreliable for solving problems in linear algebra, the mistakes it produces could become a valuable tool for improving critical thinking skills."],"url":"http://arxiv.org/abs/2303.17163v1"}
{"created":"2023-03-30","title":"Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study","abstract":"With the phenomenal success of diffusion models and ChatGPT, deep generation models (DGMs) have been experiencing explosive growth from 2022. Not limited to content generation, DGMs are also widely adopted in Internet of Things, Metaverse, and digital twin, due to their outstanding ability to represent complex patterns and generate plausible samples. In this article, we explore the applications of DGMs in a crucial task, i.e., improving the efficiency of wireless network management. Specifically, we firstly overview the generative AI, as well as three representative DGMs. Then, a DGM-empowered framework for wireless network management is proposed, in which we elaborate the issues of the conventional network management approaches, why DGMs can address them efficiently, and the step-by-step workflow for applying DGMs in managing wireless networks. Moreover, we conduct a case study on network economics, using the state-of-the-art DGM model, i.e., diffusion model, to generate effective contracts for incentivizing the mobile AI-Generated Content (AIGC) services. Last but not least, we discuss important open directions for the further research.","sentences":["With the phenomenal success of diffusion models and ChatGPT, deep generation models (DGMs) have been experiencing explosive growth from 2022.","Not limited to content generation, DGMs are also widely adopted in Internet of Things, Metaverse, and digital twin, due to their outstanding ability to represent complex patterns and generate plausible samples.","In this article, we explore the applications of DGMs in a crucial task, i.e., improving the efficiency of wireless network management.","Specifically, we firstly overview the generative AI, as well as three representative DGMs.","Then, a DGM-empowered framework for wireless network management is proposed, in which we elaborate the issues of the conventional network management approaches, why DGMs can address them efficiently, and the step-by-step workflow for applying DGMs in managing wireless networks.","Moreover, we conduct a case study on network economics, using the state-of-the-art DGM model, i.e., diffusion model, to generate effective contracts for incentivizing the mobile AI-Generated Content (AIGC) services.","Last but not least, we discuss important open directions for the further research."],"url":"http://arxiv.org/abs/2303.17114v1"}
{"created":"2023-03-29","title":"Advances in apparent conceptual physics reasoning in GPT-4","abstract":"ChatGPT is built on a large language model trained on an enormous corpus of human text to emulate human conversation. Despite lacking any explicit programming regarding the laws of physics, recent work has demonstrated that GPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory. This work replicates those results and also demonstrates that the latest version, GPT-4, has reached a much higher mark in the latter context. Indeed, its responses come quite close to perfectly demonstrating expert-level competence, with a few very notable exceptions and limitations. We briefly comment on the implications of this for the future of physics education and pedagogy.","sentences":["ChatGPT is built on a large language model trained on an enormous corpus of human text to emulate human conversation.","Despite lacking any explicit programming regarding the laws of physics, recent work has demonstrated that GPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory.","This work replicates those results and also demonstrates that the latest version, GPT-4, has reached a much higher mark in the latter context.","Indeed, its responses come quite close to perfectly demonstrating expert-level competence, with a few very notable exceptions and limitations.","We briefly comment on the implications of this for the future of physics education and pedagogy."],"url":"http://arxiv.org/abs/2303.17012v2"}
{"created":"2023-03-29","title":"Questions of science: chatting with ChatGPT about complex systems","abstract":"We present an overview of the complex systems field using ChatGPT as a representation of the community's understanding. ChatGPT has learned language patterns and styles from a large dataset of internet texts, allowing it to provide answers that reflect common opinions, ideas, and language patterns found in the community. Our exploration covers both teaching and learning, and research topics. We recognize the value of ChatGPT as a source for the community's ideas.","sentences":["We present an overview of the complex systems field using ChatGPT as a representation of the community's understanding.","ChatGPT has learned language patterns and styles from a large dataset of internet texts, allowing it to provide answers that reflect common opinions, ideas, and language patterns found in the community.","Our exploration covers both teaching and learning, and research topics.","We recognize the value of ChatGPT as a source for the community's ideas."],"url":"http://arxiv.org/abs/2303.16870v1"}
{"created":"2023-03-29","title":"RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes","abstract":"Can foundation models (such as ChatGPT) clean your data? In this proposal, we demonstrate that indeed ChatGPT can assist in data cleaning by suggesting corrections for specific cells in a data table (scenario 1). However, ChatGPT may struggle with datasets it has never encountered before (e.g., local enterprise data) or when the user requires an explanation of the source of the suggested clean values. To address these issues, we developed a retrieval-based method that complements ChatGPT's power with a user-provided data lake. The data lake is first indexed, we then retrieve the top-k relevant tuples to the user's query tuple and finally leverage ChatGPT to infer the correct value (scenario 2). Nevertheless, sharing enterprise data with ChatGPT, an externally hosted model, might not be feasible for privacy reasons. To assist with this scenario, we developed a custom RoBERTa-based foundation model that can be locally deployed. By fine-tuning it on a small number of examples, it can effectively make value inferences based on the retrieved tuples (scenario 3). Our proposed system, RetClean, seamlessly supports all three scenarios and provides a user-friendly GUI that enables the VLDB audience to explore and experiment with the system.","sentences":["Can foundation models (such as ChatGPT) clean your data?","In this proposal, we demonstrate that indeed ChatGPT can assist in data cleaning by suggesting corrections for specific cells in a data table (scenario 1).","However, ChatGPT may struggle with datasets it has never encountered before (e.g., local enterprise data) or when the user requires an explanation of the source of the suggested clean values.","To address these issues, we developed a retrieval-based method that complements ChatGPT's power with a user-provided data lake.","The data lake is first indexed, we then retrieve the top-k relevant tuples to the user's query tuple and finally leverage ChatGPT to infer the correct value (scenario 2).","Nevertheless, sharing enterprise data with ChatGPT, an externally hosted model, might not be feasible for privacy reasons.","To assist with this scenario, we developed a custom RoBERTa-based foundation model that can be locally deployed.","By fine-tuning it on a small number of examples, it can effectively make value inferences based on the retrieved tuples (scenario 3).","Our proposed system, RetClean, seamlessly supports all three scenarios and provides a user-friendly GUI that enables the VLDB audience to explore and experiment with the system."],"url":"http://arxiv.org/abs/2303.16909v1"}
{"created":"2023-03-29","title":"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs","abstract":"Artificial Intelligence (AI) has made incredible progress recently. On the one hand, advanced foundation models like ChatGPT can offer powerful conversation, in-context learning and code generation abilities on a broad range of open-domain tasks. They can also generate high-level solution outlines for domain-specific tasks based on the common sense knowledge they have acquired. However, they still face difficulties with some specialized tasks because they lack enough domain-specific data during pre-training or they often have errors in their neural network computations on those tasks that need accurate executions. On the other hand, there are also many existing models and systems (symbolic-based or neural-based) that can do some domain-specific tasks very well. However, due to the different implementation or working mechanisms, they are not easily accessible or compatible with foundation models. Therefore, there is a clear and pressing need for a mechanism that can leverage foundation models to propose task solution outlines and then automatically match some of the sub-tasks in the outlines to the off-the-shelf models and systems with special functionalities to complete them. Inspired by this, we introduce TaskMatrix.AI as a new AI ecosystem that connects foundation models with millions of APIs for task completion. Unlike most previous work that aimed to improve a single AI model, TaskMatrix.AI focuses more on using existing foundation models (as a brain-like central system) and APIs of other AI models and systems (as sub-task solvers) to achieve diversified tasks in both digital and physical domains. As a position paper, we will present our vision of how to build such an ecosystem, explain each key component, and use study cases to illustrate both the feasibility of this vision and the main challenges we need to address next.","sentences":["Artificial Intelligence (AI) has made incredible progress recently.","On the one hand, advanced foundation models like ChatGPT can offer powerful conversation, in-context learning and code generation abilities on a broad range of open-domain tasks.","They can also generate high-level solution outlines for domain-specific tasks based on the common sense knowledge they have acquired.","However, they still face difficulties with some specialized tasks because they lack enough domain-specific data during pre-training or they often have errors in their neural network computations on those tasks that need accurate executions.","On the other hand, there are also many existing models and systems (symbolic-based or neural-based) that can do some domain-specific tasks very well.","However, due to the different implementation or working mechanisms, they are not easily accessible or compatible with foundation models.","Therefore, there is a clear and pressing need for a mechanism that can leverage foundation models to propose task solution outlines and then automatically match some of the sub-tasks in the outlines to the off-the-shelf models and systems with special functionalities to complete them.","Inspired by this, we introduce TaskMatrix.","AI as a new AI ecosystem that connects foundation models with millions of APIs for task completion.","Unlike most previous work that aimed to improve a single AI model, TaskMatrix.","AI focuses more on using existing foundation models (as a brain-like central system) and APIs of other AI models and systems (as sub-task solvers) to achieve diversified tasks in both digital and physical domains.","As a position paper, we will present our vision of how to build such an ecosystem, explain each key component, and use study cases to illustrate both the feasibility of this vision and the main challenges we need to address next."],"url":"http://arxiv.org/abs/2303.16434v1"}
{"created":"2023-03-29","title":"Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology","abstract":"The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.","sentences":["The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community.","ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology.","In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows.","We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering.","We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology.","Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt.","Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences."],"url":"http://arxiv.org/abs/2303.16429v1"}
{"created":"2023-03-29","title":"ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models","abstract":"Large language models (LLMs) such as ChatGPT and GPT-4 have made significant progress in NLP. However, their ability to memorize, represent, and leverage commonsense knowledge has been a well-known pain point for LLMs. It remains unclear that: (1) Can GPTs effectively answer commonsense questions? (2) Are GPTs knowledgeable in commonsense? (3) Are GPTs aware of the underlying commonsense knowledge for answering a specific question? (4) Can GPTs effectively leverage commonsense for answering questions? To evaluate the above commonsense problems, we conduct a series of experiments to evaluate ChatGPT's commonsense abilities, and the experimental results show that: (1) GPTs can achieve good QA accuracy in commonsense tasks, while they still struggle with certain types of knowledge. (2) ChatGPT is knowledgeable, and can accurately generate most of the commonsense knowledge using knowledge prompts. (3) Despite its knowledge, ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense knowledge for answering a specific question, i.e., ChatGPT does not precisely know what commonsense knowledge is required to answer a question. The above findings raise the need to investigate better mechanisms for utilizing commonsense knowledge in LLMs, such as instruction following, better commonsense guidance, etc.","sentences":["Large language models (LLMs) such as ChatGPT and GPT-4 have made significant progress in NLP.","However, their ability to memorize, represent, and leverage commonsense knowledge has been a well-known pain point for LLMs.","It remains unclear that: (1) Can GPTs effectively answer commonsense questions?","(2) Are GPTs knowledgeable in commonsense?","(3) Are GPTs aware of the underlying commonsense knowledge for answering a specific question?","(4) Can GPTs effectively leverage commonsense for answering questions?","To evaluate the above commonsense problems, we conduct a series of experiments to evaluate ChatGPT's commonsense abilities, and the experimental results show that: (1) GPTs can achieve good QA accuracy in commonsense tasks, while they still struggle with certain types of knowledge.","(2) ChatGPT is knowledgeable, and can accurately generate most of the commonsense knowledge using knowledge prompts.","(3) Despite its knowledge, ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense knowledge for answering a specific question, i.e., ChatGPT does not precisely know what commonsense knowledge is required to answer a question.","The above findings raise the need to investigate better mechanisms for utilizing commonsense knowledge in LLMs, such as instruction following, better commonsense guidance, etc."],"url":"http://arxiv.org/abs/2303.16421v1"}
{"created":"2023-03-29","title":"Zero-shot Clinical Entity Recognition using ChatGPT","abstract":"In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies. We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples. Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively. Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies. Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.628 vs. 0.870), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, which is much more appealing as it does not require any annotation.","sentences":["In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies.","We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples.","Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively.","Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies.","Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.628 vs. 0.870), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, which is much more appealing as it does not require any annotation."],"url":"http://arxiv.org/abs/2303.16416v1"}
{"created":"2023-03-28","title":"ChatGPT or academic scientist? Distinguishing authorship with over 99% accuracy using off-the-shelf machine learning tools","abstract":"ChatGPT has enabled access to AI-generated writing for the masses, and within just a few months, this product has disrupted the knowledge economy, initiating a culture shift in the way people work, learn, and write. The need to discriminate human writing from AI is now both critical and urgent, particularly in domains like higher education and academic writing, where AI had not been a significant threat or contributor to authorship. Addressing this need, we developed a method for discriminating text generated by ChatGPT from (human) academic scientists, relying on prevalent and accessible supervised classification methods. We focused on how a particular group of humans, academic scientists, write differently than ChatGPT, and this targeted approach led to the discovery of new features for discriminating (these) humans from AI; as examples, scientists write long paragraphs and have a penchant for equivocal language, frequently using words like but, however, and although. With a set of 20 features, including the aforementioned ones and others, we built a model that assigned the author, as human or AI, at well over 99% accuracy, resulting in 20 times fewer misclassified documents compared to the field-leading approach. This strategy for discriminating a particular set of humans writing from AI could be further adapted and developed by others with basic skills in supervised classification, enabling access to many highly accurate and targeted models for detecting AI usage in academic writing and beyond.","sentences":["ChatGPT has enabled access to AI-generated writing for the masses, and within just a few months, this product has disrupted the knowledge economy, initiating a culture shift in the way people work, learn, and write.","The need to discriminate human writing from AI is now both critical and urgent, particularly in domains like higher education and academic writing, where AI had not been a significant threat or contributor to authorship.","Addressing this need, we developed a method for discriminating text generated by ChatGPT from (human) academic scientists, relying on prevalent and accessible supervised classification methods.","We focused on how a particular group of humans, academic scientists, write differently than ChatGPT, and this targeted approach led to the discovery of new features for discriminating (these) humans from AI; as examples, scientists write long paragraphs and have a penchant for equivocal language, frequently using words like but, however, and although.","With a set of 20 features, including the aforementioned ones and others, we built a model that assigned the author, as human or AI, at well over 99% accuracy, resulting in 20 times fewer misclassified documents compared to the field-leading approach.","This strategy for discriminating a particular set of humans writing from AI could be further adapted and developed by others with basic skills in supervised classification, enabling access to many highly accurate and targeted models for detecting AI usage in academic writing and beyond."],"url":"http://arxiv.org/abs/2303.16352v1"}
{"created":"2023-03-28","title":"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube","abstract":"Contrary to Google Search's mission of delivering information from \"many angles so you can form your own understanding of the world,\" we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like \"Buddhism,\" \"Liberalism,\" \"colonization,\" \"Iran\" and \"America.\" Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primarily trained on English language data, it presents the Anglo-American perspective as the normative view, reducing the complexity of a multifaceted issue to the single Anglo-American standard. In this paper, we present evidence and analysis of language bias and discuss its larger social implications. Toward the end of the paper, we propose a potential framework of using automatic translation to leverage language bias and argue that the task of piecing together a genuine depiction of the elephant is a challenging and important endeavor that deserves a new area of research in NLP and requires collaboration with scholars from the humanities to create ethically sound and socially responsible technology together.","sentences":["Contrary to Google Search's mission of delivering information from \"many angles so you can form your own understanding of the world,\" we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like \"Buddhism,\" \"Liberalism,\" \"colonization,\" \"Iran\" and \"America.\"","Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias').","Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives.","The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture.","We also find that language bias is deeply embedded in ChatGPT.","As it is primarily trained on English language data, it presents the Anglo-American perspective as the normative view, reducing the complexity of a multifaceted issue to the single Anglo-American standard.","In this paper, we present evidence and analysis of language bias and discuss its larger social implications.","Toward the end of the paper, we propose a potential framework of using automatic translation to leverage language bias and argue that the task of piecing together a genuine depiction of the elephant is a challenging and important endeavor that deserves a new area of research in NLP and requires collaboration with scholars from the humanities to create ethically sound and socially responsible technology together."],"url":"http://arxiv.org/abs/2303.16281v1"}
{"created":"2023-03-28","title":"Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services","abstract":"Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, finetuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGCdriven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.","sentences":["Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively.","This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy.","We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, finetuning, inference, and product management.","We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks.","Furthermore, we explore AIGCdriven creative applications and use cases for mobile AIGC networks.","Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks.","Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks."],"url":"http://arxiv.org/abs/2303.16129v2"}
{"created":"2023-03-28","title":"Hallucinations in Large Multilingual Translation Models","abstract":"Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs. We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems.","sentences":["Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications.","However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns.","Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios.","In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation.","Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs.","We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems."],"url":"http://arxiv.org/abs/2303.16104v1"}
{"created":"2023-03-28","title":"Ecosystem Graphs: The Social Footprint of Foundation Models","abstract":"Foundation models (e.g. ChatGPT, StableDiffusion) pervasively influence society, warranting immediate social attention. While the models themselves garner much attention, to accurately characterize their impact, we must consider the broader sociotechnical ecosystem. We propose Ecosystem Graphs as a documentation framework to transparently centralize knowledge of this ecosystem. Ecosystem Graphs is composed of assets (datasets, models, applications) linked together by dependencies that indicate technical (e.g. how Bing relies on GPT-4) and social (e.g. how Microsoft relies on OpenAI) relationships. To supplement the graph structure, each asset is further enriched with fine-grained metadata (e.g. the license or training emissions). We document the ecosystem extensively at https://crfm.stanford.edu/ecosystem-graphs/. As of March 16, 2023, we annotate 262 assets (64 datasets, 128 models, 70 applications) from 63 organizations linked by 356 dependencies. We show Ecosystem Graphs functions as a powerful abstraction and interface for achieving the minimum transparency required to address myriad use cases. Therefore, we envision Ecosystem Graphs will be a community-maintained resource that provides value to stakeholders spanning AI researchers, industry professionals, social scientists, auditors and policymakers.","sentences":["Foundation models (e.g. ChatGPT, StableDiffusion) pervasively influence society, warranting immediate social attention.","While the models themselves garner much attention, to accurately characterize their impact, we must consider the broader sociotechnical ecosystem.","We propose Ecosystem Graphs as a documentation framework to transparently centralize knowledge of this ecosystem.","Ecosystem Graphs is composed of assets (datasets, models, applications) linked together by dependencies that indicate technical (e.g. how Bing relies on GPT-4) and social (e.g. how Microsoft relies on OpenAI) relationships.","To supplement the graph structure, each asset is further enriched with fine-grained metadata (e.g. the license or training emissions).","We document the ecosystem extensively at https://crfm.stanford.edu/ecosystem-graphs/. As of March 16, 2023, we annotate 262 assets (64 datasets, 128 models, 70 applications) from 63 organizations linked by 356 dependencies.","We show Ecosystem Graphs functions as a powerful abstraction and interface for achieving the minimum transparency required to address myriad use cases.","Therefore, we envision Ecosystem Graphs will be a community-maintained resource that provides value to stakeholders spanning AI researchers, industry professionals, social scientists, auditors and policymakers."],"url":"http://arxiv.org/abs/2303.15772v1"}
{"created":"2023-03-28","title":"Evaluation of ChatGPT for NLP-based Mental Health Applications","abstract":"Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research. In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification). We obtained annotated social media posts for the three classification tasks from public datasets. Then ChatGPT API classified the social media posts with an input prompt for classification. We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively. A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a potential use of language models for mental health classification tasks.","sentences":["Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research.","In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification).","We obtained annotated social media posts for the three classification tasks from public datasets.","Then ChatGPT API classified the social media posts with an input prompt for classification.","We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively.","A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19.","The zero-shot classification accuracy obtained with ChatGPT indicates a potential use of language models for mental health classification tasks."],"url":"http://arxiv.org/abs/2303.15727v1"}
{"created":"2023-03-28","title":"Solving Regularized Exp, Cosh and Sinh Regression Problems","abstract":"In modern machine learning, attention computation is a fundamental task for training large language models such as Transformer, GPT-4 and ChatGPT. In this work, we study exponential regression problem which is inspired by the softmax/exp unit in the attention mechanism in large language models. The standard exponential regression is non-convex. We study the regularization version of exponential regression problem which is a convex problem. We use approximate newton method to solve in input sparsity time.   Formally, in this problem, one is given matrix $A \\in \\mathbb{R}^{n \\times d}$, $b \\in \\mathbb{R}^n$, $w \\in \\mathbb{R}^n$ and any of functions $\\exp, \\cosh$ and $\\sinh$ denoted as $f$. The goal is to find the optimal $x$ that minimize $ 0.5 \\| f(Ax) - b \\|_2^2 + 0.5 \\| \\mathrm{diag}(w) A x \\|_2^2$. The straightforward method is to use the naive Newton's method. Let $\\mathrm{nnz}(A)$ denote the number of non-zeros entries in matrix $A$. Let $\\omega$ denote the exponent of matrix multiplication. Currently, $\\omega \\approx 2.373$. Let $\\epsilon$ denote the accuracy error. In this paper, we make use of the input sparsity and purpose an algorithm that use $\\log ( \\|x_0 - x^*\\|_2 / \\epsilon)$ iterations and $\\widetilde{O}(\\mathrm{nnz}(A) + d^{\\omega} )$ per iteration time to solve the problem.","sentences":["In modern machine learning, attention computation is a fundamental task for training large language models such as Transformer, GPT-4 and ChatGPT.","In this work, we study exponential regression problem which is inspired by the softmax/exp unit in the attention mechanism in large language models.","The standard exponential regression is non-convex.","We study the regularization version of exponential regression problem which is a convex problem.","We use approximate newton method to solve in input sparsity time.   ","Formally, in this problem, one is given matrix $A \\in \\mathbb{R}^{n \\times d}$, $b \\in \\mathbb{R}^n$, $w \\in \\mathbb{R}^n$ and any of functions $\\exp, \\cosh$ and $\\sinh$ denoted as $f$. The goal is to find the optimal $x$ that minimize $ 0.5 \\| f(Ax) - b \\|_2^2","+ 0.5 \\| \\mathrm{diag}(w)","A x \\|_2^2$.","The straightforward method is to use the naive Newton's method.","Let $\\mathrm{nnz}(A)$ denote the number of non-zeros entries in matrix $A$.","Let $\\omega$ denote the exponent of matrix multiplication.","Currently, $\\omega \\approx 2.373$. Let $\\epsilon$ denote the accuracy error.","In this paper, we make use of the input sparsity and purpose an algorithm that use $\\log ( \\|x_0 - x^*\\|_2 / \\epsilon)$ iterations and $\\widetilde{O}(\\mathrm{nnz}(A) + d^{\\omega} )$ per iteration time to solve the problem."],"url":"http://arxiv.org/abs/2303.15725v1"}
{"created":"2023-03-28","title":"Comparative Analysis of CHATGPT and the evolution of language models","abstract":"Interest in Large Language Models (LLMs) has increased drastically since the emergence of ChatGPT and the outstanding positive societal response to the ease with which it performs tasks in Natural Language Processing (NLP). The triumph of ChatGPT, however, is how it seamlessly bridges the divide between language generation and knowledge models. In some cases, it provides anecdotal evidence of a framework for replicating human intuition over a knowledge domain. This paper highlights the prevailing ideas in NLP, including machine translation, machine summarization, question-answering, and language generation, and compares the performance of ChatGPT with the major algorithms in each of these categories using the Spontaneous Quality (SQ) score. A strategy for validating the arguments and results of ChatGPT is presented summarily as an example of safe, large-scale adoption of LLMs.","sentences":["Interest in Large Language Models (LLMs) has increased drastically since the emergence of ChatGPT and the outstanding positive societal response to the ease with which it performs tasks in Natural Language Processing (NLP).","The triumph of ChatGPT, however, is how it seamlessly bridges the divide between language generation and knowledge models.","In some cases, it provides anecdotal evidence of a framework for replicating human intuition over a knowledge domain.","This paper highlights the prevailing ideas in NLP, including machine translation, machine summarization, question-answering, and language generation, and compares the performance of ChatGPT with the major algorithms in each of these categories using the Spontaneous Quality (SQ) score.","A strategy for validating the arguments and results of ChatGPT is presented summarily as an example of safe, large-scale adoption of LLMs."],"url":"http://arxiv.org/abs/2304.02468v1"}
{"created":"2023-03-28","title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds","abstract":"This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.","sentences":["This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games.","The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills.","ChatGPT is a conversational agent developed by OpenAI.","Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability.","To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters.","Here, the quality of the generated levels is determined by their stability and similarity to the given characters.","A sample prompt is provided to participants for their reference.","An experiment is conducted to determine the effectiveness of its modified versions on level stability and similarity by testing them on several characters.","To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation."],"url":"http://arxiv.org/abs/2303.15662v1"}
{"created":"2023-03-27","title":"ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization","abstract":"The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently. The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al. However, they have limitations of high computational complexity and relying on annotated data. Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference. In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating. Experimental results show that ChatGPT outperforms previous SOTA evaluation metrics on 6/9 datasets across three tasks, demonstrating its great potential for assessing factual inconsistency in the zero-shot setting. The results also highlight the importance of prompt design and the need for future efforts to address ChatGPT's limitations on evaluation bias, wrong reasoning, and hallucination.","sentences":["The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently.","The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary.","To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al.","However, they have limitations of high computational complexity and relying on annotated data.","Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference.","In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating.","Experimental results show that ChatGPT outperforms previous SOTA evaluation metrics on 6/9 datasets across three tasks, demonstrating its great potential for assessing factual inconsistency in the zero-shot setting.","The results also highlight the importance of prompt design and the need for future efforts to address ChatGPT's limitations on evaluation bias, wrong reasoning, and hallucination."],"url":"http://arxiv.org/abs/2303.15621v1"}
{"created":"2023-03-27","title":"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing","abstract":"Large language models have revolutionized the field of artificial intelligence and have been used in various applications. Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted. ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment. Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.","sentences":["Large language models have revolutionized the field of artificial intelligence and have been used in various applications.","Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted.","ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment.","Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts.","Its versatility and accuracy make it a powerful tool for natural language processing (NLP).","However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns.","This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations.","Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios.","Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques."],"url":"http://arxiv.org/abs/2304.02017v2"}
{"created":"2023-03-27","title":"Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses","abstract":"In the field of Japanese-Chinese translation linguistics, the issue of correctly translating attributive clauses has persistently proven to be challenging. Present-day machine translation tools often fail to accurately translate attributive clauses from Japanese to Chinese. In light of this, this paper investigates the linguistic problem underlying such difficulties, namely how does the semantic role of the modified noun affect the selection of translation patterns for attributive clauses, from a linguistic perspective. To ad-dress these difficulties, a pre-edit scheme is proposed, which aims to enhance the accuracy of translation. Furthermore, we propose a novel two-step prompt strategy, which combines this pre-edit scheme with ChatGPT, currently the most widely used large language model. This prompt strategy is capable of optimizing translation input in zero-shot scenarios and has been demonstrated to improve the average translation accuracy score by over 35%.","sentences":["In the field of Japanese-Chinese translation linguistics, the issue of correctly translating attributive clauses has persistently proven to be challenging.","Present-day machine translation tools often fail to accurately translate attributive clauses from Japanese to Chinese.","In light of this, this paper investigates the linguistic problem underlying such difficulties, namely how does the semantic role of the modified noun affect the selection of translation patterns for attributive clauses, from a linguistic perspective.","To ad-dress these difficulties, a pre-edit scheme is proposed, which aims to enhance the accuracy of translation.","Furthermore, we propose a novel two-step prompt strategy, which combines this pre-edit scheme with ChatGPT, currently the most widely used large language model.","This prompt strategy is capable of optimizing translation input in zero-shot scenarios and has been demonstrated to improve the average translation accuracy score by over 35%."],"url":"http://arxiv.org/abs/2303.15587v1"}
{"created":"2023-03-27","title":"ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks","abstract":"Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.","sentences":["Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models.","Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants.","Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection.","Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks.","Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk.","These results show the potential of large language models to drastically increase the efficiency of text classification."],"url":"http://arxiv.org/abs/2303.15056v1"}
{"created":"2023-03-26","title":"MGTBench: Benchmarking Machine-Generated Text Detection","abstract":"Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies   In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs. Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods. Our source code and datasets are available at https://github.com/xinleihe/MGTBench.","sentences":["Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering.","In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent.","These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias.","However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies   In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench.","Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs.","An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs.","Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods.","We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods.","Our source code and datasets are available at https://github.com/xinleihe/MGTBench."],"url":"http://arxiv.org/abs/2303.14822v1"}
{"created":"2023-03-26","title":"Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases","abstract":"The success of ChatGPT has recently attracted numerous efforts to replicate it, with instruction-tuning strategies being a key factor in achieving remarkable results. Instruction-tuning not only significantly enhances the model's performance and generalization but also makes the model's generated results more consistent with human speech patterns. However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases. In this paper we explore the performance of large language models based on instruction tuning across different scales of instruction data. An evaluation dataset consisting of 12 major online use cases is constructed in the experiment. With Bloomz-7B1-mt as the base model, the results show that 1) merely increasing the amount of instruction data leads to continuous improvement in tasks such as open-ended generation, 2) in tasks such as math and code, the model performance curve remains quite flat while increasing data size. We further analyze the possible causes of these phenomena and propose potential future research directions such as effectively selecting high-quality training data, scaling base models and training methods specialized for hard tasks. We will release our training and evaluation datasets, as well as model checkpoints.","sentences":["The success of ChatGPT has recently attracted numerous efforts to replicate it, with instruction-tuning strategies being a key factor in achieving remarkable results.","Instruction-tuning not only significantly enhances the model's performance and generalization but also makes the model's generated results more consistent with human speech patterns.","However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases.","In this paper we explore the performance of large language models based on instruction tuning across different scales of instruction data.","An evaluation dataset consisting of 12 major online use cases is constructed in the experiment.","With Bloomz-7B1-mt as the base model, the results show that 1) merely increasing the amount of instruction data leads to continuous improvement in tasks such as open-ended generation, 2) in tasks such as math and code, the model performance curve remains quite flat while increasing data size.","We further analyze the possible causes of these phenomena and propose potential future research directions such as effectively selecting high-quality training data, scaling base models and training methods specialized for hard tasks.","We will release our training and evaluation datasets, as well as model checkpoints."],"url":"http://arxiv.org/abs/2303.14742v1"}
{"created":"2023-03-26","title":"Mathematical Characterization of Signal Semantics and Rethinking of the Mathematical Theory of Information","abstract":"Shannon information theory is established based on probability and bits, and the communication technology based on this theory realizes the information age. The original goal of Shannon's information theory is to describe and transmit information content. However, due to information is related to cognition, and cognition is considered to be subjective, Shannon information theory is to describe and transmit information-bearing signals. With the development of the information age to the intelligent age, the traditional signal-oriented processing needs to be upgraded to content-oriented processing. For example, chat generative pre-trained transformer (ChatGPT) has initially realized the content processing capability based on massive data. For many years, researchers have been searching for the answer to what the information content in the signal is, because only when the information content is mathematically and accurately described can information-based machines be truly intelligent. This paper starts from rethinking the essence of the basic concepts of the information, such as semantics, meaning, information and knowledge, presents the mathematical characterization of the information content, investigate the relationship between them, studies the transformation from Shannon's signal information theory to semantic information theory, and therefore proposes a content-oriented semantic communication framework. Furthermore, we propose semantic decomposition and composition scheme to achieve conversion between complex and simple semantics. Finally, we verify the proposed characterization of information-related concepts by implementing evolvable knowledge-based semantic recognition.","sentences":["Shannon information theory is established based on probability and bits, and the communication technology based on this theory realizes the information age.","The original goal of Shannon's information theory is to describe and transmit information content.","However, due to information is related to cognition, and cognition is considered to be subjective, Shannon information theory is to describe and transmit information-bearing signals.","With the development of the information age to the intelligent age, the traditional signal-oriented processing needs to be upgraded to content-oriented processing.","For example, chat generative pre-trained transformer (ChatGPT) has initially realized the content processing capability based on massive data.","For many years, researchers have been searching for the answer to what the information content in the signal is, because only when the information content is mathematically and accurately described can information-based machines be truly intelligent.","This paper starts from rethinking the essence of the basic concepts of the information, such as semantics, meaning, information and knowledge, presents the mathematical characterization of the information content, investigate the relationship between them, studies the transformation from Shannon's signal information theory to semantic information theory, and therefore proposes a content-oriented semantic communication framework.","Furthermore, we propose semantic decomposition and composition scheme to achieve conversion between complex and simple semantics.","Finally, we verify the proposed characterization of information-related concepts by implementing evolvable knowledge-based semantic recognition."],"url":"http://arxiv.org/abs/2303.14701v1"}
{"created":"2023-03-26","title":"Guiding AI-Generated Digital Content with Wireless Perception","abstract":"Recent advances in artificial intelligence (AI), coupled with a surge in training data, have led to the widespread use of AI for digital content generation, with ChatGPT serving as a representative example. Despite the increased efficiency and diversity, the inherent instability of AI models poses a persistent challenge in guiding these models to produce the desired content for users. In this paper, we introduce an integration of wireless perception (WP) with AI-generated content (AIGC) and propose a unified WP-AIGC framework to improve the quality of digital content production. The framework employs a novel multi-scale perception technology to read user's posture, which is difficult to describe accurately in words, and transmits it to the AIGC model as skeleton images. Based on these images and user's service requirements, the AIGC model generates corresponding digital content. Since the production process imposes the user's posture as a constraint on the AIGC model, it makes the generated content more aligned with the user's requirements. Additionally, WP-AIGC can also accept user's feedback, allowing adjustment of computing resources at edge server to improve service quality. Experiments results verify the effectiveness of the WP-AIGC framework, highlighting its potential as a novel approach for guiding AI models in the accurate generation of digital content.","sentences":["Recent advances in artificial intelligence (AI), coupled with a surge in training data, have led to the widespread use of AI for digital content generation, with ChatGPT serving as a representative example.","Despite the increased efficiency and diversity, the inherent instability of AI models poses a persistent challenge in guiding these models to produce the desired content for users.","In this paper, we introduce an integration of wireless perception (WP) with AI-generated content (AIGC) and propose a unified WP-AIGC framework to improve the quality of digital content production.","The framework employs a novel multi-scale perception technology to read user's posture, which is difficult to describe accurately in words, and transmits it to the AIGC model as skeleton images.","Based on these images and user's service requirements, the AIGC model generates corresponding digital content.","Since the production process imposes the user's posture as a constraint on the AIGC model, it makes the generated content more aligned with the user's requirements.","Additionally, WP-AIGC can also accept user's feedback, allowing adjustment of computing resources at edge server to improve service quality.","Experiments results verify the effectiveness of the WP-AIGC framework, highlighting its potential as a novel approach for guiding AI models in the accurate generation of digital content."],"url":"http://arxiv.org/abs/2303.14624v1"}
{"created":"2023-03-25","title":"Can Large Language Models assist in Hazard Analysis?","abstract":"Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.","sentences":["Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation.","This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA).","In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes.","In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service.","The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology.","The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis."],"url":"http://arxiv.org/abs/2303.15473v1"}
{"created":"2023-03-25","title":"Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System","abstract":"Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks. However, traditional recommender systems continue to face great challenges such as poor interactivity and explainability, which actually also hinder their broad deployment in real-world systems. To address these limitations, this paper proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender System) that innovatively augments LLMs for building conversational recommender systems by converting user profiles and historical interactions into prompts. Chat-Rec is demonstrated to be effective in learning user preferences and establishing connections between users and products through in-context learning, which also makes the recommendation process more interactive and explainable. What's more, within the Chat-Rec framework, user's preferences can transfer to different products for cross-domain recommendations, and prompt-based injection of information into LLMs can also handle the cold-start scenarios with new items. In our experiments, Chat-Rec effectively improve the results of top-k recommendations and performs better in zero-shot rating prediction task. Chat-Rec offers a novel approach to improving recommender systems and presents new practical scenarios for the implementation of AIGC (AI generated content) in recommender system studies.","sentences":["Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks.","However, traditional recommender systems continue to face great challenges such as poor interactivity and explainability, which actually also hinder their broad deployment in real-world systems.","To address these limitations, this paper proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender System) that innovatively augments LLMs for building conversational recommender systems by converting user profiles and historical interactions into prompts.","Chat-Rec is demonstrated to be effective in learning user preferences and establishing connections between users and products through in-context learning, which also makes the recommendation process more interactive and explainable.","What's more, within the Chat-Rec framework, user's preferences can transfer to different products for cross-domain recommendations, and prompt-based injection of information into LLMs can also handle the cold-start scenarios with new items.","In our experiments, Chat-Rec effectively improve the results of top-k recommendations and performs better in zero-shot rating prediction task.","Chat-Rec offers a novel approach to improving recommender systems and presents new practical scenarios for the implementation of AIGC (AI generated content) in recommender system studies."],"url":"http://arxiv.org/abs/2303.14524v2"}
{"created":"2023-03-24","title":"Chat2VIS: Fine-Tuning Data Visualisations using Multilingual Natural Language Text and Pre-Trained Large Language Models","abstract":"The explosion of data in recent years is driving individuals to leverage technology to generate insights. Traditional tools bring heavy learning overheads and the requirement for understanding complex charting techniques. Such barriers can hinder those who may benefit from harnessing data for informed decision making. The emerging field of generating data visualisations from natural language text (NL2VIS) addresses this issue. This study showcases Chat2VIS, a state-of-the-art NL2VIS solution. It capitalises on the latest in AI technology with the upsurge in pre-trained large language models (LLMs) such as GPT-3, Codex, and ChatGPT. Furthermore, the rise in natural language interfaces (NLI) and chatbots is taking centre stage. This work illustrates how Chat2VIS leverages similar techniques to fine-tune data visualisation components beyond that demonstrated in previous approaches. In addition, this paper presents the flexibility of Chat2VIS to comprehend multilingual natural language requests. No other NL2VIS system has demonstrated this unique talent. In concluding, this research provides quantitative benchmarking evaluations to contribute to the paucity of NL2VIS standards.","sentences":["The explosion of data in recent years is driving individuals to leverage technology to generate insights.","Traditional tools bring heavy learning overheads and the requirement for understanding complex charting techniques.","Such barriers can hinder those who may benefit from harnessing data for informed decision making.","The emerging field of generating data visualisations from natural language text (NL2VIS) addresses this issue.","This study showcases Chat2VIS, a state-of-the-art NL2VIS solution.","It capitalises on the latest in AI technology with the upsurge in pre-trained large language models (LLMs) such as GPT-3, Codex, and ChatGPT.","Furthermore, the rise in natural language interfaces (NLI) and chatbots is taking centre stage.","This work illustrates how Chat2VIS leverages similar techniques to fine-tune data visualisation components beyond that demonstrated in previous approaches.","In addition, this paper presents the flexibility of Chat2VIS to comprehend multilingual natural language requests.","No other NL2VIS system has demonstrated this unique talent.","In concluding, this research provides quantitative benchmarking evaluations to contribute to the paucity of NL2VIS standards."],"url":"http://arxiv.org/abs/2303.14292v1"}
{"created":"2023-03-24","title":"ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge","abstract":"Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been tailored to the medical domain, resulting in poor answer accuracy and inability to give plausible recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, required medical tests, and recommended medications, from which we generated 5K doctor-patient conversations. In addition, we obtained 200K real patient-doctor conversations from online Q\\&A medical consultation sites. By fine-tuning LLMs using these 205k doctor-patient conversations, the resulting models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall efficiency and quality of patient care and outcomes. In addition, we made public all the source codes, datasets, and model weights to facilitate the further development of dialogue models in the medical field. The training data, codes, and weights of this project are available at: The training data, codes, and weights of this project are available at: https://github.com/Kent0n-Li/ChatDoctor.","sentences":["Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses.","However, such language models have not been tailored to the medical domain, resulting in poor answer accuracy and inability to give plausible recommendations for medical diagnosis, medications, etc.","To address this issue, we collected more than 700 diseases and their corresponding symptoms, required medical tests, and recommended medications, from which we generated 5K doctor-patient conversations.","In addition, we obtained 200K real patient-doctor conversations from online Q\\&A medical consultation sites.","By fine-tuning LLMs using these 205k doctor-patient conversations, the resulting models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields.","The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall efficiency and quality of patient care and outcomes.","In addition, we made public all the source codes, datasets, and model weights to facilitate the further development of dialogue models in the medical field.","The training data, codes, and weights of this project are available at: The training data, codes, and weights of this project are available at: https://github.com/Kent0n-Li/ChatDoctor."],"url":"http://arxiv.org/abs/2303.14070v3"}
{"created":"2023-03-24","title":"Paraphrase Detection: Human vs. Machine Content","abstract":"The growing prominence of large language models, such as GPT-4 and ChatGPT, has led to increased concerns over academic integrity due to the potential for machine-generated content and paraphrasing. Although studies have explored the detection of human- and machine-paraphrased content, the comparison between these types of content remains underexplored. In this paper, we conduct a comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and evaluate an array of detection methods. Our findings highlight the strengths and limitations of different detection methods in terms of performance on individual datasets, revealing a lack of suitable machine-generated datasets that can be aligned with human expectations. Our main finding is that human-authored paraphrases exceed machine-generated ones in terms of difficulty, diversity, and similarity implying that automatically generated texts are not yet on par with human-level performance. Transformers emerged as the most effective method across datasets with TF-IDF excelling on semantically diverse corpora. Additionally, we identify four datasets as the most diverse and challenging for paraphrase detection.","sentences":["The growing prominence of large language models, such as GPT-4 and ChatGPT, has led to increased concerns over academic integrity due to the potential for machine-generated content and paraphrasing.","Although studies have explored the detection of human- and machine-paraphrased content, the comparison between these types of content remains underexplored.","In this paper, we conduct a comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and evaluate an array of detection methods.","Our findings highlight the strengths and limitations of different detection methods in terms of performance on individual datasets, revealing a lack of suitable machine-generated datasets that can be aligned with human expectations.","Our main finding is that human-authored paraphrases exceed machine-generated ones in terms of difficulty, diversity, and similarity implying that automatically generated texts are not yet on par with human-level performance.","Transformers emerged as the most effective method across datasets with TF-IDF excelling on semantically diverse corpora.","Additionally, we identify four datasets as the most diverse and challenging for paraphrase detection."],"url":"http://arxiv.org/abs/2303.13989v1"}
{"created":"2023-03-24","title":"Generative AI Assistants in Software Development Education","abstract":"The software development industry is amid another potentially disruptive paradigm change--adopting the use of generative AI (GAI) assistants for software development. Whilst AI is already used in various areas of software engineering, GAI technologies, such as GitHub Copilot and ChatGPT, have ignited the imaginations (and fears) of many people. Whilst it is unclear how the industry will adopt and adapt to these technologies, the move to integrate these technologies into the wider industry by large software companies, such as Microsoft (GitHub, Bing) and Google (Bard), is a clear indication of intent and direction. We performed exploratory interviews with industry professionals to understand current practices and challenges, which we incorporate into our vision of a future of software development education and make some pedagogical recommendations.","sentences":["The software development industry is amid another potentially disruptive paradigm change--adopting the use of generative AI (GAI) assistants for software development.","Whilst AI is already used in various areas of software engineering, GAI technologies, such as GitHub Copilot and ChatGPT, have ignited the imaginations (and fears) of many people.","Whilst it is unclear how the industry will adopt and adapt to these technologies, the move to integrate these technologies into the wider industry by large software companies, such as Microsoft (GitHub, Bing) and Google (Bard), is a clear indication of intent and direction.","We performed exploratory interviews with industry professionals to understand current practices and challenges, which we incorporate into our vision of a future of software development education and make some pedagogical recommendations."],"url":"http://arxiv.org/abs/2303.13936v1"}
{"created":"2023-03-24","title":"Unleasing ChatGPT on the Metaverse: Savior or Destroyer?","abstract":"The incorporation of artificial intelligence (AI) technology, and in particular natural language processing (NLP), is becoming increasingly vital for the development of immersive and interactive metaverse experiences. One such artificial intelligence tool that is gaining traction in the metaverse is ChatGPT, a large language model trained by OpenAI. The article delves into the pros and cons of utilizing ChatGPT for metaverse-based education, entertainment, personalization, and support. Dynamic and personalized experiences are possible with this technology, but there are also legitimate privacy, bias, and ethical issues to consider. This article aims to help readers understand the possible influence of ChatGPT on the metaverse and how it may be used to effectively create a more immersive and engaging virtual environment by evaluating these opportunities and obstacles.","sentences":["The incorporation of artificial intelligence (AI) technology, and in particular natural language processing (NLP), is becoming increasingly vital for the development of immersive and interactive metaverse experiences.","One such artificial intelligence tool that is gaining traction in the metaverse is ChatGPT, a large language model trained by OpenAI.","The article delves into the pros and cons of utilizing ChatGPT for metaverse-based education, entertainment, personalization, and support.","Dynamic and personalized experiences are possible with this technology, but there are also legitimate privacy, bias, and ethical issues to consider.","This article aims to help readers understand the possible influence of ChatGPT on the metaverse and how it may be used to effectively create a more immersive and engaging virtual environment by evaluating these opportunities and obstacles."],"url":"http://arxiv.org/abs/2303.13856v1"}
{"created":"2023-03-24","title":"Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT","abstract":"Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding. Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods. Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called \\textbf{\\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \\textit{generate human-like MT evaluations at both the system and segment level}. Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query. Our findings aim to provide a preliminary experience for appropriately evaluating translation quality on ChatGPT while offering a variety of tricks in designing prompts for in-context learning. We anticipate that this report will shed new light on advancing the field of translation evaluation with LLMs by enhancing both the accuracy and reliability of metrics. The project can be found in \\url{https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt}.","sentences":["Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding.","Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level.","To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods.","Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called \\textbf{\\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \\textit{generate human-like MT evaluations at both the system and segment level}.","Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query.","Our findings aim to provide a preliminary experience for appropriately evaluating translation quality on ChatGPT while offering a variety of tricks in designing prompts for in-context learning.","We anticipate that this report will shed new light on advancing the field of translation evaluation with LLMs by enhancing both the accuracy and reliability of metrics.","The project can be found in \\url{https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt}."],"url":"http://arxiv.org/abs/2303.13809v1"}
{"created":"2023-03-24","title":"Towards Making the Most of ChatGPT for Machine Translation","abstract":"ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP). We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT's performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT's generalization ability and improve its performance in the specific domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community. We also explore the effects of advanced in-context learning strategies and find a (negative but interesting) observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation.","sentences":["ChatGPT shows remarkable capabilities for machine translation (MT).","Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation.","However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT.","In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP).","We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT's performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT's generalization ability and improve its performance in the specific domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community.","We also explore the effects of advanced in-context learning strategies and find a (negative but interesting) observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation."],"url":"http://arxiv.org/abs/2303.13780v1"}
{"created":"2023-03-23","title":"Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages","abstract":"While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting multilingual LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -- Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term \"code-mixing\" is explicitly defined. Moreover, both ChatGPT's and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. Their code-mixing proficiency, however, is dampened by word choice errors that lead to semantic inaccuracies. Other multilingual models such as BLOOMZ and Flan-T5-XXL are unable to produce code-mixed texts altogether. By highlighting the limited promises of LLMs in a specific form of low-resource data generation, we call for a measured approach when applying similar techniques to other data-scarce NLP contexts.","sentences":["While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research.","The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation?","In this article, we explore prompting multilingual LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -- Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish.","We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term \"code-mixing\" is explicitly defined.","Moreover, both ChatGPT's and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts.","Their code-mixing proficiency, however, is dampened by word choice errors that lead to semantic inaccuracies.","Other multilingual models such as BLOOMZ and Flan-T5-XXL are unable to produce code-mixed texts altogether.","By highlighting the limited promises of LLMs in a specific form of low-resource data generation, we call for a measured approach when applying similar techniques to other data-scarce NLP contexts."],"url":"http://arxiv.org/abs/2303.13592v2"}
{"created":"2023-03-23","title":"ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model","abstract":"The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant potential benefits, the challenges, such as data privacy, data quality, and model bias, need further study. Overall, LLMs have the potential to revolutionize dental diagnosis and treatment, which indicates a promising avenue for clinical application and research in dentistry.","sentences":["The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters.","LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields.","This paper mainly discusses the future applications of LLMs in dentistry.","We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications.","Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations.","A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application.","While LLMs offer significant potential benefits, the challenges, such as data privacy, data quality, and model bias, need further study.","Overall, LLMs have the potential to revolutionize dental diagnosis and treatment, which indicates a promising avenue for clinical application and research in dentistry."],"url":"http://arxiv.org/abs/2304.03086v1"}
{"created":"2023-03-23","title":"Is ChatGPT A Good Keyphrase Generator? A Preliminary Study","abstract":"The emergence of ChatGPT has recently garnered significant attention from the computational linguistics community. To demonstrate its capabilities as a keyphrase generator, we conduct a preliminary evaluation of ChatGPT for the keyphrase generation task. We evaluate its performance in various aspects, including keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding. Our evaluation is based on six benchmark datasets, and we adopt the prompt suggested by OpenAI while extending it to six candidate prompts. We find that ChatGPT performs exceptionally well on all six candidate prompts, with minor performance differences observed across the datasets. Based on our findings, we conclude that ChatGPT has great potential for keyphrase generation. Moreover, we discover that ChatGPT still faces challenges when it comes to generating absent keyphrases. Meanwhile, in the final section, we also present some limitations and future expansions of this report.","sentences":["The emergence of ChatGPT has recently garnered significant attention from the computational linguistics community.","To demonstrate its capabilities as a keyphrase generator, we conduct a preliminary evaluation of ChatGPT for the keyphrase generation task.","We evaluate its performance in various aspects, including keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding.","Our evaluation is based on six benchmark datasets, and we adopt the prompt suggested by OpenAI while extending it to six candidate prompts.","We find that ChatGPT performs exceptionally well on all six candidate prompts, with minor performance differences observed across the datasets.","Based on our findings, we conclude that ChatGPT has great potential for keyphrase generation.","Moreover, we discover that ChatGPT still faces challenges when it comes to generating absent keyphrases.","Meanwhile, in the final section, we also present some limitations and future expansions of this report."],"url":"http://arxiv.org/abs/2303.13001v1"}
{"created":"2023-03-22","title":"The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs","abstract":"The successes of foundation models such as ChatGPT and AlphaFold have spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models' capabilities. We review over 80 foundation models trained on non-imaging EMR data (i.e. clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g. MIMIC-III) or broad, public biomedical corpora (e.g. PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. In light of these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.","sentences":["The successes of foundation models such as ChatGPT and AlphaFold have spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations.","However, recent hype has obscured critical gaps in our understanding of these models' capabilities.","We review over 80 foundation models trained on non-imaging EMR data (i.e. clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases.","We find that most models are trained on small, narrowly-scoped clinical datasets (e.g. MIMIC-III) or broad, public biomedical corpora (e.g. PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems.","In light of these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare."],"url":"http://arxiv.org/abs/2303.12961v2"}
{"created":"2023-03-22","title":"Cross-Layer Design for AI Acceleration with Non-Coherent Optical Computing","abstract":"Emerging AI applications such as ChatGPT, graph convolutional networks, and other deep neural networks require massive computational resources for training and inference. Contemporary computing platforms such as CPUs, GPUs, and TPUs are struggling to keep up with the demands of these AI applications. Non-coherent optical computing represents a promising approach for light-speed acceleration of AI workloads. In this paper, we show how cross-layer design can overcome challenges in non-coherent optical computing platforms. We describe approaches for optical device engineering, tuning circuit enhancements, and architectural innovations to adapt optical computing to a variety of AI workloads. We also discuss techniques for hardware/software co-design that can intelligently map and adapt AI software to improve its performance on non-coherent optical computing platforms.","sentences":["Emerging AI applications such as ChatGPT, graph convolutional networks, and other deep neural networks require massive computational resources for training and inference.","Contemporary computing platforms such as CPUs, GPUs, and TPUs are struggling to keep up with the demands of these AI applications.","Non-coherent optical computing represents a promising approach for light-speed acceleration of AI workloads.","In this paper, we show how cross-layer design can overcome challenges in non-coherent optical computing platforms.","We describe approaches for optical device engineering, tuning circuit enhancements, and architectural innovations to adapt optical computing to a variety of AI workloads.","We also discuss techniques for hardware/software co-design that can intelligently map and adapt AI software to improve its performance on non-coherent optical computing platforms."],"url":"http://arxiv.org/abs/2303.12910v1"}
{"created":"2023-03-22","title":"Can we trust the evaluation on ChatGPT?","abstract":"ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.","sentences":["ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks.","Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF).","We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection.","We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models."],"url":"http://arxiv.org/abs/2303.12767v1"}
{"created":"2023-03-22","title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4","abstract":"Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.","sentences":["Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition.","The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data.","In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI.","We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models.","We discuss the rising capabilities and implications of these models.","We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting.","Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT.","Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.","In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction.","We conclude with reflections on societal influences of the recent technological leap and future research directions."],"url":"http://arxiv.org/abs/2303.12712v3"}
{"created":"2023-03-21","title":"Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense","abstract":"Generative Language Models gained significant attention in late 2022 / early 2023, notably with the introduction of models refined to act consistently with users' expectations of interactions with AI (conversational models). Arguably the focal point of public attention has been such a refinement of the GPT3 model -- the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing. Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche. However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational fine-tuning, revealed the extent of their true capabilities in a real-world environment. This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses. This review aims to provide a brief overview of the history, state of the art, and implications of Generative Language Models in terms of their principles, abilities, limitations, and future prospects -- especially in the context of cyber-defense, with a focus on the Swiss operational environment.","sentences":["Generative Language Models gained significant attention in late 2022 / early 2023, notably with the introduction of models refined to act consistently with users' expectations of interactions with AI (conversational models).","Arguably the focal point of public attention has been such a refinement of the GPT3 model -- the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing.","Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche.","However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational fine-tuning, revealed the extent of their true capabilities in a real-world environment.","This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses.","This review aims to provide a brief overview of the history, state of the art, and implications of Generative Language Models in terms of their principles, abilities, limitations, and future prospects -- especially in the context of cyber-defense, with a focus on the Swiss operational environment."],"url":"http://arxiv.org/abs/2303.12132v1"}
{"created":"2023-03-21","title":"Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting","abstract":"The mass aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences. We examine the utility of one such model for a particularly difficult measurement task: measuring the latent ideology of lawmakers, which allows us to better understand functions that are core to democracy, such as how politics shape policy and how political actors represent their constituents. We scale the senators of the 116th United States Congress along the liberal-conservative spectrum by prompting ChatGPT to select the more liberal (or conservative) senator in pairwise comparisons. We show that the LLM produced stable answers across repeated iterations, did not hallucinate, and was not simply regurgitating information from a single source. This new scale strongly correlates with pre-existing liberal-conservative scales such as NOMINATE, but also differs in several important ways, such as correctly placing senators who vote against their party for far-left or far-right ideological reasons on the extreme ends. The scale also highly correlates with ideological measures based on campaign giving and political activists' perceptions of these senators. In addition to the potential for better-automated data collection and information retrieval, our results suggest LLMs are likely to open new avenues for measuring latent constructs like ideology that rely on aggregating large quantities of data from public sources.","sentences":["The mass aggregation of knowledge embedded in large language models (LLMs) holds the promise of new solutions to problems of observability and measurement in the social sciences.","We examine the utility of one such model for a particularly difficult measurement task: measuring the latent ideology of lawmakers, which allows us to better understand functions that are core to democracy, such as how politics shape policy and how political actors represent their constituents.","We scale the senators of the 116th United States Congress along the liberal-conservative spectrum by prompting ChatGPT to select the more liberal (or conservative) senator in pairwise comparisons.","We show that the LLM produced stable answers across repeated iterations, did not hallucinate, and was not simply regurgitating information from a single source.","This new scale strongly correlates with pre-existing liberal-conservative scales such as NOMINATE, but also differs in several important ways, such as correctly placing senators who vote against their party for far-left or far-right ideological reasons on the extreme ends.","The scale also highly correlates with ideological measures based on campaign giving and political activists' perceptions of these senators.","In addition to the potential for better-automated data collection and information retrieval, our results suggest LLMs are likely to open new avenues for measuring latent constructs like ideology that rely on aggregating large quantities of data from public sources."],"url":"http://arxiv.org/abs/2303.12057v2"}
{"created":"2023-03-21","title":"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity","abstract":"A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: $alpa.\\!ai$, $Copy.\\!ai$, ChatGPT (versions 3 and 4), $Studio.\\!ai$, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being truly creative.","sentences":["A widespread view is that Artificial Intelligence cannot be creative.","We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: $alpa.\\!ai$, $Copy.\\!ai$, ChatGPT (versions 3 and 4), $Studio.\\!ai$, and YouChat.","Humans and a specifically trained AI independently assessed the quality and quantity of ideas.","We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated.","Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4.","Our findings suggest that GAIs are valuable assistants in the creative process.","Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity.","Finally, we discuss the question of whether GAIs are capable of being truly creative."],"url":"http://arxiv.org/abs/2303.12003v1"}
{"created":"2023-03-21","title":"ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing","abstract":"This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a chatbot). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.","sentences":["This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a chatbot).","The history and principles behind ChatGPT and similar models are discussed.","This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing.","ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts.","Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing."],"url":"http://arxiv.org/abs/2303.13367v2"}
{"created":"2023-03-21","title":"Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing","abstract":"ChatGPT is a publicly available chatbot that can quickly generate texts on given topics, but it is unknown whether the chatbot is really superior to human writers in all aspects of writing and whether its writing quality can be prominently improved on the basis of updating commands. Consequently, this study compared the writing performance on a narrative topic by ChatGPT and Chinese intermediate English (CIE) learners so as to reveal the chatbot's advantage and disadvantage in writing. The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version. After more revision commands were updated, while the resulting version was facilitated in syntactic simplicity, yet it is still lagged far behind CIE learners' writing in deep cohesion. In addition, the correlation analysis of the discourse components suggests that narrativity was correlated with referential cohesion in both ChatGPT and human writers, but the correlations varied within each group.","sentences":["ChatGPT is a publicly available chatbot that can quickly generate texts on given topics, but it is unknown whether the chatbot is really superior to human writers in all aspects of writing and whether its writing quality can be prominently improved on the basis of updating commands.","Consequently, this study compared the writing performance on a narrative topic by ChatGPT and Chinese intermediate English (CIE) learners so as to reveal the chatbot's advantage and disadvantage in writing.","The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version.","After more revision commands were updated, while the resulting version was facilitated in syntactic simplicity, yet it is still lagged far behind CIE learners' writing in deep cohesion.","In addition, the correlation analysis of the discourse components suggests that narrativity was correlated with referential cohesion in both ChatGPT and human writers, but the correlations varied within each group."],"url":"http://arxiv.org/abs/2303.11812v1"}
{"created":"2023-03-21","title":"ChatGPT for Programming Numerical Methods","abstract":"ChatGPT is a large language model recently released by the OpenAI company. In this technical report, we explore for the first time the capability of ChatGPT for programming numerical algorithms. Specifically, we examine the capability of GhatGPT for generating codes for numerical algorithms in different programming languages, for debugging and improving written codes by users, for completing missed parts of numerical codes, rewriting available codes in other programming languages, and for parallelizing serial codes. Additionally, we assess if ChatGPT can recognize if given codes are written by humans or machines. To reach this goal, we consider a variety of mathematical problems such as the Poisson equation, the diffusion equation, the incompressible Navier-Stokes equations, compressible inviscid flow, eigenvalue problems, solving linear systems of equations, storing sparse matrices, etc. Furthermore, we exemplify scientific machine learning such as physics-informed neural networks and convolutional neural networks with applications to computational physics. Through these examples, we investigate the successes, failures, and challenges of ChatGPT. Examples of failures are producing singular matrices, operations on arrays with incompatible sizes, programming interruption for relatively long codes, etc. Our outcomes suggest that ChatGPT can successfully program numerical algorithms in different programming languages, but certain limitations and challenges exist that require further improvement of this machine learning model.","sentences":["ChatGPT is a large language model recently released by the OpenAI company.","In this technical report, we explore for the first time the capability of ChatGPT for programming numerical algorithms.","Specifically, we examine the capability of GhatGPT for generating codes for numerical algorithms in different programming languages, for debugging and improving written codes by users, for completing missed parts of numerical codes, rewriting available codes in other programming languages, and for parallelizing serial codes.","Additionally, we assess if ChatGPT can recognize if given codes are written by humans or machines.","To reach this goal, we consider a variety of mathematical problems such as the Poisson equation, the diffusion equation, the incompressible Navier-Stokes equations, compressible inviscid flow, eigenvalue problems, solving linear systems of equations, storing sparse matrices, etc.","Furthermore, we exemplify scientific machine learning such as physics-informed neural networks and convolutional neural networks with applications to computational physics.","Through these examples, we investigate the successes, failures, and challenges of ChatGPT.","Examples of failures are producing singular matrices, operations on arrays with incompatible sizes, programming interruption for relatively long codes, etc.","Our outcomes suggest that ChatGPT can successfully program numerical algorithms in different programming languages, but certain limitations and challenges exist that require further improvement of this machine learning model."],"url":"http://arxiv.org/abs/2303.12093v2"}
{"created":"2023-03-21","title":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?","abstract":"As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.","sentences":["As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond.","With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle.","In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks.","Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation?","Toward answering this question, a comprehensive review of existing AIGC tasks is needed.","As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications.","Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models).","After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future.","Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content.","Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future."],"url":"http://arxiv.org/abs/2303.11717v1"}
{"created":"2023-03-21","title":"Large AI Models in Health Informatics: Applications, Challenges, and the Future","abstract":"Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which often reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A concrete example is the recent debut of ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our life. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multimodality data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents an up-to-date comprehensive review of large AI models, from background to their applications. We identify seven key sectors that large AI models are applicable and might have substantial influence, including 1) molecular biology and drug discovery; 2) medical diagnosis and decision-making; 3) medical imaging and vision; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We examine their challenges in health informatics, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics.","sentences":["Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which often reach beyond billions.","Once pretrained, large AI models demonstrate impressive performance in various downstream tasks.","A concrete example is the recent debut of ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our life.","In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies.","The scale of multimodality data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas.","This article presents an up-to-date comprehensive review of large AI models, from background to their applications.","We identify seven key sectors that large AI models are applicable and might have substantial influence, including 1) molecular biology and drug discovery; 2) medical diagnosis and decision-making; 3) medical imaging and vision; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics.","We examine their challenges in health informatics, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics."],"url":"http://arxiv.org/abs/2303.11568v1"}
{"created":"2023-03-20","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action","abstract":"We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action. In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models. To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos. MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts. Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding. Furthermore, we discuss and compare MM-REACT's system paradigm with an alternative approach that extends language models for multimodal scenarios through joint finetuning. Code, demo, video, and visualization are available at https://multimodal-react.github.io/","sentences":["We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action.","In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models.","To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos.","MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts.","Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding.","Furthermore, we discuss and compare MM-REACT's system paradigm with an alternative approach that extends language models for multimodal scenarios through joint finetuning.","Code, demo, video, and visualization are available at https://multimodal-react.github.io/"],"url":"http://arxiv.org/abs/2303.11381v1"}
{"created":"2023-03-20","title":"On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?","abstract":"In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.","sentences":["In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion.","ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse.","In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization.","We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers.","We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs.","While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system.","For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process.","Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT."],"url":"http://arxiv.org/abs/2303.11146v1"}
{"created":"2023-03-20","title":"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4","abstract":"The digitization of healthcare has facilitated the sharing and re-using of medical data but has also raised concerns about confidentiality and privacy. HIPAA (Health Insurance Portability and Accountability Act) mandates removing re-identifying information before the dissemination of medical records. Thus, effective and efficient solutions for de-identifying medical data, especially those in free-text forms, are highly needed. While various computer-assisted de-identification methods, including both rule-based and learning-based, have been developed and used in prior practice, such solutions still lack generalizability or need to be fine-tuned according to different scenarios, significantly imposing restrictions in wider use. The advancement of large language models (LLM), such as ChatGPT and GPT-4, have shown great potential in processing text data in the medical domain with zero-shot in-context learning, especially in the task of privacy protection, as these models can identify confidential information by their powerful named entity recognition (NER) capability. In this work, we developed a novel GPT4-enabled de-identification framework (\"DeID-GPT\") to automatically identify and remove the identifying information. Compared to existing commonly used medical text data de-identification methods, our developed DeID-GPT showed the highest accuracy and remarkable reliability in masking private information from the unstructured medical text while preserving the original structure and meaning of the text. This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text data processing and de-identification, which provides insights for further research and solution development on the use of LLMs such as ChatGPT/GPT-4 in healthcare. Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","sentences":["The digitization of healthcare has facilitated the sharing and re-using of medical data but has also raised concerns about confidentiality and privacy.","HIPAA (Health Insurance Portability and Accountability Act) mandates removing re-identifying information before the dissemination of medical records.","Thus, effective and efficient solutions for de-identifying medical data, especially those in free-text forms, are highly needed.","While various computer-assisted de-identification methods, including both rule-based and learning-based, have been developed and used in prior practice, such solutions still lack generalizability or need to be fine-tuned according to different scenarios, significantly imposing restrictions in wider use.","The advancement of large language models (LLM), such as ChatGPT and GPT-4, have shown great potential in processing text data in the medical domain with zero-shot in-context learning, especially in the task of privacy protection, as these models can identify confidential information by their powerful named entity recognition (NER) capability.","In this work, we developed a novel GPT4-enabled de-identification framework (\"DeID-GPT\") to automatically identify and remove the identifying information.","Compared to existing commonly used medical text data de-identification methods, our developed DeID-GPT showed the highest accuracy and remarkable reliability in masking private information from the unstructured medical text while preserving the original structure and meaning of the text.","This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text data processing and de-identification, which provides insights for further research and solution development on the use of LLMs such as ChatGPT/GPT-4 in healthcare.","Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API."],"url":"http://arxiv.org/abs/2303.11032v1"}
{"created":"2023-03-18","title":"A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models","abstract":"GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and fine-tuned models, there has been limited attention given to the evolution of GPT series models' capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve, especially with the introduction of the RLHF training strategy. While this strategy enhances the models' ability to generate human-like responses, it also compromises their ability to solve some tasks. Furthermore, our findings indicate that there is still room for improvement in areas such as model robustness.","sentences":["GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities.","However, despite the abundance of research on the difference in capabilities between GPT series models and fine-tuned models, there has been limited attention given to the evolution of GPT series models' capabilities over time.","To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo).","We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets.","In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios.","Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve, especially with the introduction of the RLHF training strategy.","While this strategy enhances the models' ability to generate human-like responses, it also compromises their ability to solve some tasks.","Furthermore, our findings indicate that there is still room for improvement in areas such as model robustness."],"url":"http://arxiv.org/abs/2303.10420v1"}
{"created":"2023-03-18","title":"An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering","abstract":"Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA.","sentences":["Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP).","It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks.","In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models.","However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA.","To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency.","In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs.","We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA.","Furthermore, we test ChatGPT, which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA.","We have released the code and benchmarks to promote the use of PLMs on KGQA."],"url":"http://arxiv.org/abs/2303.10368v1"}
{"created":"2023-03-16","title":"Block-wise Bit-Compression of Transformer-based Models","abstract":"With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks. However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement. To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining. Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient BERT with the method of BBCT. Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks.","sentences":["With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks.","However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement.","To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining.","Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results.","As a case, we compress an efficient BERT with the method of BBCT.","Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks."],"url":"http://arxiv.org/abs/2303.09184v2"}
{"created":"2023-03-16","title":"How well do Large Language Models perform in Arithmetic tasks?","abstract":"Large language models have emerged abilities including chain-of-thought to answer math word problems step by step. Solving math word problems not only requires abilities to disassemble problems via chain-of-thought but also needs to calculate arithmetic expressions correctly for each step. To the best of our knowledge, there is no work to focus on evaluating the arithmetic ability of large language models. In this work, we propose an arithmetic dataset MATH 401 to test the latest large language models including GPT-4, ChatGPT, InstrctGPT, Galactica, and LLaMA with various arithmetic expressions and provide a detailed analysis of the ability of large language models. MATH 401 and evaluation codes are released at \\url{https://github.com/GanjinZero/math401-llm}.","sentences":["Large language models have emerged abilities including chain-of-thought to answer math word problems step by step.","Solving math word problems not only requires abilities to disassemble problems via chain-of-thought but also needs to calculate arithmetic expressions correctly for each step.","To the best of our knowledge, there is no work to focus on evaluating the arithmetic ability of large language models.","In this work, we propose an arithmetic dataset MATH 401 to test the latest large language models including GPT-4, ChatGPT, InstrctGPT, Galactica, and LLaMA with various arithmetic expressions and provide a detailed analysis of the ability of large language models.","MATH 401 and evaluation codes are released at \\url{https://github.com/GanjinZero/math401-llm}."],"url":"http://arxiv.org/abs/2304.02015v1"}
{"created":"2023-03-16","title":"Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential","abstract":"The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report. ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt. Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports. Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential.","sentences":["The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities.","In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare.","Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study.","According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation.","In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report.","ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt.","Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports.","Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential."],"url":"http://arxiv.org/abs/2303.09038v3"}
{"created":"2023-03-15","title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models","abstract":"Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose \"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several existing baselines and show that in sentence hallucination detection, our approach has AUC-PR scores comparable to grey-box methods, while SelfCheckGPT is best at passage factuality assessment.","sentences":["Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts.","However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output.","Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules.","In this work, we propose \"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database.","SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts.","However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another.","We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages.","We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality.","We compare our approach to several existing baselines and show that in sentence hallucination detection, our approach has AUC-PR scores comparable to grey-box methods, while SelfCheckGPT is best at passage factuality assessment."],"url":"http://arxiv.org/abs/2303.08896v1"}
{"created":"2023-03-15","title":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation","abstract":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs. Our model and code are available at https://github.com/microsoft/LMOps.","sentences":["Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization.","We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input.","Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.","Our model and code are available at https://github.com/microsoft/LMOps."],"url":"http://arxiv.org/abs/2303.08518v2"}
{"created":"2023-03-15","title":"ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark","abstract":"ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted a lot of attention due to its surprisingly strong ability in answering follow-up questions. In this report, we aim to evaluate ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g., GECToR). By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences. We inspect the outputs and find that ChatGPT goes beyond one-by-one corrections. Specifically, it prefers to change the surface expression of certain phrases or sentence structure while maintaining grammatical correctness. Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections. These results demonstrate that ChatGPT is severely under-estimated by the automatic evaluation metrics and could be a promising tool for GEC.","sentences":["ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted a lot of attention due to its surprisingly strong ability in answering follow-up questions.","In this report, we aim to evaluate ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g., GECToR).","By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences.","We inspect the outputs and find that ChatGPT goes beyond one-by-one corrections.","Specifically, it prefers to change the surface expression of certain phrases or sentence structure while maintaining grammatical correctness.","Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections.","These results demonstrate that ChatGPT is severely under-estimated by the automatic evaluation metrics and could be a promising tool for GEC."],"url":"http://arxiv.org/abs/2303.13648v1"}
{"created":"2023-03-14","title":"NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions","abstract":"The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks for the NeurIPS 2022 competition. Furthermore, we investigate and compare the performance of the ChatGPT large language model against the winning solutions. Through this competition, we hope to bring interest towards the development of novel machine learning applications and datasets for optimization modeling.","sentences":["The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description.","Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language.","We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities.","The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems.","The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers.","In this report, we present the LP word problem dataset and shared tasks for the NeurIPS 2022 competition.","Furthermore, we investigate and compare the performance of the ChatGPT large language model against the winning solutions.","Through this competition, we hope to bring interest towards the development of novel machine learning applications and datasets for optimization modeling."],"url":"http://arxiv.org/abs/2303.08233v2"}
{"created":"2023-03-14","title":"Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions","abstract":"ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding. Nevertheless, the performance and limitations of the model still need to be extensively evaluated. As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models. Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning. To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions. Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning. Following the black-box testing specifications of CheckList proposed by Ribeiro et.al, we develop an evaluation method to measure the functionality and reliability of ChatGPT in reasoning for answering complex questions. We use the proposed framework to evaluate the performance of ChatGPT in question answering on 8 real-world KB-based CQA datasets, including 6 English and 2 multilingual datasets, with a total of approximately 190,000 test cases. We compare the evaluation results of ChatGPT, GPT-3.5, GPT-3, and FLAN-T5 to identify common long-term problems in LLMs. The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT.","sentences":["ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding.","Nevertheless, the performance and limitations of the model still need to be extensively evaluated.","As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models.","Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning.","To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions.","Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning.","Following the black-box testing specifications of CheckList proposed by Ribeiro et.al, we develop an evaluation method to measure the functionality and reliability of ChatGPT in reasoning for answering complex questions.","We use the proposed framework to evaluate the performance of ChatGPT in question answering on 8 real-world KB-based CQA datasets, including 6 English and 2 multilingual datasets, with a total of approximately 190,000 test cases.","We compare the evaluation results of ChatGPT, GPT-3.5, GPT-3, and FLAN-T5 to identify common long-term problems in LLMs.","The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT."],"url":"http://arxiv.org/abs/2303.07992v1"}
{"created":"2023-03-14","title":"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences","abstract":"As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent. This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.","sentences":["As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis.","Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences.","To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content.","In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses.","ChatGPT is then instructed to rank the responses generated by these models.","The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent.","This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks."],"url":"http://arxiv.org/abs/2303.07610v1"}
{"created":"2023-03-13","title":"Thinking Upstream: Ethics and Policy Opportunities in AI Supply Chains","abstract":"After children were pictured sewing its running shoes in the early 1990s, Nike at first disavowed the \"working conditions in its suppliers' factories\", before public pressure led them to take responsibility for ethics in their upstream supply chain. In 2023, OpenAI responded to criticism that Kenyan workers were paid less than $2 per hour to filter traumatic content from its ChatGPT model by stating in part that it had outsourced the work to a subcontractor, who managed workers' payment and mental health concerns. In this position paper, we argue that policy interventions for AI Ethics must consider AI as a supply chain problem, given how the political economy and intra-firm relations structure AI production, in particular examining opportunities upstream.","sentences":["After children were pictured sewing its running shoes in the early 1990s, Nike at first disavowed the \"working conditions in its suppliers' factories\", before public pressure led them to take responsibility for ethics in their upstream supply chain.","In 2023, OpenAI responded to criticism that Kenyan workers were paid less than $2 per hour to filter traumatic content from its ChatGPT model by stating in part that it had outsourced the work to a subcontractor, who managed workers' payment and mental health concerns.","In this position paper, we argue that policy interventions for AI Ethics must consider AI as a supply chain problem, given how the political economy and intra-firm relations structure AI production, in particular examining opportunities upstream."],"url":"http://arxiv.org/abs/2303.07529v1"}
{"created":"2023-03-13","title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in","abstract":"ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","sentences":["ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models.","Traditional zero-shot learning methods are constrained by the training dataset.","To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements.","ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor.","To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively.","We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation.","Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset."],"url":"http://arxiv.org/abs/2303.06832v2"}
{"created":"2023-03-12","title":"ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions","abstract":"Asking insightful questions is crucial for acquiring knowledge and expanding our understanding of the world. However, the importance of questioning has been largely overlooked in AI research, where models have been primarily developed to answer questions. With the recent advancements of large language models (LLMs) like ChatGPT, we discover their capability to ask high-quality questions when provided with a suitable prompt. This discovery presents a new opportunity to develop an automatic questioning system. In this paper, we introduce ChatCaptioner, a novel automatic-questioning method deployed in image captioning. Here, ChatGPT is prompted to ask a series of informative questions about images to BLIP-2, a strong vision question-answering model. By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions. We conduct human-subject evaluations on common image caption datasets such as COCO, Conceptual Caption, and WikiArt, and compare ChatCaptioner with BLIP-2 as well as ground truth. Our results demonstrate that ChatCaptioner's captions are significantly more informative, receiving three times as many votes from human evaluators for providing the most image information. Besides, ChatCaptioner identifies 53% more objects within the image than BLIP-2 alone measured by WordNet synset matching. Code is available at https://github.com/Vision-CAIR/ChatCaptioner","sentences":["Asking insightful questions is crucial for acquiring knowledge and expanding our understanding of the world.","However, the importance of questioning has been largely overlooked in AI research, where models have been primarily developed to answer questions.","With the recent advancements of large language models (LLMs) like ChatGPT, we discover their capability to ask high-quality questions when provided with a suitable prompt.","This discovery presents a new opportunity to develop an automatic questioning system.","In this paper, we introduce ChatCaptioner, a novel automatic-questioning method deployed in image captioning.","Here, ChatGPT is prompted to ask a series of informative questions about images to BLIP-2, a strong vision question-answering model.","By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions.","We conduct human-subject evaluations on common image caption datasets such as COCO, Conceptual Caption, and WikiArt, and compare ChatCaptioner with BLIP-2 as well as ground truth.","Our results demonstrate that ChatCaptioner's captions are significantly more informative, receiving three times as many votes from human evaluators for providing the most image information.","Besides, ChatCaptioner identifies 53% more objects within the image than BLIP-2 alone measured by WordNet synset matching.","Code is available at https://github.com/Vision-CAIR/ChatCaptioner"],"url":"http://arxiv.org/abs/2303.06594v1"}
{"created":"2023-03-12","title":"A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability","abstract":"This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.","sentences":["This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability.","Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance.","We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities.","Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive.","Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%, demonstrating its potential for use in practical applications.","To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql."],"url":"http://arxiv.org/abs/2303.13547v1"}
{"created":"2023-03-11","title":"Context-based Ontology Modelling for Database: Enabling ChatGPT for Semantic Database Management","abstract":"This research paper explores the use of ChatGPT in database management. ChatGPT, an AI-powered chatbot, has limitations in performing tasks related to database management due to the lack of standardized vocabulary and grammar for representing database semantics. To address this limitation, the paper proposes a solution that involves developing a set of syntaxes that can represent database semantics in natural language. The syntax is used to convert database schemas into natural language formats, providing a new application of ChatGPT in database management. The proposed solution is demonstrated through a case study where ChatGPT is used to perform two tasks, semantic integration, and tables joining. Results demonstrate that the use of semantic database representations produces more precise outcomes and avoids common mistakes compared to cases with no semantic representation. The proposed method has the potential to speed up the database management process, reduce the level of understanding required for database domain knowledge, and enable automatic database operations without accessing the actual data, thus illuminating privacy protection concerns when using AI. This paper provides a promising new direction for research in the field of AI-based database management.","sentences":["This research paper explores the use of ChatGPT in database management.","ChatGPT, an AI-powered chatbot, has limitations in performing tasks related to database management due to the lack of standardized vocabulary and grammar for representing database semantics.","To address this limitation, the paper proposes a solution that involves developing a set of syntaxes that can represent database semantics in natural language.","The syntax is used to convert database schemas into natural language formats, providing a new application of ChatGPT in database management.","The proposed solution is demonstrated through a case study where ChatGPT is used to perform two tasks, semantic integration, and tables joining.","Results demonstrate that the use of semantic database representations produces more precise outcomes and avoids common mistakes compared to cases with no semantic representation.","The proposed method has the potential to speed up the database management process, reduce the level of understanding required for database domain knowledge, and enable automatic database operations without accessing the actual data, thus illuminating privacy protection concerns when using AI.","This paper provides a promising new direction for research in the field of AI-based database management."],"url":"http://arxiv.org/abs/2303.07351v1"}
{"created":"2023-03-11","title":"ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design","abstract":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","sentences":["This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented.","This paper provides two contributions to research on using LLMs for software engineering.","First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve.","Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design."],"url":"http://arxiv.org/abs/2303.07839v1"}
{"created":"2023-03-11","title":"Art-ificial Intelligence: The Effect of AI Disclosure on Evaluations of Creative Content","abstract":"The emergence of generative AI technologies, such as OpenAI's ChatGPT chatbot, has expanded the scope of tasks that AI tools can accomplish and enabled AI-generated creative content. In this study, we explore how disclosure regarding the use of AI in the creation of creative content affects human evaluation of such content. In a series of pre-registered experimental studies, we show that AI disclosure has no meaningful effect on evaluation either for creative or descriptive short stories, but that AI disclosure has a negative effect on evaluations for emotionally evocative poems written in the first person. We interpret this result to suggest that reactions to AI-generated content may be negative when the content is viewed as distinctly \"human.\" We discuss the implications of this work and outline planned pathways of research to better understand whether and when AI disclosure may affect the evaluation of creative content.","sentences":["The emergence of generative AI technologies, such as OpenAI's ChatGPT chatbot, has expanded the scope of tasks that AI tools can accomplish and enabled AI-generated creative content.","In this study, we explore how disclosure regarding the use of AI in the creation of creative content affects human evaluation of such content.","In a series of pre-registered experimental studies, we show that AI disclosure has no meaningful effect on evaluation either for creative or descriptive short stories, but that AI disclosure has a negative effect on evaluations for emotionally evocative poems written in the first person.","We interpret this result to suggest that reactions to AI-generated content may be negative when the content is viewed as distinctly \"human.\"","We discuss the implications of this work and outline planned pathways of research to better understand whether and when AI disclosure may affect the evaluation of creative content."],"url":"http://arxiv.org/abs/2303.06217v1"}
{"created":"2023-03-11","title":"Consistency Analysis of ChatGPT","abstract":"ChatGPT, a question-and-answer dialogue system based on a large language model, has gained huge popularity since its introduction. Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, including the law, medical, and finance domains, adding extra support to the claim that AI now can assist and, even, replace humans in industrial fields. Others, however, doubt its reliability and trustworthiness. In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent behaviours. Our findings suggest that, although ChatGPT seems to achieve an improved language understanding ability, it still fails to generate logically correct predictions frequently. Hence, while it is true that ChatGPT is an impressive and promising new technique, we conclude that its usage in real-world applications without thorough human inspection requires further consideration, especially for risk-sensitive areas.","sentences":["ChatGPT, a question-and-answer dialogue system based on a large language model, has gained huge popularity since its introduction.","Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, including the law, medical, and finance domains, adding extra support to the claim that AI now can assist and, even, replace humans in industrial fields.","Others, however, doubt its reliability and trustworthiness.","In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent behaviours.","Our findings suggest that, although ChatGPT seems to achieve an improved language understanding ability, it still fails to generate logically correct predictions frequently.","Hence, while it is true that ChatGPT is an impressive and promising new technique, we conclude that its usage in real-world applications without thorough human inspection requires further consideration, especially for risk-sensitive areas."],"url":"http://arxiv.org/abs/2303.06273v1"}
{"created":"2023-03-10","title":"ChatGPT as the Transportation Equity Information Source for Scientific Writing","abstract":"Transportation equity is an interdisciplinary agenda that requires both transportation and social inputs. Traditionally, transportation equity information are sources from public libraries, conferences, televisions, social media, among other. Artificial intelligence (AI) tools including advanced language models such as ChatGPT are becoming favorite information sources. However, their credibility has not been well explored. This study explored the content and usefulness of ChatGPT-generated information related to transportation equity. It utilized 152 papers retrieved through the Web of Science (WoS) repository. The prompt was crafted for ChatGPT to provide an abstract given the title of the paper. The ChatGPT-based abstracts were then compared to human-written abstracts using statistical tools and unsupervised text mining. The results indicate that a weak similarity between ChatGPT and human-written abstracts. On average, the human-written abstracts and ChatGPT generated abstracts were about 58% similar, with a maximum and minimum of 97% and 1.4%, respectively. The keywords from the abstracts of papers with over the mean similarity score were more likely to be similar whereas those from below the average score were less likely to be similar. Themes with high similarity scores include access, public transit, and policy, among others. Further, clear differences in the key pattern of clusters for high and low similarity score abstracts was observed. Contrarily, the findings from collocated keywords were inconclusive. The study findings suggest that ChatGPT has the potential to be a source of transportation equity information. However, currently, a great amount of attention is needed before a user can utilize materials from ChatGPT","sentences":["Transportation equity is an interdisciplinary agenda that requires both transportation and social inputs.","Traditionally, transportation equity information are sources from public libraries, conferences, televisions, social media, among other.","Artificial intelligence (AI) tools including advanced language models such as ChatGPT are becoming favorite information sources.","However, their credibility has not been well explored.","This study explored the content and usefulness of ChatGPT-generated information related to transportation equity.","It utilized 152 papers retrieved through the Web of Science (WoS) repository.","The prompt was crafted for ChatGPT to provide an abstract given the title of the paper.","The ChatGPT-based abstracts were then compared to human-written abstracts using statistical tools and unsupervised text mining.","The results indicate that a weak similarity between ChatGPT and human-written abstracts.","On average, the human-written abstracts and ChatGPT generated abstracts were about 58% similar, with a maximum and minimum of 97% and 1.4%, respectively.","The keywords from the abstracts of papers with over the mean similarity score were more likely to be similar whereas those from below the average score were less likely to be similar.","Themes with high similarity scores include access, public transit, and policy, among others.","Further, clear differences in the key pattern of clusters for high and low similarity score abstracts was observed.","Contrarily, the findings from collocated keywords were inconclusive.","The study findings suggest that ChatGPT has the potential to be a source of transportation equity information.","However, currently, a great amount of attention is needed before a user can utilize materials from ChatGPT"],"url":"http://arxiv.org/abs/2303.11158v1"}
{"created":"2023-03-10","title":"Does ChatGPT resemble humans in language use?","abstract":"Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities according to verb semantics, and accessed different meanings and retrieved different words depending on the identity of its interlocutor. However, unlike humans, it did not prefer using shorter words to convey less informative content and it did not use context to disambiguate syntactic ambiguities. We discuss how these convergences and divergences may occur in the transformer architecture. Overall, these experiments demonstrate that LLM-driven chatbots like ChatGPT are capable of mimicking human language processing to a great extent, and that they have the potential to provide insights into how people learn and use language.","sentences":["Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language.","However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use.","Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language.","We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment.","In 10 of them, ChatGPT replicated the human pattern of language use.","It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities according to verb semantics, and accessed different meanings and retrieved different words depending on the identity of its interlocutor.","However, unlike humans, it did not prefer using shorter words to convey less informative content and it did not use context to disambiguate syntactic ambiguities.","We discuss how these convergences and divergences may occur in the transformer architecture.","Overall, these experiments demonstrate that LLM-driven chatbots like ChatGPT are capable of mimicking human language processing to a great extent, and that they have the potential to provide insights into how people learn and use language."],"url":"http://arxiv.org/abs/2303.08014v1"}
{"created":"2023-03-09","title":"Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback","abstract":"Large language models (LLMs) are used to generate content for a wide range of tasks, and are set to reach a growing audience in coming years due to integration in product interfaces like ChatGPT or search engines like Bing. This intensifies the need to ensure that models are aligned with human preferences and do not produce unsafe, inaccurate or toxic outputs. While alignment techniques like reinforcement learning with human feedback (RLHF) and red-teaming can mitigate some safety concerns and improve model capabilities, it is unlikely that an aggregate fine-tuning process can adequately represent the full range of users' preferences and values. Different people may legitimately disagree on their preferences for language and conversational norms, as well as on values or ideologies which guide their communication. Personalising LLMs through micro-level preference learning processes may result in models that are better aligned with each user. However, there are several normative challenges in defining the bounds of a societally-acceptable and safe degree of personalisation. In this paper, we ask how, and in what ways, LLMs should be personalised. First, we review literature on current paradigms for aligning LLMs with human feedback, and identify issues including (i) a lack of clarity regarding what alignment means; (ii) a tendency of technology providers to prescribe definitions of inherently subjective preferences and values; and (iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in who we are really aligning to. Second, we present a taxonomy of benefits and risks associated with personalised LLMs, for individuals and society at large. Finally, we propose a three-tiered policy framework that allows users to experience the benefits of personalised alignment, while restraining unsafe and undesirable LLM-behaviours within (supra-)national and organisational bounds.","sentences":["Large language models (LLMs) are used to generate content for a wide range of tasks, and are set to reach a growing audience in coming years due to integration in product interfaces like ChatGPT or search engines like Bing.","This intensifies the need to ensure that models are aligned with human preferences and do not produce unsafe, inaccurate or toxic outputs.","While alignment techniques like reinforcement learning with human feedback (RLHF) and red-teaming can mitigate some safety concerns and improve model capabilities, it is unlikely that an aggregate fine-tuning process can adequately represent the full range of users' preferences and values.","Different people may legitimately disagree on their preferences for language and conversational norms, as well as on values or ideologies which guide their communication.","Personalising LLMs through micro-level preference learning processes may result in models that are better aligned with each user.","However, there are several normative challenges in defining the bounds of a societally-acceptable and safe degree of personalisation.","In this paper, we ask how, and in what ways, LLMs should be personalised.","First, we review literature on current paradigms for aligning LLMs with human feedback, and identify issues including (i) a lack of clarity regarding what alignment means; (ii) a tendency of technology providers to prescribe definitions of inherently subjective preferences and values; and (iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in who we are really aligning to.","Second, we present a taxonomy of benefits and risks associated with personalised LLMs, for individuals and society at large.","Finally, we propose a three-tiered policy framework that allows users to experience the benefits of personalised alignment, while restraining unsafe and undesirable LLM-behaviours within (supra-)national and organisational bounds."],"url":"http://arxiv.org/abs/2303.05453v1"}
{"created":"2023-03-09","title":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data","abstract":"Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","sentences":["Advanced large language models like ChatGPT have gained considerable attention recently, including among students.","However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT.","To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023.","TikTok is a rapidly growing social media platform popular among individuals under 30.","Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views.","Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code.","In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors.","This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading.","What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data."],"url":"http://arxiv.org/abs/2303.05349v1"}
{"created":"2023-03-09","title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction","abstract":"Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demonstration examples. Despite their successes in NLP tasks, no investigation has been conducted to assess the ability of LLMs to perform document information extraction (DIE) using in-context learning. Applying LLMs to DIE poses two challenges: the modality and task gap. To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to perform DIE with different types of demonstration examples. Specifically, we extract the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances. We design demonstrations describing relationships that enable LLMs to understand positional relationships. We introduce formatting demonstrations for easy answer extraction. Additionally, the framework improves diverse demonstrations by updating them iteratively. Our experiments on three widely used benchmark datasets demonstrate that the ICL-D3IE framework enables GPT-3/ChatGPT to achieve superior performance when compared to previous pre-trained methods fine-tuned with full training in both the in-distribution (ID) setting and in the out-of-distribution (OOD) setting.","sentences":["Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demonstration examples.","Despite their successes in NLP tasks, no investigation has been conducted to assess the ability of LLMs to perform document information extraction (DIE) using in-context learning.","Applying LLMs to DIE poses two challenges: the modality and task gap.","To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to perform DIE with different types of demonstration examples.","Specifically, we extract the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances.","We design demonstrations describing relationships that enable LLMs to understand positional relationships.","We introduce formatting demonstrations for easy answer extraction.","Additionally, the framework improves diverse demonstrations by updating them iteratively.","Our experiments on three widely used benchmark datasets demonstrate that the ICL-D3IE framework enables GPT-3/ChatGPT to achieve superior performance when compared to previous pre-trained methods fine-tuned with full training in both the in-distribution (ID) setting and in the out-of-distribution (OOD) setting."],"url":"http://arxiv.org/abs/2303.05063v2"}
{"created":"2023-03-08","title":"The Carbon Emissions of Writing and Illustrating Are Lower for AI than for Humans","abstract":"As AI systems proliferate, their greenhouse gas emissions are an increasingly important concern for human societies. We analyze the emissions of several AI systems (ChatGPT, BLOOM, DALL-E2, Midjourney) relative to those of humans completing the same tasks. We find that an AI writing a page of text emits 130 to 1500 times less CO2e than a human doing so. Similarly, an AI creating an image emits 310 to 2900 times less. Emissions analysis do not account for social impacts such as professional displacement, legality, and rebound effects. In addition, AI is not a substitute for all human tasks. Nevertheless, at present, the use of AI holds the potential to carry out several major activities at much lower emission levels than can humans.","sentences":["As AI systems proliferate, their greenhouse gas emissions are an increasingly important concern for human societies.","We analyze the emissions of several AI systems (ChatGPT, BLOOM, DALL-E2, Midjourney) relative to those of humans completing the same tasks.","We find that an AI writing a page of text emits 130 to 1500 times less CO2e than a human doing so.","Similarly, an AI creating an image emits 310 to 2900 times less.","Emissions analysis do not account for social impacts such as professional displacement, legality, and rebound effects.","In addition, AI is not a substitute for all human tasks.","Nevertheless, at present, the use of AI holds the potential to carry out several major activities at much lower emission levels than can humans."],"url":"http://arxiv.org/abs/2303.06219v1"}
{"created":"2023-03-08","title":"FaceChat: An Emotion-Aware Face-to-face Dialogue Framework","abstract":"While current dialogue systems like ChatGPT have made significant advancements in text-based interactions, they often overlook the potential of other modalities in enhancing the overall user experience. We present FaceChat, a web-based dialogue framework that enables emotionally-sensitive and face-to-face conversations. By seamlessly integrating cutting-edge technologies in natural language processing, computer vision, and speech processing, FaceChat delivers a highly immersive and engaging user experience. FaceChat framework has a wide range of potential applications, including counseling, emotional support, and personalized customer service. The system is designed to be simple and flexible as a platform for future researchers to advance the field of multimodal dialogue systems. The code is publicly available at https://github.com/qywu/FaceChat.","sentences":["While current dialogue systems like ChatGPT have made significant advancements in text-based interactions, they often overlook the potential of other modalities in enhancing the overall user experience.","We present FaceChat, a web-based dialogue framework that enables emotionally-sensitive and face-to-face conversations.","By seamlessly integrating cutting-edge technologies in natural language processing, computer vision, and speech processing, FaceChat delivers a highly immersive and engaging user experience.","FaceChat framework has a wide range of potential applications, including counseling, emotional support, and personalized customer service.","The system is designed to be simple and flexible as a platform for future researchers to advance the field of multimodal dialogue systems.","The code is publicly available at https://github.com/qywu/FaceChat."],"url":"http://arxiv.org/abs/2303.07316v1"}
{"created":"2023-03-08","title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","abstract":"ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.","sentences":["ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains.","However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world.","At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs.","To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps.","3) providing feedback and asking for corrected results.","We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback.","Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models.","Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}."],"url":"http://arxiv.org/abs/2303.04671v1"}
{"created":"2023-03-08","title":"ChatGPT Participates in a Computer Science Exam","abstract":"We asked ChatGPT to participate in an undergraduate computer science exam on ''Algorithms and Data Structures''. The program was evaluated on the entire exam as posed to the students. We hand-copied its answers onto an exam sheet, which was subsequently graded in a blind setup alongside those of 200 participating students. We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points. This impressive performance indicates that ChatGPT can indeed succeed in challenging tasks like university exams. At the same time, the questions in our exam are structurally similar to those of other exams, solved homework problems, and teaching materials that can be found online and might have been part of ChatGPT's training data. Therefore, it would be inadequate to conclude from this experiment that ChatGPT has any understanding of computer science. We also assess the improvements brought by GPT-4. We find that GPT-4 would have obtained about 17\\% more exam points than GPT-3.5, reaching the performance of the average student. The transcripts of our conversations with ChatGPT are available at \\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire graded exam is in the appendix of this paper.","sentences":["We asked ChatGPT to participate in an undergraduate computer science exam on ''Algorithms and Data Structures''.","The program was evaluated on the entire exam as posed to the students.","We hand-copied its answers onto an exam sheet, which was subsequently graded in a blind setup alongside those of 200 participating students.","We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points.","This impressive performance indicates that ChatGPT can indeed succeed in challenging tasks like university exams.","At the same time, the questions in our exam are structurally similar to those of other exams, solved homework problems, and teaching materials that can be found online and might have been part of ChatGPT's training data.","Therefore, it would be inadequate to conclude from this experiment that ChatGPT has any understanding of computer science.","We also assess the improvements brought by GPT-4.","We find that GPT-4 would have obtained about 17\\% more exam points than GPT-3.5, reaching the performance of the average student.","The transcripts of our conversations with ChatGPT are available at \\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire graded exam is in the appendix of this paper."],"url":"http://arxiv.org/abs/2303.09461v2"}
{"created":"2023-03-08","title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","abstract":"Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","sentences":["Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT.","These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation.","However, their effectiveness in the healthcare sector remains uncertain.","In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction.","However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API.","To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task.","Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task.","Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns.","In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining."],"url":"http://arxiv.org/abs/2303.04360v1"}
{"created":"2023-03-07","title":"Many bioinformatics programming tasks can be automated with ChatGPT","abstract":"Computer programming is a fundamental tool for life scientists, allowing them to carry out many essential research tasks. However, despite a variety of educational efforts, learning to write code can be a challenging endeavor for both researchers and students in life science disciplines. Recent advances in artificial intelligence have made it possible to translate human-language prompts to functional code, raising questions about whether these technologies can aid (or replace) life scientists' efforts to write code. Using 184 programming exercises from an introductory-bioinformatics course, we evaluated the extent to which one such model -- OpenAI's ChatGPT -- can successfully complete basic- to moderate-level programming tasks. On its first attempt, ChatGPT solved 139 (75.5%) of the exercises. For the remaining exercises, we provided natural-language feedback to the model, prompting it to try different approaches. Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of the exercises. These findings have important implications for life-sciences research and education. For many programming tasks, researchers no longer need to write code from scratch. Instead, machine-learning models may produce usable solutions. Instructors may need to adapt their pedagogical approaches and assessment techniques to account for these new capabilities that are available to the general public.","sentences":["Computer programming is a fundamental tool for life scientists, allowing them to carry out many essential research tasks.","However, despite a variety of educational efforts, learning to write code can be a challenging endeavor for both researchers and students in life science disciplines.","Recent advances in artificial intelligence have made it possible to translate human-language prompts to functional code, raising questions about whether these technologies can aid (or replace) life scientists' efforts to write code.","Using 184 programming exercises from an introductory-bioinformatics course, we evaluated the extent to which one such model -- OpenAI's ChatGPT -- can successfully complete basic- to moderate-level programming tasks.","On its first attempt, ChatGPT solved 139 (75.5%) of the exercises.","For the remaining exercises, we provided natural-language feedback to the model, prompting it to try different approaches.","Within 7 or fewer attempts, ChatGPT solved 179 (97.3%) of the exercises.","These findings have important implications for life-sciences research and education.","For many programming tasks, researchers no longer need to write code from scratch.","Instead, machine-learning models may produce usable solutions.","Instructors may need to adapt their pedagogical approaches and assessment techniques to account for these new capabilities that are available to the general public."],"url":"http://arxiv.org/abs/2303.13528v1"}
{"created":"2023-03-07","title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT","abstract":"Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society. As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models. The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information. In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results. With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation. This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.","sentences":["Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society.","As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance.","In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models.","The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace.","AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information.","In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results.","With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation.","This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction.","From the perspective of unimodality, we introduce the generation tasks and relative models of text and image.","From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above.","Finally, we discuss the existing open problems and future challenges in AIGC."],"url":"http://arxiv.org/abs/2303.04226v1"}
{"created":"2023-03-07","title":"Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering -- Example of ChatGPT","abstract":"There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI). ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions. These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future.","sentences":["There has been a growing effort to replace hand extraction of data from research papers with automated data extraction based on natural language processing (NLP), language models (LMs), and recently, large language models (LLMs).","Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding.","In this work we propose the ChatExtract method that can fully automate very accurate data extraction with essentially no initial effort or background using an advanced conversational LLM (or AI).","ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract data, and assure its correctness through a series of follow-up questions.","These follow-up questions address a critical challenge associated with LLMs - their tendency to provide factually inaccurate responses.","ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction.","In tests on materials data we find precision and recall both over 90% from the best conversational LLMs, likely rivaling or exceeding human accuracy in many cases.","We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts.","These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability and accuracy are likely to replace other methods of data extraction in the near future."],"url":"http://arxiv.org/abs/2303.05352v1"}
{"created":"2023-03-07","title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study","abstract":"Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of NLG models is an arduous task and previous statistical metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the generation of NLG models. We conduct experiments on three widely-used NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with golden human judgments. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.","sentences":["Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community.","Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics.","However, the ability of ChatGPT to serve as an evaluation metric is still underexplored.","Considering assessing the quality of NLG models is an arduous task and previous statistical metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric.","In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric.","In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the generation of NLG models.","We conduct experiments on three widely-used NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks).","Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with golden human judgments.","We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric."],"url":"http://arxiv.org/abs/2303.04048v1"}
{"created":"2023-03-07","title":"Making a Computational Attorney","abstract":"This \"blue sky idea\" paper outlines the opportunities and challenges in data mining and machine learning involving making a computational attorney -- an intelligent software agent capable of helping human lawyers with a wide range of complex high-level legal tasks such as drafting legal briefs for the prosecution or defense in court. In particular, we discuss what a ChatGPT-like Large Legal Language Model (L$^3$M) can and cannot do today, which will inspire researchers with promising short-term and long-term research objectives.","sentences":["This \"blue sky idea\" paper outlines the opportunities and challenges in data mining and machine learning involving making a computational attorney -- an intelligent software agent capable of helping human lawyers with a wide range of complex high-level legal tasks such as drafting legal briefs for the prosecution or defense in court.","In particular, we discuss what a ChatGPT-like Large Legal Language Model (L$^3$M) can and cannot do today, which will inspire researchers with promising short-term and long-term research objectives."],"url":"http://arxiv.org/abs/2303.05383v1"}
{"created":"2023-03-07","title":"ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification","abstract":"ChatGPT has shown strong capabilities in natural language generation tasks, which naturally leads researchers to explore where its abilities end. In this paper, we examine whether ChatGPT can be used for zero-shot text classification, more specifically, automatic genre identification. We compare ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on datasets, manually annotated with genres. The models are compared on test sets in two languages: English and Slovenian. Results show that ChatGPT outperforms the fine-tuned model when applied to the dataset which was not seen before by either of the models. Even when applied on Slovenian language as an under-resourced language, ChatGPT's performance is no worse than when applied to English. However, if the model is fully prompted in Slovenian, the performance drops significantly, showing the current limitations of ChatGPT usage on smaller languages. The presented results lead us to questioning whether this is the beginning of an end of laborious manual annotation campaigns even for smaller languages, such as Slovenian.","sentences":["ChatGPT has shown strong capabilities in natural language generation tasks, which naturally leads researchers to explore where its abilities end.","In this paper, we examine whether ChatGPT can be used for zero-shot text classification, more specifically, automatic genre identification.","We compare ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on datasets, manually annotated with genres.","The models are compared on test sets in two languages: English and Slovenian.","Results show that ChatGPT outperforms the fine-tuned model when applied to the dataset which was not seen before by either of the models.","Even when applied on Slovenian language as an under-resourced language, ChatGPT's performance is no worse than when applied to English.","However, if the model is fully prompted in Slovenian, the performance drops significantly, showing the current limitations of ChatGPT usage on smaller languages.","The presented results lead us to questioning whether this is the beginning of an end of laborious manual annotation campaigns even for smaller languages, such as Slovenian."],"url":"http://arxiv.org/abs/2303.03953v2"}
{"created":"2023-03-07","title":"Exploring the Feasibility of ChatGPT for Event Extraction","abstract":"Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text. However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain. The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning. While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction. Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas. To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments. Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios. Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience. Besides, ChatGPT is highly sensitive to different prompt styles.","sentences":["Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text.","However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain.","The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning.","While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction.","Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas.","To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments.","Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios.","Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience.","Besides, ChatGPT is highly sensitive to different prompt styles."],"url":"http://arxiv.org/abs/2303.03836v2"}
{"created":"2023-03-06","title":"ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?","abstract":"ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response. As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM. We present and validate these potential transportation applications equipped by LLM. To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case. Despite the potential benefits, challenges related to data privacy, data quality, and model bias must be considered. Overall, the use of LLM in intelligent transport systems holds promise for more efficient, intelligent, and sustainable transportation systems that further improve daily life around the world.","sentences":["ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters.","ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response.","As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems.","This paper explores the future applications of LLM in addressing key transportation problems.","By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM.","We present and validate these potential transportation applications equipped by LLM.","To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case.","Despite the potential benefits, challenges related to data privacy, data quality, and model bias must be considered.","Overall, the use of LLM in intelligent transport systems holds promise for more efficient, intelligent, and sustainable transportation systems that further improve daily life around the world."],"url":"http://arxiv.org/abs/2303.05382v2"}
{"created":"2023-03-06","title":"Perspectives on the Social Impacts of Reinforcement Learning with Human Feedback","abstract":"Is it possible for machines to think like humans? And if it is, how should we go about teaching them to do so? As early as 1950, Alan Turing stated that we ought to teach machines in the way of teaching a child. Reinforcement learning with human feedback (RLHF) has emerged as a strong candidate toward allowing agents to learn from human feedback in a naturalistic manner. RLHF is distinct from traditional reinforcement learning as it provides feedback from a human teacher in addition to a reward signal. It has been catapulted into public view by multiple high-profile AI applications, including OpenAI's ChatGPT, DeepMind's Sparrow, and Anthropic's Claude. These highly capable chatbots are already overturning our understanding of how AI interacts with humanity. The wide applicability and burgeoning success of RLHF strongly motivate the need to evaluate its social impacts. In light of recent developments, this paper considers an important question: can RLHF be developed and used without negatively affecting human societies? Our objectives are threefold: to provide a systematic study of the social effects of RLHF; to identify key social and ethical issues of RLHF; and to discuss social impacts for stakeholders. Although text-based applications of RLHF have received much attention, it is crucial to consider when evaluating its social implications the diverse range of areas to which it may be deployed. We describe seven primary ways in which RLHF-based technologies will affect society by positively transforming human experiences with AI. This paper ultimately proposes that RLHF has potential to net positively impact areas of misinformation, AI value-alignment, bias, AI access, cross-cultural dialogue, industry, and workforce. As RLHF raises concerns that echo those of existing AI technologies, it will be important for all to be aware and intentional in the adoption of RLHF.","sentences":["Is it possible for machines to think like humans?","And if it is, how should we go about teaching them to do so?","As early as 1950, Alan Turing stated that we ought to teach machines in the way of teaching a child.","Reinforcement learning with human feedback (RLHF) has emerged as a strong candidate toward allowing agents to learn from human feedback in a naturalistic manner.","RLHF is distinct from traditional reinforcement learning as it provides feedback from a human teacher in addition to a reward signal.","It has been catapulted into public view by multiple high-profile AI applications, including OpenAI's ChatGPT, DeepMind's Sparrow, and Anthropic's Claude.","These highly capable chatbots are already overturning our understanding of how AI interacts with humanity.","The wide applicability and burgeoning success of RLHF strongly motivate the need to evaluate its social impacts.","In light of recent developments, this paper considers an important question: can RLHF be developed and used without negatively affecting human societies?","Our objectives are threefold: to provide a systematic study of the social effects of RLHF; to identify key social and ethical issues of RLHF; and to discuss social impacts for stakeholders.","Although text-based applications of RLHF have received much attention, it is crucial to consider when evaluating its social implications the diverse range of areas to which it may be deployed.","We describe seven primary ways in which RLHF-based technologies will affect society by positively transforming human experiences with AI.","This paper ultimately proposes that RLHF has potential to net positively impact areas of misinformation, AI value-alignment, bias, AI access, cross-cultural dialogue, industry, and workforce.","As RLHF raises concerns that echo those of existing AI technologies, it will be important for all to be aware and intentional in the adoption of RLHF."],"url":"http://arxiv.org/abs/2303.02891v1"}
{"created":"2023-03-03","title":"Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT","abstract":"ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilise three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results, and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where Word2Vec models achieve worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialised training, however, it is not as good as a specialised model for a downstream task.","sentences":["ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks.","In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection.","We utilise three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words baseline (BoW).","Results show that the RoBERTa trained for a specific downstream task generally has a superior performance.","On the other hand, ChatGPT provides decent results, and is relatively comparable to the Word2Vec and BoW baselines.","ChatGPT further shows robustness against noisy data, where Word2Vec models achieve worse results due to noise.","Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialised training, however, it is not as good as a specialised model for a downstream task."],"url":"http://arxiv.org/abs/2303.03186v1"}
{"created":"2023-03-03","title":"Ask and You Shall Receive (a Graph Drawing): Testing ChatGPT's Potential to Apply Graph Layout Algorithms","abstract":"Large language models (LLMs) have recently taken the world by storm. They can generate coherent text, hold meaningful conversations, and be taught concepts and basic sets of instructions - such as the steps of an algorithm. In this context, we are interested in exploring the application of LLMs to graph drawing algorithms by performing experiments on ChatGPT. These algorithms are used to improve the readability of graph visualizations. The probabilistic nature of LLMs presents challenges to implementing algorithms correctly, but we believe that LLMs' ability to learn from vast amounts of data and apply complex operations may lead to interesting graph drawing results. For example, we could enable users with limited coding backgrounds to use simple natural language to create effective graph visualizations. Natural language specification would make data visualization more accessible and user-friendly for a wider range of users. Exploring LLMs' capabilities for graph drawing can also help us better understand how to formulate complex algorithms for LLMs; a type of knowledge that could transfer to other areas of computer science. Overall, our goal is to shed light on the exciting possibilities of using LLMs for graph drawing while providing a balanced assessment of the challenges and opportunities they present. A free copy of this paper with all supplemental materials required to reproduce our results is available on https://osf.io/n5rxd/?view_only=f09cbc2621f44074810b7d843f1e12f9","sentences":["Large language models (LLMs) have recently taken the world by storm.","They can generate coherent text, hold meaningful conversations, and be taught concepts and basic sets of instructions - such as the steps of an algorithm.","In this context, we are interested in exploring the application of LLMs to graph drawing algorithms by performing experiments on ChatGPT.","These algorithms are used to improve the readability of graph visualizations.","The probabilistic nature of LLMs presents challenges to implementing algorithms correctly, but we believe that LLMs' ability to learn from vast amounts of data and apply complex operations may lead to interesting graph drawing results.","For example, we could enable users with limited coding backgrounds to use simple natural language to create effective graph visualizations.","Natural language specification would make data visualization more accessible and user-friendly for a wider range of users.","Exploring LLMs' capabilities for graph drawing can also help us better understand how to formulate complex algorithms for LLMs; a type of knowledge that could transfer to other areas of computer science.","Overall, our goal is to shed light on the exciting possibilities of using LLMs for graph drawing while providing a balanced assessment of the challenges and opportunities they present.","A free copy of this paper with all supplemental materials required to reproduce our results is available on https://osf.io/n5rxd/?view_only=f09cbc2621f44074810b7d843f1e12f9"],"url":"http://arxiv.org/abs/2303.08819v1"}
{"created":"2023-03-02","title":"UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction","abstract":"This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 \"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure. Our cross-lingual transfer learning approach explores the benefits of using a Head-First Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate. Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available. Our study shows that HeFiT stabilizes training and consistently improves results for pre-trained models that lack domain adaptation to tweets. Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text generation systems to improve zero-shot baseline results. Finally, we examine how possible inconsistencies in the annotated data contribute to cross-lingual interference issues.","sentences":["This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 \"Multilingual Tweet Intimacy Analysis\".","We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure.","Our cross-lingual transfer learning approach explores the benefits of using a Head-First Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate.","Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available.","Our study shows that HeFiT stabilizes training and consistently improves results for pre-trained models that lack domain adaptation to tweets.","Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text generation systems to improve zero-shot baseline results.","Finally, we examine how possible inconsistencies in the annotated data contribute to cross-lingual interference issues."],"url":"http://arxiv.org/abs/2303.01194v1"}
{"created":"2023-03-02","title":"How will Language Modelers like ChatGPT Affect Occupations and Industries?","abstract":"Recent dramatic increases in AI language modeling capabilities has led to many questions about the effect of these technologies on the economy. In this paper we present a methodology to systematically assess the extent to which occupations, industries and geographies are exposed to advances in AI language modeling capabilities. We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers. We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments. We also find a positive correlation between wages and exposure to AI language modeling.","sentences":["Recent dramatic increases in AI language modeling capabilities has led to many questions about the effect of these technologies on the economy.","In this paper we present a methodology to systematically assess the extent to which occupations, industries and geographies are exposed to advances in AI language modeling capabilities.","We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers.","We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments.","We also find a positive correlation between wages and exposure to AI language modeling."],"url":"http://arxiv.org/abs/2303.01157v2"}
{"created":"2023-03-02","title":"AI and the FCI: Can ChatGPT Project an Understanding of Introductory Physics?","abstract":"ChatGPT is a groundbreaking ``chatbot\"--an AI interface built on a large language model that was trained on an enormous corpus of human text to emulate human conversation. Beyond its ability to converse in a plausible way, it has attracted attention for its ability to competently answer questions from the bar exam and from MBA coursework, and to provide useful assistance in writing computer code. These apparent abilities have prompted discussion of ChatGPT as both a threat to the integrity of higher education and conversely as a powerful teaching tool. In this work we present a preliminary analysis of how two versions of ChatGPT (ChatGPT3.5 and ChatGPT4) fare in the field of first-semester university physics, using a modified version of the Force Concept Inventory (FCI) to assess whether it can give correct responses to conceptual physics questions about kinematics and Newtonian dynamics. We demonstrate that, by some measures, ChatGPT3.5 can match or exceed the median performance of a university student who has completed one semester of college physics, though its performance is notably uneven and the results are nuanced. By these same measures, we find that ChatGPT4's performance is approaching the point of being indistinguishable from that of an expert physicist when it comes to introductory mechanics topics. After the completion of our work we became aware of Ref [1], which preceded us to publication and which completes an extensive analysis of the abilities of ChatGPT3.5 in a physics class, including a different modified version of the FCI. We view this work as confirming that portion of their results, and extending the analysis to ChatGPT4, which shows rapid and notable improvement in most, but not all respects.","sentences":["ChatGPT is a groundbreaking ``chatbot\"--an AI interface built on a large language model that was trained on an enormous corpus of human text to emulate human conversation.","Beyond its ability to converse in a plausible way, it has attracted attention for its ability to competently answer questions from the bar exam and from MBA coursework, and to provide useful assistance in writing computer code.","These apparent abilities have prompted discussion of ChatGPT as both a threat to the integrity of higher education and conversely as a powerful teaching tool.","In this work we present a preliminary analysis of how two versions of ChatGPT (ChatGPT3.5 and ChatGPT4) fare in the field of first-semester university physics, using a modified version of the Force Concept Inventory (FCI) to assess whether it can give correct responses to conceptual physics questions about kinematics and Newtonian dynamics.","We demonstrate that, by some measures, ChatGPT3.5 can match or exceed the median performance of a university student who has completed one semester of college physics, though its performance is notably uneven and the results are nuanced.","By these same measures, we find that ChatGPT4's performance is approaching the point of being indistinguishable from that of an expert physicist when it comes to introductory mechanics topics.","After the completion of our work we became aware of Ref [1], which preceded us to publication and which completes an extensive analysis of the abilities of ChatGPT3.5 in a physics class, including a different modified version of the FCI.","We view this work as confirming that portion of their results, and extending the analysis to ChatGPT4, which shows rapid and notable improvement in most, but not all respects."],"url":"http://arxiv.org/abs/2303.01067v2"}
{"created":"2023-03-01","title":"Succinct Representations for Concepts","abstract":"Foundation models like chatGPT have demonstrated remarkable performance on various tasks. However, for many questions, they may produce false answers that look accurate. How do we train the model to precisely understand the concepts? In this paper, we introduce succinct representations of concepts based on category theory. Such representation yields concept-wise invariance properties under various tasks, resulting a new learning algorithm that can provably and accurately learn complex concepts or fix misconceptions. Moreover, by recursively expanding the succinct representations, one can generate a hierarchical decomposition, and manually verify the concept by individually examining each part inside the decomposition.","sentences":["Foundation models like chatGPT have demonstrated remarkable performance on various tasks.","However, for many questions, they may produce false answers that look accurate.","How do we train the model to precisely understand the concepts?","In this paper, we introduce succinct representations of concepts based on category theory.","Such representation yields concept-wise invariance properties under various tasks, resulting a new learning algorithm that can provably and accurately learn complex concepts or fix misconceptions.","Moreover, by recursively expanding the succinct representations, one can generate a hierarchical decomposition, and manually verify the concept by individually examining each part inside the decomposition."],"url":"http://arxiv.org/abs/2303.00446v1"}
{"created":"2023-03-01","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","abstract":"Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal ChatGPT's ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT.","sentences":["Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored.","Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs.","This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests.","Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation.","Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs.","Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses.","The proposed framework enables LLMs to flexibly assess personalities of different groups of people.","We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and InstructGPT.","Our experiments reveal ChatGPT's ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT."],"url":"http://arxiv.org/abs/2303.01248v2"}
{"created":"2023-02-28","title":"Large Language Models Are State-of-the-Art Evaluators of Translation Quality","abstract":"We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate seven versions of GPT models, including ChatGPT. We show that our method for translation quality assessment only works with GPT 3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.","sentences":["We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without.","In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference.","We investigate seven versions of GPT models, including ChatGPT.","We show that our method for translation quality assessment only works with GPT 3.5 and larger models.","Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels.","Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English.","This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations.","We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility."],"url":"http://arxiv.org/abs/2302.14520v1"}
{"created":"2023-02-28","title":"Zero-Shot Cross-Lingual Summarization via Large Language Models","abstract":"Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with the fine-tuned mBART-50. Moreover, we also find some multi-lingual and bilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited zero-shot CLS ability. Due to the composite nature of CLS, which requires models to perform summarization and translation simultaneously, accomplishing this task in a zero-shot manner is even a challenge for LLMs. Therefore, we sincerely hope and recommend future LLM research could use CLS as a testbed.","sentences":["Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language.","Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community.","However, it is not yet known the performance of LLMs on CLS.","In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries.","We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information.","These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance.","Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with the fine-tuned mBART-50.","Moreover, we also find some multi-lingual and bilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited zero-shot CLS ability.","Due to the composite nature of CLS, which requires models to perform summarization and translation simultaneously, accomplishing this task in a zero-shot manner is even a challenge for LLMs.","Therefore, we sincerely hope and recommend future LLM research could use CLS as a testbed."],"url":"http://arxiv.org/abs/2302.14229v2"}
{"created":"2023-02-27","title":"Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations","abstract":"The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.","sentences":["The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention.","This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT.","Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted.","Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT.","In addition, we highlight some of the important limitations of the current version of ChatGPT.","We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer."],"url":"http://arxiv.org/abs/2302.13817v2"}
{"created":"2023-02-26","title":"Towards Human-Bot Collaborative Software Architecting with ChatGPT","abstract":"Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders' perspectives, designers' intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) inherits a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software (e.g., IoTs, blockchain, quantum systems). Software Development Bots (DevBots) trained on large language models can help synergise architects' knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT for architectural analysis, synthesis, and evaluation of a services-driven software application. Preliminary results indicate that ChatGPT can mimic an architect's role to support and often lead ACSE, however; it requires human oversight and decision support for collaborative architecting. Future research focuses on harnessing empirical evidence about architects' productivity and exploring socio-technical aspects of architecting with ChatGPT to tackle emerging and futuristic challenges of ACSE.","sentences":["Architecting software-intensive systems can be a complex process.","It deals with the daunting tasks of unifying stakeholders' perspectives, designers' intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation.","Despite its benefits, architecture-centric software engineering (ACSE) inherits a multitude of challenges.","ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software (e.g., IoTs, blockchain, quantum systems).","Software Development Bots (DevBots) trained on large language models can help synergise architects' knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE.","An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing.","We detail a case study that involves collaboration between a novice software architect and ChatGPT for architectural analysis, synthesis, and evaluation of a services-driven software application.","Preliminary results indicate that ChatGPT can mimic an architect's role to support and often lead ACSE, however; it requires human oversight and decision support for collaborative architecting.","Future research focuses on harnessing empirical evidence about architects' productivity and exploring socio-technical aspects of architecting with ChatGPT to tackle emerging and futuristic challenges of ACSE."],"url":"http://arxiv.org/abs/2302.14600v1"}
{"created":"2023-02-26","title":"Fast Attention Requires Bounded Entries","abstract":"In modern machine learning, inner product attention computation is a fundamental task for training large language models such as Transformer, GPT-1, BERT, GPT-2, GPT-3 and ChatGPT. Formally, in this problem, one is given as input three matrices $Q, K, V \\in [-B,B]^{n \\times d}$, and the goal is to construct the matrix $\\mathrm{Att}(Q,K,V) := \\mathrm{diag}(A {\\bf 1}_n)^{-1} A V \\in \\mathbb{R}^{n \\times d}$, where $A = \\exp(QK^\\top/d)$ is the `attention matrix', and $\\exp$ is applied entry-wise. Straightforward methods for this problem explicitly compute the $n \\times n$ attention matrix $A$, and hence require time $\\Omega(n^2)$ even when $d = n^{o(1)}$ is small.   In this paper, we investigate whether faster algorithms are possible by implicitly making use of the matrix $A$. We present two results, showing that there is a sharp transition at $B = \\Theta(\\sqrt{\\log n})$.   $\\bullet$ If $d = O(\\log n)$ and $B = o(\\sqrt{\\log n})$, there is an $n^{1+o(1)}$ time algorithm to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error.   $\\bullet$ If $d = O(\\log n)$ and $B = \\Theta (\\sqrt{\\log n})$, assuming the Strong Exponential Time Hypothesis from fine-grained complexity theory, it is impossible to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error in truly subquadratic time $n^{2 - \\Omega(1)}$.   This gives a theoretical explanation for the phenomenon observed in practice that attention computation is much more efficient when the input matrices have smaller entries.","sentences":["In modern machine learning, inner product attention computation is a fundamental task for training large language models such as Transformer, GPT-1, BERT, GPT-2, GPT-3 and ChatGPT.","Formally, in this problem, one is given as input three matrices $Q, K, V \\in","[-B,B]^{n \\times d}$, and the goal is to construct the matrix $\\mathrm{Att}(Q,K,V) := \\mathrm{diag}(A {\\bf 1}_n)^{-1} A V \\in \\mathbb{R}^{n \\times d}$, where $A = \\exp(QK^\\top/d)$ is the `attention matrix', and $\\exp$ is applied entry-wise.","Straightforward methods for this problem explicitly compute the $n \\times n$ attention matrix $A$, and hence require time $\\Omega(n^2)$ even when $d = n^{o(1)}$ is small.   ","In this paper, we investigate whether faster algorithms are possible by implicitly making use of the matrix $A$.","We present two results, showing that there is a sharp transition at $B = \\Theta(\\sqrt{\\log n})$.   $\\bullet$ If $d = O(\\log n)$ and $B = o(\\sqrt{\\log n})$, there is an $n^{1+o(1)}$ time algorithm to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error.   ","$\\bullet$ If $d = O(\\log n)$ and $B = \\Theta (\\sqrt{\\log n})$, assuming the Strong Exponential Time Hypothesis from fine-grained complexity theory, it is impossible to approximate $\\mathrm{Att}(Q,K,V)$ up to $1/\\mathrm{poly}(n)$ additive error in truly subquadratic time $n^{2 - \\Omega(1)}$.   This gives a theoretical explanation for the phenomenon observed in practice that attention computation is much more efficient when the input matrices have smaller entries."],"url":"http://arxiv.org/abs/2302.13214v1"}
{"created":"2023-02-25","title":"A Human-Centered Safe Robot Reinforcement Learning Framework with Interactive Behaviors","abstract":"Deployment of reinforcement learning algorithms for robotics applications in the real world requires ensuring the safety of the robot and its environment. Safe robot reinforcement learning (SRRL) is a crucial step towards achieving human-robot coexistence. In this paper, we envision a human-centered SRRL framework consisting of three stages: safe exploration, safety value alignment, and safe collaboration. We examine the research gaps in these areas and propose to leverage interactive behaviors for SRRL. Interactive behaviors enable bi-directional information transfer between humans and robots, such as conversational robot ChatGPT. We argue that interactive behaviors need further attention from the SRRL community. We discuss four open challenges related to the robustness, efficiency, transparency, and adaptability of SRRL with interactive behaviors.","sentences":["Deployment of reinforcement learning algorithms for robotics applications in the real world requires ensuring the safety of the robot and its environment.","Safe robot reinforcement learning (SRRL) is a crucial step towards achieving human-robot coexistence.","In this paper, we envision a human-centered SRRL framework consisting of three stages: safe exploration, safety value alignment, and safe collaboration.","We examine the research gaps in these areas and propose to leverage interactive behaviors for SRRL.","Interactive behaviors enable bi-directional information transfer between humans and robots, such as conversational robot ChatGPT.","We argue that interactive behaviors need further attention from the SRRL community.","We discuss four open challenges related to the robustness, efficiency, transparency, and adaptability of SRRL with interactive behaviors."],"url":"http://arxiv.org/abs/2302.13137v2"}
{"created":"2023-02-25","title":"AugGPT: Leveraging ChatGPT for Text Data Augmentation","abstract":"Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.","sentences":["Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks.","This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality.","A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size.","However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both.","Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT).","AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples.","The augmented samples can then be used in downstream model training.","Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples."],"url":"http://arxiv.org/abs/2302.13007v3"}
{"created":"2023-02-24","title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback","abstract":"Large language models (LLMs), such as ChatGPT, are able to generate human-like, fluent responses for many downstream tasks, e.g., task-oriented dialog and question answering. However, applying LLMs to real-world, mission-critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge. This paper proposes a LLM-Augmenter system, which augments a black-box LLM with a set of plug-and-play modules. Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, e.g., the factuality score of a LLM-generated response. The effectiveness of LLM-Augmenter is empirically validated on two types of scenarios, task-oriented dialog and open-domain question answering. LLM-Augmenter significantly reduces ChatGPT's hallucinations without sacrificing the fluency and informativeness of its responses. We make the source code and models publicly available.","sentences":["Large language models (LLMs), such as ChatGPT, are able to generate human-like, fluent responses for many downstream tasks, e.g., task-oriented dialog and question answering.","However, applying LLMs to real-world, mission-critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge.","This paper proposes a LLM-Augmenter system, which augments a black-box LLM with a set of plug-and-play modules.","Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases.","It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, e.g., the factuality score of a LLM-generated response.","The effectiveness of LLM-Augmenter is empirically validated on two types of scenarios, task-oriented dialog and open-domain question answering.","LLM-Augmenter significantly reduces ChatGPT's hallucinations without sacrificing the fluency and informativeness of its responses.","We make the source code and models publicly available."],"url":"http://arxiv.org/abs/2302.12813v3"}
{"created":"2023-02-23","title":"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness","abstract":"Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase. This knowledge is then used at inference to address the task specified by the user in their prompt. For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question. Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts. For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt. In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge. We study this in the context of consumers seeking health advice from the model. Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness. This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models.","sentences":["Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase.","This knowledge is then used at inference to address the task specified by the user in their prompt.","For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question.","Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts.","For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt.","In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge.","We study this in the context of consumers seeking health advice from the model.","Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness.","This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models."],"url":"http://arxiv.org/abs/2302.13793v1"}
{"created":"2023-02-23","title":"Talking Abortion (Mis)information with ChatGPT on TikTok","abstract":"In this study, we tested users' perception of accuracy and engagement with TikTok videos in which ChatGPT responded to prompts about \"at-home\" abortion remedies. The chatbot's responses, though somewhat vague and confusing, nonetheless recommended consulting with health professionals before attempting an \"at-home\" abortion. We used ChatGPT to create two TikTok video variants - one where users can see ChatGPT explicitly typing back a response, and one where the text response is presented without any notion to the chatbot. We randomly exposed 100 participants to each variant and found that the group of participants unaware of ChatGPT's text synthetization was more inclined to believe the responses were misinformation. Under the same impression, TikTok itself attached misinformation warning labels (\"Get the facts about abortion\") to all videos after we collected our initial results. We then decided to test the videos again with another set of 50 participants and found that the labels did not affect the perceptions of abortion misinformation except in the case where ChatGPT explicitly responded to a prompt for a lyrical output. We also found that more than 60% of the participants expressed negative or hesitant opinions about chatbots as sources of credible health information.","sentences":["In this study, we tested users' perception of accuracy and engagement with TikTok videos in which ChatGPT responded to prompts about \"at-home\" abortion remedies.","The chatbot's responses, though somewhat vague and confusing, nonetheless recommended consulting with health professionals before attempting an \"at-home\" abortion.","We used ChatGPT to create two TikTok video variants - one where users can see ChatGPT explicitly typing back a response, and one where the text response is presented without any notion to the chatbot.","We randomly exposed 100 participants to each variant and found that the group of participants unaware of ChatGPT's text synthetization was more inclined to believe the responses were misinformation.","Under the same impression, TikTok itself attached misinformation warning labels (\"Get the facts about abortion\") to all videos after we collected our initial results.","We then decided to test the videos again with another set of 50 participants and found that the labels did not affect the perceptions of abortion misinformation except in the case where ChatGPT explicitly responded to a prompt for a lyrical output.","We also found that more than 60% of the participants expressed negative or hesitant opinions about chatbots as sources of credible health information."],"url":"http://arxiv.org/abs/2303.13524v1"}
{"created":"2023-02-23","title":"An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)","abstract":"We study the performance of a commercially available large language model (LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K. To our knowledge, this is the first independent evaluation of ChatGPT. We found that ChatGPT's performance changes dramatically based on the requirement to show its work, failing 20% of the time when it provides work compared with 84% when it does not. Further several factors about MWPs relating to the number of unknowns and number of operations that lead to a higher probability of failure when compared with the prior, specifically noting (across all experiments) that the probability of failure increases linearly with the number of addition and subtraction operations. We also have released the dataset of ChatGPT's responses to the MWPs to support further work on the characterization of LLM performance and present baseline machine learning models to predict if ChatGPT can correctly answer an MWP. We have released a dataset comprised of ChatGPT's responses to support further research in this area.","sentences":["We study the performance of a commercially available large language model (LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K. To our knowledge, this is the first independent evaluation of ChatGPT.","We found that ChatGPT's performance changes dramatically based on the requirement to show its work, failing 20% of the time when it provides work compared with 84% when it does not.","Further several factors about MWPs relating to the number of unknowns and number of operations that lead to a higher probability of failure when compared with the prior, specifically noting (across all experiments) that the probability of failure increases linearly with the number of addition and subtraction operations.","We also have released the dataset of ChatGPT's responses to the MWPs to support further work on the characterization of LLM performance and present baseline machine learning models to predict if ChatGPT can correctly answer an MWP.","We have released a dataset comprised of ChatGPT's responses to support further research in this area."],"url":"http://arxiv.org/abs/2302.13814v2"}
{"created":"2023-02-22","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective","abstract":"ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months. While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public. Robustness is of particular concern in responsible AI, especially for safety-critical applications. In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective. To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation. We select several popular foundation models as baselines. Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks. However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat to foundation models. Moreover, ChatGPT shows astounding performance in understanding dialogue-related texts and we find that it tends to provide informal suggestions for medical tasks instead of definitive answers. Finally, we present in-depth discussions of possible research directions.","sentences":["ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months.","While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public.","Robustness is of particular concern in responsible AI, especially for safety-critical applications.","In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective.","To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation.","We select several popular foundation models as baselines.","Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks.","However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat to foundation models.","Moreover, ChatGPT shows astounding performance in understanding dialogue-related texts and we find that it tends to provide informal suggestions for medical tasks instead of definitive answers.","Finally, we present in-depth discussions of possible research directions."],"url":"http://arxiv.org/abs/2302.12095v4"}
{"created":"2023-02-21","title":"ChatGPT: Jack of all trades, master of none","abstract":"OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. There are several publications on ChatGPT evaluation, testing its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness and stance detection, natural language inference, word sense disambiguation, linguistic acceptability and question answering. We automated ChatGPT's querying process and analyzed more than 38k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability of personalizing ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established.","sentences":["OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction.","The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas.","There are several publications on ChatGPT evaluation, testing its effectiveness on well-known natural language processing (NLP) tasks.","However, the existing studies are mostly non-automated and tested on a very limited scale.","In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness and stance detection, natural language inference, word sense disambiguation, linguistic acceptability and question answering.","We automated ChatGPT's querying process and analyzed more than 38k responses.","Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation.","We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss.","It especially refers to pragmatic NLP problems like emotion recognition.","We also tested the ability of personalizing ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions.","Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI.","Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established."],"url":"http://arxiv.org/abs/2302.10724v1"}
{"created":"2023-02-21","title":"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT","abstract":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","sentences":["Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT.","Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output.","Prompts are also a form of programming that can customize the outputs and interactions with an LLM.","This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs.","This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks.","First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains.","Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations.","Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns."],"url":"http://arxiv.org/abs/2302.11382v1"}
{"created":"2023-02-20","title":"ChatGPT: A Meta-Analysis after 2.5 Months","abstract":"ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating in social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT's current perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.","sentences":["ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022.","However, little hard evidence is available regarding its perception in various sources.","In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed.","Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating in social media.","Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English.","In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education.","Our comprehensive meta-analysis of ChatGPT's current perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development.","We make our data available."],"url":"http://arxiv.org/abs/2302.13795v1"}
{"created":"2023-02-20","title":"Zero-Shot Information Extraction via Chatting with ChatGPT","abstract":"Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g., GPT-3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources.","sentences":["Zero-shot information extraction (IE) aims to build IE systems from the unannotated text.","It is challenging due to involving little human intervention.","Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes.","Recent efforts on large language models (LLMs, e.g., GPT-3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods.","In this work, we ask whether strong IE models can be constructed by directly prompting LLMs.","Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE).","With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction.","Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL).","We believe that our work could shed light on building IE models with limited resources."],"url":"http://arxiv.org/abs/2302.10205v1"}
{"created":"2023-02-19","title":"Triple birthday matches in the Senate: Lies, damned lies and chatGPT","abstract":"Our question is ``What is the probability that at least three members of the senate share the same birthday?'' Before the pandemic, I asked this question in several popular math talks I gave at universities across the country. Inspired by ChatGPT's abysmal failure to answer the question, I have recently come back to this problem and now have a more satisfactory answer, thanks in no small part to what I learned form a page of Wolfram's Math World, which I located by a Google search.","sentences":["Our question is ``What is the probability that at least three members of the senate share the same birthday?''","Before the pandemic, I asked this question in several popular math talks I gave at universities across the country.","Inspired by ChatGPT's abysmal failure to answer the question, I have recently come back to this problem and now have a more satisfactory answer, thanks in no small part to what I learned form a page of Wolfram's Math World, which I located by a Google search."],"url":"http://arxiv.org/abs/2302.09643v1"}
{"created":"2023-02-19","title":"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT","abstract":"Recently, ChatGPT has attracted great attention, as it can generate fluent and high-quality responses to human inquiries. Several prior studies have shown that ChatGPT attains remarkable generation ability compared with existing models. However, the quantitative analysis of ChatGPT's understanding ability has been given little attention. In this report, we explore the understanding ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and comparing it with 4 representative fine-tuned BERT-style models. We find that: 1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT achieves comparable performance compared with BERT on sentiment analysis and question-answering tasks. Additionally, by combining some advanced prompting strategies, we show that the understanding ability of ChatGPT can be further improved.","sentences":["Recently, ChatGPT has attracted great attention, as it can generate fluent and high-quality responses to human inquiries.","Several prior studies have shown that ChatGPT attains remarkable generation ability compared with existing models.","However, the quantitative analysis of ChatGPT's understanding ability has been given little attention.","In this report, we explore the understanding ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and comparing it with 4 representative fine-tuned BERT-style models.","We find that: 1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT achieves comparable performance compared with BERT on sentiment analysis and question-answering tasks.","Additionally, by combining some advanced prompting strategies, we show that the understanding ability of ChatGPT can be further improved."],"url":"http://arxiv.org/abs/2302.10198v2"}
{"created":"2023-02-18","title":"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT","abstract":"Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of recent research advancements, challenges, and opportunities for PFMs in text, image, graph, as well as other data modalities. The review covers the basic components and existing pretraining methods used in natural language processing, computer vision, and graph learning. Additionally, it explores advanced PFMs used for different data modalities and unified PFMs that consider data quality and quantity. The review also discusses research related to the fundamentals of PFMs, such as model efficiency and compression, security, and privacy. Finally, the study provides key implications, future research directions, challenges, and open problems in the field of PFMs. Overall, this survey aims to shed light on the research of the PFMs on scalability, security, logical reasoning ability, cross-domain learning ability, and the user-friendly interactive ability for artificial general intelligence.","sentences":["Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities.","A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications.","BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models.","Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets.","Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting.","The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI.","Numerous studies have proposed different methods, raising the demand for an updated survey.","This study provides a comprehensive review of recent research advancements, challenges, and opportunities for PFMs in text, image, graph, as well as other data modalities.","The review covers the basic components and existing pretraining methods used in natural language processing, computer vision, and graph learning.","Additionally, it explores advanced PFMs used for different data modalities and unified PFMs that consider data quality and quantity.","The review also discusses research related to the fundamentals of PFMs, such as model efficiency and compression, security, and privacy.","Finally, the study provides key implications, future research directions, challenges, and open problems in the field of PFMs.","Overall, this survey aims to shed light on the research of the PFMs on scalability, security, logical reasoning ability, cross-domain learning ability, and the user-friendly interactive ability for artificial general intelligence."],"url":"http://arxiv.org/abs/2302.09419v2"}
{"created":"2023-02-18","title":"How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation","abstract":"Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.","sentences":["Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated.","In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation.","We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002.","Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages.","We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality.","We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations.","We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation."],"url":"http://arxiv.org/abs/2302.09210v1"}
{"created":"2023-02-17","title":"Prompting Large Language Models With the Socratic Method","abstract":"This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.","sentences":["This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3.","Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified.","Techniques such as {\\em definition}, {\\em elenchus}, {\\em dialectic}, {\\em maieutics}, {\\em generalization}, and {\\em counterfactual reasoning} are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning.","Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated.","An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively."],"url":"http://arxiv.org/abs/2303.08769v2"}
{"created":"2023-02-17","title":"Complex QA and language models hybrid architectures, Survey","abstract":"This paper reviews the state-of-the-art of hybrid language models architectures and strategies for \"complex\" question-answering (QA, CQA, CPS). Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... We identify key elements augmenting LLM to solve complex questions or problems. We extend findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and analyze limits and challenges of LLM in terms of tasks complexity and strict evaluation on accuracy (e.g. fairness, robustness, toxicity, ...). Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of language models in complex QA. Hybridizing these models with different components could allow to overcome these different limits and go much further. We discuss some challenges associated with complex QA, including domain adaptation, decomposition and efficient multi-step QA, long form and non-factoid QA, safety and multi-sensitivity data protection, multimodal search, hallucinations, explainability and truthfulness, temproal reasoning. Therefore, we analyze current solutions and promising research trends, using elements such as: hybrid LLM architectures, active human reinforcement learning supervised with AI, prompting adaptation, neuro-symbolic and structured knowledge grounding, program synthesis, iterated decomposition and others.","sentences":["This paper reviews the state-of-the-art of hybrid language models architectures and strategies for \"complex\" question-answering (QA, CQA, CPS).","Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback...","We identify key elements augmenting LLM to solve complex questions or problems.","We extend findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and analyze limits and challenges of LLM in terms of tasks complexity and strict evaluation on accuracy (e.g. fairness, robustness, toxicity, ...).","Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of language models in complex QA.","Hybridizing these models with different components could allow to overcome these different limits and go much further.","We discuss some challenges associated with complex QA, including domain adaptation, decomposition and efficient multi-step QA, long form and non-factoid QA, safety and multi-sensitivity data protection, multimodal search, hallucinations, explainability and truthfulness, temproal reasoning.","Therefore, we analyze current solutions and promising research trends, using elements such as: hybrid LLM architectures, active human reinforcement learning supervised with AI, prompting adaptation, neuro-symbolic and structured knowledge grounding, program synthesis, iterated decomposition and others."],"url":"http://arxiv.org/abs/2302.09051v3"}
{"created":"2023-02-17","title":"Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?","abstract":"In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet.","sentences":["In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever.","Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety.","Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet.","The tools are trained on massive data sets that are scraped from Internet sites.","And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet.","Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data.","As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet.","This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data?","Will they evolve with the new data sets or degenerate?","Will evolution introduce biases in subsequent generations of generative AI tools?","In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool.","These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate.","Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet."],"url":"http://arxiv.org/abs/2303.01255v1"}
{"created":"2023-02-17","title":"How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study","abstract":"Generative Artificial Intelligence (AI) models such as OpenAI's ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research. However, these tools are in the early stages of development and can be easily misused or misunderstood. In this paper, we give an overview of the development of Generative AI. Specifically, we explore ChatGPT's ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research. By investigating responses to structured prompts, we highlight the benefits and limitations of the results. Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch. We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive. However, in their current stages of development, some results are misleading and wrong. Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results.","sentences":["Generative Artificial Intelligence (AI) models such as OpenAI's ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research.","However, these tools are in the early stages of development and can be easily misused or misunderstood.","In this paper, we give an overview of the development of Generative AI.","Specifically, we explore ChatGPT's ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research.","By investigating responses to structured prompts, we highlight the benefits and limitations of the results.","Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch.","We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive.","However, in their current stages of development, some results are misleading and wrong.","Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results."],"url":"http://arxiv.org/abs/2302.10916v1"}
{"created":"2023-02-16","title":"AI Usage Cards: Responsibly Reporting AI-generated Content","abstract":"Given AI systems like ChatGPT can generate content that is indistinguishable from human-made work, the responsible use of this technology is a growing concern. Although understanding the benefits and harms of using AI systems requires more time, their rapid and indiscriminate adoption in practice is a reality. Currently, we lack a common framework and language to define and report responsible use of AI for content generation. Prior work proposed guidelines for using AI in specific scenarios (e.g., robotics or medicine) which are not transferable to conducting and reporting scientific research. Our work makes two contributions: First, we propose a three-dimensional model consisting of transparency, integrity, and accountability to \\textit{define} the responsible use of AI. Second, we introduce ``AI Usage Cards'', a standardized way to \\textit{report} the use of AI in scientific research. Our model and cards allow users to reflect on key principles of responsible AI usage. They also help the research community trace, compare, and question various forms of AI usage and support the development of accepted community norms. The proposed framework and reporting system aim to promote ethical and responsible use of AI in scientific research and provide a standardized approach for reporting AI usage across different research fields. We also provide a free service to easily generate AI Usage Cards for scientific work via a questionnaire and export them in various machine-readable formats for inclusion in different work products at \\url{https://ai-cards.org}.","sentences":["Given AI systems like ChatGPT can generate content that is indistinguishable from human-made work, the responsible use of this technology is a growing concern.","Although understanding the benefits and harms of using AI systems requires more time, their rapid and indiscriminate adoption in practice is a reality.","Currently, we lack a common framework and language to define and report responsible use of AI for content generation.","Prior work proposed guidelines for using AI in specific scenarios (e.g., robotics or medicine) which are not transferable to conducting and reporting scientific research.","Our work makes two contributions: First, we propose a three-dimensional model consisting of transparency, integrity, and accountability to \\textit{define} the responsible use of AI.","Second, we introduce ``AI Usage Cards'', a standardized way to \\textit{report} the use of AI in scientific research.","Our model and cards allow users to reflect on key principles of responsible AI usage.","They also help the research community trace, compare, and question various forms of AI usage and support the development of accepted community norms.","The proposed framework and reporting system aim to promote ethical and responsible use of AI in scientific research and provide a standardized approach for reporting AI usage across different research fields.","We also provide a free service to easily generate AI Usage Cards for scientific work via a questionnaire and export them in various machine-readable formats for inclusion in different work products at \\url{https://ai-cards.org}."],"url":"http://arxiv.org/abs/2303.03886v1"}
{"created":"2023-02-16","title":"Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization","abstract":"Text summarization has been a crucial problem in natural language processing (NLP) for several decades. It aims to condense lengthy documents into shorter versions while retaining the most critical information. Various methods have been proposed for text summarization, including extractive and abstractive summarization. The emergence of large language models (LLMs) like GPT3 and ChatGPT has recently created significant interest in using these models for text summarization tasks. Recent studies \\cite{goyal2022news, zhang2023benchmarking} have shown that LLMs-generated news summaries are already on par with humans. However, the performance of LLMs for more practical applications like aspect or query-based summaries is underexplored. To fill this gap, we conducted an evaluation of ChatGPT's performance on four widely used benchmark datasets, encompassing diverse summaries from Reddit posts, news articles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's performance is comparable to traditional fine-tuning methods in terms of Rouge scores. Moreover, we highlight some unique differences between ChatGPT-generated summaries and human references, providing valuable insights into the superpower of ChatGPT for diverse text summarization tasks. Our findings call for new directions in this area, and we plan to conduct further research to systematically examine the characteristics of ChatGPT-generated summaries through extensive human evaluation.","sentences":["Text summarization has been a crucial problem in natural language processing (NLP) for several decades.","It aims to condense lengthy documents into shorter versions while retaining the most critical information.","Various methods have been proposed for text summarization, including extractive and abstractive summarization.","The emergence of large language models (LLMs) like GPT3 and ChatGPT has recently created significant interest in using these models for text summarization tasks.","Recent studies \\cite{goyal2022news, zhang2023benchmarking} have shown that LLMs-generated news summaries are already on par with humans.","However, the performance of LLMs for more practical applications like aspect or query-based summaries is underexplored.","To fill this gap, we conducted an evaluation of ChatGPT's performance on four widely used benchmark datasets, encompassing diverse summaries from Reddit posts, news articles, dialogue meetings, and stories.","Our experiments reveal that ChatGPT's performance is comparable to traditional fine-tuning methods in terms of Rouge scores.","Moreover, we highlight some unique differences between ChatGPT-generated summaries and human references, providing valuable insights into the superpower of ChatGPT for diverse text summarization tasks.","Our findings call for new directions in this area, and we plan to conduct further research to systematically examine the characteristics of ChatGPT-generated summaries through extensive human evaluation."],"url":"http://arxiv.org/abs/2302.08081v1"}
{"created":"2023-02-15","title":"NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation","abstract":"Translating natural language into Bash Commands is an emerging research field that has gained attention in recent years. Most efforts have focused on producing more accurate translation models. To the best of our knowledge, only two datasets are available, with one based on the other. Both datasets involve scraping through known data sources (through platforms like stack overflow, crowdsourcing, etc.) and hiring experts to validate and correct either the English text or Bash Commands. This paper provides two contributions to research on synthesizing Bash Commands from scratch. First, we describe a state-of-the-art translation model used to generate Bash Commands from the corresponding English text. Second, we introduce a new NL2CMD dataset that is automatically generated, involves minimal human intervention, and is over six times larger than prior datasets. Since the generation pipeline does not rely on existing Bash Commands, the distribution and types of commands can be custom adjusted. We evaluate the performance of ChatGPT on this task and discuss the potential of using it as a data generator. Our empirical results show how the scale and diversity of our dataset can offer unique opportunities for semantic parsing researchers.","sentences":["Translating natural language into Bash Commands is an emerging research field that has gained attention in recent years.","Most efforts have focused on producing more accurate translation models.","To the best of our knowledge, only two datasets are available, with one based on the other.","Both datasets involve scraping through known data sources (through platforms like stack overflow, crowdsourcing, etc.)","and hiring experts to validate and correct either the English text or Bash Commands.","This paper provides two contributions to research on synthesizing Bash Commands from scratch.","First, we describe a state-of-the-art translation model used to generate Bash Commands from the corresponding English text.","Second, we introduce a new NL2CMD dataset that is automatically generated, involves minimal human intervention, and is over six times larger than prior datasets.","Since the generation pipeline does not rely on existing Bash Commands, the distribution and types of commands can be custom adjusted.","We evaluate the performance of ChatGPT on this task and discuss the potential of using it as a data generator.","Our empirical results show how the scale and diversity of our dataset can offer unique opportunities for semantic parsing researchers."],"url":"http://arxiv.org/abs/2302.07845v2"}
{"created":"2023-02-15","title":"A Pilot Evaluation of ChatGPT and DALL-E 2 on Decision Making and Spatial Reasoning","abstract":"We conduct a pilot study selectively evaluating the cognitive abilities (decision making and spatial reasoning) of two recently released generative transformer models, ChatGPT and DALL-E 2. Input prompts were constructed following neutral a priori guidelines, rather than adversarial intent. Post hoc qualitative analysis of the outputs shows that DALL-E 2 is able to generate at least one correct image for each spatial reasoning prompt, but most images generated are incorrect (even though the model seems to have a clear understanding of the objects mentioned in the prompt). Similarly, in evaluating ChatGPT on the rationality axioms developed under the classical Von Neumann-Morgenstern utility theorem, we find that, although it demonstrates some level of rational decision-making, many of its decisions violate at least one of the axioms even under reasonable constructions of preferences, bets, and decision-making prompts. ChatGPT's outputs on such problems generally tended to be unpredictable: even as it made irrational decisions (or employed an incorrect reasoning process) for some simpler decision-making problems, it was able to draw correct conclusions for more complex bet structures. We briefly comment on the nuances and challenges involved in scaling up such a 'cognitive' evaluation or conducting it with a closed set of answer keys ('ground truth'), given that these models are inherently generative and open-ended in responding to prompts.","sentences":["We conduct a pilot study selectively evaluating the cognitive abilities (decision making and spatial reasoning) of two recently released generative transformer models, ChatGPT and DALL-E 2.","Input prompts were constructed following neutral a priori guidelines, rather than adversarial intent.","Post hoc qualitative analysis of the outputs shows that DALL-E 2 is able to generate at least one correct image for each spatial reasoning prompt, but most images generated are incorrect (even though the model seems to have a clear understanding of the objects mentioned in the prompt).","Similarly, in evaluating ChatGPT on the rationality axioms developed under the classical Von Neumann-Morgenstern utility theorem, we find that, although it demonstrates some level of rational decision-making, many of its decisions violate at least one of the axioms even under reasonable constructions of preferences, bets, and decision-making prompts.","ChatGPT's outputs on such problems generally tended to be unpredictable: even as it made irrational decisions (or employed an incorrect reasoning process) for some simpler decision-making problems, it was able to draw correct conclusions for more complex bet structures.","We briefly comment on the nuances and challenges involved in scaling up such a 'cognitive' evaluation or conducting it with a closed set of answer keys ('ground truth'), given that these models are inherently generative and open-ended in responding to prompts."],"url":"http://arxiv.org/abs/2302.09068v1"}
{"created":"2023-02-15","title":"Conversational AI-Powered Design: ChatGPT as Designer, User, and Product","abstract":"The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design. This study aims to examine the capabilities of ChatGPT in a human-centered design process. To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience. The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses. The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity. The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area.","sentences":["The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design.","This study aims to examine the capabilities of ChatGPT in a human-centered design process.","To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience.","The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses.","The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity.","The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area."],"url":"http://arxiv.org/abs/2302.07406v1"}
{"created":"2023-02-14","title":"ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models","abstract":"Large language models (LLMs) have recently demonstrated their potential in clinical applications, providing valuable medical knowledge and advice. For example, a large dialog LLM like ChatGPT has successfully passed part of the US medical licensing exam. However, LLMs currently have difficulty processing images, making it challenging to interpret information from medical images, which are rich in information that supports clinical decisions. On the other hand, computer-aided diagnosis (CAD) networks for medical images have seen significant success in the medical field by using advanced deep-learning algorithms to support clinical decision-making. This paper presents a method for integrating LLMs into medical-image CAD networks. The proposed framework uses LLMs to enhance the output of multiple CAD networks, such as diagnosis networks, lesion segmentation networks, and report generation networks, by summarizing and reorganizing the information presented in natural language text format. The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems. In the future, LLM's medical knowledge can be also used to improve the performance of vision-based medical-image CAD models.","sentences":["Large language models (LLMs) have recently demonstrated their potential in clinical applications, providing valuable medical knowledge and advice.","For example, a large dialog LLM like ChatGPT has successfully passed part of the US medical licensing exam.","However, LLMs currently have difficulty processing images, making it challenging to interpret information from medical images, which are rich in information that supports clinical decisions.","On the other hand, computer-aided diagnosis (CAD) networks for medical images have seen significant success in the medical field by using advanced deep-learning algorithms to support clinical decision-making.","This paper presents a method for integrating LLMs into medical-image CAD networks.","The proposed framework uses LLMs to enhance the output of multiple CAD networks, such as diagnosis networks, lesion segmentation networks, and report generation networks, by summarizing and reorganizing the information presented in natural language text format.","The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems.","In the future, LLM's medical knowledge can be also used to improve the performance of vision-based medical-image CAD models."],"url":"http://arxiv.org/abs/2302.07257v1"}
{"created":"2023-02-14","title":"Learning gain differences between ChatGPT and human tutor generated algebra hints","abstract":"Large Language Models (LLMs), such as ChatGPT, are quickly advancing AI to the frontiers of practical consumer use and leading industries to re-evaluate how they allocate resources for content production. Authoring of open educational resources and hint content within adaptive tutoring systems is labor intensive. Should LLMs like ChatGPT produce educational content on par with human-authored content, the implications would be significant for further scaling of computer tutoring system approaches. In this paper, we conduct the first learning gain evaluation of ChatGPT by comparing the efficacy of its hints with hints authored by human tutors with 77 participants across two algebra topic areas, Elementary Algebra and Intermediate Algebra. We find that 70% of hints produced by ChatGPT passed our manual quality checks and that both human and ChatGPT conditions produced positive learning gains. However, gains were only statistically significant for human tutor created hints. Learning gains from human-created hints were substantially and statistically significantly higher than ChatGPT hints in both topic areas, though ChatGPT participants in the Intermediate Algebra experiment were near ceiling and not even with the control at pre-test. We discuss the limitations of our study and suggest several future directions for the field. Problem and hint content used in the experiment is provided for replicability.","sentences":["Large Language Models (LLMs), such as ChatGPT, are quickly advancing AI to the frontiers of practical consumer use and leading industries to re-evaluate how they allocate resources for content production.","Authoring of open educational resources and hint content within adaptive tutoring systems is labor intensive.","Should LLMs like ChatGPT produce educational content on par with human-authored content, the implications would be significant for further scaling of computer tutoring system approaches.","In this paper, we conduct the first learning gain evaluation of ChatGPT by comparing the efficacy of its hints with hints authored by human tutors with 77 participants across two algebra topic areas, Elementary Algebra and Intermediate Algebra.","We find that 70% of hints produced by ChatGPT passed our manual quality checks and that both human and ChatGPT conditions produced positive learning gains.","However, gains were only statistically significant for human tutor created hints.","Learning gains from human-created hints were substantially and statistically significantly higher than ChatGPT hints in both topic areas, though ChatGPT participants in the Intermediate Algebra experiment were near ceiling and not even with the control at pre-test.","We discuss the limitations of our study and suggest several future directions for the field.","Problem and hint content used in the experiment is provided for replicability."],"url":"http://arxiv.org/abs/2302.06871v1"}
{"created":"2023-02-13","title":"Linguistic ambiguity analysis in ChatGPT","abstract":"Linguistic ambiguity is and has always been one of the main challenges in Natural Language Processing (NLP) systems. Modern Transformer architectures like BERT, T5 or more recently InstructGPT have achieved some impressive improvements in many NLP fields, but there is still plenty of work to do. Motivated by the uproar caused by ChatGPT, in this paper we provide an introduction to linguistic ambiguity, its varieties and their relevance in modern NLP, and perform an extensive empiric analysis. ChatGPT strengths and weaknesses are revealed, as well as strategies to get the most of this model.","sentences":["Linguistic ambiguity is and has always been one of the main challenges in Natural Language Processing (NLP) systems.","Modern Transformer architectures like BERT, T5 or more recently InstructGPT have achieved some impressive improvements in many NLP fields, but there is still plenty of work to do.","Motivated by the uproar caused by ChatGPT, in this paper we provide an introduction to linguistic ambiguity, its varieties and their relevance in modern NLP, and perform an extensive empiric analysis.","ChatGPT strengths and weaknesses are revealed, as well as strategies to get the most of this model."],"url":"http://arxiv.org/abs/2302.06426v2"}
{"created":"2023-02-12","title":"Semantic Communications with Ordered Importance using ChatGPT","abstract":"This letter proposes a novel semantic communication scheme with ordered importance (SCOI) using the chat generative pre-trained transformer (ChatGPT). In the proposed SCOI scheme, ChatGPT plays the role of a consulting assistant. Given a message to be transmitted, the transmitter first queries ChatGPT to output the importance order of each word. According to the importance order, the transmitter then performs an unequal error protection transmission strategy to make the transmission of essential words more reliable. Unlike the existing semantic communication schemes, SCOI is compatible with existing source-channel separation designs and can be directly embedded into current communication systems. Our experimental results show that both the transmission bit error rate (BER) of important words and the semantic loss measured by ChatGPT are much lower than the existing communication schemes.","sentences":["This letter proposes a novel semantic communication scheme with ordered importance (SCOI) using the chat generative pre-trained transformer (ChatGPT).","In the proposed SCOI scheme, ChatGPT plays the role of a consulting assistant.","Given a message to be transmitted, the transmitter first queries ChatGPT to output the importance order of each word.","According to the importance order, the transmitter then performs an unequal error protection transmission strategy to make the transmission of essential words more reliable.","Unlike the existing semantic communication schemes, SCOI is compatible with existing source-channel separation designs and can be directly embedded into current communication systems.","Our experimental results show that both the transmission bit error rate (BER) of important words and the semantic loss measured by ChatGPT are much lower than the existing communication schemes."],"url":"http://arxiv.org/abs/2302.07142v1"}
{"created":"2023-02-11","title":"Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech","abstract":"Recent studies have alarmed that many online hate speeches are implicit. With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem. In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs. We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research.","sentences":["Recent studies have alarmed that many online hate speeches are implicit.","With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem.","In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection.","We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs.","We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research."],"url":"http://arxiv.org/abs/2302.07736v2"}
{"created":"2023-02-10","title":"Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources","abstract":"The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies. The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet. Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams. Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources. Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail. In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI.","sentences":["The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies.","The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet.","Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams.","Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources.","Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail.","In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI."],"url":"http://arxiv.org/abs/2303.13521v1"}
{"created":"2023-02-09","title":"ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design","abstract":"Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task -- the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs. We evaluated our framework on three game design tasks with human designers who collaborated remotely.","sentences":["Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction.","These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.).","In this paper, we present a collaborative design framework that combines interactive evolution and large language models to simulate the typical human design process.","We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task -- the recombination and variation of ideas.","In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users.","Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs.","We evaluated our framework on three game design tasks with human designers who collaborated remotely."],"url":"http://arxiv.org/abs/2303.02155v1"}
{"created":"2023-02-08","title":"Will ChatGPT get you caught? Rethinking of Plagiarism Detection","abstract":"The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper.","sentences":["The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years.","The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities.","The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars.","This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT.","To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics.","Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software.","In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort.","Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools.","The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education.","Further implications are discussed in the paper."],"url":"http://arxiv.org/abs/2302.04335v1"}
{"created":"2023-02-08","title":"Deep Machine Learning in Cosmology: Evolution or Revolution?","abstract":"Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology? Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor. To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches. In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters. It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools. The 'killer applications' of ML for Cosmology are still to come. New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed. Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title.","sentences":["Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology?","Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor.","To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches.","In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters.","It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools.","The 'killer applications' of ML for Cosmology are still to come.","New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed.","Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title."],"url":"http://arxiv.org/abs/2302.04324v1"}
{"created":"2023-02-08","title":"ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots","abstract":"Conversational AI and Question-Answering systems (QASs) for knowledge graphs (KGs) are both emerging research areas: they empower users with natural language interfaces for extracting information easily and effectively. Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets. In contrast, QASs retrieve the most recent information from a KG by understanding and translating the natural language question into a formal query supported by the database engine.   In this paper, we present a comprehensive study of the characteristics of the existing alternatives towards combining both worlds into novel KG chatbots. Our framework compares two representative conversational models, ChatGPT and Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a thorough evaluation using four real KGs across various application domains to identify the current limitations of each category of systems. Based on our findings, we propose open research opportunities to empower QASs with chatbot capabilities for KGs. All benchmarks and all raw results are available1 for further analysis.","sentences":["Conversational AI and Question-Answering systems (QASs) for knowledge graphs (KGs) are both emerging research areas: they empower users with natural language interfaces for extracting information easily and effectively.","Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets.","In contrast, QASs retrieve the most recent information from a KG by understanding and translating the natural language question into a formal query supported by the database engine.   ","In this paper, we present a comprehensive study of the characteristics of the existing alternatives towards combining both worlds into novel KG chatbots.","Our framework compares two representative conversational models, ChatGPT and Galactica, against KGQAN, the current state-of-the-art QAS.","We conduct a thorough evaluation using four real KGs across various application domains to identify the current limitations of each category of systems.","Based on our findings, we propose open research opportunities to empower QASs with chatbot capabilities for KGs.","All benchmarks and all raw results are available1 for further analysis."],"url":"http://arxiv.org/abs/2302.06466v1"}
{"created":"2023-02-08","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity","abstract":"This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We also release codebase for evaluation set extraction.","sentences":["This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets.","We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks.","We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset.","We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks.","We find that it is better at understanding non-Latin script languages than generating them.","It is able to generate multimodal content from textual prompts, via an intermediate code generation step.","Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner.","It is, for example, better at deductive than inductive reasoning.","ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base.","Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion.","We also release codebase for evaluation set extraction."],"url":"http://arxiv.org/abs/2302.04023v2"}
{"created":"2023-02-08","title":"Is ChatGPT a General-Purpose Natural Language Processing Task Solver?","abstract":"Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently, the debut of ChatGPT has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations. However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot. In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories. With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT. We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging. We additionally provide in-depth analysis through qualitative case studies.","sentences":["Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot -- i.e., without adaptation on downstream data.","Recently, the debut of ChatGPT has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations.","However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot.","In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories.","With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT.","We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging.","We additionally provide in-depth analysis through qualitative case studies."],"url":"http://arxiv.org/abs/2302.06476v2"}
{"created":"2023-02-07","title":"Reliable Natural Language Understanding with Large Language Models and Answer Set Programming","abstract":"Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions. While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning. They also cannot reliably explain the answers generated for a given question. In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP). We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language. Goal-directed ASP is then employed to reliably reason over this knowledge. We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading to significant performance improvements, especially for smaller LLMs, i.e., LLMs with a smaller number of parameters. NLU applications developed using the STAR framework are also explainable: along with the predicates generated, a justification in the form of a proof tree can be produced for a given output.","sentences":["Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions.","While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning.","They also cannot reliably explain the answers generated for a given question.","In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP).","We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language.","Goal-directed ASP is then employed to reliably reason over this knowledge.","We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation.","Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading to significant performance improvements, especially for smaller LLMs, i.e., LLMs with a smaller number of parameters.","NLU applications developed using the STAR framework are also explainable: along with the predicates generated, a justification in the form of a proof tree can be produced for a given output."],"url":"http://arxiv.org/abs/2302.03780v2"}
{"created":"2023-02-07","title":"ChatGPT and Software Testing Education: Promises & Perils","abstract":"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.","sentences":["Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers.","More recently, we have seen the advent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language.","However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability.","Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.","The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock.","However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction.","As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum.","Our findings indicate that ChatGPT can provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct responses.","Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors."],"url":"http://arxiv.org/abs/2302.03287v3"}
{"created":"2023-02-07","title":"Applying BERT and ChatGPT for Sentiment Analysis of Lyme Disease in Scientific Literature","abstract":"This chapter presents a practical guide for conducting Sentiment Analysis using Natural Language Processing (NLP) techniques in the domain of tick-borne disease text. The aim is to demonstrate the process of how the presence of bias in the discourse surrounding chronic manifestations of the disease can be evaluated. The goal is to use a dataset of 5643 abstracts collected from scientific journals on the topic of chronic Lyme disease to demonstrate using Python, the steps for conducting sentiment analysis using pre-trained language models and the process of validating the preliminary results using both interpretable machine learning tools, as well as a novel methodology of using emerging state-of-the-art large language models like ChatGPT. This serves as a useful resource for researchers and practitioners interested in using NLP techniques for sentiment analysis in the medical domain.","sentences":["This chapter presents a practical guide for conducting Sentiment Analysis using Natural Language Processing (NLP) techniques in the domain of tick-borne disease text.","The aim is to demonstrate the process of how the presence of bias in the discourse surrounding chronic manifestations of the disease can be evaluated.","The goal is to use a dataset of 5643 abstracts collected from scientific journals on the topic of chronic Lyme disease to demonstrate using Python, the steps for conducting sentiment analysis using pre-trained language models and the process of validating the preliminary results using both interpretable machine learning tools, as well as a novel methodology of using emerging state-of-the-art large language models like ChatGPT.","This serves as a useful resource for researchers and practitioners interested in using NLP techniques for sentiment analysis in the medical domain."],"url":"http://arxiv.org/abs/2302.06474v1"}
{"created":"2023-02-06","title":"A Categorical Archive of ChatGPT Failures","abstract":"Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study. Eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots.","sentences":["Large language models have been demonstrated to be valuable in different fields.","ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses.","It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness.","However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study.","Eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed.","The risks, limitations, and societal implications of ChatGPT are also highlighted.","The goal of this study is to assist researchers and developers in enhancing future language models and chatbots."],"url":"http://arxiv.org/abs/2302.03494v8"}
{"created":"2023-02-05","title":"Regulating ChatGPT and other Large Generative AI Models","abstract":"Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. In particular, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers. In all areas, regulators and lawmakers need to act fast to keep track with the dynamics of ChatGPT et al.","sentences":["Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create.","However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs.","This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities.","After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals.","It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output.","We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large.","Rules in the AI Act and other direct regulation must match the specificities of pre-trained models.","In particular, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management.","Non-discrimination provisions (iii) may, however, apply to LGAIM developers.","Lastly, (iv) the core of the DSA content moderation rules should be expanded to cover LGAIMs.","This includes notice and action mechanisms, and trusted flaggers.","In all areas, regulators and lawmakers need to act fast to keep track with the dynamics of ChatGPT et al."],"url":"http://arxiv.org/abs/2302.02337v5"}
{"created":"2023-02-04","title":"Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models","abstract":"The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies.","sentences":["The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text.","Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques.","However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent.","Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations.","This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches.","Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified.","This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models.","This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets.","This work compares the performance of GPT-3, Codex and ChatGPT across a number of case studies and contrasts the performances with prior studies."],"url":"http://arxiv.org/abs/2302.02094v2"}
{"created":"2023-02-04","title":"Theory of Mind May Have Spontaneously Emerged in Large Language Models","abstract":"Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 (\"davinci-001\"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version (\"davinci-002\"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 (\"davinci-003\"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models' improving language skills.","sentences":["Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality.","We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans.","The models published before 2020 showed virtually no ability to solve ToM tasks.","Yet, the first version of GPT-3 (\"davinci-001\"), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children.","Its second version (\"davinci-002\"; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds.","Its most recent version, GPT-3.5 (\"davinci-003\"; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds.","GPT-4 published in March 2023 solved nearly all the tasks (95%).","These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models' improving language skills."],"url":"http://arxiv.org/abs/2302.02083v3"}
{"created":"2023-02-03","title":"Exploring the Cognitive Dynamics of Artificial Intelligence in the Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT","abstract":"The emergence of artificial intelligence has incited a paradigm shift across the spectrum of human endeavors, with ChatGPT serving as a catalyst for the transformation of various established domains, including but not limited to education, journalism, security, and ethics. In the post-pandemic era, the widespread adoption of remote work has prompted the educational sector to reassess conventional pedagogical methods. This paper is to scrutinize the underlying psychological principles of ChatGPT, delve into the factors that captivate user attention, and implicate its ramifications on the future of learning. The ultimate objective of this study is to instigate a scholarly discourse on the interplay between technological advancements in education and the evolution of human learning patterns, raising the question of whether technology is driving human evolution or vice versa.","sentences":["The emergence of artificial intelligence has incited a paradigm shift across the spectrum of human endeavors, with ChatGPT serving as a catalyst for the transformation of various established domains, including but not limited to education, journalism, security, and ethics.","In the post-pandemic era, the widespread adoption of remote work has prompted the educational sector to reassess conventional pedagogical methods.","This paper is to scrutinize the underlying psychological principles of ChatGPT, delve into the factors that captivate user attention, and implicate its ramifications on the future of learning.","The ultimate objective of this study is to instigate a scholarly discourse on the interplay between technological advancements in education and the evolution of human learning patterns, raising the question of whether technology is driving human evolution or vice versa."],"url":"http://arxiv.org/abs/2302.04818v1"}
{"created":"2023-02-03","title":"Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?","abstract":"Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.","sentences":["Systematic reviews are comprehensive reviews of the literature for a highly focused research question.","These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field.","To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic.","However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective.","Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies.","Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made.","In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search.","Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall.","Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search.","The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable."],"url":"http://arxiv.org/abs/2302.03495v3"}
{"created":"2023-02-01","title":"Netizens, Academicians, and Information Professionals' Opinions About AI With Special Reference To ChatGPT","abstract":"This study aims to understand the perceptions and opinions of academicians towards ChatGPT-3 by collecting and analyzing social media comments, and a survey was conducted with library and information science professionals. The research uses a content analysis method and finds that while ChatGPT-3 can be a valuable tool for research and writing, it is not 100% accurate and should be cross-checked. The study also finds that while some academicians may not accept ChatGPT-3, most are starting to accept it. The study is beneficial for academicians, content developers, and librarians.","sentences":["This study aims to understand the perceptions and opinions of academicians towards ChatGPT-3 by collecting and analyzing social media comments, and a survey was conducted with library and information science professionals.","The research uses a content analysis method and finds that while ChatGPT-3 can be a valuable tool for research and writing, it is not 100% accurate and should be cross-checked.","The study also finds that while some academicians may not accept ChatGPT-3, most are starting to accept it.","The study is beneficial for academicians, content developers, and librarians."],"url":"http://arxiv.org/abs/2302.07136v1"}
{"created":"2023-02-01","title":"Grading Conversational Responses Of Chatbots","abstract":"Chatbots have long been capable of answering basic questions and even responding to obscure prompts, but recently their improvements have been far more significant. Modern chatbots like Open AIs ChatGPT3 not only have the ability to answer basic questions but can write code and movie scripts and imitate well-known people. In this paper, we analyze ChatGPTs' responses to various questions from a dataset of queries from the popular Quora forum. We submitted sixty questions to ChatGPT and scored the answers based on three industry-standard metrics for grading machine translation: BLEU, METEOR, and ROUGE. These metrics allow us to compare the machine responses with the most upvoted human answer to the same question to assess ChatGPT's ability to submit a humanistic reply. The results showed that while the responses and translation abilities of ChatGPT are remarkable, they still fall short of what a typical human reaction would be.","sentences":["Chatbots have long been capable of answering basic questions and even responding to obscure prompts, but recently their improvements have been far more significant.","Modern chatbots like Open AIs ChatGPT3 not only have the ability to answer basic questions but can write code and movie scripts and imitate well-known people.","In this paper, we analyze ChatGPTs' responses to various questions from a dataset of queries from the popular Quora forum.","We submitted sixty questions to ChatGPT and scored the answers based on three industry-standard metrics for grading machine translation: BLEU, METEOR, and ROUGE.","These metrics allow us to compare the machine responses with the most upvoted human answer to the same question to assess ChatGPT's ability to submit a humanistic reply.","The results showed that while the responses and translation abilities of ChatGPT are remarkable, they still fall short of what a typical human reaction would be."],"url":"http://arxiv.org/abs/2303.12038v1"}
{"created":"2023-01-31","title":"Mathematical Capabilities of ChatGPT","abstract":"We investigate the mathematical capabilities of ChatGPT by testing it on publicly available datasets, as well as hand-crafted ones, and measuring its performance against other models trained on a mathematical corpus, such as Minerva. We also test whether ChatGPT can be a useful assistant to professional mathematicians by emulating various use cases that come up in the daily professional activities of mathematicians (question answering, theorem searching). In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, only cover elementary mathematics. We address this issue by introducing a new dataset: GHOSTS. It is the first natural-language dataset made and curated by working researchers in mathematics that (1) aims to cover graduate-level mathematics and (2) provides a holistic overview of the mathematical capabilities of language models. We benchmark ChatGPT on GHOSTS and evaluate performance against fine-grained criteria. We make this new dataset publicly available to assist a community-driven comparison of ChatGPT with (future) large language models in terms of advanced mathematical comprehension. We conclude that contrary to many positive reports in the media (a potential case of selection bias), ChatGPT's mathematical abilities are significantly below those of an average mathematics graduate student. Our results show that ChatGPT often understands the question but fails to provide correct solutions. Hence, if your goal is to use it to pass a university exam, you would be better off copying from your average peer!","sentences":["We investigate the mathematical capabilities of ChatGPT by testing it on publicly available datasets, as well as hand-crafted ones, and measuring its performance against other models trained on a mathematical corpus, such as Minerva.","We also test whether ChatGPT can be a useful assistant to professional mathematicians by emulating various use cases that come up in the daily professional activities of mathematicians (question answering, theorem searching).","In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, only cover elementary mathematics.","We address this issue by introducing a new dataset: GHOSTS.","It is the first natural-language dataset made and curated by working researchers in mathematics that (1) aims to cover graduate-level mathematics and (2) provides a holistic overview of the mathematical capabilities of language models.","We benchmark ChatGPT on GHOSTS and evaluate performance against fine-grained criteria.","We make this new dataset publicly available to assist a community-driven comparison of ChatGPT with (future) large language models in terms of advanced mathematical comprehension.","We conclude that contrary to many positive reports in the media (a potential case of selection bias), ChatGPT's mathematical abilities are significantly below those of an average mathematics graduate student.","Our results show that ChatGPT often understands the question but fails to provide correct solutions.","Hence, if your goal is to use it to pass a university exam, you would be better off copying from your average peer!"],"url":"http://arxiv.org/abs/2301.13867v1"}
{"created":"2023-01-31","title":"Numeracy from Literacy: Data Science as an Emergent Skill from Large Language Models","abstract":"Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique testbeds for exploring the translation challenges of turning literacy into numeracy. Previous publicly-available transformer models from eighteen months prior and 1000 times smaller failed to provide basic arithmetic. The statistical analysis of four complex datasets described here combines arithmetic manipulations that cannot be memorized or encoded by simple rules. The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding. For example, the work highlights cases for descriptive statistics on in-memory datasets that the LLM initially loads from memory or generates randomly using python libraries. The resulting exploratory data analysis showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression. To extend the model's testable range, the research deletes and appends random rows such that recall alone cannot explain emergent numeracy.","sentences":["Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique testbeds for exploring the translation challenges of turning literacy into numeracy.","Previous publicly-available transformer models from eighteen months prior and 1000 times smaller failed to provide basic arithmetic.","The statistical analysis of four complex datasets described here combines arithmetic manipulations that cannot be memorized or encoded by simple rules.","The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding.","For example, the work highlights cases for descriptive statistics on in-memory datasets that the LLM initially loads from memory or generates randomly using python libraries.","The resulting exploratory data analysis showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression.","To extend the model's testable range, the research deletes and appends random rows such that recall alone cannot explain emergent numeracy."],"url":"http://arxiv.org/abs/2301.13382v1"}
{"created":"2023-01-30","title":"Conversational Automated Program Repair","abstract":"Automated Program Repair (APR) can help developers automatically generate patches for bugs. Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR. However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases. To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner. In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback. As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test. We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach.","sentences":["Automated Program Repair (APR) can help developers automatically generate patches for bugs.","Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR.","However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases.","To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner.","In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback.","As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test.","We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach."],"url":"http://arxiv.org/abs/2301.13246v1"}
{"created":"2023-01-30","title":"Exploring AI Ethics of ChatGPT: A Diagnostic Analysis","abstract":"Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2) \\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.","sentences":["Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications.","The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters.","Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility.","Large-scale benchmarks for accountable LLMs should consequently be developed.","Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use.","To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs.","We analyze ChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2) \\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}.","In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets.","We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies.","In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs.","We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications."],"url":"http://arxiv.org/abs/2301.12867v3"}
{"created":"2023-01-30","title":"ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text","abstract":"ChatGPT has the ability to generate grammatically flawless and seemingly-human replies to different types of questions from various domains. The number of its users and of its applications is growing at an unprecedented rate. Unfortunately, use and abuse come hand in hand. In this paper, we study whether a machine learning model can be effectively trained to accurately distinguish between original human and seemingly human (that is, ChatGPT-generated) text, especially when this text is short. Furthermore, we employ an explainable artificial intelligence framework to gain insight into the reasoning behind the model trained to differentiate between ChatGPT-generated and human-generated text. The goal is to analyze model's decisions and determine if any specific patterns or characteristics can be identified. Our study focuses on short online reviews, conducting two experiments comparing human-generated and ChatGPT-generated text. The first experiment involves ChatGPT text generated from custom queries, while the second experiment involves text generated by rephrasing original human-generated reviews. We fine-tune a Transformer-based model and use it to make predictions, which are then explained using SHAP. We compare our model with a perplexity score-based approach and find that disambiguation between human and ChatGPT-generated reviews is more challenging for the ML model when using rephrased text. However, our proposed approach still achieves an accuracy of 79%. Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.","sentences":["ChatGPT has the ability to generate grammatically flawless and seemingly-human replies to different types of questions from various domains.","The number of its users and of its applications is growing at an unprecedented rate.","Unfortunately, use and abuse come hand in hand.","In this paper, we study whether a machine learning model can be effectively trained to accurately distinguish between original human and seemingly human (that is, ChatGPT-generated) text, especially when this text is short.","Furthermore, we employ an explainable artificial intelligence framework to gain insight into the reasoning behind the model trained to differentiate between ChatGPT-generated and human-generated text.","The goal is to analyze model's decisions and determine if any specific patterns or characteristics can be identified.","Our study focuses on short online reviews, conducting two experiments comparing human-generated and ChatGPT-generated text.","The first experiment involves ChatGPT text generated from custom queries, while the second experiment involves text generated by rephrasing original human-generated reviews.","We fine-tune a Transformer-based model and use it to make predictions, which are then explained using SHAP.","We compare our model with a perplexity score-based approach and find that disambiguation between human and ChatGPT-generated reviews is more challenging for the ML model when using rephrased text.","However, our proposed approach still achieves an accuracy of 79%.","Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings."],"url":"http://arxiv.org/abs/2301.13852v1"}
{"created":"2023-01-28","title":"Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions","abstract":"Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype \"GPTCompare\", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.","sentences":["Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity.","With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project.","Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software.","However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries.","While other solutions can be requested, they are not displayed by default and are not intuitive to access.","In this paper, we present our work-in-progress prototype \"GPTCompare\", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences."],"url":"http://arxiv.org/abs/2301.12169v1"}
{"created":"2023-01-28","title":"Could an Artificial-Intelligence agent pass an introductory physics course?","abstract":"Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false. Just how human-like are these responses when it comes to dialogues about physics, in particular about the standard content of introductory physics courses? This study explores that question by having ChatGTP, the pre-eminent language model in 2023, work through representative assessment content of an actual calculus-based physics course and grading the responses in the same way human responses would be graded. As it turns out, ChatGPT would narrowly pass this course while exhibiting many of the preconceptions and errors of a beginning learner.","sentences":["Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false.","Just how human-like are these responses when it comes to dialogues about physics, in particular about the standard content of introductory physics courses?","This study explores that question by having ChatGTP, the pre-eminent language model in 2023, work through representative assessment content of an actual calculus-based physics course and grading the responses in the same way human responses would be graded.","As it turns out, ChatGPT would narrowly pass this course while exhibiting many of the preconceptions and errors of a beginning learner."],"url":"http://arxiv.org/abs/2301.12127v2"}
{"created":"2023-01-28","title":"Truth Machines: Synthesizing Veracity in AI Language Models","abstract":"As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening \"reality\" are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of \"truth\" do we as listeners desire?","sentences":["As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth.","But truth is highly contested, with many different definitions and approaches.","This article discusses the struggle for truth in AI systems and the general responses to date.","It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity.","It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements.","We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem.","We suggest that enriching sociality and thickening \"reality\" are two promising vectors for enhancing the truth-evaluating capacities of future language models.","We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of \"truth\" do we as listeners desire?"],"url":"http://arxiv.org/abs/2301.12066v1"}
{"created":"2023-01-27","title":"Investigating the use of ChatGPT for the scheduling of construction projects","abstract":"Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks. This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project. The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output. The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated. The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks. However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry. Overall, this study highlights the potential of using large language models in the construction industry and the need for further research.","sentences":["Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks.","This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project.","The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output.","The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated.","The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks.","However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry.","Overall, this study highlights the potential of using large language models in the construction industry and the need for further research."],"url":"http://arxiv.org/abs/2302.02805v1"}
