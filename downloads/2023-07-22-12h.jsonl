{"created":"2023-07-20 17:59:41","title":"L-Eval: Instituting Standardized Evaluation for Long Context Language Models","abstract":"Recently, there has been growing interest in extending the context length of instruction-following models in order to effectively process single-turn long input (e.g. summarizing a paper) and conversations with more extensive histories. While proprietary models such as GPT-4 and Claude have demonstrated considerable advancements in handling tens of thousands of tokens of context, open-sourced models are still in the early stages of experimentation. It also remains unclear whether developing these long context models can offer substantial gains on practical downstream tasks over retrieval-based methods or models simply trained on chunked contexts. To address this challenge, we propose to institute standardized evaluation for long context language models. Concretely, we develop L-Eval which contains 411 long documents and over 2,000 query-response pairs manually annotated and checked by the authors encompassing areas such as law, finance, school lectures, lengthy conversations, news, long-form novels, and meetings. L-Eval also adopts diverse evaluation methods and instruction styles, enabling a more reliable assessment of Long Context Language Models (LCLMs). Our findings indicate that while open-source models typically lag behind their commercial counterparts, they still exhibit impressive performance. LLaMA2 achieves the best results (win 45\\% vs turbo-16k) on open-ended tasks with only 4k context length and ChatGLM2 achieves the best results on closed-ended tasks with 8k input tokens. We release our new evaluation suite, code, and all generation results including predictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at {\\url{https://github.com/OpenLMLab/LEval}}.","sentences":["Recently, there has been growing interest in extending the context length of instruction-following models in order to effectively process single-turn long input (e.g. summarizing a paper) and conversations with more extensive histories.","While proprietary models such as GPT-4 and Claude have demonstrated considerable advancements in handling tens of thousands of tokens of context, open-sourced models are still in the early stages of experimentation.","It also remains unclear whether developing these long context models can offer substantial gains on practical downstream tasks over retrieval-based methods or models simply trained on chunked contexts.","To address this challenge, we propose to institute standardized evaluation for long context language models.","Concretely, we develop L-Eval which contains 411 long documents and over 2,000 query-response pairs manually annotated and checked by the authors encompassing areas such as law, finance, school lectures, lengthy conversations, news, long-form novels, and meetings.","L-Eval also adopts diverse evaluation methods and instruction styles, enabling a more reliable assessment of Long Context Language Models (LCLMs).","Our findings indicate that while open-source models typically lag behind their commercial counterparts, they still exhibit impressive performance.","LLaMA2 achieves the best results (win 45\\% vs turbo-16k) on open-ended tasks with only 4k context length and ChatGLM2 achieves the best results on closed-ended tasks with 8k input tokens.","We release our new evaluation suite, code, and all generation results including predictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at {\\url{https://github.com/OpenLMLab/LEval}}."],"url":"http://arxiv.org/abs/2307.11088v1"}
{"created":"2023-07-20 17:59:33","title":"PAPR: Proximity Attention Point Rendering","abstract":"Learning accurate and parsimonious point cloud representations of scene surfaces from scratch remains a challenge in 3D representation learning. Existing point-based methods often suffer from the vanishing gradient problem or require a large number of points to accurately model scene geometry and texture. To address these limitations, we propose Proximity Attention Point Rendering (PAPR), a novel method that consists of a point-based scene representation and a differentiable renderer. Our scene representation uses a point cloud where each point is characterized by its spatial position, foreground score, and view-independent feature vector. The renderer selects the relevant points for each ray and produces accurate colours using their associated features. PAPR effectively learns point cloud positions to represent the correct scene geometry, even when the initialization drastically differs from the target geometry. Notably, our method captures fine texture details while using only a parsimonious set of points. We also demonstrate four practical applications of our method: geometry editing, object manipulation, texture transfer, and exposure control. More results and code are available on our project website at https://zvict.github.io/papr/.","sentences":["Learning accurate and parsimonious point cloud representations of scene surfaces from scratch remains a challenge in 3D representation learning.","Existing point-based methods often suffer from the vanishing gradient problem or require a large number of points to accurately model scene geometry and texture.","To address these limitations, we propose Proximity Attention Point Rendering (PAPR), a novel method that consists of a point-based scene representation and a differentiable renderer.","Our scene representation uses a point cloud where each point is characterized by its spatial position, foreground score, and view-independent feature vector.","The renderer selects the relevant points for each ray and produces accurate colours using their associated features.","PAPR effectively learns point cloud positions to represent the correct scene geometry, even when the initialization drastically differs from the target geometry.","Notably, our method captures fine texture details while using only a parsimonious set of points.","We also demonstrate four practical applications of our method: geometry editing, object manipulation, texture transfer, and exposure control.","More results and code are available on our project website at https://zvict.github.io/papr/."],"url":"http://arxiv.org/abs/2307.11086v1"}
{"created":"2023-07-20 17:59:11","title":"Representation Learning in Anomaly Detection: Successes, Limits and a Grand Challenge","abstract":"In this perspective paper, we argue that the dominant paradigm in anomaly detection cannot scale indefinitely and will eventually hit fundamental limits. This is due to the a no free lunch principle for anomaly detection. These limitations can be overcome when there are strong tasks priors, as is the case for many industrial tasks. When such priors do not exists, the task is much harder for anomaly detection. We pose two such tasks as grand challenges for anomaly detection: i) scientific discovery by anomaly detection ii) a \"mini-grand\" challenge of detecting the most anomalous image in the ImageNet dataset. We believe new anomaly detection tools and ideas would need to be developed to overcome these challenges.","sentences":["In this perspective paper, we argue that the dominant paradigm in anomaly detection cannot scale indefinitely and will eventually hit fundamental limits.","This is due to the a no free lunch principle for anomaly detection.","These limitations can be overcome when there are strong tasks priors, as is the case for many industrial tasks.","When such priors do not exists, the task is much harder for anomaly detection.","We pose two such tasks as grand challenges for anomaly detection: i) scientific discovery by anomaly detection ii) a \"mini-grand\" challenge of detecting the most anomalous image in the ImageNet dataset.","We believe new anomaly detection tools and ideas would need to be developed to overcome these challenges."],"url":"http://arxiv.org/abs/2307.11085v1"}
{"created":"2023-07-20 17:57:04","title":"GLSFormer: Gated - Long, Short Sequence Transformer for Step Recognition in Surgical Videos","abstract":"Automated surgical step recognition is an important task that can significantly improve patient safety and decision-making during surgeries. Existing state-of-the-art methods for surgical step recognition either rely on separate, multi-stage modeling of spatial and temporal information or operate on short-range temporal resolution when learned jointly. However, the benefits of joint modeling of spatio-temporal features and long-range information are not taken in account. In this paper, we propose a vision transformer-based approach to jointly learn spatio-temporal features directly from sequence of frame-level patches. Our method incorporates a gated-temporal attention mechanism that intelligently combines short-term and long-term spatio-temporal feature representations. We extensively evaluate our approach on two cataract surgery video datasets, namely Cataract-101 and D99, and demonstrate superior performance compared to various state-of-the-art methods. These results validate the suitability of our proposed approach for automated surgical step recognition. Our code is released at: https://github.com/nisargshah1999/GLSFormer","sentences":["Automated surgical step recognition is an important task that can significantly improve patient safety and decision-making during surgeries.","Existing state-of-the-art methods for surgical step recognition either rely on separate, multi-stage modeling of spatial and temporal information or operate on short-range temporal resolution when learned jointly.","However, the benefits of joint modeling of spatio-temporal features and long-range information are not taken in account.","In this paper, we propose a vision transformer-based approach to jointly learn spatio-temporal features directly from sequence of frame-level patches.","Our method incorporates a gated-temporal attention mechanism that intelligently combines short-term and long-term spatio-temporal feature representations.","We extensively evaluate our approach on two cataract surgery video datasets, namely Cataract-101 and D99, and demonstrate superior performance compared to various state-of-the-art methods.","These results validate the suitability of our proposed approach for automated surgical step recognition.","Our code is released at: https://github.com/nisargshah1999/GLSFormer"],"url":"http://arxiv.org/abs/2307.11081v1"}
{"created":"2023-07-20 17:55:14","title":"AlignDet: Aligning Pre-training and Fine-tuning in Object Detection","abstract":"The paradigm of large-scale pre-training followed by downstream fine-tuning has been widely employed in various object detection algorithms. In this paper, we reveal discrepancies in data, model, and task between the pre-training and fine-tuning procedure in existing practices, which implicitly limit the detector's performance, generalization ability, and convergence speed. To this end, we propose AlignDet, a unified pre-training framework that can be adapted to various existing detectors to alleviate the discrepancies. AlignDet decouples the pre-training process into two stages, i.e., image-domain and box-domain pre-training. The image-domain pre-training optimizes the detection backbone to capture holistic visual abstraction, and box-domain pre-training learns instance-level semantics and task-aware concepts to initialize the parts out of the backbone. By incorporating the self-supervised pre-trained backbones, we can pre-train all modules for various detectors in an unsupervised paradigm. As depicted in Figure 1, extensive experiments demonstrate that AlignDet can achieve significant improvements across diverse protocols, such as detection algorithm, model backbone, data setting, and training schedule. For example, AlignDet improves FCOS by 5.3 mAP, RetinaNet by 2.1 mAP, Faster R-CNN by 3.3 mAP, and DETR by 2.3 mAP under fewer epochs.","sentences":["The paradigm of large-scale pre-training followed by downstream fine-tuning has been widely employed in various object detection algorithms.","In this paper, we reveal discrepancies in data, model, and task between the pre-training and fine-tuning procedure in existing practices, which implicitly limit the detector's performance, generalization ability, and convergence speed.","To this end, we propose AlignDet, a unified pre-training framework that can be adapted to various existing detectors to alleviate the discrepancies.","AlignDet decouples the pre-training process into two stages, i.e., image-domain and box-domain pre-training.","The image-domain pre-training optimizes the detection backbone to capture holistic visual abstraction, and box-domain pre-training learns instance-level semantics and task-aware concepts to initialize the parts out of the backbone.","By incorporating the self-supervised pre-trained backbones, we can pre-train all modules for various detectors in an unsupervised paradigm.","As depicted in Figure 1, extensive experiments demonstrate that AlignDet can achieve significant improvements across diverse protocols, such as detection algorithm, model backbone, data setting, and training schedule.","For example, AlignDet improves FCOS by 5.3 mAP, RetinaNet by 2.1 mAP, Faster R-CNN by 3.3 mAP, and DETR by 2.3 mAP under fewer epochs."],"url":"http://arxiv.org/abs/2307.11077v1"}
{"created":"2023-07-20 17:53:57","title":"Learning Dense UV Completion for Human Mesh Recovery","abstract":"Human mesh reconstruction from a single image is challenging in the presence of occlusion, which can be caused by self, objects, or other humans. Existing methods either fail to separate human features accurately or lack proper supervision for feature completion. In this paper, we propose Dense Inpainting Human Mesh Recovery (DIMR), a two-stage method that leverages dense correspondence maps to handle occlusion. Our method utilizes a dense correspondence map to separate visible human features and completes human features on a structured UV map dense human with an attention-based feature completion module. We also design a feature inpainting training procedure that guides the network to learn from unoccluded features. We evaluate our method on several datasets and demonstrate its superior performance under heavily occluded scenarios compared to other methods. Extensive experiments show that our method obviously outperforms prior SOTA methods on heavily occluded images and achieves comparable results on the standard benchmarks (3DPW).","sentences":["Human mesh reconstruction from a single image is challenging in the presence of occlusion, which can be caused by self, objects, or other humans.","Existing methods either fail to separate human features accurately or lack proper supervision for feature completion.","In this paper, we propose Dense Inpainting Human Mesh Recovery (DIMR), a two-stage method that leverages dense correspondence maps to handle occlusion.","Our method utilizes a dense correspondence map to separate visible human features and completes human features on a structured UV map dense human with an attention-based feature completion module.","We also design a feature inpainting training procedure that guides the network to learn from unoccluded features.","We evaluate our method on several datasets and demonstrate its superior performance under heavily occluded scenarios compared to other methods.","Extensive experiments show that our method obviously outperforms prior SOTA methods on heavily occluded images and achieves comparable results on the standard benchmarks (3DPW)."],"url":"http://arxiv.org/abs/2307.11074v1"}
{"created":"2023-07-20 17:53:46","title":"OBJECT 3DIT: Language-guided 3D-aware Image Editing","abstract":"Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected. As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process. In this work, we formulate the newt ask of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction in context of the underlying 3D scene. To promote progress towards this goal, we release OBJECT: a dataset consisting of 400K editing examples created from procedurally generated 3D scenes. Each example consists of an input image, editing instruction in language, and the edited image. We also introduce 3DIT : single and multi-task models for four editing tasks. Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations. Surprisingly, training on only synthetic scenes from OBJECT, editing capabilities of 3DIT generalize to real-world images.","sentences":["Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected.","As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process.","In this work, we formulate the newt ask of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction in context of the underlying 3D scene.","To promote progress towards this goal, we release OBJECT: a dataset consisting of 400K editing examples created from procedurally generated 3D scenes.","Each example consists of an input image, editing instruction in language, and the edited image.","We also introduce 3DIT : single and multi-task models for four editing tasks.","Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations.","Surprisingly, training on only synthetic scenes from OBJECT, editing capabilities of 3DIT generalize to real-world images."],"url":"http://arxiv.org/abs/2307.11073v1"}
{"created":"2023-07-20 17:52:19","title":"Effectiveness and predictability of in-network storage cache for scientific workflows","abstract":"Large scientific collaborations often have multiple scientists accessing the same set of files while doing different analyses, which create repeated accesses to the large amounts of shared data located far away. These data accesses have long latency due to distance and occupy the limited bandwidth available over the wide-area network. To reduce the wide-area network traffic and the data access latency, regional data storage caches have been installed as a new networking service. To study the effectiveness of such a cache system in scientific applications, we examine the Southern California Petabyte Scale Cache for a high-energy physics experiment. By examining about 3TB of operational logs, we show that this cache removed 67.6% of file requests from the wide-area network and reduced the traffic volume on wide-area network by 12.3TB (or 35.4%) an average day. The reduction in the traffic volume (35.4%) is less than the reduction in file counts (67.6%) because the larger files are less likely to be reused. Due to this difference in data access patterns, the cache system has implemented a policy to avoid evicting smaller files when processing larger files. We also build a machine learning model to study the predictability of the cache behavior. Tests show that this model is able to accurately predict the cache accesses, cache misses, and network throughput, making the model useful for future studies on resource provisioning and planning.","sentences":["Large scientific collaborations often have multiple scientists accessing the same set of files while doing different analyses, which create repeated accesses to the large amounts of shared data located far away.","These data accesses have long latency due to distance and occupy the limited bandwidth available over the wide-area network.","To reduce the wide-area network traffic and the data access latency, regional data storage caches have been installed as a new networking service.","To study the effectiveness of such a cache system in scientific applications, we examine the Southern California Petabyte Scale Cache for a high-energy physics experiment.","By examining about 3TB of operational logs, we show that this cache removed 67.6% of file requests from the wide-area network and reduced the traffic volume on wide-area network by 12.3TB (or 35.4%) an average day.","The reduction in the traffic volume (35.4%) is less than the reduction in file counts (67.6%) because the larger files are less likely to be reused.","Due to this difference in data access patterns, the cache system has implemented a policy to avoid evicting smaller files when processing larger files.","We also build a machine learning model to study the predictability of the cache behavior.","Tests show that this model is able to accurately predict the cache accesses, cache misses, and network throughput, making the model useful for future studies on resource provisioning and planning."],"url":"http://arxiv.org/abs/2307.11069v1"}
{"created":"2023-07-20 17:46:21","title":"CNOS: A Strong Baseline for CAD-based Novel Object Segmentation","abstract":"We propose a simple three-stage approach to segment unseen objects in RGB images using their CAD models. Leveraging recent powerful foundation models, DINOv2 and Segment Anything, we create descriptors and generate proposals, including binary masks for a given input RGB image. By matching proposals with reference descriptors created from CAD models, we achieve precise object ID assignment along with modal masks. We experimentally demonstrate that our method achieves state-of-the-art results in CAD-based novel object segmentation, surpassing existing approaches on the seven core datasets of the BOP challenge by 19.8\\% AP using the same BOP evaluation protocol. Our source code is available at https://github.com/nv-nguyen/cnos.","sentences":["We propose a simple three-stage approach to segment unseen objects in RGB images using their CAD models.","Leveraging recent powerful foundation models, DINOv2 and Segment Anything, we create descriptors and generate proposals, including binary masks for a given input RGB image.","By matching proposals with reference descriptors created from CAD models, we achieve precise object ID assignment along with modal masks.","We experimentally demonstrate that our method achieves state-of-the-art results in CAD-based novel object segmentation, surpassing existing approaches on the seven core datasets of the BOP challenge by 19.8\\% AP using the same BOP evaluation protocol.","Our source code is available at https://github.com/nv-nguyen/cnos."],"url":"http://arxiv.org/abs/2307.11067v1"}
{"created":"2023-07-20 17:44:41","title":"Profit allocation in agricultural supply chains: exploring the nexus of cooperation and compensation","abstract":"In this paper, we focus on decentralized agricultural supply chains consisting of multiple non-competing distributors satisfying the demand of their respective markets. These distributors source a single product from a farmer through an agricultural cooperative, operating in a single period. The agents have the ability to coordinate their actions to maximize their profits, and we use cooperative game theory to analyze cooperation among them. The distributors can engage in joint ordering, increasing their order size, which leads to a decrease in the price per kilogram. Additionally, distributors have the opportunity to cooperate with the farmer, securing a reduced price per kilogram at the cost price, while compensating the farmer for any kilograms not acquired in the cooperation agreement. We introduce multidistributor-farmer games and we prove that all the agents have incentives to cooperate. We demonstrate the existence of stable allocations, where no subgroup of agents can be better off by separating. Moreover, we propose and characterize a distribution of the total profit that justly compensates the contribution of the farmer in any group of distributors. Finally, we explore the conditions under which the farmer can be compensated in order to maximize their revenues when cooperating with all players.","sentences":["In this paper, we focus on decentralized agricultural supply chains consisting of multiple non-competing distributors satisfying the demand of their respective markets.","These distributors source a single product from a farmer through an agricultural cooperative, operating in a single period.","The agents have the ability to coordinate their actions to maximize their profits, and we use cooperative game theory to analyze cooperation among them.","The distributors can engage in joint ordering, increasing their order size, which leads to a decrease in the price per kilogram.","Additionally, distributors have the opportunity to cooperate with the farmer, securing a reduced price per kilogram at the cost price, while compensating the farmer for any kilograms not acquired in the cooperation agreement.","We introduce multidistributor-farmer games and we prove that all the agents have incentives to cooperate.","We demonstrate the existence of stable allocations, where no subgroup of agents can be better off by separating.","Moreover, we propose and characterize a distribution of the total profit that justly compensates the contribution of the farmer in any group of distributors.","Finally, we explore the conditions under which the farmer can be compensated in order to maximize their revenues when cooperating with all players."],"url":"http://arxiv.org/abs/2307.11065v1"}
{"created":"2023-07-20 17:41:01","title":"The Changing Role of RSEs over the Lifetime of Parsl","abstract":"This position paper describes the Parsl open source research software project and its various phases over seven years. It defines four types of research software engineers (RSEs) who have been important to the project in those phases; we believe this is also applicable to other research software projects.","sentences":["This position paper describes the Parsl open source research software project and its various phases over seven years.","It defines four types of research software engineers (RSEs) who have been important to the project in those phases; we believe this is also applicable to other research software projects."],"url":"http://arxiv.org/abs/2307.11060v1"}
{"created":"2023-07-20 17:38:55","title":"Driving Policy Prediction based on Deep Learning Models","abstract":"In this project, we implemented an end-to-end system that takes in combined visual features of video frames from a normal camera and depth information from a cloud points scanner, and predicts driving policies (vehicle speed and steering angle). We verified the safety of our system by comparing the predicted results with standard behaviors by real-world experienced drivers. Our test results show that the predictions can be considered as accurate in at lease half of the testing cases (50% 80%, depending on the model), and using combined features improved the performance in most cases than using video frames only.","sentences":["In this project, we implemented an end-to-end system that takes in combined visual features of video frames from a normal camera and depth information from a cloud points scanner, and predicts driving policies (vehicle speed and steering angle).","We verified the safety of our system by comparing the predicted results with standard behaviors by real-world experienced drivers.","Our test results show that the predictions can be considered as accurate in at lease half of the testing cases (50% 80%, depending on the model), and using combined features improved the performance in most cases than using video frames only."],"url":"http://arxiv.org/abs/2307.11058v1"}
{"created":"2023-07-20 17:37:48","title":"Two-way automata and transducers with planar behaviours are aperiodic","abstract":"We consider a notion of planarity for two-way finite automata and transducers, inspired by Temperley-Lieb monoids of planar diagrams. We show that this restriction captures star-free languages and first-order transductions.","sentences":["We consider a notion of planarity for two-way finite automata and transducers, inspired by Temperley-Lieb monoids of planar diagrams.","We show that this restriction captures star-free languages and first-order transductions."],"url":"http://arxiv.org/abs/2307.11057v1"}
{"created":"2023-07-20 17:35:37","title":"DataXploreFines: Generalized Data for Informed Decision, Making, An Interactive Shiny Application for Data Analysis and Visualization","abstract":"This article presents DataXploreFines, an innovative Shiny application that revolutionizes data exploration, analysis, and visualization. The application offers functionalities for data loading, management, summarization, basic graphs, advanced analysis, and contact. Users can upload their datasets in popular formats like CSV or Excel, explore the data structure, perform manipulations, and obtain statistical summaries. DataXploreFines provides a wide range of interactive visualizations, including histograms, scatter plots, bar charts, and line graphs, enabling users to identify patterns and trends. Additionally, the application offers statistical tools such as time series analysis using ARIMA and SARIMA models, forecasting, and Ljung-Box statistic. Its user-friendly interface empowers individuals from various domains, including beginners in statistics, to make informed decisions.","sentences":["This article presents DataXploreFines, an innovative Shiny application that revolutionizes data exploration, analysis, and visualization.","The application offers functionalities for data loading, management, summarization, basic graphs, advanced analysis, and contact.","Users can upload their datasets in popular formats like CSV or Excel, explore the data structure, perform manipulations, and obtain statistical summaries.","DataXploreFines provides a wide range of interactive visualizations, including histograms, scatter plots, bar charts, and line graphs, enabling users to identify patterns and trends.","Additionally, the application offers statistical tools such as time series analysis using ARIMA and SARIMA models, forecasting, and Ljung-Box statistic.","Its user-friendly interface empowers individuals from various domains, including beginners in statistics, to make informed decisions."],"url":"http://arxiv.org/abs/2307.11056v1"}
{"created":"2023-07-20 17:33:57","title":"HRFNet: High-Resolution Forgery Network for Localizing Satellite Image Manipulation","abstract":"Existing high-resolution satellite image forgery localization methods rely on patch-based or downsampling-based training. Both of these training methods have major drawbacks, such as inaccurate boundaries between pristine and forged regions, the generation of unwanted artifacts, etc. To tackle the aforementioned challenges, inspired by the high-resolution image segmentation literature, we propose a novel model called HRFNet to enable satellite image forgery localization effectively. Specifically, equipped with shallow and deep branches, our model can successfully integrate RGB and resampling features in both global and local manners to localize forgery more accurately. We perform various experiments to demonstrate that our method achieves the best performance, while the memory requirement and processing speed are not compromised compared to existing methods.","sentences":["Existing high-resolution satellite image forgery localization methods rely on patch-based or downsampling-based training.","Both of these training methods have major drawbacks, such as inaccurate boundaries between pristine and forged regions, the generation of unwanted artifacts, etc.","To tackle the aforementioned challenges, inspired by the high-resolution image segmentation literature, we propose a novel model called HRFNet to enable satellite image forgery localization effectively.","Specifically, equipped with shallow and deep branches, our model can successfully integrate RGB and resampling features in both global and local manners to localize forgery more accurately.","We perform various experiments to demonstrate that our method achieves the best performance, while the memory requirement and processing speed are not compromised compared to existing methods."],"url":"http://arxiv.org/abs/2307.11052v1"}
{"created":"2023-07-20 17:30:37","title":"Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-Loop Feedback","abstract":"Exploration and reward specification are fundamental and intertwined challenges for reinforcement learning. Solving sequential decision-making tasks requiring expansive exploration requires either careful design of reward functions or the use of novelty-seeking exploration bonuses. Human supervisors can provide effective guidance in the loop to direct the exploration process, but prior methods to leverage this guidance require constant synchronous high-quality human feedback, which is expensive and impractical to obtain. In this work, we present a technique called Human Guided Exploration (HuGE), which uses low-quality feedback from non-expert users that may be sporadic, asynchronous, and noisy. HuGE guides exploration for reinforcement learning not only in simulation but also in the real world, all without meticulous reward specification. The key concept involves bifurcating human feedback and policy learning: human feedback steers exploration, while self-supervised learning from the exploration data yields unbiased policies. This procedure can leverage noisy, asynchronous human feedback to learn policies with no hand-crafted reward design or exploration bonuses. HuGE is able to learn a variety of challenging multi-stage robotic navigation and manipulation tasks in simulation using crowdsourced feedback from non-expert users. Moreover, this paradigm can be scaled to learning directly on real-world robots, using occasional, asynchronous feedback from human supervisors.","sentences":["Exploration and reward specification are fundamental and intertwined challenges for reinforcement learning.","Solving sequential decision-making tasks requiring expansive exploration requires either careful design of reward functions or the use of novelty-seeking exploration bonuses.","Human supervisors can provide effective guidance in the loop to direct the exploration process, but prior methods to leverage this guidance require constant synchronous high-quality human feedback, which is expensive and impractical to obtain.","In this work, we present a technique called Human Guided Exploration (HuGE), which uses low-quality feedback from non-expert users that may be sporadic, asynchronous, and noisy.","HuGE guides exploration for reinforcement learning not only in simulation but also in the real world, all without meticulous reward specification.","The key concept involves bifurcating human feedback and policy learning: human feedback steers exploration, while self-supervised learning from the exploration data yields unbiased policies.","This procedure can leverage noisy, asynchronous human feedback to learn policies with no hand-crafted reward design or exploration bonuses.","HuGE is able to learn a variety of challenging multi-stage robotic navigation and manipulation tasks in simulation using crowdsourced feedback from non-expert users.","Moreover, this paradigm can be scaled to learning directly on real-world robots, using occasional, asynchronous feedback from human supervisors."],"url":"http://arxiv.org/abs/2307.11049v1"}
{"created":"2023-07-20 17:27:29","title":"On the Convergence of Bounded Agents","abstract":"When has an agent converged? Standard models of the reinforcement learning problem give rise to a straightforward definition of convergence: An agent converges when its behavior or performance in each environment state stops changing. However, as we shift the focus of our learning problem from the environment's state to the agent's state, the concept of an agent's convergence becomes significantly less clear. In this paper, we propose two complementary accounts of agent convergence in a framing of the reinforcement learning problem that centers around bounded agents. The first view says that a bounded agent has converged when the minimal number of states needed to describe the agent's future behavior cannot decrease. The second view says that a bounded agent has converged just when the agent's performance only changes if the agent's internal state changes. We establish basic properties of these two definitions, show that they accommodate typical views of convergence in standard settings, and prove several facts about their nature and relationship. We take these perspectives, definitions, and analysis to bring clarity to a central idea of the field.","sentences":["When has an agent converged?","Standard models of the reinforcement learning problem give rise to a straightforward definition of convergence: An agent converges when its behavior or performance in each environment state stops changing.","However, as we shift the focus of our learning problem from the environment's state to the agent's state, the concept of an agent's convergence becomes significantly less clear.","In this paper, we propose two complementary accounts of agent convergence in a framing of the reinforcement learning problem that centers around bounded agents.","The first view says that a bounded agent has converged when the minimal number of states needed to describe the agent's future behavior cannot decrease.","The second view says that a bounded agent has converged just when the agent's performance only changes if the agent's internal state changes.","We establish basic properties of these two definitions, show that they accommodate typical views of convergence in standard settings, and prove several facts about their nature and relationship.","We take these perspectives, definitions, and analysis to bring clarity to a central idea of the field."],"url":"http://arxiv.org/abs/2307.11044v1"}
{"created":"2023-07-20 17:27:22","title":"Hypergraph Diffusions and Resolvents for Norm-Based Hypergraph Laplacians","abstract":"The development of simple and fast hypergraph spectral methods has been hindered by the lack of numerical algorithms for simulating heat diffusions and computing fundamental objects, such as Personalized PageRank vectors, over hypergraphs. In this paper, we overcome this challenge by designing two novel algorithmic primitives. The first is a simple, easy-to-compute discrete-time heat diffusion that enjoys the same favorable properties as the discrete-time heat diffusion over graphs. This diffusion can be directly applied to speed up existing hypergraph partitioning algorithms.   Our second contribution is the novel application of mirror descent to compute resolvents of non-differentiable squared norms, which we believe to be of independent interest beyond hypergraph problems. Based on this new primitive, we derive the first nearly-linear-time algorithm that simulates the discrete-time heat diffusion to approximately compute resolvents of the hypergraph Laplacian operator, which include Personalized PageRank vectors and solutions to the hypergraph analogue of Laplacian systems. Our algorithm runs in time that is linear in the size of the hypergraph and inversely proportional to the hypergraph spectral gap $\\lambda_G$, matching the complexity of analogous diffusion-based algorithms for the graph version of the problem.","sentences":["The development of simple and fast hypergraph spectral methods has been hindered by the lack of numerical algorithms for simulating heat diffusions and computing fundamental objects, such as Personalized PageRank vectors, over hypergraphs.","In this paper, we overcome this challenge by designing two novel algorithmic primitives.","The first is a simple, easy-to-compute discrete-time heat diffusion that enjoys the same favorable properties as the discrete-time heat diffusion over graphs.","This diffusion can be directly applied to speed up existing hypergraph partitioning algorithms.   ","Our second contribution is the novel application of mirror descent to compute resolvents of non-differentiable squared norms, which we believe to be of independent interest beyond hypergraph problems.","Based on this new primitive, we derive the first nearly-linear-time algorithm that simulates the discrete-time heat diffusion to approximately compute resolvents of the hypergraph Laplacian operator, which include Personalized PageRank vectors and solutions to the hypergraph analogue of Laplacian systems.","Our algorithm runs in time that is linear in the size of the hypergraph and inversely proportional to the hypergraph spectral gap $\\lambda_G$, matching the complexity of analogous diffusion-based algorithms for the graph version of the problem."],"url":"http://arxiv.org/abs/2307.11042v1"}
{"created":"2023-07-20 17:20:25","title":"To What Extent Are Honeypots and Honeynets Autonomic Computing Systems?","abstract":"Cyber threats, such as advanced persistent threats (APTs), ransomware, and zero-day exploits, are rapidly evolving and demand improved security measures. Honeypots and honeynets, as deceptive systems, offer valuable insights into attacker behavior, helping researchers and practitioners develop innovative defense strategies and enhance detection mechanisms. However, their deployment involves significant maintenance and overhead expenses. At the same time, the complexity of modern computing has prompted the rise of autonomic computing, aiming for systems that can operate without human intervention. Recent honeypot and honeynet research claims to incorporate autonomic computing principles, often using terms like adaptive, dynamic, intelligent, and learning. This study investigates such claims by measuring the extent to which autonomic principles principles are expressed in honeypot and honeynet literature. The findings reveal that autonomic computing keywords are present in the literature sample, suggesting an evolution from self-adaptation to autonomic computing implementations. Yet, despite these findings, the analysis also shows low frequencies of self-configuration, self-healing, and self-protection keywords. Interestingly, self-optimization appeared prominently in the literature. While this study presents a foundation for the convergence of autonomic computing and deceptive systems, future research could explore technical implementations in sample articles and test them for autonomic behavior. Additionally, investigations into the design and implementation of individual autonomic computing principles in honeypots and determining the necessary ratio of these principles for a system to exhibit autonomic behavior could provide valuable insights for both researchers and practitioners.","sentences":["Cyber threats, such as advanced persistent threats (APTs), ransomware, and zero-day exploits, are rapidly evolving and demand improved security measures.","Honeypots and honeynets, as deceptive systems, offer valuable insights into attacker behavior, helping researchers and practitioners develop innovative defense strategies and enhance detection mechanisms.","However, their deployment involves significant maintenance and overhead expenses.","At the same time, the complexity of modern computing has prompted the rise of autonomic computing, aiming for systems that can operate without human intervention.","Recent honeypot and honeynet research claims to incorporate autonomic computing principles, often using terms like adaptive, dynamic, intelligent, and learning.","This study investigates such claims by measuring the extent to which autonomic principles principles are expressed in honeypot and honeynet literature.","The findings reveal that autonomic computing keywords are present in the literature sample, suggesting an evolution from self-adaptation to autonomic computing implementations.","Yet, despite these findings, the analysis also shows low frequencies of self-configuration, self-healing, and self-protection keywords.","Interestingly, self-optimization appeared prominently in the literature.","While this study presents a foundation for the convergence of autonomic computing and deceptive systems, future research could explore technical implementations in sample articles and test them for autonomic behavior.","Additionally, investigations into the design and implementation of individual autonomic computing principles in honeypots and determining the necessary ratio of these principles for a system to exhibit autonomic behavior could provide valuable insights for both researchers and practitioners."],"url":"http://arxiv.org/abs/2307.11038v1"}
{"created":"2023-07-20 17:11:20","title":"Cascade-DETR: Delving into High-Quality Universal Object Detection","abstract":"Object localization in general environments is a fundamental part of vision systems. While dominating on the COCO benchmark, recent Transformer-based detection methods are not competitive in diverse domains. Moreover, these methods still struggle to very accurately estimate the object bounding boxes in complex environments.   We introduce Cascade-DETR for high-quality universal object detection. We jointly tackle the generalization to diverse domains and localization accuracy by proposing the Cascade Attention layer, which explicitly integrates object-centric information into the detection decoder by limiting the attention to the previous box prediction. To further enhance accuracy, we also revisit the scoring of queries. Instead of relying on classification scores, we predict the expected IoU of the query, leading to substantially more well-calibrated confidences. Lastly, we introduce a universal object detection benchmark, UDB10, that contains 10 datasets from diverse domains. While also advancing the state-of-the-art on COCO, Cascade-DETR substantially improves DETR-based detectors on all datasets in UDB10, even by over 10 mAP in some cases. The improvements under stringent quality requirements are even more pronounced. Our code and models will be released at https://github.com/SysCV/cascade-detr.","sentences":["Object localization in general environments is a fundamental part of vision systems.","While dominating on the COCO benchmark, recent Transformer-based detection methods are not competitive in diverse domains.","Moreover, these methods still struggle to very accurately estimate the object bounding boxes in complex environments.   ","We introduce Cascade-DETR for high-quality universal object detection.","We jointly tackle the generalization to diverse domains and localization accuracy by proposing the Cascade Attention layer, which explicitly integrates object-centric information into the detection decoder by limiting the attention to the previous box prediction.","To further enhance accuracy, we also revisit the scoring of queries.","Instead of relying on classification scores, we predict the expected IoU of the query, leading to substantially more well-calibrated confidences.","Lastly, we introduce a universal object detection benchmark, UDB10, that contains 10 datasets from diverse domains.","While also advancing the state-of-the-art on COCO, Cascade-DETR substantially improves DETR-based detectors on all datasets in UDB10, even by over 10 mAP in some cases.","The improvements under stringent quality requirements are even more pronounced.","Our code and models will be released at https://github.com/SysCV/cascade-detr."],"url":"http://arxiv.org/abs/2307.11035v1"}
{"created":"2023-07-20 17:07:28","title":"Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification","abstract":"Recent work has shown that language models' (LMs) prompt-based learning capabilities make them well suited for automating data labeling in domains where manual annotation is expensive. The challenge is that while writing an initial prompt is cheap, improving a prompt is costly -- practitioners often require significant labeled data in order to evaluate the impact of prompt modifications. Our work asks whether it is possible to improve prompt-based learning without additional labeled data. We approach this problem by attempting to modify the predictions of a prompt, rather than the prompt itself. Our intuition is that accurate predictions should also be consistent: samples which are similar under some feature representation should receive the same prompt prediction. We propose Embroid, a method which computes multiple representations of a dataset under different embedding functions, and uses the consistency between the LM predictions for neighboring samples to identify mispredictions. Embroid then uses these neighborhoods to create additional predictions for each sample, and combines these predictions with a simple latent variable graphical model in order to generate a final corrected prediction. In addition to providing a theoretical analysis of Embroid, we conduct a rigorous empirical evaluation across six different LMs and up to 95 different tasks. We find that (1) Embroid substantially improves performance over original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) also realizes improvements for more sophisticated prompting strategies (e.g., chain-of-thought), and (3) can be specialized to domains like law through the embedding functions.","sentences":["Recent work has shown that language models' (LMs) prompt-based learning capabilities make them well suited for automating data labeling in domains where manual annotation is expensive.","The challenge is that while writing an initial prompt is cheap, improving a prompt is costly -- practitioners often require significant labeled data in order to evaluate the impact of prompt modifications.","Our work asks whether it is possible to improve prompt-based learning without additional labeled data.","We approach this problem by attempting to modify the predictions of a prompt, rather than the prompt itself.","Our intuition is that accurate predictions should also be consistent: samples which are similar under some feature representation should receive the same prompt prediction.","We propose Embroid, a method which computes multiple representations of a dataset under different embedding functions, and uses the consistency between the LM predictions for neighboring samples to identify mispredictions.","Embroid then uses these neighborhoods to create additional predictions for each sample, and combines these predictions with a simple latent variable graphical model in order to generate a final corrected prediction.","In addition to providing a theoretical analysis of Embroid, we conduct a rigorous empirical evaluation across six different LMs and up to 95 different tasks.","We find that (1) Embroid substantially improves performance over original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) also realizes improvements for more sophisticated prompting strategies (e.g., chain-of-thought), and (3) can be specialized to domains like law through the embedding functions."],"url":"http://arxiv.org/abs/2307.11031v1"}
{"created":"2023-07-20 16:55:25","title":"\"It Felt Like Having a Second Mind\": Investigating Human-AI Co-creativity in Prewriting with Large Language Models","abstract":"Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.","sentences":["Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc.","Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting.","The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear.","To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing.","The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages.","This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs.","This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process."],"url":"http://arxiv.org/abs/2307.10811v1"}
{"created":"2023-07-20 16:53:41","title":"Investigating VTubing as a Reconstruction of Streamer Self-Presentation: Identity, Performance, and Gender","abstract":"VTubers, or Virtual YouTubers, are live streamers who create streaming content using animated 2D or 3D virtual avatars. In recent years, there has been a significant increase in the number of VTuber creators and viewers across the globe. This practise has drawn research attention into topics such as viewers' engagement behaviors and perceptions, however, as animated avatars offer more identity and performance flexibility than traditional live streaming where one uses their own body, little research has focused on how this flexibility influences how creators present themselves. This research thus seeks to fill this gap by presenting results from a qualitative study of 16 Chinese-speaking VTubers' streaming practices. The data revealed that the virtual avatars that were used while live streaming afforded creators opportunities to present themselves using inflated presentations and resulted in inclusive interactions with viewers. The results also unveiled the inflated, and often sexualized, gender expressions of VTubers while they were situated in misogynistic environments. The socio-technical facets of VTubing were found to potentially reduce sexual harassment and sexism, whilst also raising self-objectification concerns.","sentences":["VTubers, or Virtual YouTubers, are live streamers who create streaming content using animated 2D or 3D virtual avatars.","In recent years, there has been a significant increase in the number of VTuber creators and viewers across the globe.","This practise has drawn research attention into topics such as viewers' engagement behaviors and perceptions, however, as animated avatars offer more identity and performance flexibility than traditional live streaming where one uses their own body, little research has focused on how this flexibility influences how creators present themselves.","This research thus seeks to fill this gap by presenting results from a qualitative study of 16 Chinese-speaking VTubers' streaming practices.","The data revealed that the virtual avatars that were used while live streaming afforded creators opportunities to present themselves using inflated presentations and resulted in inclusive interactions with viewers.","The results also unveiled the inflated, and often sexualized, gender expressions of VTubers while they were situated in misogynistic environments.","The socio-technical facets of VTubing were found to potentially reduce sexual harassment and sexism, whilst also raising self-objectification concerns."],"url":"http://arxiv.org/abs/2307.11025v1"}
{"created":"2023-07-20 16:53:04","title":"Automated Termination Proofs for C Programs with Lists (Short WST Version)","abstract":"There are many techniques and tools for termination of C programs, but up to now they were not very powerful for termination proofs of programs whose termination depends on recursive data structures like lists. We present the first approach that extends powerful techniques for termination analysis of C programs (with memory allocation and explicit pointer arithmetic) to lists.","sentences":["There are many techniques and tools for termination of C programs, but up to now they were not very powerful for termination proofs of programs whose termination depends on recursive data structures like lists.","We present the first approach that extends powerful techniques for termination analysis of C programs (with memory allocation and explicit pointer arithmetic) to lists."],"url":"http://arxiv.org/abs/2307.11024v1"}
{"created":"2023-07-20 16:50:39","title":"Visual Flow-based Programming Plugin for Brain Computer Interface in Computer-Aided Design","abstract":"Over the last half century, the main application of Brain Computer Interfaces, BCIs has been controlling wheelchairs and neural prostheses or generating text or commands for people with restricted mobility. There has been very limited attention in the field to applications for computer aided design, despite the potential of BCIs to provide a new form of environmental interaction. In this paper we introduce the development and application of Neuron, a novel BCI tool that enables designers with little experience in neuroscience or computer programming to gain access to neurological data, along with established metrics relevant to design, create BCI interaction prototypes, both with digital onscreen objects and physical devices, and evaluate designs based on neurological information and record measurements for further analysis. After discussing the BCI tool development, the article presents its capabilities through two case studies, along with a brief evaluation of the tool performance and a discussion of implications, limitations, and future improvement.","sentences":["Over the last half century, the main application of Brain Computer Interfaces, BCIs has been controlling wheelchairs and neural prostheses or generating text or commands for people with restricted mobility.","There has been very limited attention in the field to applications for computer aided design, despite the potential of BCIs to provide a new form of environmental interaction.","In this paper we introduce the development and application of Neuron, a novel BCI tool that enables designers with little experience in neuroscience or computer programming to gain access to neurological data, along with established metrics relevant to design, create BCI interaction prototypes, both with digital onscreen objects and physical devices, and evaluate designs based on neurological information and record measurements for further analysis.","After discussing the BCI tool development, the article presents its capabilities through two case studies, along with a brief evaluation of the tool performance and a discussion of implications, limitations, and future improvement."],"url":"http://arxiv.org/abs/2307.11023v1"}
{"created":"2023-07-20 16:46:10","title":"Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation","abstract":"Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance. Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks. However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation. In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs. We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses. Furthermore, retrieval augmentation proves to be an effective approach in enhancing LLMs' awareness of knowledge boundaries, thereby improving their judgemental abilities. Additionally, we also find that LLMs have a propensity to rely on the provided retrieval results when formulating answers, while the quality of these results significantly impacts their reliance. The code to reproduce this work is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.","sentences":["Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance.","Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks.","However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation.","In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA.","Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs.","We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses.","Furthermore, retrieval augmentation proves to be an effective approach in enhancing LLMs' awareness of knowledge boundaries, thereby improving their judgemental abilities.","Additionally, we also find that LLMs have a propensity to rely on the provided retrieval results when formulating answers, while the quality of these results significantly impacts their reliance.","The code to reproduce this work is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary."],"url":"http://arxiv.org/abs/2307.11019v1"}
{"created":"2023-07-20 16:45:16","title":"Multi-objective point cloud autoencoders for explainable myocardial infarction prediction","abstract":"Myocardial infarction (MI) is one of the most common causes of death in the world. Image-based biomarkers commonly used in the clinic, such as ejection fraction, fail to capture more complex patterns in the heart's 3D anatomy and thus limit diagnostic accuracy. In this work, we present the multi-objective point cloud autoencoder as a novel geometric deep learning approach for explainable infarction prediction, based on multi-class 3D point cloud representations of cardiac anatomy and function. Its architecture consists of multiple task-specific branches connected by a low-dimensional latent space to allow for effective multi-objective learning of both reconstruction and MI prediction, while capturing pathology-specific 3D shape information in an interpretable latent space. Furthermore, its hierarchical branch design with point cloud-based deep learning operations enables efficient multi-scale feature learning directly on high-resolution anatomy point clouds. In our experiments on a large UK Biobank dataset, the multi-objective point cloud autoencoder is able to accurately reconstruct multi-temporal 3D shapes with Chamfer distances between predicted and input anatomies below the underlying images' pixel resolution. Our method outperforms multiple machine learning and deep learning benchmarks for the task of incident MI prediction by 19% in terms of Area Under the Receiver Operating Characteristic curve. In addition, its task-specific compact latent space exhibits easily separable control and MI clusters with clinically plausible associations between subject encodings and corresponding 3D shapes, thus demonstrating the explainability of the prediction.","sentences":["Myocardial infarction (MI) is one of the most common causes of death in the world.","Image-based biomarkers commonly used in the clinic, such as ejection fraction, fail to capture more complex patterns in the heart's 3D anatomy and thus limit diagnostic accuracy.","In this work, we present the multi-objective point cloud autoencoder as a novel geometric deep learning approach for explainable infarction prediction, based on multi-class 3D point cloud representations of cardiac anatomy and function.","Its architecture consists of multiple task-specific branches connected by a low-dimensional latent space to allow for effective multi-objective learning of both reconstruction and MI prediction, while capturing pathology-specific 3D shape information in an interpretable latent space.","Furthermore, its hierarchical branch design with point cloud-based deep learning operations enables efficient multi-scale feature learning directly on high-resolution anatomy point clouds.","In our experiments on a large UK Biobank dataset, the multi-objective point cloud autoencoder is able to accurately reconstruct multi-temporal 3D shapes with Chamfer distances between predicted and input anatomies below the underlying images' pixel resolution.","Our method outperforms multiple machine learning and deep learning benchmarks for the task of incident MI prediction by 19% in terms of Area Under the Receiver Operating Characteristic curve.","In addition, its task-specific compact latent space exhibits easily separable control and MI clusters with clinically plausible associations between subject encodings and corresponding 3D shapes, thus demonstrating the explainability of the prediction."],"url":"http://arxiv.org/abs/2307.11017v1"}
{"created":"2023-07-20 16:38:18","title":"Flow Map Learning for Unknown Dynamical Systems: Overview, Implementation, and Benchmarks","abstract":"Flow map learning (FML), in conjunction with deep neural networks (DNNs), has shown promises for data driven modeling of unknown dynamical systems. A remarkable feature of FML is that it is capable of producing accurate predictive models for partially observed systems, even when their exact mathematical models do not exist. In this paper, we present an overview of the FML framework, along with the important computational details for its successful implementation. We also present a set of well defined benchmark problems for learning unknown dynamical systems. All the numerical details of these problems are presented, along with their FML results, to ensure that the problems are accessible for cross-examination and the results are reproducible.","sentences":["Flow map learning (FML), in conjunction with deep neural networks (DNNs), has shown promises for data driven modeling of unknown dynamical systems.","A remarkable feature of FML is that it is capable of producing accurate predictive models for partially observed systems, even when their exact mathematical models do not exist.","In this paper, we present an overview of the FML framework, along with the important computational details for its successful implementation.","We also present a set of well defined benchmark problems for learning unknown dynamical systems.","All the numerical details of these problems are presented, along with their FML results, to ensure that the problems are accessible for cross-examination and the results are reproducible."],"url":"http://arxiv.org/abs/2307.11013v1"}
{"created":"2023-07-20 16:36:04","title":"Neuron Sensitivity Guided Test Case Selection for Deep Learning Testing","abstract":"Deep Neural Networks~(DNNs) have been widely deployed in software to address various tasks~(e.g., autonomous driving, medical diagnosis). However, they could also produce incorrect behaviors that result in financial losses and even threaten human safety. To reveal the incorrect behaviors in DNN and repair them, DNN developers often collect rich unlabeled datasets from the natural world and label them to test the DNN models. However, properly labeling a large number of unlabeled datasets is a highly expensive and time-consuming task.   To address the above-mentioned problem, we propose NSS, Neuron Sensitivity guided test case Selection, which can reduce the labeling time by selecting valuable test cases from unlabeled datasets. NSS leverages the internal neuron's information induced by test cases to select valuable test cases, which have high confidence in causing the model to behave incorrectly. We evaluate NSS with four widely used datasets and four well-designed DNN models compared to SOTA baseline methods. The results show that NSS performs well in assessing the test cases' probability of fault triggering and model improvement capabilities. Specifically, compared with baseline approaches, NSS obtains a higher fault detection rate~(e.g., when selecting 5\\% test case from the unlabeled dataset in MNIST \\& LeNet1 experiment, NSS can obtain 81.8\\% fault detection rate, 20\\% higher than baselines).","sentences":["Deep Neural Networks~(DNNs) have been widely deployed in software to address various tasks~(e.g., autonomous driving, medical diagnosis).","However, they could also produce incorrect behaviors that result in financial losses and even threaten human safety.","To reveal the incorrect behaviors in DNN and repair them, DNN developers often collect rich unlabeled datasets from the natural world and label them to test the DNN models.","However, properly labeling a large number of unlabeled datasets is a highly expensive and time-consuming task.   ","To address the above-mentioned problem, we propose NSS, Neuron Sensitivity guided test case Selection, which can reduce the labeling time by selecting valuable test cases from unlabeled datasets.","NSS leverages the internal neuron's information induced by test cases to select valuable test cases, which have high confidence in causing the model to behave incorrectly.","We evaluate NSS with four widely used datasets and four well-designed DNN models compared to SOTA baseline methods.","The results show that NSS performs well in assessing the test cases' probability of fault triggering and model improvement capabilities.","Specifically, compared with baseline approaches, NSS obtains a higher fault detection rate~(e.g., when selecting 5\\% test case from the unlabeled dataset in MNIST \\& LeNet1 experiment, NSS can obtain 81.8\\% fault detection rate, 20\\% higher than baselines)."],"url":"http://arxiv.org/abs/2307.11011v1"}
{"created":"2023-07-20 16:36:02","title":"Empirical Evaluation of a Live Environment for Extract Method Refactoring","abstract":"Complex software can be hard to read, adapt, and maintain. Refactoring it can create cleaner and self-explanatory code. Refactoring tools try to guide developers towards better code, with more quality. However, most of them take too long to provide feedback, support, and guidance on how developers should improve their software. To reduce this problem, we explored the concept of Live Refactoring, focusing on visually suggesting and applying refactorings, in real-time. With this in mind, we developed a Live Refactoring Environment that visually identifies, recommends, and applies Extract Method refactorings. To validate it, we conducted an empirical experiment. Early results showed that our approach improved several code quality metrics. Besides, we also concluded that our results were significantly different and better than the ones from refactoring the code manually without further help.","sentences":["Complex software can be hard to read, adapt, and maintain.","Refactoring it can create cleaner and self-explanatory code.","Refactoring tools try to guide developers towards better code, with more quality.","However, most of them take too long to provide feedback, support, and guidance on how developers should improve their software.","To reduce this problem, we explored the concept of Live Refactoring, focusing on visually suggesting and applying refactorings, in real-time.","With this in mind, we developed a Live Refactoring Environment that visually identifies, recommends, and applies Extract Method refactorings.","To validate it, we conducted an empirical experiment.","Early results showed that our approach improved several code quality metrics.","Besides, we also concluded that our results were significantly different and better than the ones from refactoring the code manually without further help."],"url":"http://arxiv.org/abs/2307.11010v1"}
{"created":"2023-07-20 16:34:58","title":"Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization","abstract":"Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve better generalization. This calls for the search for other explanations for the generalization of over-parameterized neural networks.","sentences":["Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive.","Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization.","This work critically examines this explanation.","Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize.","Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve better generalization.","This calls for the search for other explanations for the generalization of over-parameterized neural networks."],"url":"http://arxiv.org/abs/2307.11007v1"}
{"created":"2023-07-20 16:34:40","title":"Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding","abstract":"There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework. However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation. In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks. In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork. This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction. Our proposed three-pass SLU system shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE, especially on acoustically challenging utterances.","sentences":["There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework.","However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation.","In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks.","In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork.","This is followed by the LM subnetwork, which makes an initial SLU prediction.","Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction.","Our proposed three-pass SLU system shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE, especially on acoustically challenging utterances."],"url":"http://arxiv.org/abs/2307.11005v1"}
{"created":"2023-07-20 16:27:51","title":"Private Federated Learning with Autotuned Compression","abstract":"We propose new techniques for reducing communication in private federated learning without the need for setting or tuning compression rates. Our on-the-fly methods automatically adjust the compression rate based on the error induced during training, while maintaining provable privacy guarantees through the use of secure aggregation and differential privacy. Our techniques are provably instance-optimal for mean estimation, meaning that they can adapt to the ``hardness of the problem\" with minimal interactivity. We demonstrate the effectiveness of our approach on real-world datasets by achieving favorable compression rates without the need for tuning.","sentences":["We propose new techniques for reducing communication in private federated learning without the need for setting or tuning compression rates.","Our on-the-fly methods automatically adjust the compression rate based on the error induced during training, while maintaining provable privacy guarantees through the use of secure aggregation and differential privacy.","Our techniques are provably instance-optimal for mean estimation, meaning that they can adapt to the ``hardness of the problem\" with minimal interactivity.","We demonstrate the effectiveness of our approach on real-world datasets by achieving favorable compression rates without the need for tuning."],"url":"http://arxiv.org/abs/2307.10999v1"}
{"created":"2023-07-20 16:25:58","title":"DREAM: Domain-free Reverse Engineering Attributes of Black-box Model","abstract":"Deep learning models are usually black boxes when deployed on machine learning platforms. Prior works have shown that the attributes ($e.g.$, the number of convolutional layers) of a target black-box neural network can be exposed through a sequence of queries. There is a crucial limitation: these works assume the dataset used for training the target model to be known beforehand and leverage this dataset for model attribute attack. However, it is difficult to access the training dataset of the target black-box model in reality. Therefore, whether the attributes of a target black-box model could be still revealed in this case is doubtful. In this paper, we investigate a new problem of Domain-agnostic Reverse Engineering the Attributes of a black-box target Model, called DREAM, without requiring the availability of the target model's training dataset, and put forward a general and principled framework by casting this problem as an out of distribution (OOD) generalization problem. In this way, we can learn a domain-agnostic model to inversely infer the attributes of a target black-box model with unknown training data. This makes our method one of the kinds that can gracefully apply to an arbitrary domain for model attribute reverse engineering with strong generalization ability. Extensive experimental studies are conducted and the results validate the superiority of our proposed method over the baselines.","sentences":["Deep learning models are usually black boxes when deployed on machine learning platforms.","Prior works have shown that the attributes ($e.g.$, the number of convolutional layers) of a target black-box neural network can be exposed through a sequence of queries.","There is a crucial limitation: these works assume the dataset used for training the target model to be known beforehand and leverage this dataset for model attribute attack.","However, it is difficult to access the training dataset of the target black-box model in reality.","Therefore, whether the attributes of a target black-box model could be still revealed in this case is doubtful.","In this paper, we investigate a new problem of Domain-agnostic Reverse Engineering the Attributes of a black-box target Model, called DREAM, without requiring the availability of the target model's training dataset, and put forward a general and principled framework by casting this problem as an out of distribution (OOD) generalization problem.","In this way, we can learn a domain-agnostic model to inversely infer the attributes of a target black-box model with unknown training data.","This makes our method one of the kinds that can gracefully apply to an arbitrary domain for model attribute reverse engineering with strong generalization ability.","Extensive experimental studies are conducted and the results validate the superiority of our proposed method over the baselines."],"url":"http://arxiv.org/abs/2307.10997v1"}
{"created":"2023-07-20 16:25:00","title":"Progressive distillation diffusion for raw music generation","abstract":"This paper aims to apply a new deep learning approach to the task of generating raw audio files. It is based on diffusion models, a recent type of deep generative model. This new type of method has recently shown outstanding results with image generation. A lot of focus has been given to those models by the computer vision community. On the other hand, really few have been given for other types of applications such as music generation in waveform domain.   In this paper the model for unconditional generating applied to music is implemented: Progressive distillation diffusion with 1D U-Net. Then, a comparison of different parameters of diffusion and their value in a full result is presented. One big advantage of the methods implemented through this work is the fact that the model is able to deal with progressing audio processing and generating , using transformation from 1-channel 128 x 384 to 3-channel 128 x 128 mel-spectrograms and looped generation. The empirical comparisons are realized across different self-collected datasets.","sentences":["This paper aims to apply a new deep learning approach to the task of generating raw audio files.","It is based on diffusion models, a recent type of deep generative model.","This new type of method has recently shown outstanding results with image generation.","A lot of focus has been given to those models by the computer vision community.","On the other hand, really few have been given for other types of applications such as music generation in waveform domain.   ","In this paper the model for unconditional generating applied to music is implemented: Progressive distillation diffusion with 1D U-Net.","Then, a comparison of different parameters of diffusion and their value in a full result is presented.","One big advantage of the methods implemented through this work is the fact that the model is able to deal with progressing audio processing and generating , using transformation from 1-channel 128 x 384 to 3-channel 128 x 128 mel-spectrograms and looped generation.","The empirical comparisons are realized across different self-collected datasets."],"url":"http://arxiv.org/abs/2307.10994v1"}
{"created":"2023-07-20 16:21:14","title":"Dense Sample Deep Learning","abstract":"Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this paper, we explore these questions with a large (1.24M weights; VGG) DL in a novel high density sample task (5 unique tokens with at minimum 500 exemplars per token) which allows us to more carefully follow the emergence of category structure and feature construction. We use various visualization methods for following the emergence of the classification and the development of the coupling of feature detectors and structures that provide a type of graphical bootstrapping, From these results we harvest some basic observations of the learning dynamics of DL and propose a new theory of complex feature construction based on our results.","sentences":["Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently.","Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications.","Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987.","But the nature of deep learned representations remain largely unknown.","Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed.","In this paper, we explore these questions with a large (1.24M weights; VGG) DL in a novel high density sample task (5 unique tokens with at minimum 500 exemplars per token) which allows us to more carefully follow the emergence of category structure and feature construction.","We use various visualization methods for following the emergence of the classification and the development of the coupling of feature detectors and structures that provide a type of graphical bootstrapping, From these results we harvest some basic observations of the learning dynamics of DL and propose a new theory of complex feature construction based on our results."],"url":"http://arxiv.org/abs/2307.10991v1"}
{"created":"2023-07-20 16:18:33","title":"Investigating minimizing the training set fill distance in machine learning regression","abstract":"Many machine learning regression methods leverage large datasets for training predictive models. However, using large datasets may not be feasible due to computational limitations or high labelling costs. Therefore, sampling small training sets from large pools of unlabelled data points is essential to maximize model performance while maintaining computational efficiency. In this work, we study a sampling approach aimed to minimize the fill distance of the selected set. We derive an upper bound for the maximum expected prediction error that linearly depends on the training set fill distance, conditional to the knowledge of data features. For empirical validation, we perform experiments using two regression models on two datasets. We empirically show that selecting a training set by aiming to minimize the fill distance, thereby minimizing the bound, significantly reduces the maximum prediction error of various regression models, outperforming existing sampling approaches by a large margin.","sentences":["Many machine learning regression methods leverage large datasets for training predictive models.","However, using large datasets may not be feasible due to computational limitations or high labelling costs.","Therefore, sampling small training sets from large pools of unlabelled data points is essential to maximize model performance while maintaining computational efficiency.","In this work, we study a sampling approach aimed to minimize the fill distance of the selected set.","We derive an upper bound for the maximum expected prediction error that linearly depends on the training set fill distance, conditional to the knowledge of data features.","For empirical validation, we perform experiments using two regression models on two datasets.","We empirically show that selecting a training set by aiming to minimize the fill distance, thereby minimizing the bound, significantly reduces the maximum prediction error of various regression models, outperforming existing sampling approaches by a large margin."],"url":"http://arxiv.org/abs/2307.10988v1"}
{"created":"2023-07-20 16:18:22","title":"Characterising Decision Theories with Mechanised Causal Graphs","abstract":"How should my own decisions affect my beliefs about the outcomes I expect to achieve? If taking a certain action makes me view myself as a certain type of person, it might affect how I think others view me, and how I view others who are similar to me. This can influence my expected utility calculations and change which action I perceive to be best. Whether and how it should is subject to debate, with contenders for how to think about it including evidential decision theory, causal decision theory, and functional decision theory. In this paper, we show that mechanised causal models can be used to characterise and differentiate the most important decision theories, and generate a taxonomy of different decision theories.","sentences":["How should my own decisions affect my beliefs about the outcomes I expect to achieve?","If taking a certain action makes me view myself as a certain type of person, it might affect how I think others view me, and how I view others who are similar to me.","This can influence my expected utility calculations and change which action I perceive to be best.","Whether and how it should is subject to debate, with contenders for how to think about it including evidential decision theory, causal decision theory, and functional decision theory.","In this paper, we show that mechanised causal models can be used to characterise and differentiate the most important decision theories, and generate a taxonomy of different decision theories."],"url":"http://arxiv.org/abs/2307.10987v1"}
{"created":"2023-07-20 16:15:38","title":"Fair Allocation of goods and chores -- Tutorial and Survey of Recent Results","abstract":"Fair resource allocation is an important problem in many real-world scenarios, where resources such as goods and chores must be allocated among agents. In this survey, we delve into the intricacies of fair allocation, focusing specifically on the challenges associated with indivisible resources. We define fairness and efficiency within this context and thoroughly survey existential results, algorithms, and approximations that satisfy various fairness criteria, including envyfreeness, proportionality, MMS, and their relaxations. Additionally, we discuss algorithms that achieve fairness and efficiency, such as Pareto Optimality and Utilitarian Welfare. We also study the computational complexity of these algorithms, the likelihood of finding fair allocations, and the price of fairness for each fairness notion. We also cover mixed instances of indivisible and divisible items and investigate different valuation and allocation settings. By summarizing the state-of-the-art research, this survey provides valuable insights into fair resource allocation of indivisible goods and chores, highlighting computational complexities, fairness guarantees, and trade-offs between fairness and efficiency. It serves as a foundation for future advancements in this vital field.","sentences":["Fair resource allocation is an important problem in many real-world scenarios, where resources such as goods and chores must be allocated among agents.","In this survey, we delve into the intricacies of fair allocation, focusing specifically on the challenges associated with indivisible resources.","We define fairness and efficiency within this context and thoroughly survey existential results, algorithms, and approximations that satisfy various fairness criteria, including envyfreeness, proportionality, MMS, and their relaxations.","Additionally, we discuss algorithms that achieve fairness and efficiency, such as Pareto Optimality and Utilitarian Welfare.","We also study the computational complexity of these algorithms, the likelihood of finding fair allocations, and the price of fairness for each fairness notion.","We also cover mixed instances of indivisible and divisible items and investigate different valuation and allocation settings.","By summarizing the state-of-the-art research, this survey provides valuable insights into fair resource allocation of indivisible goods and chores, highlighting computational complexities, fairness guarantees, and trade-offs between fairness and efficiency.","It serves as a foundation for future advancements in this vital field."],"url":"http://arxiv.org/abs/2307.10985v1"}
{"created":"2023-07-20 16:14:23","title":"Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image","abstract":"Reconstructing accurate 3D scenes from images is a long-standing vision task. Due to the ill-posedness of the single-image reconstruction problem, most well-established methods are built upon multi-view geometry. State-of-the-art (SOTA) monocular metric depth estimation methods can only handle a single camera model and are unable to perform mixed-data training due to the metric ambiguity. Meanwhile, SOTA monocular methods trained on large mixed datasets achieve zero-shot generalization by learning affine-invariant depths, which cannot recover real-world metrics. In this work, we show that the key to a zero-shot single-view metric depth model lies in the combination of large-scale data training and resolving the metric ambiguity from various camera models. We propose a canonical camera space transformation module, which explicitly addresses the ambiguity problems and can be effortlessly plugged into existing monocular models. Equipped with our module, monocular models can be stably trained with over 8 million images with thousands of camera models, resulting in zero-shot generalization to in-the-wild images with unseen camera settings. Experiments demonstrate SOTA performance of our method on 7 zero-shot benchmarks. Notably, our method won the championship in the 2nd Monocular Depth Estimation Challenge. Our method enables the accurate recovery of metric 3D structures on randomly collected internet images, paving the way for plausible single-image metrology. The potential benefits extend to downstream tasks, which can be significantly improved by simply plugging in our model. For example, our model relieves the scale drift issues of monocular-SLAM (Fig. 1), leading to high-quality metric scale dense mapping. The code is available at https://github.com/YvanYin/Metric3D.","sentences":["Reconstructing accurate 3D scenes from images is a long-standing vision task.","Due to the ill-posedness of the single-image reconstruction problem, most well-established methods are built upon multi-view geometry.","State-of-the-art (SOTA) monocular metric depth estimation methods can only handle a single camera model and are unable to perform mixed-data training due to the metric ambiguity.","Meanwhile, SOTA monocular methods trained on large mixed datasets achieve zero-shot generalization by learning affine-invariant depths, which cannot recover real-world metrics.","In this work, we show that the key to a zero-shot single-view metric depth model lies in the combination of large-scale data training and resolving the metric ambiguity from various camera models.","We propose a canonical camera space transformation module, which explicitly addresses the ambiguity problems and can be effortlessly plugged into existing monocular models.","Equipped with our module, monocular models can be stably trained with over 8 million images with thousands of camera models, resulting in zero-shot generalization to in-the-wild images with unseen camera settings.","Experiments demonstrate SOTA performance of our method on 7 zero-shot benchmarks.","Notably, our method won the championship in the 2nd Monocular Depth Estimation Challenge.","Our method enables the accurate recovery of metric 3D structures on randomly collected internet images, paving the way for plausible single-image metrology.","The potential benefits extend to downstream tasks, which can be significantly improved by simply plugging in our model.","For example, our model relieves the scale drift issues of monocular-SLAM (Fig. 1), leading to high-quality metric scale dense mapping.","The code is available at https://github.com/YvanYin/Metric3D."],"url":"http://arxiv.org/abs/2307.10984v1"}
{"created":"2023-07-20 16:09:57","title":"MASR: Metadata Aware Speech Representation","abstract":"In the recent years, speech representation learning is constructed primarily as a self-supervised learning (SSL) task, using the raw audio signal alone, while ignoring the side-information that is often available for a given speech recording. In this paper, we propose MASR, a Metadata Aware Speech Representation learning framework, which addresses the aforementioned limitations. MASR enables the inclusion of multiple external knowledge sources to enhance the utilization of meta-data information. The external knowledge sources are incorporated in the form of sample-level pair-wise similarity matrices that are useful in a hard-mining loss. A key advantage of the MASR framework is that it can be combined with any choice of SSL method. Using MASR representations, we perform evaluations on several downstream tasks such as language identification, speech recognition and other non-semantic tasks such as speaker and emotion recognition. In these experiments, we illustrate significant performance improvements for the MASR over other established benchmarks. We perform a detailed analysis on the language identification task to provide insights on how the proposed loss function enables the representations to separate closely related languages.","sentences":["In the recent years, speech representation learning is constructed primarily as a self-supervised learning (SSL) task, using the raw audio signal alone, while ignoring the side-information that is often available for a given speech recording.","In this paper, we propose MASR, a Metadata Aware Speech Representation learning framework, which addresses the aforementioned limitations.","MASR enables the inclusion of multiple external knowledge sources to enhance the utilization of meta-data information.","The external knowledge sources are incorporated in the form of sample-level pair-wise similarity matrices that are useful in a hard-mining loss.","A key advantage of the MASR framework is that it can be combined with any choice of SSL method.","Using MASR representations, we perform evaluations on several downstream tasks such as language identification, speech recognition and other non-semantic tasks such as speaker and emotion recognition.","In these experiments, we illustrate significant performance improvements for the MASR over other established benchmarks.","We perform a detailed analysis on the language identification task to provide insights on how the proposed loss function enables the representations to separate closely related languages."],"url":"http://arxiv.org/abs/2307.10982v1"}
{"created":"2023-07-20 16:09:07","title":"PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks","abstract":"Collaborative inference has been a promising solution to enable resource-constrained edge devices to perform inference using state-of-the-art deep neural networks (DNNs). In collaborative inference, the edge device first feeds the input to a partial DNN locally and then uploads the intermediate result to the cloud to complete the inference. However, recent research indicates model inversion attacks (MIAs) can reconstruct input data from intermediate results, posing serious privacy concerns for collaborative inference. Existing perturbation and cryptography techniques are inefficient and unreliable in defending against MIAs while performing accurate inference. This paper provides a viable solution, named PATROL, which develops privacy-oriented pruning to balance privacy, efficiency, and utility of collaborative inference. PATROL takes advantage of the fact that later layers in a DNN can extract more task-specific features. Given limited local resources for collaborative inference, PATROL intends to deploy more layers at the edge based on pruning techniques to enforce task-specific features for inference and reduce task-irrelevant but sensitive features for privacy preservation. To achieve privacy-oriented pruning, PATROL introduces two key components: Lipschitz regularization and adversarial reconstruction training, which increase the reconstruction errors by reducing the stability of MIAs and enhance the target inference model by adversarial training, respectively.","sentences":["Collaborative inference has been a promising solution to enable resource-constrained edge devices to perform inference using state-of-the-art deep neural networks (DNNs).","In collaborative inference, the edge device first feeds the input to a partial DNN locally and then uploads the intermediate result to the cloud to complete the inference.","However, recent research indicates model inversion attacks (MIAs) can reconstruct input data from intermediate results, posing serious privacy concerns for collaborative inference.","Existing perturbation and cryptography techniques are inefficient and unreliable in defending against MIAs while performing accurate inference.","This paper provides a viable solution, named PATROL, which develops privacy-oriented pruning to balance privacy, efficiency, and utility of collaborative inference.","PATROL takes advantage of the fact that later layers in a DNN can extract more task-specific features.","Given limited local resources for collaborative inference, PATROL intends to deploy more layers at the edge based on pruning techniques to enforce task-specific features for inference and reduce task-irrelevant but sensitive features for privacy preservation.","To achieve privacy-oriented pruning, PATROL introduces two key components: Lipschitz regularization and adversarial reconstruction training, which increase the reconstruction errors by reducing the stability of MIAs and enhance the target inference model by adversarial training, respectively."],"url":"http://arxiv.org/abs/2307.10981v1"}
{"created":"2023-07-20 16:00:19","title":"Deep Spiking-UNet for Image Processing","abstract":"U-Net, known for its simple yet efficient architecture, is widely utilized for image processing tasks and is particularly suitable for deployment on neuromorphic chips. This paper introduces the novel concept of Spiking-UNet for image processing, which combines the power of Spiking Neural Networks (SNNs) with the U-Net architecture. To achieve an efficient Spiking-UNet, we face two primary challenges: ensuring high-fidelity information propagation through the network via spikes and formulating an effective training strategy. To address the issue of information loss, we introduce multi-threshold spiking neurons, which improve the efficiency of information transmission within the Spiking-UNet. For the training strategy, we adopt a conversion and fine-tuning pipeline that leverage pre-trained U-Net models. During the conversion process, significant variability in data distribution across different parts is observed when utilizing skip connections. Therefore, we propose a connection-wise normalization method to prevent inaccurate firing rates. Furthermore, we adopt a flow-based training method to fine-tune the converted models, reducing time steps while preserving performance. Experimental results show that, on image segmentation and denoising, our Spiking-UNet achieves comparable performance to its non-spiking counterpart, surpassing existing SNN methods. Compared with the converted Spiking-UNet without fine-tuning, our Spiking-UNet reduces inference time by approximately 90\\%. This research broadens the application scope of SNNs in image processing and is expected to inspire further exploration in the field of neuromorphic engineering. The code for our Spiking-UNet implementation is available at https://github.com/SNNresearch/Spiking-UNet.","sentences":["U-Net, known for its simple yet efficient architecture, is widely utilized for image processing tasks and is particularly suitable for deployment on neuromorphic chips.","This paper introduces the novel concept of Spiking-UNet for image processing, which combines the power of Spiking Neural Networks (SNNs) with the U-Net architecture.","To achieve an efficient Spiking-UNet, we face two primary challenges: ensuring high-fidelity information propagation through the network via spikes and formulating an effective training strategy.","To address the issue of information loss, we introduce multi-threshold spiking neurons, which improve the efficiency of information transmission within the Spiking-UNet.","For the training strategy, we adopt a conversion and fine-tuning pipeline that leverage pre-trained U-Net models.","During the conversion process, significant variability in data distribution across different parts is observed when utilizing skip connections.","Therefore, we propose a connection-wise normalization method to prevent inaccurate firing rates.","Furthermore, we adopt a flow-based training method to fine-tune the converted models, reducing time steps while preserving performance.","Experimental results show that, on image segmentation and denoising, our Spiking-UNet achieves comparable performance to its non-spiking counterpart, surpassing existing SNN methods.","Compared with the converted Spiking-UNet without fine-tuning, our Spiking-UNet reduces inference time by approximately 90\\%.","This research broadens the application scope of SNNs in image processing and is expected to inspire further exploration in the field of neuromorphic engineering.","The code for our Spiking-UNet implementation is available at https://github.com/SNNresearch/Spiking-UNet."],"url":"http://arxiv.org/abs/2307.10974v1"}
{"created":"2023-07-20 15:54:41","title":"Assessing the Effects of Illuminance and Correlated Color Temperature on Emotional Responses and Lighting Preferences Using Virtual Reality","abstract":"This paper presents a novel approach to assessing human lighting adjustment behavior and preference in diverse lighting conditions through the evaluation of emotional feedback and behavioral data using VR. Participants (n= 27) were exposed to different lighting (n=17) conditions with different levels of illuminance and correlated color temperature (CCT) with a randomized order in a virtual office environment. Results from this study significantly advanced our understanding of preferred lighting conditions in virtual reality environments, influenced by a variety of factors such as illuminance, color temperature, order of presentation, and participant demographics. Through a comprehensive analysis of user adjustment profiles, we obtained insightful data that can guide the optimization of lighting design across various settings.","sentences":["This paper presents a novel approach to assessing human lighting adjustment behavior and preference in diverse lighting conditions through the evaluation of emotional feedback and behavioral data using VR.","Participants (n= 27) were exposed to different lighting (n=17) conditions with different levels of illuminance and correlated color temperature (CCT) with a randomized order in a virtual office environment.","Results from this study significantly advanced our understanding of preferred lighting conditions in virtual reality environments, influenced by a variety of factors such as illuminance, color temperature, order of presentation, and participant demographics.","Through a comprehensive analysis of user adjustment profiles, we obtained insightful data that can guide the optimization of lighting design across various settings."],"url":"http://arxiv.org/abs/2307.10969v1"}
{"created":"2023-07-20 15:51:23","title":"ESASCF: Expertise Extraction, Generalization and Reply Framework for an Optimized Automation of Network Security Compliance","abstract":"The Cyber threats exposure has created worldwide pressure on organizations to comply with cyber security standards and policies for protecting their digital assets. Vulnerability assessment (VA) and Penetration Testing (PT) are widely adopted Security Compliance (SC) methods to identify security gaps and anticipate security breaches. In the computer networks context and despite the use of autonomous tools and systems, security compliance remains highly repetitive and resources consuming. In this paper, we proposed a novel method to tackle the ever-growing problem of efficiency and effectiveness in network infrastructures security auditing by formally introducing, designing, and developing an Expert-System Automated Security Compliance Framework (ESASCF) that enables industrial and open-source VA and PT tools and systems to extract, process, store and re-use the expertise in a human-expert way to allow direct application in similar scenarios or during the periodic re-testing. The implemented model was then integrated within the ESASCF and tested on different size networks and proved efficient in terms of time-efficiency and testing effectiveness allowing ESASCF to take over autonomously the SC in Re-testing and offloading Expert by automating repeated segments SC and thus enabling Experts to prioritize important tasks in Ad-Hoc compliance tests. The obtained results validate the performance enhancement notably by cutting the time required for an expert to 50% in the context of typical corporate networks first SC and 20% in re-testing, representing a significant cost-cutting. In addition, the framework allows a long-term impact illustrated in the knowledge extraction, generalization, and re-utilization, which enables better SC confidence independent of the human expert skills, coverage, and wrong decisions resulting in impactful false negatives.","sentences":["The Cyber threats exposure has created worldwide pressure on organizations to comply with cyber security standards and policies for protecting their digital assets.","Vulnerability assessment (VA) and Penetration Testing (PT) are widely adopted Security Compliance (SC) methods to identify security gaps and anticipate security breaches.","In the computer networks context and despite the use of autonomous tools and systems, security compliance remains highly repetitive and resources consuming.","In this paper, we proposed a novel method to tackle the ever-growing problem of efficiency and effectiveness in network infrastructures security auditing by formally introducing, designing, and developing an Expert-System Automated Security Compliance Framework (ESASCF) that enables industrial and open-source VA and PT tools and systems to extract, process, store and re-use the expertise in a human-expert way to allow direct application in similar scenarios or during the periodic re-testing.","The implemented model was then integrated within the ESASCF and tested on different size networks and proved efficient in terms of time-efficiency and testing effectiveness allowing ESASCF to take over autonomously the SC in Re-testing and offloading Expert by automating repeated segments SC and thus enabling Experts to prioritize important tasks in Ad-Hoc compliance tests.","The obtained results validate the performance enhancement notably by cutting the time required for an expert to 50% in the context of typical corporate networks first SC and 20% in re-testing, representing a significant cost-cutting.","In addition, the framework allows a long-term impact illustrated in the knowledge extraction, generalization, and re-utilization, which enables better SC confidence independent of the human expert skills, coverage, and wrong decisions resulting in impactful false negatives."],"url":"http://arxiv.org/abs/2307.10967v1"}
{"created":"2023-07-20 15:26:57","title":"Spinal nerve segmentation method and dataset construction in endoscopic surgical scenarios","abstract":"Endoscopic surgery is currently an important treatment method in the field of spinal surgery and avoiding damage to the spinal nerves through video guidance is a key challenge. This paper presents the first real-time segmentation method for spinal nerves in endoscopic surgery, which provides crucial navigational information for surgeons. A finely annotated segmentation dataset of approximately 10,000 consec-utive frames recorded during surgery is constructed for the first time for this field, addressing the problem of semantic segmentation. Based on this dataset, we propose FUnet (Frame-Unet), which achieves state-of-the-art performance by utilizing inter-frame information and self-attention mechanisms. We also conduct extended exper-iments on a similar polyp endoscopy video dataset and show that the model has good generalization ability with advantageous performance. The dataset and code of this work are presented at: https://github.com/zzzzzzpc/FUnet .","sentences":["Endoscopic surgery is currently an important treatment method in the field of spinal surgery and avoiding damage to the spinal nerves through video guidance is a key challenge.","This paper presents the first real-time segmentation method for spinal nerves in endoscopic surgery, which provides crucial navigational information for surgeons.","A finely annotated segmentation dataset of approximately 10,000 consec-utive frames recorded during surgery is constructed for the first time for this field, addressing the problem of semantic segmentation.","Based on this dataset, we propose FUnet (Frame-Unet), which achieves state-of-the-art performance by utilizing inter-frame information and self-attention mechanisms.","We also conduct extended exper-iments on a similar polyp endoscopy video dataset and show that the model has good generalization ability with advantageous performance.","The dataset and code of this work are presented at: https://github.com/zzzzzzpc/FUnet ."],"url":"http://arxiv.org/abs/2307.10955v1"}
{"created":"2023-07-20 15:26:01","title":"Soft-tissue Driven Craniomaxillofacial Surgical Planning","abstract":"In CMF surgery, the planning of bony movement to achieve a desired facial outcome is a challenging task. Current bone driven approaches focus on normalizing the bone with the expectation that the facial appearance will be corrected accordingly. However, due to the complex non-linear relationship between bony structure and facial soft-tissue, such bone-driven methods are insufficient to correct facial deformities. Despite efforts to simulate facial changes resulting from bony movement, surgical planning still relies on iterative revisions and educated guesses. To address these issues, we propose a soft-tissue driven framework that can automatically create and verify surgical plans. Our framework consists of a bony planner network that estimates the bony movements required to achieve the desired facial outcome and a facial simulator network that can simulate the possible facial changes resulting from the estimated bony movement plans. By combining these two models, we can verify and determine the final bony movement required for planning. The proposed framework was evaluated using a clinical dataset, and our experimental results demonstrate that the soft-tissue driven approach greatly improves the accuracy and efficacy of surgical planning when compared to the conventional bone-driven approach.","sentences":["In CMF surgery, the planning of bony movement to achieve a desired facial outcome is a challenging task.","Current bone driven approaches focus on normalizing the bone with the expectation that the facial appearance will be corrected accordingly.","However, due to the complex non-linear relationship between bony structure and facial soft-tissue, such bone-driven methods are insufficient to correct facial deformities.","Despite efforts to simulate facial changes resulting from bony movement, surgical planning still relies on iterative revisions and educated guesses.","To address these issues, we propose a soft-tissue driven framework that can automatically create and verify surgical plans.","Our framework consists of a bony planner network that estimates the bony movements required to achieve the desired facial outcome and a facial simulator network that can simulate the possible facial changes resulting from the estimated bony movement plans.","By combining these two models, we can verify and determine the final bony movement required for planning.","The proposed framework was evaluated using a clinical dataset, and our experimental results demonstrate that the soft-tissue driven approach greatly improves the accuracy and efficacy of surgical planning when compared to the conventional bone-driven approach."],"url":"http://arxiv.org/abs/2307.10954v1"}
{"created":"2023-07-20 15:25:55","title":"PE-YOLO: Pyramid Enhancement Network for Dark Object Detection","abstract":"Current object detection models have achieved good results on many benchmark datasets, detecting objects in dark conditions remains a large challenge. To address this issue, we propose a pyramid enhanced network (PENet) and joint it with YOLOv3 to build a dark object detection framework named PE-YOLO. Firstly, PENet decomposes the image into four components of different resolutions using the Laplacian pyramid. Specifically we propose a detail processing module (DPM) to enhance the detail of images, which consists of context branch and edge branch. In addition, we propose a low-frequency enhancement filter (LEF) to capture low-frequency semantics and prevent high-frequency noise. PE-YOLO adopts an end-to-end joint training approach and only uses normal detection loss to simplify the training process. We conduct experiments on the low-light object detection dataset ExDark to demonstrate the effectiveness of ours. The results indicate that compared with other dark detectors and low-light enhancement models, PE-YOLO achieves the advanced results, achieving 78.0% in mAP and 53.6 in FPS, respectively, which can adapt to object detection under different low-light conditions. The code is available at https://github.com/XiangchenYin/PE-YOLO.","sentences":["Current object detection models have achieved good results on many benchmark datasets, detecting objects in dark conditions remains a large challenge.","To address this issue, we propose a pyramid enhanced network (PENet) and joint it with YOLOv3 to build a dark object detection framework named PE-YOLO.","Firstly, PENet decomposes the image into four components of different resolutions using the Laplacian pyramid.","Specifically we propose a detail processing module (DPM) to enhance the detail of images, which consists of context branch and edge branch.","In addition, we propose a low-frequency enhancement filter (LEF) to capture low-frequency semantics and prevent high-frequency noise.","PE-YOLO adopts an end-to-end joint training approach and only uses normal detection loss to simplify the training process.","We conduct experiments on the low-light object detection dataset ExDark to demonstrate the effectiveness of ours.","The results indicate that compared with other dark detectors and low-light enhancement models, PE-YOLO achieves the advanced results, achieving 78.0% in mAP and 53.6 in FPS, respectively, which can adapt to object detection under different low-light conditions.","The code is available at https://github.com/XiangchenYin/PE-YOLO."],"url":"http://arxiv.org/abs/2307.10953v1"}
{"created":"2023-07-20 15:21:28","title":"Improving Online Lane Graph Extraction by Object-Lane Clustering","abstract":"Autonomous driving requires accurate local scene understanding information. To this end, autonomous agents deploy object detection and online BEV lane graph extraction methods as a part of their perception stack. In this work, we propose an architecture and loss formulation to improve the accuracy of local lane graph estimates by using 3D object detection outputs. The proposed method learns to assign the objects to centerlines by considering the centerlines as cluster centers and the objects as data points to be assigned a probability distribution over the cluster centers. This training scheme ensures direct supervision on the relationship between lanes and objects, thus leading to better performance. The proposed method improves lane graph estimation substantially over state-of-the-art methods. The extensive ablations show that our method can achieve significant performance improvements by using the outputs of existing 3D object detection methods. Since our method uses the detection outputs rather than detection method intermediate representations, a single model of our method can use any detection method at test time.","sentences":["Autonomous driving requires accurate local scene understanding information.","To this end, autonomous agents deploy object detection and online BEV lane graph extraction methods as a part of their perception stack.","In this work, we propose an architecture and loss formulation to improve the accuracy of local lane graph estimates by using 3D object detection outputs.","The proposed method learns to assign the objects to centerlines by considering the centerlines as cluster centers and the objects as data points to be assigned a probability distribution over the cluster centers.","This training scheme ensures direct supervision on the relationship between lanes and objects, thus leading to better performance.","The proposed method improves lane graph estimation substantially over state-of-the-art methods.","The extensive ablations show that our method can achieve significant performance improvements by using the outputs of existing 3D object detection methods.","Since our method uses the detection outputs rather than detection method intermediate representations, a single model of our method can use any detection method at test time."],"url":"http://arxiv.org/abs/2307.10947v1"}
{"created":"2023-07-20 15:13:29","title":"Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery","abstract":"Recent advances in deep learning have significantly improved the performance of various computer vision applications. However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories. Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch. To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge. The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset. Furthermore, the proxy anchors-based exemplar generates representative category vectors to mitigate catastrophic forgetting. Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios.","sentences":["Recent advances in deep learning have significantly improved the performance of various computer vision applications.","However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories.","Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch.","To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge.","The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset.","Furthermore, the proxy anchors-based exemplar generates representative category vectors to mitigate catastrophic forgetting.","Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios."],"url":"http://arxiv.org/abs/2307.10943v1"}
{"created":"2023-07-20 15:09:06","title":"PASTA: Pretrained Action-State Transformer Agents","abstract":"Self-supervised learning has brought about a revolutionary paradigm shift in various computing domains, including NLP, vision, and biology. Recent approaches involve pre-training transformer models on vast amounts of unlabeled data, serving as a starting point for efficiently solving downstream tasks. In the realm of reinforcement learning, researchers have recently adapted these approaches by developing models pre-trained on expert trajectories, enabling them to address a wide range of tasks, from robotics to recommendation systems. However, existing methods mostly rely on intricate pre-training objectives tailored to specific downstream applications. This paper presents a comprehensive investigation of models we refer to as Pretrained Action-State Transformer Agents (PASTA). Our study uses a unified methodology and covers an extensive set of general downstream tasks including behavioral cloning, offline RL, sensor failure robustness, and dynamics change adaptation. Our goal is to systematically compare various design choices and provide valuable insights to practitioners for building robust models. Key highlights of our study include tokenization at the action and state component level, using fundamental pre-training objectives like next token prediction, training models across diverse domains simultaneously, and using parameter efficient fine-tuning (PEFT). The developed models in our study contain fewer than 10 million parameters and the application of PEFT enables fine-tuning of fewer than 10,000 parameters during downstream adaptation, allowing a broad community to use these models and reproduce our experiments. We hope that this study will encourage further research into the use of transformers with first-principles design choices to represent RL trajectories and contribute to robust policy learning.","sentences":["Self-supervised learning has brought about a revolutionary paradigm shift in various computing domains, including NLP, vision, and biology.","Recent approaches involve pre-training transformer models on vast amounts of unlabeled data, serving as a starting point for efficiently solving downstream tasks.","In the realm of reinforcement learning, researchers have recently adapted these approaches by developing models pre-trained on expert trajectories, enabling them to address a wide range of tasks, from robotics to recommendation systems.","However, existing methods mostly rely on intricate pre-training objectives tailored to specific downstream applications.","This paper presents a comprehensive investigation of models we refer to as Pretrained Action-State Transformer Agents (PASTA).","Our study uses a unified methodology and covers an extensive set of general downstream tasks including behavioral cloning, offline RL, sensor failure robustness, and dynamics change adaptation.","Our goal is to systematically compare various design choices and provide valuable insights to practitioners for building robust models.","Key highlights of our study include tokenization at the action and state component level, using fundamental pre-training objectives like next token prediction, training models across diverse domains simultaneously, and using parameter efficient fine-tuning (PEFT).","The developed models in our study contain fewer than 10 million parameters and the application of PEFT enables fine-tuning of fewer than 10,000 parameters during downstream adaptation, allowing a broad community to use these models and reproduce our experiments.","We hope that this study will encourage further research into the use of transformers with first-principles design choices to represent RL trajectories and contribute to robust policy learning."],"url":"http://arxiv.org/abs/2307.10936v1"}
{"created":"2023-07-20 15:06:44","title":"OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios","abstract":"Modern approaches for vision-centric environment perception for autonomous navigation make extensive use of self-supervised monocular depth estimation algorithms that output disparity maps. However, when this disparity map is projected onto 3D space, the errors in disparity are magnified, resulting in a depth estimation error that increases quadratically as the distance from the camera increases. Though Light Detection and Ranging (LiDAR) can solve this issue, it is expensive and not feasible for many applications. To address the challenge of accurate ranging with low-cost sensors, we propose, OCTraN, a transformer architecture that uses iterative-attention to convert 2D image features into 3D occupancy features and makes use of convolution and transpose convolution to efficiently operate on spatial information. We also develop a self-supervised training pipeline to generalize the model to any scene by eliminating the need for LiDAR ground truth by substituting it with pseudo-ground truth labels obtained from boosted monocular depth estimation.","sentences":["Modern approaches for vision-centric environment perception for autonomous navigation make extensive use of self-supervised monocular depth estimation algorithms that output disparity maps.","However, when this disparity map is projected onto 3D space, the errors in disparity are magnified, resulting in a depth estimation error that increases quadratically as the distance from the camera increases.","Though Light Detection and Ranging (LiDAR) can solve this issue, it is expensive and not feasible for many applications.","To address the challenge of accurate ranging with low-cost sensors, we propose, OCTraN, a transformer architecture that uses iterative-attention to convert 2D image features into 3D occupancy features and makes use of convolution and transpose convolution to efficiently operate on spatial information.","We also develop a self-supervised training pipeline to generalize the model to any scene by eliminating the need for LiDAR ground truth by substituting it with pseudo-ground truth labels obtained from boosted monocular depth estimation."],"url":"http://arxiv.org/abs/2307.10934v1"}
{"created":"2023-07-20 15:02:42","title":"Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations","abstract":"The enhancement of unsupervised learning of sentence representations has been significantly achieved by the utility of contrastive learning. This approach clusters the augmented positive instance with the anchor instance to create a desired embedding space. However, relying solely on the contrastive objective can result in sub-optimal outcomes due to its inability to differentiate subtle semantic variations between positive pairs. Specifically, common data augmentation techniques frequently introduce semantic distortion, leading to a semantic margin between the positive pair. While the InfoNCE loss function overlooks the semantic margin and prioritizes similarity maximization between positive pairs during training, leading to the insensitive semantic comprehension ability of the trained model. In this paper, we introduce a novel Identical and Fraternal Twins of Contrastive Learning (named IFTCL) framework, capable of simultaneously adapting to various positive pairs generated by different augmentation techniques. We propose a \\textit{Twins Loss} to preserve the innate margin during training and promote the potential of data enhancement in order to overcome the sub-optimal issue. We also present proof-of-concept experiments combined with the contrastive objective to prove the validity of the proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanism to restore and reuse the negative instances without additional calculation, which further enhances the efficiency and performance of the IFCL. We verify the IFCL framework on nine semantic textual similarity tasks with both English and Chinese datasets, and the experimental results show that IFCL outperforms state-of-the-art methods.","sentences":["The enhancement of unsupervised learning of sentence representations has been significantly achieved by the utility of contrastive learning.","This approach clusters the augmented positive instance with the anchor instance to create a desired embedding space.","However, relying solely on the contrastive objective can result in sub-optimal outcomes due to its inability to differentiate subtle semantic variations between positive pairs.","Specifically, common data augmentation techniques frequently introduce semantic distortion, leading to a semantic margin between the positive pair.","While the InfoNCE loss function overlooks the semantic margin and prioritizes similarity maximization between positive pairs during training, leading to the insensitive semantic comprehension ability of the trained model.","In this paper, we introduce a novel Identical and Fraternal Twins of Contrastive Learning (named IFTCL) framework, capable of simultaneously adapting to various positive pairs generated by different augmentation techniques.","We propose a \\textit{Twins Loss} to preserve the innate margin during training and promote the potential of data enhancement in order to overcome the sub-optimal issue.","We also present proof-of-concept experiments combined with the contrastive objective to prove the validity of the proposed Twins Loss.","Furthermore, we propose a hippocampus queue mechanism to restore and reuse the negative instances without additional calculation, which further enhances the efficiency and performance of the IFCL.","We verify the IFCL framework on nine semantic textual similarity tasks with both English and Chinese datasets, and the experimental results show that IFCL outperforms state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.10932v1"}
{"created":"2023-07-20 14:59:02","title":"MediaGPT : A Large Language Model Target Chinese Media","abstract":"The development of large language models (LLMs) has seen rapid progress in recent years. One of the most widely used LLMs is the Generative Pre-trained Transformer (GPT) series, which has been applied in various fields, including the media domain. However, in practical applications, the differences between the media's use cases and the general-purpose applications of LLMs have become increasingly apparent, especially Chinese. As a result, there is a growing need to develop LLM that are specifically tailored to the unique requirements of the media domain. In this paper, we present MediaGPT, a large language model training on variety of media data and addressing the practical needs of Chinese media. We have designed a diverse set of task instruction types to cater to the specific requirements of the domain. To further validate the effectiveness of our proposed LLM, we have constructed unique datasets that are tailored to the media domain and have also developed verification methods that are specifically designed for generative-type tasks. By doing so, we aim to bridge the gap between the general-purpose LLM and the requirements of the media domain, and to pave the way for more effective and efficient use of LLM in this field. This paper aims to explore the challenges and opportunities of developing LLM for media applications and to propose potential solutions for addressing these challenges.","sentences":["The development of large language models (LLMs) has seen rapid progress in recent years.","One of the most widely used LLMs is the Generative Pre-trained Transformer (GPT) series, which has been applied in various fields, including the media domain.","However, in practical applications, the differences between the media's use cases and the general-purpose applications of LLMs have become increasingly apparent, especially Chinese.","As a result, there is a growing need to develop LLM that are specifically tailored to the unique requirements of the media domain.","In this paper, we present MediaGPT, a large language model training on variety of media data and addressing the practical needs of Chinese media.","We have designed a diverse set of task instruction types to cater to the specific requirements of the domain.","To further validate the effectiveness of our proposed LLM, we have constructed unique datasets that are tailored to the media domain and have also developed verification methods that are specifically designed for generative-type tasks.","By doing so, we aim to bridge the gap between the general-purpose LLM and the requirements of the media domain, and to pave the way for more effective and efficient use of LLM in this field.","This paper aims to explore the challenges and opportunities of developing LLM for media applications and to propose potential solutions for addressing these challenges."],"url":"http://arxiv.org/abs/2307.10930v1"}
{"created":"2023-07-20 14:56:35","title":"FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets","abstract":"Evaluation of Large Language Models (LLMs) is challenging because aligning to human values requires the composition of multiple skills and the required set of skills varies depending on the instruction. Recent studies have evaluated the performance of LLMs in two ways, (1) automatic evaluation on several independent benchmarks and (2) human or machined-based evaluation giving an overall score to the response. However, both settings are coarse-grained evaluations, not considering the nature of user instructions that require instance-wise skill composition, which limits the interpretation of the true capabilities of LLMs. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment SKill Sets), a fine-grained evaluation protocol that can be used for both model-based and human-based evaluation which decomposes coarse-level scoring to an instance-wise skill set-level. Specifically, we define 12 fine-grained skills needed for LLMs to follow open-ended user instructions and construct an evaluation set by allocating a set of skills for each instance. Additionally, by annotating the target domains and difficulty level for each instance, FLASK provides a holistic view with a comprehensive analysis of a model's performance depending on skill, domain, and difficulty. Through using FLASK, we compare multiple open-sourced and proprietary LLMs and observe highly-correlated findings between model-based and human-based evaluations. FLASK enables developers to more accurately measure the model performance and how it can be improved by analyzing factors that make LLMs proficient in particular skills. For practitioners, FLASK can be used to recommend suitable models for particular situations through comprehensive comparison among various LLMs. We release the evaluation data and code implementation at https://github.com/kaistAI/FLASK.","sentences":["Evaluation of Large Language Models (LLMs) is challenging because aligning to human values requires the composition of multiple skills and the required set of skills varies depending on the instruction.","Recent studies have evaluated the performance of LLMs in two ways, (1) automatic evaluation on several independent benchmarks and (2) human or machined-based evaluation giving an overall score to the response.","However, both settings are coarse-grained evaluations, not considering the nature of user instructions that require instance-wise skill composition, which limits the interpretation of the true capabilities of LLMs.","In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment SKill Sets), a fine-grained evaluation protocol that can be used for both model-based and human-based evaluation which decomposes coarse-level scoring to an instance-wise skill set-level.","Specifically, we define 12 fine-grained skills needed for LLMs to follow open-ended user instructions and construct an evaluation set by allocating a set of skills for each instance.","Additionally, by annotating the target domains and difficulty level for each instance, FLASK provides a holistic view with a comprehensive analysis of a model's performance depending on skill, domain, and difficulty.","Through using FLASK, we compare multiple open-sourced and proprietary LLMs and observe highly-correlated findings between model-based and human-based evaluations.","FLASK enables developers to more accurately measure the model performance and how it can be improved by analyzing factors that make LLMs proficient in particular skills.","For practitioners, FLASK can be used to recommend suitable models for particular situations through comprehensive comparison among various LLMs.","We release the evaluation data and code implementation at https://github.com/kaistAI/FLASK."],"url":"http://arxiv.org/abs/2307.10928v1"}
{"created":"2023-07-20 14:51:28","title":"Intrinsic Appearance Decomposition Using Point Cloud Representation","abstract":"Intrinsic decomposition is to infer the albedo and shading from the image. Since it is a heavily ill-posed problem, previous methods rely on prior assumptions from 2D images, however, the exploration of the data representation itself is limited. The point cloud is known as a rich format of scene representation, which naturally aligns the geometric information and the color information of an image. Our proposed method, Point Intrinsic Net, in short, PoInt-Net, jointly predicts the albedo, light source direction, and shading, using point cloud representation. Experiments reveal the benefits of PoInt-Net, in terms of accuracy, it outperforms 2D representation approaches on multiple metrics across datasets; in terms of efficiency, it trains on small-scale point clouds and performs stably on any-scale point clouds; in terms of robustness, it only trains on single object level dataset, and demonstrates reasonable generalization ability for unseen objects and scenes.","sentences":["Intrinsic decomposition is to infer the albedo and shading from the image.","Since it is a heavily ill-posed problem, previous methods rely on prior assumptions from 2D images, however, the exploration of the data representation itself is limited.","The point cloud is known as a rich format of scene representation, which naturally aligns the geometric information and the color information of an image.","Our proposed method, Point Intrinsic Net, in short, PoInt-Net, jointly predicts the albedo, light source direction, and shading, using point cloud representation.","Experiments reveal the benefits of PoInt-Net, in terms of accuracy, it outperforms 2D representation approaches on multiple metrics across datasets; in terms of efficiency, it trains on small-scale point clouds and performs stably on any-scale point clouds; in terms of robustness, it only trains on single object level dataset, and demonstrates reasonable generalization ability for unseen objects and scenes."],"url":"http://arxiv.org/abs/2307.10924v1"}
{"created":"2023-07-20 14:49:58","title":"Sequential Multi-Dimensional Self-Supervised Learning for Clinical Time Series","abstract":"Self-supervised learning (SSL) for clinical time series data has received significant attention in recent literature, since these data are highly rich and provide important information about a patient's physiological state. However, most existing SSL methods for clinical time series are limited in that they are designed for unimodal time series, such as a sequence of structured features (e.g., lab values and vitals signs) or an individual high-dimensional physiological signal (e.g., an electrocardiogram). These existing methods cannot be readily extended to model time series that exhibit multimodality, with structured features and high-dimensional data being recorded at each timestep in the sequence. In this work, we address this gap and propose a new SSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is applied both at the level of the entire sequence and at the level of the individual high-dimensional data points in the sequence in order to better capture information at both scales. Our strategy is agnostic to the specific form of loss function used at each level -- it can be contrastive, as in SimCLR, or non-contrastive, as in VICReg. We evaluate our method on two real-world clinical datasets, where the time series contains sequences of (1) high-frequency electrocardiograms and (2) structured data from lab values and vitals signs. Our experimental results indicate that pre-training with our method and then fine-tuning on downstream tasks improves performance over baselines on both datasets, and in several settings, can lead to improvements across different self-supervised loss functions.","sentences":["Self-supervised learning (SSL) for clinical time series data has received significant attention in recent literature, since these data are highly rich and provide important information about a patient's physiological state.","However, most existing SSL methods for clinical time series are limited in that they are designed for unimodal time series, such as a sequence of structured features (e.g., lab values and vitals signs) or an individual high-dimensional physiological signal (e.g., an electrocardiogram).","These existing methods cannot be readily extended to model time series that exhibit multimodality, with structured features and high-dimensional data being recorded at each timestep in the sequence.","In this work, we address this gap and propose a new SSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is applied both at the level of the entire sequence and at the level of the individual high-dimensional data points in the sequence in order to better capture information at both scales.","Our strategy is agnostic to the specific form of loss function used at each level -- it can be contrastive, as in SimCLR, or non-contrastive, as in VICReg.","We evaluate our method on two real-world clinical datasets, where the time series contains sequences of (1) high-frequency electrocardiograms and (2) structured data from lab values and vitals signs.","Our experimental results indicate that pre-training with our method and then fine-tuning on downstream tasks improves performance over baselines on both datasets, and in several settings, can lead to improvements across different self-supervised loss functions."],"url":"http://arxiv.org/abs/2307.10923v1"}
{"created":"2023-07-20 14:47:50","title":"Language-based Action Concept Spaces Improve Video Self-Supervised Learning","abstract":"Recent contrastive language image pre-training has led to learning highly transferable and robust image representations. However, adapting these models to video domains with minimal supervision remains an open problem. We explore a simple step in that direction, using language tied self-supervised learning to adapt an image CLIP model to the video domain. A backbone modified for temporal modeling is trained under self-distillation settings with train objectives operating in an action concept space. Feature vectors of various action concepts extracted from a language encoder using relevant textual prompts construct this space. We introduce two train objectives, concept distillation and concept alignment, that retain generality of original representations while enforcing relations between actions and their attributes. Our approach improves zero-shot and linear probing performance on three action recognition benchmarks.","sentences":["Recent contrastive language image pre-training has led to learning highly transferable and robust image representations.","However, adapting these models to video domains with minimal supervision remains an open problem.","We explore a simple step in that direction, using language tied self-supervised learning to adapt an image CLIP model to the video domain.","A backbone modified for temporal modeling is trained under self-distillation settings with train objectives operating in an action concept space.","Feature vectors of various action concepts extracted from a language encoder using relevant textual prompts construct this space.","We introduce two train objectives, concept distillation and concept alignment, that retain generality of original representations while enforcing relations between actions and their attributes.","Our approach improves zero-shot and linear probing performance on three action recognition benchmarks."],"url":"http://arxiv.org/abs/2307.10922v1"}
{"created":"2023-07-20 14:39:46","title":"Revisiting Fine-Tuning Strategies for Self-supervised Medical Imaging Analysis","abstract":"Despite the rapid progress in self-supervised learning (SSL), end-to-end fine-tuning still remains the dominant fine-tuning strategy for medical imaging analysis. However, it remains unclear whether this approach is truly optimal for effectively utilizing the pre-trained knowledge, especially considering the diverse categories of SSL that capture different types of features. In this paper, we first establish strong contrastive and restorative SSL baselines that outperform SOTA methods across four diverse downstream tasks. Building upon these strong baselines, we conduct an extensive fine-tuning analysis across multiple pre-training and fine-tuning datasets, as well as various fine-tuning dataset sizes. Contrary to the conventional wisdom of fine-tuning only the last few layers of a pre-trained network, we show that fine-tuning intermediate layers is more effective, with fine-tuning the second quarter (25-50%) of the network being optimal for contrastive SSL whereas fine-tuning the third quarter (50-75%) of the network being optimal for restorative SSL. Compared to the de-facto standard of end-to-end fine-tuning, our best fine-tuning strategy, which fine-tunes a shallower network consisting of the first three quarters (0-75%) of the pre-trained network, yields improvements of as much as 5.48%. Additionally, using these insights, we propose a simple yet effective method to leverage the complementary strengths of multiple SSL models, resulting in enhancements of up to 3.57% compared to using the best model alone. Hence, our fine-tuning strategies not only enhance the performance of individual SSL models, but also enable effective utilization of the complementary strengths offered by multiple SSL models, leading to significant improvements in self-supervised medical imaging analysis.","sentences":["Despite the rapid progress in self-supervised learning (SSL), end-to-end fine-tuning still remains the dominant fine-tuning strategy for medical imaging analysis.","However, it remains unclear whether this approach is truly optimal for effectively utilizing the pre-trained knowledge, especially considering the diverse categories of SSL that capture different types of features.","In this paper, we first establish strong contrastive and restorative SSL baselines that outperform SOTA methods across four diverse downstream tasks.","Building upon these strong baselines, we conduct an extensive fine-tuning analysis across multiple pre-training and fine-tuning datasets, as well as various fine-tuning dataset sizes.","Contrary to the conventional wisdom of fine-tuning only the last few layers of a pre-trained network, we show that fine-tuning intermediate layers is more effective, with fine-tuning the second quarter (25-50%) of the network being optimal for contrastive SSL whereas fine-tuning the third quarter (50-75%) of the network being optimal for restorative SSL.","Compared to the de-facto standard of end-to-end fine-tuning, our best fine-tuning strategy, which fine-tunes a shallower network consisting of the first three quarters (0-75%) of the pre-trained network, yields improvements of as much as 5.48%.","Additionally, using these insights, we propose a simple yet effective method to leverage the complementary strengths of multiple SSL models, resulting in enhancements of up to 3.57% compared to using the best model alone.","Hence, our fine-tuning strategies not only enhance the performance of individual SSL models, but also enable effective utilization of the complementary strengths offered by multiple SSL models, leading to significant improvements in self-supervised medical imaging analysis."],"url":"http://arxiv.org/abs/2307.10915v1"}
{"created":"2023-07-20 14:34:08","title":"WeakPolyp: You Only Look Bounding Box for Polyp Segmentation","abstract":"Limited by expensive pixel-level labels, polyp segmentation models are plagued by data shortage and suffer from impaired generalization. In contrast, polyp bounding box annotations are much cheaper and more accessible. Thus, to reduce labeling cost, we propose to learn a weakly supervised polyp segmentation model (i.e., WeakPolyp) completely based on bounding box annotations. However, coarse bounding boxes contain too much noise. To avoid interference, we introduce the mask-to-box (M2B) transformation. By supervising the outer box mask of the prediction instead of the prediction itself, M2B greatly mitigates the mismatch between the coarse label and the precise prediction. But, M2B only provides sparse supervision, leading to non-unique predictions. Therefore, we further propose a scale consistency (SC) loss for dense supervision. By explicitly aligning predictions across the same image at different scales, the SC loss largely reduces the variation of predictions. Note that our WeakPolyp is a plug-and-play model, which can be easily ported to other appealing backbones. Besides, the proposed modules are only used during training, bringing no computation cost to inference. Extensive experiments demonstrate the effectiveness of our proposed WeakPolyp, which surprisingly achieves a comparable performance with a fully supervised model, requiring no mask annotations at all.","sentences":["Limited by expensive pixel-level labels, polyp segmentation models are plagued by data shortage and suffer from impaired generalization.","In contrast, polyp bounding box annotations are much cheaper and more accessible.","Thus, to reduce labeling cost, we propose to learn a weakly supervised polyp segmentation model (i.e., WeakPolyp) completely based on bounding box annotations.","However, coarse bounding boxes contain too much noise.","To avoid interference, we introduce the mask-to-box (M2B) transformation.","By supervising the outer box mask of the prediction instead of the prediction itself, M2B greatly mitigates the mismatch between the coarse label and the precise prediction.","But, M2B only provides sparse supervision, leading to non-unique predictions.","Therefore, we further propose a scale consistency (SC) loss for dense supervision.","By explicitly aligning predictions across the same image at different scales, the SC loss largely reduces the variation of predictions.","Note that our WeakPolyp is a plug-and-play model, which can be easily ported to other appealing backbones.","Besides, the proposed modules are only used during training, bringing no computation cost to inference.","Extensive experiments demonstrate the effectiveness of our proposed WeakPolyp, which surprisingly achieves a comparable performance with a fully supervised model, requiring no mask annotations at all."],"url":"http://arxiv.org/abs/2307.10912v1"}
{"created":"2023-07-20 14:29:51","title":"The Role of Entropy and Reconstruction in Multi-View Self-Supervised Learning","abstract":"The mechanisms behind the success of multi-view self-supervised learning (MVSSL) are not yet fully understood. Contrastive MVSSL methods have been studied through the lens of InfoNCE, a lower bound of the Mutual Information (MI). However, the relation between other MVSSL methods and MI remains unclear. We consider a different lower bound on the MI consisting of an entropy and a reconstruction term (ER), and analyze the main MVSSL families through its lens. Through this ER bound, we show that clustering-based methods such as DeepCluster and SwAV maximize the MI. We also re-interpret the mechanisms of distillation-based approaches such as BYOL and DINO, showing that they explicitly maximize the reconstruction term and implicitly encourage a stable entropy, and we confirm this empirically. We show that replacing the objectives of common MVSSL methods with this ER bound achieves competitive performance, while making them stable when training with smaller batch sizes or smaller exponential moving average (EMA) coefficients.   Github repo: https://github.com/apple/ml-entropy-reconstruction.","sentences":["The mechanisms behind the success of multi-view self-supervised learning (MVSSL) are not yet fully understood.","Contrastive MVSSL methods have been studied through the lens of InfoNCE, a lower bound of the Mutual Information (MI).","However, the relation between other MVSSL methods and MI remains unclear.","We consider a different lower bound on the MI consisting of an entropy and a reconstruction term (ER), and analyze the main MVSSL families through its lens.","Through this ER bound, we show that clustering-based methods such as DeepCluster and SwAV maximize the MI.","We also re-interpret the mechanisms of distillation-based approaches such as BYOL and DINO, showing that they explicitly maximize the reconstruction term and implicitly encourage a stable entropy, and we confirm this empirically.","We show that replacing the objectives of common MVSSL methods with this ER bound achieves competitive performance, while making them stable when training with smaller batch sizes or smaller exponential moving average (EMA) coefficients.   ","Github repo: https://github.com/apple/ml-entropy-reconstruction."],"url":"http://arxiv.org/abs/2307.10907v1"}
{"created":"2023-07-20 14:26:21","title":"VoteLab: A Modular and Adaptive Experimentation Platform for Online Collective Decision Making","abstract":"Digital democracy and new forms for direct digital participation in policy making gain unprecedented momentum. This is particularly the case for preferential voting methods and decision-support systems designed to promote fairer, more inclusive and legitimate collective decision-making processes in citizens assemblies, participatory budgeting and elections. However, a systematic human experimentation with different voting methods is cumbersome and costly. This paper introduces VoteLab, an open-source and thoroughly-documented platform for modular and adaptive design of voting experiments. It supports to visually and interactively build reusable campaigns with a choice of different voting methods, while voters can easily respond to subscribed voting questions on a smartphone. A proof-of-concept with four voting methods and questions on COVID-19 in an online lab experiment have been used to study the consistency of voting outcomes. It demonstrates the capability of VoteLab to support rigorous experimentation of complex voting scenarios.","sentences":["Digital democracy and new forms for direct digital participation in policy making gain unprecedented momentum.","This is particularly the case for preferential voting methods and decision-support systems designed to promote fairer, more inclusive and legitimate collective decision-making processes in citizens assemblies, participatory budgeting and elections.","However, a systematic human experimentation with different voting methods is cumbersome and costly.","This paper introduces VoteLab, an open-source and thoroughly-documented platform for modular and adaptive design of voting experiments.","It supports to visually and interactively build reusable campaigns with a choice of different voting methods, while voters can easily respond to subscribed voting questions on a smartphone.","A proof-of-concept with four voting methods and questions on COVID-19 in an online lab experiment have been used to study the consistency of voting outcomes.","It demonstrates the capability of VoteLab to support rigorous experimentation of complex voting scenarios."],"url":"http://arxiv.org/abs/2307.10903v1"}
{"created":"2023-07-20 14:24:15","title":"Strong Invariants Are Hard: On the Hardness of Strongest Polynomial Invariants for (Probabilistic) Programs","abstract":"We show that computing the strongest polynomial invariant for single-path loops with polynomial assignments is at least as hard as the Skolem problem, a famous problem whose decidability has been open for almost a century. While the strongest polynomial invariants are computable for affine loops, for polynomial loops the problem remained wide open. As an intermediate result of independent interest, we prove that reachability for discrete polynomial dynamical systems is Skolem-hard as well. Furthermore, we generalize the notion of invariant ideals and introduce moment invariant ideals for probabilistic programs. With this tool, we further show that the strongest polynomial moment invariant is (i) uncomputable, for probabilistic loops with branching statements, and (ii) Skolem-hard to compute for polynomial probabilistic loops without branching statements. Finally, we identify a class of probabilistic loops for which the strongest polynomial moment invariant is computable and provide an algorithm for it.","sentences":["We show that computing the strongest polynomial invariant for single-path loops with polynomial assignments is at least as hard as the Skolem problem, a famous problem whose decidability has been open for almost a century.","While the strongest polynomial invariants are computable for affine loops, for polynomial loops the problem remained wide open.","As an intermediate result of independent interest, we prove that reachability for discrete polynomial dynamical systems is Skolem-hard as well.","Furthermore, we generalize the notion of invariant ideals and introduce moment invariant ideals for probabilistic programs.","With this tool, we further show that the strongest polynomial moment invariant is (i) uncomputable, for probabilistic loops with branching statements, and (ii) Skolem-hard to compute for polynomial probabilistic loops without branching statements.","Finally, we identify a class of probabilistic loops for which the strongest polynomial moment invariant is computable and provide an algorithm for it."],"url":"http://arxiv.org/abs/2307.10902v1"}
{"created":"2023-07-20 14:19:27","title":"A Survey on Dialogue Management in Human-Robot Interaction","abstract":"As social robots see increasing deployment within the general public, improving the interaction with those robots is essential. Spoken language offers an intuitive interface for the human-robot interaction (HRI), with dialogue management (DM) being a key component in those interactive systems. Yet, to overcome current challenges and manage smooth, informative and engaging interaction a more structural approach to combining HRI and DM is needed. In this systematic review, we analyse the current use of DM in HRI and focus on the type of dialogue manager used, its capabilities, evaluation methods and the challenges specific to DM in HRI. We identify the challenges and current scientific frontier related to the DM approach, interaction domain, robot appearance, physical situatedness and multimodality.","sentences":["As social robots see increasing deployment within the general public, improving the interaction with those robots is essential.","Spoken language offers an intuitive interface for the human-robot interaction (HRI), with dialogue management (DM) being a key component in those interactive systems.","Yet, to overcome current challenges and manage smooth, informative and engaging interaction a more structural approach to combining HRI and DM is needed.","In this systematic review, we analyse the current use of DM in HRI and focus on the type of dialogue manager used, its capabilities, evaluation methods and the challenges specific to DM in HRI.","We identify the challenges and current scientific frontier related to the DM approach, interaction domain, robot appearance, physical situatedness and multimodality."],"url":"http://arxiv.org/abs/2307.10897v1"}
{"created":"2023-07-20 14:19:17","title":"Software Product Line Engineering via Software Transplantation","abstract":"For companies producing related products, a Software Product Line (SPL) is a software reuse method that improves time-to-market and software quality, achieving substantial cost reductions.These benefits do not come for free. It often takes years to re-architect and re-engineer a codebase to support SPL and, once adopted, it must be maintained. Current SPL practice relies on a collection of tools, tailored for different reengineering phases, whose output developers must coordinate and integrate. We present Foundry, a general automated approach for leveraging software transplantation to speed conversion to and maintenance of SPL. Foundry facilitates feature extraction and migration. It can efficiently, repeatedly, transplant a sequence of features, implemented in multiple files. We used Foundry to create two valid product lines that integrate features from three real-world systems in an automated way. Moreover, we conducted an experiment comparing Foundry's feature migration with manual effort. We show that Foundry automatically migrated features across codebases 4.8 times faster, on average, than the average time a group of SPL experts took to accomplish the task.","sentences":["For companies producing related products, a Software Product Line (SPL) is a software reuse method that improves time-to-market and software quality, achieving substantial cost reductions.","These benefits do not come for free.","It often takes years to re-architect and re-engineer a codebase to support SPL and, once adopted, it must be maintained.","Current SPL practice relies on a collection of tools, tailored for different reengineering phases, whose output developers must coordinate and integrate.","We present Foundry, a general automated approach for leveraging software transplantation to speed conversion to and maintenance of SPL.","Foundry facilitates feature extraction and migration.","It can efficiently, repeatedly, transplant a sequence of features, implemented in multiple files.","We used Foundry to create two valid product lines that integrate features from three real-world systems in an automated way.","Moreover, we conducted an experiment comparing Foundry's feature migration with manual effort.","We show that Foundry automatically migrated features across codebases 4.8 times faster, on average, than the average time a group of SPL experts took to accomplish the task."],"url":"http://arxiv.org/abs/2307.10896v1"}
{"created":"2023-07-20 14:18:44","title":"Variational Point Encoding Deformation for Dental Modeling","abstract":"Digital dentistry has made significant advancements in recent years, yet numerous challenges remain to be addressed. In this study, we release a new extensive dataset of tooth meshes to encourage further research. Additionally, we propose Variational FoldingNet (VF-Net), which extends FoldingNet to enable probabilistic learning of point cloud representations. A key challenge in existing latent variable models for point clouds is the lack of a 1-to-1 mapping between input points and output points. Instead, they must rely on optimizing Chamfer distances, a metric that does not have a normalized distributional counterpart, preventing its usage in probabilistic models. We demonstrate that explicit minimization of Chamfer distances can be replaced by a suitable encoder, which allows us to increase computational efficiency while simplifying the probabilistic extension. Our experimental findings present empirical evidence demonstrating the superior performance of VF-Net over existing models in terms of dental scan reconstruction and extrapolation. Additionally, our investigation highlights the robustness of VF-Net's latent representations. These results underscore the promising prospects of VF-Net as an effective and reliable method for point cloud reconstruction and analysis.","sentences":["Digital dentistry has made significant advancements in recent years, yet numerous challenges remain to be addressed.","In this study, we release a new extensive dataset of tooth meshes to encourage further research.","Additionally, we propose Variational FoldingNet (VF-Net), which extends FoldingNet to enable probabilistic learning of point cloud representations.","A key challenge in existing latent variable models for point clouds is the lack of a 1-to-1 mapping between input points and output points.","Instead, they must rely on optimizing Chamfer distances, a metric that does not have a normalized distributional counterpart, preventing its usage in probabilistic models.","We demonstrate that explicit minimization of Chamfer distances can be replaced by a suitable encoder, which allows us to increase computational efficiency while simplifying the probabilistic extension.","Our experimental findings present empirical evidence demonstrating the superior performance of VF-Net over existing models in terms of dental scan reconstruction and extrapolation.","Additionally, our investigation highlights the robustness of VF-Net's latent representations.","These results underscore the promising prospects of VF-Net as an effective and reliable method for point cloud reconstruction and analysis."],"url":"http://arxiv.org/abs/2307.10895v1"}
{"created":"2023-07-20 14:15:20","title":"Human Motion Generation: A Survey","abstract":"Human motion generation aims to generate natural human pose sequences and shows immense potential for real-world applications. Substantial progress has been made recently in motion data collection technologies and generation methods, laying the foundation for increasing interest in human motion generation. Most research within this field focuses on generating human motions based on conditional signals, such as text, audio, and scene contexts. While significant advancements have been made in recent years, the task continues to pose challenges due to the intricate nature of human motion and its implicit relationship with conditional signals. In this survey, we present a comprehensive literature review of human motion generation, which, to the best of our knowledge, is the first of its kind in this field. We begin by introducing the background of human motion and generative models, followed by an examination of representative methods for three mainstream sub-tasks: text-conditioned, audio-conditioned, and scene-conditioned human motion generation. Additionally, we provide an overview of common datasets and evaluation metrics. Lastly, we discuss open problems and outline potential future research directions. We hope that this survey could provide the community with a comprehensive glimpse of this rapidly evolving field and inspire novel ideas that address the outstanding challenges.","sentences":["Human motion generation aims to generate natural human pose sequences and shows immense potential for real-world applications.","Substantial progress has been made recently in motion data collection technologies and generation methods, laying the foundation for increasing interest in human motion generation.","Most research within this field focuses on generating human motions based on conditional signals, such as text, audio, and scene contexts.","While significant advancements have been made in recent years, the task continues to pose challenges due to the intricate nature of human motion and its implicit relationship with conditional signals.","In this survey, we present a comprehensive literature review of human motion generation, which, to the best of our knowledge, is the first of its kind in this field.","We begin by introducing the background of human motion and generative models, followed by an examination of representative methods for three mainstream sub-tasks: text-conditioned, audio-conditioned, and scene-conditioned human motion generation.","Additionally, we provide an overview of common datasets and evaluation metrics.","Lastly, we discuss open problems and outline potential future research directions.","We hope that this survey could provide the community with a comprehensive glimpse of this rapidly evolving field and inspire novel ideas that address the outstanding challenges."],"url":"http://arxiv.org/abs/2307.10894v1"}
{"created":"2023-07-20 14:11:29","title":"Learning and Generalizing Polynomials in Simulation Metamodeling","abstract":"The ability to learn polynomials and generalize out-of-distribution is essential for simulation metamodels in many disciplines of engineering, where the time step updates are described by polynomials. While feed forward neural networks can fit any function, they cannot generalize out-of-distribution for higher-order polynomials. Therefore, this paper collects and proposes multiplicative neural network (MNN) architectures that are used as recursive building blocks for approximating higher-order polynomials. Our experiments show that MNNs are better than baseline models at generalizing, and their performance in validation is true to their performance in out-of-distribution tests. In addition to MNN architectures, a simulation metamodeling approach is proposed for simulations with polynomial time step updates. For these simulations, simulating a time interval can be performed in fewer steps by increasing the step size, which entails approximating higher-order polynomials. While our approach is compatible with any simulation with polynomial time step updates, a demonstration is shown for an epidemiology simulation model, which also shows the inductive bias in MNNs for learning and generalizing higher-order polynomials.","sentences":["The ability to learn polynomials and generalize out-of-distribution is essential for simulation metamodels in many disciplines of engineering, where the time step updates are described by polynomials.","While feed forward neural networks can fit any function, they cannot generalize out-of-distribution for higher-order polynomials.","Therefore, this paper collects and proposes multiplicative neural network (MNN) architectures that are used as recursive building blocks for approximating higher-order polynomials.","Our experiments show that MNNs are better than baseline models at generalizing, and their performance in validation is true to their performance in out-of-distribution tests.","In addition to MNN architectures, a simulation metamodeling approach is proposed for simulations with polynomial time step updates.","For these simulations, simulating a time interval can be performed in fewer steps by increasing the step size, which entails approximating higher-order polynomials.","While our approach is compatible with any simulation with polynomial time step updates, a demonstration is shown for an epidemiology simulation model, which also shows the inductive bias in MNNs for learning and generalizing higher-order polynomials."],"url":"http://arxiv.org/abs/2307.10892v1"}
{"created":"2023-07-20 14:10:40","title":"Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks","abstract":"Abstraction is a key verification technique to improve scalability. However, its use for neural networks is so far extremely limited. Previous approaches for abstracting classification networks replace several neurons with one of them that is similar enough. We can classify the similarity as defined either syntactically (using quantities on the connections between neurons) or semantically (on the activation values of neurons for various inputs). Unfortunately, the previous approaches only achieve moderate reductions, when implemented at all. In this work, we provide a more flexible framework where a neuron can be replaced with a linear combination of other neurons, improving the reduction. We apply this approach both on syntactic and semantic abstractions, and implement and evaluate them experimentally. Further, we introduce a refinement method for our abstractions, allowing for finding a better balance between reduction and precision.","sentences":["Abstraction is a key verification technique to improve scalability.","However, its use for neural networks is so far extremely limited.","Previous approaches for abstracting classification networks replace several neurons with one of them that is similar enough.","We can classify the similarity as defined either syntactically (using quantities on the connections between neurons) or semantically (on the activation values of neurons for various inputs).","Unfortunately, the previous approaches only achieve moderate reductions, when implemented at all.","In this work, we provide a more flexible framework where a neuron can be replaced with a linear combination of other neurons, improving the reduction.","We apply this approach both on syntactic and semantic abstractions, and implement and evaluate them experimentally.","Further, we introduce a refinement method for our abstractions, allowing for finding a better balance between reduction and precision."],"url":"http://arxiv.org/abs/2307.10891v1"}
{"created":"2023-07-20 14:10:33","title":"Player-optimal Stable Regret for Bandit Learning in Matching Markets","abstract":"The problem of matching markets has been studied for a long time in the literature due to its wide range of applications. Finding a stable matching is a common equilibrium objective in this problem. Since market participants are usually uncertain of their preferences, a rich line of recent works study the online setting where one-side participants (players) learn their unknown preferences from iterative interactions with the other side (arms). Most previous works in this line are only able to derive theoretical guarantees for player-pessimal stable regret, which is defined compared with the players' least-preferred stable matching. However, under the pessimal stable matching, players only obtain the least reward among all stable matchings. To maximize players' profits, player-optimal stable matching would be the most desirable. Though \\citet{basu21beyond} successfully bring an upper bound for player-optimal stable regret, their result can be exponentially large if players' preference gap is small. Whether a polynomial guarantee for this regret exists is a significant but still open problem. In this work, we provide a new algorithm named explore-then-Gale-Shapley (ETGS) and show that the optimal stable regret of each player can be upper bounded by $O(K\\log T/\\Delta^2)$ where $K$ is the number of arms, $T$ is the horizon and $\\Delta$ is the players' minimum preference gap among the first $N+1$-ranked arms. This result significantly improves previous works which either have a weaker player-pessimal stable matching objective or apply only to markets with special assumptions. When the preferences of participants satisfy some special conditions, our regret upper bound also matches the previously derived lower bound.","sentences":["The problem of matching markets has been studied for a long time in the literature due to its wide range of applications.","Finding a stable matching is a common equilibrium objective in this problem.","Since market participants are usually uncertain of their preferences, a rich line of recent works study the online setting where one-side participants (players) learn their unknown preferences from iterative interactions with the other side (arms).","Most previous works in this line are only able to derive theoretical guarantees for player-pessimal stable regret, which is defined compared with the players' least-preferred stable matching.","However, under the pessimal stable matching, players only obtain the least reward among all stable matchings.","To maximize players' profits, player-optimal stable matching would be the most desirable.","Though \\citet{basu21beyond} successfully bring an upper bound for player-optimal stable regret, their result can be exponentially large if players' preference gap is small.","Whether a polynomial guarantee for this regret exists is a significant but still open problem.","In this work, we provide a new algorithm named explore-then-Gale-Shapley (ETGS) and show that the optimal stable regret of each player can be upper bounded by $O(K\\log T/\\Delta^2)$ where $K$ is the number of arms, $T$ is the horizon and $\\Delta$ is the players' minimum preference gap among the first $N+1$-ranked arms.","This result significantly improves previous works which either have a weaker player-pessimal stable matching objective or apply only to markets with special assumptions.","When the preferences of participants satisfy some special conditions, our regret upper bound also matches the previously derived lower bound."],"url":"http://arxiv.org/abs/2307.10890v1"}
{"created":"2023-07-20 14:03:32","title":"Robust Alternating-Time Temporal Logic","abstract":"In multi-agent system design, a crucial aspect is to ensure robustness, meaning that for a coalition of agents A, small violations of adversarial assumptions only lead to small violations of A's goals. In this paper we introduce a logical framework for robust strategic reasoning about multi-agent systems. Specifically, inspired by recent works on robust temporal logics, we introduce and study rATL and rATL*, logics that extend the well-known Alternating-time Temporal Logic ATL and ATL* by means of an opportune multi-valued semantics for the strategy quantifiers and temporal operators. We study the model-checking and satisfiability problems for rATL and rATL* and show that dealing with robustness comes at no additional computational cost. Indeed, we show that these problems are PTime-complete and ExpTime-complete for rATL, respectively, while both are 2ExpTime-complete for rATL*.","sentences":["In multi-agent system design, a crucial aspect is to ensure robustness, meaning that for a coalition of agents A, small violations of adversarial assumptions only lead to small violations of A's goals.","In this paper we introduce a logical framework for robust strategic reasoning about multi-agent systems.","Specifically, inspired by recent works on robust temporal logics, we introduce and study rATL and rATL*, logics that extend the well-known Alternating-time Temporal Logic ATL and ATL* by means of an opportune multi-valued semantics for the strategy quantifiers and temporal operators.","We study the model-checking and satisfiability problems for rATL and rATL* and show that dealing with robustness comes at no additional computational cost.","Indeed, we show that these problems are PTime-complete and ExpTime-complete for rATL, respectively, while both are 2ExpTime-complete for rATL*."],"url":"http://arxiv.org/abs/2307.10885v1"}
{"created":"2023-07-20 14:01:16","title":"Control Input Inference of Mobile Agents under Unknown Objective","abstract":"Trajectory and control secrecy is an important issue in robotics security. This paper proposes a novel algorithm for the control input inference of a mobile agent without knowing its control objective. Specifically, the algorithm first estimates the target state by applying external perturbations. Then we identify the objective function based on the inverse optimal control, providing the well-posedness proof and the identifiability analysis. Next, we obtain the optimal estimate of the control horizon using binary search. Finally, the agent's control optimization problem is reconstructed and solved to predict its input. Simulation illustrates the efficiency and the performance of the algorithm.","sentences":["Trajectory and control secrecy is an important issue in robotics security.","This paper proposes a novel algorithm for the control input inference of a mobile agent without knowing its control objective.","Specifically, the algorithm first estimates the target state by applying external perturbations.","Then we identify the objective function based on the inverse optimal control, providing the well-posedness proof and the identifiability analysis.","Next, we obtain the optimal estimate of the control horizon using binary search.","Finally, the agent's control optimization problem is reconstructed and solved to predict its input.","Simulation illustrates the efficiency and the performance of the algorithm."],"url":"http://arxiv.org/abs/2307.10883v1"}
{"created":"2023-07-20 13:50:18","title":"Threshold Encrypted Mempools: Limitations and Considerations","abstract":"Encrypted mempools are a class of solutions aimed at preventing or reducing negative externalities of MEV extraction using cryptographic privacy. Mempool encryption aims to hide information related to pending transactions until a block including the transactions is committed, targeting the prevention of frontrunning and similar behaviour. Among the various methods of encryption, threshold schemes are particularly interesting for the design of MEV mitigation mechanisms, as their distributed nature and minimal hardware requirements harmonize with a broader goal of decentralization.   This work looks beyond the formal and technical cryptographic aspects of threshold encryption schemes to focus on the market and incentive implications of implementing encrypted mempools as MEV mitigation techniques. In particular, this paper argues that the deployment of such protocols without proper consideration and understanding of market impact invites several undesired outcomes, with the ultimate goal of stimulating further analysis of this class of solutions outside of pure cryptograhic considerations. Included in the paper is an overview of a series of problems, various candidate solutions in the form of mempool encryption techniques with a focus on threshold encryption, potential drawbacks to these solutions, and Osmosis as a case study. The paper targets a broad audience and remains agnostic to blockchain design where possible while drawing from mostly financial examples.","sentences":["Encrypted mempools are a class of solutions aimed at preventing or reducing negative externalities of MEV extraction using cryptographic privacy.","Mempool encryption aims to hide information related to pending transactions until a block including the transactions is committed, targeting the prevention of frontrunning and similar behaviour.","Among the various methods of encryption, threshold schemes are particularly interesting for the design of MEV mitigation mechanisms, as their distributed nature and minimal hardware requirements harmonize with a broader goal of decentralization.   ","This work looks beyond the formal and technical cryptographic aspects of threshold encryption schemes to focus on the market and incentive implications of implementing encrypted mempools as MEV mitigation techniques.","In particular, this paper argues that the deployment of such protocols without proper consideration and understanding of market impact invites several undesired outcomes, with the ultimate goal of stimulating further analysis of this class of solutions outside of pure cryptograhic considerations.","Included in the paper is an overview of a series of problems, various candidate solutions in the form of mempool encryption techniques with a focus on threshold encryption, potential drawbacks to these solutions, and Osmosis as a case study.","The paper targets a broad audience and remains agnostic to blockchain design where possible while drawing from mostly financial examples."],"url":"http://arxiv.org/abs/2307.10878v1"}
{"created":"2023-07-20 13:49:13","title":"Battle Ground: Data Collection and Labeling of CTF Games to Understand Human Cyber Operators","abstract":"Industry standard frameworks are now widespread for labeling the high-level stages and granular actions of attacker and defender behavior in cyberspace. While these labels are used for atomic actions, and to some extent for sequences of actions, there remains a need for labeled data from realistic full-scale attacks. This data is valuable for better understanding human actors' decisions, behaviors, and individual attributes. The analysis could lead to more effective attribution and disruption of attackers.   We present a methodological approach and exploratory case study for systematically analyzing human behavior during a cyber offense/defense capture-the-flag (CTF) game. We describe the data collection and analysis to derive a metric called keystroke accuracy. After collecting players' commands, we label them using the MITRE ATT&CK framework using a new tool called Pathfinder. We present results from preliminary analysis of participants' keystroke accuracy and its relation to score outcome in CTF games. We describe frequency of action classification within the MITRE ATT&CK framework and discuss some of the mathematical trends suggested by our observations. We conclude with a discussion of extensions for the methodology, including performance evaluation during games and the potential use of this methodology for training artificial intelligence.","sentences":["Industry standard frameworks are now widespread for labeling the high-level stages and granular actions of attacker and defender behavior in cyberspace.","While these labels are used for atomic actions, and to some extent for sequences of actions, there remains a need for labeled data from realistic full-scale attacks.","This data is valuable for better understanding human actors' decisions, behaviors, and individual attributes.","The analysis could lead to more effective attribution and disruption of attackers.   ","We present a methodological approach and exploratory case study for systematically analyzing human behavior during a cyber offense/defense capture-the-flag (CTF) game.","We describe the data collection and analysis to derive a metric called keystroke accuracy.","After collecting players' commands, we label them using the MITRE ATT&CK framework using a new tool called Pathfinder.","We present results from preliminary analysis of participants' keystroke accuracy and its relation to score outcome in CTF games.","We describe frequency of action classification within the MITRE ATT&CK framework and discuss some of the mathematical trends suggested by our observations.","We conclude with a discussion of extensions for the methodology, including performance evaluation during games and the potential use of this methodology for training artificial intelligence."],"url":"http://arxiv.org/abs/2307.10877v1"}
{"created":"2023-07-20 13:47:30","title":"Risk-optimized Outlier Removal for Robust Point Cloud Classification","abstract":"The popularity of point cloud deep models for safety-critical purposes has increased, but the reliability and security of these models can be compromised by intentional or naturally occurring point cloud noise. To combat this issue, we present a novel point cloud outlier removal method called PointCVaR, which empowers standard-trained models to eliminate additional outliers and restore the data. Our approach begins by conducting attribution analysis to determine the influence of each point on the model output, which we refer to as point risk. We then optimize the process of filtering high-risk points using Conditional Value at Risk (CVaR) as the objective. The rationale for this approach is based on the observation that noise points in point clouds tend to cluster in the tail of the risk distribution, with a low frequency but a high level of risk, resulting in significant interference with classification results. Despite requiring no additional training effort, our method produces exceptional results in various removal-and-classification experiments for noisy point clouds, which are corrupted by random noise, adversarial noise, and backdoor trigger noise. Impressively, it achieves 87% accuracy in defense against the backdoor attack by removing triggers. Overall, the proposed PointCVaR effectively eliminates noise points and enhances point cloud classification, making it a promising plug-in module for various models in different scenarios.","sentences":["The popularity of point cloud deep models for safety-critical purposes has increased, but the reliability and security of these models can be compromised by intentional or naturally occurring point cloud noise.","To combat this issue, we present a novel point cloud outlier removal method called PointCVaR, which empowers standard-trained models to eliminate additional outliers and restore the data.","Our approach begins by conducting attribution analysis to determine the influence of each point on the model output, which we refer to as point risk.","We then optimize the process of filtering high-risk points using Conditional Value at Risk (CVaR) as the objective.","The rationale for this approach is based on the observation that noise points in point clouds tend to cluster in the tail of the risk distribution, with a low frequency but a high level of risk, resulting in significant interference with classification results.","Despite requiring no additional training effort, our method produces exceptional results in various removal-and-classification experiments for noisy point clouds, which are corrupted by random noise, adversarial noise, and backdoor trigger noise.","Impressively, it achieves 87% accuracy in defense against the backdoor attack by removing triggers.","Overall, the proposed PointCVaR effectively eliminates noise points and enhances point cloud classification, making it a promising plug-in module for various models in different scenarios."],"url":"http://arxiv.org/abs/2307.10875v1"}
{"created":"2023-07-20 13:43:48","title":"Conservative Estimation of Perception Relevance of Dynamic Objects for Safe Trajectories in Automotive Scenarios","abstract":"Having efficient testing strategies is a core challenge that needs to be overcome for the release of automated driving. This necessitates clear requirements as well as suitable methods for testing. In this work, the requirements for perception modules are considered with respect to relevance. The concept of relevance currently remains insufficiently defined and specified. In this paper, we propose a novel methodology to overcome this challenge by exemplary application to collision safety in the highway domain. Using this general system and use case specification, a corresponding concept for relevance is derived. Irrelevant objects are thus defined as objects which do not limit the set of safe actions available to the ego vehicle under consideration of all uncertainties. As an initial step, the use case is decomposed into functional scenarios with respect to collision relevance. For each functional scenario, possible actions of both the ego vehicle and any other dynamic object are formalized as equations. This set of possible actions is constrained by traffic rules, yielding relevance criteria. As a result, we present a conservative estimation which dynamic objects are relevant for perception and need to be considered for a complete evaluation. The estimation provides requirements which are applicable for offline testing and validation of perception components. A visualization is presented for examples from the highD dataset, showing the plausibility of the results. Finally, a possibility for a future validation of the presented relevance concept is outlined.","sentences":["Having efficient testing strategies is a core challenge that needs to be overcome for the release of automated driving.","This necessitates clear requirements as well as suitable methods for testing.","In this work, the requirements for perception modules are considered with respect to relevance.","The concept of relevance currently remains insufficiently defined and specified.","In this paper, we propose a novel methodology to overcome this challenge by exemplary application to collision safety in the highway domain.","Using this general system and use case specification, a corresponding concept for relevance is derived.","Irrelevant objects are thus defined as objects which do not limit the set of safe actions available to the ego vehicle under consideration of all uncertainties.","As an initial step, the use case is decomposed into functional scenarios with respect to collision relevance.","For each functional scenario, possible actions of both the ego vehicle and any other dynamic object are formalized as equations.","This set of possible actions is constrained by traffic rules, yielding relevance criteria.","As a result, we present a conservative estimation which dynamic objects are relevant for perception and need to be considered for a complete evaluation.","The estimation provides requirements which are applicable for offline testing and validation of perception components.","A visualization is presented for examples from the highD dataset, showing the plausibility of the results.","Finally, a possibility for a future validation of the presented relevance concept is outlined."],"url":"http://arxiv.org/abs/2307.10873v1"}
{"created":"2023-07-20 13:41:26","title":"Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection","abstract":"Performance issues permeate large-scale cloud service systems, which can lead to huge revenue losses. To ensure reliable performance, it's essential to accurately identify and localize these issues using service monitoring metrics. Given the complexity and scale of modern cloud systems, this task can be challenging and may require extensive expertise and resources beyond the capacity of individual humans. Some existing methods tackle this problem by analyzing each metric independently to detect anomalies. However, this could incur overwhelming alert storms that are difficult for engineers to diagnose manually. To pursue better performance, not only the temporal patterns of metrics but also the correlation between metrics (i.e., relational patterns) should be considered, which can be formulated as a multivariate metrics anomaly detection problem. However, most of the studies fall short of extracting these two types of features explicitly. Moreover, there exist some unlabeled anomalies mixed in the training data, which may hinder the detection performance. To address these limitations, we propose the Relational- Temporal Anomaly Detection Model (RTAnomaly) that combines the relational and temporal information of metrics. RTAnomaly employs a graph attention layer to learn the dependencies among metrics, which will further help pinpoint the anomalous metrics that may cause the anomaly effectively. In addition, we exploit the concept of positive unlabeled learning to address the issue of potential anomalies in the training data. To evaluate our method, we conduct experiments on a public dataset and two industrial datasets. RTAnomaly outperforms all the baseline models by achieving an average F1 score of 0.929 and Hit@3 of 0.920, demonstrating its superiority.","sentences":["Performance issues permeate large-scale cloud service systems, which can lead to huge revenue losses.","To ensure reliable performance, it's essential to accurately identify and localize these issues using service monitoring metrics.","Given the complexity and scale of modern cloud systems, this task can be challenging and may require extensive expertise and resources beyond the capacity of individual humans.","Some existing methods tackle this problem by analyzing each metric independently to detect anomalies.","However, this could incur overwhelming alert storms that are difficult for engineers to diagnose manually.","To pursue better performance, not only the temporal patterns of metrics but also the correlation between metrics (i.e., relational patterns) should be considered, which can be formulated as a multivariate metrics anomaly detection problem.","However, most of the studies fall short of extracting these two types of features explicitly.","Moreover, there exist some unlabeled anomalies mixed in the training data, which may hinder the detection performance.","To address these limitations, we propose the Relational- Temporal Anomaly Detection Model (RTAnomaly) that combines the relational and temporal information of metrics.","RTAnomaly employs a graph attention layer to learn the dependencies among metrics, which will further help pinpoint the anomalous metrics that may cause the anomaly effectively.","In addition, we exploit the concept of positive unlabeled learning to address the issue of potential anomalies in the training data.","To evaluate our method, we conduct experiments on a public dataset and two industrial datasets.","RTAnomaly outperforms all the baseline models by achieving an average F1 score of 0.929 and Hit@3 of 0.920, demonstrating its superiority."],"url":"http://arxiv.org/abs/2307.10869v1"}
{"created":"2023-07-20 13:40:22","title":"FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback","abstract":"Captions are crucial for understanding scientific visualizations and documents. Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness [15] leading to generated captions being misaligned with reader preferences. To enable the generation of high-quality figure captions, we introduce FigCaps-HF a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences. Our framework comprises of 1) an automatic method for evaluating quality of figure-caption pairs, 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences. We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of models. In particular, when using BLIP as the base model, our RLHF framework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and Meteor, respectively. Finally, we release a large-scale benchmark dataset with human feedback on figure-caption pairs to enable further evaluation and development of RLHF techniques for this problem.","sentences":["Captions are crucial for understanding scientific visualizations and documents.","Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness [15] leading to generated captions being misaligned with reader preferences.","To enable the generation of high-quality figure captions, we introduce FigCaps-HF a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences.","Our framework comprises of 1) an automatic method for evaluating quality of figure-caption pairs, 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences.","We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of models.","In particular, when using BLIP as the base model, our RLHF framework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and Meteor, respectively.","Finally, we release a large-scale benchmark dataset with human feedback on figure-caption pairs to enable further evaluation and development of RLHF techniques for this problem."],"url":"http://arxiv.org/abs/2307.10867v1"}
{"created":"2023-07-20 13:34:11","title":"Addressing caveats of neural persistence with deep graph persistence","abstract":"Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at https://github.com/ExplainableML/Deep-Graph-Persistence .","sentences":["Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning.","In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence.","Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights.","Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers.","Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix.","This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation.","Code is available at https://github.com/ExplainableML/Deep-Graph-Persistence ."],"url":"http://arxiv.org/abs/2307.10865v1"}
{"created":"2023-07-20 13:33:28","title":"Divide & Bind Your Attention for Improved Generative Semantic Nursing","abstract":"Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity. Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt. Prior work, Attend & Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics. It demonstrates promising results in generating simple prompts, e.g., ``a cat and a dog''. However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding. To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide & Bind. We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss. Our approach stands out in its ability to faithfully synthesize desired objects with improved attribute alignment from complex prompts and exhibits superior performance across multiple evaluation benchmarks. More videos and updates can be found on the project page \\url{https://sites.google.com/view/divide-and-bind}.","sentences":["Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity.","Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt.","Prior work, Attend & Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics.","It demonstrates promising results in generating simple prompts, e.g., ``a cat and a dog''.","However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding.","To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide & Bind.","We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss.","Our approach stands out in its ability to faithfully synthesize desired objects with improved attribute alignment from complex prompts and exhibits superior performance across multiple evaluation benchmarks.","More videos and updates can be found on the project page \\url{https://sites.google.com/view/divide-and-bind}."],"url":"http://arxiv.org/abs/2307.10864v1"}
{"created":"2023-07-20 13:17:30","title":"BlendFace: Re-designing Identity Encoders for Face-Swapping","abstract":"The great advancements of generative adversarial networks and face recognition models in computer vision have made it possible to swap identities on images from single sources. Although a lot of studies seems to have proposed almost satisfactory solutions, we notice previous methods still suffer from an identity-attribute entanglement that causes undesired attributes swapping because widely used identity encoders, eg, ArcFace, have some crucial attribute biases owing to their pretraining on face recognition tasks. To address this issue, we design BlendFace, a novel identity encoder for face-swapping. The key idea behind BlendFace is training face recognition models on blended images whose attributes are replaced with those of another mitigates inter-personal biases such as hairsyles. BlendFace feeds disentangled identity features into generators and guides generators properly as an identity loss function. Extensive experiments demonstrate that BlendFace improves the identity-attribute disentanglement in face-swapping models, maintaining a comparable quantitative performance to previous methods.","sentences":["The great advancements of generative adversarial networks and face recognition models in computer vision have made it possible to swap identities on images from single sources.","Although a lot of studies seems to have proposed almost satisfactory solutions, we notice previous methods still suffer from an identity-attribute entanglement that causes undesired attributes swapping because widely used identity encoders, eg, ArcFace, have some crucial attribute biases owing to their pretraining on face recognition tasks.","To address this issue, we design BlendFace, a novel identity encoder for face-swapping.","The key idea behind BlendFace is training face recognition models on blended images whose attributes are replaced with those of another mitigates inter-personal biases such as hairsyles.","BlendFace feeds disentangled identity features into generators and guides generators properly as an identity loss function.","Extensive experiments demonstrate that BlendFace improves the identity-attribute disentanglement in face-swapping models, maintaining a comparable quantitative performance to previous methods."],"url":"http://arxiv.org/abs/2307.10854v1"}
{"created":"2023-07-20 13:16:10","title":"Exploring Effective Priors and Efficient Models for Weakly-Supervised Change Detection","abstract":"Weakly-supervised change detection (WSCD) aims to detect pixel-level changes with only image-level annotations. Owing to its label efficiency, WSCD is drawing increasing attention recently. However, current WSCD methods often encounter the challenge of change missing and fabricating, i.e., the inconsistency between image-level annotations and pixel-level predictions. Specifically, change missing refer to the situation that the WSCD model fails to predict any changed pixels, even though the image-level label indicates changed, and vice versa for change fabricating. To address this challenge, in this work, we leverage global-scale and local-scale priors in WSCD and propose two components: a Dilated Prior (DP) decoder and a Label Gated (LG) constraint. The DP decoder decodes samples with the changed image-level label, skips samples with the unchanged label, and replaces them with an all-unchanged pixel-level label. The LG constraint is derived from the correspondence between changed representations and image-level labels, penalizing the model when it mispredicts the change status. Additionally, we develop TransWCD, a simple yet powerful transformer-based model, showcasing the potential of weakly-supervised learning in change detection. By integrating the DP decoder and LG constraint into TransWCD, we form TransWCD-DL. Our proposed TransWCD and TransWCD-DL achieve significant +6.33% and +9.55% F1 score improvements over the state-of-the-art methods on the WHU-CD dataset, respectively. Some performance metrics even exceed several fully-supervised change detection (FSCD) competitors. Code will be available at https://github.com/zhenghuizhao/TransWCD.","sentences":["Weakly-supervised change detection (WSCD) aims to detect pixel-level changes with only image-level annotations.","Owing to its label efficiency, WSCD is drawing increasing attention recently.","However, current WSCD methods often encounter the challenge of change missing and fabricating, i.e., the inconsistency between image-level annotations and pixel-level predictions.","Specifically, change missing refer to the situation that the WSCD model fails to predict any changed pixels, even though the image-level label indicates changed, and vice versa for change fabricating.","To address this challenge, in this work, we leverage global-scale and local-scale priors in WSCD and propose two components: a Dilated Prior (DP) decoder and a Label Gated (LG) constraint.","The DP decoder decodes samples with the changed image-level label, skips samples with the unchanged label, and replaces them with an all-unchanged pixel-level label.","The LG constraint is derived from the correspondence between changed representations and image-level labels, penalizing the model when it mispredicts the change status.","Additionally, we develop TransWCD, a simple yet powerful transformer-based model, showcasing the potential of weakly-supervised learning in change detection.","By integrating the DP decoder and LG constraint into TransWCD, we form TransWCD-DL.","Our proposed TransWCD and TransWCD-DL achieve significant +6.33% and +9.55% F1 score improvements over the state-of-the-art methods on the WHU-CD dataset, respectively.","Some performance metrics even exceed several fully-supervised change detection (FSCD) competitors.","Code will be available at https://github.com/zhenghuizhao/TransWCD."],"url":"http://arxiv.org/abs/2307.10853v1"}
{"created":"2023-07-20 13:11:01","title":"Shortest Dominating Set Reconfiguration under Token Sliding","abstract":"In this paper, we present novel algorithms that efficiently compute a shortest reconfiguration sequence between two given dominating sets in trees and interval graphs under the Token Sliding model. In this problem, a graph is provided along with its two dominating sets, which can be imagined as tokens placed on vertices. The objective is to find a shortest sequence of dominating sets that transforms one set into the other, with each set in the sequence resulting from sliding a single token in the previous set. While identifying any sequence has been well studied, our work presents the first polynomial algorithms for this optimization variant in the context of dominating sets.","sentences":["In this paper, we present novel algorithms that efficiently compute a shortest reconfiguration sequence between two given dominating sets in trees and interval graphs under the Token Sliding model.","In this problem, a graph is provided along with its two dominating sets, which can be imagined as tokens placed on vertices.","The objective is to find a shortest sequence of dominating sets that transforms one set into the other, with each set in the sequence resulting from sliding a single token in the previous set.","While identifying any sequence has been well studied, our work presents the first polynomial algorithms for this optimization variant in the context of dominating sets."],"url":"http://arxiv.org/abs/2307.10847v1"}
{"created":"2023-07-20 13:08:14","title":"Goal-Conditioned Reinforcement Learning with Disentanglement-based Reachability Planning","abstract":"Goal-Conditioned Reinforcement Learning (GCRL) can enable agents to spontaneously set diverse goals to learn a set of skills. Despite the excellent works proposed in various fields, reaching distant goals in temporally extended tasks remains a challenge for GCRL. Current works tackled this problem by leveraging planning algorithms to plan intermediate subgoals to augment GCRL. Their methods need two crucial requirements: (i) a state representation space to search valid subgoals, and (ii) a distance function to measure the reachability of subgoals. However, they struggle to scale to high-dimensional state space due to their non-compact representations. Moreover, they cannot collect high-quality training data through standard GC policies, which results in an inaccurate distance function. Both affect the efficiency and performance of planning and policy learning. In the paper, we propose a goal-conditioned RL algorithm combined with Disentanglement-based Reachability Planning (REPlan) to solve temporally extended tasks. In REPlan, a Disentangled Representation Module (DRM) is proposed to learn compact representations which disentangle robot poses and object positions from high-dimensional observations in a self-supervised manner. A simple REachability discrimination Module (REM) is also designed to determine the temporal distance of subgoals. Moreover, REM computes intrinsic bonuses to encourage the collection of novel states for training. We evaluate our REPlan in three vision-based simulation tasks and one real-world task. The experiments demonstrate that our REPlan significantly outperforms the prior state-of-the-art methods in solving temporally extended tasks.","sentences":["Goal-Conditioned Reinforcement Learning (GCRL) can enable agents to spontaneously set diverse goals to learn a set of skills.","Despite the excellent works proposed in various fields, reaching distant goals in temporally extended tasks remains a challenge for GCRL.","Current works tackled this problem by leveraging planning algorithms to plan intermediate subgoals to augment GCRL.","Their methods need two crucial requirements: (i) a state representation space to search valid subgoals, and (ii) a distance function to measure the reachability of subgoals.","However, they struggle to scale to high-dimensional state space due to their non-compact representations.","Moreover, they cannot collect high-quality training data through standard GC policies, which results in an inaccurate distance function.","Both affect the efficiency and performance of planning and policy learning.","In the paper, we propose a goal-conditioned RL algorithm combined with Disentanglement-based Reachability Planning (REPlan) to solve temporally extended tasks.","In REPlan, a Disentangled Representation Module (DRM) is proposed to learn compact representations which disentangle robot poses and object positions from high-dimensional observations in a self-supervised manner.","A simple REachability discrimination Module (REM) is also designed to determine the temporal distance of subgoals.","Moreover, REM computes intrinsic bonuses to encourage the collection of novel states for training.","We evaluate our REPlan in three vision-based simulation tasks and one real-world task.","The experiments demonstrate that our REPlan significantly outperforms the prior state-of-the-art methods in solving temporally extended tasks."],"url":"http://arxiv.org/abs/2307.10846v1"}
{"created":"2023-07-20 13:07:41","title":"Self-paced Weight Consolidation for Continual Learning","abstract":"Continual learning algorithms which keep the parameters of new tasks close to that of previous tasks, are popular in preventing catastrophic forgetting in sequential task learning settings. However, 1) the performance for the new continual learner will be degraded without distinguishing the contributions of previously learned tasks; 2) the computational cost will be greatly increased with the number of tasks, since most existing algorithms need to regularize all previous tasks when learning new tasks. To address the above challenges, we propose a self-paced Weight Consolidation (spWC) framework to attain robust continual learning via evaluating the discriminative contributions of previous tasks. To be specific, we develop a self-paced regularization to reflect the priorities of past tasks via measuring difficulty based on key performance indicator (i.e., accuracy). When encountering a new task, all previous tasks are sorted from \"difficult\" to \"easy\" based on the priorities. Then the parameters of the new continual learner will be learned via selectively maintaining the knowledge amongst more difficult past tasks, which could well overcome catastrophic forgetting with less computational cost. We adopt an alternative convex search to iteratively update the model parameters and priority weights in the bi-convex formulation. The proposed spWC framework is plug-and-play, which is applicable to most continual learning algorithms (e.g., EWC, MAS and RCIL) in different directions (e.g., classification and segmentation). Experimental results on several public benchmark datasets demonstrate that our proposed framework can effectively improve performance when compared with other popular continual learning algorithms.","sentences":["Continual learning algorithms which keep the parameters of new tasks close to that of previous tasks, are popular in preventing catastrophic forgetting in sequential task learning settings.","However, 1) the performance for the new continual learner will be degraded without distinguishing the contributions of previously learned tasks; 2) the computational cost will be greatly increased with the number of tasks, since most existing algorithms need to regularize all previous tasks when learning new tasks.","To address the above challenges, we propose a self-paced Weight Consolidation (spWC) framework to attain robust continual learning via evaluating the discriminative contributions of previous tasks.","To be specific, we develop a self-paced regularization to reflect the priorities of past tasks via measuring difficulty based on key performance indicator (i.e., accuracy).","When encountering a new task, all previous tasks are sorted from \"difficult\" to \"easy\" based on the priorities.","Then the parameters of the new continual learner will be learned via selectively maintaining the knowledge amongst more difficult past tasks, which could well overcome catastrophic forgetting with less computational cost.","We adopt an alternative convex search to iteratively update the model parameters and priority weights in the bi-convex formulation.","The proposed spWC framework is plug-and-play, which is applicable to most continual learning algorithms (e.g., EWC, MAS and RCIL) in different directions (e.g., classification and segmentation).","Experimental results on several public benchmark datasets demonstrate that our proposed framework can effectively improve performance when compared with other popular continual learning algorithms."],"url":"http://arxiv.org/abs/2307.10845v1"}
{"created":"2023-07-20 13:04:26","title":"Global Precipitation Nowcasting of Integrated Multi-satellitE Retrievals for GPM: A U-Net Convolutional LSTM Architecture","abstract":"This paper presents a deep learning architecture for nowcasting of precipitation almost globally every 30 min with a 4-hour lead time. The architecture fuses a U-Net and a convolutional long short-term memory (LSTM) neural network and is trained using data from the Integrated MultisatellitE Retrievals for GPM (IMERG) and a few key precipitation drivers from the Global Forecast System (GFS). The impacts of different training loss functions, including the mean-squared error (regression) and the focal-loss (classification), on the quality of precipitation nowcasts are studied. The results indicate that the regression network performs well in capturing light precipitation (below 1.6 mm/hr), but the classification network can outperform the regression network for nowcasting of precipitation extremes (>8 mm/hr), in terms of the critical success index (CSI).. Using the Wasserstein distance, it is shown that the predicted precipitation by the classification network has a closer class probability distribution to the IMERG than the regression network. It is uncovered that the inclusion of the physical variables can improve precipitation nowcasting, especially at longer lead times in both networks. Taking IMERG as a relative reference, a multi-scale analysis in terms of fractions skill score (FSS), shows that the nowcasting machine remains skillful (FSS > 0.5) at the resolution of 10 km compared to 50 km for GFS. For precipitation rates greater than 4~mm/hr, only the classification network remains FSS-skillful on scales greater than 50 km within a 2-hour lead time.","sentences":["This paper presents a deep learning architecture for nowcasting of precipitation almost globally every 30 min with a 4-hour lead time.","The architecture fuses a U-Net and a convolutional long short-term memory (LSTM) neural network and is trained using data from the Integrated MultisatellitE Retrievals for GPM (IMERG) and a few key precipitation drivers from the Global Forecast System (GFS).","The impacts of different training loss functions, including the mean-squared error (regression) and the focal-loss (classification), on the quality of precipitation nowcasts are studied.","The results indicate that the regression network performs well in capturing light precipitation (below 1.6 mm/hr), but the classification network can outperform the regression network for nowcasting of precipitation extremes (>8 mm/hr), in terms of the critical success index (CSI)..","Using the Wasserstein distance, it is shown that the predicted precipitation by the classification network has a closer class probability distribution to the IMERG than the regression network.","It is uncovered that the inclusion of the physical variables can improve precipitation nowcasting, especially at longer lead times in both networks.","Taking IMERG as a relative reference, a multi-scale analysis in terms of fractions skill score (FSS), shows that the nowcasting machine remains skillful (FSS > 0.5) at the resolution of 10 km compared to 50 km for GFS.","For precipitation rates greater than 4~mm/hr, only the classification network remains FSS-skillful on scales greater than 50 km within a 2-hour lead time."],"url":"http://arxiv.org/abs/2307.10843v1"}
{"created":"2023-07-20 13:02:45","title":"Label Calibration for Semantic Segmentation Under Domain Shift","abstract":"Performance of a pre-trained semantic segmentation model is likely to substantially decrease on data from a new domain. We show a pre-trained model can be adapted to unlabelled target domain data by calculating soft-label prototypes under the domain shift and making predictions according to the prototype closest to the vector with predicted class probabilities. The proposed adaptation procedure is fast, comes almost for free in terms of computational resources and leads to considerable performance improvements. We demonstrate the benefits of such label calibration on the highly-practical synthetic-to-real semantic segmentation problem.","sentences":["Performance of a pre-trained semantic segmentation model is likely to substantially decrease on data from a new domain.","We show a pre-trained model can be adapted to unlabelled target domain data by calculating soft-label prototypes under the domain shift and making predictions according to the prototype closest to the vector with predicted class probabilities.","The proposed adaptation procedure is fast, comes almost for free in terms of computational resources and leads to considerable performance improvements.","We demonstrate the benefits of such label calibration on the highly-practical synthetic-to-real semantic segmentation problem."],"url":"http://arxiv.org/abs/2307.10842v1"}
{"created":"2023-07-20 12:59:41","title":"A Hybrid Adaptive Controller for Soft Robot Interchangeability","abstract":"Soft robots have been leveraged in considerable areas like surgery, rehabilitation, and bionics due to their softness, flexibility, and safety. However, it is challenging to produce two same soft robots even with the same mold and manufacturing process owing to the complexity of soft materials. Meanwhile, widespread usage of a system requires the ability to fabricate replaceable components, which is interchangeability. Due to the necessity of this property, a hybrid adaptive controller is introduced to achieve interchangeability from the perspective of control approaches. This method utilizes an offline trained recurrent neural network controller to cope with the nonlinear and delayed response from soft robots. Furthermore, an online optimizing kinematics controller is applied to decrease the error caused by the above neural network controller. Soft pneumatic robots with different deformation properties but the same mold have been included for validation experiments. In the experiments, the systems with different actuation configurations and the different robots follow the desired trajectory with errors of 0.040 and 0.030 compared with the working space length, respectively. Such an adaptive controller also shows good performance on different control frequencies and desired velocities. This controller endows soft robots with the potential for wide application, and future work may include different offline and online controllers. A weight parameter adjusting strategy may also be proposed in the future.","sentences":["Soft robots have been leveraged in considerable areas like surgery, rehabilitation, and bionics due to their softness, flexibility, and safety.","However, it is challenging to produce two same soft robots even with the same mold and manufacturing process owing to the complexity of soft materials.","Meanwhile, widespread usage of a system requires the ability to fabricate replaceable components, which is interchangeability.","Due to the necessity of this property, a hybrid adaptive controller is introduced to achieve interchangeability from the perspective of control approaches.","This method utilizes an offline trained recurrent neural network controller to cope with the nonlinear and delayed response from soft robots.","Furthermore, an online optimizing kinematics controller is applied to decrease the error caused by the above neural network controller.","Soft pneumatic robots with different deformation properties but the same mold have been included for validation experiments.","In the experiments, the systems with different actuation configurations and the different robots follow the desired trajectory with errors of 0.040 and 0.030 compared with the working space length, respectively.","Such an adaptive controller also shows good performance on different control frequencies and desired velocities.","This controller endows soft robots with the potential for wide application, and future work may include different offline and online controllers.","A weight parameter adjusting strategy may also be proposed in the future."],"url":"http://arxiv.org/abs/2307.10838v1"}
{"created":"2023-07-20 12:57:15","title":"Sensing User's Activity, Channel, and Location with Near-Field Extra-Large-Scale MIMO","abstract":"This paper proposes a grant-free massive access scheme based on the millimeter wave (mmWave) extra-large-scale multiple-input multiple-output (XL-MIMO) to support massive Internet-of-Things (IoT) devices with low latency, high data rate, and high localization accuracy in the upcoming sixth-generation (6G) networks. The XL-MIMO consists of multiple antenna subarrays that are widely spaced over the service area to ensure line-of-sight (LoS) transmissions. First, we establish the XL-MIMO-based massive access model considering the near-field spatial non-stationary (SNS) property. Then, by exploiting the block sparsity of subarrays and the SNS property, we propose a structured block orthogonal matching pursuit algorithm for efficient active user detection (AUD) and channel estimation (CE). Furthermore, different sensing matrices are applied in different pilot subcarriers for exploiting the diversity gains. Additionally, a multi-subarray collaborative localization algorithm is designed for localization. In particular, the angle of arrival (AoA) and time difference of arrival (TDoA) of the LoS links between active users and related subarrays are extracted from the estimated XL-MIMO channels, and then the coordinates of active users are acquired by jointly utilizing the AoAs and TDoAs. Simulation results show that the proposed algorithms outperform existing algorithms in terms of AUD and CE performance and can achieve centimeter-level localization accuracy.","sentences":["This paper proposes a grant-free massive access scheme based on the millimeter wave (mmWave) extra-large-scale multiple-input multiple-output (XL-MIMO) to support massive Internet-of-Things (IoT) devices with low latency, high data rate, and high localization accuracy in the upcoming sixth-generation (6G) networks.","The XL-MIMO consists of multiple antenna subarrays that are widely spaced over the service area to ensure line-of-sight (LoS) transmissions.","First, we establish the XL-MIMO-based massive access model considering the near-field spatial non-stationary (SNS) property.","Then, by exploiting the block sparsity of subarrays and the SNS property, we propose a structured block orthogonal matching pursuit algorithm for efficient active user detection (AUD) and channel estimation (CE).","Furthermore, different sensing matrices are applied in different pilot subcarriers for exploiting the diversity gains.","Additionally, a multi-subarray collaborative localization algorithm is designed for localization.","In particular, the angle of arrival (AoA) and time difference of arrival (TDoA) of the LoS links between active users and related subarrays are extracted from the estimated XL-MIMO channels, and then the coordinates of active users are acquired by jointly utilizing the AoAs and TDoAs.","Simulation results show that the proposed algorithms outperform existing algorithms in terms of AUD and CE performance and can achieve centimeter-level localization accuracy."],"url":"http://arxiv.org/abs/2307.10837v1"}
{"created":"2023-07-20 12:52:30","title":"Modifications of the Miller definition of contrastive (counterfactual) explanations","abstract":"Miller recently proposed a definition of contrastive (counterfactual) explanations based on the well-known Halpern-Pearl (HP) definitions of causes and (non-contrastive) explanations. Crucially, the Miller definition was based on the original HP definition of explanations, but this has since been modified by Halpern; presumably because the original yields counterintuitive results in many standard examples. More recently Borner has proposed a third definition, observing that this modified HP definition may also yield counterintuitive results. In this paper we show that the Miller definition inherits issues found in the original HP definition. We address these issues by proposing two improved variants based on the more robust modified HP and Borner definitions. We analyse our new definitions and show that they retain the spirit of the Miller definition where all three variants satisfy an alternative unified definition that is modular with respect to an underlying definition of non-contrastive explanations. To the best of our knowledge this paper also provides the first explicit comparison between the original and modified HP definitions.","sentences":["Miller recently proposed a definition of contrastive (counterfactual) explanations based on the well-known Halpern-Pearl (HP) definitions of causes and (non-contrastive) explanations.","Crucially, the Miller definition was based on the original HP definition of explanations, but this has since been modified by Halpern; presumably because the original yields counterintuitive results in many standard examples.","More recently Borner has proposed a third definition, observing that this modified HP definition may also yield counterintuitive results.","In this paper we show that the Miller definition inherits issues found in the original HP definition.","We address these issues by proposing two improved variants based on the more robust modified HP and Borner definitions.","We analyse our new definitions and show that they retain the spirit of the Miller definition where all three variants satisfy an alternative unified definition that is modular with respect to an underlying definition of non-contrastive explanations.","To the best of our knowledge this paper also provides the first explicit comparison between the original and modified HP definitions."],"url":"http://arxiv.org/abs/2307.10832v1"}
{"created":"2023-07-20 12:41:35","title":"Yelp Reviews and Food Types: A Comparative Analysis of Ratings, Sentiments, and Topics","abstract":"This study examines the relationship between Yelp reviews and food types, investigating how ratings, sentiments, and topics vary across different types of food. Specifically, we analyze how ratings and sentiments of reviews vary across food types, cluster food types based on ratings and sentiments, infer review topics using machine learning models, and compare topic distributions among different food types. Our analyses reveal that some food types have similar ratings, sentiments, and topics distributions, while others have distinct patterns. We identify four clusters of food types based on ratings and sentiments and find that reviewers tend to focus on different topics when reviewing certain food types. These findings have important implications for understanding user behavior and cultural influence on digital media platforms and promoting cross-cultural understanding and appreciation.","sentences":["This study examines the relationship between Yelp reviews and food types, investigating how ratings, sentiments, and topics vary across different types of food.","Specifically, we analyze how ratings and sentiments of reviews vary across food types, cluster food types based on ratings and sentiments, infer review topics using machine learning models, and compare topic distributions among different food types.","Our analyses reveal that some food types have similar ratings, sentiments, and topics distributions, while others have distinct patterns.","We identify four clusters of food types based on ratings and sentiments and find that reviewers tend to focus on different topics when reviewing certain food types.","These findings have important implications for understanding user behavior and cultural influence on digital media platforms and promoting cross-cultural understanding and appreciation."],"url":"http://arxiv.org/abs/2307.10826v1"}
{"created":"2023-07-20 12:32:25","title":"Gradient-Semantic Compensation for Incremental Semantic Segmentation","abstract":"Incremental semantic segmentation aims to continually learn the segmentation of new coming classes without accessing the training data of previously learned classes. However, most current methods fail to address catastrophic forgetting and background shift since they 1) treat all previous classes equally without considering different forgetting paces caused by imbalanced gradient back-propagation; 2) lack strong semantic guidance between classes. To tackle the above challenges, in this paper, we propose a Gradient-Semantic Compensation (GSC) model, which surmounts incremental semantic segmentation from both gradient and semantic perspectives. Specifically, to address catastrophic forgetting from the gradient aspect, we develop a step-aware gradient compensation that can balance forgetting paces of previously seen classes via re-weighting gradient backpropagation. Meanwhile, we propose a soft-sharp semantic relation distillation to distill consistent inter-class semantic relations via soft labels for alleviating catastrophic forgetting from the semantic aspect. In addition, we develop a prototypical pseudo re-labeling that provides strong semantic guidance to mitigate background shift. It produces high-quality pseudo labels for old classes in the background by measuring distances between pixels and class-wise prototypes. Extensive experiments on three public datasets, i.e., Pascal VOC 2012, ADE20K, and Cityscapes, demonstrate the effectiveness of our proposed GSC model.","sentences":["Incremental semantic segmentation aims to continually learn the segmentation of new coming classes without accessing the training data of previously learned classes.","However, most current methods fail to address catastrophic forgetting and background shift since they 1) treat all previous classes equally without considering different forgetting paces caused by imbalanced gradient back-propagation; 2) lack strong semantic guidance between classes.","To tackle the above challenges, in this paper, we propose a Gradient-Semantic Compensation (GSC) model, which surmounts incremental semantic segmentation from both gradient and semantic perspectives.","Specifically, to address catastrophic forgetting from the gradient aspect, we develop a step-aware gradient compensation that can balance forgetting paces of previously seen classes via re-weighting gradient backpropagation.","Meanwhile, we propose a soft-sharp semantic relation distillation to distill consistent inter-class semantic relations via soft labels for alleviating catastrophic forgetting from the semantic aspect.","In addition, we develop a prototypical pseudo re-labeling that provides strong semantic guidance to mitigate background shift.","It produces high-quality pseudo labels for old classes in the background by measuring distances between pixels and class-wise prototypes.","Extensive experiments on three public datasets, i.e., Pascal VOC 2012, ADE20K, and Cityscapes, demonstrate the effectiveness of our proposed GSC model."],"url":"http://arxiv.org/abs/2307.10822v1"}
{"created":"2023-07-20 12:26:50","title":"PHYFU: Fuzzing Modern Physics Simulation Engines","abstract":"A physical simulation engine (PSE) is a software system that simulates physical environments and objects. Modern PSEs feature both forward and backward simulations, where the forward phase predicts the behavior of a simulated system, and the backward phase provides gradients (guidance) for learning-based control tasks, such as a robot arm learning to fetch items. This way, modern PSEs show promising support for learning-based control methods. To date, PSEs have been largely used in various high-profitable, commercial applications, such as games, movies, virtual reality (VR), and robotics. Despite the prosperous development and usage of PSEs by academia and industrial manufacturers such as Google and NVIDIA, PSEs may produce incorrect simulations, which may lead to negative results, from poor user experience in entertainment to accidents in robotics-involved manufacturing and surgical operations.   This paper introduces PHYFU, a fuzzing framework designed specifically for PSEs to uncover errors in both forward and backward simulation phases. PHYFU mutates initial states and asserts if the PSE under test behaves consistently with respect to basic Physics Laws (PLs). We further use feedback-driven test input scheduling to guide and accelerate the search for errors. Our study of four PSEs covers mainstream industrial vendors (Google and NVIDIA) as well as academic products. We successfully uncover over 5K error-triggering inputs that generate incorrect simulation results spanning across the whole software stack of PSEs.","sentences":["A physical simulation engine (PSE) is a software system that simulates physical environments and objects.","Modern PSEs feature both forward and backward simulations, where the forward phase predicts the behavior of a simulated system, and the backward phase provides gradients (guidance) for learning-based control tasks, such as a robot arm learning to fetch items.","This way, modern PSEs show promising support for learning-based control methods.","To date, PSEs have been largely used in various high-profitable, commercial applications, such as games, movies, virtual reality (VR), and robotics.","Despite the prosperous development and usage of PSEs by academia and industrial manufacturers such as Google and NVIDIA, PSEs may produce incorrect simulations, which may lead to negative results, from poor user experience in entertainment to accidents in robotics-involved manufacturing and surgical operations.   ","This paper introduces PHYFU, a fuzzing framework designed specifically for PSEs to uncover errors in both forward and backward simulation phases.","PHYFU mutates initial states and asserts if the PSE under test behaves consistently with respect to basic Physics Laws (PLs).","We further use feedback-driven test input scheduling to guide and accelerate the search for errors.","Our study of four PSEs covers mainstream industrial vendors (Google and NVIDIA) as well as academic products.","We successfully uncover over 5K error-triggering inputs that generate incorrect simulation results spanning across the whole software stack of PSEs."],"url":"http://arxiv.org/abs/2307.10818v1"}
{"created":"2023-07-20 12:25:06","title":"BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion","abstract":"Recent text-to-image diffusion models have demonstrated an astonishing capacity to generate high-quality images. However, researchers mainly studied the way of synthesizing images with only text prompts. While some works have explored using other modalities as conditions, considerable paired data, e.g., box/mask-image pairs, and fine-tuning time are required for nurturing models. As such paired data is time-consuming and labor-intensive to acquire and restricted to a closed set, this potentially becomes the bottleneck for applications in an open world. This paper focuses on the simplest form of user-provided conditions, e.g., box or scribble. To mitigate the aforementioned problem, we propose a training-free method to control objects and contexts in the synthesized images adhering to the given spatial conditions. Specifically, three spatial constraints, i.e., Inner-Box, Outer-Box, and Corner Constraints, are designed and seamlessly integrated into the denoising step of diffusion models, requiring no additional training and massive annotated layout data. Extensive results show that the proposed constraints can control what and where to present in the images while retaining the ability of the Stable Diffusion model to synthesize with high fidelity and diverse concept coverage. The code is publicly available at https://github.com/Sierkinhane/BoxDiff.","sentences":["Recent text-to-image diffusion models have demonstrated an astonishing capacity to generate high-quality images.","However, researchers mainly studied the way of synthesizing images with only text prompts.","While some works have explored using other modalities as conditions, considerable paired data, e.g., box/mask-image pairs, and fine-tuning time are required for nurturing models.","As such paired data is time-consuming and labor-intensive to acquire and restricted to a closed set, this potentially becomes the bottleneck for applications in an open world.","This paper focuses on the simplest form of user-provided conditions, e.g., box or scribble.","To mitigate the aforementioned problem, we propose a training-free method to control objects and contexts in the synthesized images adhering to the given spatial conditions.","Specifically, three spatial constraints, i.e., Inner-Box, Outer-Box, and Corner Constraints, are designed and seamlessly integrated into the denoising step of diffusion models, requiring no additional training and massive annotated layout data.","Extensive results show that the proposed constraints can control what and where to present in the images while retaining the ability of the Stable Diffusion model to synthesize with high fidelity and diverse concept coverage.","The code is publicly available at https://github.com/Sierkinhane/BoxDiff."],"url":"http://arxiv.org/abs/2307.10816v1"}
{"created":"2023-07-20 12:24:23","title":"Cross-Corpus Multilingual Speech Emotion Recognition: Amharic vs. Other Languages","abstract":"In a conventional Speech emotion recognition (SER) task, a classifier for a given language is trained on a pre-existing dataset for that same language. However, where training data for a language does not exist, data from other languages can be used instead. We experiment with cross-lingual and multilingual SER, working with Amharic, English, German and URDU. For Amharic, we use our own publicly-available Amharic Speech Emotion Dataset (ASED). For English, German and Urdu we use the existing RAVDESS, EMO-DB and URDU datasets. We followed previous research in mapping labels for all datasets to just two classes, positive and negative. Thus we can compare performance on different languages directly, and combine languages for training and testing. In Experiment 1, monolingual SER trials were carried out using three classifiers, AlexNet, VGGE (a proposed variant of VGG), and ResNet50. Results averaged for the three models were very similar for ASED and RAVDESS, suggesting that Amharic and English SER are equally difficult. Similarly, German SER is more difficult, and Urdu SER is easier. In Experiment 2, we trained on one language and tested on another, in both directions for each pair: Amharic<->German, Amharic<->English, and Amharic<->Urdu. Results with Amharic as target suggested that using English or German as source will give the best result. In Experiment 3, we trained on several non-Amharic languages and then tested on Amharic. The best accuracy obtained was several percent greater than the best accuracy in Experiment 2, suggesting that a better result can be obtained when using two or three non-Amharic languages for training than when using just one non-Amharic language. Overall, the results suggest that cross-lingual and multilingual training can be an effective strategy for training a SER classifier when resources for a language are scarce.","sentences":["In a conventional Speech emotion recognition (SER) task, a classifier for a given language is trained on a pre-existing dataset for that same language.","However, where training data for a language does not exist, data from other languages can be used instead.","We experiment with cross-lingual and multilingual SER, working with Amharic, English, German and URDU.","For Amharic, we use our own publicly-available Amharic Speech Emotion Dataset (ASED).","For English, German and Urdu we use the existing RAVDESS, EMO-DB and URDU datasets.","We followed previous research in mapping labels for all datasets to just two classes, positive and negative.","Thus we can compare performance on different languages directly, and combine languages for training and testing.","In Experiment 1, monolingual SER trials were carried out using three classifiers, AlexNet, VGGE (a proposed variant of VGG), and ResNet50.","Results averaged for the three models were very similar for ASED and RAVDESS, suggesting that Amharic and English SER are equally difficult.","Similarly, German SER is more difficult, and Urdu SER is easier.","In Experiment 2, we trained on one language and tested on another, in both directions for each pair:","Amharic<->German, Amharic<->English, and Amharic<->Urdu.","Results with Amharic as target suggested that using English or German as source will give the best result.","In Experiment 3, we trained on several non-Amharic languages and then tested on Amharic.","The best accuracy obtained was several percent greater than the best accuracy in Experiment 2, suggesting that a better result can be obtained when using two or three non-Amharic languages for training than when using just one non-Amharic language.","Overall, the results suggest that cross-lingual and multilingual training can be an effective strategy for training a SER classifier when resources for a language are scarce."],"url":"http://arxiv.org/abs/2307.10814v1"}
{"created":"2023-07-20 12:21:26","title":"Perceptual Quality Assessment of Omnidirectional Audio-visual Signals","abstract":"Omnidirectional videos (ODVs) play an increasingly important role in the application fields of medical, education, advertising, tourism, etc. Assessing the quality of ODVs is significant for service-providers to improve the user's Quality of Experience (QoE). However, most existing quality assessment studies for ODVs only focus on the visual distortions of videos, while ignoring that the overall QoE also depends on the accompanying audio signals. In this paper, we first establish a large-scale audio-visual quality assessment dataset for omnidirectional videos, which includes 375 distorted omnidirectional audio-visual (A/V) sequences generated from 15 high-quality pristine omnidirectional A/V contents, and the corresponding perceptual audio-visual quality scores. Then, we design three baseline methods for full-reference omnidirectional audio-visual quality assessment (OAVQA), which combine existing state-of-the-art single-mode audio and video QA models via multimodal fusion strategies. We validate the effectiveness of the A/V multimodal fusion method for OAVQA on our dataset, which provides a new benchmark for omnidirectional QoE evaluation. Our dataset is available at https://github.com/iamazxl/OAVQA.","sentences":["Omnidirectional videos (ODVs) play an increasingly important role in the application fields of medical, education, advertising, tourism, etc.","Assessing the quality of ODVs is significant for service-providers to improve the user's Quality of Experience (QoE).","However, most existing quality assessment studies for ODVs only focus on the visual distortions of videos, while ignoring that the overall QoE also depends on the accompanying audio signals.","In this paper, we first establish a large-scale audio-visual quality assessment dataset for omnidirectional videos, which includes 375 distorted omnidirectional audio-visual (A/V) sequences generated from 15 high-quality pristine omnidirectional A/V contents, and the corresponding perceptual audio-visual quality scores.","Then, we design three baseline methods for full-reference omnidirectional audio-visual quality assessment (OAVQA), which combine existing state-of-the-art single-mode audio and video QA models via multimodal fusion strategies.","We validate the effectiveness of the A/V multimodal fusion method for OAVQA on our dataset, which provides a new benchmark for omnidirectional QoE evaluation.","Our dataset is available at https://github.com/iamazxl/OAVQA."],"url":"http://arxiv.org/abs/2307.10813v1"}
{"created":"2023-07-20 12:20:18","title":"On Combining Expert Demonstrations in Imitation Learning via Optimal Transport","abstract":"Imitation learning (IL) seeks to teach agents specific tasks through expert demonstrations. One of the key approaches to IL is to define a distance between agent and expert and to find an agent policy that minimizes that distance. Optimal transport methods have been widely used in imitation learning as they provide ways to measure meaningful distances between agent and expert trajectories. However, the problem of how to optimally combine multiple expert demonstrations has not been widely studied. The standard method is to simply concatenate state (-action) trajectories, which is problematic when trajectories are multi-modal. We propose an alternative method that uses a multi-marginal optimal transport distance and enables the combination of multiple and diverse state-trajectories in the OT sense, providing a more sensible geometric average of the demonstrations. Our approach enables an agent to learn from several experts, and its efficiency is analyzed on OpenAI Gym control environments and demonstrates that the standard method is not always optimal.","sentences":["Imitation learning (IL) seeks to teach agents specific tasks through expert demonstrations.","One of the key approaches to IL is to define a distance between agent and expert and to find an agent policy that minimizes that distance.","Optimal transport methods have been widely used in imitation learning as they provide ways to measure meaningful distances between agent and expert trajectories.","However, the problem of how to optimally combine multiple expert demonstrations has not been widely studied.","The standard method is to simply concatenate state (-action) trajectories, which is problematic when trajectories are multi-modal.","We propose an alternative method that uses a multi-marginal optimal transport distance and enables the combination of multiple and diverse state-trajectories in the OT sense, providing a more sensible geometric average of the demonstrations.","Our approach enables an agent to learn from several experts, and its efficiency is analyzed on OpenAI Gym control environments and demonstrates that the standard method is not always optimal."],"url":"http://arxiv.org/abs/2307.10810v1"}
{"created":"2023-07-20 12:16:26","title":"Communication-Efficient Split Learning via Adaptive Feature-Wise Compression","abstract":"This paper proposes a novel communication-efficient split learning (SL) framework, named SplitFC, which reduces the communication overhead required for transmitting intermediate feature and gradient vectors during the SL training process. The key idea of SplitFC is to leverage different dispersion degrees exhibited in the columns of the matrices. SplitFC incorporates two compression strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise quantization. In the first strategy, the intermediate feature vectors are dropped with adaptive dropout probabilities determined based on the standard deviation of these vectors. Then, by the chain rule, the intermediate gradient vectors associated with the dropped feature vectors are also dropped. In the second strategy, the non-dropped intermediate feature and gradient vectors are quantized using adaptive quantization levels determined based on the ranges of the vectors. To minimize the quantization error, the optimal quantization levels of this strategy are derived in a closed-form expression. Simulation results on the MNIST, CIFAR-10, and CelebA datasets demonstrate that SplitFC provides more than a 5.6% increase in classification accuracy compared to state-of-the-art SL frameworks, while they require 320 times less communication overhead compared to the vanilla SL framework without compression.","sentences":["This paper proposes a novel communication-efficient split learning (SL) framework, named SplitFC, which reduces the communication overhead required for transmitting intermediate feature and gradient vectors during the SL training process.","The key idea of SplitFC is to leverage different dispersion degrees exhibited in the columns of the matrices.","SplitFC incorporates two compression strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise quantization.","In the first strategy, the intermediate feature vectors are dropped with adaptive dropout probabilities determined based on the standard deviation of these vectors.","Then, by the chain rule, the intermediate gradient vectors associated with the dropped feature vectors are also dropped.","In the second strategy, the non-dropped intermediate feature and gradient vectors are quantized using adaptive quantization levels determined based on the ranges of the vectors.","To minimize the quantization error, the optimal quantization levels of this strategy are derived in a closed-form expression.","Simulation results on the MNIST, CIFAR-10, and CelebA datasets demonstrate that SplitFC provides more than a 5.6% increase in classification accuracy compared to state-of-the-art SL frameworks, while they require 320 times less communication overhead compared to the vanilla SL framework without compression."],"url":"http://arxiv.org/abs/2307.10805v1"}
{"created":"2023-07-20 12:12:05","title":"Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and Opportunities","abstract":"With the increasing amount of spatial-temporal~(ST) ocean data, numerous spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, e.g., climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data is more complicated with some unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models. Unfortunately, an overview of these studies is still missing, hindering computer scientists to identify the research issues in ocean while discouraging researchers in ocean science from applying advanced STDM techniques. To remedy this situation, we provide a comprehensive survey to summarize existing STDM studies in ocean. Concretely, we first summarize the widely-used ST ocean datasets and identify their unique characteristics. Then, typical ST ocean data quality enhancement techniques are discussed. Next, we classify existing STDM studies for ocean into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks. Finally, promising research opportunities are highlighted. This survey will help scientists from the fields of both computer science and ocean science have a better understanding of the fundamental concepts, key techniques, and open challenges of STDM in ocean.","sentences":["With the increasing amount of spatial-temporal~(ST) ocean data, numerous spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, e.g., climate forecasting and disaster warning.","Compared with typical ST data (e.g., traffic data), ST ocean data is more complicated with some unique characteristics, e.g., diverse regionality and high sparsity.","These characteristics make it difficult to design and train STDM models.","Unfortunately, an overview of these studies is still missing, hindering computer scientists to identify the research issues in ocean while discouraging researchers in ocean science from applying advanced STDM techniques.","To remedy this situation, we provide a comprehensive survey to summarize existing STDM studies in ocean.","Concretely, we first summarize the widely-used ST ocean datasets and identify their unique characteristics.","Then, typical ST ocean data quality enhancement techniques are discussed.","Next, we classify existing STDM studies for ocean into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks.","Finally, promising research opportunities are highlighted.","This survey will help scientists from the fields of both computer science and ocean science have a better understanding of the fundamental concepts, key techniques, and open challenges of STDM in ocean."],"url":"http://arxiv.org/abs/2307.10803v1"}
{"created":"2023-07-20 12:10:29","title":"Meta-Transformer: A Unified Framework for Multimodal Learning","abstract":"Multimodal learning aims to build models that can process and relate information from multiple modalities. Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities ($\\textit{e.g.}$ natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them. In this work, we propose a framework, named Meta-Transformer, that leverages a $\\textbf{frozen}$ encoder to perform multimodal perception without any paired multimodal training data. In Meta-Transformer, the raw input data from various modalities are mapped into a shared token space, allowing a subsequent encoder with frozen parameters to extract high-level semantic features of the input data. Composed of three main components: a unified data tokenizer, a modality-shared encoder, and task-specific heads for downstream tasks, Meta-Transformer is the first framework to perform unified learning across 12 modalities with unpaired data. Experiments on different benchmarks reveal that Meta-Transformer can handle a wide range of tasks including fundamental perception (text, image, point cloud, audio, video), practical application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph, tabular, and time-series). Meta-Transformer indicates a promising future for developing unified multimodal intelligence with transformers. Code will be available at https://github.com/invictus717/MetaTransformer","sentences":["Multimodal learning aims to build models that can process and relate information from multiple modalities.","Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities ($\\textit{e.g.}$ natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them.","In this work, we propose a framework, named Meta-Transformer, that leverages a $\\textbf{frozen}$ encoder to perform multimodal perception without any paired multimodal training data.","In Meta-Transformer, the raw input data from various modalities are mapped into a shared token space, allowing a subsequent encoder with frozen parameters to extract high-level semantic features of the input data.","Composed of three main components: a unified data tokenizer, a modality-shared encoder, and task-specific heads for downstream tasks, Meta-Transformer is the first framework to perform unified learning across 12 modalities with unpaired data.","Experiments on different benchmarks reveal that Meta-Transformer can handle a wide range of tasks including fundamental perception (text, image, point cloud, audio, video), practical application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph, tabular, and time-series).","Meta-Transformer indicates a promising future for developing unified multimodal intelligence with transformers.","Code will be available at https://github.com/invictus717/MetaTransformer"],"url":"http://arxiv.org/abs/2307.10802v1"}
{"created":"2023-07-20 12:01:40","title":"Layer-wise Representation Fusion for Compositional Generalization","abstract":"Despite successes across a broad range of applications, sequence-to-sequence models' construct of solutions are argued to be less compositional than human-like generalization. There is mounting evidence that one of the reasons hindering compositional generalization is representations of the encoder and decoder uppermost layer are entangled. In other words, the syntactic and semantic representations of sequences are twisted inappropriately. However, most previous studies mainly concentrate on enhancing token-level semantic information to alleviate the representations entanglement problem, rather than composing and using the syntactic and semantic representations of sequences appropriately as humans do. In addition, we explain why the entanglement problem exists from the perspective of recent studies about training deeper Transformer, mainly owing to the ``shallow'' residual connections and its simple, one-step operations, which fails to fuse previous layers' information effectively. Starting from this finding and inspired by humans' strategies, we propose \\textsc{FuSion} (\\textbf{Fu}sing \\textbf{S}yntactic and Semant\\textbf{i}c Representati\\textbf{on}s), an extension to sequence-to-sequence models to learn to fuse previous layers' information back into the encoding and decoding process appropriately through introducing a \\emph{fuse-attention module} at each encoder and decoder layer. \\textsc{FuSion} achieves competitive and even \\textbf{state-of-the-art} results on two realistic benchmarks, which empirically demonstrates the effectiveness of our proposal.","sentences":["Despite successes across a broad range of applications, sequence-to-sequence models' construct of solutions are argued to be less compositional than human-like generalization.","There is mounting evidence that one of the reasons hindering compositional generalization is representations of the encoder and decoder uppermost layer are entangled.","In other words, the syntactic and semantic representations of sequences are twisted inappropriately.","However, most previous studies mainly concentrate on enhancing token-level semantic information to alleviate the representations entanglement problem, rather than composing and using the syntactic and semantic representations of sequences appropriately as humans do.","In addition, we explain why the entanglement problem exists from the perspective of recent studies about training deeper Transformer, mainly owing to the ``shallow'' residual connections and its simple, one-step operations, which fails to fuse previous layers' information effectively.","Starting from this finding and inspired by humans' strategies, we propose \\textsc{FuSion} (\\textbf{Fu}sing \\textbf{S}yntactic and Semant\\textbf{i}c Representati\\textbf{on}s), an extension to sequence-to-sequence models to learn to fuse previous layers' information back into the encoding and decoding process appropriately through introducing a \\emph{fuse-attention module} at each encoder and decoder layer.","\\textsc{FuSion} achieves competitive and even \\textbf{state-of-the-art} results on two realistic benchmarks, which empirically demonstrates the effectiveness of our proposal."],"url":"http://arxiv.org/abs/2307.10799v1"}
{"created":"2023-07-20 11:59:42","title":"HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces","abstract":"In this paper, we present our method for neural face reenactment, called HyperReenact, that aims to generate realistic talking head images of a source identity, driven by a target facial pose. Existing state-of-the-art face reenactment methods train controllable generative models that learn to synthesize realistic facial images, yet producing reenacted faces that are prone to significant visual artifacts, especially under the challenging condition of extreme head pose changes, or requiring expensive few-shot fine-tuning to better preserve the source identity characteristics. We propose to address these limitations by leveraging the photorealistic generation ability and the disentangled properties of a pretrained StyleGAN2 generator, by first inverting the real images into its latent space and then using a hypernetwork to perform: (i) refinement of the source identity characteristics and (ii) facial pose re-targeting, eliminating this way the dependence on external editing methods that typically produce artifacts. Our method operates under the one-shot setting (i.e., using a single source frame) and allows for cross-subject reenactment, without requiring any subject-specific fine-tuning. We compare our method both quantitatively and qualitatively against several state-of-the-art techniques on the standard benchmarks of VoxCeleb1 and VoxCeleb2, demonstrating the superiority of our approach in producing artifact-free images, exhibiting remarkable robustness even under extreme head pose changes. We make the code and the pretrained models publicly available at: https://github.com/StelaBou/HyperReenact .","sentences":["In this paper, we present our method for neural face reenactment, called HyperReenact, that aims to generate realistic talking head images of a source identity, driven by a target facial pose.","Existing state-of-the-art face reenactment methods train controllable generative models that learn to synthesize realistic facial images, yet producing reenacted faces that are prone to significant visual artifacts, especially under the challenging condition of extreme head pose changes, or requiring expensive few-shot fine-tuning to better preserve the source identity characteristics.","We propose to address these limitations by leveraging the photorealistic generation ability and the disentangled properties of a pretrained StyleGAN2 generator, by first inverting the real images into its latent space and then using a hypernetwork to perform: (i) refinement of the source identity characteristics and (ii) facial pose re-targeting, eliminating this way the dependence on external editing methods that typically produce artifacts.","Our method operates under the one-shot setting (i.e., using a single source frame) and allows for cross-subject reenactment, without requiring any subject-specific fine-tuning.","We compare our method both quantitatively and qualitatively against several state-of-the-art techniques on the standard benchmarks of VoxCeleb1 and VoxCeleb2, demonstrating the superiority of our approach in producing artifact-free images, exhibiting remarkable robustness even under extreme head pose changes.","We make the code and the pretrained models publicly available at: https://github.com/StelaBou/HyperReenact ."],"url":"http://arxiv.org/abs/2307.10797v1"}
{"created":"2023-07-20 11:46:48","title":"Addressing Compiler Errors: Stack Overflow or Large Language Models?","abstract":"Compiler error messages serve as an initial resource for programmers dealing with compilation errors. However, previous studies indicate that they often lack sufficient targeted information to resolve code issues. Consequently, programmers typically rely on their own research to fix errors. Historically, Stack Overflow has been the primary resource for such information, but recent advances in large language models offer alternatives. This study systematically examines 100 compiler error messages from three sources to determine the most effective approach for programmers encountering compiler errors. Factors considered include Stack Overflow search methods and the impact of model version and prompt phrasing when using large language models. The results reveal that GPT-4 outperforms Stack Overflow in explaining compiler error messages, the effectiveness of adding code snippets to Stack Overflow searches depends on the search method, and results for Stack Overflow differ significantly between Google and StackExchange API searches. Furthermore, GPT-4 surpasses GPT-3.5, with \"How to fix\" prompts yielding superior outcomes to \"What does this error mean\" prompts. These results offer valuable guidance for programmers seeking assistance with compiler error messages, underscoring the transformative potential of advanced large language models like GPT-4 in debugging and opening new avenues of exploration for researchers in AI-assisted programming.","sentences":["Compiler error messages serve as an initial resource for programmers dealing with compilation errors.","However, previous studies indicate that they often lack sufficient targeted information to resolve code issues.","Consequently, programmers typically rely on their own research to fix errors.","Historically, Stack Overflow has been the primary resource for such information, but recent advances in large language models offer alternatives.","This study systematically examines 100 compiler error messages from three sources to determine the most effective approach for programmers encountering compiler errors.","Factors considered include Stack Overflow search methods and the impact of model version and prompt phrasing when using large language models.","The results reveal that GPT-4 outperforms Stack Overflow in explaining compiler error messages, the effectiveness of adding code snippets to Stack Overflow searches depends on the search method, and results for Stack Overflow differ significantly between Google and StackExchange API searches.","Furthermore, GPT-4 surpasses GPT-3.5, with \"How to fix\" prompts yielding superior outcomes to \"What does this error mean\" prompts.","These results offer valuable guidance for programmers seeking assistance with compiler error messages, underscoring the transformative potential of advanced large language models like GPT-4 in debugging and opening new avenues of exploration for researchers in AI-assisted programming."],"url":"http://arxiv.org/abs/2307.10793v1"}
{"created":"2023-07-20 11:45:38","title":"Optimizing PatchCore for Few/many-shot Anomaly Detection","abstract":"Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and tries to distinguish between normal and anomalous data using only few selected samples. While newly proposed few-shot AD methods do compare against pre-existing algorithms developed for the full-shot domain as baselines, they do not dedicatedly optimize them for the few-shot setting. It thus remains unclear if the performance of such pre-existing algorithms can be further improved. We address said question in this work. Specifically, we present a study on the AD/anomaly segmentation (AS) performance of PatchCore, the current state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the many-shot settings. We hypothesize that further performance improvements can be realized by (I) optimizing its various hyperparameters, and by (II) transferring techniques known to improve few-shot supervised learning to the AD domain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal that (I) significant performance improvements can be realized by optimizing hyperparameters such as the underlying feature extractor, and that (II) image-level augmentations can, but are not guaranteed, to improve performance. Based on these findings, we achieve a new state of the art in few-shot AD on VisA, further demonstrating the merit of adapting pre-existing AD/AS methods to the few-shot setting. Last, we identify the investigation of feature extractors with a strong inductive bias as a potential future research direction for (few-shot) AD/AS.","sentences":["Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and tries to distinguish between normal and anomalous data using only few selected samples.","While newly proposed few-shot AD methods do compare against pre-existing algorithms developed for the full-shot domain as baselines, they do not dedicatedly optimize them for the few-shot setting.","It thus remains unclear if the performance of such pre-existing algorithms can be further improved.","We address said question in this work.","Specifically, we present a study on the AD/anomaly segmentation (AS) performance of PatchCore, the current state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the many-shot settings.","We hypothesize that further performance improvements can be realized by (I) optimizing its various hyperparameters, and by (II) transferring techniques known to improve few-shot supervised learning to the AD domain.","Exhaustive experiments on the public VisA and MVTec AD datasets reveal that (I) significant performance improvements can be realized by optimizing hyperparameters such as the underlying feature extractor, and that (II) image-level augmentations can, but are not guaranteed, to improve performance.","Based on these findings, we achieve a new state of the art in few-shot AD on VisA, further demonstrating the merit of adapting pre-existing AD/AS methods to the few-shot setting.","Last, we identify the investigation of feature extractors with a strong inductive bias as a potential future research direction for (few-shot) AD/AS."],"url":"http://arxiv.org/abs/2307.10792v1"}
{"created":"2023-07-20 11:42:24","title":"Behavioral Analysis of Vision-and-Language Navigation Agents","abstract":"To be successful, Vision-and-Language Navigation (VLN) agents must be able to ground instructions to actions based on their surroundings. In this work, we develop a methodology to study agent behavior on a skill-specific basis -- examining how well existing agents ground instructions about stopping, turning, and moving towards specified objects or rooms. Our approach is based on generating skill-specific interventions and measuring changes in agent predictions. We present a detailed case study analyzing the behavior of a recent agent and then compare multiple agents in terms of skill-specific competency scores. This analysis suggests that biases from training have lasting effects on agent behavior and that existing models are able to ground simple referring expressions. Our comparisons between models show that skill-specific scores correlate with improvements in overall VLN task performance.","sentences":["To be successful, Vision-and-Language Navigation (VLN) agents must be able to ground instructions to actions based on their surroundings.","In this work, we develop a methodology to study agent behavior on a skill-specific basis -- examining how well existing agents ground instructions about stopping, turning, and moving towards specified objects or rooms.","Our approach is based on generating skill-specific interventions and measuring changes in agent predictions.","We present a detailed case study analyzing the behavior of a recent agent and then compare multiple agents in terms of skill-specific competency scores.","This analysis suggests that biases from training have lasting effects on agent behavior and that existing models are able to ground simple referring expressions.","Our comparisons between models show that skill-specific scores correlate with improvements in overall VLN task performance."],"url":"http://arxiv.org/abs/2307.10790v1"}
{"created":"2023-07-20 11:38:55","title":"Adversarial attacks for mixtures of classifiers","abstract":"Mixtures of classifiers (a.k.a. randomized ensembles) have been proposed as a way to improve robustness against adversarial attacks. However, it has been shown that existing attacks are not well suited for this kind of classifiers. In this paper, we discuss the problem of attacking a mixture in a principled way and introduce two desirable properties of attacks based on a geometrical analysis of the problem (effectiveness and maximality). We then show that existing attacks do not meet both of these properties. Finally, we introduce a new attack called lattice climber attack with theoretical guarantees on the binary linear setting, and we demonstrate its performance by conducting experiments on synthetic and real datasets.","sentences":["Mixtures of classifiers (a.k.a. randomized ensembles) have been proposed as a way to improve robustness against adversarial attacks.","However, it has been shown that existing attacks are not well suited for this kind of classifiers.","In this paper, we discuss the problem of attacking a mixture in a principled way and introduce two desirable properties of attacks based on a geometrical analysis of the problem (effectiveness and maximality).","We then show that existing attacks do not meet both of these properties.","Finally, we introduce a new attack called lattice climber attack with theoretical guarantees on the binary linear setting, and we demonstrate its performance by conducting experiments on synthetic and real datasets."],"url":"http://arxiv.org/abs/2307.10788v1"}
{"created":"2023-07-20 11:36:45","title":"Feed-Forward Source-Free Domain Adaptation via Class Prototypes","abstract":"Source-free domain adaptation has become popular because of its practical usefulness and no need to access source data. However, the adaptation process still takes a considerable amount of time and is predominantly based on optimization that relies on back-propagation. In this work we present a simple feed-forward approach that challenges the need for back-propagation based adaptation. Our approach is based on computing prototypes of classes under the domain shift using a pre-trained model. It achieves strong improvements in accuracy compared to the pre-trained model and requires only a small fraction of time of existing domain adaptation methods.","sentences":["Source-free domain adaptation has become popular because of its practical usefulness and no need to access source data.","However, the adaptation process still takes a considerable amount of time and is predominantly based on optimization that relies on back-propagation.","In this work we present a simple feed-forward approach that challenges the need for back-propagation based adaptation.","Our approach is based on computing prototypes of classes under the domain shift using a pre-trained model.","It achieves strong improvements in accuracy compared to the pre-trained model and requires only a small fraction of time of existing domain adaptation methods."],"url":"http://arxiv.org/abs/2307.10787v1"}
{"created":"2023-07-20 11:33:46","title":"SMURF: Spatial Multi-Representation Fusion for 3D Object Detection with 4D Imaging Radar","abstract":"The 4D Millimeter wave (mmWave) radar is a promising technology for vehicle sensing due to its cost-effectiveness and operability in adverse weather conditions. However, the adoption of this technology has been hindered by sparsity and noise issues in radar point cloud data. This paper introduces spatial multi-representation fusion (SMURF), a novel approach to 3D object detection using a single 4D imaging radar. SMURF leverages multiple representations of radar detection points, including pillarization and density features of a multi-dimensional Gaussian mixture distribution through kernel density estimation (KDE). KDE effectively mitigates measurement inaccuracy caused by limited angular resolution and multi-path propagation of radar signals. Additionally, KDE helps alleviate point cloud sparsity by capturing density features. Experimental evaluations on View-of-Delft (VoD) and TJ4DRadSet datasets demonstrate the effectiveness and generalization ability of SMURF, outperforming recently proposed 4D imaging radar-based single-representation models. Moreover, while using 4D imaging radar only, SMURF still achieves comparable performance to the state-of-the-art 4D imaging radar and camera fusion-based method, with an increase of 1.22% in the mean average precision on bird's-eye view of TJ4DRadSet dataset and 1.32% in the 3D mean average precision on the entire annotated area of VoD dataset. Our proposed method demonstrates impressive inference time and addresses the challenges of real-time detection, with the inference time no more than 0.05 seconds for most scans on both datasets. This research highlights the benefits of 4D mmWave radar and is a strong benchmark for subsequent works regarding 3D object detection with 4D imaging radar.","sentences":["The 4D Millimeter wave (mmWave) radar is a promising technology for vehicle sensing due to its cost-effectiveness and operability in adverse weather conditions.","However, the adoption of this technology has been hindered by sparsity and noise issues in radar point cloud data.","This paper introduces spatial multi-representation fusion (SMURF), a novel approach to 3D object detection using a single 4D imaging radar.","SMURF leverages multiple representations of radar detection points, including pillarization and density features of a multi-dimensional Gaussian mixture distribution through kernel density estimation (KDE).","KDE effectively mitigates measurement inaccuracy caused by limited angular resolution and multi-path propagation of radar signals.","Additionally, KDE helps alleviate point cloud sparsity by capturing density features.","Experimental evaluations on View-of-Delft (VoD) and TJ4DRadSet datasets demonstrate the effectiveness and generalization ability of SMURF, outperforming recently proposed 4D imaging radar-based single-representation models.","Moreover, while using 4D imaging radar only, SMURF still achieves comparable performance to the state-of-the-art 4D imaging radar and camera fusion-based method, with an increase of 1.22% in the mean average precision on bird's-eye view of TJ4DRadSet dataset and 1.32% in the 3D mean average precision on the entire annotated area of VoD dataset.","Our proposed method demonstrates impressive inference time and addresses the challenges of real-time detection, with the inference time no more than 0.05 seconds for most scans on both datasets.","This research highlights the benefits of 4D mmWave radar and is a strong benchmark for subsequent works regarding 3D object detection with 4D imaging radar."],"url":"http://arxiv.org/abs/2307.10784v1"}
{"created":"2023-07-20 11:32:51","title":"See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data","abstract":"Zero-shot point cloud segmentation aims to make deep models capable of recognizing novel objects in point cloud that are unseen in the training phase. Recent trends favor the pipeline which transfers knowledge from seen classes with labels to unseen classes without labels. They typically align visual features with semantic features obtained from word embedding by the supervision of seen classes' annotations. However, point cloud contains limited information to fully match with semantic features. In fact, the rich appearance information of images is a natural complement to the textureless point cloud, which is not well explored in previous literature. Motivated by this, we propose a novel multi-modal zero-shot learning method to better utilize the complementary information of point clouds and images for more accurate visual-semantic alignment. Extensive experiments are performed in two popular benchmarks, i.e., SemanticKITTI and nuScenes, and our method outperforms current SOTA methods with 52% and 49% improvement on average for unseen class mIoU, respectively.","sentences":["Zero-shot point cloud segmentation aims to make deep models capable of recognizing novel objects in point cloud that are unseen in the training phase.","Recent trends favor the pipeline which transfers knowledge from seen classes with labels to unseen classes without labels.","They typically align visual features with semantic features obtained from word embedding by the supervision of seen classes' annotations.","However, point cloud contains limited information to fully match with semantic features.","In fact, the rich appearance information of images is a natural complement to the textureless point cloud, which is not well explored in previous literature.","Motivated by this, we propose a novel multi-modal zero-shot learning method to better utilize the complementary information of point clouds and images for more accurate visual-semantic alignment.","Extensive experiments are performed in two popular benchmarks, i.e., SemanticKITTI and nuScenes, and our method outperforms current SOTA methods with 52% and 49% improvement on average for unseen class mIoU, respectively."],"url":"http://arxiv.org/abs/2307.10782v1"}
{"created":"2023-07-20 11:30:32","title":"5G Non-Public Network for Industrial IoT: Operation Models","abstract":"5G non-public networks (NPNs) play a key role in enabling critical Industrial Internet of Things (IoT) applications in various vertical industries. Among other features, 5G NPNs enable novel operation models, where the roles and responsibilities for setting up and operating the network can be distributed among several stakeholders, i.e., among the public mobile network operators (MNOs), the industrial party who uses the 5G NPN services and 3rd parties. This results in many theoretically feasible operation models for 5G NPN, each with its own advantages and disadvantages. We investigate the resulting operation models and identify a set of nine prime models taking into account today's practical considerations. Additionally, we define a framework to qualitatively analyze the operation models and use it to evaluate and compare the identified operation models.","sentences":["5G non-public networks (NPNs) play a key role in enabling critical Industrial Internet of Things (IoT) applications in various vertical industries.","Among other features, 5G NPNs enable novel operation models, where the roles and responsibilities for setting up and operating the network can be distributed among several stakeholders, i.e., among the public mobile network operators (MNOs), the industrial party who uses the 5G NPN services and 3rd parties.","This results in many theoretically feasible operation models for 5G NPN, each with its own advantages and disadvantages.","We investigate the resulting operation models and identify a set of nine prime models taking into account today's practical considerations.","Additionally, we define a framework to qualitatively analyze the operation models and use it to evaluate and compare the identified operation models."],"url":"http://arxiv.org/abs/2307.10781v1"}
{"created":"2023-07-20 11:30:12","title":"Learned Thresholds Token Merging and Pruning for Vision Transformers","abstract":"Vision transformers have demonstrated remarkable success in a wide range of computer vision tasks over the last years. However, their high computational costs remain a significant barrier to their practical deployment. In particular, the complexity of transformer models is quadratic with respect to the number of input tokens. Therefore techniques that reduce the number of input tokens that need to be processed have been proposed. This paper introduces Learned Thresholds token Merging and Pruning (LTMP), a novel approach that leverages the strengths of both token merging and token pruning. LTMP uses learned threshold masking modules that dynamically determine which tokens to merge and which to prune. We demonstrate our approach with extensive experiments on vision transformers on the ImageNet classification task. Our results demonstrate that LTMP achieves state-of-the-art accuracy across reduction rates while requiring only a single fine-tuning epoch, which is an order of magnitude faster than previous methods. Code is available at https://github.com/Mxbonn/ltmp .","sentences":["Vision transformers have demonstrated remarkable success in a wide range of computer vision tasks over the last years.","However, their high computational costs remain a significant barrier to their practical deployment.","In particular, the complexity of transformer models is quadratic with respect to the number of input tokens.","Therefore techniques that reduce the number of input tokens that need to be processed have been proposed.","This paper introduces Learned Thresholds token Merging and Pruning (LTMP), a novel approach that leverages the strengths of both token merging and token pruning.","LTMP uses learned threshold masking modules that dynamically determine which tokens to merge and which to prune.","We demonstrate our approach with extensive experiments on vision transformers on the ImageNet classification task.","Our results demonstrate that LTMP achieves state-of-the-art accuracy across reduction rates while requiring only a single fine-tuning epoch, which is an order of magnitude faster than previous methods.","Code is available at https://github.com/Mxbonn/ltmp ."],"url":"http://arxiv.org/abs/2307.10780v1"}
{"created":"2023-07-20 11:29:17","title":"Efficient Beam Tree Recursion","abstract":"Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{d}$ into a sequence contextualizer of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{n \\times d}$. Thus, our proposals not only open up a path for further scalability of RvNNs but also standardize a way to use BT-RvNNs as another building block in the deep learning toolkit that can be easily stacked or interfaced with other popular models such as Transformers and Structured State Space models.","sentences":["Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks.","However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage.","In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function.","We propose strategies to remove this bottleneck and further simplify its memory usage.","Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks.","In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{d}$ into a sequence contextualizer of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{n \\times d}$. Thus, our proposals not only open up a path for further scalability of RvNNs","but also standardize a way to use BT-RvNNs as another building block in the deep learning toolkit that can be easily stacked or interfaced with other popular models such as Transformers and Structured State Space models."],"url":"http://arxiv.org/abs/2307.10779v1"}
{"created":"2023-07-20 11:29:15","title":"Extreme Multi-Label Skill Extraction Training using Large Language Models","abstract":"Online job ads serve as a valuable source of information for skill requirements, playing a crucial role in labor market analysis and e-recruitment processes. Since such ads are typically formatted in free text, natural language processing (NLP) technologies are required to automatically process them. We specifically focus on the task of detecting skills (mentioned literally, or implicitly described) and linking them to a large skill ontology, making it a challenging case of extreme multi-label classification (XMLC). Given that there is no sizable labeled (training) dataset are available for this specific XMLC task, we propose techniques to leverage general Large Language Models (LLMs). We describe a cost-effective approach to generate an accurate, fully synthetic labeled dataset for skill extraction, and present a contrastive learning strategy that proves effective in the task. Our results across three skill extraction benchmarks show a consistent increase of between 15 to 25 percentage points in \\textit{R-Precision@5} compared to previously published results that relied solely on distant supervision through literal matches.","sentences":["Online job ads serve as a valuable source of information for skill requirements, playing a crucial role in labor market analysis and e-recruitment processes.","Since such ads are typically formatted in free text, natural language processing (NLP) technologies are required to automatically process them.","We specifically focus on the task of detecting skills (mentioned literally, or implicitly described) and linking them to a large skill ontology, making it a challenging case of extreme multi-label classification (XMLC).","Given that there is no sizable labeled (training) dataset are available for this specific XMLC task, we propose techniques to leverage general Large Language Models (LLMs).","We describe a cost-effective approach to generate an accurate, fully synthetic labeled dataset for skill extraction, and present a contrastive learning strategy that proves effective in the task.","Our results across three skill extraction benchmarks show a consistent increase of between 15 to 25 percentage points in \\textit{R-Precision@5} compared to previously published results that relied solely on distant supervision through literal matches."],"url":"http://arxiv.org/abs/2307.10778v1"}
{"created":"2023-07-20 11:24:55","title":"Urban Radiance Field Representation with Deformable Neural Mesh Primitives","abstract":"Neural Radiance Fields (NeRFs) have achieved great success in the past few years. However, most current methods still require intensive resources due to ray marching-based rendering. To construct urban-level radiance fields efficiently, we design Deformable Neural Mesh Primitive~(DNMP), and propose to parameterize the entire scene with such primitives. The DNMP is a flexible and compact neural variant of classic mesh representation, which enjoys both the efficiency of rasterization-based rendering and the powerful neural representation capability for photo-realistic image synthesis. Specifically, a DNMP consists of a set of connected deformable mesh vertices with paired vertex features to parameterize the geometry and radiance information of a local area. To constrain the degree of freedom for optimization and lower the storage budgets, we enforce the shape of each primitive to be decoded from a relatively low-dimensional latent space. The rendering colors are decoded from the vertex features (interpolated with rasterization) by a view-dependent MLP. The DNMP provides a new paradigm for urban-level scene representation with appealing properties: $(1)$ High-quality rendering. Our method achieves leading performance for novel view synthesis in urban scenarios. $(2)$ Low computational costs. Our representation enables fast rendering (2.07ms/1k pixels) and low peak memory usage (110MB/1k pixels). We also present a lightweight version that can run 33$\\times$ faster than vanilla NeRFs, and comparable to the highly-optimized Instant-NGP (0.61 vs 0.71ms/1k pixels). Project page: \\href{https://dnmp.github.io/}{https://dnmp.github.io/}.","sentences":["Neural Radiance Fields (NeRFs) have achieved great success in the past few years.","However, most current methods still require intensive resources due to ray marching-based rendering.","To construct urban-level radiance fields efficiently, we design Deformable Neural Mesh Primitive~(DNMP), and propose to parameterize the entire scene with such primitives.","The DNMP is a flexible and compact neural variant of classic mesh representation, which enjoys both the efficiency of rasterization-based rendering and the powerful neural representation capability for photo-realistic image synthesis.","Specifically, a DNMP consists of a set of connected deformable mesh vertices with paired vertex features to parameterize the geometry and radiance information of a local area.","To constrain the degree of freedom for optimization and lower the storage budgets, we enforce the shape of each primitive to be decoded from a relatively low-dimensional latent space.","The rendering colors are decoded from the vertex features (interpolated with rasterization) by a view-dependent MLP.","The DNMP provides a new paradigm for urban-level scene representation with appealing properties: $(1)$ High-quality rendering.","Our method achieves leading performance for novel view synthesis in urban scenarios.","$(2)$ Low computational costs.","Our representation enables fast rendering (2.07ms/1k pixels) and low peak memory usage (110MB/1k pixels).","We also present a lightweight version that can run 33$\\times$ faster than vanilla NeRFs, and comparable to the highly-optimized Instant-NGP (0.61 vs 0.71ms/1k pixels).","Project page: \\href{https://dnmp.github.io/}{https://dnmp.github.io/}."],"url":"http://arxiv.org/abs/2307.10776v1"}
{"created":"2023-07-20 11:14:24","title":"Assessing the Use of AutoML for Data-Driven Software Engineering","abstract":"Background. Due to the widespread adoption of Artificial Intelligence (AI) and Machine Learning (ML) for building software applications, companies are struggling to recruit employees with a deep understanding of such technologies. In this scenario, AutoML is soaring as a promising solution to fill the AI/ML skills gap since it promises to automate the building of end-to-end AI/ML pipelines that would normally be engineered by specialized team members. Aims. Despite the growing interest and high expectations, there is a dearth of information about the extent to which AutoML is currently adopted by teams developing AI/ML-enabled systems and how it is perceived by practitioners and researchers. Method. To fill these gaps, in this paper, we present a mixed-method study comprising a benchmark of 12 end-to-end AutoML tools on two SE datasets and a user survey with follow-up interviews to further our understanding of AutoML adoption and perception. Results. We found that AutoML solutions can generate models that outperform those trained and optimized by researchers to perform classification tasks in the SE domain. Also, our findings show that the currently available AutoML solutions do not live up to their names as they do not equally support automation across the stages of the ML development workflow and for all the team members. Conclusions. We derive insights to inform the SE research community on how AutoML can facilitate their activities and tool builders on how to design the next generation of AutoML technologies.","sentences":["Background.","Due to the widespread adoption of Artificial Intelligence (AI) and Machine Learning (ML) for building software applications, companies are struggling to recruit employees with a deep understanding of such technologies.","In this scenario, AutoML is soaring as a promising solution to fill the AI/ML skills gap since it promises to automate the building of end-to-end AI/ML pipelines that would normally be engineered by specialized team members.","Aims.","Despite the growing interest and high expectations, there is a dearth of information about the extent to which AutoML is currently adopted by teams developing AI/ML-enabled systems and how it is perceived by practitioners and researchers.","Method.","To fill these gaps, in this paper, we present a mixed-method study comprising a benchmark of 12 end-to-end AutoML tools on two SE datasets and a user survey with follow-up interviews to further our understanding of AutoML adoption and perception.","Results.","We found that AutoML solutions can generate models that outperform those trained and optimized by researchers to perform classification tasks in the SE domain.","Also, our findings show that the currently available AutoML solutions do not live up to their names as they do not equally support automation across the stages of the ML development workflow and for all the team members.","Conclusions.","We derive insights to inform the SE research community on how AutoML can facilitate their activities and tool builders on how to design the next generation of AutoML technologies."],"url":"http://arxiv.org/abs/2307.10774v1"}
{"created":"2023-07-20 11:10:06","title":"Music Genre Classification with ResNet and Bi-GRU Using Visual Spectrograms","abstract":"Music recommendation systems have emerged as a vital component to enhance user experience and satisfaction for the music streaming services, which dominates music consumption. The key challenge in improving these recommender systems lies in comprehending the complexity of music data, specifically for the underpinning music genre classification. The limitations of manual genre classification have highlighted the need for a more advanced system, namely the Automatic Music Genre Classification (AMGC) system. While traditional machine learning techniques have shown potential in genre classification, they heavily rely on manually engineered features and feature selection, failing to capture the full complexity of music data. On the other hand, deep learning classification architectures like the traditional Convolutional Neural Networks (CNN) are effective in capturing the spatial hierarchies but struggle to capture the temporal dynamics inherent in music data. To address these challenges, this study proposes a novel approach using visual spectrograms as input, and propose a hybrid model that combines the strength of the Residual neural Network (ResNet) and the Gated Recurrent Unit (GRU). This model is designed to provide a more comprehensive analysis of music data, offering the potential to improve the music recommender systems through achieving a more comprehensive analysis of music data and hence potentially more accurate genre classification.","sentences":["Music recommendation systems have emerged as a vital component to enhance user experience and satisfaction for the music streaming services, which dominates music consumption.","The key challenge in improving these recommender systems lies in comprehending the complexity of music data, specifically for the underpinning music genre classification.","The limitations of manual genre classification have highlighted the need for a more advanced system, namely the Automatic Music Genre Classification (AMGC) system.","While traditional machine learning techniques have shown potential in genre classification, they heavily rely on manually engineered features and feature selection, failing to capture the full complexity of music data.","On the other hand, deep learning classification architectures like the traditional Convolutional Neural Networks (CNN) are effective in capturing the spatial hierarchies but struggle to capture the temporal dynamics inherent in music data.","To address these challenges, this study proposes a novel approach using visual spectrograms as input, and propose a hybrid model that combines the strength of the Residual neural Network (ResNet) and the Gated Recurrent Unit (GRU).","This model is designed to provide a more comprehensive analysis of music data, offering the potential to improve the music recommender systems through achieving a more comprehensive analysis of music data and hence potentially more accurate genre classification."],"url":"http://arxiv.org/abs/2307.10773v1"}
{"created":"2023-07-20 10:53:12","title":"MSQNet: Actor-agnostic Action Recognition with Multi-modal Query","abstract":"Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors. This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs. Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions. To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals. We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better. The elimination of actor-specific model designs is a key advantage, as it removes the need for actor pose estimation altogether. Extensive experiments on five publicly available benchmarks show that our MSQNet consistently outperforms the prior arts of actor-specific alternatives on human and animal single- and multi-label action recognition tasks by up to 50%. Code will be released at https://github.com/mondalanindya/MSQNet.","sentences":["Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors.","This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs.","Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions.","To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals.","We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better.","The elimination of actor-specific model designs is a key advantage, as it removes the need for actor pose estimation altogether.","Extensive experiments on five publicly available benchmarks show that our MSQNet consistently outperforms the prior arts of actor-specific alternatives on human and animal single- and multi-label action recognition tasks by up to 50%.","Code will be released at https://github.com/mondalanindya/MSQNet."],"url":"http://arxiv.org/abs/2307.10763v1"}
{"created":"2023-07-20 10:42:16","title":"Vesper: A Compact and Effective Pretrained Model for Speech Emotion Recognition","abstract":"This paper presents a paradigm that adapts general large-scale pretrained models (PTMs) to speech emotion recognition task. Although PTMs shed new light on artificial general intelligence, they are constructed with general tasks in mind, and thus, their efficacy for specific tasks can be further improved. Additionally, employing PTMs in practical applications can be challenging due to their considerable size. Above limitations spawn another research direction, namely, optimizing large-scale PTMs for specific tasks to generate task-specific PTMs that are both compact and effective. In this paper, we focus on the speech emotion recognition task and propose an improved emotion-specific pretrained encoder called Vesper. Vesper is pretrained on a speech dataset based on WavLM and takes into account emotional characteristics. To enhance sensitivity to emotional information, Vesper employs an emotion-guided masking strategy to identify the regions that need masking. Subsequently, Vesper employs hierarchical and cross-layer self-supervision to improve its ability to capture acoustic and semantic representations, both of which are crucial for emotion recognition. Experimental results on the IEMOCAP, MELD, and CREMA-D datasets demonstrate that Vesper with 4 layers outperforms WavLM Base with 12 layers, and the performance of Vesper with 12 layers surpasses that of WavLM Large with 24 layers.","sentences":["This paper presents a paradigm that adapts general large-scale pretrained models (PTMs) to speech emotion recognition task.","Although PTMs shed new light on artificial general intelligence, they are constructed with general tasks in mind, and thus, their efficacy for specific tasks can be further improved.","Additionally, employing PTMs in practical applications can be challenging due to their considerable size.","Above limitations spawn another research direction, namely, optimizing large-scale PTMs for specific tasks to generate task-specific PTMs that are both compact and effective.","In this paper, we focus on the speech emotion recognition task and propose an improved emotion-specific pretrained encoder called Vesper.","Vesper is pretrained on a speech dataset based on WavLM and takes into account emotional characteristics.","To enhance sensitivity to emotional information, Vesper employs an emotion-guided masking strategy to identify the regions that need masking.","Subsequently, Vesper employs hierarchical and cross-layer self-supervision to improve its ability to capture acoustic and semantic representations, both of which are crucial for emotion recognition.","Experimental results on the IEMOCAP, MELD, and CREMA-D datasets demonstrate that Vesper with 4 layers outperforms WavLM Base with 12 layers, and the performance of Vesper with 12 layers surpasses that of WavLM Large with 24 layers."],"url":"http://arxiv.org/abs/2307.10757v1"}
{"created":"2023-07-20 10:29:48","title":"LBL: Logarithmic Barrier Loss Function for One-class Classification","abstract":"One-class classification (OCC) aims to train a classifier only with the target class data and attracts great attention for its strong applicability in real-world application. Despite a lot of advances have been made in OCC, it still lacks the effective OCC loss functions for deep learning. In this paper, a novel logarithmic barrier function based OCC loss (LBL) that assigns large gradients to the margin samples and thus derives more compact hypersphere, is first proposed by approximating the OCC objective smoothly. But the optimization of LBL may be instability especially when samples lie on the boundary leading to the infinity loss. To address this issue, then, a unilateral relaxation Sigmoid function is introduced into LBL and a novel OCC loss named LBLSig is proposed. The LBLSig can be seen as the fusion of the mean square error (MSE) and the cross entropy (CE) and the optimization of LBLSig is smoother owing to the unilateral relaxation Sigmoid function. The effectiveness of the proposed LBL and LBLSig is experimentally demonstrated in comparisons with several state-of-the-art OCC algorithms on different network structures. The source code can be found at https://github.com/ML-HDU/LBL_LBLSig.","sentences":["One-class classification (OCC) aims to train a classifier only with the target class data and attracts great attention for its strong applicability in real-world application.","Despite a lot of advances have been made in OCC, it still lacks the effective OCC loss functions for deep learning.","In this paper, a novel logarithmic barrier function based OCC loss (LBL) that assigns large gradients to the margin samples and thus derives more compact hypersphere, is first proposed by approximating the OCC objective smoothly.","But the optimization of LBL may be instability especially when samples lie on the boundary leading to the infinity loss.","To address this issue, then, a unilateral relaxation Sigmoid function is introduced into LBL and a novel OCC loss named LBLSig is proposed.","The LBLSig can be seen as the fusion of the mean square error (MSE) and the cross entropy (CE) and the optimization of LBLSig is smoother owing to the unilateral relaxation Sigmoid function.","The effectiveness of the proposed LBL and LBLSig is experimentally demonstrated in comparisons with several state-of-the-art OCC algorithms on different network structures.","The source code can be found at https://github.com/ML-HDU/LBL_LBLSig."],"url":"http://arxiv.org/abs/2307.10753v1"}
{"created":"2023-07-20 10:26:57","title":"Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots","abstract":"Artificial Intelligence (AI), and in particular generative models, are transformative tools for knowledge work. They problematise notions of creativity, originality, plagiarism, the attribution of credit, and copyright ownership. Critics of generative models emphasise the reliance on large amounts of training data, and view the output of these models as no more than randomised plagiarism, remix, or collage of the source data. On these grounds, many have argued for stronger regulations on the deployment, use, and attribution of the output of these models. However, these issues are not new or unique to artificial intelligence. In this position paper, using examples from literary criticism, the history of art, and copyright law, I show how creativity and originality resist definition as a notatable or information-theoretic property of an object, and instead can be seen as the property of a process, an author, or a viewer. Further alternative views hold that all creative work is essentially reuse (mostly without attribution), or that randomness itself can be creative. I suggest that creativity is ultimately defined by communities of creators and receivers, and the deemed sources of creativity in a workflow often depend on which parts of the workflow can be automated. Using examples from recent studies of AI in creative knowledge work, I suggest that AI shifts knowledge work from material production to critical integration. This position paper aims to begin a conversation around a more nuanced approach to the problems of creativity and credit assignment for generative models, one which more fully recognises the importance of the creative and curatorial voice of the users of these models and moves away from simpler notational or information-theoretic views.","sentences":["Artificial Intelligence (AI), and in particular generative models, are transformative tools for knowledge work.","They problematise notions of creativity, originality, plagiarism, the attribution of credit, and copyright ownership.","Critics of generative models emphasise the reliance on large amounts of training data, and view the output of these models as no more than randomised plagiarism, remix, or collage of the source data.","On these grounds, many have argued for stronger regulations on the deployment, use, and attribution of the output of these models.","However, these issues are not new or unique to artificial intelligence.","In this position paper, using examples from literary criticism, the history of art, and copyright law, I show how creativity and originality resist definition as a notatable or information-theoretic property of an object, and instead can be seen as the property of a process, an author, or a viewer.","Further alternative views hold that all creative work is essentially reuse (mostly without attribution), or that randomness itself can be creative.","I suggest that creativity is ultimately defined by communities of creators and receivers, and the deemed sources of creativity in a workflow often depend on which parts of the workflow can be automated.","Using examples from recent studies of AI in creative knowledge work, I suggest that AI shifts knowledge work from material production to critical integration.","This position paper aims to begin a conversation around a more nuanced approach to the problems of creativity and credit assignment for generative models, one which more fully recognises the importance of the creative and curatorial voice of the users of these models and moves away from simpler notational or information-theoretic views."],"url":"http://arxiv.org/abs/2307.10751v1"}
{"created":"2023-07-20 10:24:18","title":"Mitigating Voter Attribute Bias for Fair Opinion Aggregation","abstract":"The aggregation of multiple opinions plays a crucial role in decision-making, such as in hiring and loan review, and in labeling data for supervised learning. Although majority voting and existing opinion aggregation models are effective for simple tasks, they are inappropriate for tasks without objectively true labels in which disagreements may occur. In particular, when voter attributes such as gender or race introduce bias into opinions, the aggregation results may vary depending on the composition of voter attributes. A balanced group of voters is desirable for fair aggregation results but may be difficult to prepare. In this study, we consider methods to achieve fair opinion aggregation based on voter attributes and evaluate the fairness of the aggregated results. To this end, we consider an approach that combines opinion aggregation models such as majority voting and the Dawid and Skene model (D&S model) with fairness options such as sample weighting. To evaluate the fairness of opinion aggregation, probabilistic soft labels are preferred over discrete class labels. First, we address the problem of soft label estimation without considering voter attributes and identify some issues with the D&S model. To address these limitations, we propose a new Soft D&S model with improved accuracy in estimating soft labels. Moreover, we evaluated the fairness of an opinion aggregation model, including Soft D&S, in combination with different fairness options using synthetic and semi-synthetic data. The experimental results suggest that the combination of Soft D&S and data splitting as a fairness option is effective for dense data, whereas weighted majority voting is effective for sparse data. These findings should prove particularly valuable in supporting decision-making by human and machine-learning models with balanced opinion aggregation.","sentences":["The aggregation of multiple opinions plays a crucial role in decision-making, such as in hiring and loan review, and in labeling data for supervised learning.","Although majority voting and existing opinion aggregation models are effective for simple tasks, they are inappropriate for tasks without objectively true labels in which disagreements may occur.","In particular, when voter attributes such as gender or race introduce bias into opinions, the aggregation results may vary depending on the composition of voter attributes.","A balanced group of voters is desirable for fair aggregation results but may be difficult to prepare.","In this study, we consider methods to achieve fair opinion aggregation based on voter attributes and evaluate the fairness of the aggregated results.","To this end, we consider an approach that combines opinion aggregation models such as majority voting and the Dawid and Skene model (D&S model) with fairness options such as sample weighting.","To evaluate the fairness of opinion aggregation, probabilistic soft labels are preferred over discrete class labels.","First, we address the problem of soft label estimation without considering voter attributes and identify some issues with the D&S model.","To address these limitations, we propose a new Soft D&S model with improved accuracy in estimating soft labels.","Moreover, we evaluated the fairness of an opinion aggregation model, including Soft D&S, in combination with different fairness options using synthetic and semi-synthetic data.","The experimental results suggest that the combination of Soft D&S and data splitting as a fairness option is effective for dense data, whereas weighted majority voting is effective for sparse data.","These findings should prove particularly valuable in supporting decision-making by human and machine-learning models with balanced opinion aggregation."],"url":"http://arxiv.org/abs/2307.10749v1"}
{"created":"2023-07-20 10:19:47","title":"Enhancing Job Recommendation through LLM-based Generative Adversarial Networks","abstract":"Recommending suitable jobs to users is a critical task in online recruitment platforms, as it can enhance users' satisfaction and the platforms' profitability. While existing job recommendation methods encounter challenges such as the low quality of users' resumes, which hampers their accuracy and practical effectiveness. With the rapid development of large language models (LLMs), utilizing the rich external knowledge encapsulated within them, as well as their powerful capabilities of text processing and reasoning, is a promising way to complete users' resumes for more accurate recommendations. However, directly leveraging LLMs to enhance recommendation results is not a one-size-fits-all solution, as LLMs may suffer from fabricated generation and few-shot problems, which degrade the quality of resume completion. In this paper, we propose a novel LLM-based approach for job recommendation. To alleviate the limitation of fabricated generation for LLMs, we extract accurate and valuable information beyond users' self-description, which helps the LLMs better profile users for resume completion. Specifically, we not only extract users' explicit properties (e.g., skills, interests) from their self-description but also infer users' implicit characteristics from their behaviors for more accurate and meaningful resume completion. Nevertheless, some users still suffer from few-shot problems, which arise due to scarce interaction records, leading to limited guidance for the models in generating high-quality resumes. To address this issue, we propose aligning unpaired low-quality with high-quality generated resumes by Generative Adversarial Networks (GANs), which can refine the resume representations for better recommendation results. Extensive experiments on three large real-world recruitment datasets demonstrate the effectiveness of our proposed method.","sentences":["Recommending suitable jobs to users is a critical task in online recruitment platforms, as it can enhance users' satisfaction and the platforms' profitability.","While existing job recommendation methods encounter challenges such as the low quality of users' resumes, which hampers their accuracy and practical effectiveness.","With the rapid development of large language models (LLMs), utilizing the rich external knowledge encapsulated within them, as well as their powerful capabilities of text processing and reasoning, is a promising way to complete users' resumes for more accurate recommendations.","However, directly leveraging LLMs to enhance recommendation results is not a one-size-fits-all solution, as LLMs may suffer from fabricated generation and few-shot problems, which degrade the quality of resume completion.","In this paper, we propose a novel LLM-based approach for job recommendation.","To alleviate the limitation of fabricated generation for LLMs, we extract accurate and valuable information beyond users' self-description, which helps the LLMs better profile users for resume completion.","Specifically, we not only extract users' explicit properties (e.g., skills, interests) from their self-description but also infer users' implicit characteristics from their behaviors for more accurate and meaningful resume completion.","Nevertheless, some users still suffer from few-shot problems, which arise due to scarce interaction records, leading to limited guidance for the models in generating high-quality resumes.","To address this issue, we propose aligning unpaired low-quality with high-quality generated resumes by Generative Adversarial Networks (GANs), which can refine the resume representations for better recommendation results.","Extensive experiments on three large real-world recruitment datasets demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2307.10747v1"}
{"created":"2023-07-20 10:16:03","title":"EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation","abstract":"Active learning algorithms have become increasingly popular for training models with limited data. However, selecting data for annotation remains a challenging problem due to the limited information available on unseen data. To address this issue, we propose EdgeAL, which utilizes the edge information of unseen images as {\\it a priori} information for measuring uncertainty. The uncertainty is quantified by analyzing the divergence and entropy in model predictions across edges. This measure is then used to select superpixels for annotation. We demonstrate the effectiveness of EdgeAL on multi-class Optical Coherence Tomography (OCT) segmentation tasks, where we achieved a 99% dice score while reducing the annotation label cost to 12%, 2.3%, and 3%, respectively, on three publicly available datasets (Duke, AROI, and UMN). The source code is available at \\url{https://github.com/Mak-Ta-Reque/EdgeAL}","sentences":["Active learning algorithms have become increasingly popular for training models with limited data.","However, selecting data for annotation remains a challenging problem due to the limited information available on unseen data.","To address this issue, we propose EdgeAL, which utilizes the edge information of unseen images as {\\it a priori} information for measuring uncertainty.","The uncertainty is quantified by analyzing the divergence and entropy in model predictions across edges.","This measure is then used to select superpixels for annotation.","We demonstrate the effectiveness of EdgeAL on multi-class Optical Coherence Tomography (OCT) segmentation tasks, where we achieved a 99% dice score while reducing the annotation label cost to 12%, 2.3%, and 3%, respectively, on three publicly available datasets (Duke, AROI, and UMN).","The source code is available at \\url{https://github.com/Mak-Ta-Reque/EdgeAL}"],"url":"http://arxiv.org/abs/2307.10745v1"}
{"created":"2023-07-20 10:13:34","title":"Predicting human motion intention for pHRI assistive control","abstract":"This work addresses human intention identification during physical Human-Robot Interaction (pHRI) tasks to include this information in an assistive controller. To this purpose, human intention is defined as the desired trajectory that the human wants to follow over a finite rolling prediction horizon so that the robot can assist in pursuing it. This work investigates a Recurrent Neural Network (RNN), specifically, Long-Short Term Memory (LSTM) cascaded with a Fully Connected layer. In particular, we propose an iterative training procedure to adapt the model. Such an iterative procedure is powerful in reducing the prediction error. Still, it has the drawback that it is time-consuming and does not generalize to different users or different co-manipulated objects. To overcome this issue, Transfer Learning (TL) adapts the pre-trained model to new trajectories, users, and co-manipulated objects by freezing the LSTM layer and fine-tuning the last FC layer, which makes the procedure faster. Experiments show that the iterative procedure adapts the model and reduces prediction error. Experiments also show that TL adapts to different users and to the co-manipulation of a large object. Finally, to check the utility of adopting the proposed method, we compare the proposed controller enhanced by the intention prediction with the other two standard controllers of pHRI.","sentences":["This work addresses human intention identification during physical Human-Robot Interaction (pHRI) tasks to include this information in an assistive controller.","To this purpose, human intention is defined as the desired trajectory that the human wants to follow over a finite rolling prediction horizon so that the robot can assist in pursuing it.","This work investigates a Recurrent Neural Network (RNN), specifically, Long-Short Term Memory (LSTM) cascaded with a Fully Connected layer.","In particular, we propose an iterative training procedure to adapt the model.","Such an iterative procedure is powerful in reducing the prediction error.","Still, it has the drawback that it is time-consuming and does not generalize to different users or different co-manipulated objects.","To overcome this issue, Transfer Learning (TL) adapts the pre-trained model to new trajectories, users, and co-manipulated objects by freezing the LSTM layer and fine-tuning the last FC layer, which makes the procedure faster.","Experiments show that the iterative procedure adapts the model and reduces prediction error.","Experiments also show that TL adapts to different users and to the co-manipulation of a large object.","Finally, to check the utility of adopting the proposed method, we compare the proposed controller enhanced by the intention prediction with the other two standard controllers of pHRI."],"url":"http://arxiv.org/abs/2307.10743v1"}
{"created":"2023-07-20 10:06:55","title":"Modeling and analysis of pHRI with Differential Game Theory","abstract":"Applications involving humans and robots working together are spreading nowadays. Alongside, modeling and control techniques that allow physical Human-Robot Interaction (pHRI) are widely investigated. To better understand its potential application in pHRI, this work investigates the Cooperative Differential Game Theory modeling of pHRI in a cooperative reaching task, specifically for reference tracking. The proposed controller based on Collaborative Game Theory is deeply analyzed and compared in simulations with two other techniques, Linear Quadratic Regulator (LQR) and Non-Cooperative Game-Theoretic Controller. The set of simulations shows how different tuning of control parameters affects the system response and control efforts of both the players for the three controllers, suggesting the use of Cooperative GT in the case the robot should assist the human, while Non-Cooperative GT represents a better choice in the case the robot should lead the action. Finally, preliminary tests with a trained human are performed to extract useful information on the real applicability and limitations of the proposed method.","sentences":["Applications involving humans and robots working together are spreading nowadays.","Alongside, modeling and control techniques that allow physical Human-Robot Interaction (pHRI) are widely investigated.","To better understand its potential application in pHRI, this work investigates the Cooperative Differential Game Theory modeling of pHRI in a cooperative reaching task, specifically for reference tracking.","The proposed controller based on Collaborative Game Theory is deeply analyzed and compared in simulations with two other techniques, Linear Quadratic Regulator (LQR) and Non-Cooperative Game-Theoretic Controller.","The set of simulations shows how different tuning of control parameters affects the system response and control efforts of both the players for the three controllers, suggesting the use of Cooperative GT in the case the robot should assist the human, while Non-Cooperative GT represents a better choice in the case the robot should lead the action.","Finally, preliminary tests with a trained human are performed to extract useful information on the real applicability and limitations of the proposed method."],"url":"http://arxiv.org/abs/2307.10739v1"}
{"created":"2023-07-20 10:04:55","title":"Fairness-Aware Client Selection for Federated Learning","abstract":"Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients) to train machine learning models collaboratively without revealing private data. Since the FL server can only engage a limited number of clients in each training round, FL client selection has become an important research problem. Existing approaches generally focus on either enhancing FL model performance or enhancing the fair treatment of FL clients. The problem of balancing performance and fairness considerations when selecting FL clients remains open. To address this problem, we propose the Fairness-aware Federated Client Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically adjusts FL clients' selection probabilities by jointly considering their reputations, times of participation in FL tasks and contributions to the resulting model performance. By not using threshold-based reputation filtering, it provides FL clients with opportunities to redeem their reputations after a perceived poor performance, thereby further enhancing fair client treatment. Extensive experiments based on real-world multimedia datasets show that FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on average than the best-performing state-of-the-art approach.","sentences":["Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients) to train machine learning models collaboratively without revealing private data.","Since the FL server can only engage a limited number of clients in each training round, FL client selection has become an important research problem.","Existing approaches generally focus on either enhancing FL model performance or enhancing the fair treatment of FL clients.","The problem of balancing performance and fairness considerations when selecting FL clients remains open.","To address this problem, we propose the Fairness-aware Federated Client Selection (FairFedCS) approach.","Based on Lyapunov optimization, it dynamically adjusts FL clients' selection probabilities by jointly considering their reputations, times of participation in FL tasks and contributions to the resulting model performance.","By not using threshold-based reputation filtering, it provides FL clients with opportunities to redeem their reputations after a perceived poor performance, thereby further enhancing fair client treatment.","Extensive experiments based on real-world multimedia datasets show that FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on average than the best-performing state-of-the-art approach."],"url":"http://arxiv.org/abs/2307.10738v1"}
{"created":"2023-07-20 10:03:50","title":"Long-Tail Theory under Gaussian Mixtures","abstract":"We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory (2020). We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can. This confirms that for long-tailed distributions, rare training examples must be considered for optimal generalization to new data. Finally, we show that the performance gap between linear and nonlinear models can be lessened as the tail becomes shorter in the subpopulation frequency distribution, as confirmed by experiments on synthetic and real data.","sentences":["We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory (2020).","We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can.","This confirms that for long-tailed distributions, rare training examples must be considered for optimal generalization to new data.","Finally, we show that the performance gap between linear and nonlinear models can be lessened as the tail becomes shorter in the subpopulation frequency distribution, as confirmed by experiments on synthetic and real data."],"url":"http://arxiv.org/abs/2307.10736v1"}
{"created":"2023-07-20 09:45:15","title":"TransNFV: Integrating Transactional Semantics for Efficient State Management in Virtual Network Functions","abstract":"Managing shared mutable states in high concurrency state access operations is a persistent challenge in Network Functions Virtualization (NFV). This is particularly true when striving to meet chain output equivalence (COE) requirements. This paper presents TransNFV, an innovative NFV framework that incorporates transactional semantics to optimize NFV state management. The TransNFV integrates VNF state access operations as transactions, resolves transaction dependencies, schedules transactions dynamically, and executes transactions efficiently. Initial findings suggest that TransNFV maintains shared VNF state consistency, meets COE requirements, and skillfully handles complex cross-flow states in dynamic network conditions. TransNFV thus provides a promising solution to enhance state management and overall performance in future NFV platforms.","sentences":["Managing shared mutable states in high concurrency state access operations is a persistent challenge in Network Functions Virtualization (NFV).","This is particularly true when striving to meet chain output equivalence (COE) requirements.","This paper presents TransNFV, an innovative NFV framework that incorporates transactional semantics to optimize NFV state management.","The TransNFV integrates VNF state access operations as transactions, resolves transaction dependencies, schedules transactions dynamically, and executes transactions efficiently.","Initial findings suggest that TransNFV maintains shared VNF state consistency, meets COE requirements, and skillfully handles complex cross-flow states in dynamic network conditions.","TransNFV thus provides a promising solution to enhance state management and overall performance in future NFV platforms."],"url":"http://arxiv.org/abs/2307.10732v1"}
{"created":"2023-07-20 09:42:09","title":"Joint Port Selection Based Channel Acquisition for FDD Cell-Free Massive MIMO","abstract":"In frequency division duplexing (FDD) cell-free massive MIMO, the acquisition of the channel state information (CSI) is very challenging because of the large overhead required for the training and feedback of the downlink channels of multiple cooperating base stations (BSs). In this paper, for systems with partial uplink-downlink channel reciprocity, and a general spatial domain channel model with variations in the average port power and correlation among port coefficients, we propose a joint-port-selection-based CSI acquisition and feedback scheme for the downlink transmission with zero-forcing precoding. The scheme uses an eigenvalue-decomposition-based transformation to reduce the feedback overhead by exploring the port correlation. We derive the sum-rate of the system for any port selection. Based on the sum-rate result, we propose a low-complexity greedy-search-based joint port selection (GS-JPS) algorithm. Moreover, to adapt to fast time-varying scenarios, a supervised deep learning-enhanced joint port selection (DL-JPS) algorithm is proposed. Simulations verify the effectiveness of our proposed schemes and their advantage over existing port-selection channel acquisition schemes.","sentences":["In frequency division duplexing (FDD) cell-free massive MIMO, the acquisition of the channel state information (CSI) is very challenging because of the large overhead required for the training and feedback of the downlink channels of multiple cooperating base stations (BSs).","In this paper, for systems with partial uplink-downlink channel reciprocity, and a general spatial domain channel model with variations in the average port power and correlation among port coefficients, we propose a joint-port-selection-based CSI acquisition and feedback scheme for the downlink transmission with zero-forcing precoding.","The scheme uses an eigenvalue-decomposition-based transformation to reduce the feedback overhead by exploring the port correlation.","We derive the sum-rate of the system for any port selection.","Based on the sum-rate result, we propose a low-complexity greedy-search-based joint port selection (GS-JPS) algorithm.","Moreover, to adapt to fast time-varying scenarios, a supervised deep learning-enhanced joint port selection (DL-JPS) algorithm is proposed.","Simulations verify the effectiveness of our proposed schemes and their advantage over existing port-selection channel acquisition schemes."],"url":"http://arxiv.org/abs/2307.10730v1"}
{"created":"2023-07-20 09:39:29","title":"A Blockchain-based Electronic Voting System: EtherVote","abstract":"The development of an electronic voting system that would replace traditional election procedures is a research topic of great interest for many years. Blockchain technology could provide some guarantees and fulfill strong requirements for electronic voting platforms, such as transparency, immutability, and confidentiality. From time to time research is conducted to address problems in voting systems. Many research works attempt to implement secure and reliable voting systems, which address known security, anonymity, and fraud issues that might threaten such systems.   This paper presents a proposal of a secure electronic voting system, the EtherVote, using the Ethereum Blockchain network that focuses deeply on the field of identification of eligible citizens. The proposed system will be entirely based on Blockchain without any central authority servers or databases, thus improving security, privacy, and election cost. Limitations, problems, and solutions are discussed, in order to make the proposed electronic voting system ideal and ready to use for national elections.","sentences":["The development of an electronic voting system that would replace traditional election procedures is a research topic of great interest for many years.","Blockchain technology could provide some guarantees and fulfill strong requirements for electronic voting platforms, such as transparency, immutability, and confidentiality.","From time to time research is conducted to address problems in voting systems.","Many research works attempt to implement secure and reliable voting systems, which address known security, anonymity, and fraud issues that might threaten such systems.   ","This paper presents a proposal of a secure electronic voting system, the EtherVote, using the Ethereum Blockchain network that focuses deeply on the field of identification of eligible citizens.","The proposed system will be entirely based on Blockchain without any central authority servers or databases, thus improving security, privacy, and election cost.","Limitations, problems, and solutions are discussed, in order to make the proposed electronic voting system ideal and ready to use for national elections."],"url":"http://arxiv.org/abs/2307.10726v1"}
{"created":"2023-07-20 09:25:02","title":"LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?","abstract":"Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated; it should be treated as a security problem which warrants the adaptation of security-based approaches to mitigate potential risks.","sentences":["Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions.","However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use.","Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses.","Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs.","In this paper, we present the theoretical limitations of such semantic censorship approaches.","Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities.","Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones.","As a result, we propose that the problem of censorship needs to be reevaluated; it should be treated as a security problem which warrants the adaptation of security-based approaches to mitigate potential risks."],"url":"http://arxiv.org/abs/2307.10719v1"}
{"created":"2023-07-20 09:24:23","title":"Differences Between Hard and Noisy-labeled Samples: An Empirical Study","abstract":"Extracting noisy or incorrectly labeled samples from a labeled dataset with hard/difficult samples is an important yet under-explored topic. Two general and often independent lines of work exist, one focuses on addressing noisy labels, and another deals with hard samples. However, when both types of data are present, most existing methods treat them equally, which results in a decline in the overall performance of the model. In this paper, we first design various synthetic datasets with custom hardness and noisiness levels for different samples. Our proposed systematic empirical study enables us to better understand the similarities and more importantly the differences between hard-to-learn samples and incorrectly-labeled samples. These controlled experiments pave the way for the development of methods that distinguish between hard and noisy samples. Through our study, we introduce a simple yet effective metric that filters out noisy-labeled samples while keeping the hard samples. We study various data partitioning methods in the presence of label noise and observe that filtering out noisy samples from hard samples with this proposed metric results in the best datasets as evidenced by the high test accuracy achieved after models are trained on the filtered datasets. We demonstrate this for both our created synthetic datasets and for datasets with real-world label noise. Furthermore, our proposed data partitioning method significantly outperforms other methods when employed within a semi-supervised learning framework.","sentences":["Extracting noisy or incorrectly labeled samples from a labeled dataset with hard/difficult samples is an important yet under-explored topic.","Two general and often independent lines of work exist, one focuses on addressing noisy labels, and another deals with hard samples.","However, when both types of data are present, most existing methods treat them equally, which results in a decline in the overall performance of the model.","In this paper, we first design various synthetic datasets with custom hardness and noisiness levels for different samples.","Our proposed systematic empirical study enables us to better understand the similarities and more importantly the differences between hard-to-learn samples and incorrectly-labeled samples.","These controlled experiments pave the way for the development of methods that distinguish between hard and noisy samples.","Through our study, we introduce a simple yet effective metric that filters out noisy-labeled samples while keeping the hard samples.","We study various data partitioning methods in the presence of label noise and observe that filtering out noisy samples from hard samples with this proposed metric results in the best datasets as evidenced by the high test accuracy achieved after models are trained on the filtered datasets.","We demonstrate this for both our created synthetic datasets and for datasets with real-world label noise.","Furthermore, our proposed data partitioning method significantly outperforms other methods when employed within a semi-supervised learning framework."],"url":"http://arxiv.org/abs/2307.10718v1"}
{"created":"2023-07-20 09:13:32","title":"Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV","abstract":"Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.   To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.   We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) aspect ratio augmentation, 2) camera intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation. Code is available at https://github.com/jspenmar/slowtv_monodepth.","sentences":["Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data.","Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.   ","To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets.","SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving.","Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets.","The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.   ","We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization.","This includes 1) aspect ratio augmentation, 2) camera intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation.","Code is available at https://github.com/jspenmar/slowtv_monodepth."],"url":"http://arxiv.org/abs/2307.10713v1"}
{"created":"2023-07-20 09:06:21","title":"AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models","abstract":"Existing customization methods require access to multiple reference examples to align pre-trained diffusion probabilistic models (DPMs) with user-provided concepts. This paper aims to address the challenge of DPM customization when the only available supervision is a differentiable metric defined on the generated contents. Since the sampling procedure of DPMs involves recursive calls to the denoising UNet, na\\\"ive gradient backpropagation requires storing the intermediate states of all iterations, resulting in extremely high memory consumption. To overcome this issue, we propose a novel method AdjointDPM, which first generates new samples from diffusion models by solving the corresponding probability-flow ODEs. It then uses the adjoint sensitivity method to backpropagate the gradients of the loss to the models' parameters (including conditioning signals, network weights, and initial noises) by solving another augmented ODE. To reduce numerical errors in both the forward generation and gradient backpropagation processes, we further reparameterize the probability-flow ODE and augmented ODE as simple non-stiff ODEs using exponential integration. Finally, we demonstrate the effectiveness of AdjointDPM on three interesting tasks: converting visual effects into identification text embeddings, finetuning DPMs for specific types of stylization, and optimizing initial noise to generate adversarial samples for security auditing.","sentences":["Existing customization methods require access to multiple reference examples to align pre-trained diffusion probabilistic models (DPMs) with user-provided concepts.","This paper aims to address the challenge of DPM customization when the only available supervision is a differentiable metric defined on the generated contents.","Since the sampling procedure of DPMs involves recursive calls to the denoising UNet, na\\\"ive gradient backpropagation requires storing the intermediate states of all iterations, resulting in extremely high memory consumption.","To overcome this issue, we propose a novel method AdjointDPM, which first generates new samples from diffusion models by solving the corresponding probability-flow ODEs.","It then uses the adjoint sensitivity method to backpropagate the gradients of the loss to the models' parameters (including conditioning signals, network weights, and initial noises) by solving another augmented ODE.","To reduce numerical errors in both the forward generation and gradient backpropagation processes, we further reparameterize the probability-flow ODE and augmented ODE as simple non-stiff ODEs using exponential integration.","Finally, we demonstrate the effectiveness of AdjointDPM on three interesting tasks: converting visual effects into identification text embeddings, finetuning DPMs for specific types of stylization, and optimizing initial noise to generate adversarial samples for security auditing."],"url":"http://arxiv.org/abs/2307.10711v1"}
{"created":"2023-07-20 09:05:46","title":"Reparameterized Policy Learning for Multimodal Trajectory Optimization","abstract":"We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces. Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization. To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories. By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment. We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency. Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward. Our method consistently outperforms previous approaches across a range of tasks. Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/","sentences":["We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces.","Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization.","To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories.","By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment.","We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency.","Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward.","Our method consistently outperforms previous approaches across a range of tasks.","Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/"],"url":"http://arxiv.org/abs/2307.10710v1"}
{"created":"2023-07-20 08:56:51","title":"SNR Maximization in Beyond Diagonal RIS-assisted Single and Multiple Antenna Links","abstract":"Reconfigurable intelligent surface (RIS) architectures not limited to diagonal phase shift matrices have recently been considered to increase their flexibility in shaping the wireless channel. One of these beyond-diagonal RIS or BD-RIS architectures leads to a unitary and symmetric RIS matrix. In this letter, we consider the problem of maximizing the signal-to-noise ratio (SNR) in single and multiple antenna links assisted by a BD-RIS. The Max-SNR problem admits a closed-form solution based on the Takagi factorization of a certain complex and symmetric matrix. This allows us to solve the max-SNR problem for SISO, SIMO, and MISO channels.","sentences":["Reconfigurable intelligent surface (RIS) architectures not limited to diagonal phase shift matrices have recently been considered to increase their flexibility in shaping the wireless channel.","One of these beyond-diagonal RIS or BD-RIS architectures leads to a unitary and symmetric RIS matrix.","In this letter, we consider the problem of maximizing the signal-to-noise ratio (SNR) in single and multiple antenna links assisted by a BD-RIS.","The Max-SNR problem admits a closed-form solution based on the Takagi factorization of a certain complex and symmetric matrix.","This allows us to solve the max-SNR problem for SISO, SIMO, and MISO channels."],"url":"http://arxiv.org/abs/2307.10707v1"}
{"created":"2023-07-20 08:53:47","title":"TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars","abstract":"Semantic segmentation is a common task in autonomous driving to understand the surrounding environment. Driveable Area Segmentation and Lane Detection are particularly important for safe and efficient navigation on the road. However, original semantic segmentation models are computationally expensive and require high-end hardware, which is not feasible for embedded systems in autonomous vehicles. This paper proposes a lightweight model for the driveable area and lane line segmentation. TwinLiteNet is designed cheaply but achieves accurate and efficient segmentation results. We evaluate TwinLiteNet on the BDD100K dataset and compare it with modern models. Experimental results show that our TwinLiteNet performs similarly to existing approaches, requiring significantly fewer computational resources. Specifically, TwinLiteNet achieves a mIoU score of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task with only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000. Furthermore, TwinLiteNet can run in real-time on embedded devices with limited computing power, especially since it achieves 60FPS on Jetson Xavier NX, making it an ideal solution for self-driving vehicles. Code is available: url{https://github.com/chequanghuy/TwinLiteNet}.","sentences":["Semantic segmentation is a common task in autonomous driving to understand the surrounding environment.","Driveable Area Segmentation and Lane Detection are particularly important for safe and efficient navigation on the road.","However, original semantic segmentation models are computationally expensive and require high-end hardware, which is not feasible for embedded systems in autonomous vehicles.","This paper proposes a lightweight model for the driveable area and lane line segmentation.","TwinLiteNet is designed cheaply but achieves accurate and efficient segmentation results.","We evaluate TwinLiteNet on the BDD100K dataset and compare it with modern models.","Experimental results show that our TwinLiteNet performs similarly to existing approaches, requiring significantly fewer computational resources.","Specifically, TwinLiteNet achieves a mIoU score of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task with only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000.","Furthermore, TwinLiteNet can run in real-time on embedded devices with limited computing power, especially since it achieves 60FPS on Jetson Xavier NX, making it an ideal solution for self-driving vehicles.","Code is available: url{https://github.com/chequanghuy/TwinLiteNet}."],"url":"http://arxiv.org/abs/2307.10705v1"}
{"created":"2023-07-20 08:53:16","title":"Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits","abstract":"The drastic growth of electric vehicles and photovoltaics can introduce new challenges, such as electrical current congestion and voltage limit violations due to peak load demands. These issues can be mitigated by controlling the operation of electric vehicles i.e., smart charging. Centralized smart charging solutions have already been proposed in the literature. But such solutions may lack scalability and suffer from inherent drawbacks of centralization, such as a single point of failure, and data privacy concerns. Decentralization can help tackle these challenges. In this paper, a fully decentralized smart charging system is proposed using the philosophy of adaptive multi-agent systems. The proposed system utilizes multi-armed bandit learning to handle uncertainties in the system. The presented system is decentralized, scalable, real-time, model-free, and takes fairness among different players into account. A detailed case study is also presented for performance evaluation.","sentences":["The drastic growth of electric vehicles and photovoltaics can introduce new challenges, such as electrical current congestion and voltage limit violations due to peak load demands.","These issues can be mitigated by controlling the operation of electric vehicles i.e., smart charging.","Centralized smart charging solutions have already been proposed in the literature.","But such solutions may lack scalability and suffer from inherent drawbacks of centralization, such as a single point of failure, and data privacy concerns.","Decentralization can help tackle these challenges.","In this paper, a fully decentralized smart charging system is proposed using the philosophy of adaptive multi-agent systems.","The proposed system utilizes multi-armed bandit learning to handle uncertainties in the system.","The presented system is decentralized, scalable, real-time, model-free, and takes fairness among different players into account.","A detailed case study is also presented for performance evaluation."],"url":"http://arxiv.org/abs/2307.10704v1"}
{"created":"2023-07-20 08:50:16","title":"Graphs in State-Space Models for Granger Causality in Climate Science","abstract":"Granger causality (GC) is often considered not an actual form of causality. Still, it is arguably the most widely used method to assess the predictability of a time series from another one. Granger causality has been widely used in many applied disciplines, from neuroscience and econometrics to Earth sciences. We revisit GC under a graphical perspective of state-space models. For that, we use GraphEM, a recently presented expectation-maximisation algorithm for estimating the linear matrix operator in the state equation of a linear-Gaussian state-space model. Lasso regularisation is included in the M-step, which is solved using a proximal splitting Douglas-Rachford algorithm. Experiments in toy examples and challenging climate problems illustrate the benefits of the proposed model and inference technique over standard Granger causality methods.","sentences":["Granger causality (GC) is often considered not an actual form of causality.","Still, it is arguably the most widely used method to assess the predictability of a time series from another one.","Granger causality has been widely used in many applied disciplines, from neuroscience and econometrics to Earth sciences.","We revisit GC under a graphical perspective of state-space models.","For that, we use GraphEM, a recently presented expectation-maximisation algorithm for estimating the linear matrix operator in the state equation of a linear-Gaussian state-space model.","Lasso regularisation is included in the M-step, which is solved using a proximal splitting Douglas-Rachford algorithm.","Experiments in toy examples and challenging climate problems illustrate the benefits of the proposed model and inference technique over standard Granger causality methods."],"url":"http://arxiv.org/abs/2307.10703v1"}
{"created":"2023-07-20 08:47:54","title":"A Constraint-based Recommender System via RDF Knowledge Graphs","abstract":"Knowledge graphs, represented in RDF, are able to model entities and their relations by means of ontologies. The use of knowledge graphs for information modeling has attracted interest in recent years. In recommender systems, items and users can be mapped and integrated into the knowledge graph, which can represent more links and relationships between users and items. Constraint-based recommender systems are based on the idea of explicitly exploiting deep recommendation knowledge through constraints to identify relevant recommendations. When combined with knowledge graphs, a constraint-based recommender system gains several benefits in terms of constraint sets. In this paper, we investigate and propose the construction of a constraint-based recommender system via RDF knowledge graphs applied to the vehicle purchase/sale domain. The results of our experiments show that the proposed approach is able to efficiently identify recommendations in accordance with user preferences.","sentences":["Knowledge graphs, represented in RDF, are able to model entities and their relations by means of ontologies.","The use of knowledge graphs for information modeling has attracted interest in recent years.","In recommender systems, items and users can be mapped and integrated into the knowledge graph, which can represent more links and relationships between users and items.","Constraint-based recommender systems are based on the idea of explicitly exploiting deep recommendation knowledge through constraints to identify relevant recommendations.","When combined with knowledge graphs, a constraint-based recommender system gains several benefits in terms of constraint sets.","In this paper, we investigate and propose the construction of a constraint-based recommender system via RDF knowledge graphs applied to the vehicle purchase/sale domain.","The results of our experiments show that the proposed approach is able to efficiently identify recommendations in accordance with user preferences."],"url":"http://arxiv.org/abs/2307.10702v1"}
{"created":"2023-07-20 08:45:00","title":"Large language models shape and are shaped by society: A survey of arXiv publication patterns","abstract":"There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis. Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022. We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors' research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration. We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors. LLM research is also shaped by social dynamics: we document gender and academic/industry disparities in the topics LLM authors focus on, and a US/China schism in the collaboration network. Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting to the necessity of sociotechnical lenses.","sentences":["There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis.","Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022.","We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors' research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration.","We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors.","LLM research is also shaped by social dynamics: we document gender and academic/industry disparities in the topics LLM authors focus on, and a US/China schism in the collaboration network.","Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting to the necessity of sociotechnical lenses."],"url":"http://arxiv.org/abs/2307.10700v1"}
{"created":"2023-07-20 08:39:20","title":"Reverse Knowledge Distillation: Training a Large Model using a Small One for Retinal Image Matching on Limited Data","abstract":"Retinal image matching plays a crucial role in monitoring disease progression and treatment response. However, datasets with matched keypoints between temporally separated pairs of images are not available in abundance to train transformer-based model. We propose a novel approach based on reverse knowledge distillation to train large models with limited data while preventing overfitting. Firstly, we propose architectural modifications to a CNN-based semi-supervised method called SuperRetina that help us improve its results on a publicly available dataset. Then, we train a computationally heavier model based on a vision transformer encoder using the lighter CNN-based model, which is counter-intuitive in the field knowledge-distillation research where training lighter models based on heavier ones is the norm. Surprisingly, such reverse knowledge distillation improves generalization even further. Our experiments suggest that high-dimensional fitting in representation space may prevent overfitting unlike training directly to match the final output. We also provide a public dataset with annotations for retinal image keypoint detection and matching to help the research community develop algorithms for retinal image applications.","sentences":["Retinal image matching plays a crucial role in monitoring disease progression and treatment response.","However, datasets with matched keypoints between temporally separated pairs of images are not available in abundance to train transformer-based model.","We propose a novel approach based on reverse knowledge distillation to train large models with limited data while preventing overfitting.","Firstly, we propose architectural modifications to a CNN-based semi-supervised method called SuperRetina that help us improve its results on a publicly available dataset.","Then, we train a computationally heavier model based on a vision transformer encoder using the lighter CNN-based model, which is counter-intuitive in the field knowledge-distillation research where training lighter models based on heavier ones is the norm.","Surprisingly, such reverse knowledge distillation improves generalization even further.","Our experiments suggest that high-dimensional fitting in representation space may prevent overfitting unlike training directly to match the final output.","We also provide a public dataset with annotations for retinal image keypoint detection and matching to help the research community develop algorithms for retinal image applications."],"url":"http://arxiv.org/abs/2307.10698v1"}
{"created":"2023-07-20 08:38:50","title":"SqueezerFaceNet: Reducing a Small Face Recognition CNN Even More Via Filter Pruning","abstract":"The widespread use of mobile devices for various digital services has created a need for reliable and real-time person authentication. In this context, facial recognition technologies have emerged as a dependable method for verifying users due to the prevalence of cameras in mobile devices and their integration into everyday applications. The rapid advancement of deep Convolutional Neural Networks (CNNs) has led to numerous face verification architectures. However, these models are often large and impractical for mobile applications, reaching sizes of hundreds of megabytes with millions of parameters. We address this issue by developing SqueezerFaceNet, a light face recognition network which less than 1M parameters. This is achieved by applying a network pruning method based on Taylor scores, where filters with small importance scores are removed iteratively. Starting from an already small network (of 1.24M) based on SqueezeNet, we show that it can be further reduced (up to 40%) without an appreciable loss in performance. To the best of our knowledge, we are the first to evaluate network pruning methods for the task of face recognition.","sentences":["The widespread use of mobile devices for various digital services has created a need for reliable and real-time person authentication.","In this context, facial recognition technologies have emerged as a dependable method for verifying users due to the prevalence of cameras in mobile devices and their integration into everyday applications.","The rapid advancement of deep Convolutional Neural Networks (CNNs) has led to numerous face verification architectures.","However, these models are often large and impractical for mobile applications, reaching sizes of hundreds of megabytes with millions of parameters.","We address this issue by developing SqueezerFaceNet, a light face recognition network which less than 1M parameters.","This is achieved by applying a network pruning method based on Taylor scores, where filters with small importance scores are removed iteratively.","Starting from an already small network (of 1.24M) based on SqueezeNet, we show that it can be further reduced (up to 40%) without an appreciable loss in performance.","To the best of our knowledge, we are the first to evaluate network pruning methods for the task of face recognition."],"url":"http://arxiv.org/abs/2307.10697v1"}
{"created":"2023-07-20 08:38:15","title":"SLPD: Slide-level Prototypical Distillation for WSIs","abstract":"Improving the feature representation ability is the foundation of many whole slide pathological image (WSIs) tasks. Recent works have achieved great success in pathological-specific self-supervised learning (SSL). However, most of them only focus on learning patch-level representations, thus there is still a gap between pretext and slide-level downstream tasks, e.g., subtyping, grading and staging. Aiming towards slide-level representations, we propose Slide-Level Prototypical Distillation (SLPD) to explore intra- and inter-slide semantic structures for context modeling on WSIs. Specifically, we iteratively perform intra-slide clustering for the regions (4096x4096 patches) within each WSI to yield the prototypes and encourage the region representations to be closer to the assigned prototypes. By representing each slide with its prototypes, we further select similar slides by the set distance of prototypes and assign the regions by cross-slide prototypes for distillation. SLPD achieves state-of-the-art results on multiple slide-level benchmarks and demonstrates that representation learning of semantic structures of slides can make a suitable proxy task for WSI analysis. Code will be available at https://github.com/Carboxy/SLPD.","sentences":["Improving the feature representation ability is the foundation of many whole slide pathological image (WSIs) tasks.","Recent works have achieved great success in pathological-specific self-supervised learning (SSL).","However, most of them only focus on learning patch-level representations, thus there is still a gap between pretext and slide-level downstream tasks, e.g., subtyping, grading and staging.","Aiming towards slide-level representations, we propose Slide-Level Prototypical Distillation (SLPD) to explore intra- and inter-slide semantic structures for context modeling on WSIs.","Specifically, we iteratively perform intra-slide clustering for the regions (4096x4096 patches) within each WSI to yield the prototypes and encourage the region representations to be closer to the assigned prototypes.","By representing each slide with its prototypes, we further select similar slides by the set distance of prototypes and assign the regions by cross-slide prototypes for distillation.","SLPD achieves state-of-the-art results on multiple slide-level benchmarks and demonstrates that representation learning of semantic structures of slides can make a suitable proxy task for WSI analysis.","Code will be available at https://github.com/Carboxy/SLPD."],"url":"http://arxiv.org/abs/2307.10696v1"}
{"created":"2023-07-20 08:38:01","title":"Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss","abstract":"Recently, denoising methods based on supervised learning have exhibited promising performance. However, their reliance on external datasets containing noisy-clean image pairs restricts their applicability. To address this limitation, researchers have focused on training denoising networks using solely a set of noisy inputs. To improve the feasibility of denoising procedures, in this study, we proposed a single-image self-supervised learning method in which only the noisy input image is used for network training. Gated convolution was used for feature extraction and no-reference image quality assessment was used for guiding the training process. Moreover, the proposed method sampled instances from the input image dataset using Bernoulli sampling with a certain dropout rate for training. The corresponding result was produced by averaging the generated predictions from various instances of the trained network with dropouts. The experimental results indicated that the proposed method achieved state-of-the-art denoising performance on both synthetic and real-world datasets. This highlights the effectiveness and practicality of our method as a potential solution for various noise removal tasks.","sentences":["Recently, denoising methods based on supervised learning have exhibited promising performance.","However, their reliance on external datasets containing noisy-clean image pairs restricts their applicability.","To address this limitation, researchers have focused on training denoising networks using solely a set of noisy inputs.","To improve the feasibility of denoising procedures, in this study, we proposed a single-image self-supervised learning method in which only the noisy input image is used for network training.","Gated convolution was used for feature extraction and no-reference image quality assessment was used for guiding the training process.","Moreover, the proposed method sampled instances from the input image dataset using Bernoulli sampling with a certain dropout rate for training.","The corresponding result was produced by averaging the generated predictions from various instances of the trained network with dropouts.","The experimental results indicated that the proposed method achieved state-of-the-art denoising performance on both synthetic and real-world datasets.","This highlights the effectiveness and practicality of our method as a potential solution for various noise removal tasks."],"url":"http://arxiv.org/abs/2307.10695v1"}
{"created":"2023-07-20 08:37:14","title":"Towards an architectural framework for intelligent virtual agents using probabilistic programming","abstract":"We present a new framework called KorraAI for conceiving and building embodied conversational agents (ECAs). Our framework models ECAs' behavior considering contextual information, for example, about environment and interaction time, and uncertain information provided by the human interaction partner. Moreover, agents built with KorraAI can show proactive behavior, as they can initiate interactions with human partners. For these purposes, KorraAI exploits probabilistic programming. Probabilistic models in KorraAI are used to model its behavior and interactions with the user. They enable adaptation to the user's preferences and a certain degree of indeterminism in the ECAs to achieve more natural behavior. Human-like internal states, such as moods, preferences, and emotions (e.g., surprise), can be modeled in KorraAI with distributions and Bayesian networks. These models can evolve over time, even without interaction with the user. ECA models are implemented as plugins and share a common interface. This enables ECA designers to focus more on the character they are modeling and less on the technical details, as well as to store and exchange ECA models. Several applications of KorraAI ECAs are possible, such as virtual sales agents, customer service agents, virtual companions, entertainers, or tutors.","sentences":["We present a new framework called KorraAI for conceiving and building embodied conversational agents (ECAs).","Our framework models ECAs' behavior considering contextual information, for example, about environment and interaction time, and uncertain information provided by the human interaction partner.","Moreover, agents built with KorraAI can show proactive behavior, as they can initiate interactions with human partners.","For these purposes, KorraAI exploits probabilistic programming.","Probabilistic models in KorraAI are used to model its behavior and interactions with the user.","They enable adaptation to the user's preferences and a certain degree of indeterminism in the ECAs to achieve more natural behavior.","Human-like internal states, such as moods, preferences, and emotions (e.g., surprise), can be modeled in KorraAI with distributions and Bayesian networks.","These models can evolve over time, even without interaction with the user.","ECA models are implemented as plugins and share a common interface.","This enables ECA designers to focus more on the character they are modeling and less on the technical details, as well as to store and exchange ECA models.","Several applications of KorraAI ECAs are possible, such as virtual sales agents, customer service agents, virtual companions, entertainers, or tutors."],"url":"http://arxiv.org/abs/2307.10693v1"}
{"created":"2023-07-20 08:35:13","title":"Bridging Intelligence and Instinct: A New Control Paradigm for Autonomous Robots","abstract":"As the advent of artificial general intelligence (AGI) progresses at a breathtaking pace, the application of large language models (LLMs) as AI Agents in robotics remains in its nascent stage. A significant concern that hampers the seamless integration of these AI Agents into robotics is the unpredictability of the content they generate, a phenomena known as ``hallucination''. Drawing inspiration from biological neural systems, we propose a novel, layered architecture for autonomous robotics, bridging AI agent intelligence and robot instinct. In this context, we define Robot Instinct as the innate or learned set of responses and priorities in an autonomous robotic system that ensures survival-essential tasks, such as safety assurance and obstacle avoidance, are carried out in a timely and effective manner. This paradigm harmoniously combines the intelligence of LLMs with the instinct of robotic behaviors, contributing to a more safe and versatile autonomous robotic system. As a case study, we illustrate this paradigm within the context of a mobile robot, demonstrating its potential to significantly enhance autonomous robotics and enabling a future where robots can operate independently and safely across diverse environments.","sentences":["As the advent of artificial general intelligence (AGI) progresses at a breathtaking pace, the application of large language models (LLMs) as AI Agents in robotics remains in its nascent stage.","A significant concern that hampers the seamless integration of these AI Agents into robotics is the unpredictability of the content they generate, a phenomena known as ``hallucination''.","Drawing inspiration from biological neural systems, we propose a novel, layered architecture for autonomous robotics, bridging AI agent intelligence and robot instinct.","In this context, we define Robot Instinct as the innate or learned set of responses and priorities in an autonomous robotic system that ensures survival-essential tasks, such as safety assurance and obstacle avoidance, are carried out in a timely and effective manner.","This paradigm harmoniously combines the intelligence of LLMs with the instinct of robotic behaviors, contributing to a more safe and versatile autonomous robotic system.","As a case study, we illustrate this paradigm within the context of a mobile robot, demonstrating its potential to significantly enhance autonomous robotics and enabling a future where robots can operate independently and safely across diverse environments."],"url":"http://arxiv.org/abs/2307.10690v1"}
{"created":"2023-07-20 08:30:56","title":"Bounded Combinatorial Reconfiguration with Answer Set Programming","abstract":"We develop an approach called bounded combinatorial reconfiguration for solving combinatorial reconfiguration problems based on Answer Set Programming (ASP). The general task is to study the solution spaces of source combinatorial problems and to decide whether or not there are sequences of feasible solutions that have special properties. The resulting recongo solver covers all metrics of the solver track in the most recent international competition on combinatorial reconfiguration (CoRe Challenge 2022). recongo ranked first in the shortest metric of the single-engine solvers track. In this paper, we present the design and implementation of bounded combinatorial reconfiguration, and present an ASP encoding of the independent set reconfiguration problem that is one of the most studied combinatorial reconfiguration problems. Finally, we present empirical analysis considering all instances of CoRe Challenge 2022.","sentences":["We develop an approach called bounded combinatorial reconfiguration for solving combinatorial reconfiguration problems based on Answer Set Programming (ASP).","The general task is to study the solution spaces of source combinatorial problems and to decide whether or not there are sequences of feasible solutions that have special properties.","The resulting recongo solver covers all metrics of the solver track in the most recent international competition on combinatorial reconfiguration (CoRe Challenge 2022).","recongo ranked first in the shortest metric of the single-engine solvers track.","In this paper, we present the design and implementation of bounded combinatorial reconfiguration, and present an ASP encoding of the independent set reconfiguration problem that is one of the most studied combinatorial reconfiguration problems.","Finally, we present empirical analysis considering all instances of CoRe Challenge 2022."],"url":"http://arxiv.org/abs/2307.10688v1"}
{"created":"2023-07-20 08:25:38","title":"Pre-train, Adapt and Detect: Multi-Task Adapter Tuning for Camouflaged Object Detection","abstract":"Camouflaged object detection (COD), aiming to segment camouflaged objects which exhibit similar patterns with the background, is a challenging task. Most existing works are dedicated to establishing specialized modules to identify camouflaged objects with complete and fine details, while the boundary can not be well located for the lack of object-related semantics. In this paper, we propose a novel ``pre-train, adapt and detect\" paradigm to detect camouflaged objects. By introducing a large pre-trained model, abundant knowledge learned from massive multi-modal data can be directly transferred to COD. A lightweight parallel adapter is inserted to adjust the features suitable for the downstream COD task. Extensive experiments on four challenging benchmark datasets demonstrate that our method outperforms existing state-of-the-art COD models by large margins. Moreover, we design a multi-task learning scheme for tuning the adapter to exploit the shareable knowledge across different semantic classes. Comprehensive experimental results showed that the generalization ability of our model can be substantially improved with multi-task adapter initialization on source tasks and multi-task adaptation on target tasks.","sentences":["Camouflaged object detection (COD), aiming to segment camouflaged objects which exhibit similar patterns with the background, is a challenging task.","Most existing works are dedicated to establishing specialized modules to identify camouflaged objects with complete and fine details, while the boundary can not be well located for the lack of object-related semantics.","In this paper, we propose a novel ``pre-train, adapt and detect\" paradigm to detect camouflaged objects.","By introducing a large pre-trained model, abundant knowledge learned from massive multi-modal data can be directly transferred to COD.","A lightweight parallel adapter is inserted to adjust the features suitable for the downstream COD task.","Extensive experiments on four challenging benchmark datasets demonstrate that our method outperforms existing state-of-the-art COD models by large margins.","Moreover, we design a multi-task learning scheme for tuning the adapter to exploit the shareable knowledge across different semantic classes.","Comprehensive experimental results showed that the generalization ability of our model can be substantially improved with multi-task adapter initialization on source tasks and multi-task adaptation on target tasks."],"url":"http://arxiv.org/abs/2307.10685v1"}
{"created":"2023-07-20 08:14:06","title":"A Personalized Recommender System Based-on Knowledge Graph Embeddings","abstract":"Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies. The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems. By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations. In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain. The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users.","sentences":["Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies.","The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems.","By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations.","In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain.","The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users."],"url":"http://arxiv.org/abs/2307.10680v1"}
{"created":"2023-07-20 07:57:14","title":"Deep learning for classification of noisy QR codes","abstract":"We wish to define the limits of a classical classification model based on deep learning when applied to abstract images, which do not represent visually identifiable objects.QR codes (Quick Response codes) fall into this category of abstract images: one bit corresponding to one encoded character, QR codes were not designed to be decoded manually. To understand the limitations of a deep learning-based model for abstract image classification, we train an image classification model on QR codes generated from information obtained when reading a health pass. We compare a classification model with a classical (deterministic) decoding method in the presence of noise. This study allows us to conclude that a model based on deep learning can be relevant for the understanding of abstract images.","sentences":["We wish to define the limits of a classical classification model based on deep learning when applied to abstract images, which do not represent visually identifiable objects.","QR codes (Quick Response codes) fall into this category of abstract images: one bit corresponding to one encoded character, QR codes were not designed to be decoded manually.","To understand the limitations of a deep learning-based model for abstract image classification, we train an image classification model on QR codes generated from information obtained when reading a health pass.","We compare a classification model with a classical (deterministic) decoding method in the presence of noise.","This study allows us to conclude that a model based on deep learning can be relevant for the understanding of abstract images."],"url":"http://arxiv.org/abs/2307.10677v1"}
{"created":"2023-07-20 07:55:20","title":"2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network Visualisations in Virtual Reality","abstract":"Relational information between different types of entities is often modelled by a multilayer network (MLN) -- a network with subnetworks represented by layers. The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question. Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis. Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays. We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements. The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers. We found no clear overall winner. However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs.","sentences":["Relational information between different types of entities is often modelled by a multilayer network (MLN) -- a network with subnetworks represented by layers.","The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question.","Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis.","Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays.","We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements.","The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers.","We found no clear overall winner.","However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs."],"url":"http://arxiv.org/abs/2307.10674v1"}
{"created":"2023-07-20 07:53:11","title":"A parameterized approximation scheme for the 2D-Knapsack problem with wide items","abstract":"We study a natural geometric variant of the classic Knapsack problem called 2D-Knapsack: we are given a set of axis-parallel rectangles and a rectangular bounding box, and the goal is to pack as many of these rectangles inside the box without overlap. Naturally, this problem is NP-complete. Recently, Grandoni et al. [ESA'19] showed that it is also W[1]-hard when parameterized by the size $k$ of the sought packing, and they presented a parameterized approximation scheme (PAS) for the variant where we are allowed to rotate the rectangles by 90{\\textdegree} before packing them into the box. Obtaining a PAS for the original 2D-Knapsack problem, without rotation, appears to be a challenging open question. In this work, we make progress towards this goal by showing a PAS under the following assumptions: - both the box and all the input rectangles have integral, polynomially bounded sidelengths; - every input rectangle is wide -- its width is greater than its height; and - the aspect ratio of the box is bounded by a constant.Our approximation scheme relies on a mix of various parameterized and approximation techniques, including color coding, rounding, and searching for a structured near-optimum packing using dynamic programming.","sentences":["We study a natural geometric variant of the classic Knapsack problem called 2D-Knapsack: we are given a set of axis-parallel rectangles and a rectangular bounding box, and the goal is to pack as many of these rectangles inside the box without overlap.","Naturally, this problem is NP-complete.","Recently, Grandoni et al.","[ESA'19] showed that it is also W[1]-hard when parameterized by the size $k$ of the sought packing, and they presented a parameterized approximation scheme (PAS) for the variant where we are allowed to rotate the rectangles by 90{\\textdegree} before packing them into the box.","Obtaining a PAS for the original 2D-Knapsack problem, without rotation, appears to be a challenging open question.","In this work, we make progress towards this goal by showing a PAS under the following assumptions: - both the box and all the input rectangles have integral, polynomially bounded sidelengths; - every input rectangle is wide -- its width is greater than its height; and - the aspect ratio of the box is bounded by a constant.","Our approximation scheme relies on a mix of various parameterized and approximation techniques, including color coding, rounding, and searching for a structured near-optimum packing using dynamic programming."],"url":"http://arxiv.org/abs/2307.10672v1"}
{"created":"2023-07-20 07:47:08","title":"A Dataset and Strong Baselines for Classification of Czech News Texts","abstract":"Pre-trained models for Czech Natural Language Processing are often evaluated on purely linguistic tasks (POS tagging, parsing, NER) and relatively simple classification tasks such as sentiment classification or article classification from a single news source. As an alternative, we present CZEch~NEws~Classification~dataset (CZE-NEC), one of the largest Czech classification datasets, composed of news articles from various sources spanning over twenty years, which allows a more rigorous evaluation of such models. We define four classification tasks: news source, news category, inferred author's gender, and day of the week. To verify the task difficulty, we conducted a human evaluation, which revealed that human performance lags behind strong machine-learning baselines built upon pre-trained transformer models. Furthermore, we show that language-specific pre-trained encoder analysis outperforms selected commercially available large-scale generative language models.","sentences":["Pre-trained models for Czech Natural Language Processing are often evaluated on purely linguistic tasks (POS tagging, parsing, NER) and relatively simple classification tasks such as sentiment classification or article classification from a single news source.","As an alternative, we present CZEch~NEws~Classification~dataset (CZE-NEC), one of the largest Czech classification datasets, composed of news articles from various sources spanning over twenty years, which allows a more rigorous evaluation of such models.","We define four classification tasks: news source, news category, inferred author's gender, and day of the week.","To verify the task difficulty, we conducted a human evaluation, which revealed that human performance lags behind strong machine-learning baselines built upon pre-trained transformer models.","Furthermore, we show that language-specific pre-trained encoder analysis outperforms selected commercially available large-scale generative language models."],"url":"http://arxiv.org/abs/2307.10666v1"}
{"created":"2023-07-20 07:46:34","title":"Lighting up NeRF via Unsupervised Decomposition and Enhancement","abstract":"Neural Radiance Field (NeRF) is a promising approach for synthesizing novel views, given a set of images and the corresponding camera poses of a scene. However, images photographed from a low-light scene can hardly be used to train a NeRF model to produce high-quality results, due to their low pixel intensities, heavy noise, and color distortion. Combining existing low-light image enhancement methods with NeRF methods also does not work well due to the view inconsistency caused by the individual 2D enhancement process. In this paper, we propose a novel approach, called Low-Light NeRF (or LLNeRF), to enhance the scene representation and synthesize normal-light novel views directly from sRGB low-light images in an unsupervised manner. The core of our approach is a decomposition of radiance field learning, which allows us to enhance the illumination, reduce noise and correct the distorted colors jointly with the NeRF optimization process. Our method is able to produce novel view images with proper lighting and vivid colors and details, given a collection of camera-finished low dynamic range (8-bits/channel) images from a low-light scene. Experiments demonstrate that our method outperforms existing low-light enhancement methods and NeRF methods.","sentences":["Neural Radiance Field (NeRF) is a promising approach for synthesizing novel views, given a set of images and the corresponding camera poses of a scene.","However, images photographed from a low-light scene can hardly be used to train a NeRF model to produce high-quality results, due to their low pixel intensities, heavy noise, and color distortion.","Combining existing low-light image enhancement methods with NeRF methods also does not work well due to the view inconsistency caused by the individual 2D enhancement process.","In this paper, we propose a novel approach, called Low-Light NeRF (or LLNeRF), to enhance the scene representation and synthesize normal-light novel views directly from sRGB low-light images in an unsupervised manner.","The core of our approach is a decomposition of radiance field learning, which allows us to enhance the illumination, reduce noise and correct the distorted colors jointly with the NeRF optimization process.","Our method is able to produce novel view images with proper lighting and vivid colors and details, given a collection of camera-finished low dynamic range (8-bits/channel) images from a low-light scene.","Experiments demonstrate that our method outperforms existing low-light enhancement methods and NeRF methods."],"url":"http://arxiv.org/abs/2307.10664v1"}
{"created":"2023-07-20 07:43:04","title":"ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum","abstract":"Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution. Understanding and optimizing the performance of such complex Edge-to-Cloud workflows is challenging. Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions. However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge. We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads. We further integrate ProvLight into the E2Clab framework to enable workflow provenance capture across the Edge-to-Cloud Continuum. This integration makes E2Clab a promising platform for the performance optimization of applications through reproducible experiments.We validate ProvLight at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed. Evaluations show that ProvLight outperforms state-of-the-art systems like ProvLake and DfAnalyzer in resource-constrained devices. ProvLight is 26 -- 37x faster to capture and transmit provenance data; uses 5 -- 7x less CPU; 2x less memory; transmits 2x less data; and consumes 2 -- 2.5x less energy. ProvLight and E2Clab are available as open-source tools.","sentences":["Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution.","Understanding and optimizing the performance of such complex Edge-to-Cloud workflows is challenging.","Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions.","However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.","To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge.","We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads.","We further integrate ProvLight into the E2Clab framework to enable workflow provenance capture across the Edge-to-Cloud Continuum.","This integration makes E2Clab a promising platform for the performance optimization of applications through reproducible experiments.","We validate ProvLight at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed.","Evaluations show that ProvLight outperforms state-of-the-art systems like ProvLake and DfAnalyzer in resource-constrained devices.","ProvLight is 26 -- 37x faster to capture and transmit provenance data; uses 5 -- 7x less CPU; 2x less memory; transmits 2x less data; and consumes 2 -- 2.5x less energy.","ProvLight and E2Clab are available as open-source tools."],"url":"http://arxiv.org/abs/2307.10658v1"}
{"created":"2023-07-20 07:35:42","title":"A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency","abstract":"Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties. Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share privacy-preserving information without exposing private datasets. This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants. Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works. However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information. In this paper, we present a systematic survey from a new perspective, i.e., what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency. This survey differs from previous ones due to four distinct contributions. First, we present a new taxonomy of FL methods in terms of the sharing methods, which includes three categories of shared information: model sharing, synthetic data sharing, and knowledge sharing. Second, we analyze the vulnerability of different sharing methods to privacy attacks and review the defense mechanisms that provide certain privacy guarantees. Third, we conduct extensive experiments to compare the performance and communication overhead of various sharing methods in FL. Besides, we assess the potential privacy leakage through model inversion and membership inference attacks, while comparing the effectiveness of various defense approaches. Finally, we discuss potential deficiencies in current methods and outline future directions for improvement.","sentences":["Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties.","Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share privacy-preserving information without exposing private datasets.","This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants.","Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works.","However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information.","In this paper, we present a systematic survey from a new perspective, i.e., what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency.","This survey differs from previous ones due to four distinct contributions.","First, we present a new taxonomy of FL methods in terms of the sharing methods, which includes three categories of shared information: model sharing, synthetic data sharing, and knowledge sharing.","Second, we analyze the vulnerability of different sharing methods to privacy attacks and review the defense mechanisms that provide certain privacy guarantees.","Third, we conduct extensive experiments to compare the performance and communication overhead of various sharing methods in FL.","Besides, we assess the potential privacy leakage through model inversion and membership inference attacks, while comparing the effectiveness of various defense approaches.","Finally, we discuss potential deficiencies in current methods and outline future directions for improvement."],"url":"http://arxiv.org/abs/2307.10655v1"}
{"created":"2023-07-20 07:35:15","title":"Conditional expectation network for SHAP","abstract":"A very popular model-agnostic technique for explaining predictive models is the SHapley Additive exPlanation (SHAP). The two most popular versions of SHAP are a conditional expectation version and an unconditional expectation version (the latter is also known as interventional SHAP). Except for tree-based methods, usually the unconditional version is used (for computational reasons). We provide a (surrogate) neural network approach which allows us to efficiently calculate the conditional version for both neural networks and other regression models, and which properly considers the dependence structure in the feature components. This proposal is also useful to provide drop1 and anova analyses in complex regression models which are similar to their generalized linear model (GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart that considers the right dependence structure in the feature components.","sentences":["A very popular model-agnostic technique for explaining predictive models is the SHapley Additive exPlanation (SHAP).","The two most popular versions of SHAP are a conditional expectation version and an unconditional expectation version (the latter is also known as interventional SHAP).","Except for tree-based methods, usually the unconditional version is used (for computational reasons).","We provide a (surrogate) neural network approach which allows us to efficiently calculate the conditional version for both neural networks and other regression models, and which properly considers the dependence structure in the feature components.","This proposal is also useful to provide drop1 and anova analyses in complex regression models which are similar to their generalized linear model (GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart that considers the right dependence structure in the feature components."],"url":"http://arxiv.org/abs/2307.10654v1"}
{"created":"2023-07-20 07:33:36","title":"Refining the Optimization Target for Automatic Univariate Time Series Anomaly Detection in Monitoring Services","abstract":"Time series anomaly detection is crucial for industrial monitoring services that handle a large volume of data, aiming to ensure reliability and optimize system performance. Existing methods often require extensive labeled resources and manual parameter selection, highlighting the need for automation. This paper proposes a comprehensive framework for automatic parameter optimization in time series anomaly detection models. The framework introduces three optimization targets: prediction score, shape score, and sensitivity score, which can be easily adapted to different model backbones without prior knowledge or manual labeling efforts. The proposed framework has been successfully applied online for over six months, serving more than 50,000 time series every minute. It simplifies the user's experience by requiring only an expected sensitive value, offering a user-friendly interface, and achieving desired detection results. Extensive evaluations conducted on public datasets and comparison with other methods further confirm the effectiveness of the proposed framework.","sentences":["Time series anomaly detection is crucial for industrial monitoring services that handle a large volume of data, aiming to ensure reliability and optimize system performance.","Existing methods often require extensive labeled resources and manual parameter selection, highlighting the need for automation.","This paper proposes a comprehensive framework for automatic parameter optimization in time series anomaly detection models.","The framework introduces three optimization targets: prediction score, shape score, and sensitivity score, which can be easily adapted to different model backbones without prior knowledge or manual labeling efforts.","The proposed framework has been successfully applied online for over six months, serving more than 50,000 time series every minute.","It simplifies the user's experience by requiring only an expected sensitive value, offering a user-friendly interface, and achieving desired detection results.","Extensive evaluations conducted on public datasets and comparison with other methods further confirm the effectiveness of the proposed framework."],"url":"http://arxiv.org/abs/2307.10653v1"}
{"created":"2023-07-20 07:33:30","title":"Exploring the Landscape of Natural Language Processing Research","abstract":"As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing amount of research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent to this day. Contributing to closing this gap, we have systematically classified and analyzed research papers included in the ACL Anthology. As a result, we present a structured overview of the research landscape, provide a taxonomy of fields-of-study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work.","sentences":["As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years.","Given the increasing amount of research work in this area, several NLP-related approaches have been surveyed in the research community.","However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent to this day.","Contributing to closing this gap, we have systematically classified and analyzed research papers included in the ACL Anthology.","As a result, we present a structured overview of the research landscape, provide a taxonomy of fields-of-study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work."],"url":"http://arxiv.org/abs/2307.10652v1"}
{"created":"2023-07-20 07:30:27","title":"Language-Enhanced Session-Based Recommendation with Decoupled Contrastive Learning","abstract":"Session-based recommendation techniques aim to capture dynamic user behavior by analyzing past interactions. However, existing methods heavily rely on historical item ID sequences to extract user preferences, leading to challenges such as popular bias and cold-start problems. In this paper, we propose a hybrid multimodal approach for session-based recommendation to address these challenges. Our approach combines different modalities, including textual content and item IDs, leveraging the complementary nature of these modalities using CatBoost. To learn universal item representations, we design a language representation-based item retrieval architecture that extracts features from the textual content utilizing pre-trained language models. Furthermore, we introduce a novel Decoupled Contrastive Learning method to enhance the effectiveness of the language representation. This technique decouples the sequence representation and item representation space, facilitating bidirectional alignment through dual-queue contrastive learning. Simultaneously, the momentum queue provides a large number of negative samples, effectively enhancing the effectiveness of contrastive learning. Our approach yielded competitive results, securing a 5th place ranking in KDD CUP 2023 Task 1. We have released the source code and pre-trained models associated with this work.","sentences":["Session-based recommendation techniques aim to capture dynamic user behavior by analyzing past interactions.","However, existing methods heavily rely on historical item ID sequences to extract user preferences, leading to challenges such as popular bias and cold-start problems.","In this paper, we propose a hybrid multimodal approach for session-based recommendation to address these challenges.","Our approach combines different modalities, including textual content and item IDs, leveraging the complementary nature of these modalities using CatBoost.","To learn universal item representations, we design a language representation-based item retrieval architecture that extracts features from the textual content utilizing pre-trained language models.","Furthermore, we introduce a novel Decoupled Contrastive Learning method to enhance the effectiveness of the language representation.","This technique decouples the sequence representation and item representation space, facilitating bidirectional alignment through dual-queue contrastive learning.","Simultaneously, the momentum queue provides a large number of negative samples, effectively enhancing the effectiveness of contrastive learning.","Our approach yielded competitive results, securing a 5th place ranking in KDD CUP 2023 Task 1.","We have released the source code and pre-trained models associated with this work."],"url":"http://arxiv.org/abs/2307.10650v1"}
{"created":"2023-07-20 07:23:15","title":"Data-Driven Latency Probability Prediction for Wireless Networks: Focusing on Tail Probabilities","abstract":"With the emergence of new application areas, such as cyber-physical systems and human-in-the-loop applications, there is a need to guarantee a certain level of end-to-end network latency with extremely high reliability, e.g., 99.999%. While mechanisms specified under IEEE 802.1as time-sensitive networking (TSN) can be used to achieve these requirements for switched Ethernet networks, implementing TSN mechanisms in wireless networks is challenging due to their stochastic nature. To conform the wireless link to a reliability level of 99.999%, the behavior of extremely rare outliers in the latency probability distribution, or the tail of the distribution, must be analyzed and controlled. This work proposes predicting the tail of the latency distribution using state-of-the-art data-driven approaches, such as mixture density networks (MDN) and extreme value mixture models, to estimate the likelihood of rare latencies conditioned on the network parameters, which can be used to make more informed decisions in wireless transmission. Actual latency measurements of IEEE 802.11g (WiFi), commercial private and a software-defined 5G network are used to benchmark the proposed approaches and evaluate their sensitivities concerning the tail probabilities.","sentences":["With the emergence of new application areas, such as cyber-physical systems and human-in-the-loop applications, there is a need to guarantee a certain level of end-to-end network latency with extremely high reliability, e.g., 99.999%.","While mechanisms specified under IEEE 802.1as time-sensitive networking (TSN) can be used to achieve these requirements for switched Ethernet networks, implementing TSN mechanisms in wireless networks is challenging due to their stochastic nature.","To conform the wireless link to a reliability level of 99.999%, the behavior of extremely rare outliers in the latency probability distribution, or the tail of the distribution, must be analyzed and controlled.","This work proposes predicting the tail of the latency distribution using state-of-the-art data-driven approaches, such as mixture density networks (MDN) and extreme value mixture models, to estimate the likelihood of rare latencies conditioned on the network parameters, which can be used to make more informed decisions in wireless transmission.","Actual latency measurements of IEEE 802.11g (WiFi), commercial private and a software-defined 5G network are used to benchmark the proposed approaches and evaluate their sensitivities concerning the tail probabilities."],"url":"http://arxiv.org/abs/2307.10648v1"}
{"created":"2023-07-20 07:16:05","title":"On Enhancing Reliability in B5G NTNs with Packet Duplication via Multi-Connectivity","abstract":"Non-Terrestrial Networks (NTNs) can be used to provide ubiquitous 5G and beyond services to un(der)served areas. To ensure reliable communication in such networks, packet duplication (PD) through multi-connectivity is a promising solution. However, the existing PD schemes developed for terrestrial environments may not be reactive enough for the NTN environment where propagation delays are significantly longer. This paper proposes a dynamic PD activation scheme for NTNs based on hybrid automatic repeat request feedback. The scheme aims to reduce the number of duplicated packets while maintaining high reliability. To evaluate the proposed scheme, simulations are conducted in a scenario with two transparent payload lowearth orbit satellites. The results show a significant reduction of 87.2% in the number of duplicated packets compared to blind duplication, with only marginal compromise in reliability.","sentences":["Non-Terrestrial Networks (NTNs) can be used to provide ubiquitous 5G and beyond services to un(der)served areas.","To ensure reliable communication in such networks, packet duplication (PD) through multi-connectivity is a promising solution.","However, the existing PD schemes developed for terrestrial environments may not be reactive enough for the NTN environment where propagation delays are significantly longer.","This paper proposes a dynamic PD activation scheme for NTNs based on hybrid automatic repeat request feedback.","The scheme aims to reduce the number of duplicated packets while maintaining high reliability.","To evaluate the proposed scheme, simulations are conducted in a scenario with two transparent payload lowearth orbit satellites.","The results show a significant reduction of 87.2% in the number of duplicated packets compared to blind duplication, with only marginal compromise in reliability."],"url":"http://arxiv.org/abs/2307.10646v1"}
{"created":"2023-07-20 07:14:58","title":"Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions","abstract":"Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few. In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them. The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases. In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions. Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of centered normal distributions. We show that the projective Hilbert distance on the cone yields a metric on the embedded normal submanifold and we pullback that cone distance with its associated straight line Hilbert cone geodesics to obtain a distance and smooth paths between normal distributions. Compared to the Fisher-Rao distance approximation, the pullback Hilbert cone distance is computationally light since it requires to compute only the extreme minimal and maximal eigenvalues of matrices. Finally, we show how to use those distances in clustering tasks.","sentences":["Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few.","In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them.","The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases.","In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions.","Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of centered normal distributions.","We show that the projective Hilbert distance on the cone yields a metric on the embedded normal submanifold and we pullback that cone distance with its associated straight line Hilbert cone geodesics to obtain a distance and smooth paths between normal distributions.","Compared to the Fisher-Rao distance approximation, the pullback Hilbert cone distance is computationally light since it requires to compute only the extreme minimal and maximal eigenvalues of matrices.","Finally, we show how to use those distances in clustering tasks."],"url":"http://arxiv.org/abs/2307.10644v1"}
{"created":"2023-07-20 07:12:56","title":"RetouchingFFHQ: A Large-scale Dataset for Fine-grained Face Retouching Detection","abstract":"The widespread use of face retouching filters on short-video platforms has raised concerns about the authenticity of digital appearances and the impact of deceptive advertising. To address these issues, there is a pressing need to develop advanced face retouching techniques. However, the lack of large-scale and fine-grained face retouching datasets has been a major obstacle to progress in this field. In this paper, we introduce RetouchingFFHQ, a large-scale and fine-grained face retouching dataset that contains over half a million conditionally-retouched images. RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization. By including four typical types of face retouching operations and different retouching levels, we extend the binary face retouching detection into a fine-grained, multi-retouching type, and multi-retouching level estimation problem. Additionally, we propose a Multi-granularity Attention Module (MAM) as a plugin for CNN backbones for enhanced cross-scale representation learning. Extensive experiments using different baselines as well as our proposed method on RetouchingFFHQ show decent performance on face retouching detection. With the proposed new dataset, we believe there is great potential for future work to tackle the challenging problem of real-world fine-grained face retouching detection.","sentences":["The widespread use of face retouching filters on short-video platforms has raised concerns about the authenticity of digital appearances and the impact of deceptive advertising.","To address these issues, there is a pressing need to develop advanced face retouching techniques.","However, the lack of large-scale and fine-grained face retouching datasets has been a major obstacle to progress in this field.","In this paper, we introduce RetouchingFFHQ, a large-scale and fine-grained face retouching dataset that contains over half a million conditionally-retouched images.","RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization.","By including four typical types of face retouching operations and different retouching levels, we extend the binary face retouching detection into a fine-grained, multi-retouching type, and multi-retouching level estimation problem.","Additionally, we propose a Multi-granularity Attention Module (MAM) as a plugin for CNN backbones for enhanced cross-scale representation learning.","Extensive experiments using different baselines as well as our proposed method on RetouchingFFHQ show decent performance on face retouching detection.","With the proposed new dataset, we believe there is great potential for future work to tackle the challenging problem of real-world fine-grained face retouching detection."],"url":"http://arxiv.org/abs/2307.10642v1"}
{"created":"2023-07-20 07:08:25","title":"Improving Semantic Similarity Measure Within a Recommender System Based-on RDF Graphs","abstract":"In today's era of information explosion, more users are becoming more reliant upon recommender systems to have better advice, suggestions, or inspire them. The measure of the semantic relatedness or likeness between terms, words, or text data plays an important role in different applications dealing with textual data, as in a recommender system. Over the past few years, many ontologies have been developed and used as a form of structured representation of knowledge bases for information systems. The measure of semantic similarity from ontology has developed by several methods. In this paper, we propose and carry on an approach for the improvement of semantic similarity calculations within a recommender system based-on RDF graphs.","sentences":["In today's era of information explosion, more users are becoming more reliant upon recommender systems to have better advice, suggestions, or inspire them.","The measure of the semantic relatedness or likeness between terms, words, or text data plays an important role in different applications dealing with textual data, as in a recommender system.","Over the past few years, many ontologies have been developed and used as a form of structured representation of knowledge bases for information systems.","The measure of semantic similarity from ontology has developed by several methods.","In this paper, we propose and carry on an approach for the improvement of semantic similarity calculations within a recommender system based-on RDF graphs."],"url":"http://arxiv.org/abs/2307.10639v1"}
{"created":"2023-07-20 07:08:24","title":"Quantized Feature Distillation for Network Quantization","abstract":"Neural network quantization aims to accelerate and trim full-precision neural network models by using low bit approximations. Methods adopting the quantization aware training (QAT) paradigm have recently seen a rapid growth, but are often conceptually complicated. This paper proposes a novel and highly effective QAT method, quantized feature distillation (QFD). QFD first trains a quantized (or binarized) representation as the teacher, then quantize the network using knowledge distillation (KD). Quantitative results show that QFD is more flexible and effective (i.e., quantization friendly) than previous quantization methods. QFD surpasses existing methods by a noticeable margin on not only image classification but also object detection, albeit being much simpler. Furthermore, QFD quantizes ViT and Swin-Transformer on MS-COCO detection and segmentation, which verifies its potential in real world deployment. To the best of our knowledge, this is the first time that vision transformers have been quantized in object detection and image segmentation tasks.","sentences":["Neural network quantization aims to accelerate and trim full-precision neural network models by using low bit approximations.","Methods adopting the quantization aware training (QAT) paradigm have recently seen a rapid growth, but are often conceptually complicated.","This paper proposes a novel and highly effective QAT method, quantized feature distillation (QFD).","QFD first trains a quantized (or binarized) representation as the teacher, then quantize the network using knowledge distillation (KD).","Quantitative results show that QFD is more flexible and effective (i.e., quantization friendly) than previous quantization methods.","QFD surpasses existing methods by a noticeable margin on not only image classification but also object detection, albeit being much simpler.","Furthermore, QFD quantizes ViT and Swin-Transformer on MS-COCO detection and segmentation, which verifies its potential in real world deployment.","To the best of our knowledge, this is the first time that vision transformers have been quantized in object detection and image segmentation tasks."],"url":"http://arxiv.org/abs/2307.10638v1"}
{"created":"2023-07-20 07:04:16","title":"Learning and Evaluating Human Preferences for Conversational Head Generation","abstract":"A reliable and comprehensive evaluation metric that aligns with manual preference assessments is crucial for conversational head video synthesis method development. Existing quantitative evaluations often fail to capture the full complexity of human preference, as they only consider limited evaluation dimensions. Qualitative evaluations and user studies offer a solution but are time-consuming and labor-intensive. This limitation hinders the advancement of conversational head generation algorithms and systems. In this paper, we propose a novel learning-based evaluation metric named Preference Score (PS) for fitting human preference according to the quantitative evaluations across different dimensions. PS can serve as a quantitative evaluation without the need for human annotation. Experimental results validate the superiority of Preference Score in aligning with human perception, and also demonstrates robustness and generalizability to unseen data, making it a valuable tool for advancing conversation head generation. We expect this metric could facilitate new advances in conversational head generation.","sentences":["A reliable and comprehensive evaluation metric that aligns with manual preference assessments is crucial for conversational head video synthesis method development.","Existing quantitative evaluations often fail to capture the full complexity of human preference, as they only consider limited evaluation dimensions.","Qualitative evaluations and user studies offer a solution but are time-consuming and labor-intensive.","This limitation hinders the advancement of conversational head generation algorithms and systems.","In this paper, we propose a novel learning-based evaluation metric named Preference Score (PS) for fitting human preference according to the quantitative evaluations across different dimensions.","PS can serve as a quantitative evaluation without the need for human annotation.","Experimental results validate the superiority of Preference Score in aligning with human perception, and also demonstrates robustness and generalizability to unseen data, making it a valuable tool for advancing conversation head generation.","We expect this metric could facilitate new advances in conversational head generation."],"url":"http://arxiv.org/abs/2307.10636v1"}
{"created":"2023-07-20 07:01:57","title":"SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models","abstract":"Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks. However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations. To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving. SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics. Based on the two datasets, we conduct an in-depth benchmark study of two representative LLMs with various prompting strategies. The results reveal that current LLMs fall short of delivering satisfactory performance, with an overall score of merely 35.80%. Furthermore, through a detailed user study, we categorize the errors made by LLMs into ten problem-solving abilities. Our analysis indicates that no single prompting strategy significantly outperforms others and some strategies that demonstrate improvements in certain problem-solving skills result in declines in other skills. We envision that SciBench will catalyze further developments in the reasoning abilities of LLMs, thereby ultimately contributing to scientific research and discovery.","sentences":["Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks.","However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations.","To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving.","SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics.","Based on the two datasets, we conduct an in-depth benchmark study of two representative LLMs with various prompting strategies.","The results reveal that current LLMs fall short of delivering satisfactory performance, with an overall score of merely 35.80%.","Furthermore, through a detailed user study, we categorize the errors made by LLMs into ten problem-solving abilities.","Our analysis indicates that no single prompting strategy significantly outperforms others and some strategies that demonstrate improvements in certain problem-solving skills result in declines in other skills.","We envision that SciBench will catalyze further developments in the reasoning abilities of LLMs, thereby ultimately contributing to scientific research and discovery."],"url":"http://arxiv.org/abs/2307.10635v1"}
{"created":"2023-07-20 06:58:55","title":"Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa","abstract":"Large Language Models have many methods for solving the same problem. This introduces novel strengths (different methods may work well for different problems) and weaknesses (it may be difficult for users to know which method to use). In this paper, we introduce Multi-Method Self-Training (MMST), where one method is trained on the filtered outputs of another, allowing us to augment the strengths and ameliorate the weaknesses of each method. Using a 176B parameter model trained on both language and code, we show that MMST can 1) improve the less performant method (up to 30%) making the model easier to use, 2) improve the more performant method (up to 32.2%) making the model more performant, and 3) improve the performance of related but distinct tasks (up to 10.3%) by improving the ability of the model to generate rationales. We then conduct ablation analyses to explore why MMST works. We show that MMST generates more data than traditional self-training, but the improvement in performance is driven by the use of multiple methods. We also analyze prompt-engineering and anti-correlated performance between methods as means of making MMST more effective. We hope the evidence from our paper motivates machine learning researchers to explore ways in which advances in language models allow for new forms of training.","sentences":["Large Language Models have many methods for solving the same problem.","This introduces novel strengths (different methods may work well for different problems) and weaknesses (it may be difficult for users to know which method to use).","In this paper, we introduce Multi-Method Self-Training (MMST), where one method is trained on the filtered outputs of another, allowing us to augment the strengths and ameliorate the weaknesses of each method.","Using a 176B parameter model trained on both language and code, we show that MMST can 1) improve the less performant method (up to 30%) making the model easier to use, 2) improve the more performant method (up to 32.2%) making the model more performant, and 3) improve the performance of related but distinct tasks (up to 10.3%) by improving the ability of the model to generate rationales.","We then conduct ablation analyses to explore why MMST works.","We show that MMST generates more data than traditional self-training, but the improvement in performance is driven by the use of multiple methods.","We also analyze prompt-engineering and anti-correlated performance between methods as means of making MMST more effective.","We hope the evidence from our paper motivates machine learning researchers to explore ways in which advances in language models allow for new forms of training."],"url":"http://arxiv.org/abs/2307.10633v1"}
{"created":"2023-07-20 06:58:11","title":"Parallelization of a new embedded application for automatic meteor detection","abstract":"This article presents the methods used to parallelize a new computer vision application. The system is able to automatically detect meteor from non-stabilized cameras and noisy video sequences. The application is designed to be embedded in weather balloons or for airborne observation campaigns. Thus, the final target is a low power system-on-chip (< 10 Watts) while the software needs to compute a stream of frames in real-time (> 25 frames per second). For this, first the application is split in a tasks graph, then different parallelization techniques are applied. Experiment results demonstrate the efficiency of the parallelization methods. For instance, on the Raspberry Pi 4 and on a HD video sequence, the processing chain reaches 42 frames per second while it only consumes 6 Watts.","sentences":["This article presents the methods used to parallelize a new computer vision application.","The system is able to automatically detect meteor from non-stabilized cameras and noisy video sequences.","The application is designed to be embedded in weather balloons or for airborne observation campaigns.","Thus, the final target is a low power system-on-chip (< 10 Watts) while the software needs to compute a stream of frames in real-time (> 25 frames per second).","For this, first the application is split in a tasks graph, then different parallelization techniques are applied.","Experiment results demonstrate the efficiency of the parallelization methods.","For instance, on the Raspberry Pi 4 and on a HD video sequence, the processing chain reaches 42 frames per second while it only consumes 6 Watts."],"url":"http://arxiv.org/abs/2307.10632v1"}
{"created":"2023-07-20 06:55:37","title":"Pluvio: Assembly Clone Search for Out-of-domain Architectures and Libraries through Transfer Learning and Conditional Variational Information Bottleneck","abstract":"The practice of code reuse is crucial in software development for a faster and more efficient development lifecycle. In reality, however, code reuse practices lack proper control, resulting in issues such as vulnerability propagation and intellectual property infringements. Assembly clone search, a critical shift-right defence mechanism, has been effective in identifying vulnerable code resulting from reuse in released executables. Recent studies on assembly clone search demonstrate a trend towards using machine learning-based methods to match assembly code variants produced by different toolchains. However, these methods are limited to what they learn from a small number of toolchain variants used in training, rendering them inapplicable to unseen architectures and their corresponding compilation toolchain variants.   This paper presents the first study on the problem of assembly clone search with unseen architectures and libraries. We propose incorporating human common knowledge through large-scale pre-trained natural language models, in the form of transfer learning, into current learning-based approaches for assembly clone search. Transfer learning can aid in addressing the limitations of the existing approaches, as it can bring in broader knowledge from human experts in assembly code. We further address the sequence limit issue by proposing a reinforcement learning agent to remove unnecessary and redundant tokens. Coupled with a new Variational Information Bottleneck learning strategy, the proposed system minimizes the reliance on potential indicators of architectures and optimization settings, for a better generalization of unseen architectures. We simulate the unseen architecture clone search scenarios and the experimental results show the effectiveness of the proposed approach against the state-of-the-art solutions.","sentences":["The practice of code reuse is crucial in software development for a faster and more efficient development lifecycle.","In reality, however, code reuse practices lack proper control, resulting in issues such as vulnerability propagation and intellectual property infringements.","Assembly clone search, a critical shift-right defence mechanism, has been effective in identifying vulnerable code resulting from reuse in released executables.","Recent studies on assembly clone search demonstrate a trend towards using machine learning-based methods to match assembly code variants produced by different toolchains.","However, these methods are limited to what they learn from a small number of toolchain variants used in training, rendering them inapplicable to unseen architectures and their corresponding compilation toolchain variants.   ","This paper presents the first study on the problem of assembly clone search with unseen architectures and libraries.","We propose incorporating human common knowledge through large-scale pre-trained natural language models, in the form of transfer learning, into current learning-based approaches for assembly clone search.","Transfer learning can aid in addressing the limitations of the existing approaches, as it can bring in broader knowledge from human experts in assembly code.","We further address the sequence limit issue by proposing a reinforcement learning agent to remove unnecessary and redundant tokens.","Coupled with a new Variational Information Bottleneck learning strategy, the proposed system minimizes the reliance on potential indicators of architectures and optimization settings, for a better generalization of unseen architectures.","We simulate the unseen architecture clone search scenarios and the experimental results show the effectiveness of the proposed approach against the state-of-the-art solutions."],"url":"http://arxiv.org/abs/2307.10631v1"}
{"created":"2023-07-20 06:52:00","title":"Logic and theory of representation","abstract":"Underlying the theory of inferences, a primary task of logic is language analysis. Such a task can be understood as depending on a general theory of representation, taking as a starting point the idea that some entities (`` representations '') can present some entites (`` contents ''). We outline a theory of representation accounting for the capacity of representational systems to access universes that extend beyond an immediate presence. We define three logical properties that any adequate representational system should have: completeness, faithfulness, coherence. We show that logical laws are laws of representation. Finally, it appears that logic can be considered as the abstract theory of representation.","sentences":["Underlying the theory of inferences, a primary task of logic is language analysis.","Such a task can be understood as depending on a general theory of representation, taking as a starting point the idea that some entities (`` representations '') can present some entites (`` contents '').","We outline a theory of representation accounting for the capacity of representational systems to access universes that extend beyond an immediate presence.","We define three logical properties that any adequate representational system should have: completeness, faithfulness, coherence.","We show that logical laws are laws of representation.","Finally, it appears that logic can be considered as the abstract theory of representation."],"url":"http://arxiv.org/abs/2307.10629v1"}
{"created":"2023-07-20 06:47:46","title":"Learning Discriminative Visual-Text Representation for Polyp Re-Identification","abstract":"Colonoscopic Polyp Re-Identification aims to match a specific polyp in a large gallery with different cameras and views, which plays a key role for the prevention and treatment of colorectal cancer in the computer-aided diagnosis. However, traditional methods mainly focus on the visual representation learning, while neglect to explore the potential of semantic features during training, which may easily leads to poor generalization capability when adapted the pretrained model into the new scenarios. To relieve this dilemma, we propose a simple but effective training method named VT-ReID, which can remarkably enrich the representation of polyp videos with the interchange of high-level semantic information. Moreover, we elaborately design a novel clustering mechanism to introduce prior knowledge from textual data, which leverages contrastive learning to promote better separation from abundant unlabeled text data. To the best of our knowledge, this is the first attempt to employ the visual-text feature with clustering mechanism for the colonoscopic polyp re-identification. Empirical results show that our method significantly outperforms current state-of-the art methods with a clear margin.","sentences":["Colonoscopic Polyp Re-Identification aims to match a specific polyp in a large gallery with different cameras and views, which plays a key role for the prevention and treatment of colorectal cancer in the computer-aided diagnosis.","However, traditional methods mainly focus on the visual representation learning, while neglect to explore the potential of semantic features during training, which may easily leads to poor generalization capability when adapted the pretrained model into the new scenarios.","To relieve this dilemma, we propose a simple but effective training method named VT-ReID, which can remarkably enrich the representation of polyp videos with the interchange of high-level semantic information.","Moreover, we elaborately design a novel clustering mechanism to introduce prior knowledge from textual data, which leverages contrastive learning to promote better separation from abundant unlabeled text data.","To the best of our knowledge, this is the first attempt to employ the visual-text feature with clustering mechanism for the colonoscopic polyp re-identification.","Empirical results show that our method significantly outperforms current state-of-the art methods with a clear margin."],"url":"http://arxiv.org/abs/2307.10625v1"}
{"created":"2023-07-20 06:44:42","title":"Joint Skeletal and Semantic Embedding Loss for Micro-gesture Classification","abstract":"In this paper, we briefly introduce the solution of our team HFUT-VUT for the Micros-gesture Classification in the MiGA challenge at IJCAI 2023. The micro-gesture classification task aims at recognizing the action category of a given video based on the skeleton data. For this task, we propose a 3D-CNNs-based micro-gesture recognition network, which incorporates a skeletal and semantic embedding loss to improve action classification performance. Finally, we rank 1st in the Micro-gesture Classification Challenge, surpassing the second-place team in terms of Top-1 accuracy by 1.10%.","sentences":["In this paper, we briefly introduce the solution of our team HFUT-VUT for the Micros-gesture Classification in the MiGA challenge at IJCAI 2023.","The micro-gesture classification task aims at recognizing the action category of a given video based on the skeleton data.","For this task, we propose a 3D-CNNs-based micro-gesture recognition network, which incorporates a skeletal and semantic embedding loss to improve action classification performance.","Finally, we rank 1st in the Micro-gesture Classification Challenge, surpassing the second-place team in terms of Top-1 accuracy by 1.10%."],"url":"http://arxiv.org/abs/2307.10624v1"}
{"created":"2023-07-20 06:37:47","title":"Quaternion tensor ring decomposition and application for color image inpainting","abstract":"In recent years, tensor networks have emerged as powerful tools for solving large-scale optimization problems. One of the most promising tensor networks is the tensor ring (TR) decomposition, which achieves circular dimensional permutation invariance in the model through the utilization of the trace operation and equitable treatment of the latent cores. On the other hand, more recently, quaternions have gained significant attention and have been widely utilized in color image processing tasks due to their effectiveness in encoding color pixels. Therefore, in this paper, we propose the quaternion tensor ring (QTR) decomposition, which inherits the powerful and generalized representation abilities of the TR decomposition while leveraging the advantages of quaternions for color pixel representation. In addition to providing the definition of QTR decomposition and an algorithm for learning the QTR format, this paper also proposes a low-rank quaternion tensor completion (LRQTC) model and its algorithm for color image inpainting based on the QTR decomposition. Finally, extensive experiments on color image inpainting demonstrate that the proposed QTLRC method is highly competitive.","sentences":["In recent years, tensor networks have emerged as powerful tools for solving large-scale optimization problems.","One of the most promising tensor networks is the tensor ring (TR) decomposition, which achieves circular dimensional permutation invariance in the model through the utilization of the trace operation and equitable treatment of the latent cores.","On the other hand, more recently, quaternions have gained significant attention and have been widely utilized in color image processing tasks due to their effectiveness in encoding color pixels.","Therefore, in this paper, we propose the quaternion tensor ring (QTR) decomposition, which inherits the powerful and generalized representation abilities of the TR decomposition while leveraging the advantages of quaternions for color pixel representation.","In addition to providing the definition of QTR decomposition and an algorithm for learning the QTR format, this paper also proposes a low-rank quaternion tensor completion (LRQTC) model and its algorithm for color image inpainting based on the QTR decomposition.","Finally, extensive experiments on color image inpainting demonstrate that the proposed QTLRC method is highly competitive."],"url":"http://arxiv.org/abs/2307.10620v1"}
{"created":"2023-07-20 06:36:16","title":"FHPM: Fine-grained Huge Page Management For Virtualization","abstract":"As more data-intensive tasks with large footprints are deployed in virtual machines (VMs), huge pages are widely used to eliminate the increasing address translation overhead. However, once the huge page mapping is established, all the base page regions in the huge page share a single extended page table (EPT) entry, so that the hypervisor loses awareness of accesses to base page regions. None of the state-of-the-art solutions can obtain access information at base page granularity for huge pages. We observe that this can lead to incorrect decisions by the hypervisor, such as incorrect data placement in a tiered memory system and unshared base page regions when sharing pages.   This paper proposes FHPM, a fine-grained huge page management for virtualization without hardware and guest OS modification. FHPM can identify access information at base page granularity, and dynamically promote and demote pages. A key insight of FHPM is to redirect the EPT huge page directory entries (PDEs) to new companion pages so that the MMU can track access information within huge pages. Then, FHPM can promote and demote pages according to the current hot page pressure to balance address translation overhead and memory usage. At the same time, FHPM proposes a VM-friendly page splitting and collapsing mechanism to avoid extra VM-exits. In combination, FHPM minimizes the monitoring and management overhead and ensures that the hypervisor gets fine-grained VM memory accesses to make the proper decision. We apply FHPM to improve tiered memory management (FHPM-TMM) and to promote page sharing (FHPM-Share). FHPM-TMM achieves a performance improvement of up to 33% and 61% over the pure huge page and base page management. FHPM-Share can save 41% more memory than Ingens, a state-of-the-art page sharing solution, with comparable performance.","sentences":["As more data-intensive tasks with large footprints are deployed in virtual machines (VMs), huge pages are widely used to eliminate the increasing address translation overhead.","However, once the huge page mapping is established, all the base page regions in the huge page share a single extended page table (EPT) entry, so that the hypervisor loses awareness of accesses to base page regions.","None of the state-of-the-art solutions can obtain access information at base page granularity for huge pages.","We observe that this can lead to incorrect decisions by the hypervisor, such as incorrect data placement in a tiered memory system and unshared base page regions when sharing pages.   ","This paper proposes FHPM, a fine-grained huge page management for virtualization without hardware and guest OS modification.","FHPM can identify access information at base page granularity, and dynamically promote and demote pages.","A key insight of FHPM is to redirect the EPT huge page directory entries (PDEs) to new companion pages so that the MMU can track access information within huge pages.","Then, FHPM can promote and demote pages according to the current hot page pressure to balance address translation overhead and memory usage.","At the same time, FHPM proposes a VM-friendly page splitting and collapsing mechanism to avoid extra VM-exits.","In combination, FHPM minimizes the monitoring and management overhead and ensures that the hypervisor gets fine-grained VM memory accesses to make the proper decision.","We apply FHPM to improve tiered memory management (FHPM-TMM) and to promote page sharing (FHPM-Share).","FHPM-TMM achieves a performance improvement of up to 33% and 61% over the pure huge page and base page management.","FHPM-Share can save 41% more memory than Ingens, a state-of-the-art page sharing solution, with comparable performance."],"url":"http://arxiv.org/abs/2307.10618v1"}
{"created":"2023-07-20 06:35:43","title":"Detecting deceptive reviews using text classification","abstract":"In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify deceptive contents with a particular focus on fake reviews. Further, we conduct a benchmark study to investigate the performance of two different features extraction techniques and apply five machine learning classification techniques. The experimental results show that passive aggressive classifier outperforms other algorithms, and it reaches the highest accuracy not only in text classification but also to fake reviews. We also study the data augmentation and implement different deep learning techniques.","sentences":["In recent years, online reviews play a vital role for promoting any kind of product or services.","Businesses may embed fake reviews in order to attract customers to purchase their products.","They may even highlight the benefits of their own product or criticize the competition's product.","Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like.","So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation.","Thus, identifying deceptive reviews is an intense and on-going research area.","This research paper proposes machine learning model approach to identify deceptive reviews.","The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews.","We developed a n-gram model and max features to identify deceptive contents with a particular focus on fake reviews.","Further, we conduct a benchmark study to investigate the performance of two different features extraction techniques and apply five machine learning classification techniques.","The experimental results show that passive aggressive classifier outperforms other algorithms, and it reaches the highest accuracy not only in text classification but also to fake reviews.","We also study the data augmentation and implement different deep learning techniques."],"url":"http://arxiv.org/abs/2307.10617v1"}
{"created":"2023-07-20 06:32:14","title":"Heterogeneous Federated Learning: State-of-the-art and Research Challenges","abstract":"Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level. Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field. A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey.","sentences":["Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications.","Existing federated learning works mainly focus on model homogeneous settings.","However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients.","Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex.","Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential.","In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges.","In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons.","We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level.","Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field.","A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey."],"url":"http://arxiv.org/abs/2307.10616v1"}
{"created":"2023-07-20 06:25:53","title":"Analyzing HC-NJDG Data to Understand the Pendency in High Courts in India","abstract":"Indian Judiciary is suffering from burden of millions of cases that are lying pending in its courts at all the levels. In this paper, we analyze the data that we have collected on the pendency of 24 high courts in the Republic of India as they were made available on High Court NJDG (HC-NJDG). We collected data on 73 days beginning August 31, 2017 to December 26, 2018, including these days. Thus, the data collected by us spans a period of almost sixteen months. We have analyzed various statistics available on the NJDG portal for High Courts, including but not limited to the number of judges in each high court, the number of cases pending in each high court, cases that have been pending for more than 10 years, cases filed, listed and disposed, cases filed by women and senior citizens, etc. Our results show that: 1) statistics as important as the number of judges in high courts have serious errors on NJDG (Fig. 1, 2, 10, 11, Table V). 2) pending cases in most of the high courts are increasing rather than decreasing (Fig. 3, 13). 3) regular update of HC-NJDG is required for it to be useful. Data related to some high courts is not being updated regularly or is updated erroneously on the portal (Fig. 14). 4) there is a huge difference in terms of average load of cases on judges of different high courts (Fig. 6). 5) if all the high courts operate at their approved strength of judges, then for most of the high courts pendency can be nullified within 20 years from now (Fig. 21, 22). 6) the pending cases filed by women and senior citizens are disproportionately low, they together constitute less than 10% of the total pending cases (Fig. 23 - 27) 7) a better scheduling process for preparing causelists in courts can help reducing the number of pending cases in the High Courts (Fig. 29). 8) some statistics are not well defined (Fig. 31).","sentences":["Indian Judiciary is suffering from burden of millions of cases that are lying pending in its courts at all the levels.","In this paper, we analyze the data that we have collected on the pendency of 24 high courts in the Republic of India as they were made available on High Court NJDG (HC-NJDG).","We collected data on 73 days beginning August 31, 2017 to December 26, 2018, including these days.","Thus, the data collected by us spans a period of almost sixteen months.","We have analyzed various statistics available on the NJDG portal for High Courts, including but not limited to the number of judges in each high court, the number of cases pending in each high court, cases that have been pending for more than 10 years, cases filed, listed and disposed, cases filed by women and senior citizens, etc.","Our results show that: 1) statistics as important as the number of judges in high courts have serious errors on NJDG (Fig. 1, 2, 10, 11, Table V).","2) pending cases in most of the high courts are increasing rather than decreasing (Fig. 3, 13).","3) regular update of HC-NJDG is required for it to be useful.","Data related to some high courts is not being updated regularly or is updated erroneously on the portal (Fig. 14).","4) there is a huge difference in terms of average load of cases on judges of different high courts (Fig. 6).","5) if all the high courts operate at their approved strength of judges, then for most of the high courts pendency can be nullified within 20 years from now (Fig. 21, 22).","6) the pending cases filed by women and senior citizens are disproportionately low, they together constitute less than 10% of the total pending cases (Fig. 23 - 27) 7) a better scheduling process for preparing causelists in courts can help reducing the number of pending cases in the High Courts (Fig. 29).","8) some statistics are not well defined (Fig. 31)."],"url":"http://arxiv.org/abs/2307.10615v1"}
{"created":"2023-07-20 06:25:26","title":"GPRL: Gaussian Processes-Based Relative Localization for Multi-Robot Systems","abstract":"Relative localization is crucial for multi-robot systems to perform cooperative tasks, especially in GPS-denied environments. Current techniques for multi-robot relative localization rely on expensive or short-range sensors such as cameras and LIDARs. As a result, these algorithms face challenges such as high computational complexity, dependencies on well-structured environments, etc. To overcome these limitations, we propose a new distributed approach to perform relative localization using a Gaussian Processes map of the Radio Signal Strength Indicator (RSSI) values from a single wireless Access Point (AP) to which the robots are connected. Our approach, Gaussian Processes-based Relative Localization (GPRL), combines two pillars. First, the robots locate the AP w.r.t. their local reference frames using novel hierarchical inferencing that significantly reduces computational complexity. Secondly, the robots obtain relative positions of neighbor robots with an AP-oriented vector transformation. The approach readily applies to resource-constrained devices and relies only on the ubiquitously-available RSSI measurement. We extensively validate the performance of the two pillars of the proposed GRPL in Robotarium simulations. We also demonstrate the applicability of GPRL through a multi-robot rendezvous task with a team of three real-world robots. The results demonstrate that GPRL outperformed state-of-the-art approaches regarding accuracy, computation, and real-time performance.","sentences":["Relative localization is crucial for multi-robot systems to perform cooperative tasks, especially in GPS-denied environments.","Current techniques for multi-robot relative localization rely on expensive or short-range sensors such as cameras and LIDARs.","As a result, these algorithms face challenges such as high computational complexity, dependencies on well-structured environments, etc.","To overcome these limitations, we propose a new distributed approach to perform relative localization using a Gaussian Processes map of the Radio Signal Strength Indicator (RSSI) values from a single wireless Access Point (AP) to which the robots are connected.","Our approach, Gaussian Processes-based Relative Localization (GPRL), combines two pillars.","First, the robots locate the AP w.r.t.","their local reference frames using novel hierarchical inferencing that significantly reduces computational complexity.","Secondly, the robots obtain relative positions of neighbor robots with an AP-oriented vector transformation.","The approach readily applies to resource-constrained devices and relies only on the ubiquitously-available RSSI measurement.","We extensively validate the performance of the two pillars of the proposed GRPL in Robotarium simulations.","We also demonstrate the applicability of GPRL through a multi-robot rendezvous task with a team of three real-world robots.","The results demonstrate that GPRL outperformed state-of-the-art approaches regarding accuracy, computation, and real-time performance."],"url":"http://arxiv.org/abs/2307.10614v1"}
{"created":"2023-07-20 06:15:00","title":"Computing a Subtrajectory Cluster from c-packed Trajectories","abstract":"We present a near-linear time approximation algorithm for the subtrajectory cluster problem of $c$-packed trajectories. The problem involves finding $m$ subtrajectories within a given trajectory $T$ such that their Fr\\'echet distances are at most $(1 + \\varepsilon)d$, and at least one subtrajectory must be of length~$l$ or longer. A trajectory $T$ is $c$-packed if the intersection of $T$ and any ball $B$ with radius $r$ is at most $c \\cdot r$ in length.   Previous results by Gudmundsson and Wong \\cite{GudmundssonWong2022Cubicupperlower} established an $\\Omega(n^3)$ lower bound unless the Strong Exponential Time Hypothesis fails, and they presented an $O(n^3 \\log^2 n)$ time algorithm. We circumvent this conditional lower bound by studying subtrajectory cluster on $c$-packed trajectories, resulting in an algorithm with an $O((c^2 n/\\varepsilon^2)\\log(c/\\varepsilon)\\log(n/\\varepsilon))$ time complexity.","sentences":["We present a near-linear time approximation algorithm for the subtrajectory cluster problem of $c$-packed trajectories.","The problem involves finding $m$ subtrajectories within a given trajectory $T$ such that their Fr\\'echet distances are at most $(1 + \\varepsilon)d$, and at least one subtrajectory must be of length~$l$ or longer.","A trajectory $T$ is $c$-packed if the intersection of $T$ and any ball $B$ with radius $r$ is at most $c \\cdot r$ in length.   ","Previous results by Gudmundsson and Wong \\cite{GudmundssonWong2022Cubicupperlower} established an $\\Omega(n^3)$ lower bound unless the Strong Exponential Time Hypothesis fails, and they presented an $O(n^3 \\log^2","n)$ time algorithm.","We circumvent this conditional lower bound by studying subtrajectory cluster on $c$-packed trajectories, resulting in an algorithm with an $O((c^2 n/\\varepsilon^2)\\log(c/\\varepsilon)\\log(n/\\varepsilon))$ time complexity."],"url":"http://arxiv.org/abs/2307.10610v1"}
{"created":"2023-07-20 06:07:09","title":"Hybrid Feature Embedding For Automatic Building Outline Extraction","abstract":"Building outline extracted from high-resolution aerial images can be used in various application fields such as change detection and disaster assessment. However, traditional CNN model cannot recognize contours very precisely from original images. In this paper, we proposed a CNN and Transformer based model together with active contour model to deal with this problem. We also designed a triple-branch decoder structure to handle different features generated by encoder. Experiment results show that our model outperforms other baseline model on two datasets, achieving 91.1% mIoU on Vaihingen and 83.8% on Bing huts.","sentences":["Building outline extracted from high-resolution aerial images can be used in various application fields such as change detection and disaster assessment.","However, traditional CNN model cannot recognize contours very precisely from original images.","In this paper, we proposed a CNN and Transformer based model together with active contour model to deal with this problem.","We also designed a triple-branch decoder structure to handle different features generated by encoder.","Experiment results show that our model outperforms other baseline model on two datasets, achieving 91.1% mIoU on Vaihingen and 83.8% on Bing huts."],"url":"http://arxiv.org/abs/2307.10609v1"}
{"created":"2023-07-20 06:02:15","title":"Parameterized Complexity of Biclique Contraction and Balanced Biclique Contraction","abstract":"In this work, we initiate the complexity study of Biclique Contraction and Balanced Biclique Contraction. In these problems, given as input a graph G and an integer k, the objective is to determine whether one can contract at most k edges in G to obtain a biclique and a balanced biclique, respectively. We first prove that these problems are NP-complete even when the input graph is bipartite. Next, we study the parameterized complexity of these problems and show that they admit single exponential-time FPT algorithms when parameterized by the number k of edge contractions. Then, we show that Balanced Biclique Contraction admits a quadratic vertex kernel while Biclique Contraction does not admit any polynomial compression (or kernel) under standard complexity-theoretic assumptions.","sentences":["In this work, we initiate the complexity study of Biclique Contraction and Balanced Biclique Contraction.","In these problems, given as input a graph G and an integer k, the objective is to determine whether one can contract at most k edges in G to obtain a biclique and a balanced biclique, respectively.","We first prove that these problems are NP-complete even when the input graph is bipartite.","Next, we study the parameterized complexity of these problems and show that they admit single exponential-time FPT algorithms when parameterized by the number k of edge contractions.","Then, we show that Balanced Biclique Contraction admits a quadratic vertex kernel while Biclique Contraction does not admit any polynomial compression (or kernel) under standard complexity-theoretic assumptions."],"url":"http://arxiv.org/abs/2307.10607v1"}
{"created":"2023-07-20 05:46:32","title":"SCA-PVNet: Self-and-Cross Attention Based Aggregation of Point Cloud and Multi-View for 3D Object Retrieval","abstract":"To address 3D object retrieval, substantial efforts have been made to generate highly discriminative descriptors of 3D objects represented by a single modality, e.g., voxels, point clouds or multi-view images. It is promising to leverage the complementary information from multi-modality representations of 3D objects to further improve retrieval performance. However, multi-modality 3D object retrieval is rarely developed and analyzed on large-scale datasets. In this paper, we propose self-and-cross attention based aggregation of point cloud and multi-view images (SCA-PVNet) for 3D object retrieval. With deep features extracted from point clouds and multi-view images, we design two types of feature aggregation modules, namely the In-Modality Aggregation Module (IMAM) and the Cross-Modality Aggregation Module (CMAM), for effective feature fusion. IMAM leverages a self-attention mechanism to aggregate multi-view features while CMAM exploits a cross-attention mechanism to interact point cloud features with multi-view features. The final descriptor of a 3D object for object retrieval can be obtained via concatenating the aggregated features from both modules. Extensive experiments and analysis are conducted on three datasets, ranging from small to large scale, to show the superiority of the proposed SCA-PVNet over the state-of-the-art methods.","sentences":["To address 3D object retrieval, substantial efforts have been made to generate highly discriminative descriptors of 3D objects represented by a single modality, e.g., voxels, point clouds or multi-view images.","It is promising to leverage the complementary information from multi-modality representations of 3D objects to further improve retrieval performance.","However, multi-modality 3D object retrieval is rarely developed and analyzed on large-scale datasets.","In this paper, we propose self-and-cross attention based aggregation of point cloud and multi-view images (SCA-PVNet) for 3D object retrieval.","With deep features extracted from point clouds and multi-view images, we design two types of feature aggregation modules, namely the In-Modality Aggregation Module (IMAM) and the Cross-Modality Aggregation Module (CMAM), for effective feature fusion.","IMAM leverages a self-attention mechanism to aggregate multi-view features while CMAM exploits a cross-attention mechanism to interact point cloud features with multi-view features.","The final descriptor of a 3D object for object retrieval can be obtained via concatenating the aggregated features from both modules.","Extensive experiments and analysis are conducted on three datasets, ranging from small to large scale, to show the superiority of the proposed SCA-PVNet over the state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.10601v1"}
{"created":"2023-07-20 05:43:39","title":"Challenges and Solutions in AI for All","abstract":"Artificial Intelligence (AI)'s pervasive presence and variety necessitate diversity and inclusivity (D&I) principles in its design for fairness, trust, and transparency. Yet, these considerations are often overlooked, leading to issues of bias, discrimination, and perceived untrustworthiness. In response, we conducted a Systematic Review to unearth challenges and solutions relating to D&I in AI. Our rigorous search yielded 48 research articles published between 2017 and 2022. Open coding of these papers revealed 55 unique challenges and 33 solutions for D&I in AI, as well as 24 unique challenges and 23 solutions for enhancing such practices using AI. This study, by offering a deeper understanding of these issues, will enlighten researchers and practitioners seeking to integrate these principles into future AI systems.","sentences":["Artificial Intelligence (AI)'s pervasive presence and variety necessitate diversity and inclusivity (D&I) principles in its design for fairness, trust, and transparency.","Yet, these considerations are often overlooked, leading to issues of bias, discrimination, and perceived untrustworthiness.","In response, we conducted a Systematic Review to unearth challenges and solutions relating to D&I in AI.","Our rigorous search yielded 48 research articles published between 2017 and 2022.","Open coding of these papers revealed 55 unique challenges and 33 solutions for D&I in AI, as well as 24 unique challenges and 23 solutions for enhancing such practices using AI.","This study, by offering a deeper understanding of these issues, will enlighten researchers and practitioners seeking to integrate these principles into future AI systems."],"url":"http://arxiv.org/abs/2307.10600v1"}
{"created":"2023-07-20 05:23:49","title":"Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis","abstract":"The Internet of Things (IoT) integrates more than billions of intelligent devices over the globe with the capability of communicating with other connected devices with little to no human intervention. IoT enables data aggregation and analysis on a large scale to improve life quality in many domains. In particular, data collected by IoT contain a tremendous amount of information for anomaly detection. The heterogeneous nature of IoT is both a challenge and an opportunity for cybersecurity. Traditional approaches in cybersecurity monitoring often require different kinds of data pre-processing and handling for various data types, which might be problematic for datasets that contain heterogeneous features. However, heterogeneous types of network devices can often capture a more diverse set of signals than a single type of device readings, which is particularly useful for anomaly detection. In this paper, we present a comprehensive study on using ensemble machine learning methods for enhancing IoT cybersecurity via anomaly detection. Rather than using one single machine learning model, ensemble learning combines the predictive power from multiple models, enhancing their predictive accuracy in heterogeneous datasets rather than using one single machine learning model. We propose a unified framework with ensemble learning that utilises Bayesian hyperparameter optimisation to adapt to a network environment that contains multiple IoT sensor readings. Experimentally, we illustrate their high predictive power when compared to traditional methods.","sentences":["The Internet of Things (IoT) integrates more than billions of intelligent devices over the globe with the capability of communicating with other connected devices with little to no human intervention.","IoT enables data aggregation and analysis on a large scale to improve life quality in many domains.","In particular, data collected by IoT contain a tremendous amount of information for anomaly detection.","The heterogeneous nature of IoT is both a challenge and an opportunity for cybersecurity.","Traditional approaches in cybersecurity monitoring often require different kinds of data pre-processing and handling for various data types, which might be problematic for datasets that contain heterogeneous features.","However, heterogeneous types of network devices can often capture a more diverse set of signals than a single type of device readings, which is particularly useful for anomaly detection.","In this paper, we present a comprehensive study on using ensemble machine learning methods for enhancing IoT cybersecurity via anomaly detection.","Rather than using one single machine learning model, ensemble learning combines the predictive power from multiple models, enhancing their predictive accuracy in heterogeneous datasets rather than using one single machine learning model.","We propose a unified framework with ensemble learning that utilises Bayesian hyperparameter optimisation to adapt to a network environment that contains multiple IoT sensor readings.","Experimentally, we illustrate their high predictive power when compared to traditional methods."],"url":"http://arxiv.org/abs/2307.10596v1"}
{"created":"2023-07-20 05:16:33","title":"Exploiting Structure for Optimal Multi-Agent Bayesian Decentralized Estimation","abstract":"A key challenge in Bayesian decentralized data fusion is the `rumor propagation' or `double counting' phenomenon, where previously sent data circulates back to its sender. It is often addressed by approximate methods like covariance intersection (CI) which takes a weighted average of the estimates to compute the bound. The problem is that this bound is not tight, i.e. the estimate is often over-conservative. In this paper, we show that by exploiting the probabilistic independence structure in multi-agent decentralized fusion problems a tighter bound can be found using (i) an expansion to the CI algorithm that uses multiple (non-monolithic) weighting factors instead of one (monolithic) factor in the original CI and (ii) a general optimization scheme that is able to compute optimal bounds and fully exploit an arbitrary dependency structure. We compare our methods and show that on a simple problem, they converge to the same solution. We then test our new non-monolithic CI algorithm on a large-scale target tracking simulation and show that it achieves a tighter bound and a more accurate estimate compared to the original monolithic CI.","sentences":["A key challenge in Bayesian decentralized data fusion is the `rumor propagation' or `double counting' phenomenon, where previously sent data circulates back to its sender.","It is often addressed by approximate methods like covariance intersection (CI) which takes a weighted average of the estimates to compute the bound.","The problem is that this bound is not tight, i.e. the estimate is often over-conservative.","In this paper, we show that by exploiting the probabilistic independence structure in multi-agent decentralized fusion problems a tighter bound can be found using (i) an expansion to the CI algorithm that uses multiple (non-monolithic) weighting factors instead of one (monolithic) factor in the original CI and (ii) a general optimization scheme that is able to compute optimal bounds and fully exploit an arbitrary dependency structure.","We compare our methods and show that on a simple problem, they converge to the same solution.","We then test our new non-monolithic CI algorithm on a large-scale target tracking simulation and show that it achieves a tighter bound and a more accurate estimate compared to the original monolithic CI."],"url":"http://arxiv.org/abs/2307.10594v1"}
{"created":"2023-07-20 05:15:03","title":"Event Blob Tracking: An Asynchronous Real-Time Algorithm","abstract":"Event-based cameras have become increasingly popular for tracking fast-moving objects due to their high temporal resolution, low latency, and high dynamic range. In this paper, we propose a novel algorithm for tracking event blobs using raw events asynchronously in real time. We introduce the concept of an event blob as a spatio-temporal likelihood of event occurrence where the conditional spatial likelihood is blob-like. Many real-world objects generate event blob data, for example, flickering LEDs such as car headlights or any small foreground object moving against a static or slowly varying background. The proposed algorithm uses a nearest neighbour classifier with a dynamic threshold criteria for data association coupled with a Kalman filter to track the event blob state. Our algorithm achieves highly accurate tracking and event blob shape estimation even under challenging lighting conditions and high-speed motions. The microsecond time resolution achieved means that the filter output can be used to derive secondary information such as time-to-contact or range estimation, that will enable applications to real-world problems such as collision avoidance in autonomous driving.","sentences":["Event-based cameras have become increasingly popular for tracking fast-moving objects due to their high temporal resolution, low latency, and high dynamic range.","In this paper, we propose a novel algorithm for tracking event blobs using raw events asynchronously in real time.","We introduce the concept of an event blob as a spatio-temporal likelihood of event occurrence where the conditional spatial likelihood is blob-like.","Many real-world objects generate event blob data, for example, flickering LEDs such as car headlights or any small foreground object moving against a static or slowly varying background.","The proposed algorithm uses a nearest neighbour classifier with a dynamic threshold criteria for data association coupled with a Kalman filter to track the event blob state.","Our algorithm achieves highly accurate tracking and event blob shape estimation even under challenging lighting conditions and high-speed motions.","The microsecond time resolution achieved means that the filter output can be used to derive secondary information such as time-to-contact or range estimation, that will enable applications to real-world problems such as collision avoidance in autonomous driving."],"url":"http://arxiv.org/abs/2307.10593v1"}
{"created":"2023-07-20 05:07:51","title":"Boundary State Generation for Testing and Improvement of Autonomous Driving Systems","abstract":"Recent advances in Deep Neural Networks (DNNs) and sensor technologies are enabling autonomous driving systems (ADSs) with an ever-increasing level of autonomy. However, assessing their dependability remains a critical concern. State-of-the-art ADS testing approaches modify the controllable attributes of a simulated driving environment until the ADS misbehaves. Such approaches have two main drawbacks: (1) modifications to the simulated environment might not be easily transferable to the in-field test setting (e.g., changing the road shape); (2) environment instances in which the ADS is successful are discarded, despite the possibility that they could contain hidden driving conditions in which the ADS may misbehave.   In this paper, we present GenBo (GENerator of BOundary state pairs), a novel test generator for ADS testing. GenBo mutates the driving conditions of the ego vehicle (position, velocity and orientation), collected in a failure-free environment instance, and efficiently generates challenging driving conditions at the behavior boundary (i.e., where the model starts to misbehave) in the same environment. We use such boundary conditions to augment the initial training dataset and retrain the DNN model under test. Our evaluation results show that the retrained model has up to 16 higher success rate on a separate set of evaluation tracks with respect to the original DNN model.","sentences":["Recent advances in Deep Neural Networks (DNNs) and sensor technologies are enabling autonomous driving systems (ADSs) with an ever-increasing level of autonomy.","However, assessing their dependability remains a critical concern.","State-of-the-art ADS testing approaches modify the controllable attributes of a simulated driving environment until the ADS misbehaves.","Such approaches have two main drawbacks: (1) modifications to the simulated environment might not be easily transferable to the in-field test setting (e.g., changing the road shape); (2) environment instances in which the ADS is successful are discarded, despite the possibility that they could contain hidden driving conditions in which the ADS may misbehave.   ","In this paper, we present GenBo (GENerator of BOundary state pairs), a novel test generator for ADS testing.","GenBo mutates the driving conditions of the ego vehicle (position, velocity and orientation), collected in a failure-free environment instance, and efficiently generates challenging driving conditions at the behavior boundary (i.e., where the model starts to misbehave) in the same environment.","We use such boundary conditions to augment the initial training dataset and retrain the DNN model under test.","Our evaluation results show that the retrained model has up to 16 higher success rate on a separate set of evaluation tracks with respect to the original DNN model."],"url":"http://arxiv.org/abs/2307.10590v1"}
{"created":"2023-07-20 05:03:25","title":"Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques","abstract":"Energy systems, climate change, and public health are among the primary reasons for moving toward electrification in transportation. Transportation electrification is being promoted worldwide to reduce emissions. As a result, many automakers will soon start making only battery electric vehicles (BEVs). BEV adoption rates are rising in California, mainly due to climate change and air pollution concerns. While great for climate and pollution goals, improperly managed BEV charging can lead to insufficient charging infrastructure and power outages. This study develops a novel Micro Clustering Deep Neural Network (MCDNN), an artificial neural network algorithm that is highly effective at learning BEVs trip and charging data to forecast BEV charging events, information that is essential for electricity load aggregators and utility managers to provide charging stations and electricity capacity effectively. The MCDNN is configured using a robust dataset of trips and charges that occurred in California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a total of 1570167 vehicle miles traveled. The numerical findings revealed that the proposed MCDNN is more effective than benchmark approaches in this field, such as support vector machine, k nearest neighbors, decision tree, and other neural network-based models in predicting the charging events.","sentences":["Energy systems, climate change, and public health are among the primary reasons for moving toward electrification in transportation.","Transportation electrification is being promoted worldwide to reduce emissions.","As a result, many automakers will soon start making only battery electric vehicles (BEVs).","BEV adoption rates are rising in California, mainly due to climate change and air pollution concerns.","While great for climate and pollution goals, improperly managed BEV charging can lead to insufficient charging infrastructure and power outages.","This study develops a novel Micro Clustering Deep Neural Network (MCDNN), an artificial neural network algorithm that is highly effective at learning BEVs trip and charging data to forecast BEV charging events, information that is essential for electricity load aggregators and utility managers to provide charging stations and electricity capacity effectively.","The MCDNN is configured using a robust dataset of trips and charges that occurred in California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a total of 1570167 vehicle miles traveled.","The numerical findings revealed that the proposed MCDNN is more effective than benchmark approaches in this field, such as support vector machine, k nearest neighbors, decision tree, and other neural network-based models in predicting the charging events."],"url":"http://arxiv.org/abs/2307.10588v1"}
{"created":"2023-07-20 05:03:00","title":"A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos","abstract":"Automatic speech recognition (ASR) systems are designed to transcribe spoken language into written text and find utility in a variety of applications including voice assistants and transcription services. However, it has been observed that state-of-the-art ASR systems which deliver impressive benchmark results, struggle with speakers of certain regions or demographics due to variation in their speech properties. In this work, we describe the curation of a massive speech dataset of 8740 hours consisting of $\\sim9.8$K technical lectures in the English language along with their transcripts delivered by instructors representing various parts of Indian demography. The dataset is sourced from the very popular NPTEL MOOC platform. We use the curated dataset to measure the existing disparity in YouTube Automatic Captions and OpenAI Whisper model performance across the diverse demographic traits of speakers in India. While there exists disparity due to gender, native region, age and speech rate of speakers, disparity based on caste is non-existent. We also observe statistically significant disparity across the disciplines of the lectures. These results indicate the need of more inclusive and robust ASR systems and more representational datasets for disparity evaluation in them.","sentences":["Automatic speech recognition (ASR) systems are designed to transcribe spoken language into written text and find utility in a variety of applications including voice assistants and transcription services.","However, it has been observed that state-of-the-art ASR systems which deliver impressive benchmark results, struggle with speakers of certain regions or demographics due to variation in their speech properties.","In this work, we describe the curation of a massive speech dataset of 8740 hours consisting of $\\sim9.8$K technical lectures in the English language along with their transcripts delivered by instructors representing various parts of Indian demography.","The dataset is sourced from the very popular NPTEL MOOC platform.","We use the curated dataset to measure the existing disparity in YouTube Automatic Captions and OpenAI Whisper model performance across the diverse demographic traits of speakers in India.","While there exists disparity due to gender, native region, age and speech rate of speakers, disparity based on caste is non-existent.","We also observe statistically significant disparity across the disciplines of the lectures.","These results indicate the need of more inclusive and robust ASR systems and more representational datasets for disparity evaluation in them."],"url":"http://arxiv.org/abs/2307.10587v1"}
{"created":"2023-07-20 05:00:13","title":"A Holistic Assessment of the Reliability of Machine Learning Systems","abstract":"As machine learning (ML) systems increasingly permeate high-stakes settings such as healthcare, transportation, military, and national security, concerns regarding their reliability have emerged. Despite notable progress, the performance of these systems can significantly diminish due to adversarial attacks or environmental changes, leading to overconfident predictions, failures to detect input faults, and an inability to generalize in unexpected scenarios. This paper proposes a holistic assessment methodology for the reliability of ML systems. Our framework evaluates five key properties: in-distribution accuracy, distribution-shift robustness, adversarial robustness, calibration, and out-of-distribution detection. A reliability score is also introduced and used to assess the overall system reliability. To provide insights into the performance of different algorithmic approaches, we identify and categorize state-of-the-art techniques, then evaluate a selection on real-world tasks using our proposed reliability metrics and reliability score. Our analysis of over 500 models reveals that designing for one metric does not necessarily constrain others but certain algorithmic techniques can improve reliability across multiple metrics simultaneously. This study contributes to a more comprehensive understanding of ML reliability and provides a roadmap for future research and development.","sentences":["As machine learning (ML) systems increasingly permeate high-stakes settings such as healthcare, transportation, military, and national security, concerns regarding their reliability have emerged.","Despite notable progress, the performance of these systems can significantly diminish due to adversarial attacks or environmental changes, leading to overconfident predictions, failures to detect input faults, and an inability to generalize in unexpected scenarios.","This paper proposes a holistic assessment methodology for the reliability of ML systems.","Our framework evaluates five key properties: in-distribution accuracy, distribution-shift robustness, adversarial robustness, calibration, and out-of-distribution detection.","A reliability score is also introduced and used to assess the overall system reliability.","To provide insights into the performance of different algorithmic approaches, we identify and categorize state-of-the-art techniques, then evaluate a selection on real-world tasks using our proposed reliability metrics and reliability score.","Our analysis of over 500 models reveals that designing for one metric does not necessarily constrain others but certain algorithmic techniques can improve reliability across multiple metrics simultaneously.","This study contributes to a more comprehensive understanding of ML reliability and provides a roadmap for future research and development."],"url":"http://arxiv.org/abs/2307.10586v1"}
{"created":"2023-07-20 04:51:10","title":"Reference-based Painterly Inpainting via Diffusion: Crossing the Wild Reference Domain Gap","abstract":"Have you ever imagined how it would look if we placed new objects into paintings? For example, what would it look like if we placed a basketball into Claude Monet's ``Water Lilies, Evening Effect''? We propose Reference-based Painterly Inpainting, a novel task that crosses the wild reference domain gap and implants novel objects into artworks. Although previous works have examined reference-based inpainting, they are not designed for large domain discrepancies between the target and the reference, such as inpainting an artistic image using a photorealistic reference. This paper proposes a novel diffusion framework, dubbed RefPaint, to ``inpaint more wildly'' by taking such references with large domain gaps. Built with an image-conditioned diffusion model, we introduce a ladder-side branch and a masked fusion mechanism to work with the inpainting mask. By decomposing the CLIP image embeddings at inference time, one can manipulate the strength of semantic and style information with ease. Experiments demonstrate that our proposed RefPaint framework produces significantly better results than existing methods. Our method enables creative painterly image inpainting with reference objects that would otherwise be difficult to achieve. Project page: https://vita-group.github.io/RefPaint/","sentences":["Have you ever imagined how it would look if we placed new objects into paintings?","For example, what would it look like if we placed a basketball into Claude Monet's ``Water Lilies, Evening Effect''?","We propose Reference-based Painterly Inpainting, a novel task that crosses the wild reference domain gap and implants novel objects into artworks.","Although previous works have examined reference-based inpainting, they are not designed for large domain discrepancies between the target and the reference, such as inpainting an artistic image using a photorealistic reference.","This paper proposes a novel diffusion framework, dubbed RefPaint, to ``inpaint more wildly'' by taking such references with large domain gaps.","Built with an image-conditioned diffusion model, we introduce a ladder-side branch and a masked fusion mechanism to work with the inpainting mask.","By decomposing the CLIP image embeddings at inference time, one can manipulate the strength of semantic and style information with ease.","Experiments demonstrate that our proposed RefPaint framework produces significantly better results than existing methods.","Our method enables creative painterly image inpainting with reference objects that would otherwise be difficult to achieve.","Project page: https://vita-group.github.io/RefPaint/"],"url":"http://arxiv.org/abs/2307.10584v1"}
{"created":"2023-07-20 04:49:23","title":"Deep fused flow and topology features for botnet detection basing on pretrained GCN","abstract":"Nowadays, botnets have become one of the major threats to cyber security. The characteristics of botnets are mainly reflected in bots network behavior and their intercommunication relationships. Existing botnet detection methods use flow features or topological features of the communication graph individually and overlook the other type of feature, which affects model performance. In this paper, we propose a botnet detection model which uses graph convolutional network (GCN) to deeply fuse flow features and topological features for the first time. We construct communication graphs from network traffic and represent nodes with flow features. Due to the imbalance of existing public traffic flow datasets, it is impossible to train a GCN model on these datasets. Therefore, we use a balanced public communication graph dataset to pretrain a GCN model, thereby guaranteeing its capacity for recognizing topological features. We then feed the communication graph with flow features into the pretrained GCN. The output from the last hidden layer is treated as the fusion of flow and topological features. Additionally, by adjusting the number of layers in the GCN network, the model can effectively detect botnets operating under both C2 and P2P structures. Validated on the public ISCX2014 dataset, our approach achieves a remarkable accuracy of 98.85% and a recall rate of 92.90% for C2 botnets, alongside an accuracy of 99.10% and a recall rate of 94.66% for P2P botnets. These results not only demonstrate the efficacy of our method, but also surpass the performance of the currently leading detection models.","sentences":["Nowadays, botnets have become one of the major threats to cyber security.","The characteristics of botnets are mainly reflected in bots network behavior and their intercommunication relationships.","Existing botnet detection methods use flow features or topological features of the communication graph individually and overlook the other type of feature, which affects model performance.","In this paper, we propose a botnet detection model which uses graph convolutional network (GCN) to deeply fuse flow features and topological features for the first time.","We construct communication graphs from network traffic and represent nodes with flow features.","Due to the imbalance of existing public traffic flow datasets, it is impossible to train a GCN model on these datasets.","Therefore, we use a balanced public communication graph dataset to pretrain a GCN model, thereby guaranteeing its capacity for recognizing topological features.","We then feed the communication graph with flow features into the pretrained GCN.","The output from the last hidden layer is treated as the fusion of flow and topological features.","Additionally, by adjusting the number of layers in the GCN network, the model can effectively detect botnets operating under both C2 and P2P structures.","Validated on the public ISCX2014 dataset, our approach achieves a remarkable accuracy of 98.85% and a recall rate of 92.90% for C2 botnets, alongside an accuracy of 99.10% and a recall rate of 94.66% for P2P botnets.","These results not only demonstrate the efficacy of our method, but also surpass the performance of the currently leading detection models."],"url":"http://arxiv.org/abs/2307.10583v1"}
{"created":"2023-07-20 04:46:34","title":"Intelligent model for offshore China sea fog forecasting","abstract":"Accurate and timely prediction of sea fog is very important for effectively managing maritime and coastal economic activities. Given the intricate nature and inherent variability of sea fog, traditional numerical and statistical forecasting methods are often proven inadequate. This study aims to develop an advanced sea fog forecasting method embedded in a numerical weather prediction model using the Yangtze River Estuary (YRE) coastal area as a case study. Prior to training our machine learning model, we employ a time-lagged correlation analysis technique to identify key predictors and decipher the underlying mechanisms driving sea fog occurrence. In addition, we implement ensemble learning and a focal loss function to address the issue of imbalanced data, thereby enhancing the predictive ability of our model. To verify the accuracy of our method, we evaluate its performance using a comprehensive dataset spanning one year, which encompasses both weather station observations and historical forecasts. Remarkably, our machine learning-based approach surpasses the predictive performance of two conventional methods, the weather research and forecasting nonhydrostatic mesoscale model (WRF-NMM) and the algorithm developed by the National Oceanic and Atmospheric Administration (NOAA) Forecast Systems Laboratory (FSL). Specifically, in regard to predicting sea fog with a visibility of less than or equal to 1 km with a lead time of 60 hours, our methodology achieves superior results by increasing the probability of detection (POD) while simultaneously reducing the false alarm ratio (FAR).","sentences":["Accurate and timely prediction of sea fog is very important for effectively managing maritime and coastal economic activities.","Given the intricate nature and inherent variability of sea fog, traditional numerical and statistical forecasting methods are often proven inadequate.","This study aims to develop an advanced sea fog forecasting method embedded in a numerical weather prediction model using the Yangtze River Estuary (YRE) coastal area as a case study.","Prior to training our machine learning model, we employ a time-lagged correlation analysis technique to identify key predictors and decipher the underlying mechanisms driving sea fog occurrence.","In addition, we implement ensemble learning and a focal loss function to address the issue of imbalanced data, thereby enhancing the predictive ability of our model.","To verify the accuracy of our method, we evaluate its performance using a comprehensive dataset spanning one year, which encompasses both weather station observations and historical forecasts.","Remarkably, our machine learning-based approach surpasses the predictive performance of two conventional methods, the weather research and forecasting nonhydrostatic mesoscale model (WRF-NMM) and the algorithm developed by the National Oceanic and Atmospheric Administration (NOAA) Forecast Systems Laboratory (FSL).","Specifically, in regard to predicting sea fog with a visibility of less than or equal to 1 km with a lead time of 60 hours, our methodology achieves superior results by increasing the probability of detection (POD) while simultaneously reducing the false alarm ratio (FAR)."],"url":"http://arxiv.org/abs/2307.10580v1"}
{"created":"2023-07-20 04:45:59","title":"SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning","abstract":"SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting. It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability. However, SecureBoost suffers from high computational complexity and risk of label leakage. To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy. Existing methods either set hyperparameters empirically or heuristically, which are far from optimal. To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage. We design measurements of the three objectives. In particular, the privacy leakage is measured using our proposed instance clustering attack. Experimental results demonstrate that the CMOSB yields not only hyperparameters superior to the baseline but also optimal sets of hyperparameters that can support the flexible requirements of FL participants.","sentences":["SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting.","It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability.","However, SecureBoost suffers from high computational complexity and risk of label leakage.","To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy.","Existing methods either set hyperparameters empirically or heuristically, which are far from optimal.","To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage.","We design measurements of the three objectives.","In particular, the privacy leakage is measured using our proposed instance clustering attack.","Experimental results demonstrate that the CMOSB yields not only hyperparameters superior to the baseline but also optimal sets of hyperparameters that can support the flexible requirements of FL participants."],"url":"http://arxiv.org/abs/2307.10579v1"}
{"created":"2023-07-20 04:41:39","title":"Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning","abstract":"Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events. The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process.   We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest. Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set. Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems.   Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating accurate semantic knowledge of images within a few cycles. It successfully captures both explicit and nuanced elements efficiently. We also introduce the implementation of Korzybski's \"time-binding\" concept in machines, which allows for generational learning and knowledge sharing across deployments.   Our evaluations demonstrate Ethosight's efficacy across 40 complex use cases. It has exhibited an exceptional ability to discern new areas of interest, consistently generating high-affinity scores within the top five labels from a set of a thousand. Tests conducted across diverse environments attest to Ethosight's robust performance. Detailed results and case studies within the main body of this paper and an appendix underscore a promising trajectory towards enhancing the adaptability and resilience of computer vision models in detecting and extracting subtle and nuanced behaviors.","sentences":["Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events.","The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process.   ","We present Ethosight, a novel zero-shot computer vision algorithm.","Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest.","Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set.","Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems.   ","Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating accurate semantic knowledge of images within a few cycles.","It successfully captures both explicit and nuanced elements efficiently.","We also introduce the implementation of Korzybski's \"time-binding\" concept in machines, which allows for generational learning and knowledge sharing across deployments.   ","Our evaluations demonstrate Ethosight's efficacy across 40 complex use cases.","It has exhibited an exceptional ability to discern new areas of interest, consistently generating high-affinity scores within the top five labels from a set of a thousand.","Tests conducted across diverse environments attest to Ethosight's robust performance.","Detailed results and case studies within the main body of this paper and an appendix underscore a promising trajectory towards enhancing the adaptability and resilience of computer vision models in detecting and extracting subtle and nuanced behaviors."],"url":"http://arxiv.org/abs/2307.10577v1"}
{"created":"2023-07-20 04:35:50","title":"Boosting Federated Learning Convergence with Prototype Regularization","abstract":"As a distributed machine learning technique, federated learning (FL) requires clients to collaboratively train a shared model with an edge server without leaking their local data. However, the heterogeneous data distribution among clients often leads to a decrease in model performance. To tackle this issue, this paper introduces a prototype-based regularization strategy to address the heterogeneity in the data distribution. Specifically, the regularization process involves the server aggregating local prototypes from distributed clients to generate a global prototype, which is then sent back to the individual clients to guide their local training. The experimental results on MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3% and 8.9% in average test accuracy, respectively, compared to the most popular baseline FedAvg. Furthermore, our approach has a fast convergence rate in heterogeneous settings.","sentences":["As a distributed machine learning technique, federated learning (FL) requires clients to collaboratively train a shared model with an edge server without leaking their local data.","However, the heterogeneous data distribution among clients often leads to a decrease in model performance.","To tackle this issue, this paper introduces a prototype-based regularization strategy to address the heterogeneity in the data distribution.","Specifically, the regularization process involves the server aggregating local prototypes from distributed clients to generate a global prototype, which is then sent back to the individual clients to guide their local training.","The experimental results on MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3% and 8.9% in average test accuracy, respectively, compared to the most popular baseline FedAvg.","Furthermore, our approach has a fast convergence rate in heterogeneous settings."],"url":"http://arxiv.org/abs/2307.10575v1"}
{"created":"2023-07-20 04:31:39","title":"Adaptive Control of Resource Flow to Optimize Construction Work and Cash Flow via Online Deep Reinforcement Learning","abstract":"Due to complexity and dynamics of construction work, resource, and cash flows, poor management of them usually leads to time and cost overruns, bankruptcy, even project failure. Existing approaches in construction failed to achieve optimal control of resource flow in a dynamic environment with uncertainty. Therefore, this paper introducess a model and method to adaptive control the resource flows to optimize the work and cash flows of construction projects. First, a mathematical model based on a partially observable Markov decision process is established to formulate the complex interactions of construction work, resource, and cash flows as well as uncertainty and variability of diverse influence factors. Meanwhile, to efficiently find the optimal solutions, a deep reinforcement learning (DRL) based method is introduced to realize the continuous adaptive optimal control of labor and material flows, thereby optimizing the work and cash flows. To assist the training process of DRL, a simulator based on discrete event simulation is also developed to mimic the dynamic features and external environments of a project. Experiments in simulated scenarios illustrate that our method outperforms the vanilla empirical method and genetic algorithm, possesses remarkable capability in diverse projects and external environments, and a hybrid agent of DRL and empirical method leads to the best result. This paper contributes to adaptive control and optimization of coupled work, resource, and cash flows, and may serve as a step stone for adopting DRL technology in construction project management.","sentences":["Due to complexity and dynamics of construction work, resource, and cash flows, poor management of them usually leads to time and cost overruns, bankruptcy, even project failure.","Existing approaches in construction failed to achieve optimal control of resource flow in a dynamic environment with uncertainty.","Therefore, this paper introducess a model and method to adaptive control the resource flows to optimize the work and cash flows of construction projects.","First, a mathematical model based on a partially observable Markov decision process is established to formulate the complex interactions of construction work, resource, and cash flows as well as uncertainty and variability of diverse influence factors.","Meanwhile, to efficiently find the optimal solutions, a deep reinforcement learning (DRL) based method is introduced to realize the continuous adaptive optimal control of labor and material flows, thereby optimizing the work and cash flows.","To assist the training process of DRL, a simulator based on discrete event simulation is also developed to mimic the dynamic features and external environments of a project.","Experiments in simulated scenarios illustrate that our method outperforms the vanilla empirical method and genetic algorithm, possesses remarkable capability in diverse projects and external environments, and a hybrid agent of DRL and empirical method leads to the best result.","This paper contributes to adaptive control and optimization of coupled work, resource, and cash flows, and may serve as a step stone for adopting DRL technology in construction project management."],"url":"http://arxiv.org/abs/2307.10574v1"}
{"created":"2023-07-20 04:28:53","title":"Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting","abstract":"Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \\textit{why} such prompting improves performance is unclear. Recent work showed that using logically \\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \\textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \\textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning prompts. We also discover that some CoT prompts used by previous works contain logical errors. This suggests that covariates beyond logically valid reasoning are responsible for performance improvements.","sentences":["Language models can be prompted to reason through problems in a manner that significantly improves performance.","However, \\textit{why} such prompting improves performance is unclear.","Recent work showed that using logically \\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \\textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance.","Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions.","To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH).","We find that the logically \\textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning prompts.","We also discover that some CoT prompts used by previous works contain logical errors.","This suggests that covariates beyond logically valid reasoning are responsible for performance improvements."],"url":"http://arxiv.org/abs/2307.10573v1"}
{"created":"2023-07-20 04:24:49","title":"Image or Information? Examining the Nature and Impact of Visualization Perceptual Classification","abstract":"How do people internalize visualizations: as images or information? In this study, we investigate the nature of internalization for visualizations (i.e., how the mind encodes visualizations in memory) and how memory encoding affects its retrieval. This exploratory work examines the influence of various design elements on a user's perception of a chart. Specifically, which design elements lead to perceptions of visualization as an image or as information? Understanding how design elements contribute to viewers perceiving a visualization more as an image or information will help designers decide which elements to include to achieve their communication goals. For this study, we annotated 500 visualizations and analyzed the responses of 250 online participants, who rated the visualizations on a bilinear scale as image or information. We then conducted an in-person study (n = 101) using a free recall task to examine how the image/information ratings and design elements impact memory. The results revealed several interesting findings: Image-rated visualizations were perceived as more aesthetically appealing, enjoyable, and pleasing. Information-rated visualizations were perceived as less difficult to understand and more aesthetically likable and nice, though participants expressed higher positive sentiment when viewing image-rated visualizations and felt less guided to a conclusion. We also found different patterns among participants that were older. Importantly, we show that visualizations internalized as images are less effective in conveying trends and messages, though they elicit a more positive emotional judgment, while informative visualizations exhibit annotation focused recall and elicit a more positive design judgment. We discuss the implications of this dissociation between aesthetic pleasure and perceived ease of use in visualization design.","sentences":["How do people internalize visualizations: as images or information?","In this study, we investigate the nature of internalization for visualizations (i.e., how the mind encodes visualizations in memory) and how memory encoding affects its retrieval.","This exploratory work examines the influence of various design elements on a user's perception of a chart.","Specifically, which design elements lead to perceptions of visualization as an image or as information?","Understanding how design elements contribute to viewers perceiving a visualization more as an image or information will help designers decide which elements to include to achieve their communication goals.","For this study, we annotated 500 visualizations and analyzed the responses of 250 online participants, who rated the visualizations on a bilinear scale as image or information.","We then conducted an in-person study (n = 101) using a free recall task to examine how the image/information ratings and design elements impact memory.","The results revealed several interesting findings: Image-rated visualizations were perceived as more aesthetically appealing, enjoyable, and pleasing.","Information-rated visualizations were perceived as less difficult to understand and more aesthetically likable and nice, though participants expressed higher positive sentiment when viewing image-rated visualizations and felt less guided to a conclusion.","We also found different patterns among participants that were older.","Importantly, we show that visualizations internalized as images are less effective in conveying trends and messages, though they elicit a more positive emotional judgment, while informative visualizations exhibit annotation focused recall and elicit a more positive design judgment.","We discuss the implications of this dissociation between aesthetic pleasure and perceived ease of use in visualization design."],"url":"http://arxiv.org/abs/2307.10571v1"}
