{"created":"2023-07-19 17:58:03","title":"DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering","abstract":"Realistic human-centric rendering plays a key role in both computer vision and computer graphics. Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity, which are crucial for rendering effect. Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require methods to be robust across different scenarios. In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering. DNA-Rendering presents several alluring attributes. First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames' data volume. Second, we provide rich assets for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos. These assets boost the current method's accuracy on downstream rendering tasks. Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation. Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity rendering methods. In this manuscript, we describe our DNA-Rendering effort as a revealing of new observations, challenges, and future directions to human-centric rendering. The dataset, code, and benchmarks will be publicly available at https://dna-rendering.github.io/","sentences":["Realistic human-centric rendering plays a key role in both computer vision and computer graphics.","Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity, which are crucial for rendering effect.","Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require methods to be robust across different scenarios.","In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering.","DNA-Rendering presents several alluring attributes.","First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames' data volume.","Second, we provide rich assets for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos.","These assets boost the current method's accuracy on downstream rendering tasks.","Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation.","Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity rendering methods.","In this manuscript, we describe our DNA-Rendering effort as a revealing of new observations, challenges, and future directions to human-centric rendering.","The dataset, code, and benchmarks will be publicly available at https://dna-rendering.github.io/"],"url":"http://arxiv.org/abs/2307.10173v1"}
{"created":"2023-07-19 17:57:53","title":"DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI","abstract":"Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio. To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio are made publicly accessible at https://github.com/salesforce/DialogStudio","sentences":["Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness.","To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information.","Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training.","To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning.","Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio.","To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio are made publicly accessible at https://github.com/salesforce/DialogStudio"],"url":"http://arxiv.org/abs/2307.10172v1"}
{"created":"2023-07-19 17:57:27","title":"LightPath: Lightweight and Scalable Path Representation Learning","abstract":"Movement paths are used widely in intelligent transportation and smart city applications. To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation. In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential. Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability.   We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability. More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good scalability with respect to path length. Next, we propose a relational reasoning framework to enable faster training of more robust sparse path encoders. We also propose global-local knowledge distillation to further reduce the size and improve the performance of sparse path encoders. Finally, we report extensive experiments on two real-world datasets to offer insight into the efficiency, scalability, and effectiveness of the proposed framework.","sentences":["Movement paths are used widely in intelligent transportation and smart city applications.","To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation.","In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential.","Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability.   ","We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability.","More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good scalability with respect to path length.","Next, we propose a relational reasoning framework to enable faster training of more robust sparse path encoders.","We also propose global-local knowledge distillation to further reduce the size and improve the performance of sparse path encoders.","Finally, we report extensive experiments on two real-world datasets to offer insight into the efficiency, scalability, and effectiveness of the proposed framework."],"url":"http://arxiv.org/abs/2307.10171v1"}
{"created":"2023-07-19 17:55:13","title":"Challenges and Applications of Large Language Models","abstract":"Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive.","sentences":["Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years.","Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas.","In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive."],"url":"http://arxiv.org/abs/2307.10169v1"}
{"created":"2023-07-19 17:54:43","title":"LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs","abstract":"LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers' abilities in these \"human computation algorithms,\" but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate (1) the relative strengths of LLMs on different tasks (by cross-comparing their performances on sub-tasks) and (2) LLMs' potential in complex tasks, where they can complete part of the tasks while leaving others to humans.","sentences":["LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities.","However, current efforts focus mainly on simple atomic tasks.","We explore whether LLMs can replicate more complex crowdsourcing pipelines.","We find that modern LLMs can simulate some of crowdworkers' abilities in these \"human computation algorithms,\" but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks.","We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets.","Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate (1) the relative strengths of LLMs on different tasks (by cross-comparing their performances on sub-tasks) and (2) LLMs' potential in complex tasks, where they can complete part of the tasks while leaving others to humans."],"url":"http://arxiv.org/abs/2307.10168v1"}
{"created":"2023-07-19 17:50:03","title":"Adversarial Latent Autoencoder with Self-Attention for Structural Image Synthesis","abstract":"Generative Engineering Design approaches driven by Deep Generative Models (DGM) have been proposed to facilitate industrial engineering processes. In such processes, designs often come in the form of images, such as blueprints, engineering drawings, and CAD models depending on the level of detail. DGMs have been successfully employed for synthesis of natural images, e.g., displaying animals, human faces and landscapes. However, industrial design images are fundamentally different from natural scenes in that they contain rich structural patterns and long-range dependencies, which are challenging for convolution-based DGMs to generate. Moreover, DGM-driven generation process is typically triggered based on random noisy inputs, which outputs unpredictable samples and thus cannot perform an efficient industrial design exploration. We tackle these challenges by proposing a novel model Self-Attention Adversarial Latent Autoencoder (SA-ALAE), which allows generating feasible design images of complex engineering parts. With SA-ALAE, users can not only explore novel variants of an existing design, but also control the generation process by operating in latent space. The potential of SA-ALAE is shown by generating engineering blueprints in a real automotive design task.","sentences":["Generative Engineering Design approaches driven by Deep Generative Models (DGM) have been proposed to facilitate industrial engineering processes.","In such processes, designs often come in the form of images, such as blueprints, engineering drawings, and CAD models depending on the level of detail.","DGMs have been successfully employed for synthesis of natural images, e.g., displaying animals, human faces and landscapes.","However, industrial design images are fundamentally different from natural scenes in that they contain rich structural patterns and long-range dependencies, which are challenging for convolution-based DGMs to generate.","Moreover, DGM-driven generation process is typically triggered based on random noisy inputs, which outputs unpredictable samples and thus cannot perform an efficient industrial design exploration.","We tackle these challenges by proposing a novel model Self-Attention Adversarial Latent Autoencoder (SA-ALAE), which allows generating feasible design images of complex engineering parts.","With SA-ALAE, users can not only explore novel variants of an existing design, but also control the generation process by operating in latent space.","The potential of SA-ALAE is shown by generating engineering blueprints in a real automotive design task."],"url":"http://arxiv.org/abs/2307.10166v1"}
{"created":"2023-07-19 17:46:55","title":"Drone navigation and license place detection for vehicle location in indoor spaces","abstract":"Millions of vehicles are transported every year, tightly parked in vessels or boats. To reduce the risks of associated safety issues like fires, knowing the location of vehicles is essential, since different vehicles may need different mitigation measures, e.g. electric cars. This work is aimed at creating a solution based on a nano-drone that navigates across rows of parked vehicles and detects their license plates. We do so via a wall-following algorithm, and a CNN trained to detect license plates. All computations are done in real-time on the drone, which just sends position and detected images that allow the creation of a 2D map with the position of the plates. Our solution is capable of reading all plates across eight test cases (with several rows of plates, different drone speeds, or low light) by aggregation of measurements across several drone journeys.","sentences":["Millions of vehicles are transported every year, tightly parked in vessels or boats.","To reduce the risks of associated safety issues like fires, knowing the location of vehicles is essential, since different vehicles may need different mitigation measures, e.g. electric cars.","This work is aimed at creating a solution based on a nano-drone that navigates across rows of parked vehicles and detects their license plates.","We do so via a wall-following algorithm, and a CNN trained to detect license plates.","All computations are done in real-time on the drone, which just sends position and detected images that allow the creation of a 2D map with the position of the plates.","Our solution is capable of reading all plates across eight test cases (with several rows of plates, different drone speeds, or low light) by aggregation of measurements across several drone journeys."],"url":"http://arxiv.org/abs/2307.10165v1"}
{"created":"2023-07-19 17:46:00","title":"Optimized Design of Joint Mirror Array and Liquid Crystal-Based RIS-Aided VLC systems","abstract":"Most studies of reflecting intelligent surfaces (RISs)-assisted visible light communication (VLC) systems have focused on the integration of RISs in the channel to combat the line-of-sight (LoS) blockage and to enhance the corresponding achievable data rate. Some recent efforts have investigated the integration of liquid crystal (LC)-RIS in the VLC receiver to also improve the corresponding achievable data rate. To jointly benefit from the previously mentioned appealing capabilities of the RIS technology in both the channel and the receiver, in this work, we propose a novel indoor VLC system that is jointly assisted by a mirror array-based RIS in the channel and an LC-based RIS aided-VLC receiver. To illustrate the performance of the proposed system, a rate maximization problem is formulated, solved, and evaluated. This maximization problem jointly optimizes the roll and yaw angles of the mirror array-based RIS as well as the refractive index of the LC-based RIS VLC receiver. Moreover, this maximization problem considers practical assumptions, such as the presence of non-users blockers in the LoS path between the transmitter-receiver pair and the user's random device orientation (i.e., the user's self-blockage). Due to the non-convexity of the formulated optimization problem, a low-complexity algorithm is utilized to get the global optimal solution. A multi-user scenario of the proposed scheme is also presented. Furthermore, the energy efficiency of the proposed system is also investigated. Simulation results are provided, confirming that the proposed system yields a noteworthy improvement in data rate and energy efficiency performances compared to several baseline schemes.","sentences":["Most studies of reflecting intelligent surfaces (RISs)-assisted visible light communication (VLC) systems have focused on the integration of RISs in the channel to combat the line-of-sight (LoS) blockage and to enhance the corresponding achievable data rate.","Some recent efforts have investigated the integration of liquid crystal (LC)-RIS in the VLC receiver to also improve the corresponding achievable data rate.","To jointly benefit from the previously mentioned appealing capabilities of the RIS technology in both the channel and the receiver, in this work, we propose a novel indoor VLC system that is jointly assisted by a mirror array-based RIS in the channel and an LC-based RIS aided-VLC receiver.","To illustrate the performance of the proposed system, a rate maximization problem is formulated, solved, and evaluated.","This maximization problem jointly optimizes the roll and yaw angles of the mirror array-based RIS as well as the refractive index of the LC-based RIS VLC receiver.","Moreover, this maximization problem considers practical assumptions, such as the presence of non-users blockers in the LoS path between the transmitter-receiver pair and the user's random device orientation (i.e., the user's self-blockage).","Due to the non-convexity of the formulated optimization problem, a low-complexity algorithm is utilized to get the global optimal solution.","A multi-user scenario of the proposed scheme is also presented.","Furthermore, the energy efficiency of the proposed system is also investigated.","Simulation results are provided, confirming that the proposed system yields a noteworthy improvement in data rate and energy efficiency performances compared to several baseline schemes."],"url":"http://arxiv.org/abs/2307.10164v1"}
{"created":"2023-07-19 17:44:54","title":"Rethinking Backdoor Attacks","abstract":"In a backdoor attack, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation. Defending against such attacks typically involves viewing these inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them.   In this work, we present a different approach to the backdoor attack problem. Specifically, we show that without structural information about the training data distribution, backdoor attacks are indistinguishable from naturally-occurring features in the data--and thus impossible to \"detect\" in a general sense. Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make and on which they depend. Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the strongest feature in the training data. Under this assumption (which we make formal) we develop a new primitive for detecting backdoor attacks. Our primitive naturally gives rise to a detection algorithm that comes with theoretical guarantees and is effective in practice.","sentences":["In a backdoor attack, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation.","Defending against such attacks typically involves viewing these inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them.   ","In this work, we present a different approach to the backdoor attack problem.","Specifically, we show that without structural information about the training data distribution, backdoor attacks are indistinguishable from naturally-occurring features in the data--and thus impossible to \"detect\" in a general sense.","Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make and on which they depend.","Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the strongest feature in the training data.","Under this assumption (which we make formal) we develop a new primitive for detecting backdoor attacks.","Our primitive naturally gives rise to a detection algorithm that comes with theoretical guarantees and is effective in practice."],"url":"http://arxiv.org/abs/2307.10163v1"}
{"created":"2023-07-19 17:44:49","title":"RTVis: Research Trend Visualization Toolkit","abstract":"When researchers and practitioners are about to start a new project or have just entered a new research field, choosing a proper research topic is always challenging. To help them have an overall understanding of the research trend in real-time and find out the research topic they are interested in, we develop the Research Trend Visualization toolkit (RTVis) to analyze and visualize the research paper information. RTVis consists of a field theme river, a co-occurrence network, a specialized citation bar chart, and a word frequency race diagram, showing the field change through time respectively, cooperating relationship among authors, paper citation numbers in different venues, and the most common words in the abstract part. Moreover, RTVis is open source and easy to deploy. The demo of our toolkit and code with detailed documentation are both available online.","sentences":["When researchers and practitioners are about to start a new project or have just entered a new research field, choosing a proper research topic is always challenging.","To help them have an overall understanding of the research trend in real-time and find out the research topic they are interested in, we develop the Research Trend Visualization toolkit (RTVis) to analyze and visualize the research paper information.","RTVis consists of a field theme river, a co-occurrence network, a specialized citation bar chart, and a word frequency race diagram, showing the field change through time respectively, cooperating relationship among authors, paper citation numbers in different venues, and the most common words in the abstract part.","Moreover, RTVis is open source and easy to deploy.","The demo of our toolkit and code with detailed documentation are both available online."],"url":"http://arxiv.org/abs/2307.10162v1"}
{"created":"2023-07-19 17:42:36","title":"Robust Driving Policy Learning with Guided Meta Reinforcement Learning","abstract":"Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unseen situations with out-of-distribution (OOD) social agents' behaviors in a challenging uncontrolled T-intersection scenario.","sentences":["Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment.","This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors.","In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy.","By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives.","We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy.","Our method successfully learns an ego driving policy that generalizes well to unseen situations with out-of-distribution (OOD) social agents' behaviors in a challenging uncontrolled T-intersection scenario."],"url":"http://arxiv.org/abs/2307.10160v1"}
{"created":"2023-07-19 17:39:39","title":"FABRIC: Personalizing Diffusion Models with Iterative Feedback","abstract":"In an era where visual content generation is increasingly driven by machine learning, the integration of human feedback into generative models presents significant opportunities for enhancing user experience and output quality. This study explores strategies for incorporating iterative human feedback into the generative process of diffusion-based text-to-image models. We propose FABRIC, a training-free approach applicable to a wide range of popular diffusion models, which exploits the self-attention layer present in the most widely used architectures to condition the diffusion process on a set of feedback images. To ensure a rigorous assessment of our approach, we introduce a comprehensive evaluation methodology, offering a robust mechanism to quantify the performance of generative visual models that integrate human feedback. We show that generation results improve over multiple rounds of iterative feedback through exhaustive analysis, implicitly optimizing arbitrary user preferences. The potential applications of these findings extend to fields such as personalized content creation and customization.","sentences":["In an era where visual content generation is increasingly driven by machine learning, the integration of human feedback into generative models presents significant opportunities for enhancing user experience and output quality.","This study explores strategies for incorporating iterative human feedback into the generative process of diffusion-based text-to-image models.","We propose FABRIC, a training-free approach applicable to a wide range of popular diffusion models, which exploits the self-attention layer present in the most widely used architectures to condition the diffusion process on a set of feedback images.","To ensure a rigorous assessment of our approach, we introduce a comprehensive evaluation methodology, offering a robust mechanism to quantify the performance of generative visual models that integrate human feedback.","We show that generation results improve over multiple rounds of iterative feedback through exhaustive analysis, implicitly optimizing arbitrary user preferences.","The potential applications of these findings extend to fields such as personalized content creation and customization."],"url":"http://arxiv.org/abs/2307.10159v1"}
{"created":"2023-07-19 17:38:26","title":"Leveraging Visemes for Better Visual Speech Representation and Lip Reading","abstract":"Lip reading is a challenging task that has many potential applications in speech recognition, human-computer interaction, and security systems. However, existing lip reading systems often suffer from low accuracy due to the limitations of video features. In this paper, we propose a novel approach that leverages visemes, which are groups of phonetically similar lip shapes, to extract more discriminative and robust video features for lip reading. We evaluate our approach on various tasks, including word-level and sentence-level lip reading, and audiovisual speech recognition using the Arman-AV dataset, a largescale Persian corpus. Our experimental results show that our viseme based approach consistently outperforms the state-of-theart methods in all these tasks. The proposed method reduces the lip-reading word error rate (WER) by 9.1% relative to the best previous method.","sentences":["Lip reading is a challenging task that has many potential applications in speech recognition, human-computer interaction, and security systems.","However, existing lip reading systems often suffer from low accuracy due to the limitations of video features.","In this paper, we propose a novel approach that leverages visemes, which are groups of phonetically similar lip shapes, to extract more discriminative and robust video features for lip reading.","We evaluate our approach on various tasks, including word-level and sentence-level lip reading, and audiovisual speech recognition using the Arman-AV dataset, a largescale Persian corpus.","Our experimental results show that our viseme based approach consistently outperforms the state-of-theart methods in all these tasks.","The proposed method reduces the lip-reading word error rate (WER) by 9.1% relative to the best previous method."],"url":"http://arxiv.org/abs/2307.10157v1"}
{"created":"2023-07-19 17:37:03","title":"Exploring Transformer Extrapolation","abstract":"Length extrapolation has attracted considerable attention recently since it allows transformers to be tested on longer sequences than those used in training. Previous research has shown that this property can be attained by using carefully designed Relative Positional Encodings (RPEs). While these methods perform well on a variety of corpora, the conditions for length extrapolation have yet to be investigated. This paper attempts to determine what types of RPEs allow for length extrapolation through a thorough mathematical and empirical analysis. We discover that a transformer is certain to possess this property as long as the series that corresponds to the RPE's exponential converges. Two practices are derived from the conditions and examined in language modeling tasks on a variety of corpora. As a bonus from the conditions, we derive a new Theoretical Receptive Field (TRF) to measure the receptive field of RPEs without taking any training steps. Extensive experiments are conducted on the Wikitext-103, Books, Github, and WikiBook datasets to demonstrate the viability of our discovered conditions. We also compare TRF to Empirical Receptive Field (ERF) across different models, showing consistently matched trends on the aforementioned datasets. The code is available at https://github.com/OpenNLPLab/Rpe.","sentences":["Length extrapolation has attracted considerable attention recently since it allows transformers to be tested on longer sequences than those used in training.","Previous research has shown that this property can be attained by using carefully designed Relative Positional Encodings (RPEs).","While these methods perform well on a variety of corpora, the conditions for length extrapolation have yet to be investigated.","This paper attempts to determine what types of RPEs allow for length extrapolation through a thorough mathematical and empirical analysis.","We discover that a transformer is certain to possess this property as long as the series that corresponds to the RPE's exponential converges.","Two practices are derived from the conditions and examined in language modeling tasks on a variety of corpora.","As a bonus from the conditions, we derive a new Theoretical Receptive Field (TRF) to measure the receptive field of RPEs without taking any training steps.","Extensive experiments are conducted on the Wikitext-103, Books, Github, and WikiBook datasets to demonstrate the viability of our discovered conditions.","We also compare TRF to Empirical Receptive Field (ERF) across different models, showing consistently matched trends on the aforementioned datasets.","The code is available at https://github.com/OpenNLPLab/Rpe."],"url":"http://arxiv.org/abs/2307.10156v1"}
{"created":"2023-07-19 17:35:08","title":"Curvature-based Clustering on Graphs","abstract":"Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms, which exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis.","sentences":["Unsupervised node clustering (or community detection) is a classical graph learning task.","In this paper, we study algorithms, which exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities.","Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure.","We consider several discrete curvature notions and analyze the utility of the resulting algorithms.","In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap.","For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual.","We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms.","In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis."],"url":"http://arxiv.org/abs/2307.10155v1"}
{"created":"2023-07-19 17:29:05","title":"Contact-aware Shaping and Maintenance of Deformable Linear Objects With Fixtures","abstract":"Studying the manipulation of deformable linear objects has significant practical applications in industry, including car manufacturing, textile production, and electronics automation. However, deformable linear object manipulation poses a significant challenge in developing planning and control algorithms, due to the precise and continuous control required to effectively manipulate the deformable nature of these objects. In this paper, we propose a new framework to control and maintain the shape of deformable linear objects with two robot manipulators utilizing environmental contacts. The framework is composed of a shape planning algorithm which automatically generates appropriate positions to place fixtures, and an object-centered skill engine which includes task and motion planning to control the motion and force of both robots based on the object status. The status of the deformable linear object is estimated online utilizing visual as well as force information. The framework manages to handle a cable routing task in real-world experiments with two Panda robots and especially achieves contact-aware and flexible clip fixing with challenging fixtures.","sentences":["Studying the manipulation of deformable linear objects has significant practical applications in industry, including car manufacturing, textile production, and electronics automation.","However, deformable linear object manipulation poses a significant challenge in developing planning and control algorithms, due to the precise and continuous control required to effectively manipulate the deformable nature of these objects.","In this paper, we propose a new framework to control and maintain the shape of deformable linear objects with two robot manipulators utilizing environmental contacts.","The framework is composed of a shape planning algorithm which automatically generates appropriate positions to place fixtures, and an object-centered skill engine which includes task and motion planning to control the motion and force of both robots based on the object status.","The status of the deformable linear object is estimated online utilizing visual as well as force information.","The framework manages to handle a cable routing task in real-world experiments with two Panda robots and especially achieves contact-aware and flexible clip fixing with challenging fixtures."],"url":"http://arxiv.org/abs/2307.10153v1"}
{"created":"2023-07-19 17:12:28","title":"Benchmarking Potential Based Rewards for Learning Humanoid Locomotion","abstract":"The main challenge in developing effective reinforcement learning (RL) pipelines is often the design and tuning the reward functions. Well-designed shaping reward can lead to significantly faster learning. Naively formulated rewards, however, can conflict with the desired behavior and result in overfitting or even erratic performance if not properly tuned. In theory, the broad class of potential based reward shaping (PBRS) can help guide the learning process without affecting the optimal policy. Although several studies have explored the use of potential based reward shaping to accelerate learning convergence, most have been limited to grid-worlds and low-dimensional systems, and RL in robotics has predominantly relied on standard forms of reward shaping. In this paper, we benchmark standard forms of shaping with PBRS for a humanoid robot. We find that in this high-dimensional system, PBRS has only marginal benefits in convergence speed. However, the PBRS reward terms are significantly more robust to scaling than typical reward shaping approaches, and thus easier to tune.","sentences":["The main challenge in developing effective reinforcement learning (RL) pipelines is often the design and tuning the reward functions.","Well-designed shaping reward can lead to significantly faster learning.","Naively formulated rewards, however, can conflict with the desired behavior and result in overfitting or even erratic performance if not properly tuned.","In theory, the broad class of potential based reward shaping (PBRS) can help guide the learning process without affecting the optimal policy.","Although several studies have explored the use of potential based reward shaping to accelerate learning convergence, most have been limited to grid-worlds and low-dimensional systems, and RL in robotics has predominantly relied on standard forms of reward shaping.","In this paper, we benchmark standard forms of shaping with PBRS for a humanoid robot.","We find that in this high-dimensional system, PBRS has only marginal benefits in convergence speed.","However, the PBRS reward terms are significantly more robust to scaling than typical reward shaping approaches, and thus easier to tune."],"url":"http://arxiv.org/abs/2307.10142v1"}
{"created":"2023-07-19 17:00:45","title":"An Improved NeuMIP with Better Accuracy","abstract":"Neural reflectance models are capable of accurately reproducing the spatially-varying appearance of many real-world materials at different scales. However, existing methods have difficulties handling highly glossy materials. To address this problem, we introduce a new neural reflectance model which, compared with existing methods, better preserves not only specular highlights but also fine-grained details. To this end, we enhance the neural network performance by encoding input data to frequency space, inspired by NeRF, to better preserve the details. Furthermore, we introduce a gradient-based loss and employ it in multiple stages, adaptive to the progress of the learning phase. Lastly, we utilize an optional extension to the decoder network using the Inception module for more accurate yet costly performance. We demonstrate the effectiveness of our method using a variety of synthetic and real examples.","sentences":["Neural reflectance models are capable of accurately reproducing the spatially-varying appearance of many real-world materials at different scales.","However, existing methods have difficulties handling highly glossy materials.","To address this problem, we introduce a new neural reflectance model which, compared with existing methods, better preserves not only specular highlights but also fine-grained details.","To this end, we enhance the neural network performance by encoding input data to frequency space, inspired by NeRF, to better preserve the details.","Furthermore, we introduce a gradient-based loss and employ it in multiple stages, adaptive to the progress of the learning phase.","Lastly, we utilize an optional extension to the decoder network using the Inception module for more accurate yet costly performance.","We demonstrate the effectiveness of our method using a variety of synthetic and real examples."],"url":"http://arxiv.org/abs/2307.10135v1"}
{"created":"2023-07-19 16:54:56","title":"On the work of dynamic constant-time parallel algorithms for regular tree languages and context-free languages","abstract":"Previous work on Dynamic Complexity has established that there exist dynamic constant-time parallel algorithms for regular tree languages and context-free languages under label or symbol changes. However, these algorithms were not developed with the goal to minimise work (or, equivalently, the number of processors). In fact, their inspection yields the work bounds $O(n^2)$ and $O(n^7)$ per change operation, respectively. In this paper, dynamic algorithms for regular tree languages are proposed that generalise the previous algorithms in that they allow unbounded node rank and leaf insertions, while improving the work bound from $O(n^2)$ to $O(n^{\\epsilon})$, for arbitrary $\\epsilon > 0$. For context-free languages, algorithms with better work bounds (compared with $O(n^7)$) for restricted classes are proposed: for every $\\epsilon > 0$ there are such algorithms for deterministic context-free languages with work bound $O(n^{3+\\epsilon})$ and for visibly pushdown languages with work bound $O(n^{2+\\epsilon})$.","sentences":["Previous work on Dynamic Complexity has established that there exist dynamic constant-time parallel algorithms for regular tree languages and context-free languages under label or symbol changes.","However, these algorithms were not developed with the goal to minimise work (or, equivalently, the number of processors).","In fact, their inspection yields the work bounds $O(n^2)$ and $O(n^7)$ per change operation, respectively.","In this paper, dynamic algorithms for regular tree languages are proposed that generalise the previous algorithms in that they allow unbounded node rank and leaf insertions, while improving the work bound from $O(n^2)$ to $O(n^{\\epsilon})$, for arbitrary $\\epsilon > 0$.","For context-free languages, algorithms with better work bounds (compared with $O(n^7)$) for restricted classes are proposed: for every $\\epsilon > 0$ there are such algorithms for deterministic context-free languages with work bound $O(n^{3+\\epsilon})$ and for visibly pushdown languages with work bound $O(n^{2+\\epsilon})$."],"url":"http://arxiv.org/abs/2307.10131v1"}
{"created":"2023-07-19 16:51:59","title":"General vs. Long-Tailed Age Estimation: An Approach to Kill Two Birds with One Stone","abstract":"Facial age estimation has received a lot of attention for its diverse application scenarios. Most existing studies treat each sample equally and aim to reduce the average estimation error for the entire dataset, which can be summarized as General Age Estimation. However, due to the long-tailed distribution prevalent in the dataset, treating all samples equally will inevitably bias the model toward the head classes (usually the adult with a majority of samples). Driven by this, some works suggest that each class should be treated equally to improve performance in tail classes (with a minority of samples), which can be summarized as Long-tailed Age Estimation. However, Long-tailed Age Estimation usually faces a performance trade-off, i.e., achieving improvement in tail classes by sacrificing the head classes. In this paper, our goal is to design a unified framework to perform well on both tasks, killing two birds with one stone. To this end, we propose a simple, effective, and flexible training paradigm named GLAE, which is two-fold. Our GLAE provides a surprising improvement on Morph II, reaching the lowest MAE and CMAE of 1.14 and 1.27 years, respectively. Compared to the previous best method, MAE dropped by up to 34%, which is an unprecedented improvement, and for the first time, MAE is close to 1 year old. Extensive experiments on other age benchmark datasets, including CACD, MIVIA, and Chalearn LAP 2015, also indicate that GLAE outperforms the state-of-the-art approaches significantly.","sentences":["Facial age estimation has received a lot of attention for its diverse application scenarios.","Most existing studies treat each sample equally and aim to reduce the average estimation error for the entire dataset, which can be summarized as General Age Estimation.","However, due to the long-tailed distribution prevalent in the dataset, treating all samples equally will inevitably bias the model toward the head classes (usually the adult with a majority of samples).","Driven by this, some works suggest that each class should be treated equally to improve performance in tail classes (with a minority of samples), which can be summarized as Long-tailed Age Estimation.","However, Long-tailed Age Estimation usually faces a performance trade-off, i.e., achieving improvement in tail classes by sacrificing the head classes.","In this paper, our goal is to design a unified framework to perform well on both tasks, killing two birds with one stone.","To this end, we propose a simple, effective, and flexible training paradigm named GLAE, which is two-fold.","Our GLAE provides a surprising improvement on Morph II, reaching the lowest MAE and CMAE of 1.14 and 1.27 years, respectively.","Compared to the previous best method, MAE dropped by up to 34%, which is an unprecedented improvement, and for the first time, MAE is close to 1 year old.","Extensive experiments on other age benchmark datasets, including CACD, MIVIA, and Chalearn LAP 2015, also indicate that GLAE outperforms the state-of-the-art approaches significantly."],"url":"http://arxiv.org/abs/2307.10129v1"}
{"created":"2023-07-19 16:42:52","title":"Two Approaches to Supervised Image Segmentation","abstract":"Though performed almost effortlessly by humans, segmenting 2D gray-scale or color images in terms of their constituent regions of interest (e.g.~background, objects or portions of objects) constitutes one of the greatest challenges in science and technology as a consequence of the involved dimensionality reduction(3D to 2D), noise, reflections, shades, and occlusions, among many other possible effects. While a large number of interesting approaches have been respectively suggested along the last decades, it was mainly with the more recent development of deep learning that more effective and general solutions have been obtained, currently constituting the basic comparison reference for this type of operation. Also developed recently, a multiset-based methodology has been described that is capable of encouraging performance that combines spatial accuracy, stability, and robustness while requiring minimal computational resources (hardware and/or training and recognition time). The interesting features of the latter methodology mostly follow from the enhanced selectivity and sensitivity, as well as good robustness to data perturbations and outliers, allowed by the coincidence similarity index on which the multiset approach to supervised image segmentation is based. After describing the deep learning and multiset approaches, the present work develops two comparison experiments between them which are primarily aimed at illustrating their respective main interesting features when applied to the adopted specific type of data and parameter configurations. While the deep learning approach confirmed its potential for performing image segmentation, the alternative multiset methodology allowed for encouraging accuracy while requiring little computational resources.","sentences":["Though performed almost effortlessly by humans, segmenting 2D gray-scale or color images in terms of their constituent regions of interest (e.g.~background, objects or portions of objects) constitutes one of the greatest challenges in science and technology as a consequence of the involved dimensionality reduction(3D to 2D), noise, reflections, shades, and occlusions, among many other possible effects.","While a large number of interesting approaches have been respectively suggested along the last decades, it was mainly with the more recent development of deep learning that more effective and general solutions have been obtained, currently constituting the basic comparison reference for this type of operation.","Also developed recently, a multiset-based methodology has been described that is capable of encouraging performance that combines spatial accuracy, stability, and robustness while requiring minimal computational resources (hardware and/or training and recognition time).","The interesting features of the latter methodology mostly follow from the enhanced selectivity and sensitivity, as well as good robustness to data perturbations and outliers, allowed by the coincidence similarity index on which the multiset approach to supervised image segmentation is based.","After describing the deep learning and multiset approaches, the present work develops two comparison experiments between them which are primarily aimed at illustrating their respective main interesting features when applied to the adopted specific type of data and parameter configurations.","While the deep learning approach confirmed its potential for performing image segmentation, the alternative multiset methodology allowed for encouraging accuracy while requiring little computational resources."],"url":"http://arxiv.org/abs/2307.10123v1"}
{"created":"2023-07-19 16:29:25","title":"Dynamic constant time parallel graph algorithms with sub-linear work","abstract":"The paper proposes dynamic parallel algorithms for connectivity and bipartiteness of undirected graphs that require constant time and $O(n^{1/2+\\epsilon})$ work on the CRCW PRAM model. The work of these algorithms almost matches the work of the $O(\\log n)$ time algorithm for connectivity by Kopelowitz et al. (2018) on the EREW PRAM model and the time of the sequential algorithm for bipartiteness by Eppstein et al. (1997). In particular, we show that the sparsification technique, which has been used in both mentioned papers, can in principle also be used for constant time algorithms in the CRCW PRAM model, despite the logarithmic depth of sparsification trees.","sentences":["The paper proposes dynamic parallel algorithms for connectivity and bipartiteness of undirected graphs that require constant time and $O(n^{1/2+\\epsilon})$ work on the CRCW PRAM model.","The work of these algorithms almost matches the work of the $O(\\log n)$ time algorithm for connectivity by Kopelowitz et al.","(2018) on the EREW PRAM model and the time of the sequential algorithm for bipartiteness by Eppstein et al. (1997).","In particular, we show that the sparsification technique, which has been used in both mentioned papers, can in principle also be used for constant time algorithms in the CRCW PRAM model, despite the logarithmic depth of sparsification trees."],"url":"http://arxiv.org/abs/2307.10107v1"}
{"created":"2023-07-19 16:13:13","title":"Gradient Sparsification For Masked Fine-Tuning of Transformers","abstract":"Fine-tuning pretrained self-supervised language models is widely adopted for transfer learning to downstream tasks. Fine-tuning can be achieved by freezing gradients of the pretrained network and only updating gradients of a newly added classification layer, or by performing gradient updates on all parameters. Gradual unfreezing makes a trade-off between the two by gradually unfreezing gradients of whole layers during training. This has been an effective strategy to trade-off between storage and training speed with generalization performance. However, it is not clear whether gradually unfreezing layers throughout training is optimal, compared to sparse variants of gradual unfreezing which may improve fine-tuning performance. In this paper, we propose to stochastically mask gradients to regularize pretrained language models for improving overall fine-tuned performance. We introduce GradDrop and variants thereof, a class of gradient sparsification methods that mask gradients during the backward pass, acting as gradient noise. GradDrop is sparse and stochastic unlike gradual freezing. Extensive experiments on the multilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive against methods that use additional translated data for intermediate pretraining and outperforms standard fine-tuning and gradual unfreezing. A post-analysis shows how GradDrop improves performance with languages it was not trained on, such as under-resourced languages.","sentences":["Fine-tuning pretrained self-supervised language models is widely adopted for transfer learning to downstream tasks.","Fine-tuning can be achieved by freezing gradients of the pretrained network and only updating gradients of a newly added classification layer, or by performing gradient updates on all parameters.","Gradual unfreezing makes a trade-off between the two by gradually unfreezing gradients of whole layers during training.","This has been an effective strategy to trade-off between storage and training speed with generalization performance.","However, it is not clear whether gradually unfreezing layers throughout training is optimal, compared to sparse variants of gradual unfreezing which may improve fine-tuning performance.","In this paper, we propose to stochastically mask gradients to regularize pretrained language models for improving overall fine-tuned performance.","We introduce GradDrop and variants thereof, a class of gradient sparsification methods that mask gradients during the backward pass, acting as gradient noise.","GradDrop is sparse and stochastic unlike gradual freezing.","Extensive experiments on the multilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive against methods that use additional translated data for intermediate pretraining and outperforms standard fine-tuning and gradual unfreezing.","A post-analysis shows how GradDrop improves performance with languages it was not trained on, such as under-resourced languages."],"url":"http://arxiv.org/abs/2307.10098v1"}
{"created":"2023-07-19 16:12:37","title":"Boundary-Refined Prototype Generation: A General End-to-End Paradigm for Semi-Supervised Semantic Segmentation","abstract":"Prototype-based classification is a classical method in machine learning, and recently it has achieved remarkable success in semi-supervised semantic segmentation. However, the current approach isolates the prototype initialization process from the main training framework, which appears to be unnecessary. Furthermore, while the direct use of K-Means algorithm for prototype generation has considered rich intra-class variance, it may not be the optimal solution for the classification task. To tackle these problems, we propose a novel boundary-refined prototype generation (BRPG) method, which is incorporated into the whole training framework. Specifically, our approach samples and clusters high- and low-confidence features separately based on a confidence threshold, aiming to generate prototypes closer to the class boundaries. Moreover, an adaptive prototype optimization strategy is introduced to make prototype augmentation for categories with scattered feature distributions. Extensive experiments on the PASCAL VOC 2012 and Cityscapes datasets demonstrate the superiority and scalability of the proposed method, outperforming the current state-of-the-art approaches. The code is available at xxxxxxxxxxxxxx.","sentences":["Prototype-based classification is a classical method in machine learning, and recently it has achieved remarkable success in semi-supervised semantic segmentation.","However, the current approach isolates the prototype initialization process from the main training framework, which appears to be unnecessary.","Furthermore, while the direct use of K-Means algorithm for prototype generation has considered rich intra-class variance, it may not be the optimal solution for the classification task.","To tackle these problems, we propose a novel boundary-refined prototype generation (BRPG) method, which is incorporated into the whole training framework.","Specifically, our approach samples and clusters high- and low-confidence features separately based on a confidence threshold, aiming to generate prototypes closer to the class boundaries.","Moreover, an adaptive prototype optimization strategy is introduced to make prototype augmentation for categories with scattered feature distributions.","Extensive experiments on the PASCAL VOC 2012 and Cityscapes datasets demonstrate the superiority and scalability of the proposed method, outperforming the current state-of-the-art approaches.","The code is available at xxxxxxxxxxxxxx."],"url":"http://arxiv.org/abs/2307.10097v1"}
{"created":"2023-07-19 16:00:29","title":"Revisiting invariances and introducing priors in Gromov-Wasserstein distances","abstract":"Gromov-Wasserstein distance has found many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariance property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport-based distance, called Augmented Gromov-Wasserstein, that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We present theoretical insights into the proposed metric. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and a transfer learning scenario in machine learning.","sentences":["Gromov-Wasserstein distance has found many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations.","However, in certain applications, this invariance property can be too flexible, thus undesirable.","Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations.","We propose a new optimal transport-based distance, called Augmented Gromov-Wasserstein, that allows for some control over the level of rigidity to transformations.","It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance.","We present theoretical insights into the proposed metric.","We then demonstrate its usefulness for single-cell multi-omic alignment tasks and a transfer learning scenario in machine learning."],"url":"http://arxiv.org/abs/2307.10093v1"}
{"created":"2023-07-19 15:58:43","title":"Design Characterization for Black-and-White Textures in Visualization","abstract":"We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures. Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings. We specifically study how to use what we call geometric and iconic textures. Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories. We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters. 30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps. We then had 150 participants rate these designs for aesthetics. Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.","sentences":["We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures.","Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings.","We specifically study how to use what we call geometric and iconic textures.","Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories.","We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters.","30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps.","We then had 150 participants rate these designs for aesthetics.","Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart."],"url":"http://arxiv.org/abs/2307.10089v1"}
{"created":"2023-07-19 15:57:24","title":"Android in the Wild: A Large-Scale Dataset for Android Device Control","abstract":"There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly controlling its user interface. We present a dataset for device-control research, Android in the Wild (AITW), which is orders of magnitude larger than current datasets. The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions. It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10-13),and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It contains multi-step tasks that require semantic understanding of language and visual context. This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance. And, instead of simple UI element-based actions, the action space consists of precise gestures (e.g., horizontal scrolls to operate carousel widgets). We organize our dataset to encourage robustness analysis of device-control systems, i.e., how well a system performs in the presence of new task descriptions, new applications, or new platform versions. We develop two agents and report performance across the dataset. The dataset is available at https://github.com/google-research/google-research/tree/master/android_in_the_wild.","sentences":["There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly controlling its user interface.","We present a dataset for device-control research, Android in the Wild (AITW), which is orders of magnitude larger than current datasets.","The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions.","It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10-13),and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions.","It contains multi-step tasks that require semantic understanding of language and visual context.","This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance.","And, instead of simple UI element-based actions, the action space consists of precise gestures (e.g., horizontal scrolls to operate carousel widgets).","We organize our dataset to encourage robustness analysis of device-control systems, i.e., how well a system performs in the presence of new task descriptions, new applications, or new platform versions.","We develop two agents and report performance across the dataset.","The dataset is available at https://github.com/google-research/google-research/tree/master/android_in_the_wild."],"url":"http://arxiv.org/abs/2307.10088v1"}
{"created":"2023-07-19 15:55:25","title":"A decision making framework for recommended maintenance of road segments","abstract":"With the rapid development of global road transportation, countries worldwide have completed the construction of road networks. However, the ensuing challenge lies in the maintenance of existing roads. It is well-known that countries allocate limited budgets to road maintenance projects, and road management departments face difficulties in making scientifically informed maintenance decisions. Therefore, integrating various artificial intelligence decision-making techniques to thoroughly explore historical maintenance data and adapt them to the context of road maintenance scientific decision-making has become an urgent issue. This integration aims to provide road management departments with more scientific tools and evidence for decision-making. The framework proposed in this paper primarily addresses the following four issues: 1) predicting the pavement performance of various routes, 2) determining the prioritization of maintenance routes, 3) making maintenance decisions based on the evaluation of the effects of past maintenance, and considering comprehensive technical and management indicators, and 4) determining the prioritization of maintenance sections based on the maintenance effectiveness and recommended maintenance effectiveness. By tackling these four problems, the framework enables intelligent decision-making for the optimal maintenance plan and maintenance sections, taking into account limited funding and historical maintenance management experience.","sentences":["With the rapid development of global road transportation, countries worldwide have completed the construction of road networks.","However, the ensuing challenge lies in the maintenance of existing roads.","It is well-known that countries allocate limited budgets to road maintenance projects, and road management departments face difficulties in making scientifically informed maintenance decisions.","Therefore, integrating various artificial intelligence decision-making techniques to thoroughly explore historical maintenance data and adapt them to the context of road maintenance scientific decision-making has become an urgent issue.","This integration aims to provide road management departments with more scientific tools and evidence for decision-making.","The framework proposed in this paper primarily addresses the following four issues: 1) predicting the pavement performance of various routes, 2) determining the prioritization of maintenance routes, 3) making maintenance decisions based on the evaluation of the effects of past maintenance, and considering comprehensive technical and management indicators, and 4) determining the prioritization of maintenance sections based on the maintenance effectiveness and recommended maintenance effectiveness.","By tackling these four problems, the framework enables intelligent decision-making for the optimal maintenance plan and maintenance sections, taking into account limited funding and historical maintenance management experience."],"url":"http://arxiv.org/abs/2307.10085v1"}
{"created":"2023-07-19 15:55:14","title":"Eversion Robots for Mapping Radiation in Pipes","abstract":"A system and testing rig were designed and built to simulate the use of an eversion robot equipped with a radiation sensor to characterise an irradiated pipe prior to decommissioning. The magnets were used as dummy radiation sources which were detected by a hall effect sensor mounted in the interior of the robot. The robot successfully navigated a simple structure with sharp 45{\\deg} and 90{\\deg} swept bends as well as constrictions that were used to model partial blockages.","sentences":["A system and testing rig were designed and built to simulate the use of an eversion robot equipped with a radiation sensor to characterise an irradiated pipe prior to decommissioning.","The magnets were used as dummy radiation sources which were detected by a hall effect sensor mounted in the interior of the robot.","The robot successfully navigated a simple structure with sharp 45{\\deg} and 90{\\deg} swept bends as well as constrictions that were used to model partial blockages."],"url":"http://arxiv.org/abs/2307.10084v1"}
{"created":"2023-07-19 15:54:18","title":"Efficient Non-Learning Similar Subtrajectory Search","abstract":"Similar subtrajectory search is a finer-grained operator that can better capture the similarities between one query trajectory and a portion of a data trajectory than the traditional similar trajectory search, which requires the two checked trajectories are similar to each other in whole. Many real applications (e.g., trajectory clustering and trajectory join) utilize similar subtrajectory search as a basic operator. It is considered that the time complexity is O(mn^2) for exact algorithms to solve the similar subtrajectory search problem under most trajectory distance functions in the existing studies, where m is the length of the query trajectory and n is the length of the data trajectory. In this paper, to the best of our knowledge, we are the first to propose an exact algorithm to solve the similar subtrajectory search problem in O(mn) time for most of widely used trajectory distance functions (e.g., WED, DTW, ERP, EDR and Frechet distance). Through extensive experiments on three real datasets, we demonstrate the efficiency and effectiveness of our proposed algorithms.","sentences":["Similar subtrajectory search is a finer-grained operator that can better capture the similarities between one query trajectory and a portion of a data trajectory than the traditional similar trajectory search, which requires the two checked trajectories are similar to each other in whole.","Many real applications (e.g., trajectory clustering and trajectory join) utilize similar subtrajectory search as a basic operator.","It is considered that the time complexity is O(mn^2) for exact algorithms to solve the similar subtrajectory search problem under most trajectory distance functions in the existing studies, where m is the length of the query trajectory and n is the length of the data trajectory.","In this paper, to the best of our knowledge, we are the first to propose an exact algorithm to solve the similar subtrajectory search problem in O(mn) time for most of widely used trajectory distance functions (e.g., WED, DTW, ERP, EDR and Frechet distance).","Through extensive experiments on three real datasets, we demonstrate the efficiency and effectiveness of our proposed algorithms."],"url":"http://arxiv.org/abs/2307.10082v1"}
{"created":"2023-07-19 15:53:54","title":"Fundamental Limits of Reference-Based Sequence Reordering","abstract":"The problem of reconstructing a sequence of independent and identically distributed symbols from a set of equal size, consecutive, fragments, as well as a dependent reference sequence, is considered. First, in the regime in which the fragments are relatively long, and typically no fragment appears more than once, the scaling of the failure probability of maximum likelihood reconstruction algorithm is exactly determined for perfect reconstruction and bounded for partial reconstruction. Second, the regime in which the fragments are relatively short and repeating fragments abound is characterized. A trade-off is stated between the fraction of fragments that cannot be adequately reconstructed vs. the distortion level allowed for the reconstruction of each fragment, while still allowing vanishing failure probability","sentences":["The problem of reconstructing a sequence of independent and identically distributed symbols from a set of equal size, consecutive, fragments, as well as a dependent reference sequence, is considered.","First, in the regime in which the fragments are relatively long, and typically no fragment appears more than once, the scaling of the failure probability of maximum likelihood reconstruction algorithm is exactly determined for perfect reconstruction and bounded for partial reconstruction.","Second, the regime in which the fragments are relatively short and repeating fragments abound is characterized.","A trade-off is stated between the fraction of fragments that cannot be adequately reconstructed vs. the distortion level allowed for the reconstruction of each fragment, while still allowing vanishing failure probability"],"url":"http://arxiv.org/abs/2307.10080v1"}
{"created":"2023-07-19 15:51:55","title":"Scientific Exploration of Challenging Planetary Analog Environments with a Team of Legged Robots","abstract":"The interest in exploring planetary bodies for scientific investigation and in-situ resource utilization is ever-rising. Yet, many sites of interest are inaccessible to state-of-the-art planetary exploration robots because of the robots' inability to traverse steep slopes, unstructured terrain, and loose soil. Additionally, current single-robot approaches only allow a limited exploration speed and a single set of skills. Here, we present a team of legged robots with complementary skills for exploration missions in challenging planetary analog environments. We equipped the robots with an efficient locomotion controller, a mapping pipeline for online and post-mission visualization, instance segmentation to highlight scientific targets, and scientific instruments for remote and in-situ investigation. Furthermore, we integrated a robotic arm on one of the robots to enable high-precision measurements. Legged robots can swiftly navigate representative terrains, such as granular slopes beyond 25 degrees, loose soil, and unstructured terrain, highlighting their advantages compared to wheeled rover systems. We successfully verified the approach in analog deployments at the BeyondGravity ExoMars rover testbed, in a quarry in Switzerland, and at the Space Resources Challenge in Luxembourg. Our results show that a team of legged robots with advanced locomotion, perception, and measurement skills, as well as task-level autonomy, can conduct successful, effective missions in a short time. Our approach enables the scientific exploration of planetary target sites that are currently out of human and robotic reach.","sentences":["The interest in exploring planetary bodies for scientific investigation and in-situ resource utilization is ever-rising.","Yet, many sites of interest are inaccessible to state-of-the-art planetary exploration robots because of the robots' inability to traverse steep slopes, unstructured terrain, and loose soil.","Additionally, current single-robot approaches only allow a limited exploration speed and a single set of skills.","Here, we present a team of legged robots with complementary skills for exploration missions in challenging planetary analog environments.","We equipped the robots with an efficient locomotion controller, a mapping pipeline for online and post-mission visualization, instance segmentation to highlight scientific targets, and scientific instruments for remote and in-situ investigation.","Furthermore, we integrated a robotic arm on one of the robots to enable high-precision measurements.","Legged robots can swiftly navigate representative terrains, such as granular slopes beyond 25 degrees, loose soil, and unstructured terrain, highlighting their advantages compared to wheeled rover systems.","We successfully verified the approach in analog deployments at the BeyondGravity ExoMars rover testbed, in a quarry in Switzerland, and at the Space Resources Challenge in Luxembourg.","Our results show that a team of legged robots with advanced locomotion, perception, and measurement skills, as well as task-level autonomy, can conduct successful, effective missions in a short time.","Our approach enables the scientific exploration of planetary target sites that are currently out of human and robotic reach."],"url":"http://arxiv.org/abs/2307.10079v1"}
{"created":"2023-07-19 15:51:25","title":"A Dual Formulation for Probabilistic Principal Component Analysis","abstract":"In this paper, we characterize Probabilistic Principal Component Analysis in Hilbert spaces and demonstrate how the optimal solution admits a representation in dual space. This allows us to develop a generative framework for kernel methods. Furthermore, we show how it englobes Kernel Principal Component Analysis and illustrate its working on a toy and a real dataset.","sentences":["In this paper, we characterize Probabilistic Principal Component Analysis in Hilbert spaces and demonstrate how the optimal solution admits a representation in dual space.","This allows us to develop a generative framework for kernel methods.","Furthermore, we show how it englobes Kernel Principal Component Analysis and illustrate its working on a toy and a real dataset."],"url":"http://arxiv.org/abs/2307.10078v1"}
{"created":"2023-07-19 15:40:06","title":"Practical Model Reductions for Verification of Multi-Agent Systems","abstract":"Formal verification of intelligent agents is often computationally infeasible due to state-space explosion. We present a tool for reducing the impact of the explosion by means of state abstraction that is (a) easy to use and understand by non-experts, and (b) agent-based in the sense that it operates on a modular representation of the system, rather than on its huge explicit state model.","sentences":["Formal verification of intelligent agents is often computationally infeasible due to state-space explosion.","We present a tool for reducing the impact of the explosion by means of state abstraction that is (a) easy to use and understand by non-experts, and (b) agent-based in the sense that it operates on a modular representation of the system, rather than on its huge explicit state model."],"url":"http://arxiv.org/abs/2307.10068v1"}
{"created":"2023-07-19 15:34:05","title":"Object-centric Representations for Interactive Online Learning with Non-Parametric Methods","abstract":"Large offline learning-based models have enabled robots to successfully interact with objects for a wide variety of tasks. However, these models rely on fairly consistent structured environments. For more unstructured environments, an online learning component is necessary to gather and estimate information about objects in the environment in order to successfully interact with them. Unfortunately, online learning methods like Bayesian non-parametric models struggle with changes in the environment, which is often the desired outcome of interaction-based tasks. We propose using an object-centric representation for interactive online learning. This representation is generated by transforming the robot's actions into the object's coordinate frame. We demonstrate how switching to this task-relevant space improves our ability to reason with the training data collected online, enabling scalable online learning of robot-object interactions. We showcase our method by successfully navigating a manipulator arm through an environment with multiple unknown objects without violating interaction-based constraints.","sentences":["Large offline learning-based models have enabled robots to successfully interact with objects for a wide variety of tasks.","However, these models rely on fairly consistent structured environments.","For more unstructured environments, an online learning component is necessary to gather and estimate information about objects in the environment in order to successfully interact with them.","Unfortunately, online learning methods like Bayesian non-parametric models struggle with changes in the environment, which is often the desired outcome of interaction-based tasks.","We propose using an object-centric representation for interactive online learning.","This representation is generated by transforming the robot's actions into the object's coordinate frame.","We demonstrate how switching to this task-relevant space improves our ability to reason with the training data collected online, enabling scalable online learning of robot-object interactions.","We showcase our method by successfully navigating a manipulator arm through an environment with multiple unknown objects without violating interaction-based constraints."],"url":"http://arxiv.org/abs/2307.10063v1"}
{"created":"2023-07-19 15:33:11","title":"Unsupervised Accuracy Estimation of Deep Visual Models using Domain-Adaptive Adversarial Perturbation without Source Samples","abstract":"Deploying deep visual models can lead to performance drops due to the discrepancies between source and target distributions. Several approaches leverage labeled source data to estimate target domain accuracy, but accessing labeled source data is often prohibitively difficult due to data confidentiality or resource limitations on serving devices. Our work proposes a new framework to estimate model accuracy on unlabeled target data without access to source data. We investigate the feasibility of using pseudo-labels for accuracy estimation and evolve this idea into adopting recent advances in source-free domain adaptation algorithms. Our approach measures the disagreement rate between the source hypothesis and the target pseudo-labeling function, adapted from the source hypothesis. We mitigate the impact of erroneous pseudo-labels that may arise due to a high ideal joint hypothesis risk by employing adaptive adversarial perturbation on the input of the target model. Our proposed source-free framework effectively addresses the challenging distribution shift scenarios and outperforms existing methods requiring source data and labels for training.","sentences":["Deploying deep visual models can lead to performance drops due to the discrepancies between source and target distributions.","Several approaches leverage labeled source data to estimate target domain accuracy, but accessing labeled source data is often prohibitively difficult due to data confidentiality or resource limitations on serving devices.","Our work proposes a new framework to estimate model accuracy on unlabeled target data without access to source data.","We investigate the feasibility of using pseudo-labels for accuracy estimation and evolve this idea into adopting recent advances in source-free domain adaptation algorithms.","Our approach measures the disagreement rate between the source hypothesis and the target pseudo-labeling function, adapted from the source hypothesis.","We mitigate the impact of erroneous pseudo-labels that may arise due to a high ideal joint hypothesis risk by employing adaptive adversarial perturbation on the input of the target model.","Our proposed source-free framework effectively addresses the challenging distribution shift scenarios and outperforms existing methods requiring source data and labels for training."],"url":"http://arxiv.org/abs/2307.10062v1"}
{"created":"2023-07-19 15:30:29","title":"Automated Complexity Analysis of Integer Programs via Triangular Weakly Non-Linear Loops (Short WST Version)","abstract":"There exist several results on deciding termination and computing runtime bounds for triangular weakly non-linear loops (twn-loops). We show how to use results on such subclasses of programs where complexity bounds are computable within incomplete approaches for complexity analysis of full integer programs. To this end, we present a novel modular approach which computes local runtime bounds for subprograms which can be transformed into twn-loops. These local runtime bounds are then lifted to global runtime bounds for the whole program. The power of our approach is shown by our implementation in the tool KoAT which analyzes complexity of programs where all other state-of-the-art tools fail.","sentences":["There exist several results on deciding termination and computing runtime bounds for triangular weakly non-linear loops (twn-loops).","We show how to use results on such subclasses of programs where complexity bounds are computable within incomplete approaches for complexity analysis of full integer programs.","To this end, we present a novel modular approach which computes local runtime bounds for subprograms which can be transformed into twn-loops.","These local runtime bounds are then lifted to global runtime bounds for the whole program.","The power of our approach is shown by our implementation in the tool KoAT which analyzes complexity of programs where all other state-of-the-art tools fail."],"url":"http://arxiv.org/abs/2307.10061v1"}
{"created":"2023-07-19 15:27:21","title":"Online Algorithms and Lower Bounds for Average-Case Matrix Discrepancy","abstract":"We study the operator norm discrepancy of i.i.d. random matrices, initiating the matrix-valued analog of a long line of work on the $\\ell^{\\infty}$ norm discrepancy of i.i.d. random vectors. First, we give a new analysis of the matrix hyperbolic cosine algorithm of Zouzias (2011), a matrix version of an online vector discrepancy algorithm of Spencer (1977) studied for average-case inputs by Bansal and Spencer (2020), for the case of i.i.d. random matrix inputs. We both give a general analysis and extract concrete bounds on the discrepancy achieved by this algorithm for matrices with independent entries and positive semidefinite matrices drawn from Wishart distributions. Second, using the first moment method, we give lower bounds on the discrepancy of random matrices, in particular showing that the matrix hyperbolic cosine algorithm achieves optimal discrepancy up to logarithmic terms in several cases. We both treat the special case of the Gaussian orthogonal ensemble and give a general result for low-rank matrix distributions that we apply to orthogonally invariant random projections.","sentences":["We study the operator norm discrepancy of i.i.d. random matrices, initiating the matrix-valued analog of a long line of work on the $\\ell^{\\infty}$ norm discrepancy of i.i.d. random vectors.","First, we give a new analysis of the matrix hyperbolic cosine algorithm of Zouzias (2011), a matrix version of an online vector discrepancy algorithm of Spencer (1977) studied for average-case inputs by Bansal and Spencer (2020), for the case of i.i.d. random matrix inputs.","We both give a general analysis and extract concrete bounds on the discrepancy achieved by this algorithm for matrices with independent entries and positive semidefinite matrices drawn from Wishart distributions.","Second, using the first moment method, we give lower bounds on the discrepancy of random matrices, in particular showing that the matrix hyperbolic cosine algorithm achieves optimal discrepancy up to logarithmic terms in several cases.","We both treat the special case of the Gaussian orthogonal ensemble and give a general result for low-rank matrix distributions that we apply to orthogonally invariant random projections."],"url":"http://arxiv.org/abs/2307.10055v1"}
{"created":"2023-07-19 15:26:56","title":"Internet Congestion Control Benchmarking","abstract":"How do we assess a new Internet congestion control (CC) design? How do we compare it with other existing schemes? Under what scenarios and using what network parameters? These are just a handful of simple questions coming up every time a new CC design is going to be evaluated. Interestingly, the number of specific answers to these questions can be as large as the number of CC designers. In this work, we aim to highlight that the network congestion control, as a hot and active research topic, requires a crystal clear set(s) of \\textit{CC Benchmarks} to form a common ground for quantitatively comparing and unambiguously assessing the strengths and weaknesses of a design with respect to the existing ones. As a first step toward that goal, we introduce general benchmarks that can capture the different performance of the existing Internet CC schemes. Using these benchmarks, we rank the Internet CC algorithms and illustrate that there is still lots of room for more innovations and improvements in this topic.","sentences":["How do we assess a new Internet congestion control (CC) design?","How do we compare it with other existing schemes?","Under what scenarios and using what network parameters?","These are just a handful of simple questions coming up every time a new CC design is going to be evaluated.","Interestingly, the number of specific answers to these questions can be as large as the number of CC designers.","In this work, we aim to highlight that the network congestion control, as a hot and active research topic, requires a crystal clear set(s) of \\textit{CC Benchmarks} to form a common ground for quantitatively comparing and unambiguously assessing the strengths and weaknesses of a design with respect to the existing ones.","As a first step toward that goal, we introduce general benchmarks that can capture the different performance of the existing Internet CC schemes.","Using these benchmarks, we rank the Internet CC algorithms and illustrate that there is still lots of room for more innovations and improvements in this topic."],"url":"http://arxiv.org/abs/2307.10054v1"}
{"created":"2023-07-19 15:22:06","title":"Divert More Attention to Vision-Language Object Tracking","abstract":"Multimodal vision-language (VL) learning has noticeably pushed the tendency toward generic intelligence owing to emerging large foundation models. However, tracking, as a fundamental vision problem, surprisingly enjoys less bonus from recent flourishing VL learning. We argue that the reasons are two-fold: the lack of large-scale vision-language annotated videos and ineffective vision-language interaction learning of current works. These nuisances motivate us to design more effective vision-language representation for tracking, meanwhile constructing a large database with language annotation for model learning. Particularly, in this paper, we first propose a general attribute annotation strategy to decorate videos in six popular tracking benchmarks, which contributes a large-scale vision-language tracking database with more than 23,000 videos. We then introduce a novel framework to improve tracking by learning a unified-adaptive VL representation, where the cores are the proposed asymmetric architecture search and modality mixer (ModaMixer). To further improve VL representation, we introduce a contrastive loss to align different modalities. To thoroughly evidence the effectiveness of our method, we integrate the proposed framework on three tracking methods with different designs, i.e., the CNN-based SiamCAR, the Transformer-based OSTrack, and the hybrid structure TransT. The experiments demonstrate that our framework can significantly improve all baselines on six benchmarks. Besides empirical results, we theoretically analyze our approach to show its rationality. By revealing the potential of VL representation, we expect the community to divert more attention to VL tracking and hope to open more possibilities for future tracking with diversified multimodal messages.","sentences":["Multimodal vision-language (VL) learning has noticeably pushed the tendency toward generic intelligence owing to emerging large foundation models.","However, tracking, as a fundamental vision problem, surprisingly enjoys less bonus from recent flourishing VL learning.","We argue that the reasons are two-fold: the lack of large-scale vision-language annotated videos and ineffective vision-language interaction learning of current works.","These nuisances motivate us to design more effective vision-language representation for tracking, meanwhile constructing a large database with language annotation for model learning.","Particularly, in this paper, we first propose a general attribute annotation strategy to decorate videos in six popular tracking benchmarks, which contributes a large-scale vision-language tracking database with more than 23,000 videos.","We then introduce a novel framework to improve tracking by learning a unified-adaptive VL representation, where the cores are the proposed asymmetric architecture search and modality mixer (ModaMixer).","To further improve VL representation, we introduce a contrastive loss to align different modalities.","To thoroughly evidence the effectiveness of our method, we integrate the proposed framework on three tracking methods with different designs, i.e., the CNN-based SiamCAR, the Transformer-based OSTrack, and the hybrid structure TransT.","The experiments demonstrate that our framework can significantly improve all baselines on six benchmarks.","Besides empirical results, we theoretically analyze our approach to show its rationality.","By revealing the potential of VL representation, we expect the community to divert more attention to VL tracking and hope to open more possibilities for future tracking with diversified multimodal messages."],"url":"http://arxiv.org/abs/2307.10046v1"}
{"created":"2023-07-19 15:21:59","title":"Alignment complete relational Hoare logics for some and all","abstract":"In relational verification, judicious alignment of computational steps facilitates proof of relations between programs using simple relational assertions. Relational Hoare logics (RHL) provide compositional rules that embody various alignments of executions. Seemingly more flexible alignments can be expressed in terms of product automata based on program transition relations. A single degenerate alignment rule (self-composition), atop a complete Hoare logic, comprises a RHL for $\\forall\\forall$ properties that is complete in the ordinary logical sense. The notion of alignment completeness was previously proposed as a more satisfactory measure, and some rules were shown to be alignment complete with respect to a few ad hoc forms of alignment automata. This paper proves alignment completeness with respect to a general class of $\\forall\\forall$ alignment automata, for a RHL comprised of standard rules together with a rule of semantics-preserving rewrites based on Kleene algebra with tests. We also give a new logic for $\\forall\\exists$ properties and prove its alignment completeness.","sentences":["In relational verification, judicious alignment of computational steps facilitates proof of relations between programs using simple relational assertions.","Relational Hoare logics (RHL) provide compositional rules that embody various alignments of executions.","Seemingly more flexible alignments can be expressed in terms of product automata based on program transition relations.","A single degenerate alignment rule (self-composition), atop a complete Hoare logic, comprises a RHL for $\\forall\\forall$ properties that is complete in the ordinary logical sense.","The notion of alignment completeness was previously proposed as a more satisfactory measure, and some rules were shown to be alignment complete with respect to a few ad hoc forms of alignment automata.","This paper proves alignment completeness with respect to a general class of $\\forall\\forall$ alignment automata, for a RHL comprised of standard rules together with a rule of semantics-preserving rewrites based on Kleene algebra with tests.","We also give a new logic for $\\forall\\exists$ properties and prove its alignment completeness."],"url":"http://arxiv.org/abs/2307.10045v1"}
{"created":"2023-07-19 15:20:32","title":"BERRY: Bit Error Robustness for Energy-Efficient Reinforcement Learning-Based Autonomous Systems","abstract":"Autonomous systems, such as Unmanned Aerial Vehicles (UAVs), are expected to run complex reinforcement learning (RL) models to execute fully autonomous position-navigation-time tasks within stringent onboard weight and power constraints. We observe that reducing onboard operating voltage can benefit the energy efficiency of both the computation and flight mission, however, it can also result in on-chip bit failures that are detrimental to mission safety and performance. To this end, we propose BERRY, a robust learning framework to improve bit error robustness and energy efficiency for RL-enabled autonomous systems. BERRY supports robust learning, both offline and on-board the UAV, and for the first time, demonstrates the practicality of robust low-voltage operation on UAVs that leads to high energy savings in both compute-level operation and system-level quality-of-flight. We perform extensive experiments on 72 autonomous navigation scenarios and demonstrate that BERRY generalizes well across environments, UAVs, autonomy policies, operating voltages and fault patterns, and consistently improves robustness, efficiency and mission performance, achieving up to 15.62% reduction in flight energy, 18.51% increase in the number of successful missions, and 3.43x processing energy reduction.","sentences":["Autonomous systems, such as Unmanned Aerial Vehicles (UAVs), are expected to run complex reinforcement learning (RL) models to execute fully autonomous position-navigation-time tasks within stringent onboard weight and power constraints.","We observe that reducing onboard operating voltage can benefit the energy efficiency of both the computation and flight mission, however, it can also result in on-chip bit failures that are detrimental to mission safety and performance.","To this end, we propose BERRY, a robust learning framework to improve bit error robustness and energy efficiency for RL-enabled autonomous systems.","BERRY supports robust learning, both offline and on-board the UAV, and for the first time, demonstrates the practicality of robust low-voltage operation on UAVs that leads to high energy savings in both compute-level operation and system-level quality-of-flight.","We perform extensive experiments on 72 autonomous navigation scenarios and demonstrate that BERRY generalizes well across environments, UAVs, autonomy policies, operating voltages and fault patterns, and consistently improves robustness, efficiency and mission performance, achieving up to 15.62% reduction in flight energy, 18.51% increase in the number of successful missions, and 3.43x processing energy reduction."],"url":"http://arxiv.org/abs/2307.10041v1"}
{"created":"2023-07-19 15:19:02","title":"Class Attention to Regions of Lesion for Imbalanced Medical Image Recognition","abstract":"Automated medical image classification is the key component in intelligent diagnosis systems. However, most medical image datasets contain plenty of samples of common diseases and just a handful of rare ones, leading to major class imbalances. Currently, it is an open problem in intelligent diagnosis to effectively learn from imbalanced training data. In this paper, we propose a simple yet effective framework, named \\textbf{C}lass \\textbf{A}ttention to \\textbf{RE}gions of the lesion (CARE), to handle data imbalance issues by embedding attention into the training process of \\textbf{C}onvolutional \\textbf{N}eural \\textbf{N}etworks (CNNs). The proposed attention module helps CNNs attend to lesion regions of rare diseases, therefore helping CNNs to learn their characteristics more effectively. In addition, this attention module works only during the training phase and does not change the architecture of the original network, so it can be directly combined with any existing CNN architecture. The CARE framework needs bounding boxes to represent the lesion regions of rare diseases. To alleviate the need for manual annotation, we further developed variants of CARE by leveraging the traditional saliency methods or a pretrained segmentation model for bounding box generation. Results show that the CARE variants with automated bounding box generation are comparable to the original CARE framework with \\textit{manual} bounding box annotations. A series of experiments on an imbalanced skin image dataset and a pneumonia dataset indicates that our method can effectively help the network focus on the lesion regions of rare diseases and remarkably improves the classification performance of rare diseases.","sentences":["Automated medical image classification is the key component in intelligent diagnosis systems.","However, most medical image datasets contain plenty of samples of common diseases and just a handful of rare ones, leading to major class imbalances.","Currently, it is an open problem in intelligent diagnosis to effectively learn from imbalanced training data.","In this paper, we propose a simple yet effective framework, named \\textbf{C}lass \\textbf{A}ttention to \\textbf{RE}gions of the lesion (CARE), to handle data imbalance issues by embedding attention into the training process of \\textbf{C}onvolutional \\textbf{N}eural \\textbf{N}etworks (CNNs).","The proposed attention module helps CNNs attend to lesion regions of rare diseases, therefore helping CNNs to learn their characteristics more effectively.","In addition, this attention module works only during the training phase and does not change the architecture of the original network, so it can be directly combined with any existing CNN architecture.","The CARE framework needs bounding boxes to represent the lesion regions of rare diseases.","To alleviate the need for manual annotation, we further developed variants of CARE by leveraging the traditional saliency methods or a pretrained segmentation model for bounding box generation.","Results show that the CARE variants with automated bounding box generation are comparable to the original CARE framework with \\textit{manual} bounding box annotations.","A series of experiments on an imbalanced skin image dataset and a pneumonia dataset indicates that our method can effectively help the network focus on the lesion regions of rare diseases and remarkably improves the classification performance of rare diseases."],"url":"http://arxiv.org/abs/2307.10036v1"}
{"created":"2023-07-19 15:18:27","title":"Validation of Modern JSON Schema: Formalization and Complexity","abstract":"JSON Schema is the de-facto standard schema language for JSON data. The language went through many minor revisions, but the most recent versions of the language added two novel features, dynamic references and annotation-dependent validation, that change the evaluation model. Modern JSON Schema is the name used to indicate all versions from Draft 2019-09, which are characterized by these new features, while Classical JSON Schema is used to indicate the previous versions.   These new \"modern\" features make the schema language quite difficult to understand, and have generated many discussions about the correct interpretation of their official specifications; for this reason we undertook the task of their formalization. During this process, we also analyzed the complexity of data validation in Modern JSON Schema, with the idea of confirming the PTIME complexity of Classical JSON Schema validation, and we were surprised to discover a completely different truth: data validation, that is expected to be an extremely efficient process, acquires, with Modern JSON Schema features, a PSPACE complexity.   In this paper, we give the first formal description of Modern JSON Schema, which we consider a central contribution of the work that we present here. We then prove that its data validation problem is PSPACE-complete. We prove that the origin of the problem lies in dynamic references, and not in annotation-dependent validation. We study the schema and data complexities, showing that the problem is PSPACE-complete with respect to the schema size even with a fixed instance, but is in PTIME when the schema is fixed and only the instance size is allowed to vary. Finally, we run experiments that show that there are families of schemas where the difference in asymptotic complexity between dynamic and static references is extremely visible, even with small schemas.","sentences":["JSON Schema is the de-facto standard schema language for JSON data.","The language went through many minor revisions, but the most recent versions of the language added two novel features, dynamic references and annotation-dependent validation, that change the evaluation model.","Modern JSON Schema is the name used to indicate all versions from Draft 2019-09, which are characterized by these new features, while Classical JSON Schema is used to indicate the previous versions.   ","These new \"modern\" features make the schema language quite difficult to understand, and have generated many discussions about the correct interpretation of their official specifications; for this reason we undertook the task of their formalization.","During this process, we also analyzed the complexity of data validation in Modern JSON Schema, with the idea of confirming the PTIME complexity of Classical JSON Schema validation, and we were surprised to discover a completely different truth: data validation, that is expected to be an extremely efficient process, acquires, with Modern JSON Schema features, a PSPACE complexity.   ","In this paper, we give the first formal description of Modern JSON Schema, which we consider a central contribution of the work that we present here.","We then prove that its data validation problem is PSPACE-complete.","We prove that the origin of the problem lies in dynamic references, and not in annotation-dependent validation.","We study the schema and data complexities, showing that the problem is PSPACE-complete with respect to the schema size even with a fixed instance, but is in PTIME when the schema is fixed and only the instance size is allowed to vary.","Finally, we run experiments that show that there are families of schemas where the difference in asymptotic complexity between dynamic and static references is extremely visible, even with small schemas."],"url":"http://arxiv.org/abs/2307.10034v1"}
{"created":"2023-07-19 15:16:01","title":"Automatic Conversion of MiniZinc Programs to QUBO","abstract":"Obtaining Quadratic Unconstrained Binary Optimisation models for various optimisation problems, in order to solve those on physical quantum computers (such as the the DWave annealers) is nowadays a lengthy and tedious process that requires one to remodel all problem variables as binary variables and squeeze the target function and the constraints into a single quadratic polynomial into these new variables.   We report here on the basis of our automatic converter from MiniZinc to QUBO, which is able to process a large set of constraint optimisation and constraint satisfaction problems and turn them into equivalent QUBOs, effectively optimising the whole process.","sentences":["Obtaining Quadratic Unconstrained Binary Optimisation models for various optimisation problems, in order to solve those on physical quantum computers (such as the the DWave annealers) is nowadays a lengthy and tedious process that requires one to remodel all problem variables as binary variables and squeeze the target function and the constraints into a single quadratic polynomial into these new variables.   ","We report here on the basis of our automatic converter from MiniZinc to QUBO, which is able to process a large set of constraint optimisation and constraint satisfaction problems and turn them into equivalent QUBOs, effectively optimising the whole process."],"url":"http://arxiv.org/abs/2307.10032v1"}
{"created":"2023-07-19 15:11:04","title":"Contextual Reliability: When Different Features Matter in Different Contexts","abstract":"Deep neural networks often fail catastrophically by relying on spurious correlations. Most prior work assumes a clear dichotomy into spurious and reliable features; however, this is often unrealistic. For example, most of the time we do not want an autonomous car to simply copy the speed of surrounding cars -- we don't want our car to run a red light if a neighboring car does so. However, we cannot simply enforce invariance to next-lane speed, since it could provide valuable information about an unobservable pedestrian at a crosswalk. Thus, universally ignoring features that are sometimes (but not always) reliable can lead to non-robust performance. We formalize a new setting called contextual reliability which accounts for the fact that the \"right\" features to use may vary depending on the context. We propose and analyze a two-stage framework called Explicit Non-spurious feature Prediction (ENP) which first identifies the relevant features to use for a given context, then trains a model to rely exclusively on these features. Our work theoretically and empirically demonstrates the advantages of ENP over existing methods and provides new benchmarks for contextual reliability.","sentences":["Deep neural networks often fail catastrophically by relying on spurious correlations.","Most prior work assumes a clear dichotomy into spurious and reliable features; however, this is often unrealistic.","For example, most of the time we do not want an autonomous car to simply copy the speed of surrounding cars -- we don't want our car to run a red light if a neighboring car does so.","However, we cannot simply enforce invariance to next-lane speed, since it could provide valuable information about an unobservable pedestrian at a crosswalk.","Thus, universally ignoring features that are sometimes (but not always) reliable can lead to non-robust performance.","We formalize a new setting called contextual reliability which accounts for the fact that the \"right\" features to use may vary depending on the context.","We propose and analyze a two-stage framework called Explicit Non-spurious feature Prediction (ENP) which first identifies the relevant features to use for a given context, then trains a model to rely exclusively on these features.","Our work theoretically and empirically demonstrates the advantages of ENP over existing methods and provides new benchmarks for contextual reliability."],"url":"http://arxiv.org/abs/2307.10026v1"}
{"created":"2023-07-19 15:09:50","title":"An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods","abstract":"Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community. 2023 ``two sessions\" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction\" This topic was once a hot topic on the Internet, and ``unbundling\" the relationship between birth registration and marriage has become the focus of social debate. In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments. It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration\" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's sentiment inclined to be negative in most of the topics. Based on this, eight proposals were made to provide a reference for governmental decision making and to form a reference method for researching public opinion on political issues.","sentences":["Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community.","2023 ``two sessions\" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction\" This topic was once a hot topic on the Internet, and ``unbundling\" the relationship between birth registration and marriage has become the focus of social debate.","In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments.","It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration\" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's sentiment inclined to be negative in most of the topics.","Based on this, eight proposals were made to provide a reference for governmental decision making and to form a reference method for researching public opinion on political issues."],"url":"http://arxiv.org/abs/2307.10025v1"}
{"created":"2023-07-19 15:05:55","title":"Europepolls: A Dataset of Country-Level Opinion Polling Data for the European Union and the UK","abstract":"I propose an open dataset of country-level historical opinion polling data for the European Union and the UK. The dataset aims to fill a gap in available opinion polling data for the European Union. Some existing datasets are restricted to the past five years, limiting research opportunities. At the same time, some larger proprietary datasets exist but are available only in a visual preprocessed time series format. Finally, while other large datasets for individual countries might exist, these could be inaccessible due to language barriers. The data was gathered from Wikipedia, and preprocessed using the pandas library. Both the raw and the preprocessed data are in the .csv format. I hope that given the recent advances in LLMs and deep learning in general, this large dataset will enable researchers to uncover complex interactions between multimodal data (news articles, economic indicators, social media) and voting behavior. The raw data, the preprocessed data, and the preprocessing scripts are available on GitHub.","sentences":["I propose an open dataset of country-level historical opinion polling data for the European Union and the UK.","The dataset aims to fill a gap in available opinion polling data for the European Union.","Some existing datasets are restricted to the past five years, limiting research opportunities.","At the same time, some larger proprietary datasets exist but are available only in a visual preprocessed time series format.","Finally, while other large datasets for individual countries might exist, these could be inaccessible due to language barriers.","The data was gathered from Wikipedia, and preprocessed using the pandas library.","Both the raw and the preprocessed data are in the .csv format.","I hope that given the recent advances in LLMs and deep learning in general, this large dataset will enable researchers to uncover complex interactions between multimodal data (news articles, economic indicators, social media) and voting behavior.","The raw data, the preprocessed data, and the preprocessing scripts are available on GitHub."],"url":"http://arxiv.org/abs/2307.10022v1"}
{"created":"2023-07-19 14:58:30","title":"Rob\u00f4CIn Small Size League Extended Team Description Paper for RoboCup 2023","abstract":"Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its first world title in 2022 (Division B), and is currently a three-times Latin-American champion. This paper presents our improvements to defend the Small Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France. This paper aims to share some of the academic research that our team developed over the past year. Our team has successfully published 2 articles related to SSL at two high-impact conferences: the 25th RoboCup International Symposium and the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last year, we have been continuously migrating from our past codebase to Unification. We will describe the new architecture implemented and some points of software and AI refactoring. In addition, we discuss the process of integrating machined components into the mechanical system, our development for participating in the vision blackout challenge last year and what we are preparing for this year.","sentences":["Rob\\^oCIn has participated in RoboCup Small Size League since 2019, won its first world title in 2022 (Division B), and is currently a three-times Latin-American champion.","This paper presents our improvements to defend the Small Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France.","This paper aims to share some of the academic research that our team developed over the past year.","Our team has successfully published 2 articles related to SSL at two high-impact conferences: the 25th RoboCup International Symposium and the 19th IEEE Latin American Robotics Symposium (LARS 2022).","Over the last year, we have been continuously migrating from our past codebase to Unification.","We will describe the new architecture implemented and some points of software and AI refactoring.","In addition, we discuss the process of integrating machined components into the mechanical system, our development for participating in the vision blackout challenge last year and what we are preparing for this year."],"url":"http://arxiv.org/abs/2307.10018v1"}
{"created":"2023-07-19 14:53:47","title":"Optimizing the extended Fourier Mellin Transformation Algorithm","abstract":"With the increasing application of robots, stable and efficient Visual Odometry (VO) algorithms are becoming more and more important. Based on the Fourier Mellin Transformation (FMT) algorithm, the extended Fourier Mellin Transformation (eFMT) is an image registration approach that can be applied to downward-looking cameras, for example on aerial and underwater vehicles. eFMT extends FMT to multi-depth scenes and thus more application scenarios. It is a visual odometry method which estimates the pose transformation between three overlapping images. On this basis, we develop an optimized eFMT algorithm that improves certain aspects of the method and combines it with back-end optimization for the small loop of three consecutive frames. For this we investigate the extraction of uncertainty information from the eFMT registration, the related objective function and the graph-based optimization. Finally, we design a series of experiments to investigate the properties of this approach and compare it with other VO and SLAM (Simultaneous Localization and Mapping) algorithms. The results show the superior accuracy and speed of our o-eFMT approach, which is published as open source.","sentences":["With the increasing application of robots, stable and efficient Visual Odometry (VO) algorithms are becoming more and more important.","Based on the Fourier Mellin Transformation (FMT) algorithm, the extended Fourier Mellin Transformation (eFMT) is an image registration approach that can be applied to downward-looking cameras, for example on aerial and underwater vehicles.","eFMT extends FMT to multi-depth scenes and thus more application scenarios.","It is a visual odometry method which estimates the pose transformation between three overlapping images.","On this basis, we develop an optimized eFMT algorithm that improves certain aspects of the method and combines it with back-end optimization for the small loop of three consecutive frames.","For this we investigate the extraction of uncertainty information from the eFMT registration, the related objective function and the graph-based optimization.","Finally, we design a series of experiments to investigate the properties of this approach and compare it with other VO and SLAM (Simultaneous Localization and Mapping) algorithms.","The results show the superior accuracy and speed of our o-eFMT approach, which is published as open source."],"url":"http://arxiv.org/abs/2307.10015v1"}
{"created":"2023-07-19 14:49:14","title":"Towards Fair Face Verification: An In-depth Analysis of Demographic Biases","abstract":"Deep learning-based person identification and verification systems have remarkably improved in terms of accuracy in recent years; however, such systems, including widely popular cloud-based solutions, have been found to exhibit significant biases related to race, age, and gender, a problem that requires in-depth exploration and solutions. This paper presents an in-depth analysis, with a particular emphasis on the intersectionality of these demographic factors. Intersectional bias refers to the performance discrepancies w.r.t. the different combinations of race, age, and gender groups, an area relatively unexplored in current literature. Furthermore, the reliance of most state-of-the-art approaches on accuracy as the principal evaluation metric often masks significant demographic disparities in performance. To counter this crucial limitation, we incorporate five additional metrics in our quantitative analysis, including disparate impact and mistreatment metrics, which are typically ignored by the relevant fairness-aware approaches. Results on the Racial Faces in-the-Wild (RFW) benchmark indicate pervasive biases in face recognition systems, extending beyond race, with different demographic factors yielding significantly disparate outcomes. In particular, Africans demonstrate an 11.25% lower True Positive Rate (TPR) compared to Caucasians, while only a 3.51% accuracy drop is observed. Even more concerning, the intersections of multiple protected groups, such as African females over 60 years old, demonstrate a +39.89% disparate mistreatment rate compared to the highest Caucasians rate. By shedding light on these biases and their implications, this paper aims to stimulate further research towards developing fairer, more equitable face recognition and verification systems.","sentences":["Deep learning-based person identification and verification systems have remarkably improved in terms of accuracy in recent years; however, such systems, including widely popular cloud-based solutions, have been found to exhibit significant biases related to race, age, and gender, a problem that requires in-depth exploration and solutions.","This paper presents an in-depth analysis, with a particular emphasis on the intersectionality of these demographic factors.","Intersectional bias refers to the performance discrepancies w.r.t.","the different combinations of race, age, and gender groups, an area relatively unexplored in current literature.","Furthermore, the reliance of most state-of-the-art approaches on accuracy as the principal evaluation metric often masks significant demographic disparities in performance.","To counter this crucial limitation, we incorporate five additional metrics in our quantitative analysis, including disparate impact and mistreatment metrics, which are typically ignored by the relevant fairness-aware approaches.","Results on the Racial Faces in-the-Wild (RFW) benchmark indicate pervasive biases in face recognition systems, extending beyond race, with different demographic factors yielding significantly disparate outcomes.","In particular, Africans demonstrate an 11.25% lower True Positive Rate (TPR) compared to Caucasians, while only a 3.51% accuracy drop is observed.","Even more concerning, the intersections of multiple protected groups, such as African females over 60 years old, demonstrate a +39.89% disparate mistreatment rate compared to the highest Caucasians rate.","By shedding light on these biases and their implications, this paper aims to stimulate further research towards developing fairer, more equitable face recognition and verification systems."],"url":"http://arxiv.org/abs/2307.10011v1"}
{"created":"2023-07-19 14:47:08","title":"Connecting Beliefs, Mindsets, Anxiety, and Self-Efficacy in Computer Science Learning: An Instrument for Capturing Secondary School Students' Self-Beliefs","abstract":"Background and Context: Few instruments exist to measure students' CS engagement and learning especially in areas where coding happens with creative, project-based learning and in regard to students' self-beliefs about computing. Objective: We introduce the CS Interests and Beliefs Inventory (CSIBI), an instrument designed for novice secondary students learning by designing projects (particularly with physical computing). The inventory contains subscales on beliefs on problem solving competency, fascination in design, value of CS, creative expression, and beliefs about context-specific CS abilities alongside programming mindsets and outcomes. We explain the creation of the instrument and attend to the role of mindsets as mediators of self-beliefs and how CSIBI may be adapted to other K-12 project-based learning settings. Method: We administered the instrument to 303 novice CS secondary students who largely came from historically marginalized backgrounds (gender, ethnicity, and socioeconomic status). We assessed the nine-factor structure for the 32-item instrument using confirmatory factor analysis and tested the hypothesized model of mindsets as mediators with structural equation modeling. Findings: We confirmed the nine factor structure of CSIBI and found significant positive correlations across factors. The structural model results showed that problem solving competency beliefs and CS creative expression promoted programming growth mindset, which subsequently fostered students' programming self-concept. Implications: We validated an instrument to measure secondary students' self-beliefs in CS that fills several gaps in K-12 CS measurement tools by focusing on contexts of learning by designing. CSIBI can be easily adapted to other learning by designing computing education contexts.","sentences":["Background and Context: Few instruments exist to measure students' CS engagement and learning especially in areas where coding happens with creative, project-based learning and in regard to students' self-beliefs about computing.","Objective: We introduce the CS Interests and Beliefs Inventory (CSIBI), an instrument designed for novice secondary students learning by designing projects (particularly with physical computing).","The inventory contains subscales on beliefs on problem solving competency, fascination in design, value of CS, creative expression, and beliefs about context-specific CS abilities alongside programming mindsets and outcomes.","We explain the creation of the instrument and attend to the role of mindsets as mediators of self-beliefs and how CSIBI may be adapted to other K-12 project-based learning settings.","Method: We administered the instrument to 303 novice CS secondary students who largely came from historically marginalized backgrounds (gender, ethnicity, and socioeconomic status).","We assessed the nine-factor structure for the 32-item instrument using confirmatory factor analysis and tested the hypothesized model of mindsets as mediators with structural equation modeling.","Findings:","We confirmed the nine factor structure of CSIBI and found significant positive correlations across factors.","The structural model results showed that problem solving competency beliefs and CS creative expression promoted programming growth mindset, which subsequently fostered students' programming self-concept.","Implications: We validated an instrument to measure secondary students' self-beliefs in CS that fills several gaps in K-12 CS measurement tools by focusing on contexts of learning by designing.","CSIBI can be easily adapted to other learning by designing computing education contexts."],"url":"http://arxiv.org/abs/2307.10010v1"}
{"created":"2023-07-19 14:45:11","title":"MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions","abstract":"Audio-driven portrait animation aims to synthesize portrait videos that are conditioned by given audio. Animating high-fidelity and multimodal video portraits has a variety of applications. Previous methods have attempted to capture different motion modes and generate high-fidelity portrait videos by training different models or sampling signals from given videos. However, lacking correlation learning between lip-sync and other movements (e.g., head pose/eye blinking) usually leads to unnatural results. In this paper, we propose a unified system for multi-person, diverse, and high-fidelity talking portrait generation. Our method contains three stages, i.e., 1) Mapping-Once network with Dual Attentions (MODA) generates talking representation from given audio. In MODA, we design a dual-attention module to encode accurate mouth movements and diverse modalities. 2) Facial composer network generates dense and detailed face landmarks, and 3) temporal-guided renderer syntheses stable videos. Extensive evaluations demonstrate that the proposed system produces more natural and realistic video portraits compared to previous methods.","sentences":["Audio-driven portrait animation aims to synthesize portrait videos that are conditioned by given audio.","Animating high-fidelity and multimodal video portraits has a variety of applications.","Previous methods have attempted to capture different motion modes and generate high-fidelity portrait videos by training different models or sampling signals from given videos.","However, lacking correlation learning between lip-sync and other movements (e.g., head pose/eye blinking) usually leads to unnatural results.","In this paper, we propose a unified system for multi-person, diverse, and high-fidelity talking portrait generation.","Our method contains three stages, i.e., 1) Mapping-Once network with Dual Attentions (MODA) generates talking representation from given audio.","In MODA, we design a dual-attention module to encode accurate mouth movements and diverse modalities.","2) Facial composer network generates dense and detailed face landmarks, and 3) temporal-guided renderer syntheses stable videos.","Extensive evaluations demonstrate that the proposed system produces more natural and realistic video portraits compared to previous methods."],"url":"http://arxiv.org/abs/2307.10008v1"}
{"created":"2023-07-19 14:38:30","title":"6G Network Business Support System","abstract":"6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society. As the core support system for mobile communication network, 6 6G BSS need to integrate with new business models brought about by the development of the next-generation Internet and IT, upgrade from \"network-centric\" to \"business and service centric\" and \"customer-centric\". 6G OSS and BSS systems need to strengthen their integration to improve the operational efficiency and benefits of customers by connecting the digital intelligence support capabilities on both sides of supply and demand. This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G BSS systems. It also presents an evolutionary roadmap and technological prospects for the BSS systems from 5G to 6G.","sentences":["6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society.","As the core support system for mobile communication network, 6 6G BSS need to integrate with new business models brought about by the development of the next-generation Internet and IT, upgrade from \"network-centric\" to \"business and service centric\" and \"customer-centric\".","6G OSS and BSS systems need to strengthen their integration to improve the operational efficiency and benefits of customers by connecting the digital intelligence support capabilities on both sides of supply and demand.","This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G BSS systems.","It also presents an evolutionary roadmap and technological prospects for the BSS systems from 5G to 6G."],"url":"http://arxiv.org/abs/2307.10004v1"}
{"created":"2023-07-19 14:23:26","title":"TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction","abstract":"The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models. Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions. Heatmaps are almost understandable to humans, yet they are not without flaws. Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors). Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually explain them based on the statistics of objects in the input image when the initial prediction is unreliable. To assess the trustworthiness and validity of the text-based explanations, we conducted a qualitative experiment, and the findings indicated that these explanations are sufficiently reliable. Furthermore, our quantitative and qualitative experiments on TbExplain with scene classification datasets reveal an improvement in classification accuracy over ResNet variants.","sentences":["The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models.","Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions.","Heatmaps are almost understandable to humans, yet they are not without flaws.","Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors).","Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps.","In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models.","Moreover, TbExplain incorporates a novel method to correct predictions and textually explain them based on the statistics of objects in the input image when the initial prediction is unreliable.","To assess the trustworthiness and validity of the text-based explanations, we conducted a qualitative experiment, and the findings indicated that these explanations are sufficiently reliable.","Furthermore, our quantitative and qualitative experiments on TbExplain with scene classification datasets reveal an improvement in classification accuracy over ResNet variants."],"url":"http://arxiv.org/abs/2307.10003v1"}
{"created":"2023-07-19 14:21:11","title":"As large as it gets: Learning infinitely large Filters via Neural Implicit Functions in the Fourier Domain","abstract":"Motivated by the recent trend towards the usage of larger receptive fields for more context-aware neural networks in vision applications, we aim to investigate how large these receptive fields really need to be. To facilitate such study, several challenges need to be addressed, most importantly: (i) We need to provide an effective way for models to learn large filters (potentially as large as the input data) without increasing their memory consumption during training or inference, (ii) the study of filter sizes has to be decoupled from other effects such as the network width or number of learnable parameters, and (iii) the employed convolution operation should be a plug-and-play module that can replace any conventional convolution in a Convolutional Neural Network (CNN) and allow for an efficient implementation in current frameworks. To facilitate such models, we propose to learn not spatial but frequency representations of filter weights as neural implicit functions, such that even infinitely large filters can be parameterized by only a few learnable weights. The resulting neural implicit frequency CNNs are the first models to achieve results on par with the state-of-the-art on large image classification benchmarks while executing convolutions solely in the frequency domain and can be employed within any CNN architecture. They allow us to provide an extensive analysis of the learned receptive fields. Interestingly, our analysis shows that, although the proposed networks could learn very large convolution kernels, the learned filters practically translate into well-localized and relatively small convolution kernels in the spatial domain.","sentences":["Motivated by the recent trend towards the usage of larger receptive fields for more context-aware neural networks in vision applications, we aim to investigate how large these receptive fields really need to be.","To facilitate such study, several challenges need to be addressed, most importantly: (i) We need to provide an effective way for models to learn large filters (potentially as large as the input data) without increasing their memory consumption during training or inference, (ii) the study of filter sizes has to be decoupled from other effects such as the network width or number of learnable parameters, and (iii) the employed convolution operation should be a plug-and-play module that can replace any conventional convolution in a Convolutional Neural Network (CNN) and allow for an efficient implementation in current frameworks.","To facilitate such models, we propose to learn not spatial but frequency representations of filter weights as neural implicit functions, such that even infinitely large filters can be parameterized by only a few learnable weights.","The resulting neural implicit frequency CNNs are the first models to achieve results on par with the state-of-the-art on large image classification benchmarks while executing convolutions solely in the frequency domain and can be employed within any CNN architecture.","They allow us to provide an extensive analysis of the learned receptive fields.","Interestingly, our analysis shows that, although the proposed networks could learn very large convolution kernels, the learned filters practically translate into well-localized and relatively small convolution kernels in the spatial domain."],"url":"http://arxiv.org/abs/2307.10001v1"}
{"created":"2023-07-19 14:13:02","title":"Generating Mathematical Derivations with Large Language Models","abstract":"The derivation of mathematical results in specialised fields using Large Language Models (LLMs) is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery. In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises. Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models. Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in terms of absolute performance. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse 1.7K equations and over 200 derivations to highlight common reasoning errors such as the inclusion of incorrect, irrelevant, and redundant equations, along with the tendency to skip derivation steps. Finally, we explore the suitability of existing metrics for evaluating mathematical derivations finding evidence that, while they capture general properties such as sensitivity to perturbations, they fail to highlight fine-grained reasoning errors and essential differences between models. Overall, this work demonstrates that training models on synthetic data can improve their mathematical capabilities beyond larger architectures.","sentences":["The derivation of mathematical results in specialised fields using Large Language Models (LLMs) is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery.","In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises.","Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models.","Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in terms of absolute performance.","However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure.","In addition, we analyse 1.7K equations and over 200 derivations to highlight common reasoning errors such as the inclusion of incorrect, irrelevant, and redundant equations, along with the tendency to skip derivation steps.","Finally, we explore the suitability of existing metrics for evaluating mathematical derivations finding evidence that, while they capture general properties such as sensitivity to perturbations, they fail to highlight fine-grained reasoning errors and essential differences between models.","Overall, this work demonstrates that training models on synthetic data can improve their mathematical capabilities beyond larger architectures."],"url":"http://arxiv.org/abs/2307.09998v1"}
{"created":"2023-07-19 14:10:55","title":"TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical Phase Recognition","abstract":"To enable context-aware computer assistance in the operating room of the future, cognitive systems need to understand automatically which surgical phase is being performed by the medical team. The primary source of information for surgical phase recognition is typically video, which presents two challenges: extracting meaningful features from the video stream and effectively modeling temporal information in the sequence of visual features. For temporal modeling, attention mechanisms have gained popularity due to their ability to capture long-range dependencies. In this paper, we explore design choices for attention in existing temporal models for surgical phase recognition and propose a novel approach that does not resort to local attention or regularization of attention weights: TUNeS is an efficient and simple temporal model that incorporates self-attention at the coarsest stage of a U-Net-like structure. In addition, we propose to train the feature extractor, a standard CNN, together with an LSTM on preferably long video segments, i.e., with long temporal context. In our experiments, all temporal models performed better on top of feature extractors that were trained with longer temporal context. On top of these contextualized features, TUNeS achieves state-of-the-art results on Cholec80.","sentences":["To enable context-aware computer assistance in the operating room of the future, cognitive systems need to understand automatically which surgical phase is being performed by the medical team.","The primary source of information for surgical phase recognition is typically video, which presents two challenges: extracting meaningful features from the video stream and effectively modeling temporal information in the sequence of visual features.","For temporal modeling, attention mechanisms have gained popularity due to their ability to capture long-range dependencies.","In this paper, we explore design choices for attention in existing temporal models for surgical phase recognition and propose a novel approach that does not resort to local attention or regularization of attention weights: TUNeS is an efficient and simple temporal model that incorporates self-attention at the coarsest stage of a U-Net-like structure.","In addition, we propose to train the feature extractor, a standard CNN, together with an LSTM on preferably long video segments, i.e., with long temporal context.","In our experiments, all temporal models performed better on top of feature extractors that were trained with longer temporal context.","On top of these contextualized features, TUNeS achieves state-of-the-art results on Cholec80."],"url":"http://arxiv.org/abs/2307.09997v1"}
{"created":"2023-07-19 13:58:01","title":"Impact of Disentanglement on Pruning Neural Networks","abstract":"Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency. This can be realized via efficient model compression. Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand. We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification. In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works.","sentences":["Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency.","This can be realized via efficient model compression.","Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand.","We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification.","In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works."],"url":"http://arxiv.org/abs/2307.09994v1"}
{"created":"2023-07-19 13:49:35","title":"UniMatch: A Unified User-Item Matching Framework for the Multi-purpose Merchant Marketing","abstract":"When doing private domain marketing with cloud services, the merchants usually have to purchase different machine learning models for the multiple marketing purposes, leading to a very high cost. We present a unified user-item matching framework to simultaneously conduct item recommendation and user targeting with just one model. We empirically demonstrate that the above concurrent modeling is viable via modeling the user-item interaction matrix with the multinomial distribution, and propose a bidirectional bias-corrected NCE loss for the implementation. The proposed loss function guides the model to learn the user-item joint probability $p(u,i)$ instead of the conditional probability $p(i|u)$ or $p(u|i)$ through correcting both the users and items' biases caused by the in-batch negative sampling. In addition, our framework is model-agnostic enabling a flexible adaptation of different model architectures. Extensive experiments demonstrate that our framework results in significant performance gains in comparison with the state-of-the-art methods, with greatly reduced cost on computing resources and daily maintenance.","sentences":["When doing private domain marketing with cloud services, the merchants usually have to purchase different machine learning models for the multiple marketing purposes, leading to a very high cost.","We present a unified user-item matching framework to simultaneously conduct item recommendation and user targeting with just one model.","We empirically demonstrate that the above concurrent modeling is viable via modeling the user-item interaction matrix with the multinomial distribution, and propose a bidirectional bias-corrected NCE loss for the implementation.","The proposed loss function guides the model to learn the user-item joint probability $p(u,i)$ instead of the conditional probability $p(i|u)$ or $p(u|i)$ through correcting both the users and items' biases caused by the in-batch negative sampling.","In addition, our framework is model-agnostic enabling a flexible adaptation of different model architectures.","Extensive experiments demonstrate that our framework results in significant performance gains in comparison with the state-of-the-art methods, with greatly reduced cost on computing resources and daily maintenance."],"url":"http://arxiv.org/abs/2307.09989v1"}
{"created":"2023-07-19 13:49:12","title":"TinyTrain: Deep Neural Network Training at the Extreme Edge","abstract":"On-device training is essential for user personalisation and privacy. With the pervasiveness of IoT devices and microcontroller units (MCU), this task becomes more challenging due to the constrained memory and compute resources, and the limited availability of labelled user data. Nonetheless, prior works neglect the data scarcity issue, require excessively long training time (e.g. a few hours), or induce substantial accuracy loss ($\\geq$10\\%). We propose TinyTrain, an on-device training approach that drastically reduces training time by selectively updating parts of the model and explicitly coping with data scarcity. TinyTrain introduces a task-adaptive sparse-update method that dynamically selects the layer/channel based on a multi-objective criterion that jointly captures user data, the memory, and the compute capabilities of the target device, leading to high accuracy on unseen tasks with reduced computation and memory footprint. TinyTrain outperforms vanilla fine-tuning of the entire network by 3.6-5.0\\% in accuracy, while reducing the backward-pass memory and computation cost by up to 2,286$\\times$ and 7.68$\\times$, respectively. Targeting broadly used real-world edge devices, TinyTrain achieves 9.5$\\times$ faster and 3.5$\\times$ more energy-efficient training over status-quo approaches, and 2.8$\\times$ smaller memory footprint than SOTA approaches, while remaining within the 1 MB memory envelope of MCU-grade platforms.","sentences":["On-device training is essential for user personalisation and privacy.","With the pervasiveness of IoT devices and microcontroller units (MCU), this task becomes more challenging due to the constrained memory and compute resources, and the limited availability of labelled user data.","Nonetheless, prior works neglect the data scarcity issue, require excessively long training time (e.g. a few hours), or induce substantial accuracy loss ($\\geq$10\\%).","We propose TinyTrain, an on-device training approach that drastically reduces training time by selectively updating parts of the model and explicitly coping with data scarcity.","TinyTrain introduces a task-adaptive sparse-update method that dynamically selects the layer/channel based on a multi-objective criterion that jointly captures user data, the memory, and the compute capabilities of the target device, leading to high accuracy on unseen tasks with reduced computation and memory footprint.","TinyTrain outperforms vanilla fine-tuning of the entire network by 3.6-5.0\\% in accuracy, while reducing the backward-pass memory and computation cost by up to 2,286$\\times$ and 7.68$\\times$, respectively.","Targeting broadly used real-world edge devices, TinyTrain achieves 9.5$\\times$ faster and 3.5$\\times$ more energy-efficient training over status-quo approaches, and 2.8$\\times$ smaller memory footprint than SOTA approaches, while remaining within the 1 MB memory envelope of MCU-grade platforms."],"url":"http://arxiv.org/abs/2307.09988v1"}
{"created":"2023-07-19 13:45:55","title":"Modeling Rabbit-Holes on YouTube","abstract":"Numerous discussions have advocated the presence of a so called rabbit-hole (RH) phenomenon on social media, interested in advanced personalization to their users. This phenomenon is loosely understood as a collapse of mainstream recommendations, in favor of ultra personalized ones that lock users into narrow and specialized feeds. Yet quantitative studies are often ignoring personalization, are of limited scale, and rely on manual tagging to track this collapse. This precludes a precise understanding of the phenomenon based on reproducible observations, and thus the continuous audits of platforms. In this paper, we first tackle the scale issue by proposing a user-sided bot-centric approach that enables large scale data collection, through autoplay walks on recommendations. We then propose a simple theory that explains the appearance of these RHs. While this theory is a simplifying viewpoint on a complex and planet-wide phenomenon, it carries multiple advantages: it can be analytically modeled, and provides a general yet rigorous definition of RHs. We define them as an interplay between i) user interaction with personalization and ii) the attraction strength of certain video categories, which cause users to quickly step apart of mainstream recommendations made to fresh user profiles. We illustrate these concepts by highlighting some RHs found after collecting more than 16 million personalized recommendations on YouTube. A final validation step compares our automatically-identified RHs against manually-identified RHs from a previous research work. Together, those results pave the way for large scale and automated audits of the RH effect in recommendation systems.","sentences":["Numerous discussions have advocated the presence of a so called rabbit-hole (RH) phenomenon on social media, interested in advanced personalization to their users.","This phenomenon is loosely understood as a collapse of mainstream recommendations, in favor of ultra personalized ones that lock users into narrow and specialized feeds.","Yet quantitative studies are often ignoring personalization, are of limited scale, and rely on manual tagging to track this collapse.","This precludes a precise understanding of the phenomenon based on reproducible observations, and thus the continuous audits of platforms.","In this paper, we first tackle the scale issue by proposing a user-sided bot-centric approach that enables large scale data collection, through autoplay walks on recommendations.","We then propose a simple theory that explains the appearance of these RHs.","While this theory is a simplifying viewpoint on a complex and planet-wide phenomenon, it carries multiple advantages: it can be analytically modeled, and provides a general yet rigorous definition of RHs.","We define them as an interplay between i) user interaction with personalization and ii) the attraction strength of certain video categories, which cause users to quickly step apart of mainstream recommendations made to fresh user profiles.","We illustrate these concepts by highlighting some RHs found after collecting more than 16 million personalized recommendations on YouTube.","A final validation step compares our automatically-identified RHs against manually-identified RHs from a previous research work.","Together, those results pave the way for large scale and automated audits of the RH effect in recommendation systems."],"url":"http://arxiv.org/abs/2307.09986v1"}
{"created":"2023-07-19 13:44:32","title":"Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?","abstract":"A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g.,like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis on the MovieLens dataset and explain the potential impact on using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Removal of interactions that happen nearer to the last few interactions of a user leads to increasing difficulty in learning user preference, thus deteriorating recommendation accuracy. Third, changing the order of user interactions makes it more difficult for sequential algorithms to capture the progressive interaction process. Based on these findings, we further discuss the discrepancy between the interaction generation mechanism that is employed by the MovieLens system and that of typical real world recommendation scenarios. In summary, models that achieve excellent recommendation accuracy on the MovieLens dataset may not demonstrate superior performance in practice for at least two kinds of differences: (i) the differences in the contexts of user-item interaction generation, and (ii) the differences in user knowledge about the item collections.","sentences":["A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period.","The interaction generation mechanism partially explains why a user interacts with (e.g.,like, purchase, rate) an item, and the context of when a particular interaction happened.","In this study, we conduct a meticulous analysis on the MovieLens dataset and explain the potential impact on using the dataset for evaluating recommendation algorithms.","We make a few main findings from our analysis.","First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform.","The early interactions largely define the user portrait which affect the subsequent interactions.","Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s).","Removal of interactions that happen nearer to the last few interactions of a user leads to increasing difficulty in learning user preference, thus deteriorating recommendation accuracy.","Third, changing the order of user interactions makes it more difficult for sequential algorithms to capture the progressive interaction process.","Based on these findings, we further discuss the discrepancy between the interaction generation mechanism that is employed by the MovieLens system and that of typical real world recommendation scenarios.","In summary, models that achieve excellent recommendation accuracy on the MovieLens dataset may not demonstrate superior performance in practice for at least two kinds of differences: (i) the differences in the contexts of user-item interaction generation, and (ii) the differences in user knowledge about the item collections."],"url":"http://arxiv.org/abs/2307.09985v1"}
{"created":"2023-07-19 13:40:45","title":"Lazy Visual Localization via Motion Averaging","abstract":"Visual (re)localization is critical for various applications in computer vision and robotics. Its goal is to estimate the 6 degrees of freedom (DoF) camera pose for each query image, based on a set of posed database images. Currently, all leading solutions are structure-based that either explicitly construct 3D metric maps from the database with structure-from-motion, or implicitly encode the 3D information with scene coordinate regression models. On the contrary, visual localization without reconstructing the scene in 3D offers clear benefits. It makes deployment more convenient by reducing database pre-processing time, releasing storage requirements, and remaining unaffected by imperfect reconstruction, etc. In this technical report, we demonstrate that it is possible to achieve high localization accuracy without reconstructing the scene from the database. The key to achieving this owes to a tailored motion averaging over database-query pairs. Experiments show that our visual localization proposal, LazyLoc, achieves comparable performance against state-of-the-art structure-based methods. Furthermore, we showcase the versatility of LazyLoc, which can be easily extended to handle complex configurations such as multi-query co-localization and camera rigs.","sentences":["Visual (re)localization is critical for various applications in computer vision and robotics.","Its goal is to estimate the 6 degrees of freedom (DoF) camera pose for each query image, based on a set of posed database images.","Currently, all leading solutions are structure-based that either explicitly construct 3D metric maps from the database with structure-from-motion, or implicitly encode the 3D information with scene coordinate regression models.","On the contrary, visual localization without reconstructing the scene in 3D offers clear benefits.","It makes deployment more convenient by reducing database pre-processing time, releasing storage requirements, and remaining unaffected by imperfect reconstruction, etc.","In this technical report, we demonstrate that it is possible to achieve high localization accuracy without reconstructing the scene from the database.","The key to achieving this owes to a tailored motion averaging over database-query pairs.","Experiments show that our visual localization proposal, LazyLoc, achieves comparable performance against state-of-the-art structure-based methods.","Furthermore, we showcase the versatility of LazyLoc, which can be easily extended to handle complex configurations such as multi-query co-localization and camera rigs."],"url":"http://arxiv.org/abs/2307.09981v1"}
{"created":"2023-07-19 13:38:44","title":"From Ukraine to the World: Using LinkedIn Data to Monitor Professional Migration from Ukraine","abstract":"Highly skilled professionals' forced migration from Ukraine was triggered by the conflict in Ukraine in 2014 and amplified by the Russian invasion in 2022. Here, we utilize LinkedIn estimates and official refugee data from the World Bank and the United Nations Refugee Agency, to understand which are the main pull factors that drive the decision-making process of the host country. We identify an ongoing and escalating exodus of educated individuals, largely drawn to Poland and Germany, and underscore the crucial role of pre-existing networks in shaping these migration flows. Key findings include a strong correlation between LinkedIn's estimates of highly educated Ukrainian displaced people and official UN refugee statistics, pointing to the significance of prior relationships with Ukraine in determining migration destinations. We train a series of multilinear regression models and the SHAP method revealing that the existence of a support network is the most critical factor in choosing a destination country, while distance is less important. Our main findings show that the migration patterns of Ukraine's highly skilled workforce, and their impact on both the origin and host countries, are largely influenced by preexisting networks and communities. This insight can inform strategies to tackle the economic challenges posed by this loss of talent and maximize the benefits of such migration for both Ukraine and the receiving nations.","sentences":["Highly skilled professionals' forced migration from Ukraine was triggered by the conflict in Ukraine in 2014 and amplified by the Russian invasion in 2022.","Here, we utilize LinkedIn estimates and official refugee data from the World Bank and the United Nations Refugee Agency, to understand which are the main pull factors that drive the decision-making process of the host country.","We identify an ongoing and escalating exodus of educated individuals, largely drawn to Poland and Germany, and underscore the crucial role of pre-existing networks in shaping these migration flows.","Key findings include a strong correlation between LinkedIn's estimates of highly educated Ukrainian displaced people and official UN refugee statistics, pointing to the significance of prior relationships with Ukraine in determining migration destinations.","We train a series of multilinear regression models and the SHAP method revealing that the existence of a support network is the most critical factor in choosing a destination country, while distance is less important.","Our main findings show that the migration patterns of Ukraine's highly skilled workforce, and their impact on both the origin and host countries, are largely influenced by preexisting networks and communities.","This insight can inform strategies to tackle the economic challenges posed by this loss of talent and maximize the benefits of such migration for both Ukraine and the receiving nations."],"url":"http://arxiv.org/abs/2307.09979v1"}
{"created":"2023-07-19 13:33:43","title":"Learner Referral for Cost-Effective Federated Learning Over Hierarchical IoT Networks","abstract":"The paradigm of federated learning (FL) to address data privacy concerns by locally training parameters on resource-constrained clients in a distributed manner has garnered significant attention. Nonetheless, FL is not applicable when not all clients within the coverage of the FL server are registered with the FL network. To bridge this gap, this paper proposes joint learner referral aided federated client selection (LRef-FedCS), along with communications and computing resource scheduling, and local model accuracy optimization (LMAO) methods. These methods are designed to minimize the cost incurred by the worst-case participant and ensure the long-term fairness of FL in hierarchical Internet of Things (HieIoT) networks. Utilizing the Lyapunov optimization technique, we reformulate the original problem into a stepwise joint optimization problem (JOP). Subsequently, to tackle the mixed-integer non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO through the centralized method and self-adaptive global best harmony search (SGHS) algorithm, respectively. To enhance scalability, we further propose a distributed LRef-FedCS approach based on a matching game to replace the centralized method described above. Numerical simulations and experimental results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS approach could achieve a good balance between pursuing high global accuracy and reducing cost.","sentences":["The paradigm of federated learning (FL) to address data privacy concerns by locally training parameters on resource-constrained clients in a distributed manner has garnered significant attention.","Nonetheless, FL is not applicable when not all clients within the coverage of the FL server are registered with the FL network.","To bridge this gap, this paper proposes joint learner referral aided federated client selection (LRef-FedCS), along with communications and computing resource scheduling, and local model accuracy optimization (LMAO) methods.","These methods are designed to minimize the cost incurred by the worst-case participant and ensure the long-term fairness of FL in hierarchical Internet of Things (HieIoT) networks.","Utilizing the Lyapunov optimization technique, we reformulate the original problem into a stepwise joint optimization problem (JOP).","Subsequently, to tackle the mixed-integer non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO through the centralized method and self-adaptive global best harmony search (SGHS) algorithm, respectively.","To enhance scalability, we further propose a distributed LRef-FedCS approach based on a matching game to replace the centralized method described above.","Numerical simulations and experimental results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS approach could achieve a good balance between pursuing high global accuracy and reducing cost."],"url":"http://arxiv.org/abs/2307.09977v1"}
{"created":"2023-07-19 13:21:47","title":"EPUF: A Novel Scheme Based on Entropy Features of Latency-based DRAM PUFs Providing Lightweight Authentication in IoT Networks","abstract":"Physical unclonable functions (PUFs) are hardware-oriented primitives that exploit manufacturing variations to generate a unique identity for a physical system. Recent advancements showed how DRAM can be exploited to implement PUFs. DRAM PUFs require no additional circuits for PUF operations and can be used in most of the applications with resource-constrained nodes such as Internet of Things (IoT) networks. However, the existing DRAM PUF solutions either require to interrupt other functions in the host system, or provide unreliable responses due to their sensitiveness to the environmental conditions.   In this paper, we propose EPUF, a novel strategy to extract random and unique features from DRAM cells to generate reliable PUF responses. In particular, we use the bitmap images of the binary DRAM values and their entropy features. We show via real device experiments that EPUF is approximately $1.7$ times faster than other state of the art solutions, achieves $100\\%$ reliability, generates features with $47.79\\%$ uniqueness, and supports a large set of CRP that leads to new potentials for DRAM PUF-based authentication. We also propose a lightweight authentication protocol based on EPUF, which not only provides far better security guarantees but also outperforms the state-of-the-art in terms of communication overhead and computational cost.","sentences":["Physical unclonable functions (PUFs) are hardware-oriented primitives that exploit manufacturing variations to generate a unique identity for a physical system.","Recent advancements showed how DRAM can be exploited to implement PUFs.","DRAM PUFs require no additional circuits for PUF operations and can be used in most of the applications with resource-constrained nodes such as Internet of Things (IoT) networks.","However, the existing DRAM PUF solutions either require to interrupt other functions in the host system, or provide unreliable responses due to their sensitiveness to the environmental conditions.   ","In this paper, we propose EPUF, a novel strategy to extract random and unique features from DRAM cells to generate reliable PUF responses.","In particular, we use the bitmap images of the binary DRAM values and their entropy features.","We show via real device experiments that EPUF is approximately $1.7$ times faster than other state of the art solutions, achieves $100\\%$ reliability, generates features with $47.79\\%$ uniqueness, and supports a large set of CRP that leads to new potentials for DRAM PUF-based authentication.","We also propose a lightweight authentication protocol based on EPUF, which not only provides far better security guarantees but also outperforms the state-of-the-art in terms of communication overhead and computational cost."],"url":"http://arxiv.org/abs/2307.09968v1"}
{"created":"2023-07-19 13:14:47","title":"Towards green AI-based software systems: an architecture-centric approach (GAISSA)","abstract":"Nowadays, AI-based systems have achieved outstanding results and have outperformed humans in different domains. However, the processes of training AI models and inferring from them require high computational resources, which pose a significant challenge in the current energy efficiency societal demand. To cope with this challenge, this research project paper describes the main vision, goals, and expected outcomes of the GAISSA project. The GAISSA project aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green AI-based systems. Although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve GAISSA objectives.","sentences":["Nowadays, AI-based systems have achieved outstanding results and have outperformed humans in different domains.","However, the processes of training AI models and inferring from them require high computational resources, which pose a significant challenge in the current energy efficiency societal demand.","To cope with this challenge, this research project paper describes the main vision, goals, and expected outcomes of the GAISSA project.","The GAISSA project aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green AI-based systems.","Although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve GAISSA objectives."],"url":"http://arxiv.org/abs/2307.09964v1"}
{"created":"2023-07-19 13:03:27","title":"On Dynamic Graph Algorithms with Predictions","abstract":"We study dynamic algorithms in the model of algorithms with predictions. We assume the algorithm is given imperfect predictions regarding future updates, and we ask how such predictions can be used to improve the running time. This can be seen as a model interpolating between classic online and offline dynamic algorithms. Our results give smooth tradeoffs between these two extreme settings.   First, we give algorithms for incremental and decremental transitive closure and approximate APSP that take as an additional input a predicted sequence of updates (edge insertions, or edge deletions, respectively). They preprocess it in $\\tilde{O}(n^{(3+\\omega)/2})$ time, and then handle updates in $\\tilde{O}(1)$ worst-case time and queries in $\\tilde{O}(\\eta^2)$ worst-case time. Here $\\eta$ is an error measure that can be bounded by the maximum difference between the predicted and actual insertion (deletion) time of an edge, i.e., by the $\\ell_\\infty$-error of the predictions.   The second group of results concerns fully dynamic problems with vertex updates, where the algorithm has access to a predicted sequence of the next $n$ updates. We show how to solve fully dynamic triangle detection, maximum matching, single-source reachability, and more, in $O(n^{\\omega-1}+n\\eta_i)$ worst-case update time. Here $\\eta_i$ denotes how much earlier the $i$-th update occurs than predicted.   Our last result is a reduction that transforms a worst-case incremental algorithm without predictions into a fully dynamic algorithm which is given a predicted deletion time for each element at the time of its insertion. As a consequence we can, e.g., maintain fully dynamic exact APSP with such predictions in $\\tilde{O}(n^2)$ worst-case vertex insertion time and $\\tilde{O}(n^2 (1+\\eta_i))$ worst-case vertex deletion time (for the prediction error $\\eta_i$ defined as above).","sentences":["We study dynamic algorithms in the model of algorithms with predictions.","We assume the algorithm is given imperfect predictions regarding future updates, and we ask how such predictions can be used to improve the running time.","This can be seen as a model interpolating between classic online and offline dynamic algorithms.","Our results give smooth tradeoffs between these two extreme settings.   ","First, we give algorithms for incremental and decremental transitive closure and approximate APSP that take as an additional input a predicted sequence of updates (edge insertions, or edge deletions, respectively).","They preprocess it in $\\tilde{O}(n^{(3+\\omega)/2})$ time, and then handle updates in $\\tilde{O}(1)$ worst-case time and queries in $\\tilde{O}(\\eta^2)$ worst-case time.","Here $\\eta$ is an error measure that can be bounded by the maximum difference between the predicted and actual insertion (deletion) time of an edge, i.e., by the $\\ell_\\infty$-error of the predictions.   ","The second group of results concerns fully dynamic problems with vertex updates, where the algorithm has access to a predicted sequence of the next $n$ updates.","We show how to solve fully dynamic triangle detection, maximum matching, single-source reachability, and more, in $O(n^{\\omega-1}+n\\eta_i)$ worst-case update time.","Here $\\eta_i$ denotes how much earlier the $i$-th update occurs than predicted.   ","Our last result is a reduction that transforms a worst-case incremental algorithm without predictions into a fully dynamic algorithm which is given a predicted deletion time for each element at the time of its insertion.","As a consequence we can, e.g., maintain fully dynamic exact APSP with such predictions in $\\tilde{O}(n^2)$ worst-case vertex insertion time and $\\tilde{O}(n^2 (1+\\eta_i))$ worst-case vertex deletion time (for the prediction error $\\eta_i$ defined as above)."],"url":"http://arxiv.org/abs/2307.09961v1"}
{"created":"2023-07-19 13:01:03","title":"GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural Language Texts","abstract":"Extracting workflow nets from textual descriptions can be used to simplify guidelines or formalize textual descriptions of formal processes like business processes and algorithms. The task of manually extracting processes, however, requires domain expertise and effort. While automatic process model extraction is desirable, annotating texts with formalized process models is expensive. Therefore, there are only a few machine-learning-based extraction approaches. Rule-based approaches, in turn, require domain specificity to work well and can rarely distinguish relevant and irrelevant information in textual descriptions. In this paper, we present GUIDO, a hybrid approach to the process model extraction task that first, classifies sentences regarding their relevance to the process model, using a BERT-based sentence classifier, and second, extracts a process model from the sentences classified as relevant, using dependency parsing. The presented approach achieves significantly better results than a pure rule-based approach. GUIDO achieves an average behavioral similarity score of $0.93$. Still, in comparison to purely machine-learning-based approaches, the annotation costs stay low.","sentences":["Extracting workflow nets from textual descriptions can be used to simplify guidelines or formalize textual descriptions of formal processes like business processes and algorithms.","The task of manually extracting processes, however, requires domain expertise and effort.","While automatic process model extraction is desirable, annotating texts with formalized process models is expensive.","Therefore, there are only a few machine-learning-based extraction approaches.","Rule-based approaches, in turn, require domain specificity to work well and can rarely distinguish relevant and irrelevant information in textual descriptions.","In this paper, we present GUIDO, a hybrid approach to the process model extraction task that first, classifies sentences regarding their relevance to the process model, using a BERT-based sentence classifier, and second, extracts a process model from the sentences classified as relevant, using dependency parsing.","The presented approach achieves significantly better results than a pure rule-based approach.","GUIDO achieves an average behavioral similarity score of $0.93$. Still, in comparison to purely machine-learning-based approaches, the annotation costs stay low."],"url":"http://arxiv.org/abs/2307.09959v1"}
{"created":"2023-07-19 12:58:00","title":"Bias in Internet Measurement Platforms","abstract":"Network operators and researchers frequently use Internet measurement platforms (IMPs), such as RIPE Atlas, RIPE RIS, or RouteViews for, e.g., monitoring network performance, detecting routing events, topology discovery, or route optimization. To interpret the results of their measurements and avoid pitfalls or wrong generalizations, users must understand a platform's limitations. To this end, this paper studies an important limitation of IMPs, the \\textit{bias}, which exists due to the non-uniform deployment of the vantage points. Specifically, we introduce a generic framework to systematically and comprehensively quantify the multi-dimensional (e.g., across location, topology, network types, etc.) biases of IMPs. Using the framework and open datasets, we perform a detailed analysis of biases in IMPs that confirms well-known (to the domain experts) biases and sheds light on less-known or unexplored biases. To facilitate IMP users to obtain awareness of and explore bias in their measurements, as well as further research and analyses (e.g., methods for mitigating bias), we publicly share our code and data, and provide online tools (API, Web app, etc.) that calculate and visualize the bias in measurement setups.","sentences":["Network operators and researchers frequently use Internet measurement platforms (IMPs), such as RIPE Atlas, RIPE RIS, or RouteViews for, e.g., monitoring network performance, detecting routing events, topology discovery, or route optimization.","To interpret the results of their measurements and avoid pitfalls or wrong generalizations, users must understand a platform's limitations.","To this end, this paper studies an important limitation of IMPs, the \\textit{bias}, which exists due to the non-uniform deployment of the vantage points.","Specifically, we introduce a generic framework to systematically and comprehensively quantify the multi-dimensional (e.g., across location, topology, network types, etc.)","biases of IMPs.","Using the framework and open datasets, we perform a detailed analysis of biases in IMPs that confirms well-known (to the domain experts) biases and sheds light on less-known or unexplored biases.","To facilitate IMP users to obtain awareness of and explore bias in their measurements, as well as further research and analyses (e.g., methods for mitigating bias), we publicly share our code and data, and provide online tools (API, Web app, etc.) that calculate and visualize the bias in measurement setups."],"url":"http://arxiv.org/abs/2307.09958v1"}
{"created":"2023-07-19 12:51:28","title":"XSkill: Cross Embodiment Skill Discovery","abstract":"Human demonstration videos are a widely available data source for robot learning and an intuitive user interface for expressing desired behavior. However, directly extracting reusable robot manipulation skills from unstructured human videos is challenging due to the big embodiment difference and unobserved action parameters. To bridge this embodiment gap, this paper introduces XSkill, an imitation learning framework that 1) discovers a cross-embodiment representation called skill prototypes purely from unlabeled human and robot manipulation videos, 2) transfers the skill representation to robot actions using conditional diffusion policy, and finally, 3) composes the learned skill to accomplish unseen tasks specified by a human prompt video. Our experiments in simulation and real-world environments show that the discovered skill prototypes facilitate both skill transfer and composition for unseen tasks, resulting in a more general and scalable imitation learning framework. The performance of XSkill is best understood from the anonymous website: https://xskillcorl.github.io.","sentences":["Human demonstration videos are a widely available data source for robot learning and an intuitive user interface for expressing desired behavior.","However, directly extracting reusable robot manipulation skills from unstructured human videos is challenging due to the big embodiment difference and unobserved action parameters.","To bridge this embodiment gap, this paper introduces XSkill, an imitation learning framework that 1) discovers a cross-embodiment representation called skill prototypes purely from unlabeled human and robot manipulation videos, 2) transfers the skill representation to robot actions using conditional diffusion policy, and finally, 3) composes the learned skill to accomplish unseen tasks specified by a human prompt video.","Our experiments in simulation and real-world environments show that the discovered skill prototypes facilitate both skill transfer and composition for unseen tasks, resulting in a more general and scalable imitation learning framework.","The performance of XSkill is best understood from the anonymous website: https://xskillcorl.github.io."],"url":"http://arxiv.org/abs/2307.09955v1"}
{"created":"2023-07-19 12:46:50","title":"Symbolic Semantics for Probabilistic Programs (extended version)","abstract":"We present a new symbolic execution semantics of probabilistic programs that include observe statements and sampling from continuous distributions. Building on Kozen's seminal work, this symbolic semantics consists of a countable collection of measurable functions, along with a partition of the state space. We use the new semantics to provide a full correctness proof of symbolic execution for probabilistic programs. We also implement this semantics in the tool symProb, and illustrate its use on examples.","sentences":["We present a new symbolic execution semantics of probabilistic programs that include observe statements and sampling from continuous distributions.","Building on Kozen's seminal work, this symbolic semantics consists of a countable collection of measurable functions, along with a partition of the state space.","We use the new semantics to provide a full correctness proof of symbolic execution for probabilistic programs.","We also implement this semantics in the tool symProb, and illustrate its use on examples."],"url":"http://arxiv.org/abs/2307.09951v1"}
{"created":"2023-07-19 12:44:59","title":"Prompting for Automatic Log Template Extraction","abstract":"Log parsing, the initial and vital stage in automated log analysis, involves extracting log templates from semi-structured logs to generate structured logs. Nonetheless, current log parsers are limited in effectiveness due to two primary reasons. Firstly, traditional data-driven log parsers heavily rely on heuristics or manually crafted features provided by domain experts, which may not consistently yield optimal performance when applied to diverse log systems. Secondly, existing deep learning-based log parsers necessitate model tuning, which is typically confined to training samples and leads to suboptimal performance across the entire log source. To overcome these limitations, we propose a precise log parsing framework named LogDiv, which leverages the in-context inference capability of large language models. Specifically, LogDiv extracts the hidden semantics from multiple log examples through prompt demonstrations. Without the need for model tuning, LogDiv can directly generate a log template for the target log message by leveraging the semantics provided in the prompt context. Additionally, we introduce a simple yet effective prompt format for extracting the output and enhancing the quality of the generated log templates. To validate the performance of LogDiv, we conducted experiments using 16 widely-used public datasets. The results show that LogDiv achieves state-of-the-art performance with an average parsing accuracy of 97.7%, precision template accuracy of 88.1%, and recall template accuracy of 90.8%.","sentences":["Log parsing, the initial and vital stage in automated log analysis, involves extracting log templates from semi-structured logs to generate structured logs.","Nonetheless, current log parsers are limited in effectiveness due to two primary reasons.","Firstly, traditional data-driven log parsers heavily rely on heuristics or manually crafted features provided by domain experts, which may not consistently yield optimal performance when applied to diverse log systems.","Secondly, existing deep learning-based log parsers necessitate model tuning, which is typically confined to training samples and leads to suboptimal performance across the entire log source.","To overcome these limitations, we propose a precise log parsing framework named LogDiv, which leverages the in-context inference capability of large language models.","Specifically, LogDiv extracts the hidden semantics from multiple log examples through prompt demonstrations.","Without the need for model tuning, LogDiv can directly generate a log template for the target log message by leveraging the semantics provided in the prompt context.","Additionally, we introduce a simple yet effective prompt format for extracting the output and enhancing the quality of the generated log templates.","To validate the performance of LogDiv, we conducted experiments using 16 widely-used public datasets.","The results show that LogDiv achieves state-of-the-art performance with an average parsing accuracy of 97.7%, precision template accuracy of 88.1%, and recall template accuracy of 90.8%."],"url":"http://arxiv.org/abs/2307.09950v1"}
{"created":"2023-07-19 12:41:54","title":"U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation","abstract":"Deep neural networks have shown exceptional performance in various tasks, but their lack of robustness, reliability, and tendency to be overconfident pose challenges for their deployment in safety-critical applications like autonomous driving. In this regard, quantifying the uncertainty inherent to a model's prediction is a promising endeavour to address these shortcomings. In this work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that incorporates dynamic predictive uncertainties into the training process by pixel-wise weighting of the well-known cross-entropy loss (CE). Through extensive experimentation, we demonstrate the superiority of U-CE over regular CE training on two benchmark datasets, Cityscapes and ACDC, using two common backbone architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train models that not only improve their segmentation performance but also provide meaningful uncertainties after training. Consequently, we contribute to the development of more robust and reliable segmentation models, ultimately advancing the state-of-the-art in safety-critical applications and beyond.","sentences":["Deep neural networks have shown exceptional performance in various tasks, but their lack of robustness, reliability, and tendency to be overconfident pose challenges for their deployment in safety-critical applications like autonomous driving.","In this regard, quantifying the uncertainty inherent to a model's prediction is a promising endeavour to address these shortcomings.","In this work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that incorporates dynamic predictive uncertainties into the training process by pixel-wise weighting of the well-known cross-entropy loss (CE).","Through extensive experimentation, we demonstrate the superiority of U-CE over regular CE training on two benchmark datasets, Cityscapes and ACDC, using two common backbone architectures, ResNet-18 and ResNet-101.","With U-CE, we manage to train models that not only improve their segmentation performance but also provide meaningful uncertainties after training.","Consequently, we contribute to the development of more robust and reliable segmentation models, ultimately advancing the state-of-the-art in safety-critical applications and beyond."],"url":"http://arxiv.org/abs/2307.09947v1"}
{"created":"2023-07-19 12:39:40","title":"ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method","abstract":"Capsule Networks have emerged as a powerful class of deep learning architectures, known for robust performance with relatively few parameters compared to Convolutional Neural Networks (CNNs). However, their inherent efficiency is often overshadowed by their slow, iterative routing mechanisms which establish connections between Capsule layers, posing computational challenges resulting in an inability to scale. In this paper, we introduce a novel, non-iterative routing mechanism, inspired by trainable prototype clustering. This innovative approach aims to mitigate computational complexity, while retaining, if not enhancing, performance efficacy. Furthermore, we harness a shared Capsule subspace, negating the need to project each lower-level Capsule to each higher-level Capsule, thereby significantly reducing memory requisites during training. Our approach demonstrates superior results compared to the current best non-iterative Capsule Network and tests on the Imagewoof dataset, which is too computationally demanding to handle efficiently by iterative approaches. Our findings underscore the potential of our proposed methodology in enhancing the operational efficiency and performance of Capsule Networks, paving the way for their application in increasingly complex computational scenarios.","sentences":["Capsule Networks have emerged as a powerful class of deep learning architectures, known for robust performance with relatively few parameters compared to Convolutional Neural Networks (CNNs).","However, their inherent efficiency is often overshadowed by their slow, iterative routing mechanisms which establish connections between Capsule layers, posing computational challenges resulting in an inability to scale.","In this paper, we introduce a novel, non-iterative routing mechanism, inspired by trainable prototype clustering.","This innovative approach aims to mitigate computational complexity, while retaining, if not enhancing, performance efficacy.","Furthermore, we harness a shared Capsule subspace, negating the need to project each lower-level Capsule to each higher-level Capsule, thereby significantly reducing memory requisites during training.","Our approach demonstrates superior results compared to the current best non-iterative Capsule Network and tests on the Imagewoof dataset, which is too computationally demanding to handle efficiently by iterative approaches.","Our findings underscore the potential of our proposed methodology in enhancing the operational efficiency and performance of Capsule Networks, paving the way for their application in increasingly complex computational scenarios."],"url":"http://arxiv.org/abs/2307.09944v1"}
{"created":"2023-07-19 12:35:16","title":"Impatient Bandits: Optimizing for the Long-Term Without Delay","abstract":"Recommender systems are a ubiquitous feature of online platforms. Increasingly, they are explicitly tasked with increasing users' long-term satisfaction. In this context, we study a content exploration task, which we formalize as a multi-armed bandit problem with delayed rewards. We observe that there is an apparent trade-off in choosing the learning signal: Waiting for the full reward to become available might take several weeks, hurting the rate at which learning happens, whereas measuring short-term proxy rewards reflects the actual long-term goal only imperfectly. We address this challenge in two steps. First, we develop a predictive model of delayed rewards that incorporates all information obtained to date. Full observations as well as partial (short or medium-term) outcomes are combined through a Bayesian filter to obtain a probabilistic belief. Second, we devise a bandit algorithm that takes advantage of this new predictive model. The algorithm quickly learns to identify content aligned with long-term success by carefully balancing exploration and exploitation. We apply our approach to a podcast recommendation problem, where we seek to identify shows that users engage with repeatedly over two months. We empirically validate that our approach results in substantially better performance compared to approaches that either optimize for short-term proxies, or wait for the long-term outcome to be fully realized.","sentences":["Recommender systems are a ubiquitous feature of online platforms.","Increasingly, they are explicitly tasked with increasing users' long-term satisfaction.","In this context, we study a content exploration task, which we formalize as a multi-armed bandit problem with delayed rewards.","We observe that there is an apparent trade-off in choosing the learning signal:","Waiting for the full reward to become available might take several weeks, hurting the rate at which learning happens, whereas measuring short-term proxy rewards reflects the actual long-term goal only imperfectly.","We address this challenge in two steps.","First, we develop a predictive model of delayed rewards that incorporates all information obtained to date.","Full observations as well as partial (short or medium-term) outcomes are combined through a Bayesian filter to obtain a probabilistic belief.","Second, we devise a bandit algorithm that takes advantage of this new predictive model.","The algorithm quickly learns to identify content aligned with long-term success by carefully balancing exploration and exploitation.","We apply our approach to a podcast recommendation problem, where we seek to identify shows that users engage with repeatedly over two months.","We empirically validate that our approach results in substantially better performance compared to approaches that either optimize for short-term proxies, or wait for the long-term outcome to be fully realized."],"url":"http://arxiv.org/abs/2307.09943v1"}
{"created":"2023-07-19 12:35:09","title":"TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network","abstract":"Clinical trials are critical for drug development but often suffer from expensive and inefficient patient recruitment. In recent years, machine learning models have been proposed for speeding up patient recruitment via automatically matching patients with clinical trials based on longitudinal patient electronic health records (EHR) data and eligibility criteria of clinical trials. However, they either depend on trial-specific expert rules that cannot expand to other trials or perform matching at a very general level with a black-box model where the lack of interpretability makes the model results difficult to be adopted.   To provide accurate and interpretable patient trial matching, we introduce a personalized dynamic tree-based memory network model named TREEMENT. It utilizes hierarchical clinical ontologies to expand the personalized patient representation learned from sequential EHR data, and then uses an attentional beam-search query learned from eligibility criteria embedding to offer a granular level of alignment for improved performance and interpretability. We evaluated TREEMENT against existing models on real-world datasets and demonstrated that TREEMENT outperforms the best baseline by 7% in terms of error reduction in criteria-level matching and achieves state-of-the-art results in its trial-level matching ability. Furthermore, we also show TREEMENT can offer good interpretability to make the model results easier for adoption.","sentences":["Clinical trials are critical for drug development but often suffer from expensive and inefficient patient recruitment.","In recent years, machine learning models have been proposed for speeding up patient recruitment via automatically matching patients with clinical trials based on longitudinal patient electronic health records (EHR) data and eligibility criteria of clinical trials.","However, they either depend on trial-specific expert rules that cannot expand to other trials or perform matching at a very general level with a black-box model where the lack of interpretability makes the model results difficult to be adopted.   ","To provide accurate and interpretable patient trial matching, we introduce a personalized dynamic tree-based memory network model named TREEMENT.","It utilizes hierarchical clinical ontologies to expand the personalized patient representation learned from sequential EHR data, and then uses an attentional beam-search query learned from eligibility criteria embedding to offer a granular level of alignment for improved performance and interpretability.","We evaluated TREEMENT against existing models on real-world datasets and demonstrated that TREEMENT outperforms the best baseline by 7% in terms of error reduction in criteria-level matching and achieves state-of-the-art results in its trial-level matching ability.","Furthermore, we also show TREEMENT can offer good interpretability to make the model results easier for adoption."],"url":"http://arxiv.org/abs/2307.09942v1"}
{"created":"2023-07-19 12:21:39","title":"AGAR: Attention Graph-RNN for Adaptative Motion Prediction of Point Clouds of Deformable Objects","abstract":"This paper focuses on motion prediction for point cloud sequences in the challenging case of deformable 3D objects, such as human body motion. First, we investigate the challenges caused by deformable shapes and complex motions present in this type of representation, with the ultimate goal of understanding the technical limitations of state-of-the-art models. From this understanding, we propose an improved architecture for point cloud prediction of deformable 3D objects. Specifically, to handle deformable shapes, we propose a graph-based approach that learns and exploits the spatial structure of point clouds to extract more representative features. Then we propose a module able to combine the learned features in an adaptative manner according to the point cloud movements. The proposed adaptative module controls the composition of local and global motions for each point, enabling the network to model complex motions in deformable 3D objects more effectively. We tested the proposed method on the following datasets: MNIST moving digits, the Mixamo human bodies motions, JPEG and CWIPC-SXR real-world dynamic bodies. Simulation results demonstrate that our method outperforms the current baseline methods given its improved ability to model complex movements as well as preserve point cloud shape. Furthermore, we demonstrate the generalizability of the proposed framework for dynamic feature learning, by testing the framework for action recognition on the MSRAction3D dataset and achieving results on-par with state-of-the-art methods","sentences":["This paper focuses on motion prediction for point cloud sequences in the challenging case of deformable 3D objects, such as human body motion.","First, we investigate the challenges caused by deformable shapes and complex motions present in this type of representation, with the ultimate goal of understanding the technical limitations of state-of-the-art models.","From this understanding, we propose an improved architecture for point cloud prediction of deformable 3D objects.","Specifically, to handle deformable shapes, we propose a graph-based approach that learns and exploits the spatial structure of point clouds to extract more representative features.","Then we propose a module able to combine the learned features in an adaptative manner according to the point cloud movements.","The proposed adaptative module controls the composition of local and global motions for each point, enabling the network to model complex motions in deformable 3D objects more effectively.","We tested the proposed method on the following datasets: MNIST moving digits, the Mixamo human bodies motions, JPEG and CWIPC-SXR real-world dynamic bodies.","Simulation results demonstrate that our method outperforms the current baseline methods given its improved ability to model complex movements as well as preserve point cloud shape.","Furthermore, we demonstrate the generalizability of the proposed framework for dynamic feature learning, by testing the framework for action recognition on the MSRAction3D dataset and achieving results on-par with state-of-the-art methods"],"url":"http://arxiv.org/abs/2307.09936v1"}
{"created":"2023-07-19 12:15:06","title":"Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features","abstract":"To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the \"spurious\" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain. Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain. Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels. Empirically, we demonstrate the effectiveness of SFB on real and synthetic data.","sentences":["To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the \"spurious\" or unstable features whose relationship with the label changes across domains.","However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain.","Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels.","In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label.","Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain.","Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels.","Empirically, we demonstrate the effectiveness of SFB on real and synthetic data."],"url":"http://arxiv.org/abs/2307.09933v1"}
{"created":"2023-07-19 12:12:17","title":"DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration","abstract":"Multimodal image registration is a challenging but essential step for numerous image-guided procedures. Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities. Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings. We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration. We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data. Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one. Experiments on three different datasets demonstrate that our approach generalizes well beyond the training data, yielding a broad capture range even on unseen anatomies and modality pairs, without the need for specialized retraining. We make our training code and data publicly available.","sentences":["Multimodal image registration is a challenging but essential step for numerous image-guided procedures.","Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities.","Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings.","We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration.","We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data.","Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one.","Experiments on three different datasets demonstrate that our approach generalizes well beyond the training data, yielding a broad capture range even on unseen anatomies and modality pairs, without the need for specialized retraining.","We make our training code and data publicly available."],"url":"http://arxiv.org/abs/2307.09931v1"}
{"created":"2023-07-19 12:11:15","title":"Measuring and Modeling Uncertainty Degree for Monocular Depth Estimation","abstract":"Effectively measuring and modeling the reliability of a trained model is essential to the real-world deployment of monocular depth estimation (MDE) models. However, the intrinsic ill-posedness and ordinal-sensitive nature of MDE pose major challenges to the estimation of uncertainty degree of the trained models. On the one hand, utilizing current uncertainty modeling methods may increase memory consumption and are usually time-consuming. On the other hand, measuring the uncertainty based on model accuracy can also be problematic, where uncertainty reliability and prediction accuracy are not well decoupled. In this paper, we propose to model the uncertainty of MDE models from the perspective of the inherent probability distributions originating from the depth probability volume and its extensions, and to assess it more fairly with more comprehensive metrics. By simply introducing additional training regularization terms, our model, with surprisingly simple formations and without requiring extra modules or multiple inferences, can provide uncertainty estimations with state-of-the-art reliability, and can be further improved when combined with ensemble or sampling methods. A series of experiments demonstrate the effectiveness of our methods.","sentences":["Effectively measuring and modeling the reliability of a trained model is essential to the real-world deployment of monocular depth estimation (MDE) models.","However, the intrinsic ill-posedness and ordinal-sensitive nature of MDE pose major challenges to the estimation of uncertainty degree of the trained models.","On the one hand, utilizing current uncertainty modeling methods may increase memory consumption and are usually time-consuming.","On the other hand, measuring the uncertainty based on model accuracy can also be problematic, where uncertainty reliability and prediction accuracy are not well decoupled.","In this paper, we propose to model the uncertainty of MDE models from the perspective of the inherent probability distributions originating from the depth probability volume and its extensions, and to assess it more fairly with more comprehensive metrics.","By simply introducing additional training regularization terms, our model, with surprisingly simple formations and without requiring extra modules or multiple inferences, can provide uncertainty estimations with state-of-the-art reliability, and can be further improved when combined with ensemble or sampling methods.","A series of experiments demonstrate the effectiveness of our methods."],"url":"http://arxiv.org/abs/2307.09929v1"}
{"created":"2023-07-19 11:54:46","title":"Large Language Models can accomplish Business Process Management Tasks","abstract":"Business Process Management (BPM) aims to improve organizational activities and their outcomes by managing the underlying processes. To achieve this, it is often necessary to consider information from various sources, including unstructured textual documents. Therefore, researchers have developed several BPM-specific solutions that extract information from textual documents using Natural Language Processing techniques. These solutions are specific to their respective tasks and cannot accomplish multiple process-related problems as a general-purpose instrument. However, in light of the recent emergence of Large Language Models (LLMs) with remarkable reasoning capabilities, such a general-purpose instrument with multiple applications now appears attainable. In this paper, we illustrate how LLMs can accomplish text-related BPM tasks by applying a specific LLM to three exemplary tasks: mining imperative process models from textual descriptions, mining declarative process models from textual descriptions, and assessing the suitability of process tasks from textual descriptions for robotic process automation. We show that, without extensive configuration or prompt engineering, LLMs perform comparably to or better than existing solutions and discuss implications for future BPM research as well as practical usage.","sentences":["Business Process Management (BPM) aims to improve organizational activities and their outcomes by managing the underlying processes.","To achieve this, it is often necessary to consider information from various sources, including unstructured textual documents.","Therefore, researchers have developed several BPM-specific solutions that extract information from textual documents using Natural Language Processing techniques.","These solutions are specific to their respective tasks and cannot accomplish multiple process-related problems as a general-purpose instrument.","However, in light of the recent emergence of Large Language Models (LLMs) with remarkable reasoning capabilities, such a general-purpose instrument with multiple applications now appears attainable.","In this paper, we illustrate how LLMs can accomplish text-related BPM tasks by applying a specific LLM to three exemplary tasks: mining imperative process models from textual descriptions, mining declarative process models from textual descriptions, and assessing the suitability of process tasks from textual descriptions for robotic process automation.","We show that, without extensive configuration or prompt engineering, LLMs perform comparably to or better than existing solutions and discuss implications for future BPM research as well as practical usage."],"url":"http://arxiv.org/abs/2307.09923v1"}
{"created":"2023-07-19 11:44:46","title":"Analyzing IoT Hosts in the IPv6 Internet","abstract":"Users and businesses are increasingly deploying Internet of Things (IoT) devices at home, at work, and in factories. At the same time, we see an increase in the use of IPv6 for Internet connectivity. Even though the IoT ecosystem has been the focus of recent studies, there is no comprehensive analysis of IoT end-hosts in the IPv6 Internet to date. In this paper we perform an in-depth analysis of IPv6-reachable IoT hosts using active measurements. We run measurements targeting 530M IPv6 addresses on six popular IoT-related protocols. With 36.4K hosts in 156 countries we find 380x fewer IoT-speaking end-hosts compared to IPv4. Moreover, we conduct a security analysis for TLS-enabled IoT-speaking hosts identifying up to 57% untrusted certificates, with up to 32% being self-signed and 25% being expired. Finally, we plan to publish our measurement results, tools, and a website dashboard to foster further research in the area.","sentences":["Users and businesses are increasingly deploying Internet of Things (IoT) devices at home, at work, and in factories.","At the same time, we see an increase in the use of IPv6 for Internet connectivity.","Even though the IoT ecosystem has been the focus of recent studies, there is no comprehensive analysis of IoT end-hosts in the IPv6 Internet to date.","In this paper we perform an in-depth analysis of IPv6-reachable IoT hosts using active measurements.","We run measurements targeting 530M IPv6 addresses on six popular IoT-related protocols.","With 36.4K hosts in 156 countries we find 380x fewer IoT-speaking end-hosts compared to IPv4.","Moreover, we conduct a security analysis for TLS-enabled IoT-speaking hosts identifying up to 57% untrusted certificates, with up to 32% being self-signed and 25% being expired.","Finally, we plan to publish our measurement results, tools, and a website dashboard to foster further research in the area."],"url":"http://arxiv.org/abs/2307.09918v1"}
{"created":"2023-07-19 11:40:15","title":"TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations","abstract":"Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely TimeTuner, designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual explanations to connect the relationships among time-series representations, multivariate features and model predictions. Next, we design multiple coordinated views including a partition-based correlation matrix and juxtaposed bivariate stripes, and provide a set of interactions that allow users to step into the transformation selection process, navigate through the feature space, and reason the model performance. We instantiate TimeTuner with two transformation methods of smoothing and sampling, and demonstrate its applicability on real-world time-series forecasting of univariate sunspots and multivariate air pollutants. Feedback from domain experts indicates that our system can help characterize time-series representations and guide the feature engineering processes.","sentences":["Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models.","Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning.","However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable.","To improve on these limitations, this paper contributes a novel visual analytics framework, namely TimeTuner, designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations.","The system mainly consists of the following two-stage technique: We first leverage counterfactual explanations to connect the relationships among time-series representations, multivariate features and model predictions.","Next, we design multiple coordinated views including a partition-based correlation matrix and juxtaposed bivariate stripes, and provide a set of interactions that allow users to step into the transformation selection process, navigate through the feature space, and reason the model performance.","We instantiate TimeTuner with two transformation methods of smoothing and sampling, and demonstrate its applicability on real-world time-series forecasting of univariate sunspots and multivariate air pollutants.","Feedback from domain experts indicates that our system can help characterize time-series representations and guide the feature engineering processes."],"url":"http://arxiv.org/abs/2307.09916v1"}
{"created":"2023-07-19 11:35:21","title":"Embedded Heterogeneous Attention Transformer for Cross-lingual Image Captioning","abstract":"Cross-lingual image captioning is confronted with both cross-lingual and cross-modal challenges for multimedia analysis. The crucial issue in this task is to model the global and local matching between the image and different languages. Existing cross-modal embedding methods based on Transformer architecture oversight the local matching between the image region and monolingual words, not to mention in the face of a variety of differentiated languages. Due to the heterogeneous property of the cross-modal and cross-lingual task, we utilize the heterogeneous network to establish cross-domain relationships and the local correspondences between the image and different languages. In this paper, we propose an Embedded Heterogeneous Attention Transformer (EHAT) to build reasoning paths bridging cross-domain for cross-lingual image captioning and integrate into transformer. The proposed EHAT consists of a Masked Heterogeneous Cross-attention (MHCA), Heterogeneous Attention Reasoning Network (HARN) and Heterogeneous Co-attention (HCA). HARN as the core network, models and infers cross-domain relationship anchored by vision bounding box representation features to connect two languages word features and learn the heterogeneous maps. MHCA and HCA implement cross-domain integration in the encoder through the special heterogeneous attention and enable single model to generate two language captioning. We test on MSCOCO dataset to generate English and Chinese, which are most widely used and have obvious difference between their language families. Our experiments show that our method even achieve better than advanced monolingual methods.","sentences":["Cross-lingual image captioning is confronted with both cross-lingual and cross-modal challenges for multimedia analysis.","The crucial issue in this task is to model the global and local matching between the image and different languages.","Existing cross-modal embedding methods based on Transformer architecture oversight the local matching between the image region and monolingual words, not to mention in the face of a variety of differentiated languages.","Due to the heterogeneous property of the cross-modal and cross-lingual task, we utilize the heterogeneous network to establish cross-domain relationships and the local correspondences between the image and different languages.","In this paper, we propose an Embedded Heterogeneous Attention Transformer (EHAT) to build reasoning paths bridging cross-domain for cross-lingual image captioning and integrate into transformer.","The proposed EHAT consists of a Masked Heterogeneous Cross-attention (MHCA), Heterogeneous Attention Reasoning Network (HARN) and Heterogeneous Co-attention (HCA).","HARN as the core network, models and infers cross-domain relationship anchored by vision bounding box representation features to connect two languages word features and learn the heterogeneous maps.","MHCA and HCA implement cross-domain integration in the encoder through the special heterogeneous attention and enable single model to generate two language captioning.","We test on MSCOCO dataset to generate English and Chinese, which are most widely used and have obvious difference between their language families.","Our experiments show that our method even achieve better than advanced monolingual methods."],"url":"http://arxiv.org/abs/2307.09915v1"}
{"created":"2023-07-19 11:32:49","title":"Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features","abstract":"We investigate the impact of non-regular path expressions on the decidability of satisfiability checking and querying in description logics extending ALC. Our primary objects of interest are ALCreg and ALCvpl, the extensions of with path expressions employing, respectively, regular and visibly-pushdown languages. The first one, ALCreg, is a notational variant of the well-known Propositional Dynamic Logic of Fischer and Ladner. The second one, ALCvpl, was introduced and investigated by Loding and Serre in 2007. The logic ALCvpl generalises many known decidable non-regular extensions of ALCreg.   We provide a series of undecidability results. First, we show that decidability of the concept satisfiability problem for ALCvpl is lost upon adding the seemingly innocent Self operator. Second, we establish undecidability for the concept satisfiability problem for ALCvpl extended with nominals. Interestingly, our undecidability proof relies only on one single non-regular (visibly-pushdown) language, namely on r#s# := { r^n s^n | n in N } for fixed role names r and s. Finally, in contrast to the classical database setting, we establish undecidability of query entailment for queries involving non-regular atoms from r#s#, already in the case of ALC-TBoxes.","sentences":["We investigate the impact of non-regular path expressions on the decidability of satisfiability checking and querying in description logics extending ALC.","Our primary objects of interest are ALCreg and ALCvpl, the extensions of with path expressions employing, respectively, regular and visibly-pushdown languages.","The first one, ALCreg, is a notational variant of the well-known Propositional Dynamic Logic of Fischer and Ladner.","The second one, ALCvpl, was introduced and investigated by Loding and Serre in 2007.","The logic ALCvpl generalises many known decidable non-regular extensions of ALCreg.   ","We provide a series of undecidability results.","First, we show that decidability of the concept satisfiability problem for ALCvpl is lost upon adding the seemingly innocent Self operator.","Second, we establish undecidability for the concept satisfiability problem for ALCvpl extended with nominals.","Interestingly, our undecidability proof relies only on one single non-regular (visibly-pushdown) language, namely on r#s# := { r^n s^n | n in N } for fixed role names r and s. Finally, in contrast to the classical database setting, we establish undecidability of query entailment for queries involving non-regular atoms from r#s#, already in the case of ALC-TBoxes."],"url":"http://arxiv.org/abs/2307.09913v1"}
{"created":"2023-07-19 11:32:24","title":"Deep projection networks for learning time-homogeneous dynamical systems","abstract":"We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data. This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables. The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA). However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios. Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation. We apply our method to challenging discrete dynamical systems, discussing improvements over previous methods, as well as to continuous dynamical systems.","sentences":["We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data.","This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables.","The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA).","However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios.","Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation.","We apply our method to challenging discrete dynamical systems, discussing improvements over previous methods, as well as to continuous dynamical systems."],"url":"http://arxiv.org/abs/2307.09912v1"}
{"created":"2023-07-19 11:25:12","title":"Chit-Chat or Deep Talk: Prompt Engineering for Process Mining","abstract":"This research investigates the application of Large Language Models (LLMs) to augment conversational agents in process mining, aiming to tackle its inherent complexity and diverse skill requirements. While LLM advancements present novel opportunities for conversational process mining, generating efficient outputs is still a hurdle. We propose an innovative approach that amend many issues in existing solutions, informed by prior research on Natural Language Processing (NLP) for conversational agents. Leveraging LLMs, our framework improves both accessibility and agent performance, as demonstrated by experiments on public question and data sets. Our research sets the stage for future explorations into LLMs' role in process mining and concludes with propositions for enhancing LLM memory, implementing real-time user testing, and examining diverse data sets.","sentences":["This research investigates the application of Large Language Models (LLMs) to augment conversational agents in process mining, aiming to tackle its inherent complexity and diverse skill requirements.","While LLM advancements present novel opportunities for conversational process mining, generating efficient outputs is still a hurdle.","We propose an innovative approach that amend many issues in existing solutions, informed by prior research on Natural Language Processing (NLP) for conversational agents.","Leveraging LLMs, our framework improves both accessibility and agent performance, as demonstrated by experiments on public question and data sets.","Our research sets the stage for future explorations into LLMs' role in process mining and concludes with propositions for enhancing LLM memory, implementing real-time user testing, and examining diverse data sets."],"url":"http://arxiv.org/abs/2307.09909v1"}
{"created":"2023-07-19 11:10:26","title":"Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation","abstract":"Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features for the generation. Furthermore, we propose an effective query mechanism based on implicit identity representations learned from the discrete keypoints of the source image. It can greatly facilitate the retrieval of more correlated information from the memory bank for the compensation. Extensive experiments demonstrate that MCNet can learn representative and complementary facial memory, and can clearly outperform previous state-of-the-art talking head generation methods on VoxCeleb1 and CelebV datasets. Please check our \\href{https://github.com/harlanhong/ICCV2023-MCNET}{Project}.","sentences":["Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image.","However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality.","To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features for the generation.","Furthermore, we propose an effective query mechanism based on implicit identity representations learned from the discrete keypoints of the source image.","It can greatly facilitate the retrieval of more correlated information from the memory bank for the compensation.","Extensive experiments demonstrate that MCNet can learn representative and complementary facial memory, and can clearly outperform previous state-of-the-art talking head generation methods on VoxCeleb1 and CelebV datasets.","Please check our \\href{https://github.com/harlanhong/ICCV2023-MCNET}{Project}."],"url":"http://arxiv.org/abs/2307.09906v1"}
{"created":"2023-07-19 11:08:59","title":"PyTAG: Challenges and Opportunities for Reinforcement Learning in Tabletop Games","abstract":"In recent years, Game AI research has made important breakthroughs using Reinforcement Learning (RL). Despite this, RL for modern tabletop games has gained little to no attention, even when they offer a range of unique challenges compared to video games. To bridge this gap, we introduce PyTAG, a Python API for interacting with the Tabletop Games framework (TAG). TAG contains a growing set of more than 20 modern tabletop games, with a common API for AI agents. We present techniques for training RL agents in these games and introduce baseline results after training Proximal Policy Optimisation algorithms on a subset of games. Finally, we discuss the unique challenges complex modern tabletop games provide, now open to RL research through PyTAG.","sentences":["In recent years, Game AI research has made important breakthroughs using Reinforcement Learning (RL).","Despite this, RL for modern tabletop games has gained little to no attention, even when they offer a range of unique challenges compared to video games.","To bridge this gap, we introduce PyTAG, a Python API for interacting with the Tabletop Games framework (TAG).","TAG contains a growing set of more than 20 modern tabletop games, with a common API for AI agents.","We present techniques for training RL agents in these games and introduce baseline results after training Proximal Policy Optimisation algorithms on a subset of games.","Finally, we discuss the unique challenges complex modern tabletop games provide, now open to RL research through PyTAG."],"url":"http://arxiv.org/abs/2307.09905v1"}
{"created":"2023-07-19 10:50:36","title":"Repeated Observations for Classification","abstract":"We study the problem nonparametric classification with repeated observations. Let $\\bX$ be the $d$ dimensional feature vector and let $Y$ denote the label taking values in $\\{1,\\dots ,M\\}$. In contrast to usual setup with large sample size $n$ and relatively low dimension $d$, this paper deals with the situation, when instead of observing a single feature vector $\\bX$ we are given $t$ repeated feature vectors $\\bV_1,\\dots ,\\bV_t $. Some simple classification rules are presented such that the conditional error probabilities have exponential convergence rate of convergence as $t\\to\\infty$. In the analysis, we investigate particular models like robust detection by nominal densities, prototype classification, linear transformation, linear classification, scaling.","sentences":["We study the problem nonparametric classification with repeated observations.","Let $\\bX$ be the $d$ dimensional feature vector and let $Y$ denote the label taking values in $\\{1,\\dots ,M\\}$.","In contrast to usual setup with large sample size $n$ and relatively low dimension $d$, this paper deals with the situation, when instead of observing a single feature vector $\\bX$ we are given $t$ repeated feature vectors $\\bV_1,\\dots ,\\bV_t $.","Some simple classification rules are presented such that the conditional error probabilities have exponential convergence rate of convergence as $t\\to\\infty$. In the analysis, we investigate particular models like robust detection by nominal densities, prototype classification, linear transformation, linear classification, scaling."],"url":"http://arxiv.org/abs/2307.09896v1"}
{"created":"2023-07-19 10:45:49","title":"Learning from Abstract Images: on the Importance of Occlusion in a Minimalist Encoding of Human Poses","abstract":"Existing 2D-to-3D pose lifting networks suffer from poor performance in cross-dataset benchmarks. Although the use of 2D keypoints joined by \"stick-figure\" limbs has shown promise as an intermediate step, stick-figures do not account for occlusion information that is often inherent in an image. In this paper, we propose a novel representation using opaque 3D limbs that preserves occlusion information while implicitly encoding joint locations. Crucially, when training on data with accurate three-dimensional keypoints and without part-maps, this representation allows training on abstract synthetic images, with occlusion, from as many synthetic viewpoints as desired. The result is a pose defined by limb angles rather than joint positions $\\unicode{x2013}$ because poses are, in the real world, independent of cameras $\\unicode{x2013}$ allowing us to predict poses that are completely independent of camera viewpoint. The result provides not only an improvement in same-dataset benchmarks, but a \"quantum leap\" in cross-dataset benchmarks.","sentences":["Existing 2D-to-3D pose lifting networks suffer from poor performance in cross-dataset benchmarks.","Although the use of 2D keypoints joined by \"stick-figure\" limbs has shown promise as an intermediate step, stick-figures do not account for occlusion information that is often inherent in an image.","In this paper, we propose a novel representation using opaque 3D limbs that preserves occlusion information while implicitly encoding joint locations.","Crucially, when training on data with accurate three-dimensional keypoints and without part-maps, this representation allows training on abstract synthetic images, with occlusion, from as many synthetic viewpoints as desired.","The result is a pose defined by limb angles rather than joint positions $\\unicode{x2013}$ because poses are, in the real world, independent of cameras $\\unicode{x2013}$ allowing us to predict poses that are completely independent of camera viewpoint.","The result provides not only an improvement in same-dataset benchmarks, but a \"quantum leap\" in cross-dataset benchmarks."],"url":"http://arxiv.org/abs/2307.09893v1"}
{"created":"2023-07-19 10:44:44","title":"3Deformer: A Common Framework for Image-Guided Mesh Deformation","abstract":"We propose 3Deformer, a general-purpose framework for interactive 3D shape editing. Given a source 3D mesh with semantic materials, and a user-specified semantic image, 3Deformer can accurately edit the source mesh following the shape guidance of the semantic image, while preserving the source topology as rigid as possible. Recent studies of 3D shape editing mostly focus on learning neural networks to predict 3D shapes, which requires high-cost 3D training datasets and is limited to handling objects involved in the datasets. Unlike these studies, our 3Deformer is a non-training and common framework, which only requires supervision of readily-available semantic images, and is compatible with editing various objects unlimited by datasets. In 3Deformer, the source mesh is deformed utilizing the differentiable renderer technique, according to the correspondences between semantic images and mesh materials. However, guiding complex 3D shapes with a simple 2D image incurs extra challenges, that is, the deform accuracy, surface smoothness, geometric rigidity, and global synchronization of the edited mesh should be guaranteed. To address these challenges, we propose a hierarchical optimization architecture to balance the global and local shape features, and propose further various strategies and losses to improve properties of accuracy, smoothness, rigidity, and so on. Extensive experiments show that our 3Deformer is able to produce impressive results and reaches the state-of-the-art level.","sentences":["We propose 3Deformer, a general-purpose framework for interactive 3D shape editing.","Given a source 3D mesh with semantic materials, and a user-specified semantic image, 3Deformer can accurately edit the source mesh following the shape guidance of the semantic image, while preserving the source topology as rigid as possible.","Recent studies of 3D shape editing mostly focus on learning neural networks to predict 3D shapes, which requires high-cost 3D training datasets and is limited to handling objects involved in the datasets.","Unlike these studies, our 3Deformer is a non-training and common framework, which only requires supervision of readily-available semantic images, and is compatible with editing various objects unlimited by datasets.","In 3Deformer, the source mesh is deformed utilizing the differentiable renderer technique, according to the correspondences between semantic images and mesh materials.","However, guiding complex 3D shapes with a simple 2D image incurs extra challenges, that is, the deform accuracy, surface smoothness, geometric rigidity, and global synchronization of the edited mesh should be guaranteed.","To address these challenges, we propose a hierarchical optimization architecture to balance the global and local shape features, and propose further various strategies and losses to improve properties of accuracy, smoothness, rigidity, and so on.","Extensive experiments show that our 3Deformer is able to produce impressive results and reaches the state-of-the-art level."],"url":"http://arxiv.org/abs/2307.09892v1"}
{"created":"2023-07-19 10:42:56","title":"Amortised Design Optimization for Item Response Theory","abstract":"Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology. In education, IRT is used to infer student abilities and characteristics of test items from student responses. Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities. Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications. In response, we propose incorporating amortised experimental design into IRT. Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data. The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes. During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close to real-time, by taking into account the history of experiments and outcomes.","sentences":["Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology.","In education, IRT is used to infer student abilities and characteristics of test items from student responses.","Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities.","Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications.","In response, we propose incorporating amortised experimental design into IRT.","Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data.","The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes.","During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close to real-time, by taking into account the history of experiments and outcomes."],"url":"http://arxiv.org/abs/2307.09891v1"}
{"created":"2023-07-19 10:32:46","title":"A Shared Control Approach Based on First-Order Dynamical Systems and Closed-Loop Variable Stiffness Control","abstract":"In this paper, we present a novel learning-based shared control framework. This framework deploys first-order Dynamical Systems (DS) as motion generators providing the desired reference motion, and a Variable Stiffness Dynamical Systems (VSDS) \\cite{chen2021closed} for haptic guidance. We show how to shape several features of our controller in order to achieve authority allocation, local motion refinement, in addition to the inherent ability of the controller to automatically synchronize with the human state during joint task execution. We validate our approach in a teleoperated task scenario, where we also showcase the ability of our framework to deal with situations that require updating task knowledge due to possible changes in the task scenario, or changes in the environment. Finally, we conduct a user study to compare the performance of our VSDS controller for guidance generation to two state-of-the-art controllers in a target reaching task. The result shows that our VSDS controller has the highest successful rate of task execution among all conditions. Besides, our VSDS controller helps reduce the execution time and task load significantly, and was selected as the most favorable controller by participants.","sentences":["In this paper, we present a novel learning-based shared control framework.","This framework deploys first-order Dynamical Systems (DS) as motion generators providing the desired reference motion, and a Variable Stiffness Dynamical Systems (VSDS) \\cite{chen2021closed} for haptic guidance.","We show how to shape several features of our controller in order to achieve authority allocation, local motion refinement, in addition to the inherent ability of the controller to automatically synchronize with the human state during joint task execution.","We validate our approach in a teleoperated task scenario, where we also showcase the ability of our framework to deal with situations that require updating task knowledge due to possible changes in the task scenario, or changes in the environment.","Finally, we conduct a user study to compare the performance of our VSDS controller for guidance generation to two state-of-the-art controllers in a target reaching task.","The result shows that our VSDS controller has the highest successful rate of task execution among all conditions.","Besides, our VSDS controller helps reduce the execution time and task load significantly, and was selected as the most favorable controller by participants."],"url":"http://arxiv.org/abs/2307.09887v1"}
{"created":"2023-07-19 10:31:35","title":"A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading","abstract":"Recent advances in machine learning models have greatly increased the performance of automated methods in medical image analysis. However, the internal functioning of such models is largely hidden, which hinders their integration in clinical practice. Explainability and trust are viewed as important aspects of modern methods, for the latter's widespread use in clinical communities. As such, validation of machine learning models represents an important aspect and yet, most methods are only validated in a limited way. In this work, we focus on providing a richer and more appropriate validation approach for highly powerful Visual Question Answering (VQA) algorithms. To better understand the performance of these methods, which answer arbitrary questions related to images, this work focuses on an automatic visual Turing test (VTT). That is, we propose an automatic adaptive questioning method, that aims to expose the reasoning behavior of a VQA algorithm. Specifically, we introduce a reinforcement learning (RL) agent that observes the history of previously asked questions, and uses it to select the next question to pose. We demonstrate our approach in the context of evaluating algorithms that automatically answer questions related to diabetic macular edema (DME) grading. The experiments show that such an agent has similar behavior to a clinician, whereby asking questions that are relevant to key clinical concepts.","sentences":["Recent advances in machine learning models have greatly increased the performance of automated methods in medical image analysis.","However, the internal functioning of such models is largely hidden, which hinders their integration in clinical practice.","Explainability and trust are viewed as important aspects of modern methods, for the latter's widespread use in clinical communities.","As such, validation of machine learning models represents an important aspect and yet, most methods are only validated in a limited way.","In this work, we focus on providing a richer and more appropriate validation approach for highly powerful Visual Question Answering (VQA) algorithms.","To better understand the performance of these methods, which answer arbitrary questions related to images, this work focuses on an automatic visual Turing test (VTT).","That is, we propose an automatic adaptive questioning method, that aims to expose the reasoning behavior of a VQA algorithm.","Specifically, we introduce a reinforcement learning (RL) agent that observes the history of previously asked questions, and uses it to select the next question to pose.","We demonstrate our approach in the context of evaluating algorithms that automatically answer questions related to diabetic macular edema (DME) grading.","The experiments show that such an agent has similar behavior to a clinician, whereby asking questions that are relevant to key clinical concepts."],"url":"http://arxiv.org/abs/2307.09886v1"}
{"created":"2023-07-19 10:28:59","title":"Test-takers have a say: understanding the implications of the use of AI in language tests","abstract":"Language tests measure a person's ability to use a language in terms of listening, speaking, reading, or writing. Such tests play an integral role in academic, professional, and immigration domains, with entities such as educational institutions, professional accreditation bodies, and governments using them to assess candidate language proficiency. Recent advances in Artificial Intelligence (AI) and the discipline of Natural Language Processing have prompted language test providers to explore AI's potential applicability within language testing, leading to transformative activity patterns surrounding language instruction and learning. However, with concerns over AI's trustworthiness, it is imperative to understand the implications of integrating AI into language testing. This knowledge will enable stakeholders to make well-informed decisions, thus safeguarding community well-being and testing integrity. To understand the concerns and effects of AI usage in language tests, we conducted interviews and surveys with English test-takers. To the best of our knowledge, this is the first empirical study aimed at identifying the implications of AI adoption in language tests from a test-taker perspective. Our study reveals test-taker perceptions and behavioral patterns. Specifically, we identify that AI integration may enhance perceptions of fairness, consistency, and availability. Conversely, it might incite mistrust regarding reliability and interactivity aspects, subsequently influencing the behaviors and well-being of test-takers. These insights provide a better understanding of potential societal implications and assist stakeholders in making informed decisions concerning AI usage in language testing.","sentences":["Language tests measure a person's ability to use a language in terms of listening, speaking, reading, or writing.","Such tests play an integral role in academic, professional, and immigration domains, with entities such as educational institutions, professional accreditation bodies, and governments using them to assess candidate language proficiency.","Recent advances in Artificial Intelligence (AI) and the discipline of Natural Language Processing have prompted language test providers to explore AI's potential applicability within language testing, leading to transformative activity patterns surrounding language instruction and learning.","However, with concerns over AI's trustworthiness, it is imperative to understand the implications of integrating AI into language testing.","This knowledge will enable stakeholders to make well-informed decisions, thus safeguarding community well-being and testing integrity.","To understand the concerns and effects of AI usage in language tests, we conducted interviews and surveys with English test-takers.","To the best of our knowledge, this is the first empirical study aimed at identifying the implications of AI adoption in language tests from a test-taker perspective.","Our study reveals test-taker perceptions and behavioral patterns.","Specifically, we identify that AI integration may enhance perceptions of fairness, consistency, and availability.","Conversely, it might incite mistrust regarding reliability and interactivity aspects, subsequently influencing the behaviors and well-being of test-takers.","These insights provide a better understanding of potential societal implications and assist stakeholders in making informed decisions concerning AI usage in language testing."],"url":"http://arxiv.org/abs/2307.09885v1"}
{"created":"2023-07-19 10:27:34","title":"Symmetric Equilibrium Learning of VAEs","abstract":"We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa. The standard learning approach for VAEs, i.e. maximisation of the evidence lower bound (ELBO), has an obvious asymmetry in that respect. Moreover, it requires a closed form a-priori latent distribution. This limits the applicability of VAEs in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors. We propose a Nash equilibrium learning approach that relaxes these restrictions and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling. The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks. We show experimentally that the models learned by this method are comparable to those obtained by ELBO learning and demonstrate its applicability for tasks that are not accessible by standard VAE learning.","sentences":["We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa.","The standard learning approach for VAEs, i.e. maximisation of the evidence lower bound (ELBO), has an obvious asymmetry in that respect.","Moreover, it requires a closed form a-priori latent distribution.","This limits the applicability of VAEs in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors.","We propose a Nash equilibrium learning approach that relaxes these restrictions and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling.","The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks.","We show experimentally that the models learned by this method are comparable to those obtained by ELBO learning and demonstrate its applicability for tasks that are not accessible by standard VAE learning."],"url":"http://arxiv.org/abs/2307.09883v1"}
{"created":"2023-07-19 10:26:29","title":"Adversarial Likelihood Estimation with One-way Flows","abstract":"Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples. However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy). We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; 2) when optimizing for likelihood, one must maximize generator entropy. This is hypothesized to provide a better mode coverage. Different from previous works, we explicitly compute the density of the generated samples. This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term. The generator density is obtained via a new type of flow network, called one-way flow network, that is less constrained in terms of architecture, as it does not require to have a tractable inverse function. Our experimental results show that we converge faster, produce comparable sample quality to GANs with similar architecture, successfully avoid over-fitting to commonly used datasets and produce smooth low-dimensional latent representations of the training data.","sentences":["Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples.","However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy).","We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; 2) when optimizing for likelihood, one must maximize generator entropy.","This is hypothesized to provide a better mode coverage.","Different from previous works, we explicitly compute the density of the generated samples.","This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term.","The generator density is obtained via a new type of flow network, called one-way flow network, that is less constrained in terms of architecture, as it does not require to have a tractable inverse function.","Our experimental results show that we converge faster, produce comparable sample quality to GANs with similar architecture, successfully avoid over-fitting to commonly used datasets and produce smooth low-dimensional latent representations of the training data."],"url":"http://arxiv.org/abs/2307.09882v1"}
{"created":"2023-07-19 10:23:28","title":"A3D: Adaptive, Accurate, and Autonomous Navigation for Edge-Assisted Drones","abstract":"Accurate navigation is of paramount importance to ensure flight safety and efficiency for autonomous drones. Recent research starts to use Deep Neural Networks to enhance drone navigation given their remarkable predictive capability for visual perception. However, existing solutions either run DNN inference tasks on drones in situ, impeded by the limited onboard resource, or offload the computation to external servers which may incur large network latency. Few works consider jointly optimizing the offloading decisions along with image transmission configurations and adapting them on the fly. In this paper, we propose A3D, an edge server assisted drone navigation framework that can dynamically adjust task execution location, input resolution, and image compression ratio in order to achieve low inference latency, high prediction accuracy, and long flight distances. Specifically, we first augment state-of-the-art convolutional neural networks for drone navigation and define a novel metric called Quality of Navigation as our optimization objective which can effectively capture the above goals. We then design a deep reinforcement learning based neural scheduler at the drone side for which an information encoder is devised to reshape the state features and thus improve its learning ability. To further support simultaneous multi-drone serving, we extend the edge server design by developing a network-aware resource allocation algorithm, which allows provisioning containerized resources aligned with drones' demand. We finally implement a proof-of-concept prototype with realistic devices and validate its performance in a real-world campus scene, as well as a simulation environment for thorough evaluation upon AirSim. Extensive experimental results show that A3D can reduce end-to-end latency by 28.06% and extend the flight distance by up to 27.28% compared with non-adaptive solutions.","sentences":["Accurate navigation is of paramount importance to ensure flight safety and efficiency for autonomous drones.","Recent research starts to use Deep Neural Networks to enhance drone navigation given their remarkable predictive capability for visual perception.","However, existing solutions either run DNN inference tasks on drones in situ, impeded by the limited onboard resource, or offload the computation to external servers which may incur large network latency.","Few works consider jointly optimizing the offloading decisions along with image transmission configurations and adapting them on the fly.","In this paper, we propose A3D, an edge server assisted drone navigation framework that can dynamically adjust task execution location, input resolution, and image compression ratio in order to achieve low inference latency, high prediction accuracy, and long flight distances.","Specifically, we first augment state-of-the-art convolutional neural networks for drone navigation and define a novel metric called Quality of Navigation as our optimization objective which can effectively capture the above goals.","We then design a deep reinforcement learning based neural scheduler at the drone side for which an information encoder is devised to reshape the state features and thus improve its learning ability.","To further support simultaneous multi-drone serving, we extend the edge server design by developing a network-aware resource allocation algorithm, which allows provisioning containerized resources aligned with drones' demand.","We finally implement a proof-of-concept prototype with realistic devices and validate its performance in a real-world campus scene, as well as a simulation environment for thorough evaluation upon AirSim.","Extensive experimental results show that A3D can reduce end-to-end latency by 28.06% and extend the flight distance by up to 27.28% compared with non-adaptive solutions."],"url":"http://arxiv.org/abs/2307.09880v1"}
{"created":"2023-07-19 10:17:35","title":"Amortised Experimental Design and Parameter Estimation for User Models of Pointing","abstract":"User models play an important role in interaction design, supporting automation of interaction design choices. In order to do so, model parameters must be estimated from user data. While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement. In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants. Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data. The approach is demonstrated for three progressively complex models of pointing.","sentences":["User models play an important role in interaction design, supporting automation of interaction design choices.","In order to do so, model parameters must be estimated from user data.","While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement.","In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants.","Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data.","The approach is demonstrated for three progressively complex models of pointing."],"url":"http://arxiv.org/abs/2307.09878v1"}
{"created":"2023-07-19 10:06:30","title":"Agricultural Robotic System: The Automation of Detection and Speech Control","abstract":"Agriculture industries often face challenges in manual tasks such as planting, harvesting, fertilizing, and detection, which can be time consuming and prone to errors. The \"Agricultural Robotic System\" project addresses these issues through a modular design that integrates advanced visual, speech recognition, and robotic technologies. This system is comprised of separate but interconnected modules for vision detection and speech recognition, creating a flexible and adaptable solution. The vision detection module uses computer vision techniques, trained on YOLOv5 and deployed on the Jetson Nano in TensorRT format, to accurately detect and identify different items. A robotic arm module then precisely controls the picking up of seedlings or seeds, and arranges them in specific locations. The speech recognition module enhances intelligent human robot interaction, allowing for efficient and intuitive control of the system. This modular approach improves the efficiency and accuracy of agricultural tasks, demonstrating the potential of robotics in the agricultural industry.","sentences":["Agriculture industries often face challenges in manual tasks such as planting, harvesting, fertilizing, and detection, which can be time consuming and prone to errors.","The \"Agricultural Robotic System\" project addresses these issues through a modular design that integrates advanced visual, speech recognition, and robotic technologies.","This system is comprised of separate but interconnected modules for vision detection and speech recognition, creating a flexible and adaptable solution.","The vision detection module uses computer vision techniques, trained on YOLOv5 and deployed on the Jetson Nano in TensorRT format, to accurately detect and identify different items.","A robotic arm module then precisely controls the picking up of seedlings or seeds, and arranges them in specific locations.","The speech recognition module enhances intelligent human robot interaction, allowing for efficient and intuitive control of the system.","This modular approach improves the efficiency and accuracy of agricultural tasks, demonstrating the potential of robotics in the agricultural industry."],"url":"http://arxiv.org/abs/2307.09874v1"}
{"created":"2023-07-19 09:53:56","title":"Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network","abstract":"Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine-assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities. Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components.","sentences":["Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us.","Potential applications include protecting fragile facilities and designing robust topologies, etc.","Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine-assisted analysis fall short in addressing such a scenario.","In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately.","The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities.","Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components."],"url":"http://arxiv.org/abs/2307.09866v1"}
{"created":"2023-07-19 09:45:41","title":"Towards a population-informed approach to the definition of data-driven models for structural dynamics","abstract":"Machine learning has affected the way in which many phenomena for various domains are modelled, one of these domains being that of structural dynamics. However, because machine-learning algorithms are problem-specific, they often fail to perform efficiently in cases of data scarcity. To deal with such issues, combination of physics-based approaches and machine learning algorithms have been developed. Although such methods are effective, they also require the analyser's understanding of the underlying physics of the problem. The current work is aimed at motivating the use of models which learn such relationships from a population of phenomena, whose underlying physics are similar. The development of such models is motivated by the way that physics-based models, and more specifically finite element models, work. Such models are considered transferrable, explainable and trustworthy, attributes which are not trivially imposed or achieved for machine-learning models. For this reason, machine-learning approaches are less trusted by industry and often considered more difficult to form validated models. To achieve such data-driven models, a population-based scheme is followed here and two different machine-learning algorithms from the meta-learning domain are used. The two algorithms are the model-agnostic meta-learning (MAML) algorithm and the conditional neural processes (CNP) model. The algorithms seem to perform as intended and outperform a traditional machine-learning algorithm at approximating the quantities of interest. Moreover, they exhibit behaviour similar to traditional machine learning algorithms (e.g. neural networks or Gaussian processes), concerning their performance as a function of the available structures in the training population.","sentences":["Machine learning has affected the way in which many phenomena for various domains are modelled, one of these domains being that of structural dynamics.","However, because machine-learning algorithms are problem-specific, they often fail to perform efficiently in cases of data scarcity.","To deal with such issues, combination of physics-based approaches and machine learning algorithms have been developed.","Although such methods are effective, they also require the analyser's understanding of the underlying physics of the problem.","The current work is aimed at motivating the use of models which learn such relationships from a population of phenomena, whose underlying physics are similar.","The development of such models is motivated by the way that physics-based models, and more specifically finite element models, work.","Such models are considered transferrable, explainable and trustworthy, attributes which are not trivially imposed or achieved for machine-learning models.","For this reason, machine-learning approaches are less trusted by industry and often considered more difficult to form validated models.","To achieve such data-driven models, a population-based scheme is followed here and two different machine-learning algorithms from the meta-learning domain are used.","The two algorithms are the model-agnostic meta-learning (MAML) algorithm and the conditional neural processes (CNP) model.","The algorithms seem to perform as intended and outperform a traditional machine-learning algorithm at approximating the quantities of interest.","Moreover, they exhibit behaviour similar to traditional machine learning algorithms (e.g. neural networks or Gaussian processes), concerning their performance as a function of the available structures in the training population."],"url":"http://arxiv.org/abs/2307.09862v1"}
{"created":"2023-07-19 09:45:06","title":"BSDM: Background Suppression Diffusion Model for Hyperspectral Anomaly Detection","abstract":"Hyperspectral anomaly detection (HAD) is widely used in Earth observation and deep space exploration. A major challenge for HAD is the complex background of the input hyperspectral images (HSIs), resulting in anomalies confused in the background. On the other hand, the lack of labeled samples for HSIs leads to poor generalization of existing HAD methods. This paper starts the first attempt to study a new and generalizable background learning problem without labeled samples. We present a novel solution BSDM (background suppression diffusion model) for HAD, which can simultaneously learn latent background distributions and generalize to different datasets for suppressing complex background. It is featured in three aspects: (1) For the complex background of HSIs, we design pseudo background noise and learn the potential background distribution in it with a diffusion model (DM). (2) For the generalizability problem, we apply a statistical offset module so that the BSDM adapts to datasets of different domains without labeling samples. (3) For achieving background suppression, we innovatively improve the inference process of DM by feeding the original HSIs into the denoising network, which removes the background as noise. Our work paves a new background suppression way for HAD that can improve HAD performance without the prerequisite of manually labeled data. Assessments and generalization experiments of four HAD methods on several real HSI datasets demonstrate the above three unique properties of the proposed method. The code is available at https://github.com/majitao-xd/BSDM-HAD.","sentences":["Hyperspectral anomaly detection (HAD) is widely used in Earth observation and deep space exploration.","A major challenge for HAD is the complex background of the input hyperspectral images (HSIs), resulting in anomalies confused in the background.","On the other hand, the lack of labeled samples for HSIs leads to poor generalization of existing HAD methods.","This paper starts the first attempt to study a new and generalizable background learning problem without labeled samples.","We present a novel solution BSDM (background suppression diffusion model) for HAD, which can simultaneously learn latent background distributions and generalize to different datasets for suppressing complex background.","It is featured in three aspects: (1) For the complex background of HSIs, we design pseudo background noise and learn the potential background distribution in it with a diffusion model (DM).","(2) For the generalizability problem, we apply a statistical offset module so that the BSDM adapts to datasets of different domains without labeling samples.","(3) For achieving background suppression, we innovatively improve the inference process of DM by feeding the original HSIs into the denoising network, which removes the background as noise.","Our work paves a new background suppression way for HAD that can improve HAD performance without the prerequisite of manually labeled data.","Assessments and generalization experiments of four HAD methods on several real HSI datasets demonstrate the above three unique properties of the proposed method.","The code is available at https://github.com/majitao-xd/BSDM-HAD."],"url":"http://arxiv.org/abs/2307.09861v1"}
{"created":"2023-07-19 09:43:47","title":"Magic NeRF Lens: Interactive Fusion of Neural Radiance Fields for Virtual Facility Inspection","abstract":"Large industrial facilities such as particle accelerators and nuclear power plants are critical infrastructures for scientific research and industrial processes. These facilities are complex systems that not only require regular maintenance and upgrades but are often inaccessible to humans due to various safety hazards. Therefore, a virtual reality (VR) system that can quickly replicate real-world remote environments to provide users with a high level of spatial and situational awareness is crucial for facility maintenance planning. However, the exact 3D shapes of these facilities are often too complex to be accurately modeled with geometric primitives through the traditional rasterization pipeline.   In this work, we develop Magic NeRF Lens, an interactive framework to support facility inspection in immersive VR using neural radiance fields (NeRF) and volumetric rendering. We introduce a novel data fusion approach that combines the complementary strengths of volumetric rendering and geometric rasterization, allowing a NeRF model to be merged with other conventional 3D data, such as a computer-aided design model. We develop two novel 3D magic lens effects to optimize NeRF rendering by exploiting the properties of human vision and context-aware visualization. We demonstrate the high usability of our framework and methods through a technical benchmark, a visual search user study, and expert reviews. In addition, the source code of our VR NeRF framework is made publicly available for future research and development.","sentences":["Large industrial facilities such as particle accelerators and nuclear power plants are critical infrastructures for scientific research and industrial processes.","These facilities are complex systems that not only require regular maintenance and upgrades but are often inaccessible to humans due to various safety hazards.","Therefore, a virtual reality (VR) system that can quickly replicate real-world remote environments to provide users with a high level of spatial and situational awareness is crucial for facility maintenance planning.","However, the exact 3D shapes of these facilities are often too complex to be accurately modeled with geometric primitives through the traditional rasterization pipeline.   ","In this work, we develop Magic NeRF Lens, an interactive framework to support facility inspection in immersive VR using neural radiance fields (NeRF) and volumetric rendering.","We introduce a novel data fusion approach that combines the complementary strengths of volumetric rendering and geometric rasterization, allowing a NeRF model to be merged with other conventional 3D data, such as a computer-aided design model.","We develop two novel 3D magic lens effects to optimize NeRF rendering by exploiting the properties of human vision and context-aware visualization.","We demonstrate the high usability of our framework and methods through a technical benchmark, a visual search user study, and expert reviews.","In addition, the source code of our VR NeRF framework is made publicly available for future research and development."],"url":"http://arxiv.org/abs/2307.09860v1"}
{"created":"2023-07-19 09:38:52","title":"Towards Reliable Rare Category Analysis on Graphs via Individual Calibration","abstract":"Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis. Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution. While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis? How can we quantify the uncertainty in the learning process and enable reliable rare category analysis?   To answer these questions, we start by investigating miscalibration in existing RCA methods. Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confident in predicting majority classes. Motivated by the observation, we propose a novel individual calibration framework, named CALIRARE, for alleviating the unique challenges of RCA, thus enabling reliable rare category analysis. In particular, to quantify the uncertainties in RCA, we develop a node-level uncertainty quantification algorithm to model the overlapping support regions with high uncertainty; to handle the rarity of minority classes in miscalibration calculation, we generalize the distribution-based calibration metric to the instance level and propose the first individual calibration measurement on graphs named Expected Individual Calibration Error (EICE). We perform extensive experimental evaluations on real-world datasets, including rare category characterization and model calibration tasks, which demonstrate the significance of our proposed framework.","sentences":["Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis.","Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution.","While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis?","How can we quantify the uncertainty in the learning process and enable reliable rare category analysis?   ","To answer these questions, we start by investigating miscalibration in existing RCA methods.","Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confident in predicting majority classes.","Motivated by the observation, we propose a novel individual calibration framework, named CALIRARE, for alleviating the unique challenges of RCA, thus enabling reliable rare category analysis.","In particular, to quantify the uncertainties in RCA, we develop a node-level uncertainty quantification algorithm to model the overlapping support regions with high uncertainty; to handle the rarity of minority classes in miscalibration calculation, we generalize the distribution-based calibration metric to the instance level and propose the first individual calibration measurement on graphs named Expected Individual Calibration Error (EICE).","We perform extensive experimental evaluations on real-world datasets, including rare category characterization and model calibration tasks, which demonstrate the significance of our proposed framework."],"url":"http://arxiv.org/abs/2307.09858v1"}
{"created":"2023-07-19 09:36:08","title":"Blind Image Quality Assessment Using Multi-Stream Architecture with Spatial and Channel Attention","abstract":"BIQA (Blind Image Quality Assessment) is an important field of study that evaluates images automatically. Although significant progress has been made, blind image quality assessment remains a difficult task since images vary in content and distortions. Most algorithms generate quality without emphasizing the important region of interest. In order to solve this, a multi-stream spatial and channel attention-based algorithm is being proposed. This algorithm generates more accurate predictions with a high correlation to human perceptual assessment by combining hybrid features from two different backbones, followed by spatial and channel attention to provide high weights to the region of interest. Four legacy image quality assessment datasets are used to validate the effectiveness of our proposed approach. Authentic and synthetic distortion image databases are used to demonstrate the effectiveness of the proposed method, and we show that it has excellent generalization properties with a particular focus on the perceptual foreground information.","sentences":["BIQA (Blind Image Quality Assessment) is an important field of study that evaluates images automatically.","Although significant progress has been made, blind image quality assessment remains a difficult task since images vary in content and distortions.","Most algorithms generate quality without emphasizing the important region of interest.","In order to solve this, a multi-stream spatial and channel attention-based algorithm is being proposed.","This algorithm generates more accurate predictions with a high correlation to human perceptual assessment by combining hybrid features from two different backbones, followed by spatial and channel attention to provide high weights to the region of interest.","Four legacy image quality assessment datasets are used to validate the effectiveness of our proposed approach.","Authentic and synthetic distortion image databases are used to demonstrate the effectiveness of the proposed method, and we show that it has excellent generalization properties with a particular focus on the perceptual foreground information."],"url":"http://arxiv.org/abs/2307.09857v1"}
{"created":"2023-07-19 09:30:00","title":"Hierarchical Spatio-Temporal Representation Learning for Gait Recognition","abstract":"Gait recognition is a biometric technique that identifies individuals by their unique walking styles, which is suitable for unconstrained environments and has a wide range of applications. While current methods focus on exploiting body part-based representations, they often neglect the hierarchical dependencies between local motion patterns. In this paper, we propose a hierarchical spatio-temporal representation learning (HSTL) framework for extracting gait features from coarse to fine. Our framework starts with a hierarchical clustering analysis to recover multi-level body structures from the whole body to local details. Next, an adaptive region-based motion extractor (ARME) is designed to learn region-independent motion features. The proposed HSTL then stacks multiple ARMEs in a top-down manner, with each ARME corresponding to a specific partition level of the hierarchy. An adaptive spatio-temporal pooling (ASTP) module is used to capture gait features at different levels of detail to perform hierarchical feature mapping. Finally, a frame-level temporal aggregation (FTA) module is employed to reduce redundant information in gait sequences through multi-scale temporal downsampling. Extensive experiments on CASIA-B, OUMVLP, GREW, and Gait3D datasets demonstrate that our method outperforms the state-of-the-art while maintaining a reasonable balance between model accuracy and complexity.","sentences":["Gait recognition is a biometric technique that identifies individuals by their unique walking styles, which is suitable for unconstrained environments and has a wide range of applications.","While current methods focus on exploiting body part-based representations, they often neglect the hierarchical dependencies between local motion patterns.","In this paper, we propose a hierarchical spatio-temporal representation learning (HSTL) framework for extracting gait features from coarse to fine.","Our framework starts with a hierarchical clustering analysis to recover multi-level body structures from the whole body to local details.","Next, an adaptive region-based motion extractor (ARME) is designed to learn region-independent motion features.","The proposed HSTL then stacks multiple ARMEs in a top-down manner, with each ARME corresponding to a specific partition level of the hierarchy.","An adaptive spatio-temporal pooling (ASTP) module is used to capture gait features at different levels of detail to perform hierarchical feature mapping.","Finally, a frame-level temporal aggregation (FTA) module is employed to reduce redundant information in gait sequences through multi-scale temporal downsampling.","Extensive experiments on CASIA-B, OUMVLP, GREW, and Gait3D datasets demonstrate that our method outperforms the state-of-the-art while maintaining a reasonable balance between model accuracy and complexity."],"url":"http://arxiv.org/abs/2307.09856v1"}
{"created":"2023-07-19 09:29:17","title":"Cross-thread critical sections and efficient dynamic race prediction methods","abstract":"The lock set method and the partial order method are two main approaches to guarantee that dynamic data race prediction remains efficient. There are many variations of these ideas. Common to all of them is the assumption that the events in a critical section belong to the same thread. We have evidence that critical sections in the wild do extend across thread boundaries even if the surrounding acquire and release events occur in the same thread. We introduce the novel concept of a cross-thread critical section to capture such situations, offer a theoretical comprehensive framework, and study their impact on state-of-the-art data race analyses. For sound partial order relations such as WCP, SDP, and DCtp, the occurrence of cross-thread critical sections negatively impacts their precision. For complete partial order relations such as WDP and PWR, cross-thread critical sections help to eliminate more false positives. The same (positive) impact applies to the lock set construction. Our experimental evaluation confirms that cross-thread critical sections arise in practice. For the complete relation PWR, we are able to reduce the number of false positives. The performance overhead incurred by tracking cross-thread critical sections slows down the analysis by 10\\%-20\\%, on average.","sentences":["The lock set method and the partial order method are two main approaches to guarantee that dynamic data race prediction remains efficient.","There are many variations of these ideas.","Common to all of them is the assumption that the events in a critical section belong to the same thread.","We have evidence that critical sections in the wild do extend across thread boundaries even if the surrounding acquire and release events occur in the same thread.","We introduce the novel concept of a cross-thread critical section to capture such situations, offer a theoretical comprehensive framework, and study their impact on state-of-the-art data race analyses.","For sound partial order relations such as WCP, SDP, and DCtp, the occurrence of cross-thread critical sections negatively impacts their precision.","For complete partial order relations such as WDP and PWR, cross-thread critical sections help to eliminate more false positives.","The same (positive) impact applies to the lock set construction.","Our experimental evaluation confirms that cross-thread critical sections arise in practice.","For the complete relation PWR, we are able to reduce the number of false positives.","The performance overhead incurred by tracking cross-thread critical sections slows down the analysis by 10\\%-20\\%, on average."],"url":"http://arxiv.org/abs/2307.09855v1"}
{"created":"2023-07-19 09:10:38","title":"Transmitter Side Beyond-Diagonal Reconfigurable Intelligent Surface for Massive MIMO Networks","abstract":"This letter focuses on a transmitter or base station (BS) side beyond-diagonal reflecting intelligent surface (BD-RIS) deployment strategy to enhance the spectral efficiency (SE) of a time-division-duplex massive multiple-input multiple-output (MaMIMO) network. In this strategy, the active antenna array utilizes a BD-RIS at the BS to serve multiple users in the downlink. Based on the knowledge of statistical channel state information (CSI), the BD-RIS coefficients matrix is optimized by employing a novel manifold algorithm, and the power control coefficients are then optimized with the objective of maximizing the minimum SE. Through numerical results we illustrate the SE performance of the proposed transmission framework and compare it with that of a conventional MaMIMO transmission for different network settings.","sentences":["This letter focuses on a transmitter or base station (BS) side beyond-diagonal reflecting intelligent surface (BD-RIS) deployment strategy to enhance the spectral efficiency (SE) of a time-division-duplex massive multiple-input multiple-output (MaMIMO) network.","In this strategy, the active antenna array utilizes a BD-RIS at the BS to serve multiple users in the downlink.","Based on the knowledge of statistical channel state information (CSI), the BD-RIS coefficients matrix is optimized by employing a novel manifold algorithm, and the power control coefficients are then optimized with the objective of maximizing the minimum SE.","Through numerical results we illustrate the SE performance of the proposed transmission framework and compare it with that of a conventional MaMIMO transmission for different network settings."],"url":"http://arxiv.org/abs/2307.09848v1"}
{"created":"2023-07-19 09:03:50","title":"Nonlinear Model Predictive Control with Obstacle Avoidance Constraints for Autonomous Navigation in a Canal Environment","abstract":"In this paper, we describe the development process of autonomous navigation capabilities of a small cruise boat operating in a canal environment and present the results of a field experiment conducted in the Pohang Canal, South Korea. Nonlinear model predictive control (NMPC) was used for the online trajectory planning and tracking control of the cruise boat in a narrow passage in the canal. To consider the nonlinear characteristics of boat dynamics, system identification was performed using experimental data from various test maneuvers, such as acceleration-deceleration and zigzag trials. To efficiently represent the obstacle structures in the canal environment, we parameterized the canal walls as line segments with point cloud data, captured by an onboard LiDAR sensor, and considered them as constraints for obstacle avoidance. The proposed method was implemented in a single NMPC layer, and its real-world performance was verified through experimental runs in the Pohang Canal.","sentences":["In this paper, we describe the development process of autonomous navigation capabilities of a small cruise boat operating in a canal environment and present the results of a field experiment conducted in the Pohang Canal, South Korea.","Nonlinear model predictive control (NMPC) was used for the online trajectory planning and tracking control of the cruise boat in a narrow passage in the canal.","To consider the nonlinear characteristics of boat dynamics, system identification was performed using experimental data from various test maneuvers, such as acceleration-deceleration and zigzag trials.","To efficiently represent the obstacle structures in the canal environment, we parameterized the canal walls as line segments with point cloud data, captured by an onboard LiDAR sensor, and considered them as constraints for obstacle avoidance.","The proposed method was implemented in a single NMPC layer, and its real-world performance was verified through experimental runs in the Pohang Canal."],"url":"http://arxiv.org/abs/2307.09845v1"}
{"created":"2023-07-19 08:53:56","title":"Proving Non-Termination by Acceleration Driven Clause Learning (Short WST Version)","abstract":"We recently proposed Acceleration Driven Clause Learning (ADCL), a novel calculus to analyze satisfiability of Constrained Horn Clauses (CHCs). Here, we adapt ADCL to disprove termination of transition systems, and we evaluate its implementation in our tool LoAT against the state of the art.","sentences":["We recently proposed Acceleration Driven Clause Learning (ADCL), a novel calculus to analyze satisfiability of Constrained Horn Clauses (CHCs).","Here, we adapt ADCL to disprove termination of transition systems, and we evaluate its implementation in our tool LoAT against the state of the art."],"url":"http://arxiv.org/abs/2307.09839v1"}
{"created":"2023-07-19 08:47:41","title":"Near-Linear Time Projection onto the $\\ell_{1,\\infty}$ Ball; Application to Sparse Autoencoders","abstract":"Looking for sparsity is nowadays crucial to speed up the training of large-scale neural networks. Projections onto the $\\ell_{1,2}$ and $\\ell_{1,\\infty}$ are among the most efficient techniques to sparsify and reduce the overall cost of neural networks. In this paper, we introduce a new projection algorithm for the $\\ell_{1,\\infty}$ norm ball. The worst-case time complexity of this algorithm is $\\mathcal{O}\\big(nm+J\\log(nm)\\big)$ for a matrix in $\\mathbb{R}^{n\\times m}$. $J$ is a term that tends to 0 when the sparsity is high, and to $nm$ when the sparsity is low. Its implementation is easy and it is guaranteed to converge to the exact solution in a finite time. Moreover, we propose to incorporate the $\\ell_{1,\\infty}$ ball projection while training an autoencoder to enforce feature selection and sparsity of the weights. Sparsification appears in the encoder to primarily do feature selection due to our application in biology, where only a very small part ($<2\\%$) of the data is relevant. We show that both in the biological case and in the general case of sparsity that our method is the fastest.","sentences":["Looking for sparsity is nowadays crucial to speed up the training of large-scale neural networks.","Projections onto the $\\ell_{1,2}$ and $\\ell_{1,\\infty}$ are among the most efficient techniques to sparsify and reduce the overall cost of neural networks.","In this paper, we introduce a new projection algorithm for the $\\ell_{1,\\infty}$ norm ball.","The worst-case time complexity of this algorithm is $\\mathcal{O}\\big(nm+J\\log(nm)\\big)$ for a matrix in $\\mathbb{R}^{n\\times m}$. $J$ is a term that tends to 0 when the sparsity is high, and to $nm$ when the sparsity is low.","Its implementation is easy and it is guaranteed to converge to the exact solution in a finite time.","Moreover, we propose to incorporate the $\\ell_{1,\\infty}$ ball projection while training an autoencoder to enforce feature selection and sparsity of the weights.","Sparsification appears in the encoder to primarily do feature selection due to our application in biology, where only a very small part ($<2\\%$) of the data is relevant.","We show that both in the biological case and in the general case of sparsity that our method is the fastest."],"url":"http://arxiv.org/abs/2307.09836v1"}
{"created":"2023-07-19 08:44:11","title":"Who Provides the Largest Megaphone? The Role of Google News in Promoting Russian State-Affiliated News Sources","abstract":"The Internet has not only digitized but also democratized information access across the globe. This gradual but path-breaking move to online information propagation has resulted in search engines playing an increasingly prominent role in shaping access to human knowledge. When an Internet user enters a query, the search engine sorts through the hundreds of billions of possible webpages to determine what to show. Google dominates the search engine market, with Google Search surpassing 80% market share globally every year of the last decade. Only in Russia and China do Google competitors claim more market share, with approximately 60% of Internet users in Russia preferring Yandex (compared to 40% in favor of Google) and more than 80% of China's Internet users accessing Baidu as of 2022. Notwithstanding this long-standing regional variation in Internet search providers, there is limited research showing how these providers compare in terms of propagating state-sponsored information. Our study fills this research gap by focusing on Russian cyberspace and examining how Google and Yandex's search algorithms rank content from Russian state-controlled media (hereon, RSM) outlets. This question is timely and of practical interest given widespread reports indicating that RSM outlets have actively engaged in promoting Kremlin propaganda in the lead-up to, and in the aftermath of, the Russian invasion of Ukraine in February 2022.","sentences":["The Internet has not only digitized but also democratized information access across the globe.","This gradual but path-breaking move to online information propagation has resulted in search engines playing an increasingly prominent role in shaping access to human knowledge.","When an Internet user enters a query, the search engine sorts through the hundreds of billions of possible webpages to determine what to show.","Google dominates the search engine market, with Google Search surpassing 80% market share globally every year of the last decade.","Only in Russia and China do Google competitors claim more market share, with approximately 60% of Internet users in Russia preferring Yandex (compared to 40% in favor of Google) and more than 80% of China's Internet users accessing Baidu as of 2022.","Notwithstanding this long-standing regional variation in Internet search providers, there is limited research showing how these providers compare in terms of propagating state-sponsored information.","Our study fills this research gap by focusing on Russian cyberspace and examining how Google and Yandex's search algorithms rank content from Russian state-controlled media (hereon, RSM) outlets.","This question is timely and of practical interest given widespread reports indicating that RSM outlets have actively engaged in promoting Kremlin propaganda in the lead-up to, and in the aftermath of, the Russian invasion of Ukraine in February 2022."],"url":"http://arxiv.org/abs/2307.09834v1"}
{"created":"2023-07-19 08:36:31","title":"A Fast and Map-Free Model for Trajectory Prediction in Traffics","abstract":"To handle the two shortcomings of existing methods, (i)nearly all models rely on high-definition (HD) maps, yet the map information is not always available in real traffic scenes and HD map-building is expensive and time-consuming and (ii) existing models usually focus on improving prediction accuracy at the expense of reducing computing efficiency, yet the efficiency is crucial for various real applications, this paper proposes an efficient trajectory prediction model that is not dependent on traffic maps. The core idea of our model is encoding single-agent's spatial-temporal information in the first stage and exploring multi-agents' spatial-temporal interactions in the second stage. By comprehensively utilizing attention mechanism, LSTM, graph convolution network and temporal transformer in the two stages, our model is able to learn rich dynamic and interaction information of all agents. Our model achieves the highest performance when comparing with existing map-free methods and also exceeds most map-based state-of-the-art methods on the Argoverse dataset. In addition, our model also exhibits a faster inference speed than the baseline methods.","sentences":["To handle the two shortcomings of existing methods, (i)nearly all models rely on high-definition (HD) maps, yet the map information is not always available in real traffic scenes and HD map-building is expensive and time-consuming and (ii) existing models usually focus on improving prediction accuracy at the expense of reducing computing efficiency, yet the efficiency is crucial for various real applications, this paper proposes an efficient trajectory prediction model that is not dependent on traffic maps.","The core idea of our model is encoding single-agent's spatial-temporal information in the first stage and exploring multi-agents' spatial-temporal interactions in the second stage.","By comprehensively utilizing attention mechanism, LSTM, graph convolution network and temporal transformer in the two stages, our model is able to learn rich dynamic and interaction information of all agents.","Our model achieves the highest performance when comparing with existing map-free methods and also exceeds most map-based state-of-the-art methods on the Argoverse dataset.","In addition, our model also exhibits a faster inference speed than the baseline methods."],"url":"http://arxiv.org/abs/2307.09831v1"}
{"created":"2023-07-19 08:34:25","title":"What do neural networks learn in image classification? A frequency shortcut perspective","abstract":"Frequency analysis is useful for understanding the mechanisms of representation learning in neural networks (NNs). Most research in this area focuses on the learning dynamics of NNs for regression tasks, while little for classification. This study empirically investigates the latter and expands the understanding of frequency shortcuts. First, we perform experiments on synthetic datasets, designed to have a bias in different frequency bands. Our results demonstrate that NNs tend to find simple solutions for classification, and what they learn first during training depends on the most distinctive frequency characteristics, which can be either low- or high-frequencies. Second, we confirm this phenomenon on natural images. We propose a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts. The results show that frequency shortcuts can be texture-based or shape-based, depending on what best simplifies the objective. Third, we validate the transferability of frequency shortcuts on out-of-distribution (OOD) test sets. Our results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation. We recommend that future research should focus on effective training schemes mitigating frequency shortcut learning.","sentences":["Frequency analysis is useful for understanding the mechanisms of representation learning in neural networks (NNs).","Most research in this area focuses on the learning dynamics of NNs for regression tasks, while little for classification.","This study empirically investigates the latter and expands the understanding of frequency shortcuts.","First, we perform experiments on synthetic datasets, designed to have a bias in different frequency bands.","Our results demonstrate that NNs tend to find simple solutions for classification, and what they learn first during training depends on the most distinctive frequency characteristics, which can be either low- or high-frequencies.","Second, we confirm this phenomenon on natural images.","We propose a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts.","The results show that frequency shortcuts can be texture-based or shape-based, depending on what best simplifies the objective.","Third, we validate the transferability of frequency shortcuts on out-of-distribution (OOD) test sets.","Our results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation.","We recommend that future research should focus on effective training schemes mitigating frequency shortcut learning."],"url":"http://arxiv.org/abs/2307.09829v1"}
{"created":"2023-07-19 08:32:59","title":"Online Continual Learning for Robust Indoor Object Recognition","abstract":"Vision systems mounted on home robots need to interact with unseen classes in changing environments. Robots have limited computational resources, labelled data and storage capability. These requirements pose some unique challenges: models should adapt without forgetting past knowledge in a data- and parameter-efficient way. We characterize the problem as few-shot (FS) online continual learning (OCL), where robotic agents learn from a non-repeated stream of few-shot data updating only a few model parameters. Additionally, such models experience variable conditions at test time, where objects may appear in different poses (e.g., horizontal or vertical) and environments (e.g., day or night). To improve robustness of CL agents, we propose RobOCLe, which; 1) constructs an enriched feature space computing high order statistical moments from the embedded features of samples; and 2) computes similarity between high order statistics of the samples on the enriched feature space, and predicts their class labels. We evaluate robustness of CL models to train/test augmentations in various cases. We show that different moments allow RobOCLe to capture different properties of deformations, providing higher robustness with no decrease of inference speed.","sentences":["Vision systems mounted on home robots need to interact with unseen classes in changing environments.","Robots have limited computational resources, labelled data and storage capability.","These requirements pose some unique challenges: models should adapt without forgetting past knowledge in a data- and parameter-efficient way.","We characterize the problem as few-shot (FS) online continual learning (OCL), where robotic agents learn from a non-repeated stream of few-shot data updating only a few model parameters.","Additionally, such models experience variable conditions at test time, where objects may appear in different poses (e.g., horizontal or vertical) and environments (e.g., day or night).","To improve robustness of CL agents, we propose RobOCLe, which; 1) constructs an enriched feature space computing high order statistical moments from the embedded features of samples; and 2) computes similarity between high order statistics of the samples on the enriched feature space, and predicts their class labels.","We evaluate robustness of CL models to train/test augmentations in various cases.","We show that different moments allow RobOCLe to capture different properties of deformations, providing higher robustness with no decrease of inference speed."],"url":"http://arxiv.org/abs/2307.09827v1"}
{"created":"2023-07-19 08:19:08","title":"A Siamese-based Verification System for Open-set Architecture Attribution of Synthetic Images","abstract":"Despite the wide variety of methods developed for synthetic image attribution, most of them can only attribute images generated by models or architectures included in the training set and do not work with unknown architectures, hindering their applicability in real-world scenarios. In this paper, we propose a verification framework that relies on a Siamese Network to address the problem of open-set attribution of synthetic images to the architecture that generated them. We consider two different settings. In the first setting, the system determines whether two images have been produced by the same generative architecture or not. In the second setting, the system verifies a claim about the architecture used to generate a synthetic image, utilizing one or multiple reference images generated by the claimed architecture. The main strength of the proposed system is its ability to operate in both closed and open-set scenarios so that the input images, either the query and reference images, can belong to the architectures considered during training or not. Experimental evaluations encompassing various generative architectures such as GANs, diffusion models, and transformers, focusing on synthetic face image generation, confirm the excellent performance of our method in both closed and open-set settings, as well as its strong generalization capabilities.","sentences":["Despite the wide variety of methods developed for synthetic image attribution, most of them can only attribute images generated by models or architectures included in the training set and do not work with unknown architectures, hindering their applicability in real-world scenarios.","In this paper, we propose a verification framework that relies on a Siamese Network to address the problem of open-set attribution of synthetic images to the architecture that generated them.","We consider two different settings.","In the first setting, the system determines whether two images have been produced by the same generative architecture or not.","In the second setting, the system verifies a claim about the architecture used to generate a synthetic image, utilizing one or multiple reference images generated by the claimed architecture.","The main strength of the proposed system is its ability to operate in both closed and open-set scenarios so that the input images, either the query and reference images, can belong to the architectures considered during training or not.","Experimental evaluations encompassing various generative architectures such as GANs, diffusion models, and transformers, focusing on synthetic face image generation, confirm the excellent performance of our method in both closed and open-set settings, as well as its strong generalization capabilities."],"url":"http://arxiv.org/abs/2307.09822v1"}
{"created":"2023-07-19 08:16:34","title":"Hierarchical Semantic Perceptual Listener Head Video Generation: A High-performance Pipeline","abstract":"In dyadic speaker-listener interactions, the listener's head reactions along with the speaker's head movements, constitute an important non-verbal semantic expression together. The listener Head generation task aims to synthesize responsive listener's head videos based on audios of the speaker and reference images of the listener. Compared to the Talking-head generation, it is more challenging to capture the correlation clues from the speaker's audio and visual information. Following the ViCo baseline scheme, we propose a high-performance solution by enhancing the hierarchical semantic extraction capability of the audio encoder module and improving the decoder part, renderer and post-processing modules. Our solution gets the first place on the official leaderboard for the track of listening head generation. This paper is a technical report of ViCo@2023 Conversational Head Generation Challenge in ACM Multimedia 2023 conference.","sentences":["In dyadic speaker-listener interactions, the listener's head reactions along with the speaker's head movements, constitute an important non-verbal semantic expression together.","The listener Head generation task aims to synthesize responsive listener's head videos based on audios of the speaker and reference images of the listener.","Compared to the Talking-head generation, it is more challenging to capture the correlation clues from the speaker's audio and visual information.","Following the ViCo baseline scheme, we propose a high-performance solution by enhancing the hierarchical semantic extraction capability of the audio encoder module and improving the decoder part, renderer and post-processing modules.","Our solution gets the first place on the official leaderboard for the track of listening head generation.","This paper is a technical report of ViCo@2023 Conversational Head Generation Challenge in ACM Multimedia 2023 conference."],"url":"http://arxiv.org/abs/2307.09821v1"}
{"created":"2023-07-19 08:08:00","title":"Analyzing large scale political discussions on Twitter: the use case of the Greek wiretapping scandal (#ypoklopes)","abstract":"In this paper, we study the Greek wiretappings scandal, which has been revealed in 2022 and attracted a lot of attention by press and citizens. Specifically, we propose a methodology for collecting data and analyzing patterns of online public discussions on Twitter. We apply our methodology to the Greek wiretappings use case, and present findings related to the evolution of the discussion over time, its polarization, and the role of the media. The methodology can be of wider use and replicated to other topics. Finally, we provide publicly an open dataset, and online resources with the results.","sentences":["In this paper, we study the Greek wiretappings scandal, which has been revealed in 2022 and attracted a lot of attention by press and citizens.","Specifically, we propose a methodology for collecting data and analyzing patterns of online public discussions on Twitter.","We apply our methodology to the Greek wiretappings use case, and present findings related to the evolution of the discussion over time, its polarization, and the role of the media.","The methodology can be of wider use and replicated to other topics.","Finally, we provide publicly an open dataset, and online resources with the results."],"url":"http://arxiv.org/abs/2307.09819v1"}
{"created":"2023-07-19 08:03:53","title":"LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network","abstract":"Recovering sharp images from dual-pixel (DP) pairs with disparity-dependent blur is a challenging task.~Existing blur map-based deblurring methods have demonstrated promising results. In this paper, we propose, to the best of our knowledge, the first framework to introduce the contrastive language-image pre-training framework (CLIP) to achieve accurate blur map estimation from DP pairs unsupervisedly. To this end, we first carefully design text prompts to enable CLIP to understand blur-related geometric prior knowledge from the DP pair. Then, we propose a format to input stereo DP pair to the CLIP without any fine-tuning, where the CLIP is pre-trained on monocular images. Given the estimated blur map, we introduce a blur-prior attention block, a blur-weighting loss and a blur-aware loss to recover the all-in-focus image. Our method achieves state-of-the-art performance in extensive experiments.","sentences":["Recovering sharp images from dual-pixel (DP) pairs with disparity-dependent blur is a challenging task.~Existing blur map-based deblurring methods have demonstrated promising results.","In this paper, we propose, to the best of our knowledge, the first framework to introduce the contrastive language-image pre-training framework (CLIP) to achieve accurate blur map estimation from DP pairs unsupervisedly.","To this end, we first carefully design text prompts to enable CLIP to understand blur-related geometric prior knowledge from the DP pair.","Then, we propose a format to input stereo DP pair to the CLIP without any fine-tuning, where the CLIP is pre-trained on monocular images.","Given the estimated blur map, we introduce a blur-prior attention block, a blur-weighting loss and a blur-aware loss to recover the all-in-focus image.","Our method achieves state-of-the-art performance in extensive experiments."],"url":"http://arxiv.org/abs/2307.09815v1"}
{"created":"2023-07-19 08:02:20","title":"DAPrompt: Deterministic Assumption Prompt Learning for Event Causality Identification","abstract":"Event Causality Identification (ECI) aims at determining whether there is a causal relation between two event mentions. Conventional prompt learning designs a prompt template to first predict an answer word and then maps it to the final decision. Unlike conventional prompts, we argue that predicting an answer word may not be a necessary prerequisite for the ECI task. Instead, we can first make a deterministic assumption on the existence of causal relation between two events and then evaluate its rationality to either accept or reject the assumption. The design motivation is to try the most utilization of the encyclopedia-like knowledge embedded in a pre-trained language model. In light of such considerations, we propose a deterministic assumption prompt learning model, called DAPrompt, for the ECI task. In particular, we design a simple deterministic assumption template concatenating with the input event pair, which includes two masks as predicted events' tokens. We use the probabilities of predicted events to evaluate the assumption rationality for the final event causality decision. Experiments on the EventStoryLine corpus and Causal-TimeBank corpus validate our design objective in terms of significant performance improvements over the state-of-the-art algorithms.","sentences":["Event Causality Identification (ECI) aims at determining whether there is a causal relation between two event mentions.","Conventional prompt learning designs a prompt template to first predict an answer word and then maps it to the final decision.","Unlike conventional prompts, we argue that predicting an answer word may not be a necessary prerequisite for the ECI task.","Instead, we can first make a deterministic assumption on the existence of causal relation between two events and then evaluate its rationality to either accept or reject the assumption.","The design motivation is to try the most utilization of the encyclopedia-like knowledge embedded in a pre-trained language model.","In light of such considerations, we propose a deterministic assumption prompt learning model, called DAPrompt, for the ECI task.","In particular, we design a simple deterministic assumption template concatenating with the input event pair, which includes two masks as predicted events' tokens.","We use the probabilities of predicted events to evaluate the assumption rationality for the final event causality decision.","Experiments on the EventStoryLine corpus and Causal-TimeBank corpus validate our design objective in terms of significant performance improvements over the state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2307.09813v1"}
{"created":"2023-07-19 07:58:21","title":"GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity in Web Images Via a New Generalized KL Divergence","abstract":"Web image datasets curated online inherently contain ambiguous in-distribution (ID) instances and out-of-distribution (OOD) instances, which we collectively call non-conforming (NC) instances. In many recent approaches for mitigating the negative effects of NC instances, the core implicit assumption is that the NC instances can be found via entropy maximization. For \"entropy\" to be well-defined, we are interpreting the output prediction vector of an instance as the parameter vector of a multinomial random variable, with respect to some trained model with a softmax output layer. Hence, entropy maximization is based on the idealized assumption that NC instances have predictions that are \"almost\" uniformly distributed. However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed. To tackle the limitation of entropy maximization, we propose $(\\alpha, \\beta)$-generalized KL divergence, $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$, which can be used to identify significantly more NC instances. Theoretical properties of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ are proven, and we also show empirically that a simple use of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ outperforms all baselines on the NC instance identification task. Building upon $(\\alpha,\\beta)$-generalized KL divergence, we also introduce a new iterative training framework, GenKL, that identifies and relabels NC instances. When evaluated on three web image datasets, Clothing1M, Food101/Food101N, and mini WebVision 1.0, we achieved new state-of-the-art classification accuracies: $81.34\\%$, $85.73\\%$ and $78.99\\%$/$92.54\\%$ (top-1/top-5), respectively.","sentences":["Web image datasets curated online inherently contain ambiguous in-distribution (ID) instances and out-of-distribution (OOD) instances, which we collectively call non-conforming (NC) instances.","In many recent approaches for mitigating the negative effects of NC instances, the core implicit assumption is that the NC instances can be found via entropy maximization.","For \"entropy\" to be well-defined, we are interpreting the output prediction vector of an instance as the parameter vector of a multinomial random variable, with respect to some trained model with a softmax output layer.","Hence, entropy maximization is based on the idealized assumption that NC instances have predictions that are \"almost\" uniformly distributed.","However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed.","To tackle the limitation of entropy maximization, we propose $(\\alpha, \\beta)$-generalized KL divergence, $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$, which can be used to identify significantly more NC instances.","Theoretical properties of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ are proven, and we also show empirically that a simple use of $\\mathcal{D}_{\\text{KL}}^{\\alpha, \\beta}(p\\|q)$ outperforms all baselines on the NC instance identification task.","Building upon $(\\alpha,\\beta)$-generalized KL divergence, we also introduce a new iterative training framework, GenKL, that identifies and relabels NC instances.","When evaluated on three web image datasets, Clothing1M, Food101/Food101N, and mini WebVision 1.0, we achieved new state-of-the-art classification accuracies: $81.34\\%$, $85.73\\%$ and $78.99\\%$/$92.54\\%$ (top-1/top-5), respectively."],"url":"http://arxiv.org/abs/2307.09810v1"}
{"created":"2023-07-19 07:53:55","title":"A Low-Complexity Beamforming Design for Beyond-Diagonal RIS aided Multi-User Networks","abstract":"Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has been proposed recently as a novel and generalized RIS architecture that offers enhanced wave manipulation flexibility and large coverage expansion. However, the beyond-diagonal mathematical model in BD-RIS inevitably introduces additional optimization challenges in beamforming design. In this letter, we derive a closed-form solution for the BD-RIS passive beamforming matrix that maximizes the sum of the effective channel gains among users. We further propose a computationally efficient two-stage beamforming framework to jointly design the active beamforming at the base station and passive beamforming at the BD-RIS to enhance the sum-rate for a BD-RIS aided multi-user multi-antenna network.Numerical results show that our proposed algorithm achieves a higher sum-rate while requiring less computation time compared to state-of-the-art algorithms. The proposed algorithm paves the way for practical beamforming design in BD-RIS aided wireless networks.","sentences":["Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has been proposed recently as a novel and generalized RIS architecture that offers enhanced wave manipulation flexibility and large coverage expansion.","However, the beyond-diagonal mathematical model in BD-RIS inevitably introduces additional optimization challenges in beamforming design.","In this letter, we derive a closed-form solution for the BD-RIS passive beamforming matrix that maximizes the sum of the effective channel gains among users.","We further propose a computationally efficient two-stage beamforming framework to jointly design the active beamforming at the base station and passive beamforming at the BD-RIS to enhance the sum-rate for a BD-RIS aided multi-user multi-antenna network.","Numerical results show that our proposed algorithm achieves a higher sum-rate while requiring less computation time compared to state-of-the-art algorithms.","The proposed algorithm paves the way for practical beamforming design in BD-RIS aided wireless networks."],"url":"http://arxiv.org/abs/2307.09807v1"}
{"created":"2023-07-19 07:47:23","title":"Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling","abstract":"Convolutional neural networks encode images through a sequence of convolutions, normalizations and non-linearities as well as downsampling operations into potentially strong semantic embeddings. Yet, previous work showed that even slight mistakes during sampling, leading to aliasing, can be directly attributed to the networks' lack in robustness. To address such issues and facilitate simpler and faster adversarial training, [12] recently proposed FLC pooling, a method for provably alias-free downsampling - in theory. In this work, we conduct a further analysis through the lens of signal processing and find that such current pooling methods, which address aliasing in the frequency domain, are still prone to spectral leakage artifacts. Hence, we propose aliasing and spectral artifact-free pooling, short ASAP. While only introducing a few modifications to FLC pooling, networks using ASAP as downsampling method exhibit higher native robustness against common corruptions, a property that FLC pooling was missing. ASAP also increases native robustness against adversarial attacks on high and low resolution data while maintaining similar clean accuracy or even outperforming the baseline.","sentences":["Convolutional neural networks encode images through a sequence of convolutions, normalizations and non-linearities as well as downsampling operations into potentially strong semantic embeddings.","Yet, previous work showed that even slight mistakes during sampling, leading to aliasing, can be directly attributed to the networks' lack in robustness.","To address such issues and facilitate simpler and faster adversarial training, [12] recently proposed FLC pooling, a method for provably alias-free downsampling - in theory.","In this work, we conduct a further analysis through the lens of signal processing and find that such current pooling methods, which address aliasing in the frequency domain, are still prone to spectral leakage artifacts.","Hence, we propose aliasing and spectral artifact-free pooling, short ASAP.","While only introducing a few modifications to FLC pooling, networks using ASAP as downsampling method exhibit higher native robustness against common corruptions, a property that FLC pooling was missing.","ASAP also increases native robustness against adversarial attacks on high and low resolution data while maintaining similar clean accuracy or even outperforming the baseline."],"url":"http://arxiv.org/abs/2307.09804v1"}
{"created":"2023-07-19 07:40:51","title":"Graph Federated Learning Based on the Decentralized Framework","abstract":"Graph learning has a wide range of applications in many scenarios, which require more need for data privacy. Federated learning is an emerging distributed machine learning approach that leverages data from individual devices or data centers to improve the accuracy and generalization of the model, while also protecting the privacy of user data. Graph-federated learning is mainly based on the classical federated learning framework i.e., the Client-Server framework. However, the Client-Server framework faces problems such as a single point of failure of the central server and poor scalability of network topology. First, we introduce the decentralized framework to graph-federated learning. Second, determine the confidence among nodes based on the similarity of data among nodes, subsequently, the gradient information is then aggregated by linear weighting based on confidence. Finally, the proposed method is compared with FedAvg, Fedprox, GCFL, and GCFL+ to verify the effectiveness of the proposed method. Experiments demonstrate that the proposed method outperforms other methods.","sentences":["Graph learning has a wide range of applications in many scenarios, which require more need for data privacy.","Federated learning is an emerging distributed machine learning approach that leverages data from individual devices or data centers to improve the accuracy and generalization of the model, while also protecting the privacy of user data.","Graph-federated learning is mainly based on the classical federated learning framework i.e., the Client-Server framework.","However, the Client-Server framework faces problems such as a single point of failure of the central server and poor scalability of network topology.","First, we introduce the decentralized framework to graph-federated learning.","Second, determine the confidence among nodes based on the similarity of data among nodes, subsequently, the gradient information is then aggregated by linear weighting based on confidence.","Finally, the proposed method is compared with FedAvg, Fedprox, GCFL, and GCFL+ to verify the effectiveness of the proposed method.","Experiments demonstrate that the proposed method outperforms other methods."],"url":"http://arxiv.org/abs/2307.09801v1"}
{"created":"2023-07-19 07:31:37","title":"Probabilistic Forecasting with Coherent Aggregation","abstract":"Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation. The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure. In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction. This is a consequence of a simple (exchangeability) observation: permuting \\textit{}base-level series in the hierarchy does not change their aggregates. Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probability Score and quantile losses. We can choose arbitrary continuous distributions for the factor and the base-level distributions. We compare our method to two previous methods which can be optimized end-to-end, while enforcing coherent aggregation. Our model achieves significant improvements: between $11.8-41.4\\%$ on three hierarchical forecasting datasets. We also analyze the influence of parameters in our model with respect to base-level distribution and number of factors.","sentences":["Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation.","The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure.","In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction.","This is a consequence of a simple (exchangeability) observation: permuting \\textit{}base-level series in the hierarchy does not change their aggregates.","Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probability Score and quantile losses.","We can choose arbitrary continuous distributions for the factor and the base-level distributions.","We compare our method to two previous methods which can be optimized end-to-end, while enforcing coherent aggregation.","Our model achieves significant improvements: between $11.8-41.4\\%$ on three hierarchical forecasting datasets.","We also analyze the influence of parameters in our model with respect to base-level distribution and number of factors."],"url":"http://arxiv.org/abs/2307.09797v1"}
{"created":"2023-07-19 07:30:01","title":"Forecasting Early with Meta Learning","abstract":"In the early observation period of a time series, there might be only a few historic observations available to learn a model. However, in cases where an existing prior set of datasets is available, Meta learning methods can be applicable. In this paper, we devise a Meta learning method that exploits samples from additional datasets and learns to augment time series through adversarial learning as an auxiliary task for the target dataset. Our model (FEML), is equipped with a shared Convolutional backbone that learns features for varying length inputs from different datasets and has dataset specific heads to forecast for different output lengths. We show that FEML can meta learn across datasets and by additionally learning on adversarial generated samples as auxiliary samples for the target dataset, it can improve the forecasting performance compared to single task learning, and various solutions adapted from Joint learning, Multi-task learning and classic forecasting baselines.","sentences":["In the early observation period of a time series, there might be only a few historic observations available to learn a model.","However, in cases where an existing prior set of datasets is available, Meta learning methods can be applicable.","In this paper, we devise a Meta learning method that exploits samples from additional datasets and learns to augment time series through adversarial learning as an auxiliary task for the target dataset.","Our model (FEML), is equipped with a shared Convolutional backbone that learns features for varying length inputs from different datasets and has dataset specific heads to forecast for different output lengths.","We show that FEML can meta learn across datasets and by additionally learning on adversarial generated samples as auxiliary samples for the target dataset, it can improve the forecasting performance compared to single task learning, and various solutions adapted from Joint learning, Multi-task learning and classic forecasting baselines."],"url":"http://arxiv.org/abs/2307.09796v1"}
{"created":"2023-07-19 07:29:14","title":"From West to East: Who can understand the music of the others better?","abstract":"Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks. At the same time, the vast majority of these models have been trained on Western pop/rock music and related styles. This leads to research questions on whether these models can be used to learn representations for different music cultures and styles, or whether we can build similar music audio embedding models trained on data from different cultures or styles. To that end, we leverage transfer learning methods to derive insights about the similarities between the different music cultures to which the data belongs to. We use two Western music datasets, two traditional/folk datasets coming from eastern Mediterranean cultures, and two datasets belonging to Indian art music. Three deep audio embedding models are trained and transferred across domains, including two CNN-based and a Transformer-based architecture, to perform auto-tagging for each target domain dataset. Experimental results show that competitive performance is achieved in all domains via transfer learning, while the best source dataset varies for each music culture. The implementation and the trained models are both provided in a public repository.","sentences":["Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks.","At the same time, the vast majority of these models have been trained on Western pop/rock music and related styles.","This leads to research questions on whether these models can be used to learn representations for different music cultures and styles, or whether we can build similar music audio embedding models trained on data from different cultures or styles.","To that end, we leverage transfer learning methods to derive insights about the similarities between the different music cultures to which the data belongs to.","We use two Western music datasets, two traditional/folk datasets coming from eastern Mediterranean cultures, and two datasets belonging to Indian art music.","Three deep audio embedding models are trained and transferred across domains, including two CNN-based and a Transformer-based architecture, to perform auto-tagging for each target domain dataset.","Experimental results show that competitive performance is achieved in all domains via transfer learning, while the best source dataset varies for each music culture.","The implementation and the trained models are both provided in a public repository."],"url":"http://arxiv.org/abs/2307.09795v1"}
{"created":"2023-07-19 07:17:43","title":"On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models","abstract":"Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs are announced each week, many of which are deposited to Hugging Face, a repository of machine learning models and datasets. To date, nearly 16,000 Text Generation models have been uploaded to the site. Given the huge influx of LLMs, it is of interest to know which LLM backbones, settings, training methods, and families are popular or trending. However, there is no comprehensive index of LLMs available. We take advantage of the relatively systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering and identify communities amongst LLMs using n-grams and term frequency-inverse document frequency. Our methods successfully identify families of LLMs and accurately cluster LLMs into meaningful subgroups. We present a public web application to navigate and explore Constellation, our atlas of 15,821 LLMs. Constellation rapidly generates a variety of visualizations, namely dendrograms, graphs, word clouds, and scatter plots. Constellation is available at the following link: https://constellation.sites.stanford.edu/.","sentences":["Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users.","Hundreds of new LLMs are announced each week, many of which are deposited to Hugging Face, a repository of machine learning models and datasets.","To date, nearly 16,000 Text Generation models have been uploaded to the site.","Given the huge influx of LLMs, it is of interest to know which LLM backbones, settings, training methods, and families are popular or trending.","However, there is no comprehensive index of LLMs available.","We take advantage of the relatively systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering and identify communities amongst LLMs using n-grams and term frequency-inverse document frequency.","Our methods successfully identify families of LLMs and accurately cluster LLMs into meaningful subgroups.","We present a public web application to navigate and explore Constellation, our atlas of 15,821 LLMs.","Constellation rapidly generates a variety of visualizations, namely dendrograms, graphs, word clouds, and scatter plots.","Constellation is available at the following link: https://constellation.sites.stanford.edu/."],"url":"http://arxiv.org/abs/2307.09793v1"}
{"created":"2023-07-19 07:11:45","title":"Density-invariant Features for Distant Point Cloud Registration","abstract":"Registration of distant outdoor LiDAR point clouds is crucial to extending the 3D vision of collaborative autonomous vehicles, and yet is challenging due to small overlapping area and a huge disparity between observed point densities. In this paper, we propose Group-wise Contrastive Learning (GCL) scheme to extract density-invariant geometric features to register distant outdoor LiDAR point clouds. We mark through theoretical analysis and experiments that, contrastive positives should be independent and identically distributed (i.i.d.), in order to train densityinvariant feature extractors. We propose upon the conclusion a simple yet effective training scheme to force the feature of multiple point clouds in the same spatial location (referred to as positive groups) to be similar, which naturally avoids the sampling bias introduced by a pair of point clouds to conform with the i.i.d. principle. The resulting fully-convolutional feature extractor is more powerful and density-invariant than state-of-the-art methods, improving the registration recall of distant scenarios on KITTI and nuScenes benchmarks by 40.9% and 26.9%, respectively. The code will be open-sourced.","sentences":["Registration of distant outdoor LiDAR point clouds is crucial to extending the 3D vision of collaborative autonomous vehicles, and yet is challenging due to small overlapping area and a huge disparity between observed point densities.","In this paper, we propose Group-wise Contrastive Learning (GCL) scheme to extract density-invariant geometric features to register distant outdoor LiDAR point clouds.","We mark through theoretical analysis and experiments that, contrastive positives should be independent and identically distributed (i.i.d.), in order to train densityinvariant feature extractors.","We propose upon the conclusion a simple yet effective training scheme to force the feature of multiple point clouds in the same spatial location (referred to as positive groups) to be similar, which naturally avoids the sampling bias introduced by a pair of point clouds to conform with the i.i.d. principle.","The resulting fully-convolutional feature extractor is more powerful and density-invariant than state-of-the-art methods, improving the registration recall of distant scenarios on KITTI and nuScenes benchmarks by 40.9% and 26.9%, respectively.","The code will be open-sourced."],"url":"http://arxiv.org/abs/2307.09788v1"}
{"created":"2023-07-19 07:11:11","title":"DVPT: Dynamic Visual Prompt Tuning of Large Pre-trained Models for Medical Image Analysis","abstract":"Limited labeled data makes it hard to train models from scratch in medical domain, and an important paradigm is pre-training and then fine-tuning. Large pre-trained models contain rich representations, which can be adapted to downstream medical tasks. However, existing methods either tune all the parameters or the task-specific layers of the pre-trained models, ignoring the input variations of medical images, and thus they are not efficient or effective. In this work, we aim to study parameter-efficient fine-tuning (PEFT) for medical image analysis, and propose a dynamic visual prompt tuning method, named DVPT. It can extract knowledge beneficial to downstream tasks from large models with a few trainable parameters. Firstly, the frozen features are transformed by an lightweight bottleneck layer to learn the domain-specific distribution of downstream medical tasks, and then a few learnable visual prompts are used as dynamic queries and then conduct cross-attention with the transformed features, attempting to acquire sample-specific knowledge that are suitable for each sample. Finally, the features are projected to original feature dimension and aggregated with the frozen features. This DVPT module can be shared between different Transformer layers, further reducing the trainable parameters. To validate DVPT, we conduct extensive experiments with different pre-trained models on medical classification and segmentation tasks. We find such PEFT method can not only efficiently adapt the pre-trained models to the medical domain, but also brings data efficiency with partial labeled data. For example, with 0.5\\% extra trainable parameters, our method not only outperforms state-of-the-art PEFT methods, even surpasses the full fine-tuning by more than 2.20\\% Kappa score on medical classification task. It can saves up to 60\\% labeled data and 99\\% storage cost of ViT-B/16.","sentences":["Limited labeled data makes it hard to train models from scratch in medical domain, and an important paradigm is pre-training and then fine-tuning.","Large pre-trained models contain rich representations, which can be adapted to downstream medical tasks.","However, existing methods either tune all the parameters or the task-specific layers of the pre-trained models, ignoring the input variations of medical images, and thus they are not efficient or effective.","In this work, we aim to study parameter-efficient fine-tuning (PEFT) for medical image analysis, and propose a dynamic visual prompt tuning method, named DVPT.","It can extract knowledge beneficial to downstream tasks from large models with a few trainable parameters.","Firstly, the frozen features are transformed by an lightweight bottleneck layer to learn the domain-specific distribution of downstream medical tasks, and then a few learnable visual prompts are used as dynamic queries and then conduct cross-attention with the transformed features, attempting to acquire sample-specific knowledge that are suitable for each sample.","Finally, the features are projected to original feature dimension and aggregated with the frozen features.","This DVPT module can be shared between different Transformer layers, further reducing the trainable parameters.","To validate DVPT, we conduct extensive experiments with different pre-trained models on medical classification and segmentation tasks.","We find such PEFT method can not only efficiently adapt the pre-trained models to the medical domain, but also brings data efficiency with partial labeled data.","For example, with 0.5\\% extra trainable parameters, our method not only outperforms state-of-the-art PEFT methods, even surpasses the full fine-tuning by more than 2.20\\% Kappa score on medical classification task.","It can saves up to 60\\% labeled data and 99\\% storage cost of ViT-B/16."],"url":"http://arxiv.org/abs/2307.09787v1"}
{"created":"2023-07-19 06:58:03","title":"ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats","abstract":"In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints for weight quantization that negligibly impact the performance compared to the standard W4A8 model. We additionally enhance our quantization methods by integrating the Low Rank Compensation (LoRC) strategy, yielding improvements especially in smaller models. The results of our investigation emphasize the immense potential of FP quantization for LLMs, paving the way for high-efficiency deployment in resource-limited settings.","sentences":["In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge.","Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution.","Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion.","For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100.","To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints for weight quantization that negligibly impact the performance compared to the standard W4A8 model.","We additionally enhance our quantization methods by integrating the Low Rank Compensation (LoRC) strategy, yielding improvements especially in smaller models.","The results of our investigation emphasize the immense potential of FP quantization for LLMs, paving the way for high-efficiency deployment in resource-limited settings."],"url":"http://arxiv.org/abs/2307.09782v1"}
{"created":"2023-07-19 06:56:07","title":"Text2Layer: Layered Image Generation using Latent Diffusion Model","abstract":"Layer compositing is one of the most popular image editing workflows among both amateurs and professionals. Motivated by the success of diffusion models, we explore layer compositing from a layered image generation perspective. Instead of generating an image, we propose to generate background, foreground, layer mask, and the composed image simultaneously. To achieve layered image generation, we train an autoencoder that is able to reconstruct layered images and train diffusion models on the latent representation. One benefit of the proposed problem is to enable better compositing workflows in addition to the high-quality image output. Another benefit is producing higher-quality layer masks compared to masks produced by a separate step of image segmentation. Experimental results show that the proposed method is able to generate high-quality layered images and initiates a benchmark for future work.","sentences":["Layer compositing is one of the most popular image editing workflows among both amateurs and professionals.","Motivated by the success of diffusion models, we explore layer compositing from a layered image generation perspective.","Instead of generating an image, we propose to generate background, foreground, layer mask, and the composed image simultaneously.","To achieve layered image generation, we train an autoencoder that is able to reconstruct layered images and train diffusion models on the latent representation.","One benefit of the proposed problem is to enable better compositing workflows in addition to the high-quality image output.","Another benefit is producing higher-quality layer masks compared to masks produced by a separate step of image segmentation.","Experimental results show that the proposed method is able to generate high-quality layered images and initiates a benchmark for future work."],"url":"http://arxiv.org/abs/2307.09781v1"}
{"created":"2023-07-19 06:48:33","title":"Beyond Single-Feature Importance with ICECREAM","abstract":"Which set of features was responsible for a certain output of a machine learning model? Which components caused the failure of a cloud computing application? These are just two examples of questions we are addressing in this work by Identifying Coalition-based Explanations for Common and Rare Events in Any Model (ICECREAM). Specifically, we propose an information-theoretic quantitative measure for the influence of a coalition of variables on the distribution of a target variable. This allows us to identify which set of factors is essential to obtain a certain outcome, as opposed to well-established explainability and causal contribution analysis methods which can assign contributions only to individual factors and rank them by their importance. In experiments with synthetic and real-world data, we show that ICECREAM outperforms state-of-the-art methods for explainability and root cause analysis, and achieves impressive accuracy in both tasks.","sentences":["Which set of features was responsible for a certain output of a machine learning model?","Which components caused the failure of a cloud computing application?","These are just two examples of questions we are addressing in this work by Identifying Coalition-based Explanations for Common and Rare Events in Any Model (ICECREAM).","Specifically, we propose an information-theoretic quantitative measure for the influence of a coalition of variables on the distribution of a target variable.","This allows us to identify which set of factors is essential to obtain a certain outcome, as opposed to well-established explainability and causal contribution analysis methods which can assign contributions only to individual factors and rank them by their importance.","In experiments with synthetic and real-world data, we show that ICECREAM outperforms state-of-the-art methods for explainability and root cause analysis, and achieves impressive accuracy in both tasks."],"url":"http://arxiv.org/abs/2307.09779v1"}
{"created":"2023-07-19 06:36:01","title":"Generating Redstone Style Cities in Minecraft","abstract":"Procedurally generating cities in Minecraft provides players more diverse scenarios and could help understand and improve the design of cities in other digital worlds and the real world. This paper presents a city generator that was submitted as an entry to the 2023 Edition of Minecraft Settlement Generation Competition for Minecraft. The generation procedure is composed of six main steps, namely vegetation clearing, terrain reshaping, building layout generation, route planning, streetlight placement, and wall construction. Three algorithms, including a heuristic-based algorithm, an evolving layout algorithm, and a random one are applied to generate the building layout, thus determining where to place different redstone style buildings, and tested by generating cities on random maps in limited time. Experimental results show that the heuristic-based algorithm is capable of finding an acceptable building layout faster for flat maps, while the evolving layout algorithm performs better in evolving layout for rugged maps. A user study is conducted to compare our generator with outstanding entries of the competition's 2022 edition using the competition's evaluation criteria and shows that our generator performs well in the adaptation and functionality criteria","sentences":["Procedurally generating cities in Minecraft provides players more diverse scenarios and could help understand and improve the design of cities in other digital worlds and the real world.","This paper presents a city generator that was submitted as an entry to the 2023 Edition of Minecraft Settlement Generation Competition for Minecraft.","The generation procedure is composed of six main steps, namely vegetation clearing, terrain reshaping, building layout generation, route planning, streetlight placement, and wall construction.","Three algorithms, including a heuristic-based algorithm, an evolving layout algorithm, and a random one are applied to generate the building layout, thus determining where to place different redstone style buildings, and tested by generating cities on random maps in limited time.","Experimental results show that the heuristic-based algorithm is capable of finding an acceptable building layout faster for flat maps, while the evolving layout algorithm performs better in evolving layout for rugged maps.","A user study is conducted to compare our generator with outstanding entries of the competition's 2022 edition using the competition's evaluation criteria and shows that our generator performs well in the adaptation and functionality criteria"],"url":"http://arxiv.org/abs/2307.09777v1"}
{"created":"2023-07-19 06:33:51","title":"LTL Synthesis on Infinite-State Arenas defined by Programs","abstract":"This paper deals with the problem of automatically and correctly controlling infinite-state reactive programs to achieve LTL goals. Applications include adapting a program to new requirements, or to repair bugs discovered in the original specification or program code. Existing approaches are able to solve this problem for safety and some reachability properties, but require an a priori template of the solution for more general properties. Fully automated approaches for full LTL exist, reducing the problem into successive finite LTL reactive synthesis problems in an abstraction-refinement loop. However, they do not terminate when the number of steps to be completed depends on unbounded variables. Our main insight is that safety abstractions of the program are not enough -- fairness properties are also essential to be able to decide many interesting problems, something missed by existing automated approaches. We thus go beyond the state-of-the-art to allow for automated reactive program control for full LTL, with automated discovery of the knowledge, including fairness, of the program needed to determine realisability. We further implement the approach in a tool, with an associated DSL for reactive programs, and illustrate the approach through several case studies.","sentences":["This paper deals with the problem of automatically and correctly controlling infinite-state reactive programs to achieve LTL goals.","Applications include adapting a program to new requirements, or to repair bugs discovered in the original specification or program code.","Existing approaches are able to solve this problem for safety and some reachability properties, but require an a priori template of the solution for more general properties.","Fully automated approaches for full LTL exist, reducing the problem into successive finite LTL reactive synthesis problems in an abstraction-refinement loop.","However, they do not terminate when the number of steps to be completed depends on unbounded variables.","Our main insight is that safety abstractions of the program are not enough -- fairness properties are also essential to be able to decide many interesting problems, something missed by existing automated approaches.","We thus go beyond the state-of-the-art to allow for automated reactive program control for full LTL, with automated discovery of the knowledge, including fairness, of the program needed to determine realisability.","We further implement the approach in a tool, with an associated DSL for reactive programs, and illustrate the approach through several case studies."],"url":"http://arxiv.org/abs/2307.09776v1"}
{"created":"2023-07-19 06:31:58","title":"DisCover: Disentangled Music Representation Learning for Cover Song Identification","abstract":"In the field of music information retrieval (MIR), cover song identification (CSI) is a challenging task that aims to identify cover versions of a query song from a massive collection. Existing works still suffer from high intra-song variances and inter-song correlations, due to the entangled nature of version-specific and version-invariant factors in their modeling. In this work, we set the goal of disentangling version-specific and version-invariant factors, which could make it easier for the model to learn invariant music representations for unseen query songs. We analyze the CSI task in a disentanglement view with the causal graph technique, and identify the intra-version and inter-version effects biasing the invariant learning. To block these effects, we propose the disentangled music representation learning framework (DisCover) for CSI. DisCover consists of two critical components: (1) Knowledge-guided Disentanglement Module (KDM) and (2) Gradient-based Adversarial Disentanglement Module (GADM), which block intra-version and inter-version biased effects, respectively. KDM minimizes the mutual information between the learned representations and version-variant factors that are identified with prior domain knowledge. GADM identifies version-variant factors by simulating the representation transitions between intra-song versions, and exploits adversarial distillation for effect blocking. Extensive comparisons with best-performing methods and in-depth analysis demonstrate the effectiveness of DisCover and the and necessity of disentanglement for CSI.","sentences":["In the field of music information retrieval (MIR), cover song identification (CSI) is a challenging task that aims to identify cover versions of a query song from a massive collection.","Existing works still suffer from high intra-song variances and inter-song correlations, due to the entangled nature of version-specific and version-invariant factors in their modeling.","In this work, we set the goal of disentangling version-specific and version-invariant factors, which could make it easier for the model to learn invariant music representations for unseen query songs.","We analyze the CSI task in a disentanglement view with the causal graph technique, and identify the intra-version and inter-version effects biasing the invariant learning.","To block these effects, we propose the disentangled music representation learning framework (DisCover) for CSI.","DisCover consists of two critical components: (1) Knowledge-guided Disentanglement Module (KDM) and (2) Gradient-based Adversarial Disentanglement Module (GADM), which block intra-version and inter-version biased effects, respectively.","KDM minimizes the mutual information between the learned representations and version-variant factors that are identified with prior domain knowledge.","GADM identifies version-variant factors by simulating the representation transitions between intra-song versions, and exploits adversarial distillation for effect blocking.","Extensive comparisons with best-performing methods and in-depth analysis demonstrate the effectiveness of DisCover and the and necessity of disentanglement for CSI."],"url":"http://arxiv.org/abs/2307.09775v1"}
{"created":"2023-07-19 06:07:12","title":"Source-Free Domain Adaptation for Medical Image Segmentation via Prototype-Anchored Feature Alignment and Contrastive Learning","abstract":"Unsupervised domain adaptation (UDA) has increasingly gained interests for its capacity to transfer the knowledge learned from a labeled source domain to an unlabeled target domain. However, typical UDA methods require concurrent access to both the source and target domain data, which largely limits its application in medical scenarios where source data is often unavailable due to privacy concern. To tackle the source data-absent problem, we present a novel two-stage source-free domain adaptation (SFDA) framework for medical image segmentation, where only a well-trained source segmentation model and unlabeled target data are available during domain adaptation. Specifically, in the prototype-anchored feature alignment stage, we first utilize the weights of the pre-trained pixel-wise classifier as source prototypes, which preserve the information of source features. Then, we introduce the bi-directional transport to align the target features with class prototypes by minimizing its expected cost. On top of that, a contrastive learning stage is further devised to utilize those pixels with unreliable predictions for a more compact target feature distribution. Extensive experiments on a cross-modality medical segmentation task demonstrate the superiority of our method in large domain discrepancy settings compared with the state-of-the-art SFDA approaches and even some UDA methods. Code is available at https://github.com/CSCYQJ/MICCAI23-ProtoContra-SFDA.","sentences":["Unsupervised domain adaptation (UDA) has increasingly gained interests for its capacity to transfer the knowledge learned from a labeled source domain to an unlabeled target domain.","However, typical UDA methods require concurrent access to both the source and target domain data, which largely limits its application in medical scenarios where source data is often unavailable due to privacy concern.","To tackle the source data-absent problem, we present a novel two-stage source-free domain adaptation (SFDA) framework for medical image segmentation, where only a well-trained source segmentation model and unlabeled target data are available during domain adaptation.","Specifically, in the prototype-anchored feature alignment stage, we first utilize the weights of the pre-trained pixel-wise classifier as source prototypes, which preserve the information of source features.","Then, we introduce the bi-directional transport to align the target features with class prototypes by minimizing its expected cost.","On top of that, a contrastive learning stage is further devised to utilize those pixels with unreliable predictions for a more compact target feature distribution.","Extensive experiments on a cross-modality medical segmentation task demonstrate the superiority of our method in large domain discrepancy settings compared with the state-of-the-art SFDA approaches and even some UDA methods.","Code is available at https://github.com/CSCYQJ/MICCAI23-ProtoContra-SFDA."],"url":"http://arxiv.org/abs/2307.09769v1"}
{"created":"2023-07-19 06:05:33","title":"How Curvature Enhance the Adaptation Power of Framelet GCNs","abstract":"Graph neural network (GNN) has been demonstrated powerful in modeling graph-structured data. However, despite many successful cases of applying GNNs to various graph classification and prediction tasks, whether the graph geometrical information has been fully exploited to enhance the learning performance of GNNs is not yet well understood. This paper introduces a new approach to enhance GNN by discrete graph Ricci curvature. Specifically, the graph Ricci curvature defined on the edges of a graph measures how difficult the information transits on one edge from one node to another based on their neighborhoods. Motivated by the geometric analogy of Ricci curvature in the graph setting, we prove that by inserting the curvature information with different carefully designed transformation function $\\zeta$, several known computational issues in GNN such as over-smoothing can be alleviated in our proposed model. Furthermore, we verified that edges with very positive Ricci curvature (i.e., $\\kappa_{i,j} \\approx 1$) are preferred to be dropped to enhance model's adaption to heterophily graph and one curvature based graph edge drop algorithm is proposed. Comprehensive experiments show that our curvature-based GNN model outperforms the state-of-the-art baselines in both homophily and heterophily graph datasets, indicating the effectiveness of involving graph geometric information in GNNs.","sentences":["Graph neural network (GNN) has been demonstrated powerful in modeling graph-structured data.","However, despite many successful cases of applying GNNs to various graph classification and prediction tasks, whether the graph geometrical information has been fully exploited to enhance the learning performance of GNNs is not yet well understood.","This paper introduces a new approach to enhance GNN by discrete graph Ricci curvature.","Specifically, the graph Ricci curvature defined on the edges of a graph measures how difficult the information transits on one edge from one node to another based on their neighborhoods.","Motivated by the geometric analogy of Ricci curvature in the graph setting, we prove that by inserting the curvature information with different carefully designed transformation function $\\zeta$, several known computational issues in GNN such as over-smoothing can be alleviated in our proposed model.","Furthermore, we verified that edges with very positive Ricci curvature (i.e., $\\kappa_{i,j} \\approx 1$) are preferred to be dropped to enhance model's adaption to heterophily graph and one curvature based graph edge drop algorithm is proposed.","Comprehensive experiments show that our curvature-based GNN model outperforms the state-of-the-art baselines in both homophily and heterophily graph datasets, indicating the effectiveness of involving graph geometric information in GNNs."],"url":"http://arxiv.org/abs/2307.09768v1"}
{"created":"2023-07-19 05:58:21","title":"Sig-Splines: universal approximation and convex calibration of time series generative models","abstract":"We propose a novel generative model for multivariate discrete-time time series data. Drawing inspiration from the construction of neural spline flows, our algorithm incorporates linear transformations and the signature transform as a seamless substitution for traditional neural networks. This approach enables us to achieve not only the universality property inherent in neural networks but also introduces convexity in the model's parameters.","sentences":["We propose a novel generative model for multivariate discrete-time time series data.","Drawing inspiration from the construction of neural spline flows, our algorithm incorporates linear transformations and the signature transform as a seamless substitution for traditional neural networks.","This approach enables us to achieve not only the universality property inherent in neural networks but also introduces convexity in the model's parameters."],"url":"http://arxiv.org/abs/2307.09767v1"}
{"created":"2023-07-19 05:54:43","title":"Are We Ready to Embrace Generative AI for Software Q&A?","abstract":"Stack Overflow, the world's largest software Q&A (SQA) website, is facing a significant traffic drop due to the emergence of generative AI techniques. ChatGPT is banned by Stack Overflow after only 6 days from its release. The main reason provided by the official Stack Overflow is that the answers generated by ChatGPT are of low quality. To verify this, we conduct a comparative evaluation of human-written and ChatGPT-generated answers. Our methodology employs both automatic comparison and a manual study. Our results suggest that human-written and ChatGPT-generated answers are semantically similar, however, human-written answers outperform ChatGPT-generated ones consistently across multiple aspects, specifically by 10% on the overall score. We release the data, analysis scripts, and detailed results at https://anonymous.4open.science/r/GAI4SQA-FD5C.","sentences":["Stack Overflow, the world's largest software Q&A (SQA) website, is facing a significant traffic drop due to the emergence of generative AI techniques.","ChatGPT is banned by Stack Overflow after only 6 days from its release.","The main reason provided by the official Stack Overflow is that the answers generated by ChatGPT are of low quality.","To verify this, we conduct a comparative evaluation of human-written and ChatGPT-generated answers.","Our methodology employs both automatic comparison and a manual study.","Our results suggest that human-written and ChatGPT-generated answers are semantically similar, however, human-written answers outperform ChatGPT-generated ones consistently across multiple aspects, specifically by 10% on the overall score.","We release the data, analysis scripts, and detailed results at https://anonymous.4open.science/r/GAI4SQA-FD5C."],"url":"http://arxiv.org/abs/2307.09765v1"}
{"created":"2023-07-19 05:46:56","title":"Towards Building More Robust Models with Frequency Bias","abstract":"The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad applications, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters directly to input images leads to irreversible loss of discriminative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference Control Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representations, providing better utilization of frequency in robust learning. Empirical studies show that our proposed module can be easily incorporated into any adversarial training framework, further improving model robustness across different architectures and datasets. Additionally, experiments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights.","sentences":["The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad applications, despite their success in various fields.","Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness.","While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters directly to input images leads to irreversible loss of discriminative information and poor generalizability to datasets with distinct frequency features.","This paper presents a plug-and-play module called the Frequency Preference Control Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representations, providing better utilization of frequency in robust learning.","Empirical studies show that our proposed module can be easily incorporated into any adversarial training framework, further improving model robustness across different architectures and datasets.","Additionally, experiments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights."],"url":"http://arxiv.org/abs/2307.09763v1"}
{"created":"2023-07-19 05:45:05","title":"Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition","abstract":"Complex networks are used to model many real-world systems. However, the dimensionality of these systems can make them challenging to analyze. Dimensionality reduction techniques like POD can be used in such cases. However, these models are susceptible to perturbations in the input data. We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models. The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs. Deep Neural Networks (DNNs) are susceptible to adversarial attacks. However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications. We benchmark our algorithmic framework with a Neural ODE-based approach as a reference.","sentences":["Complex networks are used to model many real-world systems.","However, the dimensionality of these systems can make them challenging to analyze.","Dimensionality reduction techniques like POD can be used in such cases.","However, these models are susceptible to perturbations in the input data.","We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models.","The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs.","Deep Neural Networks (DNNs) are susceptible to adversarial attacks.","However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications.","We benchmark our algorithmic framework with a Neural ODE-based approach as a reference."],"url":"http://arxiv.org/abs/2307.09762v1"}
{"created":"2023-07-19 05:43:30","title":"On the Tractability of Defensive Alliance Problem","abstract":"Given a graph $G = (V, E)$, a non-empty set $S \\subseteq V$ is a defensive alliance, if for every vertex $v \\in S$, the majority of its closed neighbours are in $S$, that is, $|N_G[v] \\cap S| \\geq |N_G[v] \\setminus S|$. The decision version of the problem is known to be NP-Complete even when restricted to split and bipartite graphs. The problem is \\textit{fixed-parameter tractable} for the parameters solution size, vertex cover number and neighbourhood diversity. For the parameters treewidth and feedback vertex set number, the problem is W[1]-hard. \\\\ \\hspace*{2em} In this paper, we study the defensive alliance problem for graphs with bounded degree. We show that the problem is \\textit{polynomial-time solvable} on graphs with maximum degree at most 5 and NP-Complete on graphs with maximum degree 6. This rules out the fixed-parameter tractability of the problem for the parameter maximum degree of the graph. We also consider the problem from the standpoint of parameterized complexity. We provide an FPT algorithm using the Integer Linear Programming approach for the parameter distance to clique. We also answer an open question posed in \\cite{AG2} by providing an FPT algorithm for the parameter twin cover.","sentences":["Given a graph $G = (V, E)$, a non-empty set $S \\subseteq V$ is a defensive alliance, if for every vertex $v \\in S$, the majority of its closed neighbours are in $S$, that is, $|N_G[v] \\cap S| \\geq |N_G[v]","\\setminus S|$.","The decision version of the problem is known to be NP-Complete even when restricted to split and bipartite graphs.","The problem is \\textit{fixed-parameter tractable} for the parameters solution size, vertex cover number and neighbourhood diversity.","For the parameters treewidth and feedback vertex set number, the problem is W[1]-hard. \\\\ \\hspace*{2em} In this paper, we study the defensive alliance problem for graphs with bounded degree.","We show that the problem is \\textit{polynomial-time solvable} on graphs with maximum degree at most 5 and NP-Complete on graphs with maximum degree 6.","This rules out the fixed-parameter tractability of the problem for the parameter maximum degree of the graph.","We also consider the problem from the standpoint of parameterized complexity.","We provide an FPT algorithm using the Integer Linear Programming approach for the parameter distance to clique.","We also answer an open question posed in \\cite{AG2} by providing an FPT algorithm for the parameter twin cover."],"url":"http://arxiv.org/abs/2307.09760v1"}
{"created":"2023-07-19 05:41:40","title":"Constructing Extreme Learning Machines with zero Spectral Bias","abstract":"The phenomena of Spectral Bias, where the higher frequency components of a function being learnt in a feedforward Artificial Neural Network (ANN) are seen to converge more slowly than the lower frequencies, is observed ubiquitously across ANNs. This has created technology challenges in fields where resolution of higher frequencies is crucial, like in Physics Informed Neural Networks (PINNs). Extreme Learning Machines (ELMs) that obviate an iterative solution process which provides the theoretical basis of Spectral Bias (SB), should in principle be free of the same. This work verifies the reliability of this assumption, and shows that it is incorrect. However, the structure of ELMs makes them naturally amenable to implementation of variants of Fourier Feature Embeddings, which have been shown to mitigate SB in ANNs. This approach is implemented and verified to completely eliminate SB, thus bringing into feasibility the application of ELMs for practical problems like PINNs where resolution of higher frequencies is essential.","sentences":["The phenomena of Spectral Bias, where the higher frequency components of a function being learnt in a feedforward Artificial Neural Network (ANN) are seen to converge more slowly than the lower frequencies, is observed ubiquitously across ANNs.","This has created technology challenges in fields where resolution of higher frequencies is crucial, like in Physics Informed Neural Networks (PINNs).","Extreme Learning Machines (ELMs) that obviate an iterative solution process which provides the theoretical basis of Spectral Bias (SB), should in principle be free of the same.","This work verifies the reliability of this assumption, and shows that it is incorrect.","However, the structure of ELMs makes them naturally amenable to implementation of variants of Fourier Feature Embeddings, which have been shown to mitigate SB in ANNs.","This approach is implemented and verified to completely eliminate SB, thus bringing into feasibility the application of ELMs for practical problems like PINNs where resolution of higher frequencies is essential."],"url":"http://arxiv.org/abs/2307.09759v1"}
{"created":"2023-07-19 05:41:14","title":"Longitudinal Data and a Semantic Similarity Reward for Chest X-Ray Report Generation","abstract":"Chest X-Ray (CXR) report generation is a promising approach to improving the efficiency of CXR interpretation. However, a significant increase in diagnostic accuracy is required before that can be realised. Motivated by this, we propose a framework that is more inline with a radiologist's workflow by considering longitudinal data. Here, the decoder is additionally conditioned on the report from the subject's previous imaging study via a prompt. We also propose a new reward for reinforcement learning based on CXR-BERT, which computes the similarity between reports. We conduct experiments on the MIMIC-CXR dataset. The results indicate that longitudinal data improves CXR report generation. CXR-BERT is also shown to be a promising alternative to the current state-of-the-art reward based on RadGraph. This investigation indicates that longitudinal CXR report generation can offer a substantial increase in diagnostic accuracy. Our Hugging Face model is available at: https://huggingface.co/aehrc/cxrmate and code is available at: https://github.com/aehrc/cxrmate.","sentences":["Chest X-Ray (CXR) report generation is a promising approach to improving the efficiency of CXR interpretation.","However, a significant increase in diagnostic accuracy is required before that can be realised.","Motivated by this, we propose a framework that is more inline with a radiologist's workflow by considering longitudinal data.","Here, the decoder is additionally conditioned on the report from the subject's previous imaging study via a prompt.","We also propose a new reward for reinforcement learning based on CXR-BERT, which computes the similarity between reports.","We conduct experiments on the MIMIC-CXR dataset.","The results indicate that longitudinal data improves CXR report generation.","CXR-BERT is also shown to be a promising alternative to the current state-of-the-art reward based on RadGraph.","This investigation indicates that longitudinal CXR report generation can offer a substantial increase in diagnostic accuracy.","Our Hugging Face model is available at: https://huggingface.co/aehrc/cxrmate and code is available at: https://github.com/aehrc/cxrmate."],"url":"http://arxiv.org/abs/2307.09758v1"}
{"created":"2023-07-19 05:40:38","title":"Generative Prompt Model for Weakly Supervised Object Localization","abstract":"Weakly supervised object localization (WSOL) remains challenging when learning object localization models from image category labels. Conventional methods that discriminatively train activation models ignore representative yet less discriminative object parts. In this study, we propose a generative prompt model (GenPromp), defining the first generative pipeline to localize less discriminative object parts by formulating WSOL as a conditional image denoising procedure. During training, GenPromp converts image category labels to learnable prompt embeddings which are fed to a generative model to conditionally recover the input image with noise and learn representative embeddings. During inference, enPromp combines the representative embeddings with discriminative embeddings (queried from an off-the-shelf vision-language model) for both representative and discriminative capacity. The combined embeddings are finally used to generate multi-scale high-quality attention maps, which facilitate localizing full object extent. Experiments on CUB-200-2011 and ILSVRC show that GenPromp respectively outperforms the best discriminative models by 5.2% and 5.6% (Top-1 Loc), setting a solid baseline for WSOL with the generative model. Code is available at https://github.com/callsys/GenPromp.","sentences":["Weakly supervised object localization (WSOL) remains challenging when learning object localization models from image category labels.","Conventional methods that discriminatively train activation models ignore representative yet less discriminative object parts.","In this study, we propose a generative prompt model (GenPromp), defining the first generative pipeline to localize less discriminative object parts by formulating WSOL as a conditional image denoising procedure.","During training, GenPromp converts image category labels to learnable prompt embeddings which are fed to a generative model to conditionally recover the input image with noise and learn representative embeddings.","During inference, enPromp combines the representative embeddings with discriminative embeddings (queried from an off-the-shelf vision-language model) for both representative and discriminative capacity.","The combined embeddings are finally used to generate multi-scale high-quality attention maps, which facilitate localizing full object extent.","Experiments on CUB-200-2011 and ILSVRC show that GenPromp respectively outperforms the best discriminative models by 5.2% and 5.6% (Top-1 Loc), setting a solid baseline for WSOL with the generative model.","Code is available at https://github.com/callsys/GenPromp."],"url":"http://arxiv.org/abs/2307.09756v1"}
{"created":"2023-07-19 05:39:15","title":"Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation","abstract":"Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model with limited labeled images and a substantial volume of unlabeled images. To improve the robustness of representations, powerful methods introduce a pixel-wise contrastive learning approach in latent space (i.e., representation space) that aggregates the representations to their prototypes in a fully supervised manner. However, previous contrastive-based S4 methods merely rely on the supervision from the model's output (logits) in logit space during unlabeled training. In contrast, we utilize the outputs in both logit space and representation space to obtain supervision in a collaborative way. The supervision from two spaces plays two roles: 1) reduces the risk of over-fitting to incorrect semantic information in logits with the help of representations; 2) enhances the knowledge exchange between the two spaces. Furthermore, unlike previous approaches, we use the similarity between representations and prototypes as a new indicator to tilt training those under-performing representations and achieve a more efficient contrastive learning process. Results on two public benchmarks demonstrate the competitive performance of our method compared with state-of-the-art methods.","sentences":["Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model with limited labeled images and a substantial volume of unlabeled images.","To improve the robustness of representations, powerful methods introduce a pixel-wise contrastive learning approach in latent space (i.e., representation space) that aggregates the representations to their prototypes in a fully supervised manner.","However, previous contrastive-based S4 methods merely rely on the supervision from the model's output (logits) in logit space during unlabeled training.","In contrast, we utilize the outputs in both logit space and representation space to obtain supervision in a collaborative way.","The supervision from two spaces plays two roles: 1) reduces the risk of over-fitting to incorrect semantic information in logits with the help of representations; 2) enhances the knowledge exchange between the two spaces.","Furthermore, unlike previous approaches, we use the similarity between representations and prototypes as a new indicator to tilt training those under-performing representations and achieve a more efficient contrastive learning process.","Results on two public benchmarks demonstrate the competitive performance of our method compared with state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.09755v1"}
{"created":"2023-07-19 05:34:15","title":"ProNav: Proprioceptive Traversability Estimation for Autonomous Legged Robot Navigation in Outdoor Environments","abstract":"We propose a novel method, ProNav, which uses proprioceptive signals for traversability estimation in challenging outdoor terrains for autonomous legged robot navigation. Our approach uses sensor data from a legged robot's joint encoders, force, and current sensors to measure the joint positions, forces, and current consumption respectively to accurately assess a terrain's stability, resistance to the robot's motion, risk of entrapment, and crash. Based on these factors, we compute the appropriate robot trajectories and gait to maximize stability and minimize energy consumption. Our approach can also be used to predict imminent crashes in challenging terrains and execute behaviors to preemptively avoid them. We integrate ProNav with a method to navigate dense vegetation and demonstrate our method's benefits in real-world terrains with dense bushes, high granularity, negative obstacles, etc. Our method shows an improvement up to 50% in terms of success rate and up to 35% in terms of energy efficiency.","sentences":["We propose a novel method, ProNav, which uses proprioceptive signals for traversability estimation in challenging outdoor terrains for autonomous legged robot navigation.","Our approach uses sensor data from a legged robot's joint encoders, force, and current sensors to measure the joint positions, forces, and current consumption respectively to accurately assess a terrain's stability, resistance to the robot's motion, risk of entrapment, and crash.","Based on these factors, we compute the appropriate robot trajectories and gait to maximize stability and minimize energy consumption.","Our approach can also be used to predict imminent crashes in challenging terrains and execute behaviors to preemptively avoid them.","We integrate ProNav with a method to navigate dense vegetation and demonstrate our method's benefits in real-world terrains with dense bushes, high granularity, negative obstacles, etc.","Our method shows an improvement up to 50% in terms of success rate and up to 35% in terms of energy efficiency."],"url":"http://arxiv.org/abs/2307.09754v1"}
{"created":"2023-07-19 05:26:10","title":"Unmaking AI Imagemaking: A Methodological Toolkit for Critical Investigation","abstract":"AI image models are rapidly evolving, disrupting aesthetic production in many industries. However, understanding of their underlying archives, their logic of image reproduction, and their persistent biases remains limited. What kind of methods and approaches could open up these black boxes? In this paper, we provide three methodological approaches for investigating AI image models and apply them to Stable Diffusion as a case study. Unmaking the ecosystem analyzes the values, structures, and incentives surrounding the model's production. Unmaking the data analyzes the images and text the model draws upon, with their attendant particularities and biases. Unmaking the output analyzes the model's generative results, revealing its logics through prompting, reflection, and iteration. Each mode of inquiry highlights particular ways in which the image model captures, \"understands,\" and recreates the world. This accessible framework supports the work of critically investigating generative AI image models and paves the way for more socially and politically attuned analyses of their impacts in the world.","sentences":["AI image models are rapidly evolving, disrupting aesthetic production in many industries.","However, understanding of their underlying archives, their logic of image reproduction, and their persistent biases remains limited.","What kind of methods and approaches could open up these black boxes?","In this paper, we provide three methodological approaches for investigating AI image models and apply them to Stable Diffusion as a case study.","Unmaking the ecosystem analyzes the values, structures, and incentives surrounding the model's production.","Unmaking the data analyzes the images and text the model draws upon, with their attendant particularities and biases.","Unmaking the output analyzes the model's generative results, revealing its logics through prompting, reflection, and iteration.","Each mode of inquiry highlights particular ways in which the image model captures, \"understands,\" and recreates the world.","This accessible framework supports the work of critically investigating generative AI image models and paves the way for more socially and politically attuned analyses of their impacts in the world."],"url":"http://arxiv.org/abs/2307.09753v1"}
{"created":"2023-07-19 05:23:43","title":"Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community","abstract":"The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges.","sentences":["The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs.","Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research.","LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions.","More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking.","IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services.","Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations.","To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights.","This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges."],"url":"http://arxiv.org/abs/2307.09751v1"}
{"created":"2023-07-19 05:08:47","title":"Towards Robust Scene Text Image Super-resolution via Explicit Location Enhancement","abstract":"Scene text image super-resolution (STISR), aiming to improve image quality while boosting downstream scene text recognition accuracy, has recently achieved great success. However, most existing methods treat the foreground (character regions) and background (non-character regions) equally in the forward process, and neglect the disturbance from the complex background, thus limiting the performance. To address these issues, in this paper, we propose a novel method LEMMA that explicitly models character regions to produce high-level text-specific guidance for super-resolution. To model the location of characters effectively, we propose the location enhancement module to extract character region features based on the attention map sequence. Besides, we propose the multi-modal alignment module to perform bidirectional visual-semantic alignment to generate high-quality prior guidance, which is then incorporated into the super-resolution branch in an adaptive manner using the proposed adaptive fusion module. Experiments on TextZoom and four scene text recognition benchmarks demonstrate the superiority of our method over other state-of-the-art methods. Code is available at https://github.com/csguoh/LEMMA.","sentences":["Scene text image super-resolution (STISR), aiming to improve image quality while boosting downstream scene text recognition accuracy, has recently achieved great success.","However, most existing methods treat the foreground (character regions) and background (non-character regions) equally in the forward process, and neglect the disturbance from the complex background, thus limiting the performance.","To address these issues, in this paper, we propose a novel method LEMMA that explicitly models character regions to produce high-level text-specific guidance for super-resolution.","To model the location of characters effectively, we propose the location enhancement module to extract character region features based on the attention map sequence.","Besides, we propose the multi-modal alignment module to perform bidirectional visual-semantic alignment to generate high-quality prior guidance, which is then incorporated into the super-resolution branch in an adaptive manner using the proposed adaptive fusion module.","Experiments on TextZoom and four scene text recognition benchmarks demonstrate the superiority of our method over other state-of-the-art methods.","Code is available at https://github.com/csguoh/LEMMA."],"url":"http://arxiv.org/abs/2307.09749v1"}
{"created":"2023-07-19 04:59:58","title":"Watch out Venomous Snake Species: A Solution to SnakeCLEF2023","abstract":"The SnakeCLEF2023 competition aims to the development of advanced algorithms for snake species identification through the analysis of images and accompanying metadata. This paper presents a method leveraging utilization of both images and metadata. Modern CNN models and strong data augmentation are utilized to learn better representation of images. To relieve the challenge of long-tailed distribution, seesaw loss is utilized in our method. We also design a light model to calculate prior probabilities using metadata features extracted from CLIP in post processing stage. Besides, we attach more importance to venomous species by assigning venomous species labels to some examples that model is uncertain about. Our method achieves 91.31% score of the final metric combined of F1 and other metrics on private leaderboard, which is the 1st place among the participators. The code is available at https://github.com/xiaoxsparraw/CLEF2023.","sentences":["The SnakeCLEF2023 competition aims to the development of advanced algorithms for snake species identification through the analysis of images and accompanying metadata.","This paper presents a method leveraging utilization of both images and metadata.","Modern CNN models and strong data augmentation are utilized to learn better representation of images.","To relieve the challenge of long-tailed distribution, seesaw loss is utilized in our method.","We also design a light model to calculate prior probabilities using metadata features extracted from CLIP in post processing stage.","Besides, we attach more importance to venomous species by assigning venomous species labels to some examples that model is uncertain about.","Our method achieves 91.31% score of the final metric combined of F1 and other metrics on private leaderboard, which is the 1st place among the participators.","The code is available at https://github.com/xiaoxsparraw/CLEF2023."],"url":"http://arxiv.org/abs/2307.09748v1"}
{"created":"2023-07-19 04:25:21","title":"Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction","abstract":"The integration of natural language processing (NLP) technologies into educational applications has shown promising results, particularly in the language learning domain. Recently, many spoken open-domain chatbots have been used as speaking partners, helping language learners improve their language skills. However, one of the significant challenges is the high word-error-rate (WER) when recognizing non-native/non-fluent speech, which interrupts conversation flow and leads to disappointment for learners. This paper explores the use of GPT4 for ASR error correction in conversational settings. In addition to WER, we propose to use semantic textual similarity (STS) and next response sensibility (NRS) metrics to evaluate the impact of error correction models on the quality of the conversation. We find that transcriptions corrected by GPT4 lead to higher conversation quality, despite an increase in WER. GPT4 also outperforms standard error correction methods without the need for in-domain training data.","sentences":["The integration of natural language processing (NLP) technologies into educational applications has shown promising results, particularly in the language learning domain.","Recently, many spoken open-domain chatbots have been used as speaking partners, helping language learners improve their language skills.","However, one of the significant challenges is the high word-error-rate (WER) when recognizing non-native/non-fluent speech, which interrupts conversation flow and leads to disappointment for learners.","This paper explores the use of GPT4 for ASR error correction in conversational settings.","In addition to WER, we propose to use semantic textual similarity (STS) and next response sensibility (NRS) metrics to evaluate the impact of error correction models on the quality of the conversation.","We find that transcriptions corrected by GPT4 lead to higher conversation quality, despite an increase in WER.","GPT4 also outperforms standard error correction methods without the need for in-domain training data."],"url":"http://arxiv.org/abs/2307.09744v1"}
{"created":"2023-07-19 04:07:33","title":"Improved Distribution Matching for Dataset Condensation","abstract":"Dataset Condensation aims to condense a large dataset into a smaller one while maintaining its ability to train a well-performing model, thus reducing the storage cost and training effort in deep learning applications. However, conventional dataset condensation methods are optimization-oriented and condense the dataset by performing gradient or parameter matching during model optimization, which is computationally intensive even on small datasets and models. In this paper, we propose a novel dataset condensation method based on distribution matching, which is more efficient and promising. Specifically, we identify two important shortcomings of naive distribution matching (i.e., imbalanced feature numbers and unvalidated embeddings for distance computation) and address them with three novel techniques (i.e., partitioning and expansion augmentation, efficient and enriched model sampling, and class-aware distribution regularization). Our simple yet effective method outperforms most previous optimization-oriented methods with much fewer computational resources, thereby scaling data condensation to larger datasets and models. Extensive experiments demonstrate the effectiveness of our method. Codes are available at https://github.com/uitrbn/IDM","sentences":["Dataset Condensation aims to condense a large dataset into a smaller one while maintaining its ability to train a well-performing model, thus reducing the storage cost and training effort in deep learning applications.","However, conventional dataset condensation methods are optimization-oriented and condense the dataset by performing gradient or parameter matching during model optimization, which is computationally intensive even on small datasets and models.","In this paper, we propose a novel dataset condensation method based on distribution matching, which is more efficient and promising.","Specifically, we identify two important shortcomings of naive distribution matching (i.e., imbalanced feature numbers and unvalidated embeddings for distance computation) and address them with three novel techniques (i.e., partitioning and expansion augmentation, efficient and enriched model sampling, and class-aware distribution regularization).","Our simple yet effective method outperforms most previous optimization-oriented methods with much fewer computational resources, thereby scaling data condensation to larger datasets and models.","Extensive experiments demonstrate the effectiveness of our method.","Codes are available at https://github.com/uitrbn/IDM"],"url":"http://arxiv.org/abs/2307.09742v1"}
{"created":"2023-07-19 03:08:44","title":"Reduction of the secret key length in the perfect cipher by data compression and randomisation","abstract":"Perfect ciphers have been a very attractive cryptographic tool ever since C. Shannon described them. Note that, by definition, if a perfect cipher is used, no one can get any information about the encrypted message without knowing the secret key. We consider the problem of reducing the key length of perfect ciphers, because in many applications the length of the secret key is a crucial parameter. This paper describes a simple method of key length reduction. This method gives a perfect cipher and is based on the use of data compression and randomisation, and the average key length can be made close to Shannon entropy (which is the key length limit). It should be noted that the method can effectively use readily available data compressors (archivers).","sentences":["Perfect ciphers have been a very attractive cryptographic tool ever since C. Shannon described them.","Note that, by definition, if a perfect cipher is used, no one can get any information about the encrypted message without knowing the secret key.","We consider the problem of reducing the key length of perfect ciphers, because in many applications the length of the secret key is a crucial parameter.","This paper describes a simple method of key length reduction.","This method gives a perfect cipher and is based on the use of data compression and randomisation, and the average key length can be made close to Shannon entropy (which is the key length limit).","It should be noted that the method can effectively use readily available data compressors (archivers)."],"url":"http://arxiv.org/abs/2307.09735v1"}
{"created":"2023-07-19 02:49:44","title":"ClickSeg: 3D Instance Segmentation with Click-Level Weak Annotations","abstract":"3D instance segmentation methods often require fully-annotated dense labels for training, which are costly to obtain. In this paper, we present ClickSeg, a novel click-level weakly supervised 3D instance segmentation method that requires one point per instance annotation merely. Such a problem is very challenging due to the extremely limited labels, which has rarely been solved before. We first develop a baseline weakly-supervised training method, which generates pseudo labels for unlabeled data by the model itself. To utilize the property of click-level annotation setting, we further propose a new training framework. Instead of directly using the model inference way, i.e., mean-shift clustering, to generate the pseudo labels, we propose to use k-means with fixed initial seeds: the annotated points. New similarity metrics are further designed for clustering. Experiments on ScanNetV2 and S3DIS datasets show that the proposed ClickSeg surpasses the previous best weakly supervised instance segmentation result by a large margin (e.g., +9.4% mAP on ScanNetV2). Using 0.02% supervision signals merely, ClickSeg achieves $\\sim$90% of the accuracy of the fully-supervised counterpart. Meanwhile, it also achieves state-of-the-art semantic segmentation results among weakly supervised methods that use the same annotation settings.","sentences":["3D instance segmentation methods often require fully-annotated dense labels for training, which are costly to obtain.","In this paper, we present ClickSeg, a novel click-level weakly supervised 3D instance segmentation method that requires one point per instance annotation merely.","Such a problem is very challenging due to the extremely limited labels, which has rarely been solved before.","We first develop a baseline weakly-supervised training method, which generates pseudo labels for unlabeled data by the model itself.","To utilize the property of click-level annotation setting, we further propose a new training framework.","Instead of directly using the model inference way, i.e., mean-shift clustering, to generate the pseudo labels, we propose to use k-means with fixed initial seeds: the annotated points.","New similarity metrics are further designed for clustering.","Experiments on ScanNetV2 and S3DIS datasets show that the proposed ClickSeg surpasses the previous best weakly supervised instance segmentation result by a large margin (e.g., +9.4% mAP on ScanNetV2).","Using 0.02% supervision signals merely, ClickSeg achieves $\\sim$90% of the accuracy of the fully-supervised counterpart.","Meanwhile, it also achieves state-of-the-art semantic segmentation results among weakly supervised methods that use the same annotation settings."],"url":"http://arxiv.org/abs/2307.09732v1"}
{"created":"2023-07-19 02:47:58","title":"AcousTac: Tactile sensing with acoustic resonance for electronics-free soft skin","abstract":"Sound is a rich information medium that transmits through air; people communicate through speech and can even discern material through tapping and listening. To capture frequencies in the human hearing range, commercial microphones typically have a sampling rate of over 40kHz. These accessible acoustic technologies are not yet widely adopted for the explicit purpose of giving robots a sense of touch. Some researchers have used sound to sense tactile information, both monitoring ambient soundscape and with embedded speakers and microphones to measure sounds within structures. However, these options commonly do not provide a direct measure of steady state force, or require electronics integrated somewhere near the contact location. In this work, we present AcousTac, an acoustic tactile sensor for electronics-free force sensitive soft skin. Compliant silicone caps and plastic tubes compose the resonant chambers that emit pneumatic-driven sound measurable with a conventional off-board microphone. The resulting frequency changes depend on the external loads on the compliant end caps. We can tune each AcousTac taxel to specific force and frequency ranges, based on geometric parameters, including tube length and end-cap geometry and thus uniquely sense each taxel simultaneously in an array. We demonstrate AcousTac's functionality on two robotic systems: a 4-taxel array and a 3-taxel astrictive gripper. AcousTac is a promising concept for force sensing on soft robotic surfaces, especially in situations where electronics near the contact are not suitable. Equipping robots with tactile sensing and soft skin provides them with a sense of touch and the ability to safely interact with their surroundings.","sentences":["Sound is a rich information medium that transmits through air; people communicate through speech and can even discern material through tapping and listening.","To capture frequencies in the human hearing range, commercial microphones typically have a sampling rate of over 40kHz.","These accessible acoustic technologies are not yet widely adopted for the explicit purpose of giving robots a sense of touch.","Some researchers have used sound to sense tactile information, both monitoring ambient soundscape and with embedded speakers and microphones to measure sounds within structures.","However, these options commonly do not provide a direct measure of steady state force, or require electronics integrated somewhere near the contact location.","In this work, we present AcousTac, an acoustic tactile sensor for electronics-free force sensitive soft skin.","Compliant silicone caps and plastic tubes compose the resonant chambers that emit pneumatic-driven sound measurable with a conventional off-board microphone.","The resulting frequency changes depend on the external loads on the compliant end caps.","We can tune each AcousTac taxel to specific force and frequency ranges, based on geometric parameters, including tube length and end-cap geometry and thus uniquely sense each taxel simultaneously in an array.","We demonstrate AcousTac's functionality on two robotic systems: a 4-taxel array and a 3-taxel astrictive gripper.","AcousTac is a promising concept for force sensing on soft robotic surfaces, especially in situations where electronics near the contact are not suitable.","Equipping robots with tactile sensing and soft skin provides them with a sense of touch and the ability to safely interact with their surroundings."],"url":"http://arxiv.org/abs/2307.09730v1"}
{"created":"2023-07-19 02:33:42","title":"NTIRE 2023 Quality Assessment of Video Enhancement Challenge","abstract":"This paper reports on the NTIRE 2023 Quality Assessment of Video Enhancement Challenge, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2023. This challenge is to address a major challenge in the field of video processing, namely, video quality assessment (VQA) for enhanced videos. The challenge uses the VQA Dataset for Perceptual Video Enhancement (VDPVE), which has a total of 1211 enhanced videos, including 600 videos with color, brightness, and contrast enhancements, 310 videos with deblurring, and 301 deshaked videos. The challenge has a total of 167 registered participants. 61 participating teams submitted their prediction results during the development phase, with a total of 3168 submissions. A total of 176 submissions were submitted by 37 participating teams during the final testing phase. Finally, 19 participating teams submitted their models and fact sheets, and detailed the methods they used. Some methods have achieved better results than baseline methods, and the winning methods have demonstrated superior prediction performance.","sentences":["This paper reports on the NTIRE 2023 Quality Assessment of Video Enhancement Challenge, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2023.","This challenge is to address a major challenge in the field of video processing, namely, video quality assessment (VQA) for enhanced videos.","The challenge uses the VQA Dataset for Perceptual Video Enhancement (VDPVE), which has a total of 1211 enhanced videos, including 600 videos with color, brightness, and contrast enhancements, 310 videos with deblurring, and 301 deshaked videos.","The challenge has a total of 167 registered participants.","61 participating teams submitted their prediction results during the development phase, with a total of 3168 submissions.","A total of 176 submissions were submitted by 37 participating teams during the final testing phase.","Finally, 19 participating teams submitted their models and fact sheets, and detailed the methods they used.","Some methods have achieved better results than baseline methods, and the winning methods have demonstrated superior prediction performance."],"url":"http://arxiv.org/abs/2307.09729v1"}
{"created":"2023-07-19 02:29:57","title":"Uncertainty-Driven Multi-Scale Feature Fusion Network for Real-time Image Deraining","abstract":"Visual-based measurement systems are frequently affected by rainy weather due to the degradation caused by rain streaks in captured images, and existing imaging devices struggle to address this issue in real-time. While most efforts leverage deep networks for image deraining and have made progress, their large parameter sizes hinder deployment on resource-constrained devices. Additionally, these data-driven models often produce deterministic results, without considering their inherent epistemic uncertainty, which can lead to undesired reconstruction errors. Well-calibrated uncertainty can help alleviate prediction errors and assist measurement devices in mitigating risks and improving usability. Therefore, we propose an Uncertainty-Driven Multi-Scale Feature Fusion Network (UMFFNet) that learns the probability mapping distribution between paired images to estimate uncertainty. Specifically, we introduce an uncertainty feature fusion block (UFFB) that utilizes uncertainty information to dynamically enhance acquired features and focus on blurry regions obscured by rain streaks, reducing prediction errors. In addition, to further boost the performance of UMFFNet, we fused feature information from multiple scales to guide the network for efficient collaborative rain removal. Extensive experiments demonstrate that UMFFNet achieves significant performance improvements with few parameters, surpassing state-of-the-art image deraining methods.","sentences":["Visual-based measurement systems are frequently affected by rainy weather due to the degradation caused by rain streaks in captured images, and existing imaging devices struggle to address this issue in real-time.","While most efforts leverage deep networks for image deraining and have made progress, their large parameter sizes hinder deployment on resource-constrained devices.","Additionally, these data-driven models often produce deterministic results, without considering their inherent epistemic uncertainty, which can lead to undesired reconstruction errors.","Well-calibrated uncertainty can help alleviate prediction errors and assist measurement devices in mitigating risks and improving usability.","Therefore, we propose an Uncertainty-Driven Multi-Scale Feature Fusion Network (UMFFNet) that learns the probability mapping distribution between paired images to estimate uncertainty.","Specifically, we introduce an uncertainty feature fusion block (UFFB) that utilizes uncertainty information to dynamically enhance acquired features and focus on blurry regions obscured by rain streaks, reducing prediction errors.","In addition, to further boost the performance of UMFFNet, we fused feature information from multiple scales to guide the network for efficient collaborative rain removal.","Extensive experiments demonstrate that UMFFNet achieves significant performance improvements with few parameters, surpassing state-of-the-art image deraining methods."],"url":"http://arxiv.org/abs/2307.09728v1"}
{"created":"2023-07-19 02:28:41","title":"SAMConvex: Fast Discrete Optimization for CT Registration using Self-supervised Anatomical Embedding and Correlation Pyramid","abstract":"Estimating displacement vector field via a cost volume computed in the feature space has shown great success in image registration, but it suffers excessive computation burdens. Moreover, existing feature descriptors only extract local features incapable of representing the global semantic information, which is especially important for solving large transformations. To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine discrete optimization method for CT registration that includes a decoupled convex optimization procedure to obtain deformation fields based on a self-supervised anatomical embedding (SAM) feature extractor that captures both local and global information. To be specific, SAMConvex extracts per-voxel features and builds 6D correlation volumes based on SAM features, and iteratively updates a flow field by performing lookups on the correlation volumes with a coarse-to-fine scheme. SAMConvex outperforms the state-of-the-art learning-based methods and optimization-based methods over two inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one intra-patient registration dataset (Lung CT). Moreover, as an optimization-based method, SAMConvex only takes $\\sim2$s ($\\sim5s$ with instance optimization) for one paired images.","sentences":["Estimating displacement vector field via a cost volume computed in the feature space has shown great success in image registration, but it suffers excessive computation burdens.","Moreover, existing feature descriptors only extract local features incapable of representing the global semantic information, which is especially important for solving large transformations.","To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine discrete optimization method for CT registration that includes a decoupled convex optimization procedure to obtain deformation fields based on a self-supervised anatomical embedding (SAM) feature extractor that captures both local and global information.","To be specific, SAMConvex extracts per-voxel features and builds 6D correlation volumes based on SAM features, and iteratively updates a flow field by performing lookups on the correlation volumes with a coarse-to-fine scheme.","SAMConvex outperforms the state-of-the-art learning-based methods and optimization-based methods over two inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one intra-patient registration dataset (Lung CT).","Moreover, as an optimization-based method, SAMConvex only takes $\\sim2$s ($\\sim5s$ with instance optimization) for one paired images."],"url":"http://arxiv.org/abs/2307.09727v1"}
{"created":"2023-07-19 02:26:20","title":"AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks","abstract":"To deliver the artistic expression of the target style, recent studies exploit the attention mechanism owing to its ability to map the local patches of the style image to the corresponding patches of the content image. However, because of the low semantic correspondence between arbitrary content and artworks, the attention module repeatedly abuses specific local patches from the style image, resulting in disharmonious and evident repetitive artifacts. To overcome this limitation and accomplish impeccable artistic style transfer, we focus on enhancing the attention mechanism and capturing the rhythm of patterns that organize the style. In this paper, we introduce a novel metric, namely pattern repeatability, that quantifies the repetition of patterns in the style image. Based on the pattern repeatability, we propose Aesthetic Pattern-Aware style transfer Networks (AesPA-Net) that discover the sweet spot of local and global style expressions. In addition, we propose a novel self-supervisory task to encourage the attention mechanism to learn precise and meaningful semantic correspondence. Lastly, we introduce the patch-wise style loss to transfer the elaborate rhythm of local patterns. Through qualitative and quantitative evaluations, we verify the reliability of the proposed pattern repeatability that aligns with human perception, and demonstrate the superiority of the proposed framework.","sentences":["To deliver the artistic expression of the target style, recent studies exploit the attention mechanism owing to its ability to map the local patches of the style image to the corresponding patches of the content image.","However, because of the low semantic correspondence between arbitrary content and artworks, the attention module repeatedly abuses specific local patches from the style image, resulting in disharmonious and evident repetitive artifacts.","To overcome this limitation and accomplish impeccable artistic style transfer, we focus on enhancing the attention mechanism and capturing the rhythm of patterns that organize the style.","In this paper, we introduce a novel metric, namely pattern repeatability, that quantifies the repetition of patterns in the style image.","Based on the pattern repeatability, we propose Aesthetic Pattern-Aware style transfer Networks (AesPA-Net) that discover the sweet spot of local and global style expressions.","In addition, we propose a novel self-supervisory task to encourage the attention mechanism to learn precise and meaningful semantic correspondence.","Lastly, we introduce the patch-wise style loss to transfer the elaborate rhythm of local patterns.","Through qualitative and quantitative evaluations, we verify the reliability of the proposed pattern repeatability that aligns with human perception, and demonstrate the superiority of the proposed framework."],"url":"http://arxiv.org/abs/2307.09724v1"}
{"created":"2023-07-19 02:21:44","title":"Improving Domain Generalization for Sound Classification with Sparse Frequency-Regularized Transformer","abstract":"Sound classification models' performance suffers from generalizing on out-of-distribution (OOD) data. Numerous methods have been proposed to help the model generalize. However, most either introduce inference overheads or focus on long-lasting CNN-variants, while Transformers has been proven to outperform CNNs on numerous natural language processing and computer vision tasks. We propose FRITO, an effective regularization technique on Transformer's self-attention, to improve the model's generalization ability by limiting each sequence position's attention receptive field along the frequency dimension on the spectrogram. Experiments show that our method helps Transformer models achieve SOTA generalization performance on TAU 2020 and Nsynth datasets while saving 20% inference time.","sentences":["Sound classification models' performance suffers from generalizing on out-of-distribution (OOD) data.","Numerous methods have been proposed to help the model generalize.","However, most either introduce inference overheads or focus on long-lasting CNN-variants, while Transformers has been proven to outperform CNNs on numerous natural language processing and computer vision tasks.","We propose FRITO, an effective regularization technique on Transformer's self-attention, to improve the model's generalization ability by limiting each sequence position's attention receptive field along the frequency dimension on the spectrogram.","Experiments show that our method helps Transformer models achieve SOTA generalization performance on TAU 2020 and Nsynth datasets while saving 20% inference time."],"url":"http://arxiv.org/abs/2307.09723v1"}
{"created":"2023-07-19 02:11:19","title":"Multi-Grained Multimodal Interaction Network for Entity Linking","abstract":"Multimodal entity linking (MEL) task, which aims at resolving ambiguous mentions to a multimodal knowledge graph, has attracted wide attention in recent years. Though large efforts have been made to explore the complementary effect among multiple modalities, however, they may fail to fully absorb the comprehensive expression of abbreviated textual context and implicit visual indication. Even worse, the inevitable noisy data may cause inconsistency of different modalities during the learning process, which severely degenerates the performance. To address the above issues, in this paper, we propose a novel Multi-GraIned Multimodal InteraCtion Network $\\textbf{(MIMIC)}$ framework for solving the MEL task. Specifically, the unified inputs of mentions and entities are first encoded by textual/visual encoders separately, to extract global descriptive features and local detailed features. Then, to derive the similarity matching score for each mention-entity pair, we device three interaction units to comprehensively explore the intra-modal interaction and inter-modal fusion among features of entities and mentions. In particular, three modules, namely the Text-based Global-Local interaction Unit (TGLU), Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based interaction Unit (CMFU) are designed to capture and integrate the fine-grained representation lying in abbreviated text and implicit visual cues. Afterwards, we introduce a unit-consistency objective function via contrastive learning to avoid inconsistency and model degradation. Experimental results on three public benchmark datasets demonstrate that our solution outperforms various state-of-the-art baselines, and ablation studies verify the effectiveness of designed modules.","sentences":["Multimodal entity linking (MEL) task, which aims at resolving ambiguous mentions to a multimodal knowledge graph, has attracted wide attention in recent years.","Though large efforts have been made to explore the complementary effect among multiple modalities, however, they may fail to fully absorb the comprehensive expression of abbreviated textual context and implicit visual indication.","Even worse, the inevitable noisy data may cause inconsistency of different modalities during the learning process, which severely degenerates the performance.","To address the above issues, in this paper, we propose a novel Multi-GraIned Multimodal InteraCtion Network $\\textbf{(MIMIC)}$ framework for solving the MEL task.","Specifically, the unified inputs of mentions and entities are first encoded by textual/visual encoders separately, to extract global descriptive features and local detailed features.","Then, to derive the similarity matching score for each mention-entity pair, we device three interaction units to comprehensively explore the intra-modal interaction and inter-modal fusion among features of entities and mentions.","In particular, three modules, namely the Text-based Global-Local interaction Unit (TGLU), Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based interaction Unit (CMFU) are designed to capture and integrate the fine-grained representation lying in abbreviated text and implicit visual cues.","Afterwards, we introduce a unit-consistency objective function via contrastive learning to avoid inconsistency and model degradation.","Experimental results on three public benchmark datasets demonstrate that our solution outperforms various state-of-the-art baselines, and ablation studies verify the effectiveness of designed modules."],"url":"http://arxiv.org/abs/2307.09721v1"}
{"created":"2023-07-19 01:57:31","title":"Semantic-Aware Dual Contrastive Learning for Multi-label Image Classification","abstract":"Extracting image semantics effectively and assigning corresponding labels to multiple objects or attributes for natural images is challenging due to the complex scene contents and confusing label dependencies. Recent works have focused on modeling label relationships with graph and understanding object regions using class activation maps (CAM). However, these methods ignore the complex intra- and inter-category relationships among specific semantic features, and CAM is prone to generate noisy information. To this end, we propose a novel semantic-aware dual contrastive learning framework that incorporates sample-to-sample contrastive learning (SSCL) as well as prototype-to-sample contrastive learning (PSCL). Specifically, we leverage semantic-aware representation learning to extract category-related local discriminative features and construct category prototypes. Then based on SSCL, label-level visual representations of the same category are aggregated together, and features belonging to distinct categories are separated. Meanwhile, we construct a novel PSCL module to narrow the distance between positive samples and category prototypes and push negative samples away from the corresponding category prototypes. Finally, the discriminative label-level features related to the image content are accurately captured by the joint training of the above three parts. Experiments on five challenging large-scale public datasets demonstrate that our proposed method is effective and outperforms the state-of-the-art methods. Code and supplementary materials are released on https://github.com/yu-gi-oh-leilei/SADCL.","sentences":["Extracting image semantics effectively and assigning corresponding labels to multiple objects or attributes for natural images is challenging due to the complex scene contents and confusing label dependencies.","Recent works have focused on modeling label relationships with graph and understanding object regions using class activation maps (CAM).","However, these methods ignore the complex intra- and inter-category relationships among specific semantic features, and CAM is prone to generate noisy information.","To this end, we propose a novel semantic-aware dual contrastive learning framework that incorporates sample-to-sample contrastive learning (SSCL) as well as prototype-to-sample contrastive learning (PSCL).","Specifically, we leverage semantic-aware representation learning to extract category-related local discriminative features and construct category prototypes.","Then based on SSCL, label-level visual representations of the same category are aggregated together, and features belonging to distinct categories are separated.","Meanwhile, we construct a novel PSCL module to narrow the distance between positive samples and category prototypes and push negative samples away from the corresponding category prototypes.","Finally, the discriminative label-level features related to the image content are accurately captured by the joint training of the above three parts.","Experiments on five challenging large-scale public datasets demonstrate that our proposed method is effective and outperforms the state-of-the-art methods.","Code and supplementary materials are released on https://github.com/yu-gi-oh-leilei/SADCL."],"url":"http://arxiv.org/abs/2307.09715v1"}
{"created":"2023-07-19 01:46:38","title":"Two Tales of Platoon Intelligence for Autonomous Mobility Control: Enabling Deep Learning Recipes","abstract":"This paper presents the deep learning-based recent achievements to resolve the problem of autonomous mobility control and efficient resource management of autonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning (MARL), and (ii) neural Myerson auction. Representatively, communication network (CommNet), which is one of the most popular MARL algorithms, is introduced to enable multiple agents to take actions in a distributed manner for their shared goals by training all agents' states and actions in a single neural network. Moreover, the neural Myerson auction guarantees trustfulness among multiple agents as well as achieves the optimal revenue of highly dynamic systems. Therefore, we survey the recent studies on autonomous mobility control based on MARL and neural Myerson auction. Furthermore, we emphasize that integration of MARL and neural Myerson auction is expected to be critical for efficient and trustful autonomous mobility services.","sentences":["This paper presents the deep learning-based recent achievements to resolve the problem of autonomous mobility control and efficient resource management of autonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning (MARL), and (ii) neural Myerson auction.","Representatively, communication network (CommNet), which is one of the most popular MARL algorithms, is introduced to enable multiple agents to take actions in a distributed manner for their shared goals by training all agents' states and actions in a single neural network.","Moreover, the neural Myerson auction guarantees trustfulness among multiple agents as well as achieves the optimal revenue of highly dynamic systems.","Therefore, we survey the recent studies on autonomous mobility control based on MARL and neural Myerson auction.","Furthermore, we emphasize that integration of MARL and neural Myerson auction is expected to be critical for efficient and trustful autonomous mobility services."],"url":"http://arxiv.org/abs/2307.09711v1"}
{"created":"2023-07-19 01:37:31","title":"RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap","abstract":"Taxonomies are an essential knowledge representation, yet most studies on automatic taxonomy construction (ATC) resort to manual evaluation to score proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just as important as taxonomy construction. We propose RaTE, an automatic label-free taxonomy scoring procedure, which relies on a large pre-trained language model. We apply our evaluation procedure to three state-of-the-art ATC algorithms with which we built seven taxonomies from the Yelp domain, and show that 1) RaTE correlates well with human judgments and 2) artificially degrading a taxonomy leads to decreasing RaTE score.","sentences":["Taxonomies are an essential knowledge representation, yet most studies on automatic taxonomy construction (ATC) resort to manual evaluation to score proposed algorithms.","We argue that automatic taxonomy evaluation (ATE) is just as important as taxonomy construction.","We propose RaTE, an automatic label-free taxonomy scoring procedure, which relies on a large pre-trained language model.","We apply our evaluation procedure to three state-of-the-art ATC algorithms with which we built seven taxonomies from the Yelp domain, and show that 1) RaTE correlates well with human judgments and 2) artificially degrading a taxonomy leads to decreasing RaTE score."],"url":"http://arxiv.org/abs/2307.09706v1"}
{"created":"2023-07-19 01:22:40","title":"CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility","abstract":"With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts. Therefore, evaluation of human values alignment is becoming increasingly important. Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context. In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria. As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts. To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation. Our findings suggest that while most Chinese LLMs perform well in terms of safety, there is considerable room for improvement in terms of responsibility. Moreover, both the automatic and human evaluation are important for assessing the human values alignment in different aspects. The benchmark and code is available on ModelScope and Github.","sentences":["With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts.","Therefore, evaluation of human values alignment is becoming increasingly important.","Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context.","In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria.","As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts.","To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation.","Our findings suggest that while most Chinese LLMs perform well in terms of safety, there is considerable room for improvement in terms of responsibility.","Moreover, both the automatic and human evaluation are important for assessing the human values alignment in different aspects.","The benchmark and code is available on ModelScope and Github."],"url":"http://arxiv.org/abs/2307.09705v1"}
{"created":"2023-07-19 01:21:29","title":"How are exclusively data journals indexed in major scholarly databases? An examination of the Web of Science, Scopus, Dimensions, and OpenAlex","abstract":"As part of the data-driven paradigm and open science movement, the data paper is becoming a popular way for researchers to publish their research data, based on academic norms that cross knowledge domains. Data journals have also been created to host this new academic genre. The growing number of data papers and journals has made them an important large-scale data source for understanding how research data is published and reused in our research system. One barrier to this research agenda is a lack of knowledge as to how data journals and their publications are indexed in the scholarly databases used for quantitative analysis. To address this gap, this study examines how a list of 18 exclusively data journals (i.e., journals that primarily accept data papers) are indexed in four popular scholarly databases: the Web of Science, Scopus, Dimensions, and OpenAlex. We investigate how comprehensively these databases cover the selected data journals and, in particular, how they present the document type information of data papers. We find that the coverage of data papers, as well as their document type information, is highly inconsistent across databases, which creates major challenges for future efforts to study them quantitatively. As a result, we argue that efforts should be made by data journals and databases to improve the quality of metadata for this emerging genre.","sentences":["As part of the data-driven paradigm and open science movement, the data paper is becoming a popular way for researchers to publish their research data, based on academic norms that cross knowledge domains.","Data journals have also been created to host this new academic genre.","The growing number of data papers and journals has made them an important large-scale data source for understanding how research data is published and reused in our research system.","One barrier to this research agenda is a lack of knowledge as to how data journals and their publications are indexed in the scholarly databases used for quantitative analysis.","To address this gap, this study examines how a list of 18 exclusively data journals (i.e., journals that primarily accept data papers) are indexed in four popular scholarly databases: the Web of Science, Scopus, Dimensions, and OpenAlex.","We investigate how comprehensively these databases cover the selected data journals and, in particular, how they present the document type information of data papers.","We find that the coverage of data papers, as well as their document type information, is highly inconsistent across databases, which creates major challenges for future efforts to study them quantitatively.","As a result, we argue that efforts should be made by data journals and databases to improve the quality of metadata for this emerging genre."],"url":"http://arxiv.org/abs/2307.09704v1"}
{"created":"2023-07-19 01:14:49","title":"Efficient Guided Generation for LLMs","abstract":"In this article we describe an efficient approach to guiding language model text generation with regular expressions and context-free grammars. Our approach adds little to no overhead to the token sequence generation process, and makes guided generation feasible in practice. An implementation is provided in the open source Python library Outlines.","sentences":["In this article we describe an efficient approach to guiding language model text generation with regular expressions and context-free grammars.","Our approach adds little to no overhead to the token sequence generation process, and makes guided generation feasible in practice.","An implementation is provided in the open source Python library Outlines."],"url":"http://arxiv.org/abs/2307.09702v1"}
{"created":"2023-07-19 01:05:33","title":"Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation","abstract":"Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.","sentences":["Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns.","Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison.","For example, hardware is challenging to control due to disparate levels of accessibility across different institutions.","Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications.","In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency.","Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle.","It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios.","It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption.","Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation.","As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons.","While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields.","We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models."],"url":"http://arxiv.org/abs/2307.09701v1"}
{"created":"2023-07-19 01:04:01","title":"ActorLens: Visual Analytics for High-level Actor Identification in MOBA Games","abstract":"Multiplayer Online Battle Arenas (MOBAs) have garnered a substantial player base worldwide. Nevertheless, the presence of noxious players, commonly referred to as \"actors\", can significantly compromise game fairness by exhibiting negative behaviors that diminish their team's competitive edge. Furthermore, high-level actors tend to engage in more egregious conduct to evade detection, thereby causing harm to the game community and necessitating their identification. To tackle this urgent concern, a partnership was formed with a team of game specialists from a prominent company to facilitate the identification and labeling of high-level actors in MOBA games. We first characterize the problem and abstract data and events from the game scene to formulate design requirements. Subsequently, ActorLens, a visual analytics system, was developed to exclude low-level actors, detect potential high-level actors, and assist users in labeling players. ActorLens furnishes an overview of players' status, summarizes behavioral patterns across three player cohorts (namely, focused players, historical matches of focused players, and matches of other players who played the same hero), and synthesizes key match events. By incorporating multiple views of information, users can proficiently recognize and label high-level actors in MOBA games. We conducted case studies and user studies to demonstrate the efficacy of the system.","sentences":["Multiplayer Online Battle Arenas (MOBAs) have garnered a substantial player base worldwide.","Nevertheless, the presence of noxious players, commonly referred to as \"actors\", can significantly compromise game fairness by exhibiting negative behaviors that diminish their team's competitive edge.","Furthermore, high-level actors tend to engage in more egregious conduct to evade detection, thereby causing harm to the game community and necessitating their identification.","To tackle this urgent concern, a partnership was formed with a team of game specialists from a prominent company to facilitate the identification and labeling of high-level actors in MOBA games.","We first characterize the problem and abstract data and events from the game scene to formulate design requirements.","Subsequently, ActorLens, a visual analytics system, was developed to exclude low-level actors, detect potential high-level actors, and assist users in labeling players.","ActorLens furnishes an overview of players' status, summarizes behavioral patterns across three player cohorts (namely, focused players, historical matches of focused players, and matches of other players who played the same hero), and synthesizes key match events.","By incorporating multiple views of information, users can proficiently recognize and label high-level actors in MOBA games.","We conducted case studies and user studies to demonstrate the efficacy of the system."],"url":"http://arxiv.org/abs/2307.09699v1"}
{"created":"2023-07-19 00:41:39","title":"Towards Saner Deep Image Registration","abstract":"With recent advances in computing hardware and surges of deep-learning architectures, learning-based deep image registration methods have surpassed their traditional counterparts, in terms of metric performance and inference time. However, these methods focus on improving performance measurements such as Dice, resulting in less attention given to model behaviors that are equally desirable for registrations, especially for medical imaging. This paper investigates these behaviors for popular learning-based deep registrations under a sanity-checking microscope. We find that most existing registrations suffer from low inverse consistency and nondiscrimination of identical pairs due to overly optimized image similarities. To rectify these behaviors, we propose a novel regularization-based sanity-enforcer method that imposes two sanity checks on the deep model to reduce its inverse consistency errors and increase its discriminative power simultaneously. Moreover, we derive a set of theoretical guarantees for our sanity-checked image registration method, with experimental results supporting our theoretical findings and their effectiveness in increasing the sanity of models without sacrificing any performance. Our code and models are available at \\url{https://github.com/tuffr5/Saner-deep-registration}.","sentences":["With recent advances in computing hardware and surges of deep-learning architectures, learning-based deep image registration methods have surpassed their traditional counterparts, in terms of metric performance and inference time.","However, these methods focus on improving performance measurements such as Dice, resulting in less attention given to model behaviors that are equally desirable for registrations, especially for medical imaging.","This paper investigates these behaviors for popular learning-based deep registrations under a sanity-checking microscope.","We find that most existing registrations suffer from low inverse consistency and nondiscrimination of identical pairs due to overly optimized image similarities.","To rectify these behaviors, we propose a novel regularization-based sanity-enforcer method that imposes two sanity checks on the deep model to reduce its inverse consistency errors and increase its discriminative power simultaneously.","Moreover, we derive a set of theoretical guarantees for our sanity-checked image registration method, with experimental results supporting our theoretical findings and their effectiveness in increasing the sanity of models without sacrificing any performance.","Our code and models are available at \\url{https://github.com/tuffr5/Saner-deep-registration}."],"url":"http://arxiv.org/abs/2307.09696v1"}
{"created":"2023-07-19 00:36:05","title":"GlobalMapper: Arbitrary-Shaped Urban Layout Generation","abstract":"Modeling and designing urban building layouts is of significant interest in computer vision, computer graphics, and urban applications. A building layout consists of a set of buildings in city blocks defined by a network of roads. We observe that building layouts are discrete structures, consisting of multiple rows of buildings of various shapes, and are amenable to skeletonization for mapping arbitrary city block shapes to a canonical form. Hence, we propose a fully automatic approach to building layout generation using graph attention networks. Our method generates realistic urban layouts given arbitrary road networks, and enables conditional generation based on learned priors. Our results, including user study, demonstrate superior performance as compared to prior layout generation networks, support arbitrary city block and varying building shapes as demonstrated by generating layouts for 28 large cities.","sentences":["Modeling and designing urban building layouts is of significant interest in computer vision, computer graphics, and urban applications.","A building layout consists of a set of buildings in city blocks defined by a network of roads.","We observe that building layouts are discrete structures, consisting of multiple rows of buildings of various shapes, and are amenable to skeletonization for mapping arbitrary city block shapes to a canonical form.","Hence, we propose a fully automatic approach to building layout generation using graph attention networks.","Our method generates realistic urban layouts given arbitrary road networks, and enables conditional generation based on learned priors.","Our results, including user study, demonstrate superior performance as compared to prior layout generation networks, support arbitrary city block and varying building shapes as demonstrated by generating layouts for 28 large cities."],"url":"http://arxiv.org/abs/2307.09693v1"}
{"created":"2023-07-19 00:31:58","title":"STRAPPER: Preference-based Reinforcement Learning via Self-training Augmentation and Peer Regularization","abstract":"Preference-based reinforcement learning (PbRL) promises to learn a complex reward function with binary human preference. However, such human-in-the-loop formulation requires considerable human effort to assign preference labels to segment pairs, hindering its large-scale applications. Recent approache has tried to reuse unlabeled segments, which implicitly elucidates the distribution of segments and thereby alleviates the human effort. And consistency regularization is further considered to improve the performance of semi-supervised learning. However, we notice that, unlike general classification tasks, in PbRL there exits a unique phenomenon that we defined as similarity trap in this paper. Intuitively, human can have diametrically opposite preferredness for similar segment pairs, but such similarity may trap consistency regularization fail in PbRL. Due to the existence of similarity trap, such consistency regularization improperly enhances the consistency possiblity of the model's predictions between segment pairs, and thus reduces the confidence in reward learning, since the augmented distribution does not match with the original one in PbRL. To overcome such issue, we present a self-training method along with our proposed peer regularization, which penalizes the reward model memorizing uninformative labels and acquires confident predictions. Empirically, we demonstrate that our approach is capable of learning well a variety of locomotion and robotic manipulation behaviors using different semi-supervised alternatives and peer regularization.","sentences":["Preference-based reinforcement learning (PbRL) promises to learn a complex reward function with binary human preference.","However, such human-in-the-loop formulation requires considerable human effort to assign preference labels to segment pairs, hindering its large-scale applications.","Recent approache has tried to reuse unlabeled segments, which implicitly elucidates the distribution of segments and thereby alleviates the human effort.","And consistency regularization is further considered to improve the performance of semi-supervised learning.","However, we notice that, unlike general classification tasks, in PbRL there exits a unique phenomenon that we defined as similarity trap in this paper.","Intuitively, human can have diametrically opposite preferredness for similar segment pairs, but such similarity may trap consistency regularization fail in PbRL.","Due to the existence of similarity trap, such consistency regularization improperly enhances the consistency possiblity of the model's predictions between segment pairs, and thus reduces the confidence in reward learning, since the augmented distribution does not match with the original one in PbRL.","To overcome such issue, we present a self-training method along with our proposed peer regularization, which penalizes the reward model memorizing uninformative labels and acquires confident predictions.","Empirically, we demonstrate that our approach is capable of learning well a variety of locomotion and robotic manipulation behaviors using different semi-supervised alternatives and peer regularization."],"url":"http://arxiv.org/abs/2307.09692v1"}
{"created":"2023-07-19 00:27:49","title":"Joint Service Caching, Communication and Computing Resource Allocation in Collaborative MEC Systems: A DRL-based Two-timescale Approach","abstract":"Meeting the strict Quality of Service (QoS) requirements of terminals has imposed a signiffcant challenge on Multiaccess Edge Computing (MEC) systems, due to the limited multidimensional resources. To address this challenge, we propose a collaborative MEC framework that facilitates resource sharing between the edge servers, and with the aim to maximize the long-term QoS and reduce the cache switching cost through joint optimization of service caching, collaborative offfoading, and computation and communication resource allocation. The dual timescale feature and temporal recurrence relationship between service caching and other resource allocation make solving the problem even more challenging. To solve it, we propose a deep reinforcement learning (DRL)-based dual timescale scheme, called DGL-DDPG, which is composed of a short-term genetic algorithm (GA) and a long short-term memory network-based deep deterministic policy gradient (LSTM-DDPG). In doing so, we reformulate the optimization problem as a Markov decision process (MDP) where the small-timescale resource allocation decisions generated by an improved GA are taken as the states and input into a centralized LSTM-DDPG agent to generate the service caching decision for the large-timescale. Simulation results demonstrate that our proposed algorithm outperforms the baseline algorithms in terms of the average QoS and cache switching cost.","sentences":["Meeting the strict Quality of Service (QoS) requirements of terminals has imposed a signiffcant challenge on Multiaccess Edge Computing (MEC) systems, due to the limited multidimensional resources.","To address this challenge, we propose a collaborative MEC framework that facilitates resource sharing between the edge servers, and with the aim to maximize the long-term QoS and reduce the cache switching cost through joint optimization of service caching, collaborative offfoading, and computation and communication resource allocation.","The dual timescale feature and temporal recurrence relationship between service caching and other resource allocation make solving the problem even more challenging.","To solve it, we propose a deep reinforcement learning (DRL)-based dual timescale scheme, called DGL-DDPG, which is composed of a short-term genetic algorithm (GA) and a long short-term memory network-based deep deterministic policy gradient (LSTM-DDPG).","In doing so, we reformulate the optimization problem as a Markov decision process (MDP) where the small-timescale resource allocation decisions generated by an improved GA are taken as the states and input into a centralized LSTM-DDPG agent to generate the service caching decision for the large-timescale.","Simulation results demonstrate that our proposed algorithm outperforms the baseline algorithms in terms of the average QoS and cache switching cost."],"url":"http://arxiv.org/abs/2307.09691v1"}
{"created":"2023-07-19 00:08:49","title":"Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation","abstract":"Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 and have attracted thousands of users and submissions. The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/.","sentences":["Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement.","Thus, accurately understanding customer preferences is essential for providing personalized recommendations.","Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular.","However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale.","As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences.","To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2.","It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish.","Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks.","To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation.","With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice.","In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 and have attracted thousands of users and submissions.","The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/."],"url":"http://arxiv.org/abs/2307.09688v1"}
{"created":"2023-07-18 23:35:53","title":"PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search","abstract":"Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, including natural language questions. 4. Locating related articles with literature recommendation. 5. Mining literature to discover associations between concepts such as diseases and genetic variants. Additionally, we cover practical considerations and best practices for choosing and using these tools. Finally, we provide a perspective on the future of literature search engines, considering recent breakthroughs in large language models such as ChatGPT. In summary, our survey provides a comprehensive view of biomedical literature search functionalities with 36 publicly available tools.","sentences":["Biomedical research yields a wealth of information, much of which is only accessible through the literature.","Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research.","Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers.","In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs.","We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges.","We then describe literature search tools catering to five specific information needs: 1.","Identifying high-quality clinical research for evidence-based medicine.","2. Retrieving gene-related information for precision medicine and genomics.","3. Searching by meaning, including natural language questions.","4. Locating related articles with literature recommendation.","5. Mining literature to discover associations between concepts such as diseases and genetic variants.","Additionally, we cover practical considerations and best practices for choosing and using these tools.","Finally, we provide a perspective on the future of literature search engines, considering recent breakthroughs in large language models such as ChatGPT.","In summary, our survey provides a comprehensive view of biomedical literature search functionalities with 36 publicly available tools."],"url":"http://arxiv.org/abs/2307.09683v1"}
{"created":"2023-07-18 23:17:28","title":"A Modal Logic with n-ary Relations Over Paths: Comonadic Semantics and Expressivity","abstract":"Game comonads give a categorical semantics for comparison games in Finite Model Theory, thus providing an abstract characterisation of logical equivalence for a wide range of logics, each one captured through a specific choice of comonad. However, data-aware logics such as CoreDataXPath present sophisticated notions of bisimulation which defy a straightforward comonadic encoding. In this work we begin the comonadic treatment of data-aware logics by introducing a generalisation of Modal Logic that allows relation symbols of arbitrary arity as atoms of the syntax, which we call Path Predicate Modal Logic or PPML. We motivate this logic as arising from a shift in perspective on a already studied restricted version of CoreDataXPath, called DataGL, and prove that PPML recovers DataGL for a specific choice of signature. We argue that this shift in perspective allows the capturing and designing of new data-aware logics. On the other hand, PPML enjoys an intrinsic motivation in that it extends Modal Logic to predicate over more general models. Having defined the simulation and bisimulation games for PPML and having proven a Hennessy-Milner-type theorem, we define the PPML comonad and prove that it captures these games, following analogous results in the literature. Our treatment is novel in that we explicitly prove that our comonad satisfies the axioms of arboreal categories and arboreal covers. Using the comonadic machinery, we immediately obtain a tree-model property for PPML. Finally, we define a translation functor from relational structures into Kripke structures and use its properties to prove a series of polynomial-time reductions from PPML problems to their Basic Modal Logic counterparts. Our results explain precisely in what sense PPML lets us view general relational structures through the modal lens.","sentences":["Game comonads give a categorical semantics for comparison games in Finite Model Theory, thus providing an abstract characterisation of logical equivalence for a wide range of logics, each one captured through a specific choice of comonad.","However, data-aware logics such as CoreDataXPath present sophisticated notions of bisimulation which defy a straightforward comonadic encoding.","In this work we begin the comonadic treatment of data-aware logics by introducing a generalisation of Modal Logic that allows relation symbols of arbitrary arity as atoms of the syntax, which we call Path Predicate Modal Logic or PPML.","We motivate this logic as arising from a shift in perspective on a already studied restricted version of CoreDataXPath, called DataGL, and prove that PPML recovers DataGL for a specific choice of signature.","We argue that this shift in perspective allows the capturing and designing of new data-aware logics.","On the other hand, PPML enjoys an intrinsic motivation in that it extends Modal Logic to predicate over more general models.","Having defined the simulation and bisimulation games for PPML and having proven a Hennessy-Milner-type theorem, we define the PPML comonad and prove that it captures these games, following analogous results in the literature.","Our treatment is novel in that we explicitly prove that our comonad satisfies the axioms of arboreal categories and arboreal covers.","Using the comonadic machinery, we immediately obtain a tree-model property for PPML.","Finally, we define a translation functor from relational structures into Kripke structures and use its properties to prove a series of polynomial-time reductions from PPML problems to their Basic Modal Logic counterparts.","Our results explain precisely in what sense PPML lets us view general relational structures through the modal lens."],"url":"http://arxiv.org/abs/2307.09679v1"}
{"created":"2023-07-18 23:06:47","title":"Domain Adaptation for Enhanced Object Detection in Foggy and Rainy Weather for Autonomous Driving","abstract":"Most object detection models for autonomous driving may experience a significant drop in performance when deployed in real-world applications, due to the well-known domain shift issue. Supervised object detection methods for autonomous driving usually assume a consistent feature distribution between training and testing data, however, such assumptions may not always be the case when weather conditions differ significantly. For example, an object detection model trained under clear weather may not perform well in foggy or rainy weather, due to the domain gap. Overcoming detection bottlenecks in foggy or rainy weather scenarios is a significant challenge for autonomous vehicles deployed in the wild. To address the domain gap in different weather conditions, This paper proposes a novel domain adaptive object detection framework for autonomous driving in foggy and rainy weather. Our method leverages both image-level and object-level adaptation to reduce the domain discrepancy in image style and object appearance. Additionally, to enhance the model's performance under challenging samples, we introduce a new adversarial gradient reversal layer that performs adversarial mining on hard examples alongside domain adaptation. Moreover, we propose to generate an auxiliary domain by data augmentation to enforce a new domain-level metric regularization. Experimental results on public benchmarks demonstrate that object detection performance is significantly improved when using our proposed method in domain shift scenarios for autonomous driving applications.","sentences":["Most object detection models for autonomous driving may experience a significant drop in performance when deployed in real-world applications, due to the well-known domain shift issue.","Supervised object detection methods for autonomous driving usually assume a consistent feature distribution between training and testing data, however, such assumptions may not always be the case when weather conditions differ significantly.","For example, an object detection model trained under clear weather may not perform well in foggy or rainy weather, due to the domain gap.","Overcoming detection bottlenecks in foggy or rainy weather scenarios is a significant challenge for autonomous vehicles deployed in the wild.","To address the domain gap in different weather conditions, This paper proposes a novel domain adaptive object detection framework for autonomous driving in foggy and rainy weather.","Our method leverages both image-level and object-level adaptation to reduce the domain discrepancy in image style and object appearance.","Additionally, to enhance the model's performance under challenging samples, we introduce a new adversarial gradient reversal layer that performs adversarial mining on hard examples alongside domain adaptation.","Moreover, we propose to generate an auxiliary domain by data augmentation to enforce a new domain-level metric regularization.","Experimental results on public benchmarks demonstrate that object detection performance is significantly improved when using our proposed method in domain shift scenarios for autonomous driving applications."],"url":"http://arxiv.org/abs/2307.09676v1"}
{"created":"2023-07-18 22:55:04","title":"What's meant by explainable model: A Scoping Review","abstract":"We often see the term explainable in the titles of papers that describe applications based on artificial intelligence (AI). However, the literature in explainable artificial intelligence (XAI) indicates that explanations in XAI are application- and domain-specific, hence requiring evaluation whenever they are employed to explain a model that makes decisions for a specific application problem. Additionally, the literature reveals that the performance of post-hoc methods, particularly feature attribution methods, varies substantially hinting that they do not represent a solution to AI explainability. Therefore, when using XAI methods, the quality and suitability of their information outputs should be evaluated within the specific application. For these reasons, we used a scoping review methodology to investigate papers that apply AI models and adopt methods to generate post-hoc explanations while referring to said models as explainable. This paper investigates whether the term explainable model is adopted by authors under the assumption that incorporating a post-hoc XAI method suffices to characterize a model as explainable. To inspect this problem, our review analyzes whether these papers conducted evaluations. We found that 81% of the application papers that refer to their approaches as an explainable model do not conduct any form of evaluation on the XAI method they used.","sentences":["We often see the term explainable in the titles of papers that describe applications based on artificial intelligence (AI).","However, the literature in explainable artificial intelligence (XAI) indicates that explanations in XAI are application- and domain-specific, hence requiring evaluation whenever they are employed to explain a model that makes decisions for a specific application problem.","Additionally, the literature reveals that the performance of post-hoc methods, particularly feature attribution methods, varies substantially hinting that they do not represent a solution to AI explainability.","Therefore, when using XAI methods, the quality and suitability of their information outputs should be evaluated within the specific application.","For these reasons, we used a scoping review methodology to investigate papers that apply AI models and adopt methods to generate post-hoc explanations while referring to said models as explainable.","This paper investigates whether the term explainable model is adopted by authors under the assumption that incorporating a post-hoc XAI method suffices to characterize a model as explainable.","To inspect this problem, our review analyzes whether these papers conducted evaluations.","We found that 81% of the application papers that refer to their approaches as an explainable model do not conduct any form of evaluation on the XAI method they used."],"url":"http://arxiv.org/abs/2307.09673v1"}
{"created":"2023-07-18 22:54:51","title":"Convex Geometry of ReLU-layers, Injectivity on the Ball and Local Reconstruction","abstract":"The paper uses a frame-theoretic setting to study the injectivity of a ReLU-layer on the closed ball of $\\mathbb{R}^n$ and its non-negative part. In particular, the interplay between the radius of the ball and the bias vector is emphasized. Together with a perspective from convex geometry, this leads to a computationally feasible method of verifying the injectivity of a ReLU-layer under reasonable restrictions in terms of an upper bound of the bias vector. Explicit reconstruction formulas are provided, inspired by the duality concept from frame theory. All this gives rise to the possibility of quantifying the invertibility of a ReLU-layer and a concrete reconstruction algorithm for any input vector on the ball.","sentences":["The paper uses a frame-theoretic setting to study the injectivity of a ReLU-layer on the closed ball of $\\mathbb{R}^n$ and its non-negative part.","In particular, the interplay between the radius of the ball and the bias vector is emphasized.","Together with a perspective from convex geometry, this leads to a computationally feasible method of verifying the injectivity of a ReLU-layer under reasonable restrictions in terms of an upper bound of the bias vector.","Explicit reconstruction formulas are provided, inspired by the duality concept from frame theory.","All this gives rise to the possibility of quantifying the invertibility of a ReLU-layer and a concrete reconstruction algorithm for any input vector on the ball."],"url":"http://arxiv.org/abs/2307.09672v1"}
{"created":"2023-07-18 22:48:54","title":"JAZZVAR: A Dataset of Variations found within Solo Piano Performances of Jazz Standards for Music Overpainting","abstract":"Jazz pianists often uniquely interpret jazz standards. Passages from these interpretations can be viewed as sections of variation. We manually extracted such variations from solo jazz piano performances. The JAZZVAR dataset is a collection of 502 pairs of Variation and Original MIDI segments. Each Variation in the dataset is accompanied by a corresponding Original segment containing the melody and chords from the original jazz standard. Our approach differs from many existing jazz datasets in the music information retrieval (MIR) community, which often focus on improvisation sections within jazz performances. In this paper, we outline the curation process for obtaining and sorting the repertoire, the pipeline for creating the Original and Variation pairs, and our analysis of the dataset. We also introduce a new generative music task, Music Overpainting, and present a baseline Transformer model trained on the JAZZVAR dataset for this task. Other potential applications of our dataset include expressive performance analysis and performer identification.","sentences":["Jazz pianists often uniquely interpret jazz standards.","Passages from these interpretations can be viewed as sections of variation.","We manually extracted such variations from solo jazz piano performances.","The JAZZVAR dataset is a collection of 502 pairs of Variation and Original MIDI segments.","Each Variation in the dataset is accompanied by a corresponding Original segment containing the melody and chords from the original jazz standard.","Our approach differs from many existing jazz datasets in the music information retrieval (MIR) community, which often focus on improvisation sections within jazz performances.","In this paper, we outline the curation process for obtaining and sorting the repertoire, the pipeline for creating the Original and Variation pairs, and our analysis of the dataset.","We also introduce a new generative music task, Music Overpainting, and present a baseline Transformer model trained on the JAZZVAR dataset for this task.","Other potential applications of our dataset include expressive performance analysis and performer identification."],"url":"http://arxiv.org/abs/2307.09670v1"}
{"created":"2023-07-18 22:37:30","title":"Towards A Unified Agent with Foundation Models","abstract":"Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve novel tasks or imitate videos of human experts.","sentences":["Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others.","In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents.","We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms.","We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects.","We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve novel tasks or imitate videos of human experts."],"url":"http://arxiv.org/abs/2307.09668v1"}
{"created":"2023-07-18 22:31:34","title":"Visualization of Mobility Digital Twin: Framework Design, Case Study, and Future Challenges","abstract":"A Mobility Digital Twin is an emerging implementation of digital twin technology in the transportation domain, which creates digital replicas for various physical mobility entities, such as vehicles, drivers, and pedestrians. Although a few work have investigated the applications of mobility digital twin recently, the extent to which it can facilitate safer autonomous vehicles remains insufficiently explored. In this paper, we first propose visualization of mobility digital twin, which aims to augment the existing perception systems in connected and autonomous vehicles through twinning high-fidelity and manipulable geometry representations for causal traffic participants, such as surrounding pedestrians and vehicles, in the digital space. An end-to-end system framework, including image data crowdsourcing, preprocessing, offloading, and edge-assisted 3D geometry reconstruction, is designed to enable real-world development of the proposed visualization of mobility digital twin. We implement the proposed system framework and conduct a case study to assess the twinning fidelity and physical-to-digital synchronicity within different image sampling scenarios and wireless network conditions. Based on the case study, future challenges of the proposed visualization of mobility digital twin are discussed toward the end of the paper.","sentences":["A Mobility Digital Twin is an emerging implementation of digital twin technology in the transportation domain, which creates digital replicas for various physical mobility entities, such as vehicles, drivers, and pedestrians.","Although a few work have investigated the applications of mobility digital twin recently, the extent to which it can facilitate safer autonomous vehicles remains insufficiently explored.","In this paper, we first propose visualization of mobility digital twin, which aims to augment the existing perception systems in connected and autonomous vehicles through twinning high-fidelity and manipulable geometry representations for causal traffic participants, such as surrounding pedestrians and vehicles, in the digital space.","An end-to-end system framework, including image data crowdsourcing, preprocessing, offloading, and edge-assisted 3D geometry reconstruction, is designed to enable real-world development of the proposed visualization of mobility digital twin.","We implement the proposed system framework and conduct a case study to assess the twinning fidelity and physical-to-digital synchronicity within different image sampling scenarios and wireless network conditions.","Based on the case study, future challenges of the proposed visualization of mobility digital twin are discussed toward the end of the paper."],"url":"http://arxiv.org/abs/2307.09666v1"}
{"created":"2023-07-18 22:17:07","title":"Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers","abstract":"The ability to anticipate technical expertise and capability evolution trends globally is essential for national and global security, especially in safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by (a) forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b) relying on both discrete -- and continuous -- time inputs. We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains. DGT model performance exceeds the best-performing static graph baseline models by 30-80% across AI and NN domains. Our findings demonstrate that DGT models boost inductive task performance, when previously unseen nodes appear in the test data, for the domains with emerging collaboration patterns (e.g., AI). Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice-versa in the AI domain.","sentences":["The ability to anticipate technical expertise and capability evolution trends globally is essential for national and global security, especially in safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI).","In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations.","We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields.","We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by (a) forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b) relying on both discrete -- and continuous -- time inputs.","We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains.","DGT model performance exceeds the best-performing static graph baseline models by 30-80% across AI and NN domains.","Our findings demonstrate that DGT models boost inductive task performance, when previously unseen nodes appear in the test data, for the domains with emerging collaboration patterns (e.g., AI).","Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice-versa in the AI domain."],"url":"http://arxiv.org/abs/2307.09665v1"}
{"created":"2023-07-18 22:04:41","title":"Object-aware Gaze Target Detection","abstract":"Gaze target detection aims to predict the image location where the person is looking and the probability that a gaze is out of the scene. Several works have tackled this task by regressing a gaze heatmap centered on the gaze location, however, they overlooked decoding the relationship between the people and the gazed objects. This paper proposes a Transformer-based architecture that automatically detects objects (including heads) in the scene to build associations between every head and the gazed-head/object, resulting in a comprehensive, explainable gaze analysis composed of: gaze target area, gaze pixel point, the class and the image location of the gazed-object. Upon evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze distance, and 9% gain in out-of-frame average precision) for gaze target detection and 11-13% improvement in average precision for the classification and the localization of the gazed-objects. The code of the proposed method is available https://github.com/francescotonini/object-aware-gaze-target-detection","sentences":["Gaze target detection aims to predict the image location where the person is looking and the probability that a gaze is out of the scene.","Several works have tackled this task by regressing a gaze heatmap centered on the gaze location, however, they overlooked decoding the relationship between the people and the gazed objects.","This paper proposes a Transformer-based architecture that automatically detects objects (including heads) in the scene to build associations between every head and the gazed-head/object, resulting in a comprehensive, explainable gaze analysis composed of: gaze target area, gaze pixel point, the class and the image location of the gazed-object.","Upon evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze distance, and 9% gain in out-of-frame average precision) for gaze target detection and 11-13% improvement in average precision for the classification and the localization of the gazed-objects.","The code of the proposed method is available https://github.com/francescotonini/object-aware-gaze-target-detection"],"url":"http://arxiv.org/abs/2307.09662v1"}
{"created":"2023-07-18 22:03:43","title":"Physics-based Reduced Order Modeling for Uncertainty Quantification of Guided Wave Propagation using Bayesian Optimization","abstract":"In the context of digital twins, structural health monitoring (SHM) constitutes the backbone of condition-based maintenance, facilitating the interconnection between virtual and physical assets. Guided wave propagation (GWP) is commonly employed for the inspection of structures in SHM. However, GWP is sensitive to variations in the material properties of the structure, leading to false alarms. In this direction, uncertainty quantification (UQ) is regularly applied to improve the reliability of predictions. Computational mechanics is a useful tool for the simulation of GWP, and is often applied for UQ. Even so, the application of UQ methods requires numerous simulations, while large-scale, transient numerical GWP solutions increase the computational cost. Reduced order models (ROMs) are commonly employed to provide numerical results in a limited amount of time. In this paper, we propose a machine learning (ML)-based ROM, mentioned as BO-ML-ROM, to decrease the computational time related to the simulation of the GWP. The ROM is integrated with a Bayesian optimization (BO) framework, to adaptively sample the parameters for the ROM training. The finite element method is used for the simulation of the high-fidelity models. The formulated ROM is used for forward UQ of the GWP in an aluminum plate with varying material properties. To determine the influence of each parameter perturbation, a global, variance-based sensitivity analysis is implemented based on Sobol' indices. It is shown that Bayesian optimization outperforms one-shot sampling methods, both in terms of accuracy and speed-up. The predicted results reveal the efficiency of BO-ML-ROM for GWP and demonstrate its value for UQ.","sentences":["In the context of digital twins, structural health monitoring (SHM) constitutes the backbone of condition-based maintenance, facilitating the interconnection between virtual and physical assets.","Guided wave propagation (GWP) is commonly employed for the inspection of structures in SHM.","However, GWP is sensitive to variations in the material properties of the structure, leading to false alarms.","In this direction, uncertainty quantification (UQ) is regularly applied to improve the reliability of predictions.","Computational mechanics is a useful tool for the simulation of GWP, and is often applied for UQ.","Even so, the application of UQ methods requires numerous simulations, while large-scale, transient numerical GWP solutions increase the computational cost.","Reduced order models (ROMs) are commonly employed to provide numerical results in a limited amount of time.","In this paper, we propose a machine learning (ML)-based ROM, mentioned as BO-ML-ROM, to decrease the computational time related to the simulation of the GWP.","The ROM is integrated with a Bayesian optimization (BO) framework, to adaptively sample the parameters for the ROM training.","The finite element method is used for the simulation of the high-fidelity models.","The formulated ROM is used for forward UQ of the GWP in an aluminum plate with varying material properties.","To determine the influence of each parameter perturbation, a global, variance-based sensitivity analysis is implemented based on Sobol' indices.","It is shown that Bayesian optimization outperforms one-shot sampling methods, both in terms of accuracy and speed-up.","The predicted results reveal the efficiency of BO-ML-ROM for GWP and demonstrate its value for UQ."],"url":"http://arxiv.org/abs/2307.09661v1"}
{"created":"2023-07-18 22:01:08","title":"Neural Priority Queues for Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) have shown considerable success in neural algorithmic reasoning. Many traditional algorithms make use of an explicit memory in the form of a data structure. However, there has been limited exploration on augmenting GNNs with external memory. In this paper, we present Neural Priority Queues, a differentiable analogue to algorithmic priority queues, for GNNs. We propose and motivate a desiderata for memory modules, and show that Neural PQs exhibit the desiderata, and reason about their use with algorithmic reasoning. This is further demonstrated by empirical results on the CLRS-30 dataset. Furthermore, we find the Neural PQs useful in capturing long-range interactions, as empirically shown on a dataset from the Long-Range Graph Benchmark.","sentences":["Graph Neural Networks (GNNs) have shown considerable success in neural algorithmic reasoning.","Many traditional algorithms make use of an explicit memory in the form of a data structure.","However, there has been limited exploration on augmenting GNNs with external memory.","In this paper, we present Neural Priority Queues, a differentiable analogue to algorithmic priority queues, for GNNs.","We propose and motivate a desiderata for memory modules, and show that Neural PQs exhibit the desiderata, and reason about their use with algorithmic reasoning.","This is further demonstrated by empirical results on the CLRS-30 dataset.","Furthermore, we find the Neural PQs useful in capturing long-range interactions, as empirically shown on a dataset from the Long-Range Graph Benchmark."],"url":"http://arxiv.org/abs/2307.09660v1"}
{"created":"2023-07-18 21:53:40","title":"HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual Learning","abstract":"Catastrophic forgetting, the phenomenon in which a neural network loses previously obtained knowledge during the learning of new tasks, poses a significant challenge in continual learning. The Hard-Attention-to-the-Task (HAT) mechanism has shown potential in mitigating this problem, but its practical implementation has been complicated by issues of usability and compatibility, and a lack of support for existing network reuse. In this paper, we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT mechanism. HAT-CL not only automates gradient manipulation but also streamlines the transformation of PyTorch modules into HAT modules. It achieves this by providing a comprehensive suite of modules that can be seamlessly integrated into existing architectures. Additionally, HAT-CL offers ready-to-use HAT networks that are smoothly integrated with the TIMM library. Beyond the redesign and reimplementation of HAT, we also introduce novel mask manipulation techniques for HAT, which have consistently shown improvements across various experiments. Our work paves the way for a broader application of the HAT mechanism, opening up new possibilities in continual learning across diverse models and applications.","sentences":["Catastrophic forgetting, the phenomenon in which a neural network loses previously obtained knowledge during the learning of new tasks, poses a significant challenge in continual learning.","The Hard-Attention-to-the-Task (HAT) mechanism has shown potential in mitigating this problem, but its practical implementation has been complicated by issues of usability and compatibility, and a lack of support for existing network reuse.","In this paper, we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT mechanism.","HAT-CL not only automates gradient manipulation but also streamlines the transformation of PyTorch modules into HAT modules.","It achieves this by providing a comprehensive suite of modules that can be seamlessly integrated into existing architectures.","Additionally, HAT-CL offers ready-to-use HAT networks that are smoothly integrated with the TIMM library.","Beyond the redesign and reimplementation of HAT, we also introduce novel mask manipulation techniques for HAT, which have consistently shown improvements across various experiments.","Our work paves the way for a broader application of the HAT mechanism, opening up new possibilities in continual learning across diverse models and applications."],"url":"http://arxiv.org/abs/2307.09653v1"}
{"created":"2023-07-18 21:51:47","title":"VISER: A Tractable Solution Concept for Games with Information Asymmetry","abstract":"Many real-world games suffer from information asymmetry: one player is only aware of their own payoffs while the other player has the full game information. Examples include the critical domain of security games and adversarial multi-agent reinforcement learning. Information asymmetry renders traditional solution concepts such as Strong Stackelberg Equilibrium (SSE) and Robust-Optimization Equilibrium (ROE) inoperative. We propose a novel solution concept called VISER (Victim Is Secure, Exploiter best-Responds). VISER enables an external observer to predict the outcome of such games. In particular, for security applications, VISER allows the victim to better defend itself while characterizing the most damaging attacks available to the attacker. We show that each player's VISER strategy can be computed independently in polynomial time using linear programming (LP). We also extend VISER to its Markov-perfect counterpart for Markov games, which can be solved efficiently using a series of LPs.","sentences":["Many real-world games suffer from information asymmetry: one player is only aware of their own payoffs while the other player has the full game information.","Examples include the critical domain of security games and adversarial multi-agent reinforcement learning.","Information asymmetry renders traditional solution concepts such as Strong Stackelberg Equilibrium (SSE) and Robust-Optimization Equilibrium (ROE) inoperative.","We propose a novel solution concept called VISER (Victim Is Secure, Exploiter best-Responds).","VISER enables an external observer to predict the outcome of such games.","In particular, for security applications, VISER allows the victim to better defend itself while characterizing the most damaging attacks available to the attacker.","We show that each player's VISER strategy can be computed independently in polynomial time using linear programming (LP).","We also extend VISER to its Markov-perfect counterpart for Markov games, which can be solved efficiently using a series of LPs."],"url":"http://arxiv.org/abs/2307.09652v1"}
{"created":"2023-07-18 21:43:37","title":"With Flying Colors: Predicting Community Success in Large-scale Collaborative Campaigns","abstract":"Online communities develop unique characteristics, establish social norms, and exhibit distinct dynamics among their members. Activity in online communities often results in concrete ``off-line'' actions with a broad societal impact (e.g., political street protests and norms related to sexual misconduct). While community dynamics, information diffusion, and online collaborations have been widely studied in the past two decades, quantitative studies that measure the effectiveness of online communities in promoting their agenda are scarce. In this work, we study the correspondence between the effectiveness of a community, measured by its success level in a competitive online campaign, and the underlying dynamics between its members. To this end, we define a novel task: predicting the success level of online communities in Reddit's r/place - a large-scale distributed experiment that required collaboration between community members. We consider an array of definitions for success level; each is geared toward different aspects of collaborative achievement. We experiment with several hybrid models, combining various types of features. Our models significantly outperform all baseline models over all definitions of `success level'. Analysis of the results and the factors that contribute to the success of coordinated campaigns can provide a better understanding of the resilience or the vulnerability of communities to online social threats such as election interference or anti-science trends. We make all data used for this study publicly available for further research.","sentences":["Online communities develop unique characteristics, establish social norms, and exhibit distinct dynamics among their members.","Activity in online communities often results in concrete ``off-line'' actions with a broad societal impact (e.g., political street protests and norms related to sexual misconduct).","While community dynamics, information diffusion, and online collaborations have been widely studied in the past two decades, quantitative studies that measure the effectiveness of online communities in promoting their agenda are scarce.","In this work, we study the correspondence between the effectiveness of a community, measured by its success level in a competitive online campaign, and the underlying dynamics between its members.","To this end, we define a novel task: predicting the success level of online communities in Reddit's r/place - a large-scale distributed experiment that required collaboration between community members.","We consider an array of definitions for success level; each is geared toward different aspects of collaborative achievement.","We experiment with several hybrid models, combining various types of features.","Our models significantly outperform all baseline models over all definitions of `success level'.","Analysis of the results and the factors that contribute to the success of coordinated campaigns can provide a better understanding of the resilience or the vulnerability of communities to online social threats such as election interference or anti-science trends.","We make all data used for this study publicly available for further research."],"url":"http://arxiv.org/abs/2307.09650v1"}
{"created":"2023-07-18 21:39:39","title":"Application of BadNets in Spam Filters","abstract":"Spam filters are a crucial component of modern email systems, as they help to protect users from unwanted and potentially harmful emails. However, the effectiveness of these filters is dependent on the quality of the machine learning models that power them. In this paper, we design backdoor attacks in the domain of spam filtering. By demonstrating the potential vulnerabilities in the machine learning model supply chain, we highlight the need for careful consideration and evaluation of the models used in spam filters. Our results show that the backdoor attacks can be effectively used to identify vulnerabilities in spam filters and suggest the need for ongoing monitoring and improvement in this area.","sentences":["Spam filters are a crucial component of modern email systems, as they help to protect users from unwanted and potentially harmful emails.","However, the effectiveness of these filters is dependent on the quality of the machine learning models that power them.","In this paper, we design backdoor attacks in the domain of spam filtering.","By demonstrating the potential vulnerabilities in the machine learning model supply chain, we highlight the need for careful consideration and evaluation of the models used in spam filters.","Our results show that the backdoor attacks can be effectively used to identify vulnerabilities in spam filters and suggest the need for ongoing monitoring and improvement in this area."],"url":"http://arxiv.org/abs/2307.09649v1"}
{"created":"2023-07-18 21:39:15","title":"On the Existence of Envy-Free Allocations Beyond Additive Valuations","abstract":"We study the problem of fairly allocating $m$ indivisible items among $n$ agents. Envy-free allocations, in which each agent prefers her bundle to the bundle of every other agent, need not exist in the worst case. However, when agents have additive preferences and the value $v_{i,j}$ of agent $i$ for item $j$ is drawn independently from a distribution $D_i$, envy-free allocations exist with high probability when $m \\in \\Omega( n \\log n / \\log \\log n )$.   In this paper, we study the existence of envy-free allocations under stochastic valuations far beyond the additive setting. We introduce a new stochastic model in which each agent's valuation is sampled by first fixing a worst-case function, and then drawing a uniformly random renaming of the items, independently for each agent. This strictly generalizes known settings; for example, $v_{i,j} \\sim D_i$ may be seen as picking a random (instead of a worst-case) additive function before renaming. We prove that random renaming is sufficient to ensure that envy-free allocations exist with high probability in very general settings. When valuations are non-negative and ``order-consistent,'' a valuation class that generalizes additive, budget-additive, unit-demand, and single-minded agents, SD-envy-free allocations (a stronger notion of fairness than envy-freeness) exist for $m \\in \\omega(n^2)$ when $n$ divides $m$, and SD-EFX allocations exist for all $m \\in \\omega(n^2)$. The dependence on $n$ is tight, that is, for $m \\in O(n^2)$ envy-free allocations don't exist with constant probability. For the case of arbitrary valuations (allowing non-monotone, negative, or mixed-manna valuations) and $n=2$ agents, we prove envy-free allocations exist with probability $1 - \\Theta(1/m)$ (and this is tight).","sentences":["We study the problem of fairly allocating $m$ indivisible items among $n$ agents.","Envy-free allocations, in which each agent prefers her bundle to the bundle of every other agent, need not exist in the worst case.","However, when agents have additive preferences and the value $v_{i,j}$ of agent $i$ for item $j$ is drawn independently from a distribution $D_i$, envy-free allocations exist with high probability when $m \\in \\Omega( n \\log n / \\log \\log n )$.   ","In this paper, we study the existence of envy-free allocations under stochastic valuations far beyond the additive setting.","We introduce a new stochastic model in which each agent's valuation is sampled by first fixing a worst-case function, and then drawing a uniformly random renaming of the items, independently for each agent.","This strictly generalizes known settings; for example, $v_{i,j} \\sim D_i$ may be seen as picking a random (instead of a worst-case) additive function before renaming.","We prove that random renaming is sufficient to ensure that envy-free allocations exist with high probability in very general settings.","When valuations are non-negative and ``order-consistent,'' a valuation class that generalizes additive, budget-additive, unit-demand, and single-minded agents, SD-envy-free allocations (a stronger notion of fairness than envy-freeness) exist for $m \\in \\omega(n^2)$ when $n$ divides $m$, and SD-EFX allocations exist for all $m \\in \\omega(n^2)$. The dependence on $n$ is tight, that is, for $m \\in O(n^2)$ envy-free allocations don't exist with constant probability.","For the case of arbitrary valuations (allowing non-monotone, negative, or mixed-manna valuations) and $n=2$ agents, we prove envy-free allocations exist with probability $1 - \\Theta(1/m)$ (and this is tight)."],"url":"http://arxiv.org/abs/2307.09648v1"}
{"created":"2023-07-18 21:10:59","title":"Skin Lesion Correspondence Localization in Total Body Photography","abstract":"Longitudinal tracking of skin lesions - finding correspondence, changes in morphology, and texture - is beneficial to the early detection of melanoma. However, it has not been well investigated in the context of full-body imaging. We propose a novel framework combining geometric and texture information to localize skin lesion correspondence from a source scan to a target scan in total body photography (TBP). Body landmarks or sparse correspondence are first created on the source and target 3D textured meshes. Every vertex on each of the meshes is then mapped to a feature vector characterizing the geodesic distances to the landmarks on that mesh. Then, for each lesion of interest (LOI) on the source, its corresponding location on the target is first coarsely estimated using the geometric information encoded in the feature vectors and then refined using the texture information. We evaluated the framework quantitatively on both a public and a private dataset, for which our success rates (at 10 mm criterion) are comparable to the only reported longitudinal study. As full-body 3D capture becomes more prevalent and has higher quality, we expect the proposed method to constitute a valuable step in the longitudinal tracking of skin lesions.","sentences":["Longitudinal tracking of skin lesions - finding correspondence, changes in morphology, and texture - is beneficial to the early detection of melanoma.","However, it has not been well investigated in the context of full-body imaging.","We propose a novel framework combining geometric and texture information to localize skin lesion correspondence from a source scan to a target scan in total body photography (TBP).","Body landmarks or sparse correspondence are first created on the source and target 3D textured meshes.","Every vertex on each of the meshes is then mapped to a feature vector characterizing the geodesic distances to the landmarks on that mesh.","Then, for each lesion of interest (LOI) on the source, its corresponding location on the target is first coarsely estimated using the geometric information encoded in the feature vectors and then refined using the texture information.","We evaluated the framework quantitatively on both a public and a private dataset, for which our success rates (at 10 mm criterion) are comparable to the only reported longitudinal study.","As full-body 3D capture becomes more prevalent and has higher quality, we expect the proposed method to constitute a valuable step in the longitudinal tracking of skin lesions."],"url":"http://arxiv.org/abs/2307.09642v1"}
{"created":"2023-07-18 21:03:01","title":"Accelerating End-host Congestion Response using P4 Programmable Switches","abstract":"Transport layer congestion control relies on feedback signals that travel from the congested link to the receiver and back to the sender. This forward congestion control loop, first, requires at least one rount-trip time (RTT) to react to congestion and secondly, it depends on the downstream path after the bottleneck. The former property leads to a reaction time in the order of RTT + bottleneck queue delay, while the second may amplify the unfairness due to heterogeneous RTT. In this paper, we present Reverse Path Congestion Marking (RPM) to accelerate the reaction to network congestion events without changing the end-host stack. RPM decouples the congestion signal from the downstream path after the bottleneck while maintaining the stability of the congestion control loop. We show that RPM improves throughput fairness for RTT-heterogeneous TCP flows as well as the flow completion time, especially for small Data Center TCP (DCTCP) flows. Finally, we show RPM evaluation results in a testbed built around P4 programmable ASIC switches.","sentences":["Transport layer congestion control relies on feedback signals that travel from the congested link to the receiver and back to the sender.","This forward congestion control loop, first, requires at least one rount-trip time (RTT) to react to congestion and secondly, it depends on the downstream path after the bottleneck.","The former property leads to a reaction time in the order of RTT + bottleneck queue delay, while the second may amplify the unfairness due to heterogeneous RTT.","In this paper, we present Reverse Path Congestion Marking (RPM) to accelerate the reaction to network congestion events without changing the end-host stack.","RPM decouples the congestion signal from the downstream path after the bottleneck while maintaining the stability of the congestion control loop.","We show that RPM improves throughput fairness for RTT-heterogeneous TCP flows as well as the flow completion time, especially for small Data Center TCP (DCTCP) flows.","Finally, we show RPM evaluation results in a testbed built around P4 programmable ASIC switches."],"url":"http://arxiv.org/abs/2307.09639v1"}
{"created":"2023-07-18 20:59:52","title":"Promoting Exploration in Memory-Augmented Adam using Critical Momenta","abstract":"Adaptive gradient-based optimizers, particularly Adam, have left their mark in training large-scale deep learning models. The strength of such optimizers is that they exhibit fast convergence while being more robust to hyperparameter choice. However, they often generalize worse than non-adaptive methods. Recent studies have tied this performance gap to flat minima selection: adaptive methods tend to find solutions in sharper basins of the loss landscape, which in turn hurts generalization. To overcome this issue, we propose a new memory-augmented version of Adam that promotes exploration towards flatter minima by using a buffer of critical momentum terms during training. Intuitively, the use of the buffer makes the optimizer overshoot outside the basin of attraction if it is not wide enough. We empirically show that our method improves the performance of several variants of Adam on standard supervised language modelling and image classification tasks.","sentences":["Adaptive gradient-based optimizers, particularly Adam, have left their mark in training large-scale deep learning models.","The strength of such optimizers is that they exhibit fast convergence while being more robust to hyperparameter choice.","However, they often generalize worse than non-adaptive methods.","Recent studies have tied this performance gap to flat minima selection: adaptive methods tend to find solutions in sharper basins of the loss landscape, which in turn hurts generalization.","To overcome this issue, we propose a new memory-augmented version of Adam that promotes exploration towards flatter minima by using a buffer of critical momentum terms during training.","Intuitively, the use of the buffer makes the optimizer overshoot outside the basin of attraction if it is not wide enough.","We empirically show that our method improves the performance of several variants of Adam on standard supervised language modelling and image classification tasks."],"url":"http://arxiv.org/abs/2307.09638v1"}
{"created":"2023-07-18 20:56:41","title":"Traffic-Domain Video Question Answering with Automatic Captioning","abstract":"Video Question Answering (VidQA) exhibits remarkable potential in facilitating advanced machine reasoning capabilities within the domains of Intelligent Traffic Monitoring and Intelligent Transportation Systems. Nevertheless, the integration of urban traffic scene knowledge into VidQA systems has received limited attention in previous research endeavors. In this work, we present a novel approach termed Traffic-domain Video Question Answering with Automatic Captioning (TRIVIA), which serves as a weak-supervision technique for infusing traffic-domain knowledge into large video-language models. Empirical findings obtained from the SUTD-TrafficQA task highlight the substantial enhancements achieved by TRIVIA, elevating the accuracy of representative video-language models by a remarkable 6.5 points (19.88%) compared to baseline settings. This pioneering methodology holds great promise for driving advancements in the field, inspiring researchers and practitioners alike to unlock the full potential of emerging video-language models in traffic-related applications.","sentences":["Video Question Answering (VidQA) exhibits remarkable potential in facilitating advanced machine reasoning capabilities within the domains of Intelligent Traffic Monitoring and Intelligent Transportation Systems.","Nevertheless, the integration of urban traffic scene knowledge into VidQA systems has received limited attention in previous research endeavors.","In this work, we present a novel approach termed Traffic-domain Video Question Answering with Automatic Captioning (TRIVIA), which serves as a weak-supervision technique for infusing traffic-domain knowledge into large video-language models.","Empirical findings obtained from the SUTD-TrafficQA task highlight the substantial enhancements achieved by TRIVIA, elevating the accuracy of representative video-language models by a remarkable 6.5 points (19.88%) compared to baseline settings.","This pioneering methodology holds great promise for driving advancements in the field, inspiring researchers and practitioners alike to unlock the full potential of emerging video-language models in traffic-related applications."],"url":"http://arxiv.org/abs/2307.09636v1"}
