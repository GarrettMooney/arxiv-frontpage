{"created":"2023-07-06 17:59:31","title":"Synthesizing Artistic Cinemagraphs from Text","abstract":"We introduce Artistic Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images. Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static. To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin. While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis. Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information. The predicted motion can then be transferred to the artistic image to create the final cinemagraph. Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies. Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text.","sentences":["We introduce Artistic Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images.","Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static.","To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin.","While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis.","Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information.","The predicted motion can then be transferred to the artistic image to create the final cinemagraph.","Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies.","Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text."],"url":"http://arxiv.org/abs/2307.03190v1"}
{"created":"2023-07-06 17:58:40","title":"TGRL: An Algorithm for Teacher Guided Reinforcement Learning","abstract":"Learning from rewards (i.e., reinforcement learning or RL) and learning to imitate a teacher (i.e., teacher-student learning) are two established approaches for solving sequential decision-making problems. To combine the benefits of these different forms of learning, it is common to train a policy to maximize a combination of reinforcement and teacher-student learning objectives. However, without a principled method to balance these objectives, prior work used heuristics and problem-specific hyperparameter searches to balance the two objectives. We present a $\\textit{principled}$ approach, along with an approximate implementation for $\\textit{dynamically}$ and $\\textit{automatically}$ balancing when to follow the teacher and when to use rewards. The main idea is to adjust the importance of teacher supervision by comparing the agent's performance to the counterfactual scenario of the agent learning without teacher supervision and only from rewards. If using teacher supervision improves performance, the importance of teacher supervision is increased and otherwise it is decreased. Our method, $\\textit{Teacher Guided Reinforcement Learning}$ (TGRL), outperforms strong baselines across diverse domains without hyper-parameter tuning.","sentences":["Learning from rewards (i.e., reinforcement learning or RL) and learning to imitate a teacher (i.e., teacher-student learning) are two established approaches for solving sequential decision-making problems.","To combine the benefits of these different forms of learning, it is common to train a policy to maximize a combination of reinforcement and teacher-student learning objectives.","However, without a principled method to balance these objectives, prior work used heuristics and problem-specific hyperparameter searches to balance the two objectives.","We present a $\\textit{principled}$ approach, along with an approximate implementation for $\\textit{dynamically}$ and $\\textit{automatically}$ balancing when to follow the teacher and when to use rewards.","The main idea is to adjust the importance of teacher supervision by comparing the agent's performance to the counterfactual scenario of the agent learning without teacher supervision and only from rewards.","If using teacher supervision improves performance, the importance of teacher supervision is increased and otherwise it is decreased.","Our method, $\\textit{Teacher Guided Reinforcement Learning}$ (TGRL), outperforms strong baselines across diverse domains without hyper-parameter tuning."],"url":"http://arxiv.org/abs/2307.03186v1"}
{"created":"2023-07-06 17:58:28","title":"Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong General Audio Event Taggers","abstract":"In this paper, we focus on Whisper, a recent automatic speech recognition model trained with a massive 680k hour labeled speech corpus recorded in diverse conditions. We first show an interesting finding that while Whisper is very robust against real-world background sounds (e.g., music), its audio representation is actually not noise-invariant, but is instead highly correlated to non-speech sounds, indicating that Whisper recognizes speech conditioned on the noise type. With this finding, we build a unified audio tagging and speech recognition model Whisper-AT by freezing the backbone of Whisper, and training a lightweight audio tagging model on top of it. With <1% extra computational cost, Whisper-AT can recognize audio events, in addition to spoken text, in a single forward pass.","sentences":["In this paper, we focus on Whisper, a recent automatic speech recognition model trained with a massive 680k hour labeled speech corpus recorded in diverse conditions.","We first show an interesting finding that while Whisper is very robust against real-world background sounds (e.g., music), its audio representation is actually not noise-invariant, but is instead highly correlated to non-speech sounds, indicating that Whisper recognizes speech conditioned on the noise type.","With this finding, we build a unified audio tagging and speech recognition model Whisper-AT by freezing the backbone of Whisper, and training a lightweight audio tagging model on top of it.","With <1% extra computational cost, Whisper-AT can recognize audio events, in addition to spoken text, in a single forward pass."],"url":"http://arxiv.org/abs/2307.03183v1"}
{"created":"2023-07-06 17:58:01","title":"Markov Persuasion Processes with Endogenous Agent Beliefs","abstract":"We consider a dynamic Bayesian persuasion setting where a single long-lived sender persuades a stream of ``short-lived'' agents (receivers) by sharing information about a payoff-relevant state. The state transitions are Markovian and the sender seeks to maximize the long-run average reward by committing to a (possibly history-dependent) signaling mechanism. While most previous studies of Markov persuasion consider exogenous agent beliefs that are independent of the chain, we study a more natural variant with endogenous agent beliefs that depend on the chain's realized history. A key challenge to analyze such settings is to model the agents' partial knowledge about the history information. We analyze a Markov persuasion process (MPP) under various information models that differ in the amount of information the receivers have about the history of the process. Specifically, we formulate a general partial-information model where each receiver observes the history with an $\\ell$ period lag. Our technical contribution start with analyzing two benchmark models, i.e., the full-history information model and the no-history information model. We establish an ordering of the sender's payoff as a function of the informativeness of agent's information model (with no-history as the least informative), and develop efficient algorithms to compute optimal solutions for these two benchmarks. For general $\\ell$, we present the technical challenges in finding an optimal signaling mechanism, where even determining the right dependency on the history becomes difficult. To bypass the difficulties, we use a robustness framework to design a \"simple\" \\emph{history-independent} signaling mechanism that approximately achieves optimal payoff when $\\ell$ is reasonably large.","sentences":["We consider a dynamic Bayesian persuasion setting where a single long-lived sender persuades a stream of ``short-lived'' agents (receivers) by sharing information about a payoff-relevant state.","The state transitions are Markovian and the sender seeks to maximize the long-run average reward by committing to a (possibly history-dependent) signaling mechanism.","While most previous studies of Markov persuasion consider exogenous agent beliefs that are independent of the chain, we study a more natural variant with endogenous agent beliefs that depend on the chain's realized history.","A key challenge to analyze such settings is to model the agents' partial knowledge about the history information.","We analyze a Markov persuasion process (MPP) under various information models that differ in the amount of information the receivers have about the history of the process.","Specifically, we formulate a general partial-information model where each receiver observes the history with an $\\ell$ period lag.","Our technical contribution start with analyzing two benchmark models, i.e., the full-history information model and the no-history information model.","We establish an ordering of the sender's payoff as a function of the informativeness of agent's information model (with no-history as the least informative), and develop efficient algorithms to compute optimal solutions for these two benchmarks.","For general $\\ell$, we present the technical challenges in finding an optimal signaling mechanism, where even determining the right dependency on the history becomes difficult.","To bypass the difficulties, we use a robustness framework to design a \"simple\" \\emph{history-independent} signaling mechanism that approximately achieves optimal payoff when $\\ell$ is reasonably large."],"url":"http://arxiv.org/abs/2307.03181v1"}
{"created":"2023-07-06 17:57:02","title":"IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model","abstract":"Generating complete 360-degree panoramas from narrow field of view images is ongoing research as omnidirectional RGB data is not readily available. Existing GAN-based approaches face some barriers to achieving higher quality output, and have poor generalization performance over different mask types. In this paper, we present our 360-degree indoor RGB panorama outpainting model using latent diffusion models (LDM), called IPO-LDM. We introduce a new bi-modal latent diffusion structure that utilizes both RGB and depth panoramic data during training, but works surprisingly well to outpaint normal depth-free RGB images during inference. We further propose a novel technique of introducing progressive camera rotations during each diffusion denoising step, which leads to substantial improvement in achieving panorama wraparound consistency. Results show that our IPO-LDM not only significantly outperforms state-of-the-art methods on RGB panorama outpainting, but can also produce multiple and diverse well-structured results for different types of masks.","sentences":["Generating complete 360-degree panoramas from narrow field of view images is ongoing research as omnidirectional RGB data is not readily available.","Existing GAN-based approaches face some barriers to achieving higher quality output, and have poor generalization performance over different mask types.","In this paper, we present our 360-degree indoor RGB panorama outpainting model using latent diffusion models (LDM), called IPO-LDM.","We introduce a new bi-modal latent diffusion structure that utilizes both RGB and depth panoramic data during training, but works surprisingly well to outpaint normal depth-free RGB images during inference.","We further propose a novel technique of introducing progressive camera rotations during each diffusion denoising step, which leads to substantial improvement in achieving panorama wraparound consistency.","Results show that our IPO-LDM not only significantly outperforms state-of-the-art methods on RGB panorama outpainting, but can also produce multiple and diverse well-structured results for different types of masks."],"url":"http://arxiv.org/abs/2307.03177v1"}
{"created":"2023-07-06 17:55:28","title":"Push Past Green: Learning to Look Behind Plant Foliage by Moving It","abstract":"Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations. Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations.","sentences":["Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches.","Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging.","We tackle these challenges through data-driven methods.","We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant.","We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage.","Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage.","We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations.","Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations."],"url":"http://arxiv.org/abs/2307.03175v1"}
{"created":"2023-07-06 17:54:11","title":"Lost in the Middle: How Language Models Use Long Contexts","abstract":"While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.","sentences":["While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context.","We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval.","We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts.","Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models.","Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models."],"url":"http://arxiv.org/abs/2307.03172v1"}
{"created":"2023-07-06 17:52:29","title":"LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams","abstract":"Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time. However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering. To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time. Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is ~30-300% and ~10-200% faster at PF enumeration than common ordering strategies and algorithm configuration. Our code and instances are available at https://github.com/khalil-research/leo.","sentences":["Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems.","The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems.","We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach.","To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features.","We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time.","However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering.","To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time.","Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is ~30-300% and ~10-200% faster at PF enumeration than common ordering strategies and algorithm configuration.","Our code and instances are available at https://github.com/khalil-research/leo."],"url":"http://arxiv.org/abs/2307.03171v1"}
{"created":"2023-07-06 17:52:10","title":"Focused Transformer: Contrastive Training for Context Scaling","abstract":"Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context. This is demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context. We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval.","sentences":["Large language models have an exceptional capability to incorporate new information in a contextual manner.","However, the full potential of such an approach is often restrained due to a limitation in the effective context length.","One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs.","Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys.","We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish.","To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning.","This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.","Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context.","This is demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints.","The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context.","We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval."],"url":"http://arxiv.org/abs/2307.03170v1"}
{"created":"2023-07-06 17:48:27","title":"Risk-Averse Trajectory Optimization via Sample Average Approximation","abstract":"Trajectory optimization under uncertainty underpins a wide range of applications in robotics. However, existing methods are limited in terms of reasoning about sources of epistemic and aleatoric uncertainty, space and time correlations, nonlinear dynamics, and non-convex constraints. In this work, we first introduce a continuous-time planning formulation with an average-value-at-risk constraint over the entire planning horizon. Then, we propose a sample-based approximation that unlocks an efficient, general-purpose, and time-consistent algorithm for risk-averse trajectory optimization. We prove that the method is asymptotically optimal and derive finite-sample error bounds. Simulations demonstrate the high speed and reliability of the approach on problems with stochasticity in nonlinear dynamics, obstacle fields, interactions, and terrain parameters.","sentences":["Trajectory optimization under uncertainty underpins a wide range of applications in robotics.","However, existing methods are limited in terms of reasoning about sources of epistemic and aleatoric uncertainty, space and time correlations, nonlinear dynamics, and non-convex constraints.","In this work, we first introduce a continuous-time planning formulation with an average-value-at-risk constraint over the entire planning horizon.","Then, we propose a sample-based approximation that unlocks an efficient, general-purpose, and time-consistent algorithm for risk-averse trajectory optimization.","We prove that the method is asymptotically optimal and derive finite-sample error bounds.","Simulations demonstrate the high speed and reliability of the approach on problems with stochasticity in nonlinear dynamics, obstacle fields, interactions, and terrain parameters."],"url":"http://arxiv.org/abs/2307.03167v1"}
{"created":"2023-07-06 17:47:52","title":"VideoGLUE: Video General Understanding Evaluation of Foundation Models","abstract":"We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task. Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks. Our main findings are as follows. First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs.","sentences":["We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task.","Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks.","Our main findings are as follows.","First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding.","Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action.","Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning.","The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs."],"url":"http://arxiv.org/abs/2307.03166v1"}
{"created":"2023-07-06 17:42:56","title":"BrickPal: Augmented Reality-based Assembly Instructions for Brick Models","abstract":"The assembly instruction is a mandatory component of Lego-like brick sets.The conventional production of assembly instructions requires a considerable amount of manual fine-tuning, which is intractable for casual users and customized brick sets.Moreover, the traditional paper-based instructions lack expressiveness and interactivity.To tackle the two problems above, we present BrickPal, an augmented reality-based system, which visualizes assembly instructions in an augmented reality head-mounted display. It utilizes Natural Language Processing (NLP) techniques to generate plausible assembly sequences, and provide real-time guidance in the AR headset.Our user study demonstrates BrickPal's effectiveness at assisting users in brick assembly compared to traditional assembly methods. Additionally, the NLP algorithm-generated assembly sequences achieve the same usability with manually adapted sequences.","sentences":["The assembly instruction is a mandatory component of Lego-like brick sets.","The conventional production of assembly instructions requires a considerable amount of manual fine-tuning, which is intractable for casual users and customized brick sets.","Moreover, the traditional paper-based instructions lack expressiveness and interactivity.","To tackle the two problems above, we present BrickPal, an augmented reality-based system, which visualizes assembly instructions in an augmented reality head-mounted display.","It utilizes Natural Language Processing (NLP) techniques to generate plausible assembly sequences, and provide real-time guidance in the AR headset.","Our user study demonstrates BrickPal's effectiveness at assisting users in brick assembly compared to traditional assembly methods.","Additionally, the NLP algorithm-generated assembly sequences achieve the same usability with manually adapted sequences."],"url":"http://arxiv.org/abs/2307.03162v1"}
{"created":"2023-07-06 17:32:38","title":"Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?","abstract":"Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant. However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system. In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification. In particular, we assess three UDA training schemes: single-, combined-, and multi-source. Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated. In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy. Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets. Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques.","sentences":["Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant.","However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system.","In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification.","In particular, we assess three UDA training schemes: single-, combined-, and multi-source.","Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated.","In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy.","Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets.","Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques."],"url":"http://arxiv.org/abs/2307.03157v1"}
{"created":"2023-07-06 17:29:34","title":"MultiVENT: Multilingual Videos of Events with Aligned Natural Text","abstract":"Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage. Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages. MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models. Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.","sentences":["Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage.","Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences.","We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages.","MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models.","Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT."],"url":"http://arxiv.org/abs/2307.03153v1"}
{"created":"2023-07-06 17:23:52","title":"On the Computation of Accessibility Provided by Shared Mobility","abstract":"Shared Mobility Services (SMS), e.g., Demand-Responsive Transit (DRT) or ride-sharing, can improve mobility in low-density areas, often poorly served by conventional Public Transport (PT). Such improvement is mostly quantified via basic performance indicators, like wait or travel time. However, accessibility indicators, measuring the ease of reaching surrounding opportunities (e.g., jobs, schools, shops, ...), would be a more comprehensive indicator. To date, no method exists to quantify the accessibility of SMS based on empirical measurements. Indeed, accessibility is generally computed on graph representations of PT networks, but SMS are dynamic and do not follow a predefined network. We propose a spatial-temporal statistical method that takes as input observed trips of a SMS acting as a feeder for PT and summarized such trips in a graph. On such a graph, we compute classic accessibility indicators. We apply our method to a MATSim simulation study concerning DRT in Paris-Saclay.","sentences":["Shared Mobility Services (SMS), e.g., Demand-Responsive Transit (DRT) or ride-sharing, can improve mobility in low-density areas, often poorly served by conventional Public Transport (PT).","Such improvement is mostly quantified via basic performance indicators, like wait or travel time.","However, accessibility indicators, measuring the ease of reaching surrounding opportunities (e.g., jobs, schools, shops, ...), would be a more comprehensive indicator.","To date, no method exists to quantify the accessibility of SMS based on empirical measurements.","Indeed, accessibility is generally computed on graph representations of PT networks, but SMS are dynamic and do not follow a predefined network.","We propose a spatial-temporal statistical method that takes as input observed trips of a SMS acting as a feeder for PT and summarized such trips in a graph.","On such a graph, we compute classic accessibility indicators.","We apply our method to a MATSim simulation study concerning DRT in Paris-Saclay."],"url":"http://arxiv.org/abs/2307.03148v1"}
{"created":"2023-07-06 17:05:26","title":"Distilling Large Vision-Language Model with Out-of-Distribution Generalizability","abstract":"Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Our code will be released at https://github.com/xuanlinli17/large_vlm_distillation_ood","sentences":["Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical.","Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution.","This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset.","Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature.","We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels.","We propose several metrics and conduct extensive experiments to investigate their techniques.","The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches.","Our code will be released at https://github.com/xuanlinli17/large_vlm_distillation_ood"],"url":"http://arxiv.org/abs/2307.03135v1"}
{"created":"2023-07-06 16:59:53","title":"Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification","abstract":"Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.","sentences":["Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction.","Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed.","However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness.","To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home.","These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation).","Furthermore, we explore the compatibility of different TTA methods with diverse network backbones.","To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures.","By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance.","Our code is available at https://github.com/yuyongcan/Benchmark-TTA."],"url":"http://arxiv.org/abs/2307.03133v1"}
{"created":"2023-07-06 16:59:52","title":"T-MARS: Improving Visual Representations by Circumventing Text Feature Learning","abstract":"Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the \"medium scale\" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. Code is available at https://github.com/locuslab/T-MARS.","sentences":["Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero-","and few-shot recognition.","One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets.","For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold.","In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption.","Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features.","However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text).","Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image.","Experimentally, T-MARS outperforms the top-ranked method on the \"medium scale\" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB.","Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially.","Code is available at https://github.com/locuslab/T-MARS."],"url":"http://arxiv.org/abs/2307.03132v1"}
{"created":"2023-07-06 16:59:30","title":"BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training","abstract":"Automatic metrics play a crucial role in machine translation. Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics. However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect. In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems. Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore. In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm. By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems. Codes are available at \\url{https://github.com/powerpuffpomelo/fairseq_mrt}.","sentences":["Automatic metrics play a crucial role in machine translation.","Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics.","However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect.","In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems.","Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore.","In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm.","By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems.","Codes are available at \\url{https://github.com/powerpuffpomelo/fairseq_mrt}."],"url":"http://arxiv.org/abs/2307.03131v1"}
{"created":"2023-07-06 16:58:27","title":"VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering","abstract":"We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries. VisKoP not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements. KoPL programs can be edited with simple graphical operators, such as dragging to add knowledge operators and slot filling to designate operator arguments. Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results. To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end. Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer. The VisKoP online demo https://demoviskop.xlore.cn (Stable release of this paper) and https://viskop.xlore.cn (Beta release with new features), highly efficient KoPL engine https://pypi.org/project/kopl-engine, and screencast video https://youtu.be/zAbJtxFPTXo are now publicly available.","sentences":["We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries.","VisKoP","not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements.","KoPL programs can be edited with simple graphical operators, such as dragging to add knowledge operators and slot filling to designate operator arguments.","Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results.","To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end.","Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer.","The VisKoP online demo https://demoviskop.xlore.cn (Stable release of this paper) and https://viskop.xlore.cn (Beta release with new features), highly efficient KoPL engine https://pypi.org/project/kopl-engine, and screencast video https://youtu.be/zAbJtxFPTXo are now publicly available."],"url":"http://arxiv.org/abs/2307.03130v1"}
{"created":"2023-07-06 16:52:20","title":"Context-Aware Configuration and Management of WiFi Direct Groups for Real Opportunistic Networks","abstract":"Wi-Fi Direct is a promising technology for the support of device-to-device communications (D2D) on commercial mobile devices. However, the standard as-it-is is not sufficient to support the real deployment of networking solutions entirely based on D2D such as opportunistic networks. In fact, WiFi Direct presents some characteristics that could limit the autonomous creation of D2D connections among users' personal devices. Specifically, the standard explicitly requires the user's authorization to establish a connection between two or more devices, and it provides a limited support for inter-group communication. In some cases, this might lead to the creation of isolated groups of nodes which cannot communicate among each other. In this paper, we propose a novel middleware-layer protocol for the efficient configuration and management of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enable autonomous connections and inter-group communication. This enables opportunistic networks in real conditions (e.g., variable mobility and network size). WFD-GM defines a context function that takes into account heterogeneous parameters for the creation of the best group configuration in a specific time window, including an index of nodes' stability and power levels. We evaluate the protocol performances by simulating three reference scenarios including different mobility models, geographical areas and number of nodes. Simulations are also supported by experimental results related to the evaluation in a real testbed of the involved context parameters. We compare WFD-GM with the state-of-the-art solutions and we show that it performs significantly better than a Baseline approach in scenarios with medium/low mobility, and it is comparable with it in case of high mobility, without introducing additional overhead.","sentences":["Wi-Fi Direct is a promising technology for the support of device-to-device communications (D2D) on commercial mobile devices.","However, the standard as-it-is is not sufficient to support the real deployment of networking solutions entirely based on D2D such as opportunistic networks.","In fact, WiFi Direct presents some characteristics that could limit the autonomous creation of D2D connections among users' personal devices.","Specifically, the standard explicitly requires the user's authorization to establish a connection between two or more devices, and it provides a limited support for inter-group communication.","In some cases, this might lead to the creation of isolated groups of nodes which cannot communicate among each other.","In this paper, we propose a novel middleware-layer protocol for the efficient configuration and management of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enable autonomous connections and inter-group communication.","This enables opportunistic networks in real conditions (e.g., variable mobility and network size).","WFD-GM defines a context function that takes into account heterogeneous parameters for the creation of the best group configuration in a specific time window, including an index of nodes' stability and power levels.","We evaluate the protocol performances by simulating three reference scenarios including different mobility models, geographical areas and number of nodes.","Simulations are also supported by experimental results related to the evaluation in a real testbed of the involved context parameters.","We compare WFD-GM with the state-of-the-art solutions and we show that it performs significantly better than a Baseline approach in scenarios with medium/low mobility, and it is comparable with it in case of high mobility, without introducing additional overhead."],"url":"http://arxiv.org/abs/2307.03126v1"}
{"created":"2023-07-06 16:48:32","title":"Extracting Multi-valued Relations from Language Models","abstract":"The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge. However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct. To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge. We formulate the problem as a rank-then-select task. For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge. Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score. Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task and pave the way for further research on extracting relational knowledge from latent language representations.","sentences":["The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge.","However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct.","To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge.","We formulate the problem as a rank-then-select task.","For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge.","Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score.","Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task and pave the way for further research on extracting relational knowledge from latent language representations."],"url":"http://arxiv.org/abs/2307.03122v1"}
{"created":"2023-07-06 16:45:40","title":"Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance","abstract":"Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market. To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly. It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient. The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method.","sentences":["Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets.","Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem.","However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias.","In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints.","Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits.","Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market.","To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly.","It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient.","The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method."],"url":"http://arxiv.org/abs/2307.03119v1"}
{"created":"2023-07-06 16:35:25","title":"KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding","abstract":"Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years. However, these benchmarks have encountered two major limitations. On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage. On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space. To overcome these limitations, we build a new challenging benchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format. Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions. Moreover, we use labels in knowledge bases rather than spans or choices as the final answers. We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the in-distribution and out-of-distribution test set, respectively. These results indicate that deep text understanding is still an unsolved challenge. The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/THU-KEG/KoRC.","sentences":["Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years.","However, these benchmarks have encountered two major limitations.","On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage.","On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space.","To overcome these limitations, we build a new challenging benchmark named KoRc in this paper.","Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format.","Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions.","Moreover, we use labels in knowledge bases rather than spans or choices as the final answers.","We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the in-distribution and out-of-distribution test set, respectively.","These results indicate that deep text understanding is still an unsolved challenge.","The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/THU-KEG/KoRC."],"url":"http://arxiv.org/abs/2307.03115v1"}
{"created":"2023-07-06 16:30:38","title":"JSONoid: Monoid-based Enrichment for Configurable and Scalable Data-Driven Schema Discovery","abstract":"Schema discovery is an important aspect to working with data in formats such as JSON. Unlike relational databases, JSON data sets often do not have associated structural information. Consumers of such datasets are often left to browse through data in an attempt to observe commonalities in structure across documents to construct suitable code for data processing. However, this process is time-consuming and error-prone. Existing distributed approaches to mining schemas present a significant usability advantage as they provide useful metadata for large data sources. However, depending on the data source, ad hoc queries for estimating other properties to help with crafting an efficient data pipeline can be expensive. We propose JSONoid, a distributed schema discovery process augmented with additional metadata in the form of monoid data structures that are easily maintainable in a distributed setting. JSONoid subsumes several existing approaches to distributed schema discovery with similar performance. Our approach also adds significant useful additional information about data values to discovered schemas with linear scalability.","sentences":["Schema discovery is an important aspect to working with data in formats such as JSON.","Unlike relational databases, JSON data sets often do not have associated structural information.","Consumers of such datasets are often left to browse through data in an attempt to observe commonalities in structure across documents to construct suitable code for data processing.","However, this process is time-consuming and error-prone.","Existing distributed approaches to mining schemas present a significant usability advantage as they provide useful metadata for large data sources.","However, depending on the data source, ad hoc queries for estimating other properties to help with crafting an efficient data pipeline can be expensive.","We propose JSONoid, a distributed schema discovery process augmented with additional metadata in the form of monoid data structures that are easily maintainable in a distributed setting.","JSONoid subsumes several existing approaches to distributed schema discovery with similar performance.","Our approach also adds significant useful additional information about data values to discovered schemas with linear scalability."],"url":"http://arxiv.org/abs/2307.03113v1"}
{"created":"2023-07-06 16:28:51","title":"LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search","abstract":"Search spaces hallmark the advancement of Neural Architecture Search (NAS). Large and complex search spaces with versatile building operators and structures provide more opportunities to brew promising architectures, yet pose severe challenges on efficient exploration and exploitation. Subsequently, several search space shrinkage methods optimize by selecting a single sub-region that contains some well-performing networks. Small performance and efficiency gains are observed with these methods but such techniques leave room for significantly improved search performance and are ineffective at retaining architectural diversity. We propose LISSNAS, an automated algorithm that shrinks a large space into a diverse, small search space with SOTA search performance. Our approach leverages locality, the relationship between structural and performance similarity, to efficiently extract many pockets of well-performing networks. We showcase our method on an array of search spaces spanning various sizes and datasets. We accentuate the effectiveness of our shrunk spaces when used in one-shot search by achieving the best Top-1 accuracy in two different search spaces. Our method achieves a SOTA Top-1 accuracy of 77.6\\% in ImageNet under mobile constraints, best-in-class Kendal-Tau, architectural diversity, and search space size.","sentences":["Search spaces hallmark the advancement of Neural Architecture Search (NAS).","Large and complex search spaces with versatile building operators and structures provide more opportunities to brew promising architectures, yet pose severe challenges on efficient exploration and exploitation.","Subsequently, several search space shrinkage methods optimize by selecting a single sub-region that contains some well-performing networks.","Small performance and efficiency gains are observed with these methods but such techniques leave room for significantly improved search performance and are ineffective at retaining architectural diversity.","We propose LISSNAS, an automated algorithm that shrinks a large space into a diverse, small search space with SOTA search performance.","Our approach leverages locality, the relationship between structural and performance similarity, to efficiently extract many pockets of well-performing networks.","We showcase our method on an array of search spaces spanning various sizes and datasets.","We accentuate the effectiveness of our shrunk spaces when used in one-shot search by achieving the best Top-1 accuracy in two different search spaces.","Our method achieves a SOTA Top-1 accuracy of 77.6\\% in ImageNet under mobile constraints, best-in-class Kendal-Tau, architectural diversity, and search space size."],"url":"http://arxiv.org/abs/2307.03110v1"}
{"created":"2023-07-06 16:28:35","title":"A Survey on Evaluation of Large Language Models","abstract":"Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.","sentences":["Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.","As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks.","Over the past years, significant efforts have been made to examine LLMs from various perspectives.","This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate.","Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas.","Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs.","Then, we summarize the success and failure cases of LLMs in different tasks.","Finally, we shed light on several future challenges that lie ahead in LLMs evaluation.","Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs.","Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs.","We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey."],"url":"http://arxiv.org/abs/2307.03109v1"}
{"created":"2023-07-06 16:27:39","title":"How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models","abstract":"Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages.","sentences":["Recent text-to-image diffusion models have shown surprising performance in generating high-quality images.","However, concerns have arisen regarding the unauthorized usage of data during the training process.","One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist.","To address this issue, it becomes crucial to detect unauthorized data usage.","In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset.","Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models.","By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data.","Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages."],"url":"http://arxiv.org/abs/2307.03108v1"}
{"created":"2023-07-06 16:26:41","title":"On Distribution-Preserving Mitigation Strategies for Communication under Cognitive Adversaries","abstract":"In wireless security, cognitive adversaries are known to inject jamming energy on the victim's frequency band and monitor the same band for countermeasures thereby trapping the victim. Under the class of cognitive adversaries, we propose a new threat model wherein the adversary, upon executing the jamming attack, measures the long-term statistic of Kullback-Leibler Divergence (KLD) between its observations over each of the network frequencies before and after the jamming attack. To mitigate this adversary, we propose a new cooperative strategy wherein the victim takes the assistance for a helper node in the network to reliably communicate its message to the destination. The underlying idea is to appropriately split their energy and time resources such that their messages are reliably communicated without disturbing the statistical distribution of the samples in the network. We present rigorous analyses on the reliability and the covertness metrics at the destination and the adversary, respectively, and then synthesize tractable algorithms to obtain near-optimal division of resources between the victim and the helper. Finally, we show that the obtained near-optimal division of energy facilitates in deceiving the adversary with a KLD estimator.","sentences":["In wireless security, cognitive adversaries are known to inject jamming energy on the victim's frequency band and monitor the same band for countermeasures thereby trapping the victim.","Under the class of cognitive adversaries, we propose a new threat model wherein the adversary, upon executing the jamming attack, measures the long-term statistic of Kullback-Leibler Divergence (KLD) between its observations over each of the network frequencies before and after the jamming attack.","To mitigate this adversary, we propose a new cooperative strategy wherein the victim takes the assistance for a helper node in the network to reliably communicate its message to the destination.","The underlying idea is to appropriately split their energy and time resources such that their messages are reliably communicated without disturbing the statistical distribution of the samples in the network.","We present rigorous analyses on the reliability and the covertness metrics at the destination and the adversary, respectively, and then synthesize tractable algorithms to obtain near-optimal division of resources between the victim and the helper.","Finally, we show that the obtained near-optimal division of energy facilitates in deceiving the adversary with a KLD estimator."],"url":"http://arxiv.org/abs/2307.03105v1"}
{"created":"2023-07-06 16:26:34","title":"Efficient Domain Adaptation of Sentence Embeddings using Adapters","abstract":"Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always using the same base model and only exchanging the domain-specific adapters to adapt sentence embeddings to a specific domain. We show that using adapters for parameter-efficient domain adaptation of sentence embeddings yields competitive performance within 1% of a domain-adapted, entirely fine-tuned sentence embedding model while only training approximately 3.6% of the parameters.","sentences":["Sentence embeddings enable us to capture the semantic similarity of short texts.","Most sentence embedding models are trained for general semantic textual similarity (STS) tasks.","Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results.","Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest.","While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive.","Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters.","These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters.","Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed.","Training domain-specific adapters allows always using the same base model and only exchanging the domain-specific adapters to adapt sentence embeddings to a specific domain.","We show that using adapters for parameter-efficient domain adaptation of sentence embeddings yields competitive performance within 1% of a domain-adapted, entirely fine-tuned sentence embedding model while only training approximately 3.6% of the parameters."],"url":"http://arxiv.org/abs/2307.03104v1"}
{"created":"2023-07-06 16:23:49","title":"Role Engine Implementation for a Continuous and Collaborative Multi-Robot System","abstract":"In situations involving teams of diverse robots, assigning appropriate roles to each robot and evaluating their performance is crucial. These roles define the specific characteristics of a robot within a given context. The stream actions exhibited by a robot based on its assigned role are referred to as the process role. Our research addresses the depiction of process roles using a multivariate probabilistic function. The main aim of this study is to develop a role engine for collaborative multi-robot systems and optimize the behavior of the robots. The role engine is designed to assign suitable roles to each robot, generate approximately optimal process roles, update them on time, and identify instances of robot malfunction or trigger replanning when necessary. The environment considered is dynamic, involving obstacles and other agents. The role engine operates hybrid, with central initiation and decentralized action, and assigns unlabeled roles to agents. We employ the Gaussian Process (GP) inference method to optimize process roles based on local constraints and constraints related to other agents. Furthermore, we propose an innovative approach that utilizes the environment's skeleton to address initialization and feasibility evaluation challenges. We successfully demonstrated the proposed approach's feasibility, and efficiency through simulation studies and real-world experiments involving diverse mobile robots.","sentences":["In situations involving teams of diverse robots, assigning appropriate roles to each robot and evaluating their performance is crucial.","These roles define the specific characteristics of a robot within a given context.","The stream actions exhibited by a robot based on its assigned role are referred to as the process role.","Our research addresses the depiction of process roles using a multivariate probabilistic function.","The main aim of this study is to develop a role engine for collaborative multi-robot systems and optimize the behavior of the robots.","The role engine is designed to assign suitable roles to each robot, generate approximately optimal process roles, update them on time, and identify instances of robot malfunction or trigger replanning when necessary.","The environment considered is dynamic, involving obstacles and other agents.","The role engine operates hybrid, with central initiation and decentralized action, and assigns unlabeled roles to agents.","We employ the Gaussian Process (GP) inference method to optimize process roles based on local constraints and constraints related to other agents.","Furthermore, we propose an innovative approach that utilizes the environment's skeleton to address initialization and feasibility evaluation challenges.","We successfully demonstrated the proposed approach's feasibility, and efficiency through simulation studies and real-world experiments involving diverse mobile robots."],"url":"http://arxiv.org/abs/2307.03103v1"}
{"created":"2023-07-06 16:18:14","title":"Contextual Affinity Distillation for Image Anomaly Detection","abstract":"Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset.","sentences":["Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination.","While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position.","In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior.","The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies.","To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring.","Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset."],"url":"http://arxiv.org/abs/2307.03101v1"}
{"created":"2023-07-06 16:08:47","title":"Beyond Intuition, a Framework for Applying GPs to Real-World Data","abstract":"Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.","sentences":["Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets.","However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets.","We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model.","The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability.","The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time."],"url":"http://arxiv.org/abs/2307.03093v1"}
{"created":"2023-07-06 16:01:43","title":"Volumetric Occupancy Detection: A Comparative Analysis of Mapping Algorithms","abstract":"Despite the growing interest in innovative functionalities for collaborative robotics, volumetric detection remains indispensable for ensuring basic security. However, there is a lack of widely used volumetric detection frameworks specifically tailored to this domain, and existing evaluation metrics primarily focus on time and memory efficiency. To bridge this gap, the authors present a detailed comparison using a simulation environment, ground truth extraction, and automated evaluation metrics calculation. This enables the evaluation of state-of-the-art volumetric mapping algorithms, including OctoMap, SkiMap, and Voxblox, providing valuable insights and comparisons through the impact of qualitative and quantitative analyses. The study not only compares different frameworks but also explores various parameters within each framework, offering additional insights into their performance.","sentences":["Despite the growing interest in innovative functionalities for collaborative robotics, volumetric detection remains indispensable for ensuring basic security.","However, there is a lack of widely used volumetric detection frameworks specifically tailored to this domain, and existing evaluation metrics primarily focus on time and memory efficiency.","To bridge this gap, the authors present a detailed comparison using a simulation environment, ground truth extraction, and automated evaluation metrics calculation.","This enables the evaluation of state-of-the-art volumetric mapping algorithms, including OctoMap, SkiMap, and Voxblox, providing valuable insights and comparisons through the impact of qualitative and quantitative analyses.","The study not only compares different frameworks but also explores various parameters within each framework, offering additional insights into their performance."],"url":"http://arxiv.org/abs/2307.03089v1"}
{"created":"2023-07-06 15:50:58","title":"Predicting Opioid Use Outcomes in Minoritized Communities","abstract":"Machine learning algorithms can sometimes exacerbate health disparities based on ethnicity, gender, and other factors. There has been limited work at exploring potential biases within algorithms deployed on a small scale, and/or within minoritized communities. Understanding the nature of potential biases may improve the prediction of various health outcomes. As a case study, we used data from a sample of 539 young adults from minoritized communities who engaged in nonmedical use of prescription opioids and/or heroin. We addressed the indicated issues through the following contributions: 1) Using machine learning techniques, we predicted a range of opioid use outcomes for participants in our dataset; 2) We assessed if algorithms trained only on a majority sub-sample (e.g., Non-Hispanic/Latino, male), could accurately predict opioid use outcomes for a minoritized sub-sample (e.g., Latino, female). Results indicated that models trained on a random sample of our data could predict a range of opioid use outcomes with high precision. However, we noted a decrease in precision when we trained our models on data from a majority sub-sample, and tested these models on a minoritized sub-sample. We posit that a range of cultural factors and systemic forms of discrimination are not captured by data from majority sub-samples. Broadly, for predictions to be valid, models should be trained on data that includes adequate representation of the groups of people about whom predictions will be made. Stakeholders may utilize our findings to mitigate biases in models for predicting opioid use outcomes within minoritized communities.","sentences":["Machine learning algorithms can sometimes exacerbate health disparities based on ethnicity, gender, and other factors.","There has been limited work at exploring potential biases within algorithms deployed on a small scale, and/or within minoritized communities.","Understanding the nature of potential biases may improve the prediction of various health outcomes.","As a case study, we used data from a sample of 539 young adults from minoritized communities who engaged in nonmedical use of prescription opioids and/or heroin.","We addressed the indicated issues through the following contributions: 1) Using machine learning techniques, we predicted a range of opioid use outcomes for participants in our dataset; 2) We assessed if algorithms trained only on a majority sub-sample (e.g., Non-Hispanic/Latino, male), could accurately predict opioid use outcomes for a minoritized sub-sample (e.g., Latino, female).","Results indicated that models trained on a random sample of our data could predict a range of opioid use outcomes with high precision.","However, we noted a decrease in precision when we trained our models on data from a majority sub-sample, and tested these models on a minoritized sub-sample.","We posit that a range of cultural factors and systemic forms of discrimination are not captured by data from majority sub-samples.","Broadly, for predictions to be valid, models should be trained on data that includes adequate representation of the groups of people about whom predictions will be made.","Stakeholders may utilize our findings to mitigate biases in models for predicting opioid use outcomes within minoritized communities."],"url":"http://arxiv.org/abs/2307.03083v1"}
{"created":"2023-07-06 15:48:29","title":"A Map-Free LiDAR-Based System for Autonomous Navigation in Vineyards","abstract":"Agricultural robots have the potential to increase production yields and reduce costs by performing repetitive and time-consuming tasks. However, for robots to be effective, they must be able to navigate autonomously in fields or orchards without human intervention. In this paper, we introduce a navigation system that utilizes LiDAR and wheel encoder sensors for in-row, turn, and end-row navigation in row structured agricultural environments, such as vineyards. Our approach exploits the simple and precise geometrical structure of plants organized in parallel rows. We tested our system in both simulated and real environments, and the results demonstrate the effectiveness of our approach in achieving accurate and robust navigation. Our navigation system achieves mean displacement errors from the center line of 0.049 m and 0.372 m for in-row navigation in the simulated and real environments, respectively. In addition, we developed an end-row points detection that allows end-row navigation in vineyards, a task often ignored by most works.","sentences":["Agricultural robots have the potential to increase production yields and reduce costs by performing repetitive and time-consuming tasks.","However, for robots to be effective, they must be able to navigate autonomously in fields or orchards without human intervention.","In this paper, we introduce a navigation system that utilizes LiDAR and wheel encoder sensors for in-row, turn, and end-row navigation in row structured agricultural environments, such as vineyards.","Our approach exploits the simple and precise geometrical structure of plants organized in parallel rows.","We tested our system in both simulated and real environments, and the results demonstrate the effectiveness of our approach in achieving accurate and robust navigation.","Our navigation system achieves mean displacement errors from the center line of 0.049 m and 0.372 m for in-row navigation in the simulated and real environments, respectively.","In addition, we developed an end-row points detection that allows end-row navigation in vineyards, a task often ignored by most works."],"url":"http://arxiv.org/abs/2307.03080v1"}
{"created":"2023-07-06 15:45:35","title":"Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions","abstract":"Signed graphs are complex systems that represent trust relationships or preferences in various domains. Learning node representations in such graphs is crucial for many mining tasks. Although real-world signed relationships can be influenced by multiple latent factors, most existing methods often oversimplify the modeling of signed relationships by relying on social theories and treating them as simplistic factors. This limits their expressiveness and their ability to capture the diverse factors that shape these relationships. In this paper, we propose DINES, a novel method for learning disentangled node representations in signed directed graphs without social assumptions. We adopt a disentangled framework that separates each embedding into distinct factors, allowing for capturing multiple latent factors. We also explore lightweight graph convolutions that focus solely on sign and direction, without depending on social theories. Additionally, we propose a decoder that effectively classifies an edge's sign by considering correlations between the factors. To further enhance disentanglement, we jointly train a self-supervised factor discriminator with our encoder and decoder. Throughout extensive experiments on real-world signed directed graphs, we show that DINES effectively learns disentangled node representations, and significantly outperforms its competitors in the sign prediction task.","sentences":["Signed graphs are complex systems that represent trust relationships or preferences in various domains.","Learning node representations in such graphs is crucial for many mining tasks.","Although real-world signed relationships can be influenced by multiple latent factors, most existing methods often oversimplify the modeling of signed relationships by relying on social theories and treating them as simplistic factors.","This limits their expressiveness and their ability to capture the diverse factors that shape these relationships.","In this paper, we propose DINES, a novel method for learning disentangled node representations in signed directed graphs without social assumptions.","We adopt a disentangled framework that separates each embedding into distinct factors, allowing for capturing multiple latent factors.","We also explore lightweight graph convolutions that focus solely on sign and direction, without depending on social theories.","Additionally, we propose a decoder that effectively classifies an edge's sign by considering correlations between the factors.","To further enhance disentanglement, we jointly train a self-supervised factor discriminator with our encoder and decoder.","Throughout extensive experiments on real-world signed directed graphs, we show that DINES effectively learns disentangled node representations, and significantly outperforms its competitors in the sign prediction task."],"url":"http://arxiv.org/abs/2307.03077v1"}
{"created":"2023-07-06 15:41:53","title":"Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning","abstract":"We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP. Motivated by the unimodal prototypical networks for few-shot learning, we introduce PROTO-CLIP that utilizes image prototypes and text prototypes for few-shot learning. Specifically, PROTO-CLIP adapts the image encoder and text encoder in CLIP in a joint fashion using few-shot examples. The two encoders are used to compute prototypes of image classes for classification. During adaptation, we propose aligning the image and text prototypes of corresponding classes. Such a proposed alignment is beneficial for few-shot classification due to the contributions from both types of prototypes. We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning as well as in the real world for robot perception.","sentences":["We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP.","Motivated by the unimodal prototypical networks for few-shot learning, we introduce PROTO-CLIP that utilizes image prototypes and text prototypes for few-shot learning.","Specifically, PROTO-CLIP adapts the image encoder and text encoder in CLIP in a joint fashion using few-shot examples.","The two encoders are used to compute prototypes of image classes for classification.","During adaptation, we propose aligning the image and text prototypes of corresponding classes.","Such a proposed alignment is beneficial for few-shot classification due to the contributions from both types of prototypes.","We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning as well as in the real world for robot perception."],"url":"http://arxiv.org/abs/2307.03073v1"}
{"created":"2023-07-06 15:36:55","title":"Querying Data Exchange Settings Beyond Positive Queries","abstract":"Data exchange, the problem of transferring data from a source schema to a target schema, has been studied for several years.   The semantics of answering positive queries over the target schema has been defined in early work, but little attention has been paid to more general queries. A few proposals of semantics for more general queries exist but they either do not properly extend the standard semantics under positive queries, giving rise to counterintuitive answers, or they make query answering undecidable even for the most important data exchange settings, e.g., with weakly-acyclic dependencies.   The goal of this paper is to provide a new semantics for data exchange that is able to deal with general queries. At the same time, we want our semantics to coincide with the classical one when focusing on positive queries, and to not trade-off too much in terms of complexity of query answering. We show that query answering is undecidable in general under the new semantics, but it is $\\co\\NP\\complete$ when the dependencies are weakly-acyclic.   Moreover, in the latter case, we show that exact answers under our semantics can be computed by means of logic programs with choice, thus exploiting existing efficient systems. For more efficient computations, we also show that our semantics allows for the construction of a representative target instance, similar in spirit to a universal solution, that can be exploited for computing approximate answers in polynomial time. Under consideration in Theory and Practice of Logic Programming (TPLP).","sentences":["Data exchange, the problem of transferring data from a source schema to a target schema, has been studied for several years.   ","The semantics of answering positive queries over the target schema has been defined in early work, but little attention has been paid to more general queries.","A few proposals of semantics for more general queries exist but they either do not properly extend the standard semantics under positive queries, giving rise to counterintuitive answers, or they make query answering undecidable even for the most important data exchange settings, e.g., with weakly-acyclic dependencies.   ","The goal of this paper is to provide a new semantics for data exchange that is able to deal with general queries.","At the same time, we want our semantics to coincide with the classical one when focusing on positive queries, and to not trade-off too much in terms of complexity of query answering.","We show that query answering is undecidable in general under the new semantics, but it is $\\co\\NP\\complete$ when the dependencies are weakly-acyclic.   ","Moreover, in the latter case, we show that exact answers under our semantics can be computed by means of logic programs with choice, thus exploiting existing efficient systems.","For more efficient computations, we also show that our semantics allows for the construction of a representative target instance, similar in spirit to a universal solution, that can be exploited for computing approximate answers in polynomial time.","Under consideration in Theory and Practice of Logic Programming (TPLP)."],"url":"http://arxiv.org/abs/2307.03071v1"}
{"created":"2023-07-06 15:35:14","title":"A Hybrid End-to-End Spatio-Temporal Attention Neural Network with Graph-Smooth Signals for EEG Emotion Recognition","abstract":"Recently, physiological data such as electroencephalography (EEG) signals have attracted significant attention in affective computing. In this context, the main goal is to design an automated model that can assess emotional states. Lately, deep neural networks have shown promising performance in emotion recognition tasks. However, designing a deep architecture that can extract practical information from raw data is still a challenge. Here, we introduce a deep neural network that acquires interpretable physiological representations by a hybrid structure of spatio-temporal encoding and recurrent attention network blocks. Furthermore, a preprocessing step is applied to the raw data using graph signal processing tools to perform graph smoothing in the spatial domain. We demonstrate that our proposed architecture exceeds state-of-the-art results for emotion classification on the publicly available DEAP dataset. To explore the generality of the learned model, we also evaluate the performance of our architecture towards transfer learning (TL) by transferring the model parameters from a specific source to other target domains. Using DEAP as the source dataset, we demonstrate the effectiveness of our model in performing cross-modality TL and improving emotion classification accuracy on DREAMER and the Emotional English Word (EEWD) datasets, which involve EEG-based emotion classification tasks with different stimuli.","sentences":["Recently, physiological data such as electroencephalography (EEG) signals have attracted significant attention in affective computing.","In this context, the main goal is to design an automated model that can assess emotional states.","Lately, deep neural networks have shown promising performance in emotion recognition tasks.","However, designing a deep architecture that can extract practical information from raw data is still a challenge.","Here, we introduce a deep neural network that acquires interpretable physiological representations by a hybrid structure of spatio-temporal encoding and recurrent attention network blocks.","Furthermore, a preprocessing step is applied to the raw data using graph signal processing tools to perform graph smoothing in the spatial domain.","We demonstrate that our proposed architecture exceeds state-of-the-art results for emotion classification on the publicly available DEAP dataset.","To explore the generality of the learned model, we also evaluate the performance of our architecture towards transfer learning (TL) by transferring the model parameters from a specific source to other target domains.","Using DEAP as the source dataset, we demonstrate the effectiveness of our model in performing cross-modality TL and improving emotion classification accuracy on DREAMER and the Emotional English Word (EEWD) datasets, which involve EEG-based emotion classification tasks with different stimuli."],"url":"http://arxiv.org/abs/2307.03068v1"}
{"created":"2023-07-06 15:35:02","title":"DeepOnto: A Python Package for Ontology Engineering with Deep Learning","abstract":"Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more \"Pythonic\" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs. In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI).","sentences":["Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention.","However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based.","To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering.","The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more \"Pythonic\" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more.","Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs.","In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI)."],"url":"http://arxiv.org/abs/2307.03067v1"}
{"created":"2023-07-06 15:24:40","title":"Explorations in Subexponential non-associative non-commutative Linear Logic","abstract":"In a previous work we introduced a non-associative non-commutative logic extended by multimodalities, called subexponentials, licensing local application of structural rules. Here, we further explore this system, considering a classical one-sided multi-succedent classical version of the system, following the exponential-free calculi of Buszkowski's and de Groote and Lamarche's works, where the intuitionistic calculus is shown to embed faithfully into the classical fragment.","sentences":["In a previous work we introduced a non-associative non-commutative logic extended by multimodalities, called subexponentials, licensing local application of structural rules.","Here, we further explore this system, considering a classical one-sided multi-succedent classical version of the system, following the exponential-free calculi of Buszkowski's and de Groote and Lamarche's works, where the intuitionistic calculus is shown to embed faithfully into the classical fragment."],"url":"http://arxiv.org/abs/2307.03059v1"}
{"created":"2023-07-06 15:19:53","title":"Generalizing Backpropagation for Gradient-Based Interpretability","abstract":"Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs. While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important.","sentences":["Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs.","While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself.","In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings.","This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy.","We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA).","With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important."],"url":"http://arxiv.org/abs/2307.03056v1"}
{"created":"2023-07-06 15:18:11","title":"Multi-source imagery fusion using deep learning in a cloud computing platform","abstract":"Given the high availability of data collected by different remote sensing instruments, the data fusion of multi-spectral and hyperspectral images (HSI) is an important topic in remote sensing. In particular, super-resolution as a data fusion application using spatial and spectral domains is highly investigated because its fused images is used to improve the classification and tracking objects accuracy. On the other hand, the huge amount of data obtained by remote sensing instruments represent a key concern in terms of data storage, management and pre-processing. This paper proposes a Big Data Cloud platform using Hadoop and Spark to store, manages, and process remote sensing data. Also, a study over the parameter \\textit{chunk size} is presented to suggest the appropriate value for this parameter to download imagery data from Hadoop into a Spark application, based on the format of our data. We also developed an alternative approach based on Long Short Term Memory trained with different patch sizes for super-resolution image. This approach fuse hyperspectral and multispectral images. As a result, we obtain images with high-spatial and high-spectral resolution. The experimental results show that for a chunk size of 64k, an average of 3.5s was required to download data from Hadoop into a Spark application. The proposed model for super-resolution provides a structural similarity index of 0.98 and 0.907 for the used dataset.","sentences":["Given the high availability of data collected by different remote sensing instruments, the data fusion of multi-spectral and hyperspectral images (HSI) is an important topic in remote sensing.","In particular, super-resolution as a data fusion application using spatial and spectral domains is highly investigated because its fused images is used to improve the classification and tracking objects accuracy.","On the other hand, the huge amount of data obtained by remote sensing instruments represent a key concern in terms of data storage, management and pre-processing.","This paper proposes a Big Data Cloud platform using Hadoop and Spark to store, manages, and process remote sensing data.","Also, a study over the parameter \\textit{chunk size} is presented to suggest the appropriate value for this parameter to download imagery data from Hadoop into a Spark application, based on the format of our data.","We also developed an alternative approach based on Long Short Term Memory trained with different patch sizes for super-resolution image.","This approach fuse hyperspectral and multispectral images.","As a result, we obtain images with high-spatial and high-spectral resolution.","The experimental results show that for a chunk size of 64k, an average of 3.5s was required to download data from Hadoop into a Spark application.","The proposed model for super-resolution provides a structural similarity index of 0.98 and 0.907 for the used dataset."],"url":"http://arxiv.org/abs/2307.03054v1"}
{"created":"2023-07-06 15:14:23","title":"Origin-Destination Travel Time Oracle for Map-based Services","abstract":"Given an origin (O), a destination (D), and a departure time (T), an Origin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate of the time it takes to travel from O to D when departing at T. ODT-Oracles serve important purposes in map-based services. To enable the construction of such oracles, we provide a travel-time estimation (TTE) solution that leverages historical trajectories to estimate time-varying travel times for OD pairs.   The problem is complicated by the fact that multiple historical trajectories with different travel times may connect an OD pair, while trajectories may vary from one another. To solve the problem, it is crucial to remove outlier trajectories when doing travel time estimation for future queries.   We propose a novel, two-stage framework called Diffusion-based Origin-destination Travel Time Estimation (DOT), that solves the problem. First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser that enables building a diffusion-based PiT inference process by learning correlations between OD pairs and historical trajectories. Specifically, given an OD pair and a departure time, we aim to infer a PiT. Next, DOT encompasses a Masked Vision Transformer~(MViT) that effectively and efficiently estimates a travel time based on the inferred PiT. We report on extensive experiments on two real-world datasets that offer evidence that DOT is capable of outperforming baseline methods in terms of accuracy, scalability, and explainability.","sentences":["Given an origin (O), a destination (D), and a departure time (T), an Origin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate of the time it takes to travel from O to D when departing at T. ODT-Oracles serve important purposes in map-based services.","To enable the construction of such oracles, we provide a travel-time estimation (TTE) solution that leverages historical trajectories to estimate time-varying travel times for OD pairs.   ","The problem is complicated by the fact that multiple historical trajectories with different travel times may connect an OD pair, while trajectories may vary from one another.","To solve the problem, it is crucial to remove outlier trajectories when doing travel time estimation for future queries.   ","We propose a novel, two-stage framework called Diffusion-based Origin-destination Travel Time Estimation (DOT), that solves the problem.","First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser that enables building a diffusion-based PiT inference process by learning correlations between OD pairs and historical trajectories.","Specifically, given an OD pair and a departure time, we aim to infer a PiT.","Next, DOT encompasses a Masked Vision Transformer~(MViT) that effectively and efficiently estimates a travel time based on the inferred PiT.","We report on extensive experiments on two real-world datasets that offer evidence that DOT is capable of outperforming baseline methods in terms of accuracy, scalability, and explainability."],"url":"http://arxiv.org/abs/2307.03048v1"}
{"created":"2023-07-06 15:10:29","title":"Track Mix Generation on Music Streaming Services using Transformers","abstract":"This paper introduces Track Mix, a personalized playlist generation system released in 2022 on the music streaming service Deezer. Track Mix automatically generates \"mix\" playlists inspired by initial music tracks, allowing users to discover music similar to their favorite content. To generate these mixes, we consider a Transformer model trained on millions of track sequences from user playlists. In light of the growing popularity of Transformers in recent years, we analyze the advantages, drawbacks, and technical challenges of using such a model for mix generation on the service, compared to a more traditional collaborative filtering approach. Since its release, Track Mix has been generating playlists for millions of users daily, enhancing their music discovery experience on Deezer.","sentences":["This paper introduces Track Mix, a personalized playlist generation system released in 2022 on the music streaming service Deezer.","Track Mix automatically generates \"mix\" playlists inspired by initial music tracks, allowing users to discover music similar to their favorite content.","To generate these mixes, we consider a Transformer model trained on millions of track sequences from user playlists.","In light of the growing popularity of Transformers in recent years, we analyze the advantages, drawbacks, and technical challenges of using such a model for mix generation on the service, compared to a more traditional collaborative filtering approach.","Since its release, Track Mix has been generating playlists for millions of users daily, enhancing their music discovery experience on Deezer."],"url":"http://arxiv.org/abs/2307.03045v1"}
{"created":"2023-07-06 15:07:48","title":"A Near-Linear Time Algorithm for the Chamfer Distance","abstract":"For any two point sets $A,B \\subset \\mathbb{R}^d$ of size up to $n$, the Chamfer distance from $A$ to $B$ is defined as $\\text{CH}(A,B)=\\sum_{a \\in A} \\min_{b \\in B} d_X(a,b)$, where $d_X$ is the underlying distance measure (e.g., the Euclidean or Manhattan distance). The Chamfer distance is a popular measure of dissimilarity between point clouds, used in many machine learning, computer vision, and graphics applications, and admits a straightforward $O(d n^2)$-time brute force algorithm. Further, the Chamfer distance is often used as a proxy for the more computationally demanding Earth-Mover (Optimal Transport) Distance. However, the \\emph{quadratic} dependence on $n$ in the running time makes the naive approach intractable for large datasets.   We overcome this bottleneck and present the first $(1+\\epsilon)$-approximate algorithm for estimating the Chamfer distance with a near-linear running time. Specifically, our algorithm runs in time $O(nd \\log (n)/\\varepsilon^2)$ and is implementable. Our experiments demonstrate that it is both accurate and fast on large high-dimensional datasets. We believe that our algorithm will open new avenues for analyzing large high-dimensional point clouds. We also give evidence that if the goal is to \\emph{report} a $(1+\\varepsilon)$-approximate mapping from $A$ to $B$ (as opposed to just its value), then any sub-quadratic time algorithm is unlikely to exist.","sentences":["For any two point sets $A,B \\subset \\mathbb{R}^d$ of size up to $n$, the Chamfer distance from $A$ to $B$ is defined as $\\text{CH}(A,B)=\\sum_{a \\in A} \\min_{b \\in B} d_X(a,b)$, where $d_X$ is the underlying distance measure (e.g., the Euclidean or Manhattan distance).","The Chamfer distance is a popular measure of dissimilarity between point clouds, used in many machine learning, computer vision, and graphics applications, and admits a straightforward $O(d n^2)$-time brute force algorithm.","Further, the Chamfer distance is often used as a proxy for the more computationally demanding Earth-Mover (Optimal Transport) Distance.","However, the \\emph{quadratic} dependence on $n$ in the running time makes the naive approach intractable for large datasets.   ","We overcome this bottleneck and present the first $(1+\\epsilon)$-approximate algorithm for estimating the Chamfer distance with a near-linear running time.","Specifically, our algorithm runs in time $O(nd \\log (n)/\\varepsilon^2)$ and is implementable.","Our experiments demonstrate that it is both accurate and fast on large high-dimensional datasets.","We believe that our algorithm will open new avenues for analyzing large high-dimensional point clouds.","We also give evidence that if the goal is to \\emph{report} a $(1+\\varepsilon)$-approximate mapping from $A$ to $B$ (as opposed to just its value), then any sub-quadratic time algorithm is unlikely to exist."],"url":"http://arxiv.org/abs/2307.03043v1"}
{"created":"2023-07-06 15:06:41","title":"Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain","abstract":"Adapting pretrained language models to novel domains, such as clinical applications, traditionally involves retraining their entire set of parameters. However, this approach is increasingly proven to be impractical owing to the substantial computational requirements associated with training such large language models. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) techniques offer a viable solution by selectively fine-tuning a small subset of additional parameters, significantly reducing the computational requirements for domain adaptation. In this study, we propose Clinical LLaMA-LoRA, a PEFT adapter layer built upon the open-sourced LLaMA model. Clinical LLaMA-LoRA is trained using clinical notes obtained from the MIMIC-IV database, thereby creating a specialised adapter designed for the clinical domain. Additionally, we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA with Downstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks. We evaluate this framework on multiple clinical outcome prediction datasets, comparing it to clinically trained language models. Our proposed framework achieves a state-of-the-art AUROC score averaged across all clinical downstream tasks. We observe substantial improvements of 6-9% AUROC score in the large-scale multilabel classification tasks, such as diagnoses and procedures classification.","sentences":["Adapting pretrained language models to novel domains, such as clinical applications, traditionally involves retraining their entire set of parameters.","However, this approach is increasingly proven to be impractical owing to the substantial computational requirements associated with training such large language models.","To address this issue, Parameter-Efficient Fine-Tuning (PEFT) techniques offer a viable solution by selectively fine-tuning a small subset of additional parameters, significantly reducing the computational requirements for domain adaptation.","In this study, we propose Clinical LLaMA-LoRA, a PEFT adapter layer built upon the open-sourced LLaMA model.","Clinical LLaMA-LoRA is trained using clinical notes obtained from the MIMIC-IV database, thereby creating a specialised adapter designed for the clinical domain.","Additionally, we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA with Downstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks.","We evaluate this framework on multiple clinical outcome prediction datasets, comparing it to clinically trained language models.","Our proposed framework achieves a state-of-the-art AUROC score averaged across all clinical downstream tasks.","We observe substantial improvements of 6-9% AUROC score in the large-scale multilabel classification tasks, such as diagnoses and procedures classification."],"url":"http://arxiv.org/abs/2307.03042v1"}
{"created":"2023-07-06 15:04:18","title":"Art Authentication with Vision Transformers","abstract":"In recent years, Transformers, initially developed for language, have been successfully applied to visual tasks. Vision Transformers have been shown to push the state-of-the-art in a wide range of tasks, including image classification, object detection, and semantic segmentation. While ample research has shown promising results in art attribution and art authentication tasks using Convolutional Neural Networks, this paper examines if the superiority of Vision Transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks. Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin Transformers with those of EfficientNet. Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall. With a contrast set that only consists of imitations, we find the Swin Transformer to be superior to EfficientNet by achieving an authentication accuracy of over 85%. These results lead us to conclude that Vision Transformers represent a strong and promising contender in art authentication, particularly in enhancing the computer-based ability to detect artistic imitations.","sentences":["In recent years, Transformers, initially developed for language, have been successfully applied to visual tasks.","Vision Transformers have been shown to push the state-of-the-art in a wide range of tasks, including image classification, object detection, and semantic segmentation.","While ample research has shown promising results in art attribution and art authentication tasks using Convolutional Neural Networks, this paper examines if the superiority of Vision Transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks.","Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin Transformers with those of EfficientNet.","Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall.","With a contrast set that only consists of imitations, we find the Swin Transformer to be superior to EfficientNet by achieving an authentication accuracy of over 85%.","These results lead us to conclude that Vision Transformers represent a strong and promising contender in art authentication, particularly in enhancing the computer-based ability to detect artistic imitations."],"url":"http://arxiv.org/abs/2307.03039v1"}
{"created":"2023-07-06 14:45:41","title":"Performance Analysis and Approximate Message Passing Detection of Orthogonal Time Sequency Multiplexing Modulation","abstract":"In orthogonal time sequency multiplexing (OTSM) modulation, the information symbols are conveyed in the delay-sequency domain upon exploiting the inverse Walsh Hadamard transform (IWHT). It has been shown that OTSM is capable of attaining a bit error ratio (BER) similar to that of orthogonal time-frequency space (OTFS) modulation at a lower complexity, since the saving of multiplication operations in the IWHT. Hence we provide its BER performance analysis and characterize its detection complexity. We commence by deriving its generalized input-output relationship and its unconditional pairwise error probability (UPEP). Then, its BER upper bound is derived in closed form under both ideal and imperfect channel estimation conditions, which is shown to be tight at moderate to high signal-to-noise ratios (SNRs). Moreover, a novel approximate message passing (AMP) aided OTSM detection framework is proposed. Specifically, to circumvent the high residual BER of the conventional AMP detector, we proposed a vector AMP-based expectation-maximization (VAMP-EM) detector for performing joint data detection and noise variance estimation. The variance auto-tuning algorithm based on the EM algorithm is designed for the VAMP-EM detector to further improve the convergence performance. The simulation results illustrate that the VAMP-EM detector is capable of striking an attractive BER vs. complexity trade-off than the state-of-the-art schemes as well as providing a better convergence. Finally, we propose AMP and VAMP-EM turbo receivers for low-density parity-check (LDPC)-coded OTSM systems. It is demonstrated that our proposed VAMP-EM turbo receiver is capable of providing both BER and convergence performance improvements over the conventional AMP solution.","sentences":["In orthogonal time sequency multiplexing (OTSM) modulation, the information symbols are conveyed in the delay-sequency domain upon exploiting the inverse Walsh Hadamard transform (IWHT).","It has been shown that OTSM is capable of attaining a bit error ratio (BER) similar to that of orthogonal time-frequency space (OTFS) modulation at a lower complexity, since the saving of multiplication operations in the IWHT.","Hence we provide its BER performance analysis and characterize its detection complexity.","We commence by deriving its generalized input-output relationship and its unconditional pairwise error probability (UPEP).","Then, its BER upper bound is derived in closed form under both ideal and imperfect channel estimation conditions, which is shown to be tight at moderate to high signal-to-noise ratios (SNRs).","Moreover, a novel approximate message passing (AMP) aided OTSM detection framework is proposed.","Specifically, to circumvent the high residual BER of the conventional AMP detector, we proposed a vector AMP-based expectation-maximization (VAMP-EM) detector for performing joint data detection and noise variance estimation.","The variance auto-tuning algorithm based on the EM algorithm is designed for the VAMP-EM detector to further improve the convergence performance.","The simulation results illustrate that the VAMP-EM detector is capable of striking an attractive BER vs. complexity trade-off than the state-of-the-art schemes as well as providing a better convergence.","Finally, we propose AMP and VAMP-EM turbo receivers for low-density parity-check (LDPC)-coded OTSM systems.","It is demonstrated that our proposed VAMP-EM turbo receiver is capable of providing both BER and convergence performance improvements over the conventional AMP solution."],"url":"http://arxiv.org/abs/2307.03028v1"}
{"created":"2023-07-06 14:44:07","title":"Improving Retrieval-Augmented Large Language Models via Data Importance Learning","abstract":"Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements).","sentences":["Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation.","However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus.","In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points.","There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function.","We further proposed an even more efficient ({\\epsilon}, {\\delta})-approximation algorithm.","Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training.","For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation).","Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements)."],"url":"http://arxiv.org/abs/2307.03027v1"}
{"created":"2023-07-06 14:42:01","title":"Style Over Substance: Evaluation Biases for Large Language Models","abstract":"As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging. Conventionally, human evaluations are considered the gold standard in natural language generation. Recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes. Nonetheless, the extent to which humans and LLMs are capable evaluators remains uncertain. This study aims to investigate the behavior of both crowd-sourced human and LLM-based judges when comparing outputs from different models. To accomplish this, we curate a dataset comprising intentionally flawed machine-generated answers. Our findings indicate that despite the potentially greater danger posed by factual errors, answers with factual errors were still rated more favorably compared to answers that were too short or contained grammatical errors. This highlights a concerning bias in the evaluation process. To address this issue, we propose to independently evaluate machine-generated text across multiple dimensions, rather than merging all the evaluation aspects into a single score. We instantiate this idea with the Elo rating system, resulting in the Multi-Elo Rating System. Empirical results from our study reveal that this proposed approach significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy. However, notable improvement is not observed in crowd-sourced-based evaluations, suggesting the need for further investigation and refinement.","sentences":["As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging.","Conventionally, human evaluations are considered the gold standard in natural language generation.","Recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes.","Nonetheless, the extent to which humans and LLMs are capable evaluators remains uncertain.","This study aims to investigate the behavior of both crowd-sourced human and LLM-based judges when comparing outputs from different models.","To accomplish this, we curate a dataset comprising intentionally flawed machine-generated answers.","Our findings indicate that despite the potentially greater danger posed by factual errors, answers with factual errors were still rated more favorably compared to answers that were too short or contained grammatical errors.","This highlights a concerning bias in the evaluation process.","To address this issue, we propose to independently evaluate machine-generated text across multiple dimensions, rather than merging all the evaluation aspects into a single score.","We instantiate this idea with the Elo rating system, resulting in the Multi-Elo Rating System.","Empirical results from our study reveal that this proposed approach significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy.","However, notable improvement is not observed in crowd-sourced-based evaluations, suggesting the need for further investigation and refinement."],"url":"http://arxiv.org/abs/2307.03025v1"}
{"created":"2023-07-06 14:31:01","title":"EffLiFe: Efficient Light Field Generation via Hierarchical Sparse Gradient Descent","abstract":"With the rise of Extended Reality (XR) technology, there is a growing need for real-time light field generation from sparse view inputs. Existing methods can be classified into offline techniques, which can generate high-quality novel views but at the cost of long inference/training time, and online methods, which either lack generalizability or produce unsatisfactory results. However, we have observed that the intrinsic sparse manifold of Multi-plane Images (MPI) enables a significant acceleration of light field generation while maintaining rendering quality. Based on this insight, we introduce EffLiFe, a novel light field optimization method, which leverages the proposed Hierarchical Sparse Gradient Descent (HSGD) to produce high-quality light fields from sparse view images in real time. Technically, the coarse MPI of a scene is first generated using a 3D CNN, and it is further sparsely optimized by focusing only on important MPI gradients in a few iterations. Nevertheless, relying solely on optimization can lead to artifacts at occlusion boundaries. Therefore, we propose an occlusion-aware iterative refinement module that removes visual artifacts in occluded regions by iteratively filtering the input. Extensive experiments demonstrate that our method achieves comparable visual quality while being 100x faster on average than state-of-the-art offline methods and delivering better performance (about 2 dB higher in PSNR) compared to other online approaches.","sentences":["With the rise of Extended Reality (XR) technology, there is a growing need for real-time light field generation from sparse view inputs.","Existing methods can be classified into offline techniques, which can generate high-quality novel views but at the cost of long inference/training time, and online methods, which either lack generalizability or produce unsatisfactory results.","However, we have observed that the intrinsic sparse manifold of Multi-plane Images (MPI) enables a significant acceleration of light field generation while maintaining rendering quality.","Based on this insight, we introduce EffLiFe, a novel light field optimization method, which leverages the proposed Hierarchical Sparse Gradient Descent (HSGD) to produce high-quality light fields from sparse view images in real time.","Technically, the coarse MPI of a scene is first generated using a 3D CNN, and it is further sparsely optimized by focusing only on important MPI gradients in a few iterations.","Nevertheless, relying solely on optimization can lead to artifacts at occlusion boundaries.","Therefore, we propose an occlusion-aware iterative refinement module that removes visual artifacts in occluded regions by iteratively filtering the input.","Extensive experiments demonstrate that our method achieves comparable visual quality while being 100x faster on average than state-of-the-art offline methods and delivering better performance (about 2 dB higher in PSNR) compared to other online approaches."],"url":"http://arxiv.org/abs/2307.03017v1"}
{"created":"2023-07-06 14:24:17","title":"Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance","abstract":"There are two major challenges for scaling up robot navigation around dynamic obstacles: the complex interaction dynamics of the obstacles can be hard to model analytically, and the complexity of planning and control grows exponentially in the number of obstacles. Data-driven and learning-based methods are thus particularly valuable in this context. However, data-driven methods are sensitive to distribution drift, making it hard to train and generalize learned models across different obstacle densities. We propose a novel method for compositional learning of Sequential Neural Control Barrier models (SNCBFs) to achieve scalability. Our approach exploits an important observation: the spatial interaction patterns of multiple dynamic obstacles can be decomposed and predicted through temporal sequences of states for each obstacle. Through decomposition, we can generalize control policies trained only with a small number of obstacles, to environments where the obstacle density can be 100x higher. We demonstrate the benefits of the proposed methods in improving dynamic collision avoidance in comparison with existing methods including potential fields, end-to-end reinforcement learning, and model-predictive control. We also perform hardware experiments and show the practical effectiveness of the approach in the supplementary video.","sentences":["There are two major challenges for scaling up robot navigation around dynamic obstacles: the complex interaction dynamics of the obstacles can be hard to model analytically, and the complexity of planning and control grows exponentially in the number of obstacles.","Data-driven and learning-based methods are thus particularly valuable in this context.","However, data-driven methods are sensitive to distribution drift, making it hard to train and generalize learned models across different obstacle densities.","We propose a novel method for compositional learning of Sequential Neural Control Barrier models (SNCBFs) to achieve scalability.","Our approach exploits an important observation: the spatial interaction patterns of multiple dynamic obstacles can be decomposed and predicted through temporal sequences of states for each obstacle.","Through decomposition, we can generalize control policies trained only with a small number of obstacles, to environments where the obstacle density can be 100x higher.","We demonstrate the benefits of the proposed methods in improving dynamic collision avoidance in comparison with existing methods including potential fields, end-to-end reinforcement learning, and model-predictive control.","We also perform hardware experiments and show the practical effectiveness of the approach in the supplementary video."],"url":"http://arxiv.org/abs/2307.03015v1"}
{"created":"2023-07-06 14:13:11","title":"Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning","abstract":"Manual assembly workers face increasing complexity in their work. Human-centered assistance systems could help, but object recognition as an enabling technology hinders sophisticated human-centered design of these systems. At the same time, activity recognition based on hand poses suffers from poor pose estimation in complex usage scenarios, such as wearing gloves. This paper presents a self-supervised pipeline for adapting hand pose estimation to specific use cases with minimal human interaction. This enables cheap and robust hand posebased activity recognition. The pipeline consists of a general machine learning model for hand pose estimation trained on a generalized dataset, spatial and temporal filtering to account for anatomical constraints of the hand, and a retraining step to improve the model. Different parameter combinations are evaluated on a publicly available and annotated dataset. The best parameter and model combination is then applied to unlabelled videos from a manual assembly scenario. The effectiveness of the pipeline is demonstrated by training an activity recognition as a downstream task in the manual assembly scenario.","sentences":["Manual assembly workers face increasing complexity in their work.","Human-centered assistance systems could help, but object recognition as an enabling technology hinders sophisticated human-centered design of these systems.","At the same time, activity recognition based on hand poses suffers from poor pose estimation in complex usage scenarios, such as wearing gloves.","This paper presents a self-supervised pipeline for adapting hand pose estimation to specific use cases with minimal human interaction.","This enables cheap and robust hand posebased activity recognition.","The pipeline consists of a general machine learning model for hand pose estimation trained on a generalized dataset, spatial and temporal filtering to account for anatomical constraints of the hand, and a retraining step to improve the model.","Different parameter combinations are evaluated on a publicly available and annotated dataset.","The best parameter and model combination is then applied to unlabelled videos from a manual assembly scenario.","The effectiveness of the pipeline is demonstrated by training an activity recognition as a downstream task in the manual assembly scenario."],"url":"http://arxiv.org/abs/2307.03007v1"}
{"created":"2023-07-06 14:06:23","title":"Improving the Efficiency of Human-in-the-Loop Systems: Adding Artificial to Human Experts","abstract":"Information systems increasingly leverage artificial intelligence (AI) and machine learning (ML) to generate value from vast amounts of data. However, ML models are imperfect and can generate incorrect classifications. Hence, human-in-the-loop (HITL) extensions to ML models add a human review for instances that are difficult to classify. This study argues that continuously relying on human experts to handle difficult model classifications leads to a strong increase in human effort, which strains limited resources. To address this issue, we propose a hybrid system that creates artificial experts that learn to classify data instances from unknown classes previously reviewed by human experts. Our hybrid system assesses which artificial expert is suitable for classifying an instance from an unknown class and automatically assigns it. Over time, this reduces human effort and increases the efficiency of the system. Our experiments demonstrate that our approach outperforms traditional HITL systems for several benchmarks on image classification.","sentences":["Information systems increasingly leverage artificial intelligence (AI) and machine learning (ML) to generate value from vast amounts of data.","However, ML models are imperfect and can generate incorrect classifications.","Hence, human-in-the-loop (HITL) extensions to ML models add a human review for instances that are difficult to classify.","This study argues that continuously relying on human experts to handle difficult model classifications leads to a strong increase in human effort, which strains limited resources.","To address this issue, we propose a hybrid system that creates artificial experts that learn to classify data instances from unknown classes previously reviewed by human experts.","Our hybrid system assesses which artificial expert is suitable for classifying an instance from an unknown class and automatically assigns it.","Over time, this reduces human effort and increases the efficiency of the system.","Our experiments demonstrate that our approach outperforms traditional HITL systems for several benchmarks on image classification."],"url":"http://arxiv.org/abs/2307.03003v1"}
{"created":"2023-07-06 13:44:29","title":"ContainerGym: A Real-World Reinforcement Learning Benchmark for Resource Allocation","abstract":"We present ContainerGym, a benchmark for reinforcement learning inspired by a real-world industrial resource allocation task. The proposed benchmark encodes a range of challenges commonly encountered in real-world sequential decision making problems, such as uncertainty. It can be configured to instantiate problems of varying degrees of difficulty, e.g., in terms of variable dimensionality. Our benchmark differs from other reinforcement learning benchmarks, including the ones aiming to encode real-world difficulties, in that it is directly derived from a real-world industrial problem, which underwent minimal simplification and streamlining. It is sufficiently versatile to evaluate reinforcement learning algorithms on any real-world problem that fits our resource allocation framework. We provide results of standard baseline methods. Going beyond the usual training reward curves, our results and the statistical tools used to interpret them allow to highlight interesting limitations of well-known deep reinforcement learning algorithms, namely PPO, TRPO and DQN.","sentences":["We present ContainerGym, a benchmark for reinforcement learning inspired by a real-world industrial resource allocation task.","The proposed benchmark encodes a range of challenges commonly encountered in real-world sequential decision making problems, such as uncertainty.","It can be configured to instantiate problems of varying degrees of difficulty, e.g., in terms of variable dimensionality.","Our benchmark differs from other reinforcement learning benchmarks, including the ones aiming to encode real-world difficulties, in that it is directly derived from a real-world industrial problem, which underwent minimal simplification and streamlining.","It is sufficiently versatile to evaluate reinforcement learning algorithms on any real-world problem that fits our resource allocation framework.","We provide results of standard baseline methods.","Going beyond the usual training reward curves, our results and the statistical tools used to interpret them allow to highlight interesting limitations of well-known deep reinforcement learning algorithms, namely PPO, TRPO and DQN."],"url":"http://arxiv.org/abs/2307.02991v1"}
{"created":"2023-07-06 13:42:21","title":"UAV Swarms for Joint Data Ferrying and Dynamic Cell Coverage via Optimal Transport Descent and Quadratic Assignment","abstract":"Both data ferrying with disruption-tolerant networking (DTN) and mobile cellular base stations constitute important techniques for UAV-aided communication in situations of crises where standard communication infrastructure is unavailable. For optimal use of a limited number of UAVs, we propose providing both DTN and a cellular base station on each UAV. Here, DTN is used for large amounts of low-priority data, while capacity-constrained cell coverage remains reserved for emergency calls or command and control. We optimize cell coverage via a novel optimal transport-based formulation using alternating minimization, while for data ferrying we periodically deliver data between dynamic clusters by solving quadratic assignment problems. In our evaluation, we consider different scenarios with varying mobility models and a wide range of flight patterns. Overall, we tractably achieve optimal cell coverage under quality-of-service costs with DTN-based data ferrying, enabling large-scale deployment of UAV swarms for crisis communication.","sentences":["Both data ferrying with disruption-tolerant networking (DTN) and mobile cellular base stations constitute important techniques for UAV-aided communication in situations of crises where standard communication infrastructure is unavailable.","For optimal use of a limited number of UAVs, we propose providing both DTN and a cellular base station on each UAV.","Here, DTN is used for large amounts of low-priority data, while capacity-constrained cell coverage remains reserved for emergency calls or command and control.","We optimize cell coverage via a novel optimal transport-based formulation using alternating minimization, while for data ferrying we periodically deliver data between dynamic clusters by solving quadratic assignment problems.","In our evaluation, we consider different scenarios with varying mobility models and a wide range of flight patterns.","Overall, we tractably achieve optimal cell coverage under quality-of-service costs with DTN-based data ferrying, enabling large-scale deployment of UAV swarms for crisis communication."],"url":"http://arxiv.org/abs/2307.02988v1"}
{"created":"2023-07-06 13:35:48","title":"A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications","abstract":"Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent space, our walking strategy is safer than linear interpolation. We then test our path-finding strategy combined to k-same methods and demonstrate, on two benchmarks for tuberculosis and diabetic retinopathy classification, that training a model using samples generated by our approach mitigate drops in performance, while keeping privacy preservation.","sentences":["Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution.","However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space.","Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way.","Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples.","We empirically demonstrate that, given any random pair of points in the latent space, our walking strategy is safer than linear interpolation.","We then test our path-finding strategy combined to k-same methods and demonstrate, on two benchmarks for tuberculosis and diabetic retinopathy classification, that training a model using samples generated by our approach mitigate drops in performance, while keeping privacy preservation."],"url":"http://arxiv.org/abs/2307.02984v1"}
{"created":"2023-07-06 13:33:59","title":"Efficient Semiring-Weighted Earley Parsing","abstract":"This paper provides a reference description, in the form of a deduction system, of Earley's (1970) context-free parsing algorithm with various speed-ups. Our presentation includes a known worst-case runtime improvement from Earley's $O (N^3|G||R|)$, which is unworkable for the large grammars that arise in natural language processing, to $O (N^3|G|)$, which matches the runtime of CKY on a binarized version of the grammar $G$. Here $N$ is the length of the sentence, $|R|$ is the number of productions in $G$, and $|G|$ is the total length of those productions. We also provide a version that achieves runtime of $O (N^3|M|)$ with $|M| \\leq |G|$ when the grammar is represented compactly as a single finite-state automaton $M$ (this is partly novel). We carefully treat the generalization to semiring-weighted deduction, preprocessing the grammar like Stolcke (1995) to eliminate deduction cycles, and further generalize Stolcke's method to compute the weights of sentence prefixes. We also provide implementation details for efficient execution, ensuring that on a preprocessed grammar, the semiring-weighted versions of our methods have the same asymptotic runtime and space requirements as the unweighted methods, including sub-cubic runtime on some grammars.","sentences":["This paper provides a reference description, in the form of a deduction system, of Earley's (1970) context-free parsing algorithm with various speed-ups.","Our presentation includes a known worst-case runtime improvement from Earley's $O (N^3|G||R|)$, which is unworkable for the large grammars that arise in natural language processing, to $O (N^3|G|)$, which matches the runtime of CKY on a binarized version of the grammar $G$. Here $N$ is the length of the sentence, $|R|$ is the number of productions in $G$, and $|G|$ is the total length of those productions.","We also provide a version that achieves runtime of $O (N^3|M|)$ with $|M| \\leq |G|$ when the grammar is represented compactly as a single finite-state automaton $M$ (this is partly novel).","We carefully treat the generalization to semiring-weighted deduction, preprocessing the grammar like Stolcke (1995) to eliminate deduction cycles, and further generalize Stolcke's method to compute the weights of sentence prefixes.","We also provide implementation details for efficient execution, ensuring that on a preprocessed grammar, the semiring-weighted versions of our methods have the same asymptotic runtime and space requirements as the unweighted methods, including sub-cubic runtime on some grammars."],"url":"http://arxiv.org/abs/2307.02982v1"}
{"created":"2023-07-06 13:25:31","title":"Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion","abstract":"Parkinson disease is the second most common neurodegenerative disorder, as reported by the World Health Organization. In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit and Healthy Control. We use white matter and gray matter from the MRI and fractional anisotropy and mean diffusivity from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53 percentage for the direct three class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.","sentences":["Parkinson disease is the second most common neurodegenerative disorder, as reported by the World Health Organization.","In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI.","The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit and Healthy Control.","We use white matter and gray matter from the MRI and fractional anisotropy and mean diffusivity from the DTI to achieve our goal.","We train four separate CNNs on the above four types of data.","At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique.","We achieve an accuracy of 95.53 percentage for the direct three class classification of PD, HC and SWEDD on the publicly available PPMI database.","Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution."],"url":"http://arxiv.org/abs/2307.02978v1"}
{"created":"2023-07-06 13:19:27","title":"Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data","abstract":"Disease detection from smartphone data represents an open research challenge in mobile health (m-health) systems. COVID-19 and its respiratory symptoms are an important case study in this area and their early detection is a potential real instrument to counteract the pandemic situation. The efficacy of this solution mainly depends on the performances of AI algorithms applied to the collected data and their possible implementation directly on the users' mobile devices. Considering these issues, and the limited amount of available data, in this paper we present the experimental evaluation of 3 different deep learning models, compared also with hand-crafted features, and of two main approaches of transfer learning in the considered scenario: both feature extraction and fine-tuning. Specifically, we considered VGGish, YAMNET, and L\\textsuperscript{3}-Net (including 12 different configurations) evaluated through user-independent experiments on 4 different datasets (13,447 samples in total). Results clearly show the advantages of L\\textsuperscript{3}-Net in all the experimental settings as it overcomes the other solutions by 12.3\\% in terms of Precision-Recall AUC as features extractor, and by 10\\% when the model is fine-tuned. Moreover, we note that to fine-tune only the fully-connected layers of the pre-trained models generally leads to worse performances, with an average drop of 6.6\\% with respect to feature extraction. %highlighting the need for further investigations. Finally, we evaluate the memory footprints of the different models for their possible applications on commercial mobile devices.","sentences":["Disease detection from smartphone data represents an open research challenge in mobile health (m-health) systems.","COVID-19 and its respiratory symptoms are an important case study in this area and their early detection is a potential real instrument to counteract the pandemic situation.","The efficacy of this solution mainly depends on the performances of AI algorithms applied to the collected data and their possible implementation directly on the users' mobile devices.","Considering these issues, and the limited amount of available data, in this paper we present the experimental evaluation of 3 different deep learning models, compared also with hand-crafted features, and of two main approaches of transfer learning in the considered scenario: both feature extraction and fine-tuning.","Specifically, we considered VGGish, YAMNET, and L\\textsuperscript{3}-Net (including 12 different configurations) evaluated through user-independent experiments on 4 different datasets (13,447 samples in total).","Results clearly show the advantages of L\\textsuperscript{3}-Net in all the experimental settings as it overcomes the other solutions by 12.3\\% in terms of Precision-Recall AUC as features extractor, and by 10\\% when the model is fine-tuned.","Moreover, we note that to fine-tune only the fully-connected layers of the pre-trained models generally leads to worse performances, with an average drop of 6.6\\% with respect to feature extraction.","%highlighting the need for further investigations.","Finally, we evaluate the memory footprints of the different models for their possible applications on commercial mobile devices."],"url":"http://arxiv.org/abs/2307.02975v1"}
{"created":"2023-07-06 13:19:06","title":"Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution","abstract":"Remote sensing image super-resolution (RSISR) plays a vital role in enhancing spatial detials and improving the quality of satellite imagery. Recently, Transformer-based models have shown competitive performance in RSISR. To mitigate the quadratic computational complexity resulting from global self-attention, various methods constrain attention to a local window, enhancing its efficiency. Consequently, the receptive fields in a single attention layer are inadequate, leading to insufficient context modeling. Furthermore, while most transform-based approaches reuse shallow features through skip connections, relying solely on these connections treats shallow and deep features equally, impeding the model's ability to characterize them. To address these issues, we propose a novel transformer architecture called Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network (SPIFFNet) for RSISR. Our proposed model effectively enhances global cognition and understanding of the entire image, facilitating efficient integration of features cross-stages. The model incorporates cross-spatial pixel integration attention (CSPIA) to introduce contextual information into a local window, while cross-stage feature fusion attention (CSFFA) adaptively fuses features from the previous stage to improve feature expression in line with the requirements of the current stage. We conducted comprehensive experiments on multiple benchmark datasets, demonstrating the superior performance of our proposed SPIFFNet in terms of both quantitative metrics and visual quality when compared to state-of-the-art methods.","sentences":["Remote sensing image super-resolution (RSISR) plays a vital role in enhancing spatial detials and improving the quality of satellite imagery.","Recently, Transformer-based models have shown competitive performance in RSISR.","To mitigate the quadratic computational complexity resulting from global self-attention, various methods constrain attention to a local window, enhancing its efficiency.","Consequently, the receptive fields in a single attention layer are inadequate, leading to insufficient context modeling.","Furthermore, while most transform-based approaches reuse shallow features through skip connections, relying solely on these connections treats shallow and deep features equally, impeding the model's ability to characterize them.","To address these issues, we propose a novel transformer architecture called Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network (SPIFFNet) for RSISR.","Our proposed model effectively enhances global cognition and understanding of the entire image, facilitating efficient integration of features cross-stages.","The model incorporates cross-spatial pixel integration attention (CSPIA) to introduce contextual information into a local window, while cross-stage feature fusion attention (CSFFA) adaptively fuses features from the previous stage to improve feature expression in line with the requirements of the current stage.","We conducted comprehensive experiments on multiple benchmark datasets, demonstrating the superior performance of our proposed SPIFFNet in terms of both quantitative metrics and visual quality when compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2307.02974v1"}
{"created":"2023-07-06 13:18:44","title":"Pruning vs Quantization: Which is Better?","abstract":"Neural network pruning and quantization techniques are almost as old as neural networks themselves. However, to date only ad-hoc comparisons between the two have been published. In this paper, we set out to answer the question on which is better: neural network quantization or pruning? By answering this question, we hope to inform design decisions made on neural network hardware going forward. We provide an extensive comparison between the two techniques for compressing deep neural networks. First, we give an analytical comparison of expected quantization and pruning error for general data distributions. Then, we provide lower bounds for the per-layer pruning and quantization error in trained networks, and compare these to empirical error after optimization. Finally, we provide an extensive experimental comparison for training 8 large-scale models on 3 tasks. Our results show that in most cases quantization outperforms pruning. Only in some scenarios with very high compression ratio, pruning might be beneficial from an accuracy standpoint.","sentences":["Neural network pruning and quantization techniques are almost as old as neural networks themselves.","However, to date only ad-hoc comparisons between the two have been published.","In this paper, we set out to answer the question on which is better: neural network quantization or pruning?","By answering this question, we hope to inform design decisions made on neural network hardware going forward.","We provide an extensive comparison between the two techniques for compressing deep neural networks.","First, we give an analytical comparison of expected quantization and pruning error for general data distributions.","Then, we provide lower bounds for the per-layer pruning and quantization error in trained networks, and compare these to empirical error after optimization.","Finally, we provide an extensive experimental comparison for training 8 large-scale models on 3 tasks.","Our results show that in most cases quantization outperforms pruning.","Only in some scenarios with very high compression ratio, pruning might be beneficial from an accuracy standpoint."],"url":"http://arxiv.org/abs/2307.02973v1"}
{"created":"2023-07-06 13:17:55","title":"On the Cultural Gap in Text-to-Image Generation","abstract":"One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural generation. Experimental results show that our multi-modal metric provides stronger data selection performance on the C3 benchmark than existing metrics, in which the object-text alignment is crucial. We release the benchmark, data, code, and generated images to facilitate future research on culturally diverse T2I generation (https://github.com/longyuewangdcu/C3-Bench).","sentences":["One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set.","Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images.","To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture.","By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects.","Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural generation.","Experimental results show that our multi-modal metric provides stronger data selection performance on the C3 benchmark than existing metrics, in which the object-text alignment is crucial.","We release the benchmark, data, code, and generated images to facilitate future research on culturally diverse T2I generation (https://github.com/longyuewangdcu/C3-Bench)."],"url":"http://arxiv.org/abs/2307.02971v1"}
{"created":"2023-07-06 13:12:19","title":"DPM: Clustering Sensitive Data through Separation","abstract":"Privacy-preserving clustering groups data points in an unsupervised manner whilst ensuring that sensitive information remains protected. Previous privacy-preserving clustering focused on identifying concentration of point clouds. In this paper, we take another path and focus on identifying appropriate separators that split a data set. We introduce the novel differentially private clustering algorithm DPM that searches for accurate data point separators in a differentially private manner. DPM addresses two key challenges for finding accurate separators: identifying separators that are large gaps between clusters instead of small gaps within a cluster and, to efficiently spend the privacy budget, prioritising separators that split the data into large subparts. Using the differentially private Exponential Mechanism, DPM randomly chooses cluster separators with provably high utility: For a data set $D$, if there is a wide low-density separator in the central $60\\%$ quantile, DPM finds that separator with probability $1 - \\exp(-\\sqrt{|D|})$. Our experimental evaluation demonstrates that DPM achieves significant improvements in terms of the clustering metric inertia. With the inertia results of the non-private KMeans++ as a baseline, for $\\varepsilon = 1$ and $\\delta=10^{-5}$ DPM improves upon the difference to the baseline by up to $50\\%$ for a synthetic data set and by up to $62\\%$ for a real-world data set compared to a state-of-the-art clustering algorithm by Chang and Kamath.","sentences":["Privacy-preserving clustering groups data points in an unsupervised manner whilst ensuring that sensitive information remains protected.","Previous privacy-preserving clustering focused on identifying concentration of point clouds.","In this paper, we take another path and focus on identifying appropriate separators that split a data set.","We introduce the novel differentially private clustering algorithm DPM that searches for accurate data point separators in a differentially private manner.","DPM addresses two key challenges for finding accurate separators: identifying separators that are large gaps between clusters instead of small gaps within a cluster and, to efficiently spend the privacy budget, prioritising separators that split the data into large subparts.","Using the differentially private Exponential Mechanism, DPM randomly chooses cluster separators with provably high utility:","For a data set $D$, if there is a wide low-density separator in the central $60\\%$ quantile, DPM finds that separator with probability $1 - \\exp(-\\sqrt{|D|})$. Our experimental evaluation demonstrates that DPM achieves significant improvements in terms of the clustering metric inertia.","With the inertia results of the non-private KMeans++ as a baseline, for $\\varepsilon = 1$ and $\\delta=10^{-5}$ DPM improves upon the difference to the baseline by up to $50\\%$ for a synthetic data set and by up to $62\\%$ for a real-world data set compared to a state-of-the-art clustering algorithm by Chang and Kamath."],"url":"http://arxiv.org/abs/2307.02969v1"}
{"created":"2023-07-06 13:08:27","title":"A Simple $(1-\u03b5)$-Approximation Semi-Streaming Algorithm for Maximum (Weighted) Matching","abstract":"We present a simple semi-streaming algorithm for $(1-\\epsilon)$-approximation of bipartite matching in $O(\\log{\\!(n)}/\\epsilon)$ passes. This matches the performance of state-of-the-art \"$\\epsilon$-efficient\" algorithms, while being considerably simpler.   The algorithm relies on a \"white-box\" application of the multiplicative weight update method with a self-contained primal-dual analysis that can be of independent interest. To show case this, we use the same ideas, alongside standard tools from matching theory, to present an equally simple semi-streaming algorithm for $(1-\\epsilon)$-approximation of weighted matchings in general (not necessarily bipartite) graphs, again in $O(\\log{\\!(n)}/\\epsilon)$ passes.","sentences":["We present a simple semi-streaming algorithm for $(1-\\epsilon)$-approximation of bipartite matching in $O(\\log{\\!(n)}/\\epsilon)$ passes.","This matches the performance of state-of-the-art \"$\\epsilon$-efficient\" algorithms, while being considerably simpler.   ","The algorithm relies on a \"white-box\" application of the multiplicative weight update method with a self-contained primal-dual analysis that can be of independent interest.","To show case this, we use the same ideas, alongside standard tools from matching theory, to present an equally simple semi-streaming algorithm for $(1-\\epsilon)$-approximation of weighted matchings in general (not necessarily bipartite) graphs, again in $O(\\log{\\!(n)}/\\epsilon)$ passes."],"url":"http://arxiv.org/abs/2307.02968v1"}
{"created":"2023-07-06 12:40:33","title":"Eating sandwiches: Modular and lightweight elimination of transaction reordering attacks","abstract":"Traditional blockchains grant the miner of a block full control not only over which transactions but also their order. This constitutes a major flaw discovered with the introduction of decentralized finance and allows miners to perform MEV attacks. In this paper, we address the issue of sandwich attacks by providing a construction that takes as input a blockchain protocol and outputs a new blockchain protocol with the same security but in which sandwich attacks are not profitable. Furthermore, our protocol is fully decentralized with no trusted third parties or heavy cryptography primitives and carries a linear increase in latency and minimum computation overhead.","sentences":["Traditional blockchains grant the miner of a block full control not only over which transactions but also their order.","This constitutes a major flaw discovered with the introduction of decentralized finance and allows miners to perform MEV attacks.","In this paper, we address the issue of sandwich attacks by providing a construction that takes as input a blockchain protocol and outputs a new blockchain protocol with the same security but in which sandwich attacks are not profitable.","Furthermore, our protocol is fully decentralized with no trusted third parties or heavy cryptography primitives and carries a linear increase in latency and minimum computation overhead."],"url":"http://arxiv.org/abs/2307.02954v1"}
{"created":"2023-07-06 12:36:20","title":"Recognition and Estimation of Human Finger Pointing with an RGB Camera for Robot Directive","abstract":"In communication between humans, gestures are often preferred or complementary to verbal expression since the former offers better spatial referral. Finger pointing gesture conveys vital information regarding some point of interest in the environment. In human-robot interaction, a user can easily direct a robot to a target location, for example, in search and rescue or factory assistance. State-of-the-art approaches for visual pointing estimation often rely on depth cameras, are limited to indoor environments and provide discrete predictions between limited targets. In this paper, we explore the learning of models for robots to understand pointing directives in various indoor and outdoor environments solely based on a single RGB camera. A novel framework is proposed which includes a designated model termed PointingNet. PointingNet recognizes the occurrence of pointing followed by approximating the position and direction of the index finger. The model relies on a novel segmentation model for masking any lifted arm. While state-of-the-art human pose estimation models provide poor pointing angle estimation accuracy of 28deg, PointingNet exhibits mean accuracy of less than 2deg. With the pointing information, the target is computed followed by planning and motion of the robot. The framework is evaluated on two robotic systems yielding accurate target reaching.","sentences":["In communication between humans, gestures are often preferred or complementary to verbal expression since the former offers better spatial referral.","Finger pointing gesture conveys vital information regarding some point of interest in the environment.","In human-robot interaction, a user can easily direct a robot to a target location, for example, in search and rescue or factory assistance.","State-of-the-art approaches for visual pointing estimation often rely on depth cameras, are limited to indoor environments and provide discrete predictions between limited targets.","In this paper, we explore the learning of models for robots to understand pointing directives in various indoor and outdoor environments solely based on a single RGB camera.","A novel framework is proposed which includes a designated model termed PointingNet.","PointingNet recognizes the occurrence of pointing followed by approximating the position and direction of the index finger.","The model relies on a novel segmentation model for masking any lifted arm.","While state-of-the-art human pose estimation models provide poor pointing angle estimation accuracy of 28deg, PointingNet exhibits mean accuracy of less than 2deg.","With the pointing information, the target is computed followed by planning and motion of the robot.","The framework is evaluated on two robotic systems yielding accurate target reaching."],"url":"http://arxiv.org/abs/2307.02949v1"}
{"created":"2023-07-06 12:34:32","title":"Exact Point Cloud Downsampling for Fast and Accurate Global Trajectory Optimization","abstract":"This paper presents a point cloud downsampling algorithm for fast and accurate trajectory optimization based on global registration error minimization. The proposed algorithm selects a weighted subset of residuals of the input point cloud such that the subset yields exactly the same quadratic point cloud registration error function as that of the original point cloud at the evaluation point. This method accurately approximates the original registration error function with only a small subset of input points (29 residuals at a minimum). Experimental results using the KITTI dataset demonstrate that the proposed algorithm significantly reduces processing time (by 87\\%) and memory consumption (by 99\\%) for global registration error minimization while retaining accuracy.","sentences":["This paper presents a point cloud downsampling algorithm for fast and accurate trajectory optimization based on global registration error minimization.","The proposed algorithm selects a weighted subset of residuals of the input point cloud such that the subset yields exactly the same quadratic point cloud registration error function as that of the original point cloud at the evaluation point.","This method accurately approximates the original registration error function with only a small subset of input points (29 residuals at a minimum).","Experimental results using the KITTI dataset demonstrate that the proposed algorithm significantly reduces processing time (by 87\\%) and memory consumption (by 99\\%) for global registration error minimization while retaining accuracy."],"url":"http://arxiv.org/abs/2307.02948v1"}
{"created":"2023-07-06 12:33:34","title":"A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations","abstract":"Reinforcement Learning (RL) provides a powerful framework for decision-making in complex environments. However, implementing RL in hardware-efficient and bio-inspired ways remains a challenge. This paper presents a novel Spiking Neural Network (SNN) architecture for solving RL problems with real-valued observations. The proposed model incorporates multi-layered event-based clustering, with the addition of Temporal Difference (TD)-error modulation and eligibility traces, building upon prior work. An ablation study confirms the significant impact of these components on the proposed model's performance. A tabular actor-critic algorithm with eligibility traces and a state-of-the-art Proximal Policy Optimization (PPO) algorithm are used as benchmarks. Our network consistently outperforms the tabular approach and successfully discovers stable control policies on classic RL environments: mountain car, cart-pole, and acrobot. The proposed model offers an appealing trade-off in terms of computational and hardware implementation requirements. The model does not require an external memory buffer nor a global error gradient computation, and synaptic updates occur online, driven by local learning rules and a broadcasted TD-error signal. Thus, this work contributes to the development of more hardware-efficient RL solutions.","sentences":["Reinforcement Learning (RL) provides a powerful framework for decision-making in complex environments.","However, implementing RL in hardware-efficient and bio-inspired ways remains a challenge.","This paper presents a novel Spiking Neural Network (SNN) architecture for solving RL problems with real-valued observations.","The proposed model incorporates multi-layered event-based clustering, with the addition of Temporal Difference (TD)-error modulation and eligibility traces, building upon prior work.","An ablation study confirms the significant impact of these components on the proposed model's performance.","A tabular actor-critic algorithm with eligibility traces and a state-of-the-art Proximal Policy Optimization (PPO) algorithm are used as benchmarks.","Our network consistently outperforms the tabular approach and successfully discovers stable control policies on classic RL environments: mountain car, cart-pole, and acrobot.","The proposed model offers an appealing trade-off in terms of computational and hardware implementation requirements.","The model does not require an external memory buffer nor a global error gradient computation, and synaptic updates occur online, driven by local learning rules and a broadcasted TD-error signal.","Thus, this work contributes to the development of more hardware-efficient RL solutions."],"url":"http://arxiv.org/abs/2307.02947v1"}
{"created":"2023-07-06 12:31:32","title":"Finding Favourite Tuples on Data Streams with Provably Few Comparisons","abstract":"One of the most fundamental tasks in data science is to assist a user with unknown preferences in finding high-utility tuples within a large database. To accurately elicit the unknown user preferences, a widely-adopted way is by asking the user to compare pairs of tuples. In this paper, we study the problem of identifying one or more high-utility tuples by adaptively receiving user input on a minimum number of pairwise comparisons. We devise a single-pass streaming algorithm, which processes each tuple in the stream at most once, while ensuring that the memory size and the number of requested comparisons are in the worst case logarithmic in $n$, where $n$ is the number of all tuples. An important variant of the problem, which can help to reduce human error in comparisons, is to allow users to declare ties when confronted with pairs of tuples of nearly equal utility. We show that the theoretical guarantees of our method can be maintained for this important problem variant. In addition, we show how to enhance existing pruning techniques in the literature by leveraging powerful tools from mathematical programming. Finally, we systematically evaluate all proposed algorithms over both synthetic and real-life datasets, examine their scalability, and demonstrate their superior performance over existing methods.","sentences":["One of the most fundamental tasks in data science is to assist a user with unknown preferences in finding high-utility tuples within a large database.","To accurately elicit the unknown user preferences, a widely-adopted way is by asking the user to compare pairs of tuples.","In this paper, we study the problem of identifying one or more high-utility tuples by adaptively receiving user input on a minimum number of pairwise comparisons.","We devise a single-pass streaming algorithm, which processes each tuple in the stream at most once, while ensuring that the memory size and the number of requested comparisons are in the worst case logarithmic in $n$, where $n$ is the number of all tuples.","An important variant of the problem, which can help to reduce human error in comparisons, is to allow users to declare ties when confronted with pairs of tuples of nearly equal utility.","We show that the theoretical guarantees of our method can be maintained for this important problem variant.","In addition, we show how to enhance existing pruning techniques in the literature by leveraging powerful tools from mathematical programming.","Finally, we systematically evaluate all proposed algorithms over both synthetic and real-life datasets, examine their scalability, and demonstrate their superior performance over existing methods."],"url":"http://arxiv.org/abs/2307.02946v1"}
{"created":"2023-07-06 12:02:38","title":"A Meta-Evaluation of C/W/L/A Metrics: System Ranking Similarity, System Ranking Consistency and Discriminative Power","abstract":"Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for offline evaluation metrics. This framework allows information retrieval (IR) researchers to design evaluation metrics through the flexible combination of user browsing models and user gain aggregations. However, the statistical stability of C/W/L/A metrics with different aggregations is not yet investigated. In this study, we investigate the statistical stability of C/W/L/A metrics from the perspective of: (1) the system ranking similarity among aggregations, (2) the system ranking consistency of aggregations and (3) the discriminative power of aggregations. More specifically, we combined various aggregation functions with the browsing model of Precision, Discounted Cumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision (AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of system ranking similarity, system ranking consistency and discriminative power on two offline test collections. Our experimental result suggests that, in terms of system ranking consistency and discriminative power, the aggregation function of expected rate of gain (ERG) has an outstanding performance while the aggregation function of maximum relevance usually has an insufficient performance. The result also suggests that Precision, DCG, RBP, INST and AP with their canonical aggregation all have favourable performances in system ranking consistency and discriminative power; but for ERR, replacing its canonical aggregation with ERG can further strengthen the discriminative power while obtaining a system ranking list similar to the canonical version at the same time.","sentences":["Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for offline evaluation metrics.","This framework allows information retrieval (IR) researchers to design evaluation metrics through the flexible combination of user browsing models and user gain aggregations.","However, the statistical stability of C/W/L/A metrics with different aggregations is not yet investigated.","In this study, we investigate the statistical stability of C/W/L/A metrics from the perspective of: (1) the system ranking similarity among aggregations, (2) the system ranking consistency of aggregations and (3) the discriminative power of aggregations.","More specifically, we combined various aggregation functions with the browsing model of Precision, Discounted Cumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision (AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of system ranking similarity, system ranking consistency and discriminative power on two offline test collections.","Our experimental result suggests that, in terms of system ranking consistency and discriminative power, the aggregation function of expected rate of gain (ERG) has an outstanding performance while the aggregation function of maximum relevance usually has an insufficient performance.","The result also suggests that Precision, DCG, RBP, INST and AP with their canonical aggregation all have favourable performances in system ranking consistency and discriminative power; but for ERR, replacing its canonical aggregation with ERG can further strengthen the discriminative power while obtaining a system ranking list similar to the canonical version at the same time."],"url":"http://arxiv.org/abs/2307.02936v1"}
{"created":"2023-07-06 11:52:36","title":"DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning","abstract":"Asymmetry is a crucial characteristic of bilateral mammograms (Bi-MG) when abnormalities are developing. It is widely utilized by radiologists for diagnosis. The question of 'what the symmetrical Bi-MG would look like when the asymmetrical abnormalities have been removed ?' has not yet received strong attention in the development of algorithms on mammograms. Addressing this question could provide valuable insights into mammographic anatomy and aid in diagnostic interpretation. Hence, we propose a novel framework, DisAsymNet, which utilizes asymmetrical abnormality transformer guided self-adversarial learning for disentangling abnormalities and symmetric Bi-MG. At the same time, our proposed method is partially guided by randomly synthesized abnormalities. We conduct experiments on three public and one in-house dataset, and demonstrate that our method outperforms existing methods in abnormality classification, segmentation, and localization tasks. Additionally, reconstructed normal mammograms can provide insights toward better interpretable visual cues for clinical diagnosis. The code will be accessible to the public.","sentences":["Asymmetry is a crucial characteristic of bilateral mammograms (Bi-MG) when abnormalities are developing.","It is widely utilized by radiologists for diagnosis.","The question of 'what the symmetrical Bi-MG would look like when the asymmetrical abnormalities have been removed ?' has not yet received strong attention in the development of algorithms on mammograms.","Addressing this question could provide valuable insights into mammographic anatomy and aid in diagnostic interpretation.","Hence, we propose a novel framework, DisAsymNet, which utilizes asymmetrical abnormality transformer guided self-adversarial learning for disentangling abnormalities and symmetric Bi-MG.","At the same time, our proposed method is partially guided by randomly synthesized abnormalities.","We conduct experiments on three public and one in-house dataset, and demonstrate that our method outperforms existing methods in abnormality classification, segmentation, and localization tasks.","Additionally, reconstructed normal mammograms can provide insights toward better interpretable visual cues for clinical diagnosis.","The code will be accessible to the public."],"url":"http://arxiv.org/abs/2307.02935v1"}
{"created":"2023-07-06 11:51:43","title":"In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms","abstract":"Robotic solutions, in particular robotic arms, are becoming more frequently deployed for close collaboration with humans, for example in manufacturing or domestic care environments. These robotic arms require the user to control several Degrees-of-Freedom (DoFs) to perform tasks, primarily involving grasping and manipulating objects. Standard input devices predominantly have two DoFs, requiring time-consuming and cognitively demanding mode switches to select individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have shown to decrease the necessary number of mode switches but were up to now not able to significantly reduce the perceived workload. Users still bear the mental workload of incorporating abstract mode switching into their workflow. We address this by providing feed-forward multimodal feedback using updated recommendations of ADMC, allowing users to visually compare the current and the suggested mapping in real-time. We contrast the effectiveness of two new approaches that a) continuously recommend updated DoF combinations or b) use discrete thresholds between current robot movements and new recommendations. Both are compared in a Virtual Reality (VR) in-person study against a classic control method. Significant results for lowered task completion time, fewer mode switches, and reduced perceived workload conclusively establish that in combination with feedforward, ADMC methods can indeed outperform classic mode switching. A lack of apparent quantitative differences between Continuous and Threshold reveals the importance of user-centered customization options. Including these implications in the development process will improve usability, which is essential for successfully implementing robotic technologies with high user acceptance.","sentences":["Robotic solutions, in particular robotic arms, are becoming more frequently deployed for close collaboration with humans, for example in manufacturing or domestic care environments.","These robotic arms require the user to control several Degrees-of-Freedom (DoFs) to perform tasks, primarily involving grasping and manipulating objects.","Standard input devices predominantly have two DoFs, requiring time-consuming and cognitively demanding mode switches to select individual DoFs.","Contemporary Adaptive DoF Mapping Controls (ADMCs) have shown to decrease the necessary number of mode switches but were up to now not able to significantly reduce the perceived workload.","Users still bear the mental workload of incorporating abstract mode switching into their workflow.","We address this by providing feed-forward multimodal feedback using updated recommendations of ADMC, allowing users to visually compare the current and the suggested mapping in real-time.","We contrast the effectiveness of two new approaches that a) continuously recommend updated DoF combinations or b) use discrete thresholds between current robot movements and new recommendations.","Both are compared in a Virtual Reality (VR) in-person study against a classic control method.","Significant results for lowered task completion time, fewer mode switches, and reduced perceived workload conclusively establish that in combination with feedforward, ADMC methods can indeed outperform classic mode switching.","A lack of apparent quantitative differences between Continuous and Threshold reveals the importance of user-centered customization options.","Including these implications in the development process will improve usability, which is essential for successfully implementing robotic technologies with high user acceptance."],"url":"http://arxiv.org/abs/2307.02933v1"}
{"created":"2023-07-06 11:43:22","title":"When No-Rejection Learning is Optimal for Regression with Rejection","abstract":"Learning with rejection is a prototypical model for studying the interaction between humans and AI on prediction tasks. The model has two components, a predictor and a rejector. Upon the arrival of a sample, the rejector first decides whether to accept it; if accepted, the predictor fulfills the prediction task, and if rejected, the prediction will be deferred to humans. The learning problem requires learning a predictor and a rejector simultaneously. This changes the structure of the conventional loss function and often results in non-convexity and inconsistency issues. For the classification with rejection problem, several works develop surrogate losses for the jointly learning with provable consistency guarantees; in parallel, there has been less work for the regression counterpart. We study the regression with rejection (RwR) problem and investigate the no-rejection learning strategy which treats the RwR problem as a standard regression task to learn the predictor. We establish that the suboptimality of the no-rejection learning strategy observed in the literature can be mitigated by enlarging the function class of the predictor. Then we introduce the truncated loss to single out the learning for the predictor and we show that a consistent surrogate property can be established for the predictor individually in an easier way than for the predictor and the rejector jointly. Our findings advocate for a two-step learning procedure that first uses all the data to learn the predictor and then calibrates the prediction loss for the rejector. It is better aligned with the common intuition that more data samples will lead to a better predictor and it calls for more efforts on a better design of calibration algorithms for learning the rejector. While our discussions mainly focus on the regression problem, the theoretical results and insights generalize to the classification problem as well.","sentences":["Learning with rejection is a prototypical model for studying the interaction between humans and AI on prediction tasks.","The model has two components, a predictor and a rejector.","Upon the arrival of a sample, the rejector first decides whether to accept it; if accepted, the predictor fulfills the prediction task, and if rejected, the prediction will be deferred to humans.","The learning problem requires learning a predictor and a rejector simultaneously.","This changes the structure of the conventional loss function and often results in non-convexity and inconsistency issues.","For the classification with rejection problem, several works develop surrogate losses for the jointly learning with provable consistency guarantees; in parallel, there has been less work for the regression counterpart.","We study the regression with rejection (RwR) problem and investigate the no-rejection learning strategy which treats the RwR problem as a standard regression task to learn the predictor.","We establish that the suboptimality of the no-rejection learning strategy observed in the literature can be mitigated by enlarging the function class of the predictor.","Then we introduce the truncated loss to single out the learning for the predictor and we show that a consistent surrogate property can be established for the predictor individually in an easier way than for the predictor and the rejector jointly.","Our findings advocate for a two-step learning procedure that first uses all the data to learn the predictor and then calibrates the prediction loss for the rejector.","It is better aligned with the common intuition that more data samples will lead to a better predictor and it calls for more efforts on a better design of calibration algorithms for learning the rejector.","While our discussions mainly focus on the regression problem, the theoretical results and insights generalize to the classification problem as well."],"url":"http://arxiv.org/abs/2307.02932v1"}
{"created":"2023-07-06 11:42:54","title":"Smartphones in a Microwave: Formal and Experimental Feasibility Study on Fingerprinting the Corona-Warn-App","abstract":"Contact Tracing Apps (CTAs) have been developed to contain the coronavirus disease 19 (COVID-19) spread. By design, such apps invade their users' privacy by recording data about their health, contacts, and partially location. Many CTAs frequently broadcast pseudorandom numbers via Bluetooth to detect encounters. These numbers are changed regularly to prevent individual smartphones from being trivially trackable. However, the effectiveness of this procedure has been little studied. We measured real smartphones and observed that the German Corona-Warn-App (CWA) exhibits a device-specific latency between two subsequent broadcasts. These timing differences provide a potential attack vector for fingerprinting smartphones by passively recording Bluetooth messages. This could conceivably lead to the tracking of users' trajectories and, ultimately, the re-identification of users.","sentences":["Contact Tracing Apps (CTAs) have been developed to contain the coronavirus disease 19 (COVID-19) spread.","By design, such apps invade their users' privacy by recording data about their health, contacts, and partially location.","Many CTAs frequently broadcast pseudorandom numbers via Bluetooth to detect encounters.","These numbers are changed regularly to prevent individual smartphones from being trivially trackable.","However, the effectiveness of this procedure has been little studied.","We measured real smartphones and observed that the German Corona-Warn-App (CWA) exhibits a device-specific latency between two subsequent broadcasts.","These timing differences provide a potential attack vector for fingerprinting smartphones by passively recording Bluetooth messages.","This could conceivably lead to the tracking of users' trajectories and, ultimately, the re-identification of users."],"url":"http://arxiv.org/abs/2307.02931v1"}
{"created":"2023-07-06 11:28:53","title":"AllSight: A Low-Cost and High-Resolution Round Tactile Sensor with Zero-Shot Learning Capability","abstract":"Tactile sensing is a necessary capability for a robotic hand to perform fine manipulations and interact with the environment. Optical sensors are a promising solution for high-resolution contact estimation. Nevertheless, they are usually not easy to fabricate and require individual calibration in order to acquire sufficient accuracy. In this letter, we propose AllSight, an optical tactile sensor with a round 3D structure potentially designed for robotic in-hand manipulation tasks. AllSight is mostly 3D printed making it low-cost, modular, durable and in the size of a human thumb while with a large contact surface. We show the ability of AllSight to learn and estimate a full contact state, i.e., contact position, forces and torsion. With that, an experimental benchmark between various configurations of illumination and contact elastomers are provided. Furthermore, the robust design of AllSight provides it with a unique zero-shot capability such that a practitioner can fabricate the open-source design and have a ready-to-use state estimation model. A set of experiments demonstrates the accurate state estimation performance of AllSight.","sentences":["Tactile sensing is a necessary capability for a robotic hand to perform fine manipulations and interact with the environment.","Optical sensors are a promising solution for high-resolution contact estimation.","Nevertheless, they are usually not easy to fabricate and require individual calibration in order to acquire sufficient accuracy.","In this letter, we propose AllSight, an optical tactile sensor with a round 3D structure potentially designed for robotic in-hand manipulation tasks.","AllSight is mostly 3D printed making it low-cost, modular, durable and in the size of a human thumb while with a large contact surface.","We show the ability of AllSight to learn and estimate a full contact state, i.e., contact position, forces and torsion.","With that, an experimental benchmark between various configurations of illumination and contact elastomers are provided.","Furthermore, the robust design of AllSight provides it with a unique zero-shot capability such that a practitioner can fabricate the open-source design and have a ready-to-use state estimation model.","A set of experiments demonstrates the accurate state estimation performance of AllSight."],"url":"http://arxiv.org/abs/2307.02928v1"}
{"created":"2023-07-06 11:28:51","title":"Rank analysis of most cited publications, a new approach for research assessments","abstract":"Citation metrics are the best tools for research assessments. However, current metrics are misleading in research systems that pursue simultaneously different goals, such as the advance of science and incremental innovations, because their publications have different citation distributions. We estimate the contribution to the progress of knowledge by studying only a limited number of the most cited papers, which are dominated by publications pursuing this progress. To field-normalize the metrics, we substitute the number of citations by the rank position of papers from one country in the global list of papers. Using synthetic series of lognormally distributed numbers, we developed the Rk-index, which is calculated from the global ranks of the 10 highest numbers in each series, and demonstrate its equivalence to the number of papers in top percentiles, P top 0.1% and P top 0.01% . In real cases, the Rk-index is simple and easy to calculate, and evaluates the contribution to the progress of knowledge much better than commonly used metrics. Although further research is needed, rank analysis of the most cited papers is a promising approach for research evaluation. It is also demonstrated that, for this purpose, domestic and collaborative papers should be studied independently.","sentences":["Citation metrics are the best tools for research assessments.","However, current metrics are misleading in research systems that pursue simultaneously different goals, such as the advance of science and incremental innovations, because their publications have different citation distributions.","We estimate the contribution to the progress of knowledge by studying only a limited number of the most cited papers, which are dominated by publications pursuing this progress.","To field-normalize the metrics, we substitute the number of citations by the rank position of papers from one country in the global list of papers.","Using synthetic series of lognormally distributed numbers, we developed the Rk-index, which is calculated from the global ranks of the 10 highest numbers in each series, and demonstrate its equivalence to the number of papers in top percentiles, P top 0.1% and P top 0.01% .","In real cases, the Rk-index is simple and easy to calculate, and evaluates the contribution to the progress of knowledge much better than commonly used metrics.","Although further research is needed, rank analysis of the most cited papers is a promising approach for research evaluation.","It is also demonstrated that, for this purpose, domestic and collaborative papers should be studied independently."],"url":"http://arxiv.org/abs/2307.02927v1"}
{"created":"2023-07-06 11:23:40","title":"The Emotional Dilemma: Influence of a Human-like Robot on Trust and Cooperation","abstract":"Increasing anthropomorphic robot behavioral design could affect trust and cooperation positively. However, studies have shown contradicting results and suggest a task-dependent relationship between robots that display emotions and trust. Therefore, this study analyzes the effect of robots that display human-like emotions on trust, cooperation, and participants' emotions. In the between-group study, participants play the coin entrustment game with an emotional and a non-emotional robot. The results show that the robot that displays emotions induces more anxiety than the neutral robot. Accordingly, the participants trust the emotional robot less and are less likely to cooperate. Furthermore, the perceived intelligence of a robot increases trust, while a desire to outcompete the robot can reduce trust and cooperation. Thus, the design of robots expressing emotions should be task dependent to avoid adverse effects that reduce trust and cooperation.","sentences":["Increasing anthropomorphic robot behavioral design could affect trust and cooperation positively.","However, studies have shown contradicting results and suggest a task-dependent relationship between robots that display emotions and trust.","Therefore, this study analyzes the effect of robots that display human-like emotions on trust, cooperation, and participants' emotions.","In the between-group study, participants play the coin entrustment game with an emotional and a non-emotional robot.","The results show that the robot that displays emotions induces more anxiety than the neutral robot.","Accordingly, the participants trust the emotional robot less and are less likely to cooperate.","Furthermore, the perceived intelligence of a robot increases trust, while a desire to outcompete the robot can reduce trust and cooperation.","Thus, the design of robots expressing emotions should be task dependent to avoid adverse effects that reduce trust and cooperation."],"url":"http://arxiv.org/abs/2307.02924v1"}
{"created":"2023-07-06 11:07:39","title":"The impact of an employee's psychological contract breach on compliance with information security policies: intrinsic and extrinsic motivation","abstract":"Despite the rapid rise in social engineering attacks, not all employees are as compliant with information security policies (ISPs) to the extent that organisations expect them to be. ISP non-compliance is caused by a variety of psychological motivation. This study investigates the effect of psychological contract breach (PCB) of employees on ISP compliance intention (ICI) by dividing them into intrinsic and extrinsic motivation using the theory of planned behaviour (TPB) and the general deterrence theory (GDT). Data analysis from UK employees (\\textit{n=206}) showed that the higher the PCB, the lower the ICI. The study also found that PCBs significantly reduced intrinsic motivation (attitude and perceived fairness) for ICI, whereas PCBs did not moderate the relationship between extrinsic motivation (sanction severity and sanctions certainty) and ICI. As a result, this study successfully addresses the risks of PCBs in the field of IS security and proposes effective solutions for employees with high PCBs.","sentences":["Despite the rapid rise in social engineering attacks, not all employees are as compliant with information security policies (ISPs) to the extent that organisations expect them to be.","ISP non-compliance is caused by a variety of psychological motivation.","This study investigates the effect of psychological contract breach (PCB) of employees on ISP compliance intention (ICI) by dividing them into intrinsic and extrinsic motivation using the theory of planned behaviour (TPB) and the general deterrence theory (GDT).","Data analysis from UK employees (\\textit{n=206}) showed that the higher the PCB, the lower the ICI.","The study also found that PCBs significantly reduced intrinsic motivation (attitude and perceived fairness) for ICI, whereas PCBs did not moderate the relationship between extrinsic motivation (sanction severity and sanctions certainty) and ICI.","As a result, this study successfully addresses the risks of PCBs in the field of IS security and proposes effective solutions for employees with high PCBs."],"url":"http://arxiv.org/abs/2307.02916v1"}
{"created":"2023-07-06 11:05:38","title":"MorphoArms: Morphogenetic Teleoperation of Multimanual Robot","abstract":"Nowadays, there are few unmanned aerial vehicles (UAVs) capable of flying, walking and grasping. A drone with all these functionalities can significantly improve its performance in complex tasks such as monitoring and exploring different types of terrain, and rescue operations. This paper presents MorphoArms, a novel system that consists of a morphogenetic chassis and a hand gesture recognition teleoperation system. The mechanics, electronics, control architecture, and walking behavior of the morphogenetic chassis are described. This robot is capable of walking and grasping objects using four robotic limbs. Robotic limbs with four degrees-of-freedom are used as pedipulators when walking and as manipulators when performing actions in the environment. The robot control system is implemented using teleoperation, where commands are given by hand gestures. A motion capture system is used to track the user's hands and to recognize their gestures. The method of controlling the robot was experimentally tested in a study involving 10 users. The evaluation included three questionnaires (NASA TLX, SUS, and UEQ). The results showed that the proposed system was more user-friendly than 56% of the systems, and it was rated above average in terms of attractiveness, stimulation, and novelty.","sentences":["Nowadays, there are few unmanned aerial vehicles (UAVs) capable of flying, walking and grasping.","A drone with all these functionalities can significantly improve its performance in complex tasks such as monitoring and exploring different types of terrain, and rescue operations.","This paper presents MorphoArms, a novel system that consists of a morphogenetic chassis and a hand gesture recognition teleoperation system.","The mechanics, electronics, control architecture, and walking behavior of the morphogenetic chassis are described.","This robot is capable of walking and grasping objects using four robotic limbs.","Robotic limbs with four degrees-of-freedom are used as pedipulators when walking and as manipulators when performing actions in the environment.","The robot control system is implemented using teleoperation, where commands are given by hand gestures.","A motion capture system is used to track the user's hands and to recognize their gestures.","The method of controlling the robot was experimentally tested in a study involving 10 users.","The evaluation included three questionnaires (NASA TLX, SUS, and UEQ).","The results showed that the proposed system was more user-friendly than 56% of the systems, and it was rated above average in terms of attractiveness, stimulation, and novelty."],"url":"http://arxiv.org/abs/2307.02915v1"}
{"created":"2023-07-06 10:53:50","title":"LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias","abstract":"Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks. We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing. Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them. Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training. However, all these methods still suffer from the token distribution shift induced by typos. In this work, we propose to tackle textual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences. By using raw text similarities, our approach avoids the tokenization shift problem obtaining improved robustness. We demonstrate that the attention bias introduced by LEA helps cross-encoders to tackle complex scenarios with textual noise, specially in domains with short-text descriptions and limited context. Experiments using three popular Transformer encoders in five e-commerce datasets for product matching show that LEA consistently boosts performance under the presence of noise, while remaining competitive on the original (clean) splits. We also evaluate our approach in two datasets for textual entailment and paraphrasing showing that LEA is robust to typos in domains with longer sentences and more natural context. Additionally, we thoroughly analyze several design choices in our approach, providing insights about the impact of the decisions made and fostering future research in cross-encoders dealing with typos.","sentences":["Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks.","We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing.","Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them.","Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training.","However, all these methods still suffer from the token distribution shift induced by typos.","In this work, we propose to tackle textual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences.","By using raw text similarities, our approach avoids the tokenization shift problem obtaining improved robustness.","We demonstrate that the attention bias introduced by LEA helps cross-encoders to tackle complex scenarios with textual noise, specially in domains with short-text descriptions and limited context.","Experiments using three popular Transformer encoders in five e-commerce datasets for product matching show that LEA consistently boosts performance under the presence of noise, while remaining competitive on the original (clean) splits.","We also evaluate our approach in two datasets for textual entailment and paraphrasing showing that LEA is robust to typos in domains with longer sentences and more natural context.","Additionally, we thoroughly analyze several design choices in our approach, providing insights about the impact of the decisions made and fostering future research in cross-encoders dealing with typos."],"url":"http://arxiv.org/abs/2307.02912v1"}
{"created":"2023-07-06 10:52:22","title":"Agentivit\u00e0 e telicit\u00e0 in GilBERTo: implicazioni cognitive","abstract":"The goal of this study is to investigate whether a Transformer-based neural language model infers lexical semantics and use this information for the completion of morphosyntactic patterns. The semantic properties considered are telicity (also combined with definiteness) and agentivity. Both act at the interface between semantics and morphosyntax: they are semantically determined and syntactically encoded. The tasks were submitted to both the computational model and a group of Italian native speakers. The comparison between the two groups of data allows us to investigate to what extent neural language models capture significant aspects of human semantic competence.","sentences":["The goal of this study is to investigate whether a Transformer-based neural language model infers lexical semantics and use this information for the completion of morphosyntactic patterns.","The semantic properties considered are telicity (also combined with definiteness) and agentivity.","Both act at the interface between semantics and morphosyntax: they are semantically determined and syntactically encoded.","The tasks were submitted to both the computational model and a group of Italian native speakers.","The comparison between the two groups of data allows us to investigate to what extent neural language models capture significant aspects of human semantic competence."],"url":"http://arxiv.org/abs/2307.02910v1"}
{"created":"2023-07-06 10:38:14","title":"A Real-time Human Pose Estimation Approach for Optimal Sensor Placement in Sensor-based Human Activity Recognition","abstract":"Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of human movements. However, determining the most effective sensor placement for optimal classification performance remains challenging. This paper introduces a novel methodology to resolve this issue, using real-time 2D pose estimations derived from video recordings of target activities. The derived skeleton data provides a unique strategy for identifying the optimal sensor location. We validate our approach through a feasibility study, applying inertial sensors to monitor 13 different activities across ten subjects. Our findings indicate that the vision-based method for sensor placement offers comparable results to the conventional deep learning approach, demonstrating its efficacy. This research significantly advances the field of Human Activity Recognition by providing a lightweight, on-device solution for determining the optimal sensor placement, thereby enhancing data anonymization and supporting a multimodal classification approach.","sentences":["Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of human movements.","However, determining the most effective sensor placement for optimal classification performance remains challenging.","This paper introduces a novel methodology to resolve this issue, using real-time 2D pose estimations derived from video recordings of target activities.","The derived skeleton data provides a unique strategy for identifying the optimal sensor location.","We validate our approach through a feasibility study, applying inertial sensors to monitor 13 different activities across ten subjects.","Our findings indicate that the vision-based method for sensor placement offers comparable results to the conventional deep learning approach, demonstrating its efficacy.","This research significantly advances the field of Human Activity Recognition by providing a lightweight, on-device solution for determining the optimal sensor placement, thereby enhancing data anonymization and supporting a multimodal classification approach."],"url":"http://arxiv.org/abs/2307.02906v1"}
{"created":"2023-07-06 10:09:52","title":"RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution","abstract":"Smartphones equipped with a multi-camera system comprising multiple cameras with different field-of-view (FoVs) are becoming more prevalent. These camera configurations are compatible with reference-based SR and video SR, which can be executed simultaneously while recording video on the device. Thus, combining these two SR methods can improve image quality. Recently, Lee et al. have presented such a method, RefVSR. In this paper, we consider how to optimally utilize the observations obtained, including input low-resolution (LR) video and reference (Ref) video. RefVSR extends conventional video SR quite simply, aggregating the LR and Ref inputs over time in a single bidirectional stream. However, considering the content difference between LR and Ref images due to their FoVs, we can derive the maximum information from the two image sequences by aggregating them independently in the temporal direction. Then, we propose an improved method, RefVSR++, which can aggregate two features in parallel in the temporal direction, one for aggregating the fused LR and Ref inputs and the other for Ref inputs over time. Furthermore, we equip RefVSR++ with enhanced mechanisms to align image features over time, which is the key to the success of video SR. We experimentally show that RefVSR++ outperforms RefVSR by over 1dB in PSNR, achieving the new state-of-the-art.","sentences":["Smartphones equipped with a multi-camera system comprising multiple cameras with different field-of-view (FoVs) are becoming more prevalent.","These camera configurations are compatible with reference-based SR and video SR, which can be executed simultaneously while recording video on the device.","Thus, combining these two SR methods can improve image quality.","Recently, Lee et al. have presented such a method, RefVSR.","In this paper, we consider how to optimally utilize the observations obtained, including input low-resolution (LR) video and reference (Ref) video.","RefVSR extends conventional video SR quite simply, aggregating the LR and Ref inputs over time in a single bidirectional stream.","However, considering the content difference between LR and Ref images due to their FoVs, we can derive the maximum information from the two image sequences by aggregating them independently in the temporal direction.","Then, we propose an improved method, RefVSR++, which can aggregate two features in parallel in the temporal direction, one for aggregating the fused LR and Ref inputs and the other for Ref inputs over time.","Furthermore, we equip RefVSR++ with enhanced mechanisms to align image features over time, which is the key to the success of video SR.","We experimentally show that RefVSR++ outperforms RefVSR by over 1dB in PSNR, achieving the new state-of-the-art."],"url":"http://arxiv.org/abs/2307.02897v1"}
{"created":"2023-07-06 10:03:08","title":"Robust Deployment and Resource Allocation for Robotic Aerial Base Station Enabled OFDM Integrated Sensing and Communication","abstract":"The envisioned robotic aerial base station (RABS) concept is expected to bring further flexibility to integrated sensing and communication (ISAC) systems. In this letter, characterizing the spatial traffic distribution on a grid-based model, the RABS-assisted ISAC system is formulated as a robust optimization problem to maximize the minimum satisfaction rate (SR) under a cardinality constrained uncertainty set. The problem is reformulated as a mixed-integer linear programming (MILP) and solved approximately by the iterative linear programming rounding algorithm. Numerical investigations show that the minimum SR can be improved by 28.61% on average compared to fixed small cells.","sentences":["The envisioned robotic aerial base station (RABS) concept is expected to bring further flexibility to integrated sensing and communication (ISAC) systems.","In this letter, characterizing the spatial traffic distribution on a grid-based model, the RABS-assisted ISAC system is formulated as a robust optimization problem to maximize the minimum satisfaction rate (SR) under a cardinality constrained uncertainty set.","The problem is reformulated as a mixed-integer linear programming (MILP) and solved approximately by the iterative linear programming rounding algorithm.","Numerical investigations show that the minimum SR can be improved by 28.61% on average compared to fixed small cells."],"url":"http://arxiv.org/abs/2307.02896v1"}
{"created":"2023-07-06 09:57:48","title":"Free Bits: Latency Optimization of Mixed-Precision Quantized Neural Networks on the Edge","abstract":"Mixed-precision quantization, where a deep neural network's layers are quantized to different precisions, offers the opportunity to optimize the trade-offs between model size, latency, and statistical accuracy beyond what can be achieved with homogeneous-bit-width quantization. To navigate the intractable search space of mixed-precision configurations for a given network, this paper proposes a hybrid search methodology. It consists of a hardware-agnostic differentiable search algorithm followed by a hardware-aware heuristic optimization to find mixed-precision configurations latency-optimized for a specific hardware target. We evaluate our algorithm on MobileNetV1 and MobileNetV2 and deploy the resulting networks on a family of multi-core RISC-V microcontroller platforms with different hardware characteristics. We achieve up to 28.6% reduction of end-to-end latency compared to an 8-bit model at a negligible accuracy drop from a full-precision baseline on the 1000-class ImageNet dataset. We demonstrate speedups relative to an 8-bit baseline, even on systems with no hardware support for sub-byte arithmetic at negligible accuracy drop. Furthermore, we show the superiority of our approach with respect to differentiable search targeting reduced binary operation counts as a proxy for latency.","sentences":["Mixed-precision quantization, where a deep neural network's layers are quantized to different precisions, offers the opportunity to optimize the trade-offs between model size, latency, and statistical accuracy beyond what can be achieved with homogeneous-bit-width quantization.","To navigate the intractable search space of mixed-precision configurations for a given network, this paper proposes a hybrid search methodology.","It consists of a hardware-agnostic differentiable search algorithm followed by a hardware-aware heuristic optimization to find mixed-precision configurations latency-optimized for a specific hardware target.","We evaluate our algorithm on MobileNetV1 and MobileNetV2 and deploy the resulting networks on a family of multi-core RISC-V microcontroller platforms with different hardware characteristics.","We achieve up to 28.6% reduction of end-to-end latency compared to an 8-bit model at a negligible accuracy drop from a full-precision baseline on the 1000-class ImageNet dataset.","We demonstrate speedups relative to an 8-bit baseline, even on systems with no hardware support for sub-byte arithmetic at negligible accuracy drop.","Furthermore, we show the superiority of our approach with respect to differentiable search targeting reduced binary operation counts as a proxy for latency."],"url":"http://arxiv.org/abs/2307.02894v1"}
{"created":"2023-07-06 09:54:35","title":"The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection","abstract":"This work shows that depression changes the correlation between features extracted from speech. Furthermore, it shows that using such an insight can improve the training speed and performance of depression detectors based on SVMs and LSTMs. The experiments were performed over the Androids Corpus, a publicly available dataset involving 112 speakers, including 58 people diagnosed with depression by professional psychiatrists. The results show that the models used in the experiments improve in terms of training speed and performance when fed with feature correlation matrices rather than with feature vectors. The relative reduction of the error rate ranges between 23.1% and 26.6% depending on the model. The probable explanation is that feature correlation matrices appear to be more variable in the case of depressed speakers. Correspondingly, such a phenomenon can be thought of as a depression marker.","sentences":["This work shows that depression changes the correlation between features extracted from speech.","Furthermore, it shows that using such an insight can improve the training speed and performance of depression detectors based on SVMs and LSTMs.","The experiments were performed over the Androids Corpus, a publicly available dataset involving 112 speakers, including 58 people diagnosed with depression by professional psychiatrists.","The results show that the models used in the experiments improve in terms of training speed and performance when fed with feature correlation matrices rather than with feature vectors.","The relative reduction of the error rate ranges between 23.1% and 26.6% depending on the model.","The probable explanation is that feature correlation matrices appear to be more variable in the case of depressed speakers.","Correspondingly, such a phenomenon can be thought of as a depression marker."],"url":"http://arxiv.org/abs/2307.02892v1"}
{"created":"2023-07-06 09:53:56","title":"BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables","abstract":"We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness. Corrective methods like statistical parity usually lead to bad accuracy and do not really achieve fairness in situations where there is a correlation between the sensitive attribute S and the legitimate attribute E (explanatory variable) that should determine the decision. To overcome these drawbacks, other notions of fairness have been proposed, in particular, conditional statistical parity and equal opportunity. However, E is often not directly observable in the data, i.e., it is a latent variable. We may observe some other variable Z representing E, but the problem is that Z may also be affected by S, hence Z itself can be biased. To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each group. The decision can then be based directly on the estimated E. We show, by experiments on synthetic and real data sets, that our approach provides a good level of fairness as well as high accuracy.","sentences":["We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness.","Corrective methods like statistical parity usually lead to bad accuracy and do not really achieve fairness in situations where there is a correlation between the sensitive attribute S and the legitimate attribute E (explanatory variable) that should determine the decision.","To overcome these drawbacks, other notions of fairness have been proposed, in particular, conditional statistical parity and equal opportunity.","However, E is often not directly observable in the data, i.e., it is a latent variable.","We may observe some other variable Z representing E, but the problem is that Z may also be affected by S, hence Z itself can be biased.","To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each group.","The decision can then be based directly on the estimated E. We show, by experiments on synthetic and real data sets, that our approach provides a good level of fairness as well as high accuracy."],"url":"http://arxiv.org/abs/2307.02891v1"}
{"created":"2023-07-06 09:48:51","title":"Learning to Solve Tasks with Exploring Prior Behaviours","abstract":"Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards. However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours. For example, consider we are given the demonstration for the task of \\emph{picking up an object from an open drawer}, but the drawer is closed in the training. Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task. To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \\textbf{(IRDEC)}. Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours. The performance of our method outperforms other baselines on three navigation tasks and one robotic manipulation task with sparse rewards. Codes are available at https://github.com/Ricky-Zhu/IRDEC.","sentences":["Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards.","However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours.","For example, consider we are given the demonstration for the task of \\emph{picking up an object from an open drawer}, but the drawer is closed in the training.","Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task.","To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \\textbf{(IRDEC)}.","Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours.","The performance of our method outperforms other baselines on three navigation tasks and one robotic manipulation task with sparse rewards.","Codes are available at https://github.com/Ricky-Zhu/IRDEC."],"url":"http://arxiv.org/abs/2307.02889v1"}
{"created":"2023-07-06 09:39:01","title":"Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight","abstract":"This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case. Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves. We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \\emph{multi-observation revealing POMDPs} and \\emph{distinguishable POMDPs}. Both subclasses generalize and substantially relax \\emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback. Notably, distinguishable POMDPs only require the emission distributions from different latent states to be \\emph{different} instead of \\emph{linearly independent} as required in revealing POMDPs.","sentences":["This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case.","Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves.","We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \\emph{multi-observation revealing POMDPs} and \\emph{distinguishable POMDPs}.","Both subclasses generalize and substantially relax \\emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback.","Notably, distinguishable POMDPs only require the emission distributions from different latent states to be \\emph{different} instead of \\emph{linearly independent} as required in revealing POMDPs."],"url":"http://arxiv.org/abs/2307.02884v1"}
{"created":"2023-07-06 09:36:54","title":"Contrast Is All You Need","abstract":"In this study, we analyze data-scarce classification scenarios, where available labeled legal data is small and imbalanced, potentially hurting the quality of the results. We focused on two finetuning objectives; SetFit (Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla finetuning setup on a legal provision classification task. Additionally, we compare the features that are extracted with LIME (Local Interpretable Model-agnostic Explanations) to see which particular features contributed to the model's classification decisions. The results show that a contrastive setup with SetFit performed better than vanilla finetuning while using a fraction of the training samples. LIME results show that the contrastive learning approach helps boost both positive and negative features which are legally informative and contribute to the classification results. Thus a model finetuned with a contrastive objective seems to base its decisions more confidently on legally informative features.","sentences":["In this study, we analyze data-scarce classification scenarios, where available labeled legal data is small and imbalanced, potentially hurting the quality of the results.","We focused on two finetuning objectives; SetFit (Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla finetuning setup on a legal provision classification task.","Additionally, we compare the features that are extracted with LIME (Local Interpretable Model-agnostic Explanations) to see which particular features contributed to the model's classification decisions.","The results show that a contrastive setup with SetFit performed better than vanilla finetuning while using a fraction of the training samples.","LIME results show that the contrastive learning approach helps boost both positive and negative features which are legally informative and contribute to the classification results.","Thus a model finetuned with a contrastive objective seems to base its decisions more confidently on legally informative features."],"url":"http://arxiv.org/abs/2307.02882v1"}
{"created":"2023-07-06 09:36:45","title":"Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications","abstract":"This paper begins with a description of methods for estimating probability density functions for images that reflects the observation that such data is usually constrained to lie in restricted regions of the high-dimensional image space - not every pattern of pixels is an image. It is common to say that images lie on a lower-dimensional manifold in the high-dimensional space. However, although images may lie on such lower-dimensional manifolds, it is not the case that all points on the manifold have an equal probability of being images. Images are unevenly distributed on the manifold, and our task is to devise ways to model this distribution as a probability distribution. In pursuing this goal, we consider generative models that are popular in AI and computer vision community. For our purposes, generative/probabilistic models should have the properties of 1) sample generation: it should be possible to sample from this distribution according to the modelled density function, and 2) probability computation: given a previously unseen sample from the dataset of interest, one should be able to compute the probability of the sample, at least up to a normalising constant. To this end, we investigate the use of methods such as normalising flow and diffusion models. We then show that such probabilistic descriptions can be used to construct defences against adversarial attacks. In addition to describing the manifold in terms of density, we also consider how semantic interpretations can be used to describe points on the manifold. To this end, we consider an emergent language framework which makes use of variational encoders to produce a disentangled representation of points that reside on a given manifold. Trajectories between points on a manifold can then be described in terms of evolving semantic descriptions.","sentences":["This paper begins with a description of methods for estimating probability density functions for images that reflects the observation that such data is usually constrained to lie in restricted regions of the high-dimensional image space - not every pattern of pixels is an image.","It is common to say that images lie on a lower-dimensional manifold in the high-dimensional space.","However, although images may lie on such lower-dimensional manifolds, it is not the case that all points on the manifold have an equal probability of being images.","Images are unevenly distributed on the manifold, and our task is to devise ways to model this distribution as a probability distribution.","In pursuing this goal, we consider generative models that are popular in AI and computer vision community.","For our purposes, generative/probabilistic models should have the properties of 1) sample generation: it should be possible to sample from this distribution according to the modelled density function, and 2) probability computation: given a previously unseen sample from the dataset of interest, one should be able to compute the probability of the sample, at least up to a normalising constant.","To this end, we investigate the use of methods such as normalising flow and diffusion models.","We then show that such probabilistic descriptions can be used to construct defences against adversarial attacks.","In addition to describing the manifold in terms of density, we also consider how semantic interpretations can be used to describe points on the manifold.","To this end, we consider an emergent language framework which makes use of variational encoders to produce a disentangled representation of points that reside on a given manifold.","Trajectories between points on a manifold can then be described in terms of evolving semantic descriptions."],"url":"http://arxiv.org/abs/2307.02881v1"}
{"created":"2023-07-06 09:33:36","title":"Algorithms for computing norms and characteristic polynomials on general Drinfeld modules","abstract":"We provide two families of algorithms to compute characteristic polynomials of endomorphisms and norms of isogenies of Drinfeld modules. Our algorithms work for Drinfeld modules of any rank, defined over any base curve. When the base curve is $\\mathbb P^1_{\\mathbb F_q}$, we do a thorough study of the complexity, demonstrating that our algorithms are, in many cases, the most asymptotically performant. The first family of algorithms relies on the correspondence between Drinfeld modules and Anderson motives, reducing the computation to linear algebra over a polynomial ring. The second family, available only for the Frobenius endomorphism, is based on a new formula expressing the characteristic polynomial of the Frobenius as a reduced norm in a central simple algebra.","sentences":["We provide two families of algorithms to compute characteristic polynomials of endomorphisms and norms of isogenies of Drinfeld modules.","Our algorithms work for Drinfeld modules of any rank, defined over any base curve.","When the base curve is $\\mathbb P^1_{\\mathbb F_q}$, we do a thorough study of the complexity, demonstrating that our algorithms are, in many cases, the most asymptotically performant.","The first family of algorithms relies on the correspondence between Drinfeld modules and Anderson motives, reducing the computation to linear algebra over a polynomial ring.","The second family, available only for the Frobenius endomorphism, is based on a new formula expressing the characteristic polynomial of the Frobenius as a reduced norm in a central simple algebra."],"url":"http://arxiv.org/abs/2307.02879v1"}
{"created":"2023-07-06 09:29:03","title":"Towards accurate instance segmentation in large-scale LiDAR point clouds","abstract":"Panoptic segmentation is the combination of semantic and instance segmentation: assign the points in a 3D point cloud to semantic categories and partition them into distinct object instances. It has many obvious applications for outdoor scene understanding, from city mapping to forest management. Existing methods struggle to segment nearby instances of the same semantic category, like adjacent pieces of street furniture or neighbouring trees, which limits their usability for inventory- or management-type applications that rely on object instances. This study explores the steps of the panoptic segmentation pipeline concerned with clustering points into object instances, with the goal to alleviate that bottleneck. We find that a carefully designed clustering strategy, which leverages multiple types of learned point embeddings, significantly improves instance segmentation. Experiments on the NPM3D urban mobile mapping dataset and the FOR-instance forest dataset demonstrate the effectiveness and versatility of the proposed strategy.","sentences":["Panoptic segmentation is the combination of semantic and instance segmentation: assign the points in a 3D point cloud to semantic categories and partition them into distinct object instances.","It has many obvious applications for outdoor scene understanding, from city mapping to forest management.","Existing methods struggle to segment nearby instances of the same semantic category, like adjacent pieces of street furniture or neighbouring trees, which limits their usability for inventory- or management-type applications that rely on object instances.","This study explores the steps of the panoptic segmentation pipeline concerned with clustering points into object instances, with the goal to alleviate that bottleneck.","We find that a carefully designed clustering strategy, which leverages multiple types of learned point embeddings, significantly improves instance segmentation.","Experiments on the NPM3D urban mobile mapping dataset and the FOR-instance forest dataset demonstrate the effectiveness and versatility of the proposed strategy."],"url":"http://arxiv.org/abs/2307.02877v1"}
{"created":"2023-07-06 09:24:55","title":"Reference-based Motion Blur Removal: Learning to Utilize Sharpness in the Reference Image","abstract":"Despite the recent advancement in the study of removing motion blur in an image, it is still hard to deal with strong blurs. While there are limits in removing blurs from a single image, it has more potential to use multiple images, e.g., using an additional image as a reference to deblur a blurry image. A typical setting is deburring an image using a nearby sharp image(s) in a video sequence, as in the studies of video deblurring. This paper proposes a better method to use the information present in a reference image. The method does not need a strong assumption on the reference image. We can utilize an alternative shot of the identical scene, just like in video deblurring, or we can even employ a distinct image from another scene. Our method first matches local patches of the target and reference images and then fuses their features to estimate a sharp image. We employ a patch-based feature matching strategy to solve the difficult problem of matching the blurry image with the sharp reference. Our method can be integrated into pre-existing networks designed for single image deblurring. The experimental results show the effectiveness of the proposed method.","sentences":["Despite the recent advancement in the study of removing motion blur in an image, it is still hard to deal with strong blurs.","While there are limits in removing blurs from a single image, it has more potential to use multiple images, e.g., using an additional image as a reference to deblur a blurry image.","A typical setting is deburring an image using a nearby sharp image(s) in a video sequence, as in the studies of video deblurring.","This paper proposes a better method to use the information present in a reference image.","The method does not need a strong assumption on the reference image.","We can utilize an alternative shot of the identical scene, just like in video deblurring, or we can even employ a distinct image from another scene.","Our method first matches local patches of the target and reference images and then fuses their features to estimate a sharp image.","We employ a patch-based feature matching strategy to solve the difficult problem of matching the blurry image with the sharp reference.","Our method can be integrated into pre-existing networks designed for single image deblurring.","The experimental results show the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2307.02875v1"}
{"created":"2023-07-06 09:19:03","title":"Computing Motion Plans for Assembling Particles with Global Control","abstract":"We investigate motion planning algorithms for the assembly of shapes in the \\emph{tilt model} in which unit-square tiles move in a grid world under the influence of uniform external forces and self-assemble according to certain rules. We provide several heuristics and experimental evaluation of their success rate, solution length, runtime, and memory consumption.","sentences":["We investigate motion planning algorithms for the assembly of shapes in the \\emph{tilt model} in which unit-square tiles move in a grid world under the influence of uniform external forces and self-assemble according to certain rules.","We provide several heuristics and experimental evaluation of their success rate, solution length, runtime, and memory consumption."],"url":"http://arxiv.org/abs/2307.02873v1"}
{"created":"2023-07-06 09:15:38","title":"Contrastive Label Disambiguation for Self-Supervised Terrain Traversability Learning in Off-Road Environments","abstract":"Discriminating the traversability of terrains is a crucial task for autonomous driving in off-road environments. However, it is challenging due to the diverse, ambiguous, and platform-specific nature of off-road traversability. In this paper, we propose a novel self-supervised terrain traversability learning framework, utilizing a contrastive label disambiguation mechanism. Firstly, weakly labeled training samples with pseudo labels are automatically generated by projecting actual driving experiences onto the terrain models constructed in real time. Subsequently, a prototype-based contrastive representation learning method is designed to learn distinguishable embeddings, facilitating the self-supervised updating of those pseudo labels. As the iterative interaction between representation learning and pseudo label updating, the ambiguities in those pseudo labels are gradually eliminated, enabling the learning of platform-specific and task-specific traversability without any human-provided annotations. Experimental results on the RELLIS-3D dataset and our Gobi Desert driving dataset demonstrate the effectiveness of the proposed method.","sentences":["Discriminating the traversability of terrains is a crucial task for autonomous driving in off-road environments.","However, it is challenging due to the diverse, ambiguous, and platform-specific nature of off-road traversability.","In this paper, we propose a novel self-supervised terrain traversability learning framework, utilizing a contrastive label disambiguation mechanism.","Firstly, weakly labeled training samples with pseudo labels are automatically generated by projecting actual driving experiences onto the terrain models constructed in real time.","Subsequently, a prototype-based contrastive representation learning method is designed to learn distinguishable embeddings, facilitating the self-supervised updating of those pseudo labels.","As the iterative interaction between representation learning and pseudo label updating, the ambiguities in those pseudo labels are gradually eliminated, enabling the learning of platform-specific and task-specific traversability without any human-provided annotations.","Experimental results on the RELLIS-3D dataset and our Gobi Desert driving dataset demonstrate the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2307.02871v1"}
{"created":"2023-07-06 09:12:13","title":"MomentDiff: Generative Video Moment Retrieval from Random to Real","abstract":"Video moment retrieval pursues an efficient and generalized solution to identify the specific temporal segments within an untrimmed video that correspond to a given language description. To achieve this goal, we provide a generative diffusion-based framework called MomentDiff, which simulates a typical human retrieval process from random browsing to gradual localization. Specifically, we first diffuse the real span to random noise, and learn to denoise the random noise to the original span with the guidance of similarity between text and video. This allows the model to learn a mapping from arbitrary random locations to real moments, enabling the ability to locate segments from random initialization. Once trained, MomentDiff could sample random temporal segments as initial guesses and iteratively refine them to generate an accurate temporal boundary. Different from discriminative works (e.g., based on learnable proposals or queries), MomentDiff with random initialized spans could resist the temporal location biases from datasets. To evaluate the influence of the temporal location biases, we propose two anti-bias datasets with location distribution shifts, named Charades-STA-Len and Charades-STA-Mom. The experimental results demonstrate that our efficient framework consistently outperforms state-of-the-art methods on three public benchmarks, and exhibits better generalization and robustness on the proposed anti-bias datasets. The code, model, and anti-bias evaluation datasets are available at https://github.com/IMCCretrieval/MomentDiff.","sentences":["Video moment retrieval pursues an efficient and generalized solution to identify the specific temporal segments within an untrimmed video that correspond to a given language description.","To achieve this goal, we provide a generative diffusion-based framework called MomentDiff, which simulates a typical human retrieval process from random browsing to gradual localization.","Specifically, we first diffuse the real span to random noise, and learn to denoise the random noise to the original span with the guidance of similarity between text and video.","This allows the model to learn a mapping from arbitrary random locations to real moments, enabling the ability to locate segments from random initialization.","Once trained, MomentDiff could sample random temporal segments as initial guesses and iteratively refine them to generate an accurate temporal boundary.","Different from discriminative works (e.g., based on learnable proposals or queries), MomentDiff with random initialized spans could resist the temporal location biases from datasets.","To evaluate the influence of the temporal location biases, we propose two anti-bias datasets with location distribution shifts, named Charades-STA-Len and Charades-STA-Mom.","The experimental results demonstrate that our efficient framework consistently outperforms state-of-the-art methods on three public benchmarks, and exhibits better generalization and robustness on the proposed anti-bias datasets.","The code, model, and anti-bias evaluation datasets are available at https://github.com/IMCCretrieval/MomentDiff."],"url":"http://arxiv.org/abs/2307.02869v1"}
{"created":"2023-07-06 09:08:20","title":"Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain","abstract":"Traditional automation technologies alone are not sufficient to enable driverless operation of trains (called Grade of Automation (GoA) 4) on non-restricted infrastructure. The required perception tasks are nowadays realized using Machine Learning (ML) and thus need to be developed and deployed reliably and efficiently. One important aspect to achieve this is to use an MLOps process for tackling improved reproducibility, traceability, collaboration, and continuous adaptation of a driverless operation to changing conditions. MLOps mixes ML application development and operation (Ops) and enables high frequency software releases and continuous innovation based on the feedback from operations. In this paper, we outline a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain. It integrates system engineering, safety assurance, and the ML life-cycle in a comprehensive workflow. We present the individual stages of the process and their interactions. Moreover, we describe relevant challenges to automate the different stages of the safe MLOps process.","sentences":["Traditional automation technologies alone are not sufficient to enable driverless operation of trains (called Grade of Automation (GoA) 4) on non-restricted infrastructure.","The required perception tasks are nowadays realized using Machine Learning (ML) and thus need to be developed and deployed reliably and efficiently.","One important aspect to achieve this is to use an MLOps process for tackling improved reproducibility, traceability, collaboration, and continuous adaptation of a driverless operation to changing conditions.","MLOps mixes ML application development and operation (Ops) and enables high frequency software releases and continuous innovation based on the feedback from operations.","In this paper, we outline a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain.","It integrates system engineering, safety assurance, and the ML life-cycle in a comprehensive workflow.","We present the individual stages of the process and their interactions.","Moreover, we describe relevant challenges to automate the different stages of the safe MLOps process."],"url":"http://arxiv.org/abs/2307.02867v1"}
{"created":"2023-07-06 09:04:58","title":"PLIERS: a Popularity-Based Recommender System for Content Dissemination in Online Social Networks","abstract":"In this paper, we propose a novel tag-based recommender system called PLIERS, which relies on the assumption that users are mainly interested in items and tags with similar popularity to those they already own. PLIERS is aimed at reaching a good tradeoff between algorithmic complexity and the level of personalization of recommended items. To evaluate PLIERS, we performed a set of experiments on real OSN datasets, demonstrating that it outperforms state-of-the-art solutions in terms of personalization, relevance, and novelty of recommendations.","sentences":["In this paper, we propose a novel tag-based recommender system called PLIERS, which relies on the assumption that users are mainly interested in items and tags with similar popularity to those they already own.","PLIERS is aimed at reaching a good tradeoff between algorithmic complexity and the level of personalization of recommended items.","To evaluate PLIERS, we performed a set of experiments on real OSN datasets, demonstrating that it outperforms state-of-the-art solutions in terms of personalization, relevance, and novelty of recommendations."],"url":"http://arxiv.org/abs/2307.02865v1"}
{"created":"2023-07-06 09:03:10","title":"ValiTex -- a uniform validation framework for computational text-based measures of social science constructs","abstract":"Guidance on how to validate computational text-based measures of social science constructs is fragmented. Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components, a conceptual model, and a dynamic checklist. Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing additional supporting validation evidence. The utility of the framework is demonstrated by applying it to a use case of detecting sexism from social media data.","sentences":["Guidance on how to validate computational text-based measures of social science constructs is fragmented.","Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so.","This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data.","The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis.","ValiTex consists of two components, a conceptual model, and a dynamic checklist.","Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing additional supporting validation evidence.","The utility of the framework is demonstrated by applying it to a use case of detecting sexism from social media data."],"url":"http://arxiv.org/abs/2307.02863v1"}
{"created":"2023-07-06 08:57:53","title":"A Critical Look at the Current Usage of Foundation Model for Dense Recognition Task","abstract":"In recent years large model trained on huge amount of cross-modality data, which is usually be termed as foundation model, achieves conspicuous accomplishment in many fields, such as image recognition and generation. Though achieving great success in their original application case, it is still unclear whether those foundation models can be applied to other different downstream tasks. In this paper, we conduct a short survey on the current methods for discriminative dense recognition tasks, which are built on the pretrained foundation model. And we also provide some preliminary experimental analysis of an existing open-vocabulary segmentation method based on Stable Diffusion, which indicates the current way of deploying diffusion model for segmentation is not optimal. This aims to provide insights for future research on adopting foundation model for downstream task.","sentences":["In recent years large model trained on huge amount of cross-modality data, which is usually be termed as foundation model, achieves conspicuous accomplishment in many fields, such as image recognition and generation.","Though achieving great success in their original application case, it is still unclear whether those foundation models can be applied to other different downstream tasks.","In this paper, we conduct a short survey on the current methods for discriminative dense recognition tasks, which are built on the pretrained foundation model.","And we also provide some preliminary experimental analysis of an existing open-vocabulary segmentation method based on Stable Diffusion, which indicates the current way of deploying diffusion model for segmentation is not optimal.","This aims to provide insights for future research on adopting foundation model for downstream task."],"url":"http://arxiv.org/abs/2307.02862v1"}
{"created":"2023-07-06 08:52:28","title":"Scaling Package Queries to a Billion Tuples via Hierarchical Partitioning and Customized Optimization","abstract":"A package query returns a package -- a multiset of tuples -- that maximizes or minimizes a linear objective function subject to linear constraints, thereby enabling in-database decision support. Prior work has established the equivalence of package queries to Integer Linear Programs (ILPs) and developed the SketchRefine algorithm for package query processing. While this algorithm was an important first step toward supporting prescriptive analytics scalably inside a relational database, it struggles when the data size grows beyond a few hundred million tuples or when the constraints become very tight. In this paper, we present Progressive Shading, a novel algorithm for processing package queries that can scale efficiently to billions of tuples and gracefully handle tight constraints. Progressive Shading solves a sequence of optimization problems over a hierarchy of relations, each resulting from an ever-finer partitioning of the original tuples into homogeneous groups until the original relation is obtained. This strategy avoids the premature discarding of high-quality tuples that can occur with SketchRefine. Our novel partitioning scheme, Dynamic Low Variance, can handle very large relations with multiple attributes and can dynamically adapt to both concentrated and spread-out sets of attribute values, provably outperforming traditional partitioning schemes such as KD-Tree. We further optimize our system by replacing our off-the-shelf optimization software with customized ILP and LP solvers, called Dual Reducer and Parallel Dual Simplex respectively, that are highly accurate and orders of magnitude faster.","sentences":["A package query returns a package -- a multiset of tuples -- that maximizes or minimizes a linear objective function subject to linear constraints, thereby enabling in-database decision support.","Prior work has established the equivalence of package queries to Integer Linear Programs (ILPs) and developed the SketchRefine algorithm for package query processing.","While this algorithm was an important first step toward supporting prescriptive analytics scalably inside a relational database, it struggles when the data size grows beyond a few hundred million tuples or when the constraints become very tight.","In this paper, we present Progressive Shading, a novel algorithm for processing package queries that can scale efficiently to billions of tuples and gracefully handle tight constraints.","Progressive Shading solves a sequence of optimization problems over a hierarchy of relations, each resulting from an ever-finer partitioning of the original tuples into homogeneous groups until the original relation is obtained.","This strategy avoids the premature discarding of high-quality tuples that can occur with SketchRefine.","Our novel partitioning scheme, Dynamic Low Variance, can handle very large relations with multiple attributes and can dynamically adapt to both concentrated and spread-out sets of attribute values, provably outperforming traditional partitioning schemes such as KD-Tree.","We further optimize our system by replacing our off-the-shelf optimization software with customized ILP and LP solvers, called Dual Reducer and Parallel Dual Simplex respectively, that are highly accurate and orders of magnitude faster."],"url":"http://arxiv.org/abs/2307.02860v1"}
{"created":"2023-07-06 08:50:29","title":"Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing","abstract":"Face presentation attacks, also known as spoofing attacks, pose a significant threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems. To prevent spoofing, several video-based methods have been presented in the literature that analyze facial motion in successive video frames. However, estimating the motion between adjacent frames is a challenging task and requires high computational cost. In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism. The proposed frame skipping is based on a uniform sampling approach where the original video is divided into fixed size video clips. In this way, every nth frame of the clip is selected to ensure that the temporal patterns can easily be perceived during the training of three different recurrent neural networks (RNNs). Motivated by the performance of each RNNs, a meta-model is developed to improve the overall recognition performance by combining the predictions of the individual RNNs. Extensive experiments were conducted on four datasets, and state-of-the-art performance is reported for MSU-MFSD (3.12\\%), Replay-Attack (11.19\\%), and OULU-NPU (12.23\\%) using half total error rate (HTER) in the most challenging cross-dataset test scenario.","sentences":["Face presentation attacks, also known as spoofing attacks, pose a significant threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems.","To prevent spoofing, several video-based methods have been presented in the literature that analyze facial motion in successive video frames.","However, estimating the motion between adjacent frames is a challenging task and requires high computational cost.","In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism.","The proposed frame skipping is based on a uniform sampling approach where the original video is divided into fixed size video clips.","In this way, every nth frame of the clip is selected to ensure that the temporal patterns can easily be perceived during the training of three different recurrent neural networks (RNNs).","Motivated by the performance of each RNNs, a meta-model is developed to improve the overall recognition performance by combining the predictions of the individual RNNs.","Extensive experiments were conducted on four datasets, and state-of-the-art performance is reported for MSU-MFSD (3.12\\%), Replay-Attack (11.19\\%), and OULU-NPU (12.23\\%) using half total error rate (HTER) in the most challenging cross-dataset test scenario."],"url":"http://arxiv.org/abs/2307.02858v1"}
{"created":"2023-07-06 08:46:16","title":"It's more than just money: The real-world harms from ransomware attacks","abstract":"As cyber-attacks continue to increase in frequency and sophistication, organisations must be better prepared to face the reality of an incident. Any organisational plan that intends to be successful at managing security risks must clearly understand the harm (i.e., negative impact) and the various parties affected in the aftermath of an attack. To this end, this article conducts a novel exploration into the multitude of real-world harms that can arise from cyber-attacks, with a particular focus on ransomware incidents given their current prominence. This exploration also leads to the proposal of a new, robust methodology for modelling harms from such incidents. We draw on publicly-available case data on high-profile ransomware incidents to examine the types of harm that emerge at various stages after a ransomware attack and how harms (e.g., an offline enterprise server) may trigger other negative, potentially more substantial impacts for stakeholders (e.g., the inability for a customer to access their social welfare benefits or bank account). Prominent findings from our analysis include the identification of a notable set of social/human harms beyond the business itself (and beyond the financial payment of a ransom) and a complex web of harms that emerge after attacks regardless of the industry sector. We also observed that deciphering the full extent and sequence of harms can be a challenging undertaking because of the lack of complete data available. This paper consequently argues for more transparency on ransomware harms, as it would lead to a better understanding of the realities of these incidents to the benefit of organisations and society more generally.","sentences":["As cyber-attacks continue to increase in frequency and sophistication, organisations must be better prepared to face the reality of an incident.","Any organisational plan that intends to be successful at managing security risks must clearly understand the harm (i.e., negative impact) and the various parties affected in the aftermath of an attack.","To this end, this article conducts a novel exploration into the multitude of real-world harms that can arise from cyber-attacks, with a particular focus on ransomware incidents given their current prominence.","This exploration also leads to the proposal of a new, robust methodology for modelling harms from such incidents.","We draw on publicly-available case data on high-profile ransomware incidents to examine the types of harm that emerge at various stages after a ransomware attack and how harms (e.g., an offline enterprise server) may trigger other negative, potentially more substantial impacts for stakeholders (e.g., the inability for a customer to access their social welfare benefits or bank account).","Prominent findings from our analysis include the identification of a notable set of social/human harms beyond the business itself (and beyond the financial payment of a ransom) and a complex web of harms that emerge after attacks regardless of the industry sector.","We also observed that deciphering the full extent and sequence of harms can be a challenging undertaking because of the lack of complete data available.","This paper consequently argues for more transparency on ransomware harms, as it would lead to a better understanding of the realities of these incidents to the benefit of organisations and society more generally."],"url":"http://arxiv.org/abs/2307.02855v1"}
{"created":"2023-07-06 08:36:08","title":"TDLE: 2-D LiDAR Exploration With Hierarchical Planning Using Regional Division","abstract":"Exploration systems are critical for enhancing the autonomy of robots. Due to the unpredictability of the future planning space, existing methods either adopt an inefficient greedy strategy or require a lot of resources to obtain a global solution. In this work, we address the challenge of obtaining global exploration routes with minimal computing resources. A hierarchical planning framework dynamically divides the planning space into subregions and arranges their orders to provide global guidance for exploration. Indicators that are compatible with the subregion order are used to choose specific exploration targets, thereby considering estimates of spatial structure and extending the planning space to unknown regions. Extensive simulations and field tests demonstrate the efficacy of our method in comparison to existing 2D LiDAR-based approaches. Our code has been made public for further investigation.","sentences":["Exploration systems are critical for enhancing the autonomy of robots.","Due to the unpredictability of the future planning space, existing methods either adopt an inefficient greedy strategy or require a lot of resources to obtain a global solution.","In this work, we address the challenge of obtaining global exploration routes with minimal computing resources.","A hierarchical planning framework dynamically divides the planning space into subregions and arranges their orders to provide global guidance for exploration.","Indicators that are compatible with the subregion order are used to choose specific exploration targets, thereby considering estimates of spatial structure and extending the planning space to unknown regions.","Extensive simulations and field tests demonstrate the efficacy of our method in comparison to existing 2D LiDAR-based approaches.","Our code has been made public for further investigation."],"url":"http://arxiv.org/abs/2307.02852v1"}
{"created":"2023-07-06 08:32:38","title":"Resist the Hype! Practical Recommendations to Cope With R\u00e9sum\u00e9-Driven Development","abstract":"Technology trends play an important role in the hiring process for software and IT professionals. In a recent study of 591 software professionals in both hiring (130) and technical (558) roles, we found empirical support for a tendency to overemphasize technology trends in r\\'esum\\'es and the application process. 60% of the hiring professionals agreed that such trends would influence their job advertisements. Among the software professionals, 82% believed that using trending technologies in their daily work would make them more attractive for potential future employers. This phenomenon has previously been reported anecdotally and somewhat humorously under the label R\\'esum\\'e-Driven Development (RDD). Our article seeks to initiate a more serious debate about the consequences of RDD on software development practice. We explain how the phenomenon may constitute a harmful self-sustaining dynamic, and provide practical recommendations for both the hiring and applicant perspectives to change the current situation for the better.","sentences":["Technology trends play an important role in the hiring process for software and IT professionals.","In a recent study of 591 software professionals in both hiring (130) and technical (558) roles, we found empirical support for a tendency to overemphasize technology trends in r\\'esum\\'es and the application process.","60% of the hiring professionals agreed that such trends would influence their job advertisements.","Among the software professionals, 82% believed that using trending technologies in their daily work would make them more attractive for potential future employers.","This phenomenon has previously been reported anecdotally and somewhat humorously under the label R\\'esum\\'e-Driven Development (RDD).","Our article seeks to initiate a more serious debate about the consequences of RDD on software development practice.","We explain how the phenomenon may constitute a harmful self-sustaining dynamic, and provide practical recommendations for both the hiring and applicant perspectives to change the current situation for the better."],"url":"http://arxiv.org/abs/2307.02850v1"}
{"created":"2023-07-06 08:32:14","title":"NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic","abstract":"Reasoning has been a central topic in artificial intelligence from the beginning. The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference. However, it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations. Adversarial attacks have proven to be an important tool to help evaluate the Achilles' heel of the victim models. In this study, we explore the fundamental problem of developing attack models based on logic formalism. We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle's syllogism and has been closely developed for natural language inference. The proposed framework renders both label-preserving and label-flipping attacks. We show that compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models. The victim models are found to be more vulnerable under the label-flipping setting. NatLogAttack provides a tool to probe the existing and future NLI models' capacity from a key viewpoint and we hope more logic-based attacks will be further explored for understanding the desired property of reasoning.","sentences":["Reasoning has been a central topic in artificial intelligence from the beginning.","The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference.","However, it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations.","Adversarial attacks have proven to be an important tool to help evaluate the Achilles' heel of the victim models.","In this study, we explore the fundamental problem of developing attack models based on logic formalism.","We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle's syllogism and has been closely developed for natural language inference.","The proposed framework renders both label-preserving and label-flipping attacks.","We show that compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models.","The victim models are found to be more vulnerable under the label-flipping setting.","NatLogAttack provides a tool to probe the existing and future NLI models' capacity from a key viewpoint and we hope more logic-based attacks will be further explored for understanding the desired property of reasoning."],"url":"http://arxiv.org/abs/2307.02849v1"}
{"created":"2023-07-06 08:27:48","title":"Revisiting Computer-Aided Tuberculosis Diagnosis","abstract":"Tuberculosis (TB) is a major global health threat, causing millions of deaths annually. Although early diagnosis and treatment can greatly improve the chances of survival, it remains a major challenge, especially in developing countries. Recently, computer-aided tuberculosis diagnosis (CTD) using deep learning has shown promise, but progress is hindered by limited training data. To address this, we establish a large-scale dataset, namely the Tuberculosis X-ray (TBX11K) dataset, which contains 11,200 chest X-ray (CXR) images with corresponding bounding box annotations for TB areas. This dataset enables the training of sophisticated detectors for high-quality CTD. Furthermore, we propose a strong baseline, SymFormer, for simultaneous CXR image classification and TB infection area detection. SymFormer incorporates Symmetric Search Attention (SymAttention) to tackle the bilateral symmetry property of CXR images for learning discriminative features. Since CXR images may not strictly adhere to the bilateral symmetry property, we also propose Symmetric Positional Encoding (SPE) to facilitate SymAttention through feature recalibration. To promote future research on CTD, we build a benchmark by introducing evaluation metrics, evaluating baseline models reformed from existing detectors, and running an online challenge. Experiments show that SymFormer achieves state-of-the-art performance on the TBX11K dataset. The data, code, and models will be released.","sentences":["Tuberculosis (TB) is a major global health threat, causing millions of deaths annually.","Although early diagnosis and treatment can greatly improve the chances of survival, it remains a major challenge, especially in developing countries.","Recently, computer-aided tuberculosis diagnosis (CTD) using deep learning has shown promise, but progress is hindered by limited training data.","To address this, we establish a large-scale dataset, namely the Tuberculosis X-ray (TBX11K) dataset, which contains 11,200 chest X-ray (CXR) images with corresponding bounding box annotations for TB areas.","This dataset enables the training of sophisticated detectors for high-quality CTD.","Furthermore, we propose a strong baseline, SymFormer, for simultaneous CXR image classification and TB infection area detection.","SymFormer incorporates Symmetric Search Attention (SymAttention) to tackle the bilateral symmetry property of CXR images for learning discriminative features.","Since CXR images may not strictly adhere to the bilateral symmetry property, we also propose Symmetric Positional Encoding (SPE) to facilitate SymAttention through feature recalibration.","To promote future research on CTD, we build a benchmark by introducing evaluation metrics, evaluating baseline models reformed from existing detectors, and running an online challenge.","Experiments show that SymFormer achieves state-of-the-art performance on the TBX11K dataset.","The data, code, and models will be released."],"url":"http://arxiv.org/abs/2307.02848v1"}
{"created":"2023-07-06 08:26:31","title":"Towards Efficient Control Flow Handling in Spatial Architecture via Architecting the Control Flow Plane","abstract":"Spatial architecture is a high-performance architecture that uses control flow graphs and data flow graphs as the computational model and producer/consumer models as the execution models. However, existing spatial architectures suffer from control flow handling challenges. Upon categorizing their PE execution models, we find that they lack autonomous, peer-to-peer, and temporally loosely-coupled control flow handling capability. This leads to limited performance in intensive control programs.   A spatial architecture, Marionette, is proposed, with an explicit-designed control flow plane. The Control Flow Plane enables autonomous, peer-to-peer and temporally loosely-coupled control flow handling. The Proactive PE Configuration ensures timely and computation-overlapped configuration to improve handling Branch Divergence. The Agile PE Assignment enhance the pipeline performance of Imperfect Loops. We develop full stack of Marionette (ISA, compiler, simulator, RTL) and demonstrate that in a variety of challenging intensive control programs, compared to state-of-the-art spatial architectures, Marionette outperforms Softbrain, TIA, REVEL, and RipTide by geomean 2.88x, 3.38x, 1.55x, and 2.66x.","sentences":["Spatial architecture is a high-performance architecture that uses control flow graphs and data flow graphs as the computational model and producer/consumer models as the execution models.","However, existing spatial architectures suffer from control flow handling challenges.","Upon categorizing their PE execution models, we find that they lack autonomous, peer-to-peer, and temporally loosely-coupled control flow handling capability.","This leads to limited performance in intensive control programs.   ","A spatial architecture, Marionette, is proposed, with an explicit-designed control flow plane.","The Control Flow Plane enables autonomous, peer-to-peer and temporally loosely-coupled control flow handling.","The Proactive PE Configuration ensures timely and computation-overlapped configuration to improve handling Branch Divergence.","The Agile PE Assignment enhance the pipeline performance of Imperfect Loops.","We develop full stack of Marionette (ISA, compiler, simulator, RTL) and demonstrate that in a variety of challenging intensive control programs, compared to state-of-the-art spatial architectures, Marionette outperforms Softbrain, TIA, REVEL, and RipTide by geomean 2.88x, 3.38x, 1.55x, and 2.66x."],"url":"http://arxiv.org/abs/2307.02847v1"}
{"created":"2023-07-06 08:14:54","title":"Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation","abstract":"Risk-sensitive reinforcement learning (RL) aims to optimize policies that balance the expected reward and risk. In this paper, we investigate a novel risk-sensitive RL formulation with an Iterated Conditional Value-at-Risk (CVaR) objective under linear and general function approximations. This new formulation, named ICVaR-RL with function approximation, provides a principled way to guarantee safety at each decision step. For ICVaR-RL with linear function approximation, we propose a computationally efficient algorithm ICVaR-L, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}(d^2H^4+dH^6)K})$ regret, where $\\alpha$ is the risk level, $d$ is the dimension of state-action features, $H$ is the length of each episode, and $K$ is the number of episodes. We also establish a matching lower bound $\\Omega(\\sqrt{\\alpha^{-(H-1)}d^2K})$ to validate the optimality of ICVaR-L with respect to $d$ and $K$. For ICVaR-RL with general function approximation, we propose algorithm ICVaR-G, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}DH^4K})$ regret, where $D$ is a dimensional parameter that depends on the eluder dimension and covering number. Furthermore, our analysis provides several novel techniques for risk-sensitive RL, including an efficient approximation of the CVaR operator, a new ridge regression with CVaR-adapted features, and a refined elliptical potential lemma.","sentences":["Risk-sensitive reinforcement learning (RL) aims to optimize policies that balance the expected reward and risk.","In this paper, we investigate a novel risk-sensitive RL formulation with an Iterated Conditional Value-at-Risk (CVaR) objective under linear and general function approximations.","This new formulation, named ICVaR-RL with function approximation, provides a principled way to guarantee safety at each decision step.","For ICVaR-RL with linear function approximation, we propose a computationally efficient algorithm ICVaR-L, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}(d^2H^4+dH^6)K})$ regret, where $\\alpha$ is the risk level, $d$ is the dimension of state-action features, $H$ is the length of each episode, and $K$ is the number of episodes.","We also establish a matching lower bound $\\Omega(\\sqrt{\\alpha^{-(H-1)}d^2K})$ to validate the optimality of ICVaR-L with respect to $d$ and $K$. For ICVaR-RL with general function approximation, we propose algorithm ICVaR-G, which achieves an $\\widetilde{O}(\\sqrt{\\alpha^{-(H+1)}DH^4K})$ regret, where $D$ is a dimensional parameter that depends on the eluder dimension and covering number.","Furthermore, our analysis provides several novel techniques for risk-sensitive RL, including an efficient approximation of the CVaR operator, a new ridge regression with CVaR-adapted features, and a refined elliptical potential lemma."],"url":"http://arxiv.org/abs/2307.02842v1"}
{"created":"2023-07-06 08:13:53","title":"Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation","abstract":"News summary generation is an important task in the field of intelligence analysis, which can provide accurate and comprehensive information to help people better understand and respond to complex real-world events. However, traditional news summary generation methods face some challenges, which are limited by the model itself and the amount of training data, as well as the influence of text noise, making it difficult to generate reliable information accurately. In this paper, we propose a new paradigm for news summary generation using LLM with powerful natural language understanding and generative capabilities. We use LLM to extract multiple structured event patterns from the events contained in news paragraphs, evolve the event pattern population with genetic algorithm, and select the most adaptive event pattern to input into the LLM to generate news summaries. A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate news summaries. The experimental results show that the news summary generator is able to generate accurate and reliable news summaries with some generalization ability.","sentences":["News summary generation is an important task in the field of intelligence analysis, which can provide accurate and comprehensive information to help people better understand and respond to complex real-world events.","However, traditional news summary generation methods face some challenges, which are limited by the model itself and the amount of training data, as well as the influence of text noise, making it difficult to generate reliable information accurately.","In this paper, we propose a new paradigm for news summary generation using LLM with powerful natural language understanding and generative capabilities.","We use LLM to extract multiple structured event patterns from the events contained in news paragraphs, evolve the event pattern population with genetic algorithm, and select the most adaptive event pattern to input into the LLM to generate news summaries.","A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate news summaries.","The experimental results show that the news summary generator is able to generate accurate and reliable news summaries with some generalization ability."],"url":"http://arxiv.org/abs/2307.02839v1"}
{"created":"2023-07-06 08:06:48","title":"Noise-to-Norm Reconstruction for Industrial Anomaly Detection and Localization","abstract":"Anomaly detection has a wide range of applications and is especially important in industrial quality inspection. Currently, many top-performing anomaly-detection models rely on feature-embedding methods. However, these methods do not perform well on datasets with large variations in object locations. Reconstruction-based methods use reconstruction errors to detect anomalies without considering positional differences between samples. In this study, a reconstruction-based method using the noise-to-norm paradigm is proposed, which avoids the invariant reconstruction of anomalous regions. Our reconstruction network is based on M-net and incorporates multiscale fusion and residual attention modules to enable end-to-end anomaly detection and localization. Experiments demonstrate that the method is effective in reconstructing anomalous regions into normal patterns and achieving accurate anomaly detection and localization. On the MPDD and VisA datasets, our proposed method achieved more competitive results than the latest methods, and it set a new state-of-the-art standard on the MPDD dataset.","sentences":["Anomaly detection has a wide range of applications and is especially important in industrial quality inspection.","Currently, many top-performing anomaly-detection models rely on feature-embedding methods.","However, these methods do not perform well on datasets with large variations in object locations.","Reconstruction-based methods use reconstruction errors to detect anomalies without considering positional differences between samples.","In this study, a reconstruction-based method using the noise-to-norm paradigm is proposed, which avoids the invariant reconstruction of anomalous regions.","Our reconstruction network is based on M-net and incorporates multiscale fusion and residual attention modules to enable end-to-end anomaly detection and localization.","Experiments demonstrate that the method is effective in reconstructing anomalous regions into normal patterns and achieving accurate anomaly detection and localization.","On the MPDD and VisA datasets, our proposed method achieved more competitive results than the latest methods, and it set a new state-of-the-art standard on the MPDD dataset."],"url":"http://arxiv.org/abs/2307.02836v1"}
{"created":"2023-07-06 08:02:56","title":"Applying Process Mining on Scientific Workflows: a Case Study","abstract":"Computer-based scientific experiments are becoming increasingly data-intensive. High-Performance Computing (HPC) clusters are ideal for executing large scientific experiment workflows. Executing large scientific workflows in an HPC cluster leads to complex flows of data and control within the system, which are difficult to analyze. This paper presents a case study where process mining is applied to logs extracted from SLURM-based HPC clusters, in order to document the running workflows and find the performance bottlenecks. The challenge lies in correlating the jobs recorded in the system to enable the application of mainstream process mining techniques. Users may submit jobs with explicit or implicit interdependencies, leading to the consideration of different event correlation techniques. We present a log extraction technique from SLURM clusters, completed with an experimental.","sentences":["Computer-based scientific experiments are becoming increasingly data-intensive.","High-Performance Computing (HPC) clusters are ideal for executing large scientific experiment workflows.","Executing large scientific workflows in an HPC cluster leads to complex flows of data and control within the system, which are difficult to analyze.","This paper presents a case study where process mining is applied to logs extracted from SLURM-based HPC clusters, in order to document the running workflows and find the performance bottlenecks.","The challenge lies in correlating the jobs recorded in the system to enable the application of mainstream process mining techniques.","Users may submit jobs with explicit or implicit interdependencies, leading to the consideration of different event correlation techniques.","We present a log extraction technique from SLURM clusters, completed with an experimental."],"url":"http://arxiv.org/abs/2307.02833v1"}
{"created":"2023-07-06 07:53:46","title":"Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting","abstract":"Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness. In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work. Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt-tuning strategy to boost higher performance by only training fewer prompt parameters. Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots.","sentences":["Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain.","Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness.","In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work.","Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt-tuning strategy to boost higher performance by only training fewer prompt parameters.","Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots."],"url":"http://arxiv.org/abs/2307.02830v1"}
{"created":"2023-07-06 07:52:50","title":"Policy Contrastive Imitation Learning","abstract":"Adversarial imitation learning (AIL) is a popular method that has recently achieved much success. However, the performance of AIL is still unsatisfactory on the more challenging tasks. We find that one of the major reasons is due to the low quality of AIL discriminator representation. Since the AIL discriminator is trained via binary classification that does not necessarily discriminate the policy from the expert in a meaningful way, the resulting reward might not be meaningful either. We propose a new method called Policy Contrastive Imitation Learning (PCIL) to resolve this issue. PCIL learns a contrastive representation space by anchoring on different policies and generates a smooth cosine-similarity-based reward. Our proposed representation learning objective can be viewed as a stronger version of the AIL objective and provide a more meaningful comparison between the agent and the policy. From a theoretical perspective, we show the validity of our method using the apprenticeship learning framework. Furthermore, our empirical evaluation on the DeepMind Control suite demonstrates that PCIL can achieve state-of-the-art performance. Finally, qualitative results suggest that PCIL builds a smoother and more meaningful representation space for imitation learning.","sentences":["Adversarial imitation learning (AIL) is a popular method that has recently achieved much success.","However, the performance of AIL is still unsatisfactory on the more challenging tasks.","We find that one of the major reasons is due to the low quality of AIL discriminator representation.","Since the AIL discriminator is trained via binary classification that does not necessarily discriminate the policy from the expert in a meaningful way, the resulting reward might not be meaningful either.","We propose a new method called Policy Contrastive Imitation Learning (PCIL) to resolve this issue.","PCIL learns a contrastive representation space by anchoring on different policies and generates a smooth cosine-similarity-based reward.","Our proposed representation learning objective can be viewed as a stronger version of the AIL objective and provide a more meaningful comparison between the agent and the policy.","From a theoretical perspective, we show the validity of our method using the apprenticeship learning framework.","Furthermore, our empirical evaluation on the DeepMind Control suite demonstrates that PCIL can achieve state-of-the-art performance.","Finally, qualitative results suggest that PCIL builds a smoother and more meaningful representation space for imitation learning."],"url":"http://arxiv.org/abs/2307.02829v1"}
{"created":"2023-07-06 07:52:42","title":"Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks","abstract":"Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input. After achieving nearly 100% attack success rates in white-box setting, more focus is shifted to black-box attacks, of which the transferability of adversarial examples has gained significant attention. In either case, the common gradient-based methods generally use the sign function to generate perturbations on the gradient update, that offers a roughly correct direction and has gained great success. But little work pays attention to its possible limitation. In this work, we observe that the deviation between the original gradient and the generated noise may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability. To this end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM). Specifically, we use data rescaling to substitute the sign function without extra computational cost. We further propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update. Our method could be used in any gradient-based attacks and is extensible to be integrated with various input transformation or ensemble methods to further improve the adversarial transferability. Extensive experiments on the standard ImageNet dataset show that our method could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines.","sentences":["Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input.","After achieving nearly 100% attack success rates in white-box setting, more focus is shifted to black-box attacks, of which the transferability of adversarial examples has gained significant attention.","In either case, the common gradient-based methods generally use the sign function to generate perturbations on the gradient update, that offers a roughly correct direction and has gained great success.","But little work pays attention to its possible limitation.","In this work, we observe that the deviation between the original gradient and the generated noise may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability.","To this end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM).","Specifically, we use data rescaling to substitute the sign function without extra computational cost.","We further propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update.","Our method could be used in any gradient-based attacks and is extensible to be integrated with various input transformation or ensemble methods to further improve the adversarial transferability.","Extensive experiments on the standard ImageNet dataset show that our method could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines."],"url":"http://arxiv.org/abs/2307.02828v1"}
{"created":"2023-07-06 07:50:47","title":"Cell-Free XL-MIMO Meets Multi-Agent Reinforcement Learning: Architectures, Challenges, and Future Directions","abstract":"Cell-free massive multiple-input multiple-output (mMIMO) and extremely large-scale MIMO (XL-MIMO) are regarded as promising innovations for the forthcoming generation of wireless communication systems. Their significant advantages in augmenting the number of degrees of freedom have garnered considerable interest. In this article, we first review the essential opportunities and challenges induced by XL-MIMO systems. We then propose the enhanced paradigm of cell-free XL-MIMO, which incorporates multi-agent reinforcement learning (MARL) to provide a distributed strategy for tackling the problem of high-dimension signal processing and costly energy consumption. Based on the unique near-field characteristics, we propose two categories of the low-complexity design, i.e., antenna selection and power control, to adapt to different cell-free XL-MIMO scenarios and achieve the maximum data rate. For inspiration, several critical future research directions pertaining to green cell-free XL-MIMO systems are presented.","sentences":["Cell-free massive multiple-input multiple-output (mMIMO) and extremely large-scale MIMO (XL-MIMO) are regarded as promising innovations for the forthcoming generation of wireless communication systems.","Their significant advantages in augmenting the number of degrees of freedom have garnered considerable interest.","In this article, we first review the essential opportunities and challenges induced by XL-MIMO systems.","We then propose the enhanced paradigm of cell-free XL-MIMO, which incorporates multi-agent reinforcement learning (MARL) to provide a distributed strategy for tackling the problem of high-dimension signal processing and costly energy consumption.","Based on the unique near-field characteristics, we propose two categories of the low-complexity design, i.e., antenna selection and power control, to adapt to different cell-free XL-MIMO scenarios and achieve the maximum data rate.","For inspiration, several critical future research directions pertaining to green cell-free XL-MIMO systems are presented."],"url":"http://arxiv.org/abs/2307.02827v1"}
{"created":"2023-07-06 07:45:31","title":"Bundle-specific Tractogram Distribution Estimation Using Higher-order Streamline Differential Equation","abstract":"Tractography traces the peak directions extracted from fiber orientation distribution (FOD) suffering from ambiguous spatial correspondences between diffusion directions and fiber geometry, which is prone to producing erroneous tracks while missing true positive connections. The peaks-based tractography methods 'locally' reconstructed streamlines in 'single to single' manner, thus lacking of global information about the trend of the whole fiber bundle. In this work, we propose a novel tractography method based on a bundle-specific tractogram distribution function by using a higher-order streamline differential equation, which reconstructs the streamline bundles in 'cluster to cluster' manner. A unified framework for any higher-order streamline differential equation is presented to describe the fiber bundles with disjoint streamlines defined based on the diffusion tensor vector field. At the global level, the tractography process is simplified as the estimation of bundle-specific tractogram distribution (BTD) coefficients by minimizing the energy optimization model, and is used to characterize the relations between BTD and diffusion tensor vector under the prior guidance by introducing the tractogram bundle information to provide anatomic priors. Experiments are performed on simulated Hough, Sine, Circle data, ISMRM 2015 Tractography Challenge data, FiberCup data, and in vivo data from the Human Connectome Project (HCP) data for qualitative and quantitative evaluation. The results demonstrate that our approach can reconstruct the complex global fiber bundles directly. BTD reduces the error deviation and accumulation at the local level and shows better results in reconstructing long-range, twisting, and large fanning tracts.","sentences":["Tractography traces the peak directions extracted from fiber orientation distribution (FOD) suffering from ambiguous spatial correspondences between diffusion directions and fiber geometry, which is prone to producing erroneous tracks while missing true positive connections.","The peaks-based tractography methods 'locally' reconstructed streamlines in 'single to single' manner, thus lacking of global information about the trend of the whole fiber bundle.","In this work, we propose a novel tractography method based on a bundle-specific tractogram distribution function by using a higher-order streamline differential equation, which reconstructs the streamline bundles in 'cluster to cluster' manner.","A unified framework for any higher-order streamline differential equation is presented to describe the fiber bundles with disjoint streamlines defined based on the diffusion tensor vector field.","At the global level, the tractography process is simplified as the estimation of bundle-specific tractogram distribution (BTD) coefficients by minimizing the energy optimization model, and is used to characterize the relations between BTD and diffusion tensor vector under the prior guidance by introducing the tractogram bundle information to provide anatomic priors.","Experiments are performed on simulated Hough, Sine, Circle data, ISMRM 2015 Tractography Challenge data, FiberCup data, and in vivo data from the Human Connectome Project (HCP) data for qualitative and quantitative evaluation.","The results demonstrate that our approach can reconstruct the complex global fiber bundles directly.","BTD reduces the error deviation and accumulation at the local level and shows better results in reconstructing long-range, twisting, and large fanning tracts."],"url":"http://arxiv.org/abs/2307.02825v1"}
{"created":"2023-07-06 07:27:59","title":"Evaluating raw waveforms with deep learning frameworks for speech emotion recognition","abstract":"Speech emotion recognition is a challenging task in speech processing field. For this reason, feature extraction process has a crucial importance to demonstrate and process the speech signals. In this work, we represent a model, which feeds raw audio files directly into the deep neural networks without any feature extraction stage for the recognition of emotions utilizing six different data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To demonstrate the contribution of proposed model, the performance of traditional feature extraction techniques namely, mel-scale spectogram, mel-frequency cepstral coefficients, are blended with machine learning algorithms, ensemble learning methods, deep and hybrid deep learning techniques. Support vector machine, decision tree, naive Bayes, random forests models are evaluated as machine learning algorithms while majority voting and stacking methods are assessed as ensemble learning techniques. Moreover, convolutional neural networks, long short-term memory networks, and hybrid CNN- LSTM model are evaluated as deep learning techniques and compared with machine learning and ensemble learning methods. To demonstrate the effectiveness of proposed model, the comparison with state-of-the-art studies are carried out. Based on the experiment results, CNN model excels existent approaches with 95.86% of accuracy for TESS+RAVDESS data set using raw audio files, thence determining the new state-of-the-art. The proposed model performs 90.34% of accuracy for EMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of accuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model, 85.76% of accuracy for SAVEE with CNN model in speaker-independent audio categorization problems.","sentences":["Speech emotion recognition is a challenging task in speech processing field.","For this reason, feature extraction process has a crucial importance to demonstrate and process the speech signals.","In this work, we represent a model, which feeds raw audio files directly into the deep neural networks without any feature extraction stage for the recognition of emotions utilizing six different data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS.","To demonstrate the contribution of proposed model, the performance of traditional feature extraction techniques namely, mel-scale spectogram, mel-frequency cepstral coefficients, are blended with machine learning algorithms, ensemble learning methods, deep and hybrid deep learning techniques.","Support vector machine, decision tree, naive Bayes, random forests models are evaluated as machine learning algorithms while majority voting and stacking methods are assessed as ensemble learning techniques.","Moreover, convolutional neural networks, long short-term memory networks, and hybrid CNN- LSTM model are evaluated as deep learning techniques and compared with machine learning and ensemble learning methods.","To demonstrate the effectiveness of proposed model, the comparison with state-of-the-art studies are carried out.","Based on the experiment results, CNN model excels existent approaches with 95.86% of accuracy for TESS+RAVDESS data set using raw audio files, thence determining the new state-of-the-art.","The proposed model performs 90.34% of accuracy for EMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of accuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model, 85.76% of accuracy for SAVEE with CNN model in speaker-independent audio categorization problems."],"url":"http://arxiv.org/abs/2307.02820v1"}
{"created":"2023-07-06 07:24:38","title":"Trends in Machine Learning and Electroencephalogram (EEG): A Review for Undergraduate Researchers","abstract":"This paper presents a systematic literature review on Brain-Computer Interfaces (BCIs) in the context of Machine Learning. Our focus is on Electroencephalography (EEG) research, highlighting the latest trends as of 2023. The objective is to provide undergraduate researchers with an accessible overview of the BCI field, covering tasks, algorithms, and datasets. By synthesizing recent findings, our aim is to offer a fundamental understanding of BCI research, identifying promising avenues for future investigations.","sentences":["This paper presents a systematic literature review on Brain-Computer Interfaces (BCIs) in the context of Machine Learning.","Our focus is on Electroencephalography (EEG) research, highlighting the latest trends as of 2023.","The objective is to provide undergraduate researchers with an accessible overview of the BCI field, covering tasks, algorithms, and datasets.","By synthesizing recent findings, our aim is to offer a fundamental understanding of BCI research, identifying promising avenues for future investigations."],"url":"http://arxiv.org/abs/2307.02819v1"}
{"created":"2023-07-06 07:22:09","title":"Exploiting Adjoints in Property Directed Reachability Analysis","abstract":"We formulate, in lattice-theoretic terms, two novel algorithms inspired by Bradley's property directed reachability algorithm. For finding safe invariants or counterexamples, the first algorithm exploits over-approximations of both forward and backward transition relations, expressed abstractly by the notion of adjoints. In the absence of adjoints, one can use the second algorithm, which exploits lower sets and their principals. As a notable example of application, we consider quantitative reachability problems for Markov Decision Processes.","sentences":["We formulate, in lattice-theoretic terms, two novel algorithms inspired by Bradley's property directed reachability algorithm.","For finding safe invariants or counterexamples, the first algorithm exploits over-approximations of both forward and backward transition relations, expressed abstractly by the notion of adjoints.","In the absence of adjoints, one can use the second algorithm, which exploits lower sets and their principals.","As a notable example of application, we consider quantitative reachability problems for Markov Decision Processes."],"url":"http://arxiv.org/abs/2307.02817v1"}
{"created":"2023-07-06 07:19:47","title":"Single Image LDR to HDR Conversion using Conditional Diffusion","abstract":"Digital imaging aims to replicate realistic scenes, but Low Dynamic Range (LDR) cameras cannot represent the wide dynamic range of real scenes, resulting in under-/overexposed images. This paper presents a deep learning-based approach for recovering intricate details from shadows and highlights while reconstructing High Dynamic Range (HDR) images. We formulate the problem as an image-to-image (I2I) translation task and propose a conditional Denoising Diffusion Probabilistic Model (DDPM) based framework using classifier-free guidance. We incorporate a deep CNN-based autoencoder in our proposed framework to enhance the quality of the latent representation of the input LDR image used for conditioning. Moreover, we introduce a new loss function for LDR-HDR translation tasks, termed Exposure Loss. This loss helps direct gradients in the opposite direction of the saturation, further improving the results' quality. By conducting comprehensive quantitative and qualitative experiments, we have effectively demonstrated the proficiency of our proposed method. The results indicate that a simple conditional diffusion-based method can replace the complex camera pipeline-based architectures.","sentences":["Digital imaging aims to replicate realistic scenes, but Low Dynamic Range (LDR) cameras cannot represent the wide dynamic range of real scenes, resulting in under-/overexposed images.","This paper presents a deep learning-based approach for recovering intricate details from shadows and highlights while reconstructing High Dynamic Range (HDR) images.","We formulate the problem as an image-to-image (I2I) translation task and propose a conditional Denoising Diffusion Probabilistic Model (DDPM) based framework using classifier-free guidance.","We incorporate a deep CNN-based autoencoder in our proposed framework to enhance the quality of the latent representation of the input LDR image used for conditioning.","Moreover, we introduce a new loss function for LDR-HDR translation tasks, termed Exposure Loss.","This loss helps direct gradients in the opposite direction of the saturation, further improving the results' quality.","By conducting comprehensive quantitative and qualitative experiments, we have effectively demonstrated the proficiency of our proposed method.","The results indicate that a simple conditional diffusion-based method can replace the complex camera pipeline-based architectures."],"url":"http://arxiv.org/abs/2307.02814v1"}
{"created":"2023-07-06 07:18:22","title":"CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural Networks","abstract":"Dynamic graph data mining has gained popularity in recent years due to the rich information contained in dynamic graphs and their widespread use in the real world. Despite the advances in dynamic graph neural networks (DGNNs), the rich information and diverse downstream tasks have posed significant difficulties for the practical application of DGNNs in industrial scenarios. To this end, in this paper, we propose to address them by pre-training and present the Contrastive Pre-Training Method for Dynamic Graph Neural Networks (CPDG). CPDG tackles the challenges of pre-training for DGNNs, including generalization and long-short term modeling capability, through a flexible structural-temporal subgraph sampler along with structural-temporal contrastive pre-training schemes. Extensive experiments conducted on both large-scale research and industrial dynamic graph datasets show that CPDG outperforms existing methods in dynamic graph pre-training for various downstream tasks under three transfer settings.","sentences":["Dynamic graph data mining has gained popularity in recent years due to the rich information contained in dynamic graphs and their widespread use in the real world.","Despite the advances in dynamic graph neural networks (DGNNs), the rich information and diverse downstream tasks have posed significant difficulties for the practical application of DGNNs in industrial scenarios.","To this end, in this paper, we propose to address them by pre-training and present the Contrastive Pre-Training Method for Dynamic Graph Neural Networks (CPDG).","CPDG tackles the challenges of pre-training for DGNNs, including generalization and long-short term modeling capability, through a flexible structural-temporal subgraph sampler along with structural-temporal contrastive pre-training schemes.","Extensive experiments conducted on both large-scale research and industrial dynamic graph datasets show that CPDG outperforms existing methods in dynamic graph pre-training for various downstream tasks under three transfer settings."],"url":"http://arxiv.org/abs/2307.02813v1"}
{"created":"2023-07-06 06:39:27","title":"OLR-WA Online Regression with Weighted Average","abstract":"Machine Learning requires a large amount of training data in order to build accurate models. Sometimes the data arrives over time, requiring significant storage space and recalculating the model to account for the new data. On-line learning addresses these issues by incrementally modifying the model as data is encountered, and then discarding the data. In this study we introduce a new online linear regression approach. Our approach combines newly arriving data with a previously existing model to create a new model. The introduced model, named OLR-WA (OnLine Regression with Weighted Average) uses user-defined weights to provide flexibility in the face of changing data to bias the results in favor of old or new data. We have conducted 2-D and 3-D experiments comparing OLR-WA to a static model using the entire data set. The results show that for consistent data, OLR-WA and the static batch model perform similarly and for varying data, the user can set the OLR-WA to adapt more quickly or to resist change.","sentences":["Machine Learning requires a large amount of training data in order to build accurate models.","Sometimes the data arrives over time, requiring significant storage space and recalculating the model to account for the new data.","On-line learning addresses these issues by incrementally modifying the model as data is encountered, and then discarding the data.","In this study we introduce a new online linear regression approach.","Our approach combines newly arriving data with a previously existing model to create a new model.","The introduced model, named OLR-WA (OnLine Regression with Weighted Average) uses user-defined weights to provide flexibility in the face of changing data to bias the results in favor of old or new data.","We have conducted 2-D and 3-D experiments comparing OLR-WA to a static model using the entire data set.","The results show that for consistent data, OLR-WA and the static batch model perform similarly and for varying data, the user can set the OLR-WA to adapt more quickly or to resist change."],"url":"http://arxiv.org/abs/2307.02804v1"}
{"created":"2023-07-06 06:31:07","title":"Age-of-Information Dependent Random Access for Periodic Updating","abstract":"This paper considers an uplink Internet of Things system with synchronous periodic traffic, where multiple devices generate their status updates at the beginning of each global frame and attempt to send them to a common access point. To achieve a low network-wide age of information (AoI) in an easily implementable manner, we require each device to adopt an age-dependent random access protocol, i.e., to transmit with a certain probability only when its corresponding AoI reaches a certain threshold. We analyze the time-average expected AoI by a multi-layer Markov model where an external infinite-horizon Markov chain manages the jumps between the beginnings of frames, while two internal finite-horizon Markov chains manage the evolution during an arbitrary frame for different cases. Simulation results verify the accuracy of the modeling and the AoI advantage over age-independent schemes.","sentences":["This paper considers an uplink Internet of Things system with synchronous periodic traffic, where multiple devices generate their status updates at the beginning of each global frame and attempt to send them to a common access point.","To achieve a low network-wide age of information (AoI) in an easily implementable manner, we require each device to adopt an age-dependent random access protocol, i.e., to transmit with a certain probability only when its corresponding AoI reaches a certain threshold.","We analyze the time-average expected AoI by a multi-layer Markov model where an external infinite-horizon Markov chain manages the jumps between the beginnings of frames, while two internal finite-horizon Markov chains manage the evolution during an arbitrary frame for different cases.","Simulation results verify the accuracy of the modeling and the AoI advantage over age-independent schemes."],"url":"http://arxiv.org/abs/2307.02801v1"}
{"created":"2023-07-06 06:13:22","title":"Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning","abstract":"Although unsupervised domain adaptation (UDA) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts. In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially. Specifically, we propose a two-stage training process. First, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (CL) along with a pixel-level feature consistency constraint. The proposed CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity. This pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task, (i.e. pixel-level segmentation) using a semi-supervised setting. Furthermore, we experimentally validate that our proposed method can easily be extended for UDA settings, adding to the superiority of the proposed strategy. Upon evaluation on two domain adaptive image segmentation tasks, our proposed method outperforms the SoTA methods, both in SSDA and UDA settings. Code is available at https://github.com/hritam-98/GFDA-disentangled","sentences":["Although unsupervised domain adaptation (UDA) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts.","In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially.","Specifically, we propose a two-stage training process.","First, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (CL) along with a pixel-level feature consistency constraint.","The proposed CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity.","This pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task, (i.e. pixel-level segmentation) using a semi-supervised setting.","Furthermore, we experimentally validate that our proposed method can easily be extended for UDA settings, adding to the superiority of the proposed strategy.","Upon evaluation on two domain adaptive image segmentation tasks, our proposed method outperforms the SoTA methods, both in SSDA and UDA settings.","Code is available at https://github.com/hritam-98/GFDA-disentangled"],"url":"http://arxiv.org/abs/2307.02798v1"}
{"created":"2023-07-06 06:12:37","title":"BHEISR: Nudging from Bias to Balance -- Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations","abstract":"In the realm of personalized recommendation systems, the increasing concern is the amplification of belief imbalance and user biases, a phenomenon primarily attributed to the filter bubble. Addressing this critical issue, we introduce an innovative intermediate agency (BHEISR) between users and existing recommendation systems to attenuate the negative repercussions of the filter bubble effect in extant recommendation systems. The main objective is to strike a belief balance for users while minimizing the detrimental influence caused by filter bubbles. The BHEISR model amalgamates principles from nudge theory while upholding democratic and transparent principles. It harnesses user-specific category information to stimulate curiosity, even in areas users might initially deem uninteresting. By progressively stimulating interest in novel categories, the model encourages users to broaden their belief horizons and explore the information they typically overlook. Our model is time-sensitive and operates on a user feedback loop. It utilizes the existing recommendation algorithm of the model and incorporates user feedback from the prior time frame. This approach endeavors to transcend the constraints of the filter bubble, enrich recommendation diversity, and strike a belief balance among users while also catering to user preferences and system-specific business requirements. To validate the effectiveness and reliability of the BHEISR model, we conducted a series of comprehensive experiments with real-world datasets. These experiments compared the performance of the BHEISR model against several baseline models using nearly 200 filter bubble-impacted users as test subjects. Our experimental results conclusively illustrate the superior performance of the BHEISR model in mitigating filter bubbles and balancing user perspectives.","sentences":["In the realm of personalized recommendation systems, the increasing concern is the amplification of belief imbalance and user biases, a phenomenon primarily attributed to the filter bubble.","Addressing this critical issue, we introduce an innovative intermediate agency (BHEISR) between users and existing recommendation systems to attenuate the negative repercussions of the filter bubble effect in extant recommendation systems.","The main objective is to strike a belief balance for users while minimizing the detrimental influence caused by filter bubbles.","The BHEISR model amalgamates principles from nudge theory while upholding democratic and transparent principles.","It harnesses user-specific category information to stimulate curiosity, even in areas users might initially deem uninteresting.","By progressively stimulating interest in novel categories, the model encourages users to broaden their belief horizons and explore the information they typically overlook.","Our model is time-sensitive and operates on a user feedback loop.","It utilizes the existing recommendation algorithm of the model and incorporates user feedback from the prior time frame.","This approach endeavors to transcend the constraints of the filter bubble, enrich recommendation diversity, and strike a belief balance among users while also catering to user preferences and system-specific business requirements.","To validate the effectiveness and reliability of the BHEISR model, we conducted a series of comprehensive experiments with real-world datasets.","These experiments compared the performance of the BHEISR model against several baseline models using nearly 200 filter bubble-impacted users as test subjects.","Our experimental results conclusively illustrate the superior performance of the BHEISR model in mitigating filter bubbles and balancing user perspectives."],"url":"http://arxiv.org/abs/2307.02797v1"}
{"created":"2023-07-06 06:11:51","title":"VerifAI: Verified Generative AI","abstract":"Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow. Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more. Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge. We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI. This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency. By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models. Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence. Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI.","sentences":["Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow.","Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more.","Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge.","We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI.","This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency.","By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models.","Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence.","Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI."],"url":"http://arxiv.org/abs/2307.02796v1"}
{"created":"2023-07-06 06:10:52","title":"A Testbed To Study Adversarial Cyber-Attack Strategies in Enterprise Networks","abstract":"In this work, we propose a testbed environment to capture the attack strategies of an adversary carrying out a cyber-attack on an enterprise network. The testbed contains nodes with known security vulnerabilities which can be exploited by hackers. Participants can be invited to play the role of a hacker (e.g., black-hat, hacktivist) and attack the testbed. The testbed is designed such that there are multiple attack pathways available to hackers. We describe the working of the testbed components and discuss its implementation on a VMware ESXi server. Finally, we subject our testbed implementation to a few well-known cyber-attack strategies, collect data during the process and present our analysis of the data.","sentences":["In this work, we propose a testbed environment to capture the attack strategies of an adversary carrying out a cyber-attack on an enterprise network.","The testbed contains nodes with known security vulnerabilities which can be exploited by hackers.","Participants can be invited to play the role of a hacker (e.g., black-hat, hacktivist) and attack the testbed.","The testbed is designed such that there are multiple attack pathways available to hackers.","We describe the working of the testbed components and discuss its implementation on a VMware ESXi server.","Finally, we subject our testbed implementation to a few well-known cyber-attack strategies, collect data during the process and present our analysis of the data."],"url":"http://arxiv.org/abs/2307.02794v1"}
{"created":"2023-07-06 06:07:29","title":"What Should Data Science Education Do with Large Language Models?","abstract":"The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and learning tools, contributing to personalized education. This paper discusses the opportunities, resources and open challenges for each of these directions. As with any transformative technology, integrating LLMs into education calls for careful consideration. While LLMs can perform repetitive tasks efficiently, it's crucial to remember that their role is to supplement human intelligence and creativity, not to replace it. Therefore, the new era of data science education should balance the benefits of LLMs while fostering complementary human expertise and innovations. In conclusion, the rise of LLMs heralds a transformative period for data science and its education. This paper seeks to shed light on the emerging trends, potential opportunities, and challenges accompanying this paradigm shift, hoping to spark further discourse and investigation into this exciting, uncharted territory.","sentences":["The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics.","These state-of-the-art tools can streamline complex processes.","As a result, it reshapes the role of data scientists.","We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs.","This evolution of roles is reminiscent of the transition from a software engineer to a product manager.","We illustrate this transition with concrete data science case studies using LLMs in this paper.","These developments necessitate a meaningful evolution in data science education.","Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming.","LLMs can also play a significant role in the classroom as interactive teaching and learning tools, contributing to personalized education.","This paper discusses the opportunities, resources and open challenges for each of these directions.","As with any transformative technology, integrating LLMs into education calls for careful consideration.","While LLMs can perform repetitive tasks efficiently, it's crucial to remember that their role is to supplement human intelligence and creativity, not to replace it.","Therefore, the new era of data science education should balance the benefits of LLMs while fostering complementary human expertise and innovations.","In conclusion, the rise of LLMs heralds a transformative period for data science and its education.","This paper seeks to shed light on the emerging trends, potential opportunities, and challenges accompanying this paradigm shift, hoping to spark further discourse and investigation into this exciting, uncharted territory."],"url":"http://arxiv.org/abs/2307.02792v1"}
{"created":"2023-07-06 06:06:47","title":"The Role of Subgroup Separability in Group-Fair Medical Image Classification","abstract":"We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.","sentences":["We investigate performance disparities in deep classifiers.","We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias.","Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis.","Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI."],"url":"http://arxiv.org/abs/2307.02791v1"}
{"created":"2023-07-06 06:05:35","title":"Sensor Allocation and Online-Learning-based Path Planning for Maritime Situational Awareness Enhancement: A Multi-Agent Approach","abstract":"Countries with access to large bodies of water often aim to protect their maritime transport by employing maritime surveillance systems. However, the number of available sensors (e.g., cameras) is typically small compared to the to-be-monitored targets, and their Field of View (FOV) and range are often limited. This makes improving the situational awareness of maritime transports challenging. To this end, we propose a method that not only distributes multiple sensors but also plans paths for them to observe multiple targets, while minimizing the time needed to achieve situational awareness. In particular, we provide a formulation of this sensor allocation and path planning problem which considers the partial awareness of the targets' state, as well as the unawareness of the targets' trajectories. To solve the problem we present two algorithms: \\emph{1)} a greedy algorithm for assigning sensors to targets, and \\emph{2)} a distributed multi-agent path planning algorithm based on regret-matching learning. Because a quick convergence is a requirement for algorithms developed for high mobility environments, we employ a forgetting factor to quickly converge to correlated equilibrium solutions. Experimental results show that our combined approach achieves situational awareness more quickly than related work.","sentences":["Countries with access to large bodies of water often aim to protect their maritime transport by employing maritime surveillance systems.","However, the number of available sensors (e.g., cameras) is typically small compared to the to-be-monitored targets, and their Field of View (FOV) and range are often limited.","This makes improving the situational awareness of maritime transports challenging.","To this end, we propose a method that not only distributes multiple sensors but also plans paths for them to observe multiple targets, while minimizing the time needed to achieve situational awareness.","In particular, we provide a formulation of this sensor allocation and path planning problem which considers the partial awareness of the targets' state, as well as the unawareness of the targets' trajectories.","To solve the problem we present two algorithms: \\emph{1)} a greedy algorithm for assigning sensors to targets, and \\emph{2)} a distributed multi-agent path planning algorithm based on regret-matching learning.","Because a quick convergence is a requirement for algorithms developed for high mobility environments, we employ a forgetting factor to quickly converge to correlated equilibrium solutions.","Experimental results show that our combined approach achieves situational awareness more quickly than related work."],"url":"http://arxiv.org/abs/2307.02790v1"}
{"created":"2023-07-06 05:43:53","title":"Shortest Beer Path Queries based on Graph Decomposition","abstract":"Given a directed edge-weighted graph $G=(V, E)$ with beer vertices $B\\subseteq V$, a beer path between two vertices $u$ and $v$ is a path between $u$ and $v$ that visits at least one beer vertex in $B$, and the beer distance between two vertices is the shortest length of beer paths. We consider \\emph{indexing problems} on beer paths, that is, a graph is given a priori, and we construct some data structures (called indexes) for the graph. Then later, we are given two vertices, and we find the beer distance or beer path between them using the data structure. For such a scheme, efficient algorithms using indexes for the beer distance and beer path queries have been proposed for outerplanar graphs and interval graphs. For example, Bacic et al. (2021) present indexes with size $O(n)$ for outerplanar graphs and an algorithm using them that answers the beer distance between given two vertices in $O(\\alpha(n))$ time, where $\\alpha(\\cdot)$ is the inverse Ackermann function; the performance is shown to be optimal. This paper proposes indexing data structures and algorithms for beer path queries on general graphs based on two types of graph decomposition: the tree decomposition and the triconnected component decomposition. We propose indexes with size $O(m+nr^2)$ based on the triconnected component decomposition, where $r$ is the size of the largest triconnected component. For a given query $u,v\\in V$, our algorithm using the indexes can output the beer distance in query time $O(\\alpha(m))$. In particular, our indexing data structures and algorithms achieve the optimal performance (the space and the query time) for series-parallel graphs, which is a wider class of outerplanar graphs.","sentences":["Given a directed edge-weighted graph $G=(V, E)$ with beer vertices $B\\subseteq V$, a beer path between two vertices $u$ and $v$ is a path between $u$ and $v$ that visits at least one beer vertex in $B$, and the beer distance between two vertices is the shortest length of beer paths.","We consider \\emph{indexing problems} on beer paths, that is, a graph is given a priori, and we construct some data structures (called indexes) for the graph.","Then later, we are given two vertices, and we find the beer distance or beer path between them using the data structure.","For such a scheme, efficient algorithms using indexes for the beer distance and beer path queries have been proposed for outerplanar graphs and interval graphs.","For example, Bacic et al. (2021) present indexes with size $O(n)$ for outerplanar graphs and an algorithm using them that answers the beer distance between given two vertices in $O(\\alpha(n))$ time, where $\\alpha(\\cdot)$ is the inverse Ackermann function; the performance is shown to be optimal.","This paper proposes indexing data structures and algorithms for beer path queries on general graphs based on two types of graph decomposition: the tree decomposition and the triconnected component decomposition.","We propose indexes with size $O(m+nr^2)$ based on the triconnected component decomposition, where $r$ is the size of the largest triconnected component.","For a given query $u,v\\in V$, our algorithm using the indexes can output the beer distance in query time $O(\\alpha(m))$. In particular, our indexing data structures and algorithms achieve the optimal performance (the space and the query time) for series-parallel graphs, which is a wider class of outerplanar graphs."],"url":"http://arxiv.org/abs/2307.02787v1"}
{"created":"2023-07-06 05:22:37","title":"On the Spatial-Wideband Effects in Millimeter-Wave Cell-Free Massive MIMO","abstract":"In this paper, we investigate the spatial-wideband effects in cell-free massive MIMO (CF-mMIMO) systems in mmWave bands. The utilization of mmWave frequencies brings challenges such as signal attenuation and the need for denser networks like ultra-dense networks (UDN) to maintain communication performance. CF-mMIMO is introduced as a solution, where distributed access points (APs) transmit signals to a central processing unit (CPU) for joint processing. CF-mMIMO offers advantages in reducing non-line-of-sight (NLOS) conditions and overcoming signal blockage. We investigate the synchronization problem in CF-mMIMO due to time delays between APs. It proposes a minimum cyclic prefix length to mitigate inter-symbol interference (ISI) in OFDM systems. Furthermore, the spatial correlations of channel responses are analyzed in the frequency-phase domain. The impact of these correlations on system performance is examined. The findings contribute to improving the performance of CF-mMIMO systems and enhancing the effective utilization of mmWave communication.","sentences":["In this paper, we investigate the spatial-wideband effects in cell-free massive MIMO (CF-mMIMO) systems in mmWave bands.","The utilization of mmWave frequencies brings challenges such as signal attenuation and the need for denser networks like ultra-dense networks (UDN) to maintain communication performance.","CF-mMIMO is introduced as a solution, where distributed access points (APs) transmit signals to a central processing unit (CPU) for joint processing.","CF-mMIMO offers advantages in reducing non-line-of-sight (NLOS) conditions and overcoming signal blockage.","We investigate the synchronization problem in CF-mMIMO due to time delays between APs.","It proposes a minimum cyclic prefix length to mitigate inter-symbol interference (ISI) in OFDM systems.","Furthermore, the spatial correlations of channel responses are analyzed in the frequency-phase domain.","The impact of these correlations on system performance is examined.","The findings contribute to improving the performance of CF-mMIMO systems and enhancing the effective utilization of mmWave communication."],"url":"http://arxiv.org/abs/2307.02784v1"}
{"created":"2023-07-06 05:22:20","title":"UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image Enhancement for Gastrointestinal Visual Question Answering","abstract":"In recent years, artificial intelligence has played an important role in medicine and disease diagnosis, with many applications to be mentioned, one of which is Medical Visual Question Answering (MedVQA). By combining computer vision and natural language processing, MedVQA systems can assist experts in extracting relevant information from medical image based on a given question and providing precise diagnostic answers. The ImageCLEFmed-MEDVQA-GI-2023 challenge carried out visual question answering task in the gastrointestinal domain, which includes gastroscopy and colonoscopy images. Our team approached Task 1 of the challenge by proposing a multimodal learning method with image enhancement to improve the VQA performance on gastrointestinal images. The multimodal architecture is set up with BERT encoder and different pre-trained vision models based on convolutional neural network (CNN) and Transformer architecture for features extraction from question and endoscopy image. The result of this study highlights the dominance of Transformer-based vision models over the CNNs and demonstrates the effectiveness of the image enhancement process, with six out of the eight vision models achieving better F1-Score. Our best method, which takes advantages of BERT+BEiT fusion and image enhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the development test set, while also producing good result on the private test set with accuracy of 82.01%.","sentences":["In recent years, artificial intelligence has played an important role in medicine and disease diagnosis, with many applications to be mentioned, one of which is Medical Visual Question Answering (MedVQA).","By combining computer vision and natural language processing, MedVQA systems can assist experts in extracting relevant information from medical image based on a given question and providing precise diagnostic answers.","The ImageCLEFmed-MEDVQA-GI-2023 challenge carried out visual question answering task in the gastrointestinal domain, which includes gastroscopy and colonoscopy images.","Our team approached Task 1 of the challenge by proposing a multimodal learning method with image enhancement to improve the VQA performance on gastrointestinal images.","The multimodal architecture is set up with BERT encoder and different pre-trained vision models based on convolutional neural network (CNN) and Transformer architecture for features extraction from question and endoscopy image.","The result of this study highlights the dominance of Transformer-based vision models over the CNNs and demonstrates the effectiveness of the image enhancement process, with six out of the eight vision models achieving better F1-Score.","Our best method, which takes advantages of BERT+BEiT fusion and image enhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the development test set, while also producing good result on the private test set with accuracy of 82.01%."],"url":"http://arxiv.org/abs/2307.02783v1"}
{"created":"2023-07-06 05:17:45","title":"Brain Computer Interface (BCI) based on Electroencephalographic (EEG) patterns due to new cognitive tasks","abstract":"New mental tasks were investigated for suitability in Brain-Computer Interface (BCI). Electroencephalography (EEG) signals were collected and analyzed to identify these mental tasks. MS Windows-based software was developed for investigating and classifying recorded EEG data with unnecessary frequencies filtered out with Bandpass filtering. To identify the best feature vector construction method for a given mental task, feature vectors were constructed using Bandpower, Principal Component Analysis, and Downsampling separately. These feature vectors were then classified with Linear Discriminant Analysis, Linear Support Vector Machines, Critical Distance Classifiers, Nearest Neighbor Classifiers, and their Non-Linear counterparts to find the best-performing classifier. For comparison purposes, performances of already well-known mental tasks in the BCI community were computed along with that of new mental tasks introduced in this thesis. In the preliminary studies, it was found that the most promising new mental task which a BCI system could identify is the imagination of hitting a given square with an imaginary arrow from above (or below) and right, (or left) to the screen. The group of these mental tasks was named as 'Hit Series' (HS). A detailed investigation of HS was carried out and compared with the performance of Motor Imagery (MI) events which are the most heavily used mental tasks in EEG-based BCI systems. One subject achieved the maximum average performance for HS, 100 pct in the binary classifications while 99 pct in overall combined performance. The best average performances of the other two subjects for the same mental tasks were 93 pct and 87pct with the overall performance of 89 pct and 78 pct. Performances of the same three subjects for mental tasks in MI were relatively poor. The average performances were 92, 78, and 92 pct while overall performances were 87, 69, and 88 pct.","sentences":["New mental tasks were investigated for suitability in Brain-Computer Interface (BCI).","Electroencephalography (EEG) signals were collected and analyzed to identify these mental tasks.","MS Windows-based software was developed for investigating and classifying recorded EEG data with unnecessary frequencies filtered out with Bandpass filtering.","To identify the best feature vector construction method for a given mental task, feature vectors were constructed using Bandpower, Principal Component Analysis, and Downsampling separately.","These feature vectors were then classified with Linear Discriminant Analysis, Linear Support Vector Machines, Critical Distance Classifiers, Nearest Neighbor Classifiers, and their Non-Linear counterparts to find the best-performing classifier.","For comparison purposes, performances of already well-known mental tasks in the BCI community were computed along with that of new mental tasks introduced in this thesis.","In the preliminary studies, it was found that the most promising new mental task which a BCI system could identify is the imagination of hitting a given square with an imaginary arrow from above (or below) and right, (or left) to the screen.","The group of these mental tasks was named as 'Hit Series' (HS).","A detailed investigation of HS was carried out and compared with the performance of Motor Imagery (MI) events which are the most heavily used mental tasks in EEG-based BCI systems.","One subject achieved the maximum average performance for HS, 100 pct in the binary classifications while 99 pct in overall combined performance.","The best average performances of the other two subjects for the same mental tasks were 93 pct and 87pct with the overall performance of 89 pct and 78 pct.","Performances of the same three subjects for mental tasks in MI were relatively poor.","The average performances were 92, 78, and 92 pct while overall performances were 87, 69, and 88 pct."],"url":"http://arxiv.org/abs/2307.02780v1"}
{"created":"2023-07-06 05:16:55","title":"Large Language Models Empowered Autonomous Edge AI for Connected Intelligence","abstract":"The evolution of wireless networks gravitates towards connected intelligence, a concept that envisions seamless interconnectivity among humans, objects, and intelligence in a hyper-connected cyber-physical world. Edge AI emerges as a promising solution to achieve connected intelligence by delivering high-quality, low-latency, and privacy-preserving AI services at the network edge. In this article, we introduce an autonomous edge AI system that automatically organizes, adapts, and optimizes itself to meet users' diverse requirements. The system employs a cloud-edge-client hierarchical architecture, where the large language model, i.e., Generative Pretrained Transformer (GPT), resides in the cloud, and other AI models are co-deployed on devices and edge servers. By leveraging the powerful abilities of GPT in language understanding, planning, and code generation, we present a versatile framework that efficiently coordinates edge AI models to cater to users' personal demands while automatically generating code to train new models via edge federated learning. Experimental results demonstrate the system's remarkable ability to accurately comprehend user demands, efficiently execute AI models with minimal cost, and effectively create high-performance AI models through federated learning.","sentences":["The evolution of wireless networks gravitates towards connected intelligence, a concept that envisions seamless interconnectivity among humans, objects, and intelligence in a hyper-connected cyber-physical world.","Edge AI emerges as a promising solution to achieve connected intelligence by delivering high-quality, low-latency, and privacy-preserving AI services at the network edge.","In this article, we introduce an autonomous edge AI system that automatically organizes, adapts, and optimizes itself to meet users' diverse requirements.","The system employs a cloud-edge-client hierarchical architecture, where the large language model, i.e., Generative Pretrained Transformer (GPT), resides in the cloud, and other AI models are co-deployed on devices and edge servers.","By leveraging the powerful abilities of GPT in language understanding, planning, and code generation, we present a versatile framework that efficiently coordinates edge AI models to cater to users' personal demands while automatically generating code to train new models via edge federated learning.","Experimental results demonstrate the system's remarkable ability to accurately comprehend user demands, efficiently execute AI models with minimal cost, and effectively create high-performance AI models through federated learning."],"url":"http://arxiv.org/abs/2307.02779v1"}
{"created":"2023-07-06 05:04:16","title":"Approximation Algorithms for Directed Weighted Spanners","abstract":"In the pairwise weighted spanner problem, the input consists of an $n$-vertex-directed graph, where each edge is assigned a cost and a length. Given $k$ vertex pairs and a distance constraint for each pair, the goal is to find a minimum-cost subgraph in which the distance constraints are satisfied. This formulation captures many well-studied connectivity problems, including spanners, distance preservers, and Steiner forests.   In the offline setting, we show:   1. An $\\tilde{O}(n^{4/5 + \\epsilon})$-approximation algorithm for pairwise weighted spanners. When the edges have unit costs and lengths, the best previous algorithm gives an $\\tilde{O}(n^{3/5 + \\epsilon})$-approximation, due to Chlamt{\\'a}{\\v{c}}, Dinitz, Kortsarz, and Laekhanukit (TALG, 2020).   2. An $\\tilde{O}(n^{1/2+\\epsilon})$-approximation algorithm for all-pair weighted distance preservers. When the edges have unit costs and arbitrary lengths, the best previous algorithm gives an $\\tilde{O}(n^{1/2})$-approximation for all-pair spanners, due to Berman, Bhattacharyya, Makarychev, Raskhodnikova, and Yaroslavtsev (Information and Computation, 2013).   In the online setting, we show:   1. An $\\tilde{O}(k^{1/2 + \\epsilon})$-competitive algorithm for pairwise weighted spanners. The state-of-the-art results are $\\tilde{O}(n^{4/5})$-competitive when edges have unit costs and arbitrary lengths, and $\\min\\{\\tilde{O}(k^{1/2 + \\epsilon}), \\tilde{O}(n^{2/3 + \\epsilon})\\}$-competitive when edges have unit costs and lengths, due to Grigorescu, Lin, and Quanrud (APPROX, 2021).   2. An $\\tilde{O}(k^{\\epsilon})$-competitive algorithm for single-source weighted spanners. Without distance constraints, this problem is equivalent to the directed Steiner tree problem. The best previous algorithm for online directed Steiner trees is $\\tilde{O}(k^{\\epsilon})$-competitive, due to Chakrabarty, Ene, Krishnaswamy, and Panigrahi (SICOMP, 2018).","sentences":["In the pairwise weighted spanner problem, the input consists of an $n$-vertex-directed graph, where each edge is assigned a cost and a length.","Given $k$ vertex pairs and a distance constraint for each pair, the goal is to find a minimum-cost subgraph in which the distance constraints are satisfied.","This formulation captures many well-studied connectivity problems, including spanners, distance preservers, and Steiner forests.   ","In the offline setting, we show:   1.","An $\\tilde{O}(n^{4/5 + \\epsilon})$-approximation algorithm for pairwise weighted spanners.","When the edges have unit costs and lengths, the best previous algorithm gives an $\\tilde{O}(n^{3/5 + \\epsilon})$-approximation, due to Chlamt{\\'a}{\\v{c}}, Dinitz, Kortsarz, and Laekhanukit (TALG, 2020).   ","2.","An $\\tilde{O}(n^{1/2+\\epsilon})$-approximation algorithm for all-pair weighted distance preservers.","When the edges have unit costs and arbitrary lengths, the best previous algorithm gives an $\\tilde{O}(n^{1/2})$-approximation for all-pair spanners, due to Berman, Bhattacharyya, Makarychev, Raskhodnikova, and Yaroslavtsev (Information and Computation, 2013).   ","In the online setting, we show:   1.","An $\\tilde{O}(k^{1/2 + \\epsilon})$-competitive algorithm for pairwise weighted spanners.","The state-of-the-art results are $\\tilde{O}(n^{4/5})$-competitive when edges have unit costs and arbitrary lengths, and $\\min\\{\\tilde{O}(k^{1/2 + \\epsilon}), \\tilde{O}(n^{2/3","+ \\epsilon})\\}$-competitive when edges have unit costs and lengths, due to Grigorescu, Lin, and Quanrud (APPROX, 2021).   ","2.","An $\\tilde{O}(k^{\\epsilon})$-competitive algorithm for single-source weighted spanners.","Without distance constraints, this problem is equivalent to the directed Steiner tree problem.","The best previous algorithm for online directed Steiner trees is $\\tilde{O}(k^{\\epsilon})$-competitive, due to Chakrabarty, Ene, Krishnaswamy, and Panigrahi (SICOMP, 2018)."],"url":"http://arxiv.org/abs/2307.02774v1"}
{"created":"2023-07-06 04:49:47","title":"SeLiNet: Sentiment enriched Lightweight Network for Emotion Recognition in Images","abstract":"In this paper, we propose a sentiment-enriched lightweight network SeLiNet and an end-to-end on-device pipeline for contextual emotion recognition in images. SeLiNet model consists of body feature extractor, image aesthetics feature extractor, and learning-based fusion network which jointly estimates discrete emotion and human sentiments tasks. On the EMOTIC dataset, the proposed approach achieves an Average Precision (AP) score of 27.17 in comparison to the baseline AP score of 27.38 while reducing the model size by >85%. In addition, we report an on-device AP score of 26.42 with reduction in model size by >93% when compared to the baseline.","sentences":["In this paper, we propose a sentiment-enriched lightweight network SeLiNet and an end-to-end on-device pipeline for contextual emotion recognition in images.","SeLiNet model consists of body feature extractor, image aesthetics feature extractor, and learning-based fusion network which jointly estimates discrete emotion and human sentiments tasks.","On the EMOTIC dataset, the proposed approach achieves an Average Precision (AP) score of 27.17 in comparison to the baseline AP score of 27.38 while reducing the model size by >85%.","In addition, we report an on-device AP score of 26.42 with reduction in model size by >93% when compared to the baseline."],"url":"http://arxiv.org/abs/2307.02773v1"}
{"created":"2023-07-06 04:48:24","title":"Efficiency of Self-Adjusting Heaps","abstract":"Since the invention of the pairing heap by Fredman et al., it has been an open question whether this or any other simple \"self-adjusting\" heap supports decrease-key operations on $n$-item heaps in $O(\\log\\log n)$ time. Using powerful new techniques, we answer this question in the affirmative. We prove that both slim and smooth heaps, recently introduced self-adjusting heaps, support heap operations on an $n$-item heap in the following amortized time bounds: $O(\\log n)$ for delete-min and delete, $O(\\log\\log n)$ for decrease-key, and $O(1)$ for all other heap operations, including insert and meld. We also analyze the multipass pairing heap, a variant of pairing heaps. For this heap implementation, we obtain the same bounds except for decrease-key, for which our bound is $O(\\log\\log n \\log\\log\\log n)$. Our bounds significantly improve the best previously known bounds for all three data structures. For slim and smooth heaps our bounds are tight, since they match lower bounds of Iacono and Ozkan; for multipass pairing heaps our bounds are tight except for decrease-key, which by the lower bounds of Fredman and Iacono and \\\"Ozkan must take $O(\\log\\log n)$ amortized time if delete-min takes $O(\\log n)$ time.","sentences":["Since the invention of the pairing heap by Fredman et al., it has been an open question whether this or any other simple \"self-adjusting\" heap supports decrease-key operations on $n$-item heaps in $O(\\log\\log n)$ time.","Using powerful new techniques, we answer this question in the affirmative.","We prove that both slim and smooth heaps, recently introduced self-adjusting heaps, support heap operations on an $n$-item heap in the following amortized time bounds: $O(\\log n)$ for delete-min and delete, $O(\\log\\log n)$ for decrease-key, and $O(1)$ for all other heap operations, including insert and meld.","We also analyze the multipass pairing heap, a variant of pairing heaps.","For this heap implementation, we obtain the same bounds except for decrease-key, for which our bound is $O(\\log\\log n \\log\\log\\log n)$. Our bounds significantly improve the best previously known bounds for all three data structures.","For slim and smooth heaps our bounds are tight, since they match lower bounds of Iacono and Ozkan; for multipass pairing heaps our bounds are tight except for decrease-key, which by the lower bounds of Fredman and Iacono and \\\"Ozkan must take $O(\\log\\log n)$ amortized time if delete-min takes $O(\\log n)$ time."],"url":"http://arxiv.org/abs/2307.02772v1"}
{"created":"2023-07-06 04:45:14","title":"Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback","abstract":"Diffusion models have recently shown remarkable success in high-quality image generation. Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images. If so, we simply need to prevent the generation of the bad images, and we call this task censoring. In this work, we present censored generation with a pre-trained diffusion model using a reward model trained on minimal human feedback. We show that censoring can be accomplished with extreme human feedback efficiency and that labels generated with a mere few minutes of human feedback are sufficient. Code available at: https://github.com/tetrzim/diffusion-human-feedback.","sentences":["Diffusion models have recently shown remarkable success in high-quality image generation.","Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images.","If so, we simply need to prevent the generation of the bad images, and we call this task censoring.","In this work, we present censored generation with a pre-trained diffusion model using a reward model trained on minimal human feedback.","We show that censoring can be accomplished with extreme human feedback efficiency and that labels generated with a mere few minutes of human feedback are sufficient.","Code available at: https://github.com/tetrzim/diffusion-human-feedback."],"url":"http://arxiv.org/abs/2307.02770v1"}
{"created":"2023-07-06 04:40:52","title":"Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts","abstract":"Many cognitive approaches to well-being, such as recognizing and reframing unhelpful thoughts, have received considerable empirical support over the past decades, yet still lack truly widespread adoption in self-help format. A barrier to that adoption is a lack of adequately specific and diverse dedicated practice material. This work examines whether current language models can be leveraged to both produce a virtually unlimited quantity of practice material illustrating standard unhelpful thought patterns matching specific given contexts, and generate suitable positive reframing proposals. We propose PATTERNREFRAME, a novel dataset of about 10k examples of thoughts containing unhelpful thought patterns conditioned on a given persona, accompanied by about 27k positive reframes. By using this dataset to train and/or evaluate current models, we show that existing models can already be powerful tools to help generate an abundance of tailored practice material and hypotheses, with no or minimal additional model training required.","sentences":["Many cognitive approaches to well-being, such as recognizing and reframing unhelpful thoughts, have received considerable empirical support over the past decades, yet still lack truly widespread adoption in self-help format.","A barrier to that adoption is a lack of adequately specific and diverse dedicated practice material.","This work examines whether current language models can be leveraged to both produce a virtually unlimited quantity of practice material illustrating standard unhelpful thought patterns matching specific given contexts, and generate suitable positive reframing proposals.","We propose PATTERNREFRAME, a novel dataset of about 10k examples of thoughts containing unhelpful thought patterns conditioned on a given persona, accompanied by about 27k positive reframes.","By using this dataset to train and/or evaluate current models, we show that existing models can already be powerful tools to help generate an abundance of tailored practice material and hypotheses, with no or minimal additional model training required."],"url":"http://arxiv.org/abs/2307.02768v1"}
{"created":"2023-07-06 04:13:57","title":"When Does Confidence-Based Cascade Deferral Suffice?","abstract":"Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn. A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction. One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability. Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice. In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better. We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer. We then study post-hoc deferral mechanisms, and demonstrate they can significantly improve upon confidence-based deferral in settings where (i) downstream models are specialists that only work well on a subset of inputs, (ii) samples are subject to label noise, and (iii) there is distribution shift between the train and test set.","sentences":["Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn.","A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction.","One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability.","Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice.","In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better.","We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer.","We then study post-hoc deferral mechanisms, and demonstrate they can significantly improve upon confidence-based deferral in settings where (i) downstream models are specialists that only work well on a subset of inputs, (ii) samples are subject to label noise, and (iii) there is distribution shift between the train and test set."],"url":"http://arxiv.org/abs/2307.02764v1"}
{"created":"2023-07-06 04:06:05","title":"Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships","abstract":"Understanding interpersonal communication requires, in part, understanding the social context and norms in which a message is said. However, current methods for identifying offensive content in such communication largely operate independent of context, with only a few approaches considering community norms or prior conversation as context. Here, we introduce a new approach to identifying inappropriate communication by explicitly modeling the social relationship between the individuals. We introduce a new dataset of contextually-situated judgments of appropriateness and show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context. Using data from online conversations and movie dialogues, we provide insight into how the relationships themselves function as implicit norms and quantify the degree to which context-sensitivity is needed in different conversation settings. Further, we also demonstrate that contextual-appropriateness judgments are predictive of other social factors expressed in language such as condescension and politeness.","sentences":["Understanding interpersonal communication requires, in part, understanding the social context and norms in which a message is said.","However, current methods for identifying offensive content in such communication largely operate independent of context, with only a few approaches considering community norms or prior conversation as context.","Here, we introduce a new approach to identifying inappropriate communication by explicitly modeling the social relationship between the individuals.","We introduce a new dataset of contextually-situated judgments of appropriateness and show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context.","Using data from online conversations and movie dialogues, we provide insight into how the relationships themselves function as implicit norms and quantify the degree to which context-sensitivity is needed in different conversation settings.","Further, we also demonstrate that contextual-appropriateness judgments are predictive of other social factors expressed in language such as condescension and politeness."],"url":"http://arxiv.org/abs/2307.02763v1"}
{"created":"2023-07-06 04:05:44","title":"PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations","abstract":"Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized \"strongest\" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two answers. We conduct experiments on two benchmark datasets. We find that our approaches achieve higher accuracy and align better with human judgments, respectively. Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed. Our work provides space to explore evaluating models that are hard to compare for humans.","sentences":["Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically.","Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering.","More specifically, they use the recognized \"strongest\" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score.","However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias.","We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations.","Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two answers.","We conduct experiments on two benchmark datasets.","We find that our approaches achieve higher accuracy and align better with human judgments, respectively.","Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed.","Our work provides space to explore evaluating models that are hard to compare for humans."],"url":"http://arxiv.org/abs/2307.02762v1"}
{"created":"2023-07-06 03:54:19","title":"Cross-Modal Content Inference and Feature Enrichment for Cold-Start Recommendation","abstract":"Multimedia recommendation aims to fuse the multi-modal information of items for feature enrichment to improve the recommendation performance. However, existing methods typically introduce multi-modal information based on collaborative information to improve the overall recommendation precision, while failing to explore its cold-start recommendation performance. Meanwhile, these above methods are only applicable when such multi-modal data is available. To address this problem, this paper proposes a recommendation framework, named Cross-modal Content Inference and Feature Enrichment Recommendation (CIERec), which exploits the multi-modal information to improve its cold-start recommendation performance. Specifically, CIERec first introduces image annotation as the privileged information to help guide the mapping of unified features from the visual space to the semantic space in the training phase. And then CIERec enriches the content representation with the fusion of collaborative, visual, and cross-modal inferred representations, so as to improve its cold-start recommendation performance. Experimental results on two real-world datasets show that the content representations learned by CIERec are able to achieve superior cold-start recommendation performance over existing visually-aware recommendation algorithms. More importantly, CIERec can consistently achieve significant improvements with different conventional visually-aware backbones, which verifies its universality and effectiveness.","sentences":["Multimedia recommendation aims to fuse the multi-modal information of items for feature enrichment to improve the recommendation performance.","However, existing methods typically introduce multi-modal information based on collaborative information to improve the overall recommendation precision, while failing to explore its cold-start recommendation performance.","Meanwhile, these above methods are only applicable when such multi-modal data is available.","To address this problem, this paper proposes a recommendation framework, named Cross-modal Content Inference and Feature Enrichment Recommendation (CIERec), which exploits the multi-modal information to improve its cold-start recommendation performance.","Specifically, CIERec first introduces image annotation as the privileged information to help guide the mapping of unified features from the visual space to the semantic space in the training phase.","And then CIERec enriches the content representation with the fusion of collaborative, visual, and cross-modal inferred representations, so as to improve its cold-start recommendation performance.","Experimental results on two real-world datasets show that the content representations learned by CIERec are able to achieve superior cold-start recommendation performance over existing visually-aware recommendation algorithms.","More importantly, CIERec can consistently achieve significant improvements with different conventional visually-aware backbones, which verifies its universality and effectiveness."],"url":"http://arxiv.org/abs/2307.02761v1"}
{"created":"2023-07-06 03:44:40","title":"Knowledge Graph Self-Supervised Rationalization for Recommendation","abstract":"In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the rational scores are masked. Extensive experiments on three real-world datasets demonstrate that KGRec outperforms state-of-the-art methods. We also provide the implementation codes for our approach at https://github.com/HKUDS/KGRec.","sentences":["In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems.","To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets.","With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking.","To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing.","By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales.","To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views.","To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the rational scores are masked.","Extensive experiments on three real-world datasets demonstrate that KGRec outperforms state-of-the-art methods.","We also provide the implementation codes for our approach at https://github.com/HKUDS/KGRec."],"url":"http://arxiv.org/abs/2307.02759v1"}
{"created":"2023-07-06 03:43:45","title":"Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics","abstract":"Linguistic style matching (LSM) in conversations can be reflective of several aspects of social influence such as power or persuasion. However, how LSM relates to the outcomes of online communication on platforms such as Reddit is an unknown question. In this study, we analyze a large corpus of two-party conversation threads in Reddit where we identify all occurrences of LSM using two types of style: the use of function words and formality. Using this framework, we examine how levels of LSM differ in conversations depending on several social factors within Reddit: post and subreddit features, conversation depth, user tenure, and the controversiality of a comment. Finally, we measure the change of LSM following loss of status after community banning. Our findings reveal the interplay of LSM in Reddit conversations with several community metrics, suggesting the importance of understanding conversation engagement when understanding community dynamics.","sentences":["Linguistic style matching (LSM) in conversations can be reflective of several aspects of social influence such as power or persuasion.","However, how LSM relates to the outcomes of online communication on platforms such as Reddit is an unknown question.","In this study, we analyze a large corpus of two-party conversation threads in Reddit where we identify all occurrences of LSM using two types of style: the use of function words and formality.","Using this framework, we examine how levels of LSM differ in conversations depending on several social factors within Reddit: post and subreddit features, conversation depth, user tenure, and the controversiality of a comment.","Finally, we measure the change of LSM following loss of status after community banning.","Our findings reveal the interplay of LSM in Reddit conversations with several community metrics, suggesting the importance of understanding conversation engagement when understanding community dynamics."],"url":"http://arxiv.org/abs/2307.02758v1"}
{"created":"2023-07-06 03:41:15","title":"Wireless Multi-Agent Generative AI: From Connected Intelligence to Collective Intelligence","abstract":"The convergence of generative large language models (LLMs), edge networks, and multi-agent systems represents a groundbreaking synergy that holds immense promise for future wireless generations, harnessing the power of collective intelligence and paving the way for self-governed networks where intelligent decision-making happens right at the edge. This article puts the stepping-stone for incorporating multi-agent generative artificial intelligence (AI) in wireless networks, and sets the scene for realizing on-device LLMs, where multi-agent LLMs are collaboratively planning and solving tasks to achieve a number of network goals. We further investigate the profound limitations of cloud-based LLMs, and explore multi-agent LLMs from a game theoretic perspective, where agents collaboratively solve tasks in competitive environments. Moreover, we establish the underpinnings for the architecture design of wireless multi-agent generative AI systems at the network level and the agent level, and we identify the wireless technologies that are envisioned to play a key role in enabling on-device LLM. To demonstrate the promising potentials of wireless multi-agent generative AI networks, we highlight the benefits that can be achieved when implementing wireless generative agents in intent-based networking, and we provide a case study to showcase how on-device LLMs can contribute to solving network intents in a collaborative fashion. We finally shed lights on potential challenges and sketch a research roadmap towards realizing the vision of wireless collective intelligence.","sentences":["The convergence of generative large language models (LLMs), edge networks, and multi-agent systems represents a groundbreaking synergy that holds immense promise for future wireless generations, harnessing the power of collective intelligence and paving the way for self-governed networks where intelligent decision-making happens right at the edge.","This article puts the stepping-stone for incorporating multi-agent generative artificial intelligence (AI) in wireless networks, and sets the scene for realizing on-device LLMs, where multi-agent LLMs are collaboratively planning and solving tasks to achieve a number of network goals.","We further investigate the profound limitations of cloud-based LLMs, and explore multi-agent LLMs from a game theoretic perspective, where agents collaboratively solve tasks in competitive environments.","Moreover, we establish the underpinnings for the architecture design of wireless multi-agent generative AI systems at the network level and the agent level, and we identify the wireless technologies that are envisioned to play a key role in enabling on-device LLM.","To demonstrate the promising potentials of wireless multi-agent generative AI networks, we highlight the benefits that can be achieved when implementing wireless generative agents in intent-based networking, and we provide a case study to showcase how on-device LLMs can contribute to solving network intents in a collaborative fashion.","We finally shed lights on potential challenges and sketch a research roadmap towards realizing the vision of wireless collective intelligence."],"url":"http://arxiv.org/abs/2307.02757v1"}
{"created":"2023-07-06 03:26:11","title":"Intent-driven Intelligent Control and Orchestration in O-RAN Via Hierarchical Reinforcement Learning","abstract":"rApps and xApps need to be controlled and orchestrated well in the open radio access network (O-RAN) so that they can deliver a guaranteed network performance in a complex multi-vendor environment. This paper proposes a novel intent-driven intelligent control and orchestration scheme based on hierarchical reinforcement learning (HRL). The proposed scheme can orchestrate multiple rApps or xApps according to the operator's intent of optimizing certain key performance indicators (KPIs), such as throughput, energy efficiency, and latency. Specifically, we propose a bi-level architecture with a meta-controller and a controller. The meta-controller provides the target performance in terms of KPIs, while the controller performs xApp orchestration at the lower level. Our simulation results show that the proposed HRL-based intent-driven xApp orchestration mechanism achieves 7.5% and 21.4% increase in average system throughput with respect to two baselines, i.e., a single xApp baseline and a non-machine learning-based algorithm, respectively. Similarly, 17.3% and 37.9% increase in energy efficiency are observed in comparison to the same baselines.","sentences":["rApps and xApps need to be controlled and orchestrated well in the open radio access network (O-RAN) so that they can deliver a guaranteed network performance in a complex multi-vendor environment.","This paper proposes a novel intent-driven intelligent control and orchestration scheme based on hierarchical reinforcement learning (HRL).","The proposed scheme can orchestrate multiple rApps or xApps according to the operator's intent of optimizing certain key performance indicators (KPIs), such as throughput, energy efficiency, and latency.","Specifically, we propose a bi-level architecture with a meta-controller and a controller.","The meta-controller provides the target performance in terms of KPIs, while the controller performs xApp orchestration at the lower level.","Our simulation results show that the proposed HRL-based intent-driven xApp orchestration mechanism achieves 7.5% and 21.4% increase in average system throughput with respect to two baselines, i.e., a single xApp baseline and a non-machine learning-based algorithm, respectively.","Similarly, 17.3% and 37.9% increase in energy efficiency are observed in comparison to the same baselines."],"url":"http://arxiv.org/abs/2307.02754v1"}
{"created":"2023-07-06 03:25:37","title":"CityTrack: Improving City-Scale Multi-Camera Multi-Target Tracking by Location-Aware Tracking and Box-Grained Matching","abstract":"Multi-Camera Multi-Target Tracking (MCMT) is a computer vision technique that involves tracking multiple targets simultaneously across multiple cameras. MCMT in urban traffic visual analysis faces great challenges due to the complex and dynamic nature of urban traffic scenes, where multiple cameras with different views and perspectives are often used to cover a large city-scale area. Targets in urban traffic scenes often undergo occlusion, illumination changes, and perspective changes, making it difficult to associate targets across different cameras accurately. To overcome these challenges, we propose a novel systematic MCMT framework, called CityTrack. Specifically, we present a Location-Aware SCMT tracker which integrates various advanced techniques to improve its effectiveness in the MCMT task and propose a novel Box-Grained Matching (BGM) method for the ICA module to solve the aforementioned problems. We evaluated our approach on the public test set of the CityFlowV2 dataset and achieved an IDF1 of 84.91%, ranking 1st in the 2022 AI CITY CHALLENGE. Our experimental results demonstrate the effectiveness of our approach in overcoming the challenges posed by urban traffic scenes.","sentences":["Multi-Camera Multi-Target Tracking (MCMT) is a computer vision technique that involves tracking multiple targets simultaneously across multiple cameras.","MCMT in urban traffic visual analysis faces great challenges due to the complex and dynamic nature of urban traffic scenes, where multiple cameras with different views and perspectives are often used to cover a large city-scale area.","Targets in urban traffic scenes often undergo occlusion, illumination changes, and perspective changes, making it difficult to associate targets across different cameras accurately.","To overcome these challenges, we propose a novel systematic MCMT framework, called CityTrack.","Specifically, we present a Location-Aware SCMT tracker which integrates various advanced techniques to improve its effectiveness in the MCMT task and propose a novel Box-Grained Matching (BGM) method for the ICA module to solve the aforementioned problems.","We evaluated our approach on the public test set of the CityFlowV2 dataset and achieved an IDF1 of 84.91%, ranking 1st in the 2022 AI CITY CHALLENGE.","Our experimental results demonstrate the effectiveness of our approach in overcoming the challenges posed by urban traffic scenes."],"url":"http://arxiv.org/abs/2307.02753v1"}
{"created":"2023-07-06 03:22:19","title":"Offline Reinforcement Learning with Imbalanced Datasets","abstract":"The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the context of imbalanced datasets with varying levels of imbalance, utilizing the variant of D4RL. Empirical results demonstrate the superiority of our method over other baselines.","sentences":["The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models.","The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations.","In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies.","Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset.","Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets.","We evaluate our method on several tasks in the context of imbalanced datasets with varying levels of imbalance, utilizing the variant of D4RL.","Empirical results demonstrate the superiority of our method over other baselines."],"url":"http://arxiv.org/abs/2307.02752v1"}
{"created":"2023-07-06 03:19:40","title":"DSARSR: Deep Stacked Auto-encoders Enhanced Robust Speaker Recognition","abstract":"Speaker recognition is a biometric modality that utilizes the speaker's speech segments to recognize the identity, determining whether the test speaker belongs to one of the enrolled speakers. In order to improve the robustness of the i-vector framework on cross-channel conditions and explore the nova method for applying deep learning to speaker recognition, the Stacked Auto-encoders are used to get the abstract extraction of the i-vector instead of applying PLDA. After pre-processing and feature extraction, the speaker and channel-independent speeches are employed for UBM training. The UBM is then used to extract the i-vector of the enrollment and test speech. Unlike the traditional i-vector framework, which uses linear discriminant analysis (LDA) to reduce dimension and increase the discrimination between speaker subspaces, this research use stacked auto-encoders to reconstruct the i-vector with lower dimension and different classifiers can be chosen to achieve final classification. The experimental results show that the proposed method achieves better performance than the state-of-the-art method.","sentences":["Speaker recognition is a biometric modality that utilizes the speaker's speech segments to recognize the identity, determining whether the test speaker belongs to one of the enrolled speakers.","In order to improve the robustness of the i-vector framework on cross-channel conditions and explore the nova method for applying deep learning to speaker recognition, the Stacked Auto-encoders are used to get the abstract extraction of the i-vector instead of applying PLDA.","After pre-processing and feature extraction, the speaker and channel-independent speeches are employed for UBM training.","The UBM is then used to extract the i-vector of the enrollment and test speech.","Unlike the traditional i-vector framework, which uses linear discriminant analysis (LDA) to reduce dimension and increase the discrimination between speaker subspaces, this research use stacked auto-encoders to reconstruct the i-vector with lower dimension and different classifiers can be chosen to achieve final classification.","The experimental results show that the proposed method achieves better performance than the state-of-the-art method."],"url":"http://arxiv.org/abs/2307.02751v1"}
{"created":"2023-07-06 03:16:36","title":"Dynamic Multi-time Scale User Admission and Resource Allocation for Semantic Extraction in MEC Systems","abstract":"This paper investigates the semantic extraction task-oriented dynamic multi-time scale user admission and resourceallocation in mobile edge computing (MEC) systems. Amid prevalence artifi cial intelligence applications in various industries,the offloading of semantic extraction tasks which are mainlycomposed of convolutional neural networks of computer vision isa great challenge for communication bandwidth and computing capacity allocation in MEC systems. Considering the stochasticnature of the semantic extraction tasks, we formulate a stochastic optimization problem by modeling it as the dynamic arrival of tasks in the temporal domain. We jointly optimize the system revenue and cost which are represented as user admission in the long term and resource allocation in the short term respectively. To handle the proposed stochastic optimization problem, we decompose it into short-time-scale subproblems and a long-time-scale subproblem by using the Lyapunov optimization technique. After that, the short-time-scale optimization variables of resource allocation, including user association, bandwidth allocation, and computing capacity allocation are obtained in closed form. The user admission optimization on long-time scales is solved by a heuristic iteration method. Then, the multi-time scale user admission and resource allocation algorithm is proposed for dynamic semantic extraction task computing in MEC systems. Simulation results demonstrate that, compared with the benchmarks, the proposed algorithm improves the performance of user admission and resource allocation efficiently and achieves a flexible trade-off between system revenue and cost at multi-time scales and considering semantic extraction tasks.","sentences":["This paper investigates the semantic extraction task-oriented dynamic multi-time scale user admission and resourceallocation in mobile edge computing (MEC) systems.","Amid prevalence artifi cial intelligence applications in various industries,the offloading of semantic extraction tasks which are mainlycomposed of convolutional neural networks of computer vision isa great challenge for communication bandwidth and computing capacity allocation in MEC systems.","Considering the stochasticnature of the semantic extraction tasks, we formulate a stochastic optimization problem by modeling it as the dynamic arrival of tasks in the temporal domain.","We jointly optimize the system revenue and cost which are represented as user admission in the long term and resource allocation in the short term respectively.","To handle the proposed stochastic optimization problem, we decompose it into short-time-scale subproblems and a long-time-scale subproblem by using the Lyapunov optimization technique.","After that, the short-time-scale optimization variables of resource allocation, including user association, bandwidth allocation, and computing capacity allocation are obtained in closed form.","The user admission optimization on long-time scales is solved by a heuristic iteration method.","Then, the multi-time scale user admission and resource allocation algorithm is proposed for dynamic semantic extraction task computing in MEC systems.","Simulation results demonstrate that, compared with the benchmarks, the proposed algorithm improves the performance of user admission and resource allocation efficiently and achieves a flexible trade-off between system revenue and cost at multi-time scales and considering semantic extraction tasks."],"url":"http://arxiv.org/abs/2307.02748v1"}
{"created":"2023-07-06 03:15:58","title":"Computing Offloading and Semantic Compression for Intelligent Computing Tasks in MEC Systems","abstract":"This paper investigates the intelligent computing task-oriented computing offloading and semantic compression in mobile edge computing (MEC) systems. With the popularity of intelligent applications in various industries, terminals increasingly need to offload intelligent computing tasks with complex demands to MEC servers for computing, which is a great challenge for bandwidth and computing capacity allocation in MEC systems. Considering the accuracy requirement of intelligent computing tasks, we formulate an optimization problem of computing offloading and semantic compression. We jointly optimize the system utility which are represented as computing accuracy and task delay respectively to acquire the optimized system utility. To solve the proposed optimization problem, we decompose it into computing capacity allocation subproblem and compression offloading subproblem and obtain solutions through convex optimization and successive convex approximation. After that, the offloading decisions, computing capacity and compressed ratio are obtained in closed forms. We design the computing offloading and semantic compression algorithm for intelligent computing tasks in MEC systems then. Simulation results represent that our algorithm converges quickly and acquires better performance and resource utilization efficiency through the trend with total number of users and computing capacity compared with benchmarks.","sentences":["This paper investigates the intelligent computing task-oriented computing offloading and semantic compression in mobile edge computing (MEC) systems.","With the popularity of intelligent applications in various industries, terminals increasingly need to offload intelligent computing tasks with complex demands to MEC servers for computing, which is a great challenge for bandwidth and computing capacity allocation in MEC systems.","Considering the accuracy requirement of intelligent computing tasks, we formulate an optimization problem of computing offloading and semantic compression.","We jointly optimize the system utility which are represented as computing accuracy and task delay respectively to acquire the optimized system utility.","To solve the proposed optimization problem, we decompose it into computing capacity allocation subproblem and compression offloading subproblem and obtain solutions through convex optimization and successive convex approximation.","After that, the offloading decisions, computing capacity and compressed ratio are obtained in closed forms.","We design the computing offloading and semantic compression algorithm for intelligent computing tasks in MEC systems then.","Simulation results represent that our algorithm converges quickly and acquires better performance and resource utilization efficiency through the trend with total number of users and computing capacity compared with benchmarks."],"url":"http://arxiv.org/abs/2307.02747v1"}
{"created":"2023-07-06 03:08:03","title":"Active Learning with Contrastive Pre-training for Facial Expression Recognition","abstract":"Deep learning has played a significant role in the success of facial expression recognition (FER), thanks to large models and vast amounts of labelled data. However, obtaining labelled data requires a tremendous amount of human effort, time, and financial resources. Even though some prior works have focused on reducing the need for large amounts of labelled data using different unsupervised methods, another promising approach called active learning is barely explored in the context of FER. This approach involves selecting and labelling the most representative samples from an unlabelled set to make the best use of a limited 'labelling budget'. In this paper, we implement and study 8 recent active learning methods on three public FER datasets, FER13, RAF-DB, and KDEF. Our findings show that existing active learning methods do not perform well in the context of FER, likely suffering from a phenomenon called 'Cold Start', which occurs when the initial set of labelled samples is not well representative of the entire dataset. To address this issue, we propose contrastive self-supervised pre-training, which first learns the underlying representations based on the entire unlabelled dataset. We then follow this with the active learning methods and observe that our 2-step approach shows up to 9.2% improvement over random sampling and up to 6.7% improvement over the best existing active learning baseline without the pre-training. We will make the code for this study public upon publication at: github.com/ShuvenduRoy/ActiveFER.","sentences":["Deep learning has played a significant role in the success of facial expression recognition (FER), thanks to large models and vast amounts of labelled data.","However, obtaining labelled data requires a tremendous amount of human effort, time, and financial resources.","Even though some prior works have focused on reducing the need for large amounts of labelled data using different unsupervised methods, another promising approach called active learning is barely explored in the context of FER.","This approach involves selecting and labelling the most representative samples from an unlabelled set to make the best use of a limited 'labelling budget'.","In this paper, we implement and study 8 recent active learning methods on three public FER datasets, FER13, RAF-DB, and KDEF.","Our findings show that existing active learning methods do not perform well in the context of FER, likely suffering from a phenomenon called 'Cold Start', which occurs when the initial set of labelled samples is not well representative of the entire dataset.","To address this issue, we propose contrastive self-supervised pre-training, which first learns the underlying representations based on the entire unlabelled dataset.","We then follow this with the active learning methods and observe that our 2-step approach shows up to 9.2% improvement over random sampling and up to 6.7% improvement over the best existing active learning baseline without the pre-training.","We will make the code for this study public upon publication at: github.com/ShuvenduRoy/ActiveFER."],"url":"http://arxiv.org/abs/2307.02744v1"}
{"created":"2023-07-06 02:59:47","title":"Dense Retrieval Adaptation using Target Domain Description","abstract":"In information retrieval (IR), domain adaptation is the process of adapting a retrieval model to a new domain whose data distribution is different from the source domain. Existing methods in this area focus on unsupervised domain adaptation where they have access to the target document collection or supervised (often few-shot) domain adaptation where they additionally have access to (limited) labeled data in the target domain. There also exists research on improving zero-shot performance of retrieval models with no adaptation. This paper introduces a new category of domain adaptation in IR that is as-yet unexplored. Here, similar to the zero-shot setting, we assume the retrieval model does not have access to the target document collection. In contrast, it does have access to a brief textual description that explains the target domain. We define a taxonomy of domain attributes in retrieval tasks to understand different properties of a source domain that can be adapted to a target domain. We introduce a novel automatic data construction pipeline that produces a synthetic document collection, query set, and pseudo relevance labels, given a textual domain description. Extensive experiments on five diverse target domains show that adapting dense retrieval models using the constructed synthetic data leads to effective retrieval performance on the target domain.","sentences":["In information retrieval (IR), domain adaptation is the process of adapting a retrieval model to a new domain whose data distribution is different from the source domain.","Existing methods in this area focus on unsupervised domain adaptation where they have access to the target document collection or supervised (often few-shot) domain adaptation where they additionally have access to (limited) labeled data in the target domain.","There also exists research on improving zero-shot performance of retrieval models with no adaptation.","This paper introduces a new category of domain adaptation in IR that is as-yet unexplored.","Here, similar to the zero-shot setting, we assume the retrieval model does not have access to the target document collection.","In contrast, it does have access to a brief textual description that explains the target domain.","We define a taxonomy of domain attributes in retrieval tasks to understand different properties of a source domain that can be adapted to a target domain.","We introduce a novel automatic data construction pipeline that produces a synthetic document collection, query set, and pseudo relevance labels, given a textual domain description.","Extensive experiments on five diverse target domains show that adapting dense retrieval models using the constructed synthetic data leads to effective retrieval performance on the target domain."],"url":"http://arxiv.org/abs/2307.02740v1"}
{"created":"2023-07-06 02:51:54","title":"RecallM: An Architecture for Temporal Context Understanding and Question Answering","abstract":"The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides.","sentences":["The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt.","Creating this type of memory mechanism is an extremely challenging problem.","In this paper we explore different methods of achieving the effect of long-term memory.","We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems.","We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides."],"url":"http://arxiv.org/abs/2307.02738v1"}
{"created":"2023-07-06 02:51:17","title":"Theoretical Bounds for the Size of Elementary Trapping Sets by Graphic Methods","abstract":"Elementary trapping sets (ETSs) are the main culprits for the performance of LDPC codes in the error floor region. Due to the large quantity, complex structures, and computational difficulties of ETSs, how to eliminate dominant ETSs in designing LDPC codes becomes a pivotal issue to improve the error floor behavior. In practice, researchers commonly address this problem by avoiding some special graph structures to free specific ETSs in Tanner graph. In this paper, we deduce the accurate Tur\\'an number of $\\theta(1,2,2)$ and prove that all $(a,b)$-ETSs in Tanner graph with variable-regular degree $d_L(v)=\\gamma$ must satisfy the bound $b\\geq a\\gamma-\\frac{1}{2}a^2$, which improves the lower bound obtained by Amirzade when the girth is 6. For the case of girth 8, by limiting the relation between any two 8-cycles in the Tanner graph, we prove a similar inequality $b\\geq a\\gamma-\\frac{a(\\sqrt{8a-7}-1)}{2}$. The simulation results show that the designed codes have good performance with lower error floor over additive white Gaussian noise channels.","sentences":["Elementary trapping sets (ETSs) are the main culprits for the performance of LDPC codes in the error floor region.","Due to the large quantity, complex structures, and computational difficulties of ETSs, how to eliminate dominant ETSs in designing LDPC codes becomes a pivotal issue to improve the error floor behavior.","In practice, researchers commonly address this problem by avoiding some special graph structures to free specific ETSs in Tanner graph.","In this paper, we deduce the accurate Tur\\'an number of $\\theta(1,2,2)$ and prove that all $(a,b)$-ETSs in Tanner graph with variable-regular degree $d_L(v)=\\gamma$ must satisfy the bound $b\\geq a\\gamma-\\frac{1}{2}a^2$, which improves the lower bound obtained by Amirzade when the girth is 6.","For the case of girth 8, by limiting the relation between any two 8-cycles in the Tanner graph, we prove a similar inequality $b\\geq a\\gamma-\\frac{a(\\sqrt{8a-7}-1)}{2}$. The simulation results show that the designed codes have good performance with lower error floor over additive white Gaussian noise channels."],"url":"http://arxiv.org/abs/2307.02737v1"}
{"created":"2023-07-06 02:32:08","title":"MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection","abstract":"Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forged face images. In response, various deepfake detection methods have been proposed to assess image authenticity. Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery. Nonetheless, due to the different combinations of spatial and sequential manipulations, forged face images exhibit substantial discrepancies that severely impact detection performance. Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers. To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forged face images and achieve recovery without requiring knowledge of the corresponding manipulation method. Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps. To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences. Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance.","sentences":["Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forged face images.","In response, various deepfake detection methods have been proposed to assess image authenticity.","Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery.","Nonetheless, due to the different combinations of spatial and sequential manipulations, forged face images exhibit substantial discrepancies that severely impact detection performance.","Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers.","To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forged face images and achieve recovery without requiring knowledge of the corresponding manipulation method.","Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps.","To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences.","Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance."],"url":"http://arxiv.org/abs/2307.02733v1"}
{"created":"2023-07-06 02:31:38","title":"Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?","abstract":"Numerous benchmarks for Few-Shot Learning have been proposed in the last decade. However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual tasks in this regime has not been addressed. This paper presents the first investigation into task-level evaluation -- a fundamental step when deploying a model. We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust. We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes. Overall, we find that existing benchmarks for few-shot learning are not designed in such a way that one can get a reliable picture of how effectively methods can be used on individual tasks.","sentences":["Numerous benchmarks for Few-Shot Learning have been proposed in the last decade.","However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual tasks in this regime has not been addressed.","This paper presents the first investigation into task-level evaluation -- a fundamental step when deploying a model.","We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust.","We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes.","Overall, we find that existing benchmarks for few-shot learning are not designed in such a way that one can get a reliable picture of how effectively methods can be used on individual tasks."],"url":"http://arxiv.org/abs/2307.02732v1"}
{"created":"2023-07-06 02:30:56","title":"Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating","abstract":"The fine-grained action analysis of the existing action datasets is challenged by insufficient action categories, low fine granularities, limited modalities, and tasks. In this paper, we propose a Multi-modality and Multi-task dataset of Figure Skating (MMFS) which was collected from the World Figure Skating Championships. MMFS, which possesses action recognition and action quality assessment, captures RGB, skeleton, and is collected the score of actions from 11671 clips with 256 categories including spatial and temporal labels. The key contributions of our dataset fall into three aspects as follows. (1) Independently spatial and temporal categories are first proposed to further explore fine-grained action recognition and quality assessment. (2) MMFS first introduces the skeleton modality for complex fine-grained action quality assessment. (3) Our multi-modality and multi-task dataset encourage more action analysis models. To benchmark our dataset, we adopt RGB-based and skeleton-based baseline methods for action recognition and action quality assessment.","sentences":["The fine-grained action analysis of the existing action datasets is challenged by insufficient action categories, low fine granularities, limited modalities, and tasks.","In this paper, we propose a Multi-modality and Multi-task dataset of Figure Skating (MMFS) which was collected from the World Figure Skating Championships. MMFS, which possesses action recognition and action quality assessment, captures RGB, skeleton, and is collected the score of actions from 11671 clips with 256 categories including spatial and temporal labels.","The key contributions of our dataset fall into three aspects as follows.","(1) Independently spatial and temporal categories are first proposed to further explore fine-grained action recognition and quality assessment.","(2) MMFS first introduces the skeleton modality for complex fine-grained action quality assessment.","(3) Our multi-modality and multi-task dataset encourage more action analysis models.","To benchmark our dataset, we adopt RGB-based and skeleton-based baseline methods for action recognition and action quality assessment."],"url":"http://arxiv.org/abs/2307.02730v1"}
{"created":"2023-07-06 02:28:31","title":"Text Alignment Is An Efficient Unified Model for Massive NLP Tasks","abstract":"Large language models (LLMs), typically designed as a function of next-word prediction, have excelled across extensive NLP tasks. Despite the generality, next-word prediction is often not an efficient formulation for many of the tasks, demanding an extreme scale of model parameters (10s or 100s of billions) and sometimes yielding suboptimal performance. In practice, it is often desirable to build more efficient models -- despite being less versatile, they still apply to a substantial subset of problems, delivering on par or even superior performance with much smaller model sizes. In this paper, we propose text alignment as an efficient unified model for a wide range of crucial tasks involving text entailment, similarity, question answering (and answerability), factual consistency, and so forth. Given a pair of texts, the model measures the degree of alignment between their information. We instantiate an alignment model (Align) through lightweight finetuning of RoBERTa (355M parameters) using 5.9M examples from 28 datasets. Despite its compact size, extensive experiments show the model's efficiency and strong performance: (1) On over 20 datasets of aforementioned diverse tasks, the model matches or surpasses FLAN-T5 models that have around 2x or 10x more parameters; the single unified model also outperforms task-specific models finetuned on individual datasets; (2) When applied to evaluate factual consistency of language generation on 23 datasets, our model improves over various baselines, including the much larger GPT-3.5 (ChatGPT) and sometimes even GPT-4; (3) The lightweight model can also serve as an add-on component for LLMs such as GPT-3.5 in question answering tasks, improving the average exact match (EM) score by 17.94 and F1 score by 15.05 through identifying unanswerable questions.","sentences":["Large language models (LLMs), typically designed as a function of next-word prediction, have excelled across extensive NLP tasks.","Despite the generality, next-word prediction is often not an efficient formulation for many of the tasks, demanding an extreme scale of model parameters (10s or 100s of billions) and sometimes yielding suboptimal performance.","In practice, it is often desirable to build more efficient models -- despite being less versatile, they still apply to a substantial subset of problems, delivering on par or even superior performance with much smaller model sizes.","In this paper, we propose text alignment as an efficient unified model for a wide range of crucial tasks involving text entailment, similarity, question answering (and answerability), factual consistency, and so forth.","Given a pair of texts, the model measures the degree of alignment between their information.","We instantiate an alignment model (Align) through lightweight finetuning of RoBERTa (355M parameters) using 5.9M examples from 28 datasets.","Despite its compact size, extensive experiments show the model's efficiency and strong performance: (1) On over 20 datasets of aforementioned diverse tasks, the model matches or surpasses FLAN-T5 models that have around 2x or 10x more parameters; the single unified model also outperforms task-specific models finetuned on individual datasets; (2) When applied to evaluate factual consistency of language generation on 23 datasets, our model improves over various baselines, including the much larger GPT-3.5 (ChatGPT) and sometimes even GPT-4; (3) The lightweight model can also serve as an add-on component for LLMs such as GPT-3.5 in question answering tasks, improving the average exact match (EM) score by 17.94 and F1 score by 15.05 through identifying unanswerable questions."],"url":"http://arxiv.org/abs/2307.02729v1"}
{"created":"2023-07-06 02:27:05","title":"Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning","abstract":"General purpose agents will require large repertoires of skills. Empowerment -- the maximum mutual information between skills and the states -- provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize. We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning. Our framework makes two specific contributions. First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons. Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales. We verify the contributions of the framework in a series of simulated robotics tasks. In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work.","sentences":["General purpose agents will require large repertoires of skills.","Empowerment -- the maximum mutual information between skills and the states -- provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize.","We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning.","Our framework makes two specific contributions.","First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons.","Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales.","We verify the contributions of the framework in a series of simulated robotics tasks.","In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work."],"url":"http://arxiv.org/abs/2307.02728v1"}
{"created":"2023-07-06 02:21:08","title":"Through the Fairness Lens: Experimental Analysis and Evaluation of Entity Matching","abstract":"Entity matching (EM) is a challenging problem studied by different communities for over half a century. Algorithmic fairness has also become a timely topic to address machine bias and its societal impacts. Despite extensive research on these two topics, little attention has been paid to the fairness of entity matching.   Towards addressing this gap, we perform an extensive experimental evaluation of a variety of EM techniques in this paper. We generated two social datasets from publicly available datasets for the purpose of auditing EM through the lens of fairness. Our findings underscore potential unfairness under two common conditions in real-world societies: (i) when some demographic groups are overrepresented, and (ii) when names are more similar in some groups compared to others. Among our many findings, it is noteworthy to mention that while various fairness definitions are valuable for different settings, due to EM's class imbalance nature, measures such as positive predictive value parity and true positive rate parity are, in general, more capable of revealing EM unfairness.","sentences":["Entity matching (EM) is a challenging problem studied by different communities for over half a century.","Algorithmic fairness has also become a timely topic to address machine bias and its societal impacts.","Despite extensive research on these two topics, little attention has been paid to the fairness of entity matching.   ","Towards addressing this gap, we perform an extensive experimental evaluation of a variety of EM techniques in this paper.","We generated two social datasets from publicly available datasets for the purpose of auditing EM through the lens of fairness.","Our findings underscore potential unfairness under two common conditions in real-world societies: (i) when some demographic groups are overrepresented, and (ii) when names are more similar in some groups compared to others.","Among our many findings, it is noteworthy to mention that while various fairness definitions are valuable for different settings, due to EM's class imbalance nature, measures such as positive predictive value parity and true positive rate parity are, in general, more capable of revealing EM unfairness."],"url":"http://arxiv.org/abs/2307.02726v1"}
{"created":"2023-07-06 02:18:41","title":"Massive MIMO with Cauchy Noise: Channel Estimation, Achievable Rate and Data Decoding","abstract":"We consider massive multiple-input multiple-output (MIMO) systems in the presence of Cauchy noise. First, we focus on the channel estimation problem. In the standard massive MIMO setup, the users transmit orthonormal pilots during the training phase and the received signal at the base station is projected onto each pilot. This processing is optimum when the noise is Gaussian. We show that this processing is not optimal when the noise is Cauchy and as a remedy propose a channel estimation technique that operates on the raw received signal. Second, we derive uplink-downlink achievable rates in the presence of Cauchy noise for perfect and imperfect channel state information. Finally, we derive log-likelihood ratio expressions for soft bit detection for both uplink and downlink, and simulate coded bit-error-rate curves. In addition to this, we derive and compare the symbol detectors in the presence of both Gaussian and Cauchy noises. An important observation is that the detector constructed for Cauchy noise performs well with both Gaussian and Cauchy noises; on the other hand, the detector for Gaussian noise works poorly in the presence of Cauchy noise. That is, the Cauchy detector is robust against heavy-tailed noise, whereas the Gaussian detector is not.","sentences":["We consider massive multiple-input multiple-output (MIMO) systems in the presence of Cauchy noise.","First, we focus on the channel estimation problem.","In the standard massive MIMO setup, the users transmit orthonormal pilots during the training phase and the received signal at the base station is projected onto each pilot.","This processing is optimum when the noise is Gaussian.","We show that this processing is not optimal when the noise is Cauchy and as a remedy propose a channel estimation technique that operates on the raw received signal.","Second, we derive uplink-downlink achievable rates in the presence of Cauchy noise for perfect and imperfect channel state information.","Finally, we derive log-likelihood ratio expressions for soft bit detection for both uplink and downlink, and simulate coded bit-error-rate curves.","In addition to this, we derive and compare the symbol detectors in the presence of both Gaussian and Cauchy noises.","An important observation is that the detector constructed for Cauchy noise performs well with both Gaussian and Cauchy noises; on the other hand, the detector for Gaussian noise works poorly in the presence of Cauchy noise.","That is, the Cauchy detector is robust against heavy-tailed noise, whereas the Gaussian detector is not."],"url":"http://arxiv.org/abs/2307.02724v1"}
{"created":"2023-07-06 02:03:31","title":"On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation","abstract":"Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting. To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting. Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives. We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset. Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints.","sentences":["Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting.","To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting.","Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives.","We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset.","Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints."],"url":"http://arxiv.org/abs/2307.02720v1"}
{"created":"2023-07-06 01:57:37","title":"Understanding Uncertainty Sampling","abstract":"Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of \"uncertainty\" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properness of existing uncertainty measures from two aspects: surrogate property and loss convexity. Furthermore, we propose a new notion for designing uncertainty measures called \\textit{loss as uncertainty}. The idea is to use the conditional expected loss given the features as the uncertainty measure. Such an uncertainty measure has nice analytical properties and generality to cover both classification and regression problems, which enable us to provide the first generalization bound for uncertainty sampling algorithms under both stream-based and pool-based settings, in the full generality of the underlying model and problem. Lastly, we establish connections between certain variants of the uncertainty sampling algorithms with risk-sensitive objectives and distributional robustness, which can partly explain the advantage of uncertainty sampling algorithms when the sample size is small.","sentences":["Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about.","However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of \"uncertainty\" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent.","In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning.","We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss.","The perspective verifies the properness of existing uncertainty measures from two aspects: surrogate property and loss convexity.","Furthermore, we propose a new notion for designing uncertainty measures called \\textit{loss as uncertainty}.","The idea is to use the conditional expected loss given the features as the uncertainty measure.","Such an uncertainty measure has nice analytical properties and generality to cover both classification and regression problems, which enable us to provide the first generalization bound for uncertainty sampling algorithms under both stream-based and pool-based settings, in the full generality of the underlying model and problem.","Lastly, we establish connections between certain variants of the uncertainty sampling algorithms with risk-sensitive objectives and distributional robustness, which can partly explain the advantage of uncertainty sampling algorithms when the sample size is small."],"url":"http://arxiv.org/abs/2307.02719v1"}
{"created":"2023-07-06 01:46:06","title":"TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations","abstract":"Accommodating all the weights on-chip for large-scale NNs remains a great challenge for SRAM based computing-in-memory (SRAM-CIM) with limited on-chip capacity. Previous non-volatile SRAM-CIM (nvSRAM-CIM) addresses this issue by integrating high-density single-level ReRAMs on the top of high-efficiency SRAM-CIM for weight storage to eliminate the off-chip memory access. However, previous SL-nvSRAM-CIM suffers from poor scalability for an increased number of SL-ReRAMs and limited computing efficiency. To overcome these challenges, this work proposes an ultra-high-density three-level ReRAMs-assisted computing-in-nonvolatile-SRAM (TL-nvSRAM-CIM) scheme for large NN models. The clustered n-selector-n-ReRAM (cluster-nSnRs) is employed for reliable weight-restore with eliminated DC power. Furthermore, a ternary SRAM-CIM mechanism with differential computing scheme is proposed for energy-efficient ternary MAC operations while preserving high NN accuracy. The proposed TL-nvSRAM-CIM achieves 7.8x higher storage density, compared with the state-of-art works. Moreover, TL-nvSRAM-CIM shows up to 2.9x and 1.9x enhanced energy-efficiency, respectively, compared to the baseline designs of SRAM-CIM and ReRAM-CIM, respectively.","sentences":["Accommodating all the weights on-chip for large-scale NNs remains a great challenge for SRAM based computing-in-memory (SRAM-CIM) with limited on-chip capacity.","Previous non-volatile SRAM-CIM (nvSRAM-CIM) addresses this issue by integrating high-density single-level ReRAMs on the top of high-efficiency SRAM-CIM for weight storage to eliminate the off-chip memory access.","However, previous SL-nvSRAM-CIM suffers from poor scalability for an increased number of SL-ReRAMs and limited computing efficiency.","To overcome these challenges, this work proposes an ultra-high-density three-level ReRAMs-assisted computing-in-nonvolatile-SRAM (TL-nvSRAM-CIM) scheme for large NN models.","The clustered n-selector-n-ReRAM (cluster-nSnRs) is employed for reliable weight-restore with eliminated DC power.","Furthermore, a ternary SRAM-CIM mechanism with differential computing scheme is proposed for energy-efficient ternary MAC operations while preserving high NN accuracy.","The proposed TL-nvSRAM-CIM achieves 7.8x higher storage density, compared with the state-of-art works.","Moreover, TL-nvSRAM-CIM shows up to 2.9x and 1.9x enhanced energy-efficiency, respectively, compared to the baseline designs of SRAM-CIM and ReRAM-CIM, respectively."],"url":"http://arxiv.org/abs/2307.02717v1"}
{"created":"2023-07-06 01:46:00","title":"CFSum: A Coarse-to-Fine Contribution Network for Multimodal Summarization","abstract":"Multimodal summarization usually suffers from the problem that the contribution of the visual modality is unclear. Existing multimodal summarization approaches focus on designing the fusion methods of different modalities, while ignoring the adaptive conditions under which visual modalities are useful. Therefore, we propose a novel Coarse-to-Fine contribution network for multimodal Summarization (CFSum) to consider different contributions of images for summarization. First, to eliminate the interference of useless images, we propose a pre-filter module to abandon useless images. Second, to make accurate use of useful images, we propose two levels of visual complement modules, word level and phrase level. Specifically, image contributions are calculated and are adopted to guide the attention of both textual and visual modalities. Experimental results have shown that CFSum significantly outperforms multiple strong baselines on the standard benchmark. Furthermore, the analysis verifies that useful images can even help generate non-visual words which are implicitly represented in the image.","sentences":["Multimodal summarization usually suffers from the problem that the contribution of the visual modality is unclear.","Existing multimodal summarization approaches focus on designing the fusion methods of different modalities, while ignoring the adaptive conditions under which visual modalities are useful.","Therefore, we propose a novel Coarse-to-Fine contribution network for multimodal Summarization (CFSum) to consider different contributions of images for summarization.","First, to eliminate the interference of useless images, we propose a pre-filter module to abandon useless images.","Second, to make accurate use of useful images, we propose two levels of visual complement modules, word level and phrase level.","Specifically, image contributions are calculated and are adopted to guide the attention of both textual and visual modalities.","Experimental results have shown that CFSum significantly outperforms multiple strong baselines on the standard benchmark.","Furthermore, the analysis verifies that useful images can even help generate non-visual words which are implicitly represented in the image."],"url":"http://arxiv.org/abs/2307.02716v1"}
{"created":"2023-07-06 01:26:01","title":"Multi-Similarity Contrastive Learning","abstract":"Given a similarity metric, contrastive methods learn a representation in which examples that are similar are pushed together and examples that are dissimilar are pulled apart. Contrastive learning techniques have been utilized extensively to learn representations for tasks ranging from image classification to caption generation. However, existing contrastive learning approaches can fail to generalize because they do not take into account the possibility of different similarity relations. In this paper, we propose a novel multi-similarity contrastive loss (MSCon), that learns generalizable embeddings by jointly utilizing supervision from multiple metrics of similarity. Our method automatically learns contrastive similarity weightings based on the uncertainty in the corresponding similarity, down-weighting uncertain tasks and leading to better out-of-domain generalization to new tasks. We show empirically that networks trained with MSCon outperform state-of-the-art baselines on in-domain and out-of-domain settings.","sentences":["Given a similarity metric, contrastive methods learn a representation in which examples that are similar are pushed together and examples that are dissimilar are pulled apart.","Contrastive learning techniques have been utilized extensively to learn representations for tasks ranging from image classification to caption generation.","However, existing contrastive learning approaches can fail to generalize because they do not take into account the possibility of different similarity relations.","In this paper, we propose a novel multi-similarity contrastive loss (MSCon), that learns generalizable embeddings by jointly utilizing supervision from multiple metrics of similarity.","Our method automatically learns contrastive similarity weightings based on the uncertainty in the corresponding similarity, down-weighting uncertain tasks and leading to better out-of-domain generalization to new tasks.","We show empirically that networks trained with MSCon outperform state-of-the-art baselines on in-domain and out-of-domain settings."],"url":"http://arxiv.org/abs/2307.02712v1"}
{"created":"2023-07-06 01:17:29","title":"Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels","abstract":"Logical assessment formula (LAF) is a new theory proposed for evaluations with inaccurate ground-truth labels (IAGTLs) to assess the predictive models for various artificial intelligence applications. However, the practicability of LAF for evaluations with IAGTLs has not yet been validated in real-world practice. In this paper, to address this issue, we applied LAF to tumour segmentation for breast cancer (TSfBC) in medical histopathology whole slide image analysis (MHWSIA). Experimental results and analysis show the validity of LAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials of LAF applied to MHWSIA.","sentences":["Logical assessment formula (LAF) is a new theory proposed for evaluations with inaccurate ground-truth labels (IAGTLs) to assess the predictive models for various artificial intelligence applications.","However, the practicability of LAF for evaluations with IAGTLs has not yet been validated in real-world practice.","In this paper, to address this issue, we applied LAF to tumour segmentation for breast cancer (TSfBC) in medical histopathology whole slide image analysis (MHWSIA).","Experimental results and analysis show the validity of LAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials of LAF applied to MHWSIA."],"url":"http://arxiv.org/abs/2307.02709v1"}
{"created":"2023-07-06 01:05:34","title":"Towards Symmetry-Aware Generation of Periodic Materials","abstract":"We consider the problem of generating periodic materials with deep models. While symmetry-aware molecule generation has been studied extensively, periodic materials possess different symmetries, which have not been completely captured by existing methods. In this work, we propose SyMat, a novel material generation approach that can capture physical symmetries of periodic material structures. SyMat generates atom types and lattices of materials through generating atom type sets, lattice lengths and lattice angles with a variational auto-encoder model. In addition, SyMat employs a score-based diffusion model to generate atom coordinates of materials, in which a novel symmetry-aware probabilistic model is used in the coordinate diffusion process. We show that SyMat is theoretically invariant to all symmetry transformations on materials and demonstrate that SyMat achieves promising performance on random generation and property optimization tasks.","sentences":["We consider the problem of generating periodic materials with deep models.","While symmetry-aware molecule generation has been studied extensively, periodic materials possess different symmetries, which have not been completely captured by existing methods.","In this work, we propose SyMat, a novel material generation approach that can capture physical symmetries of periodic material structures.","SyMat generates atom types and lattices of materials through generating atom type sets, lattice lengths and lattice angles with a variational auto-encoder model.","In addition, SyMat employs a score-based diffusion model to generate atom coordinates of materials, in which a novel symmetry-aware probabilistic model is used in the coordinate diffusion process.","We show that SyMat is theoretically invariant to all symmetry transformations on materials and demonstrate that SyMat achieves promising performance on random generation and property optimization tasks."],"url":"http://arxiv.org/abs/2307.02707v1"}
{"created":"2023-07-06 00:37:30","title":"A Logical Way to Negotiate Services","abstract":"Service providers commonly provide only a fixed catalog of services to their clients. Both clients and service providers can benefit from service negotiation, in which a client makes a query for a specific service, and the provider counters with an offer. The query could include parameters that control the performance, reliability, and function of the service. However, a problem with service negotiation is that it can be expensive for a service provider to support.   In this paper we define a formal negotiation policy language that enables automated service negotiation. In the model supported by the language, service providers can recursively obtain the services they need from sub-providers. The queries made by clients, and the offers returned from service providers, are expressed in quantifier-free first-order logic. Quantifier elimination is used to transform constraints between providers and sub-providers. The pattern of interaction between clients and service providers is defined in process algebra. We show a correctness property of our language: if sub-providers respond positively to queries, then so does the provider itself.","sentences":["Service providers commonly provide only a fixed catalog of services to their clients.","Both clients and service providers can benefit from service negotiation, in which a client makes a query for a specific service, and the provider counters with an offer.","The query could include parameters that control the performance, reliability, and function of the service.","However, a problem with service negotiation is that it can be expensive for a service provider to support.   ","In this paper we define a formal negotiation policy language that enables automated service negotiation.","In the model supported by the language, service providers can recursively obtain the services they need from sub-providers.","The queries made by clients, and the offers returned from service providers, are expressed in quantifier-free first-order logic.","Quantifier elimination is used to transform constraints between providers and sub-providers.","The pattern of interaction between clients and service providers is defined in process algebra.","We show a correctness property of our language: if sub-providers respond positively to queries, then so does the provider itself."],"url":"http://arxiv.org/abs/2307.02703v1"}
{"created":"2023-07-06 00:33:15","title":"Incremental Nonlinear Dynamic Inversion based Optical Flow Control for Flying Robots: An Efficient Data-driven Approach","abstract":"This paper presents a novel approach for optical flow control of Micro Air Vehicles (MAVs). The task is challenging due to the nonlinearity of optical flow observables. Our proposed Incremental Nonlinear Dynamic Inversion (INDI) control scheme incorporates an efficient data-driven method to address the nonlinearity. It directly estimates the inverse of the time-varying control effectiveness in real-time, eliminating the need for the constant assumption and avoiding high computation in traditional INDI. This approach effectively handles fast-changing system dynamics commonly encountered in optical flow control, particularly height-dependent changes. We demonstrate the robustness and efficiency of the proposed control scheme in numerical simulations and also real-world flight tests: multiple landings of an MAV on a static and flat surface with various tracking setpoints, hovering and landings on moving and undulating surfaces. Despite being challenged with the presence of noisy optical flow estimates and the lateral and vertical movement of the landing surfaces, the MAV is able to successfully track or land on the surface with an exponential decay of both height and vertical velocity at almost the same time, as desired.","sentences":["This paper presents a novel approach for optical flow control of Micro Air Vehicles (MAVs).","The task is challenging due to the nonlinearity of optical flow observables.","Our proposed Incremental Nonlinear Dynamic Inversion (INDI) control scheme incorporates an efficient data-driven method to address the nonlinearity.","It directly estimates the inverse of the time-varying control effectiveness in real-time, eliminating the need for the constant assumption and avoiding high computation in traditional INDI.","This approach effectively handles fast-changing system dynamics commonly encountered in optical flow control, particularly height-dependent changes.","We demonstrate the robustness and efficiency of the proposed control scheme in numerical simulations and also real-world flight tests: multiple landings of an MAV on a static and flat surface with various tracking setpoints, hovering and landings on moving and undulating surfaces.","Despite being challenged with the presence of noisy optical flow estimates and the lateral and vertical movement of the landing surfaces, the MAV is able to successfully track or land on the surface with an exponential decay of both height and vertical velocity at almost the same time, as desired."],"url":"http://arxiv.org/abs/2307.02702v1"}
{"created":"2023-07-06 00:32:42","title":"Touch, press and stroke: a soft capacitive sensor skin","abstract":"Soft sensors that can discriminate shear and normal force could help provide machines the fine control desirable for safe and effective physical interactions with people. A capacitive sensor is made for this purpose, composed of patterned elastomer and containing both fixed and sliding pillars that allow the sensor to deform and buckle, much like skin itself. The sensor differentiates between simultaneously applied pressure and shear. In addition, finger proximity is detectable up to 15 mm, with a pressure and shear sensitivity of 1 kPa and a displacement resolution of 50 $\\mu$m. The operation is demonstrated on a simple gripper holding a cup. The combination of features and the straightforward fabrication method make this sensor a candidate for implementation as a sensing skin for humanoid robotics applications.","sentences":["Soft sensors that can discriminate shear and normal force could help provide machines the fine control desirable for safe and effective physical interactions with people.","A capacitive sensor is made for this purpose, composed of patterned elastomer and containing both fixed and sliding pillars that allow the sensor to deform and buckle, much like skin itself.","The sensor differentiates between simultaneously applied pressure and shear.","In addition, finger proximity is detectable up to 15 mm, with a pressure and shear sensitivity of 1 kPa and a displacement resolution of 50 $\\mu$m.","The operation is demonstrated on a simple gripper holding a cup.","The combination of features and the straightforward fabrication method make this sensor a candidate for implementation as a sensing skin for humanoid robotics applications."],"url":"http://arxiv.org/abs/2307.02701v1"}
{"created":"2023-07-06 00:07:32","title":"Applying a Color Palette with Local Control using Diffusion Models","abstract":"We demonstrate two novel editing procedures in the context of fantasy card art. Palette transfer applies a specified reference palette to a given card. For fantasy art, the desired change in palette can be very large, leading to huge changes in the \"look\" of the art. We demonstrate that a pipeline of vector quantization; matching; and \"vector dequantization\" (using a diffusion model) produces successful extreme palette transfers. Segment control allows an artist to move one or more image segments, and to optionally specify the desired color of the result. The combination of these two types of edit yields valuable workflows, including: move a segment, then recolor; recolor, then force some segments to take a prescribed color. We demonstrate our methods on the challenging Yu-Gi-Oh card art dataset.","sentences":["We demonstrate two novel editing procedures in the context of fantasy card art.","Palette transfer applies a specified reference palette to a given card.","For fantasy art, the desired change in palette can be very large, leading to huge changes in the \"look\" of the art.","We demonstrate that a pipeline of vector quantization; matching; and \"vector dequantization\" (using a diffusion model) produces successful extreme palette transfers.","Segment control allows an artist to move one or more image segments, and to optionally specify the desired color of the result.","The combination of these two types of edit yields valuable workflows, including: move a segment, then recolor; recolor, then force some segments to take a prescribed color.","We demonstrate our methods on the challenging Yu-Gi-Oh card art dataset."],"url":"http://arxiv.org/abs/2307.02698v1"}
{"created":"2023-07-06 00:06:14","title":"Statistical Mechanics of Strahler Number via Random and Natural Language Sentences","abstract":"The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications. This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures, which are available in a large dataset allowing for statistical mechanics analysis.   Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost always 3 or 4, similar to the case of river bifurcation as reported by Strahler (1957) and Horton (1945).   From the theory behind the number, we show that it is the lower limit of the amount of memory required to process sentences under a particular model. A mathematical analysis of random trees provides a further conjecture on the nature of the Strahler number, revealing that it is not a constant but grows logarithmically. This finding uncovers the statistical basics behind the Strahler number as a characteristic of a general tree structure target.","sentences":["The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications.","This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures, which are available in a large dataset allowing for statistical mechanics analysis.   ","Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost always 3 or 4, similar to the case of river bifurcation as reported by Strahler (1957) and Horton (1945).   ","From the theory behind the number, we show that it is the lower limit of the amount of memory required to process sentences under a particular model.","A mathematical analysis of random trees provides a further conjecture on the nature of the Strahler number, revealing that it is not a constant but grows logarithmically.","This finding uncovers the statistical basics behind the Strahler number as a characteristic of a general tree structure target."],"url":"http://arxiv.org/abs/2307.02697v1"}
{"created":"2023-07-05 23:53:55","title":"Loss Functions and Metrics in Deep Learning. A Review","abstract":"One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.","sentences":["One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models.","This paper reviews the most prevalent loss functions and performance measurements in deep learning.","We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems.","Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task."],"url":"http://arxiv.org/abs/2307.02694v1"}
{"created":"2023-07-05 23:51:05","title":"Kernels, Data & Physics","abstract":"Lecture notes from the course given by Professor Julia Kempe at the summer school \"Statistical physics of Machine Learning\" in Les Houches. The notes discuss the so-called NTK approach to problems in machine learning, which consists of gaining an understanding of generally unsolvable problems by finding a tractable kernel formulation. The notes are mainly focused on practical applications such as data distillation and adversarial robustness, examples of inductive bias are also discussed.","sentences":["Lecture notes from the course given by Professor Julia Kempe at the summer school \"Statistical physics of Machine Learning\" in Les Houches.","The notes discuss the so-called NTK approach to problems in machine learning, which consists of gaining an understanding of generally unsolvable problems by finding a tractable kernel formulation.","The notes are mainly focused on practical applications such as data distillation and adversarial robustness, examples of inductive bias are also discussed."],"url":"http://arxiv.org/abs/2307.02693v1"}
{"created":"2023-07-05 23:36:33","title":"SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding","abstract":"Multi-Agent Path Finding (MAPF) is a crucial component for many large-scale robotic systems, where agents must plan their collision-free paths to their given goal positions. Recently, multi-agent reinforcement learning has been introduced to solve the partially observable variant of MAPF by learning a decentralized single-agent policy in a centralized fashion based on each agent's partial observation. However, existing learning-based methods are ineffective in achieving complex multi-agent cooperation, especially in congested environments, due to the non-stationarity of this setting. To tackle this challenge, we propose a multi-agent actor-critic method called Soft Actor-Critic with Heuristic-Based Attention (SACHA), which employs novel heuristic-based attention mechanisms for both the actors and critics to encourage cooperation among agents. SACHA learns a neural network for each agent to selectively pay attention to the shortest path heuristic guidance from multiple agents within its field of view, thereby allowing for more scalable learning of cooperation. SACHA also extends the existing multi-agent actor-critic framework by introducing a novel critic centered on each agent to approximate $Q$-values. Compared to existing methods that use a fully observable critic, our agent-centered multi-agent actor-critic method results in more impartial credit assignment and better generalizability of the learned policy to MAPF instances with varying numbers of agents and types of environments. We also implement SACHA(C), which embeds a communication module in the agent's policy network to enable information exchange among agents. We evaluate both SACHA and SACHA(C) on a variety of MAPF instances and demonstrate decent improvements over several state-of-the-art learning-based MAPF methods with respect to success rate and solution quality.","sentences":["Multi-Agent Path Finding (MAPF) is a crucial component for many large-scale robotic systems, where agents must plan their collision-free paths to their given goal positions.","Recently, multi-agent reinforcement learning has been introduced to solve the partially observable variant of MAPF by learning a decentralized single-agent policy in a centralized fashion based on each agent's partial observation.","However, existing learning-based methods are ineffective in achieving complex multi-agent cooperation, especially in congested environments, due to the non-stationarity of this setting.","To tackle this challenge, we propose a multi-agent actor-critic method called Soft Actor-Critic with Heuristic-Based Attention (SACHA), which employs novel heuristic-based attention mechanisms for both the actors and critics to encourage cooperation among agents.","SACHA learns a neural network for each agent to selectively pay attention to the shortest path heuristic guidance from multiple agents within its field of view, thereby allowing for more scalable learning of cooperation.","SACHA also extends the existing multi-agent actor-critic framework by introducing a novel critic centered on each agent to approximate $Q$-values.","Compared to existing methods that use a fully observable critic, our agent-centered multi-agent actor-critic method results in more impartial credit assignment and better generalizability of the learned policy to MAPF instances with varying numbers of agents and types of environments.","We also implement SACHA(C), which embeds a communication module in the agent's policy network to enable information exchange among agents.","We evaluate both SACHA and SACHA(C) on a variety of MAPF instances and demonstrate decent improvements over several state-of-the-art learning-based MAPF methods with respect to success rate and solution quality."],"url":"http://arxiv.org/abs/2307.02691v1"}
{"created":"2023-07-05 23:26:01","title":"Scaling In-Context Demonstrations with Structured Attention","abstract":"The recent surge of large language models (LLMs) highlights their ability to perform in-context learning, i.e., \"learning\" to perform a task from a few demonstrations in the context without any parameter updates. However, their capabilities of in-context learning are limited by the model architecture: 1) the use of demonstrations is constrained by a maximum sentence length due to positional embeddings; 2) the quadratic complexity of attention hinders users from using more demonstrations efficiently; 3) LLMs are shown to be sensitive to the order of the demonstrations. In this work, we tackle these challenges by proposing a better architectural design for in-context learning. We propose SAICL (Structured Attention for In-Context Learning), which replaces the full-attention by a structured attention mechanism designed for in-context learning, and removes unnecessary dependencies between individual demonstrations, while making the model invariant to the permutation of demonstrations. We evaluate SAICL in a meta-training framework and show that SAICL achieves comparable or better performance than full attention while obtaining up to 3.4x inference speed-up. SAICL also consistently outperforms a strong Fusion-in-Decoder (FiD) baseline which processes each demonstration independently. Finally, thanks to its linear nature, we demonstrate that SAICL can easily scale to hundreds of demonstrations with continuous performance gains with scaling.","sentences":["The recent surge of large language models (LLMs) highlights their ability to perform in-context learning, i.e., \"learning\" to perform a task from a few demonstrations in the context without any parameter updates.","However, their capabilities of in-context learning are limited by the model architecture: 1) the use of demonstrations is constrained by a maximum sentence length due to positional embeddings; 2) the quadratic complexity of attention hinders users from using more demonstrations efficiently; 3) LLMs are shown to be sensitive to the order of the demonstrations.","In this work, we tackle these challenges by proposing a better architectural design for in-context learning.","We propose SAICL (Structured Attention for In-Context Learning), which replaces the full-attention by a structured attention mechanism designed for in-context learning, and removes unnecessary dependencies between individual demonstrations, while making the model invariant to the permutation of demonstrations.","We evaluate SAICL in a meta-training framework and show that SAICL achieves comparable or better performance than full attention while obtaining up to 3.4x inference speed-up.","SAICL also consistently outperforms a strong Fusion-in-Decoder (FiD) baseline which processes each demonstration independently.","Finally, thanks to its linear nature, we demonstrate that SAICL can easily scale to hundreds of demonstrations with continuous performance gains with scaling."],"url":"http://arxiv.org/abs/2307.02690v1"}
{"created":"2023-07-05 23:21:05","title":"Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning","abstract":"Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.","sentences":["Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games.","On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks.","This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data.","Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies.","Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions."],"url":"http://arxiv.org/abs/2307.02689v1"}
